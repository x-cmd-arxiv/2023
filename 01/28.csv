"2301.11752","Pravin Kumar Rana Mr.","Pravin Kumar Rana and Markus Flierl","Inter-View Depth Consistency Testing in Depth Difference Subspace",,,,,"cs.CV cs.MM eess.IV","http://creativecommons.org/licenses/by/4.0/","  Multiview depth imagery will play a critical role in free-viewpoint
television. This technology requires high quality virtual view synthesis to
enable viewers to move freely in a dynamic real world scene. Depth imagery at
different viewpoints is used to synthesize an arbitrary number of novel views.
Usually, depth images at multiple viewpoints are estimated individually by
stereo-matching algorithms, and hence, show lack of interview consistency. This
inconsistency affects the quality of view synthesis negatively. This paper
proposes a method for depth consistency testing in depth difference subspace to
enhance the depth representation of a scene across multiple viewpoints.
Furthermore, we propose a view synthesis algorithm that uses the obtained
consistency information to improve the visual quality of virtual views at
arbitrary viewpoints. Our method helps us to find a linear subspace for our
depth difference measurements in which we can test the inter-view consistency
efficiently. With this, our approach is able to enhance the depth information
for real world scenes. In combination with our consistency-adaptive view
synthesis, we improve the visual experience of the free-viewpoint user. The
experiments show that our approach enhances the objective quality of virtual
views by up to 1.4 dB. The advantage for the subjective quality is also
demonstrated.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:43:38 GMT""}]","2023-01-30"
"2301.11809","Eyad Hasan Hasan","Eyad Hasan Hasan","Quantization of Fractional Singular Lagrangian systems with Second-Order
  Derivatives Using Path Integral Method","arXiv admin note: substantial text overlap with arXiv:2301.08133",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  The fractional quantization of singular systems with second order Lagrangian
is examined. The fractional singular Lagrangian is presented. The equations of
motion are written as total differential equations within fractional calculus.
Also, the set of Hamilton Jacobi partial differential equations is constructed
in fractional form. The path integral formulation and path integral
quantization for these systems are constructed within fractional derivatives.
We examined a mathematical singular Lagrangian with two primary first class
constraints.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:03:16 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 17:19:22 GMT""}]","2023-02-01"
"2301.11810","Floran de Putter","David van Son, Floran de Putter, Sebastian Vogel, Henk Corporaal","BOMP-NAS: Bayesian Optimization Mixed Precision NAS",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian Optimization Mixed-Precision Neural Architecture Search (BOMP-NAS)
is an approach to quantization-aware neural architecture search (QA-NAS) that
leverages both Bayesian optimization (BO) and mixed-precision quantization (MP)
to efficiently search for compact, high performance deep neural networks. The
results show that integrating quantization-aware fine-tuning (QAFT) into the
NAS loop is a necessary step to find networks that perform well under
low-precision quantization: integrating it allows a model size reduction of
nearly 50\% on the CIFAR-10 dataset. BOMP-NAS is able to find neural networks
that achieve state of the art performance at much lower design costs. This
study shows that BOMP-NAS can find these neural networks at a 6x shorter search
time compared to the closest related work.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:04:34 GMT""}]","2023-01-30"
"2301.11814","M. Cristina Volpe","Maria Cristina Volpe","Neutrinos from dense: flavor mechanisms, theoretical approaches,
  observations, new directions","45 pages",,,,"hep-ph astro-ph.SR hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutrino masses and mixings produce vacuum oscillations, an established
quantum mechanical phenomenon. In matter, the Mikheev-Smirnov-Wolfenstein
effect, due to neutrino interactions with the background particles, triggers
resonant flavor modification. In dense environments, sizable neutrino-neutrino
interactions, shock waves and turbulence impact the neutrino flavor content
under a variety of phenomena. Theoretical approaches of neutrino propagation
range from the mean-field approximation to the full quantum kinetic equations.
Intriguing connections have been uncovered between weakly interacting dense
neutrino gases and other many-body systems and domains, from condensed matter
and nuclear physics to quantum computing. Besides the intrinsic theoretical
interest, establishing how neutrinos change flavor contributes to answer the
longstanding open questions of how massive stars explode and of the r-process
sites. It is also important for future observations of core-collapse supernova
neutrinos and of the diffuse supernova neutrino background that should be
discovered in the foreseeable future.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:07:03 GMT""}]","2023-01-30"
"2301.11815","Matias Bundgaard-Nielsen","Matias Bundgaard-Nielsen and Emil Vosmar Denning and Marco Saldutti
  and Jesper M{\o}rk","A stochastic approach to the quantum noise of a single-emitter nanolaser","Revised and resubmitted for review",,,,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that the intensity quantum noise of a single-emitter nanolaser
can be accurately computed by adopting a stochastic interpretation of the
standard rate equation model under the only assumption that the emitter
excitation and photon number are stochastic variables with integer values. This
extends the validity of rate equations beyond the mean-field limit and avoids
using the standard Langevin approach, which is shown to fail for few emitters.
The model is validated by comparison to full quantum simulations of the
relative intensity noise and second-order intensity correlation function,
g(2)({\tau} ). Surprisingly, even when the full quantum model displays vacuum
Rabi oscillations, which are not accounted for by rate equations, the intensity
quantum noise is correctly predicted by the stochastic approach. Adopting a
simple discretization of the emitter and photon populations, thus, goes a long
way in describing quantum noise in lasers. Besides providing a versatile and
easy-to-use tool for modeling a new generation of nanolasers with many possible
applications, these results provide insight into the fundamental nature of
quantum noise in lasers.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:10:33 GMT""},{""version"":""v2"",""created"":""Wed, 19 Apr 2023 13:24:49 GMT""}]","2023-04-20"
"2301.11816","Ying Zhang","Ying Zhang, Heyong Wang, Maoliang Yin, Jiankun Wang, and Changchun Hua","Bi-AM-RRT*: A Fast and Efficient Sampling-Based Motion Planning
  Algorithm in Dynamic Environments","Submitted to IEEE Transactions on Intelligent Vehicles",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The efficiency of sampling-based motion planning brings wide application in
autonomous mobile robots. The conventional rapidly exploring random tree (RRT)
algorithm and its variants have gained significant successes, but there are
still challenges for the optimal motion planning of mobile robots in dynamic
environments. In this paper, based on Bidirectional RRT and the use of an
assisting metric (AM), we propose a novel motion planning algorithm, namely
Bi-AM-RRT*. Different from the existing RRT-based methods, the AM is introduced
in this paper to optimize the performance of robot motion planning in dynamic
environments with obstacles. On this basis, the bidirectional search sampling
strategy is employed to reduce the search time. Further, we present a new
rewiring method to shorten path lengths. The effectiveness and efficiency of
the proposed Bi-AM-RRT* are proved through comparative experiments in different
environments. Experimental results show that the Bi-AM-RRT* algorithm can
achieve better performance in terms of path length and search time, and always
finds near-optimal paths with the shortest search time when the diffusion
metric is used as the AM.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:11:03 GMT""},{""version"":""v2"",""created"":""Sun, 30 Apr 2023 09:24:18 GMT""}]","2023-05-02"
"2301.11817","Alexander Rogozin V.","Dmitriy Metelev, Alexander Rogozin, Dmitry Kovalev, Alexander Gasnikov","Is Consensus Acceleration Possible in Decentralized Optimization over
  Slowly Time-Varying Networks?",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider decentralized optimization problems where one aims to minimize a
sum of convex smooth objective functions distributed between nodes in the
network. The links in the network can change from time to time. For the setting
when the amount of changes is arbitrary, lower complexity bounds and
corresponding optimal algorithms are known, and the consensus acceleration is
not possible. However, in practice the magnitude of network changes may be
limited. We derive lower communication complexity bounds for several regimes of
velocity of networks changes. Moreover, we show how to obtain accelerated
communication rates for a certain class of time-varying graphs using a specific
consensus algorithm.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:11:55 GMT""}]","2023-01-30"
"2301.11818","Michael D. Graham","Andrew J. Fox and Michael D. Graham","Predicting extreme events in a data-driven model of turbulent shear flow
  using an atlas of charts","7 pages, 7 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Dynamical systems with extreme events are difficult to capture with
data-driven modeling, due to the relative scarcity of data within extreme
events compared to the typical dynamics of the system, and the strong
dependence of the long-time occurrence of extreme events on short-time
conditions.A recently developed technique [Floryan, D. & Graham, M. D.
Data-driven discovery of intrinsic dynamics. Nat Mach Intell $\textbf{4}$,
1113-1120 (2022)], here denoted as $\textit{Charts and Atlases for Nonlinear
Data-Driven Dynamics on Manifolds}$, or CANDyMan, overcomes these difficulties
by decomposing the time series into separate charts based on data similarity,
learning dynamical models on each chart via individual time-mapping neural
networks, then stitching the charts together to create a single atlas to yield
a global dynamical model. We apply CANDyMan to a nine-dimensional model of
turbulent shear flow between infinite parallel free-slip walls under a
sinusoidal body force [Moehlis, J., Faisst, H. & Eckhardt, B. A low-dimensional
model for turbulent shear flows. New J Phys $\textbf{6}$, 56 (2004)], which
undergoes extreme events in the form of intermittent quasi-laminarization and
long-time full laminarization. We demonstrate that the CANDyMan method allows
the trained dynamical models to more accurately forecast the evolution of the
model coefficients, reducing the error in the predictions as the model evolves
forward in time. The technique exhibits more accurate predictions of extreme
events, capturing the frequency of quasi-laminarization events and predicting
the time until full laminarization more accurately than a single neural
network.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:15:51 GMT""}]","2023-01-30"
"2301.11819","Seishi Enomoto","Seishi Enomoto, Yu-Hang Su, Man-Zhu Zheng, Hong-Hao Zhang","Boltzmann equation and its cosmological applications","34 pages, 2 figures, 1 table",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We review the derivation of the Boltzmann equation and its cosmological
applications in this paper. The derivation of the Boltzmann equation,
especially the collision term, is discussed in detail in the language of the
quantum field theory without any assumption of the finite temperature system.
We also discuss the integrated Boltzmann equation with the deal of the
temperature parameter as an extension of the standard equation. Among a number
of its cosmological applications, we mainly target two familiar examples, the
dynamics of the dark matter abundance through the freeze-out/in process and a
baryogenesis scenario. The formulations in those systems are briefly discussed
with techniques in their calculations.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:17:52 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 07:48:42 GMT""},{""version"":""v3"",""created"":""Tue, 28 Feb 2023 20:10:15 GMT""}]","2023-03-02"
"2301.11820","Robert Cardona","Robert Cardona","Hydrodynamic and symbolic models of hypercomputation","28 pages, corrections of the second part",,,,"math-ph cs.CC math.DS math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamical systems and physical models defined on idealized continuous phase
spaces are known to exhibit non-computable phenomena, examples include the wave
equation, recurrent neural networks, or Julia sets in holomorphic dynamics.
Inspired by the works of Moore and Siegelmann, we show that ideal fluids,
modeled by the Euler equations, are capable of simulating poly-time Turing
machines with polynomial advice on compact three-dimensional domains. The
complexity class that is shown to be computable by stationary ideal fluids is
precisely the one considered by Siegelmann in her study of analog recurrent
neural networks: the class $P/poly$. In the last part, we introduce a new class
of symbolic systems, related to countably piecewise linear transformations of
the unit square, that is capable of simulating Turing machines with advice in
real-time, contrary to previously known models.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:18:23 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 17:12:12 GMT""}]","2023-03-07"
"2301.11821","Stephen Adler","Stephen L. Adler","Dynamical gravastars may evade no-go results for exotic compact objects,
  together with further analytical and numerical results for the dynamical
  gravastar model","15 pages; sections 6 and 7 added in version 5",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using graphs plotted from the Mathematica notebooks posted with our paper
``Dynamical Gravastars'', we show that a dynamical gravastar has no hard
surface, and that a second light sphere resides in the deep interior where
there is maximum time dilation. These facts may permit dynamical gravastars to
evade no-go results for exotic compact objects relating to light leakage inside
the shadow, and nonlinear instabilities arising from an interior light sphere.
Testing either of these surmises will require further detailed modeling
calculations. We also discuss the effect of replacing the sigmoidal function in
the gravastar calculation by a unit step function, and we analyze why the
dynamical gravastar evades the singularities predicted by the Penrose and
Hawking singularity theorems, despite satisfying both the null and strong
energy conditions. Finally, we give a simplified two-step process for tuning
the initial value $\nu(0)={\rm nuinit}$ to achieve $\nu(\infty)=0$, and we give
exact integrals for the pressure differential equation in terms of $\nu(r)$ in
the interior and exterior regions.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:22:07 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 17:05:45 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 21:03:23 GMT""},{""version"":""v4"",""created"":""Tue, 14 Mar 2023 15:21:17 GMT""},{""version"":""v5"",""created"":""Wed, 24 May 2023 15:22:39 GMT""},{""version"":""v6"",""created"":""Thu, 25 May 2023 01:03:23 GMT""}]","2023-05-26"
"2301.11822","Giorgio Stefani","Marco Inversi and Giorgio Stefani","Lagrangian stability for a system of non-local continuity equations
  under Osgood condition","11 pages",,,,"math.AP math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend known existence and uniqueness results of weak measure solutions
for systems of non-local continuity equations beyond the usual Lipschitz
regularity. Existence of weak measure solutions holds for uniformly continuous
vector fields and convolution kernels, while uniqueness follows from a
Lagrangian stability estimate under an additional Osgood condition.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:24:48 GMT""}]","2023-01-30"
"2301.11823","Mostafa Ahmadi","Mostafa Ahmadi, Amin Alizadeh Naeini, Mohammad Moein Sheikholeslami,
  Zahra Arjmandi, Yujia Zhang, and Gunho Sohn","HDPV-SLAM: Hybrid Depth-augmented Panoramic Visual SLAM for Mobile
  Mapping System with Tilted LiDAR and Panoramic Visual Camera",,,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a novel visual simultaneous localization and mapping
(SLAM) system called Hybrid Depth-augmented Panoramic Visual SLAM (HDPV-SLAM),
that employs a panoramic camera and a tilted multi-beam LiDAR scanner to
generate accurate and metrically-scaled trajectories. RGB-D SLAM was the design
basis for HDPV-SLAM, which added depth information to visual features. It aims
to solve the two major issues hindering the performance of similar SLAM
systems. The first obstacle is the sparseness of LiDAR depth, which makes it
difficult to correlate it with the extracted visual features of the RGB image.
A deep learning-based depth estimation module for iteratively densifying sparse
LiDAR depth was suggested to address this issue. The second issue pertains to
the difficulties in depth association caused by a lack of horizontal overlap
between the panoramic camera and the tilted LiDAR sensor. To surmount this
difficulty, we present a hybrid depth association module that optimally
combines depth information estimated by two independent procedures,
feature-based triangulation and depth estimation. During a phase of feature
tracking, this hybrid depth association module aims to maximize the use of more
accurate depth information between the triangulated depth with visual features
tracked and the deep learning-based corrected depth. We evaluated the efficacy
of HDPV-SLAM using the 18.95 km-long York University and Teledyne Optech (YUTO)
MMS dataset. The experimental results demonstrate that the two proposed modules
contribute substantially to the performance of HDPV-SLAM, which surpasses that
of the state-of-the-art (SOTA) SLAM systems.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:25:28 GMT""},{""version"":""v2"",""created"":""Sat, 18 Mar 2023 06:25:51 GMT""}]","2023-03-21"
"2301.11824","Yuhao Zhang","Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni","PECAN: A Deterministic Certified Defense Against Backdoor Attacks",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Neural networks are vulnerable to backdoor poisoning attacks, where the
attackers maliciously poison the training set and insert triggers into the test
input to change the prediction of the victim model. Existing defenses for
backdoor attacks either provide no formal guarantees or come with
expensive-to-compute and ineffective probabilistic guarantees. We present
PECAN, an efficient and certified approach for defending against backdoor
attacks. The key insight powering PECAN is to apply off-the-shelf test-time
evasion certification techniques on a set of neural networks trained on
disjoint partitions of the data. We evaluate PECAN on image classification and
malware detection datasets. Our results demonstrate that PECAN can (1)
significantly outperform the state-of-the-art certified backdoor defense, both
in defense strength and efficiency, and (2) on real back-door attacks, PECAN
can reduce attack success rate by order of magnitude when compared to a range
of baselines from the literature.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:25:43 GMT""}]","2023-01-30"
"2301.11825","Hallouin Emmanuel","R\'egis Blache, Emmanuel Hallouin","Construction of good codes from weak Del Pezzo surfaces","33 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct algebraic geometric codes from weak del Pezzo surfaces. The
codes are associated to the anti-canonical class of the anti-canonical model
and to the set of rational points of these models. Since we consider weak Del
Pezzo surfaces, the anti canonical model is not smooth any more. This
complicates the computation of the parameters of the codes; in particular we
need to distinguish the Cartier divisors from the Weil ones.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:26:00 GMT""}]","2023-01-30"
"2301.11826","Bojian Hou","Bojian Hou, Hongming Li, Zhicheng Jiao, Zhen Zhou, Hao Zheng, Yong Fan","Deep Clustering Survival Machines with Interpretable Expert
  Distributions",,,,,"cs.LG cs.AI","http://creativecommons.org/publicdomain/zero/1.0/","  Conventional survival analysis methods are typically ineffective to
characterize heterogeneity in the population while such information can be used
to assist predictive modeling. In this study, we propose a hybrid survival
analysis method, referred to as deep clustering survival machines, that
combines the discriminative and generative mechanisms. Similar to the mixture
models, we assume that the timing information of survival data is generatively
described by a mixture of certain numbers of parametric distributions, i.e.,
expert distributions. We learn weights of the expert distributions for
individual instances according to their features discriminatively such that
each instance's survival information can be characterized by a weighted
combination of the learned constant expert distributions. This method also
facilitates interpretable subgrouping/clustering of all instances according to
their associated expert distributions. Extensive experiments on both real and
synthetic datasets have demonstrated that the method is capable of obtaining
promising clustering results and competitive time-to-event predicting
performance.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:27:18 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 20:34:01 GMT""},{""version"":""v3"",""created"":""Fri, 10 Mar 2023 18:13:57 GMT""}]","2023-03-13"
"2301.11827","Christian T Preuss","A. Gehrmann-De Ridder, T. Gehrmann, E. W. N. Glover, A. Huss, C. T.
  Preuss, D. M. Walker","Precision phenomenology with fiducial cross sections in the
  triple-differential Drell-Yan process","49 pages, 22 figures",,"10.1007/JHEP05(2023)002",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The production of lepton pairs (Drell-Yan process) at the LHC is being
measured to high precision, enabling the extraction of distributions that are
triply differential in the di-lepton mass and rapidity as well as in the
scattering angle described by the leptons. The measurements are performed for a
fiducial phase space, defined by cuts on the individual lepton momenta and
rapidities. Based on the ATLAS triple-differential Drell-Yan measurement at
8~TeV, we perform a detailed investigation of the phenomenology of this process
based on state-of-the-art perturbative predictions in QCD and the electroweak
theory. Our results demonstrate the highly non-trivial interplay between
measurement variables and fiducial cuts, which leads to forbidden regions at
Born level, and induces sensitivity on extra particle emissions from higher
perturbative orders. We also investigate the sensitivity of the measurement on
parton distributions and electroweak parameters. We derive Standard-Model
theory predictions which combine NNLO QCD and NLO EW corrections and include
partial N$^3$LO QCD as well as higher-order EW corrections where appropriate.
Our results will enable the use of the triple-differential Drell-Yan data in a
precise experimental determination of the weak mixing angle.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:28:28 GMT""}]","2023-05-24"
"2301.11828","Hao Tian","Chenguang Liu, Hao Tian, Wai sun Don, Hong Wang","A fast computational framework for the linear bond-based peridynamic
  model",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Peridynamic (PD) theory is significant and promising in engineering and
materials science; however, it imposes challenges owing to the enormous
computational cost caused by its nonlocality. Our main contribution, which
overcomes the restrictions of the existing fast method, is a general
computational framework for the linear bond-based peridynamic models based on
the meshfree method, called the matrix-structure-based fast method (MSBFM),
which is suitable for the general case, including 2D/3D problems, and
static/dynamic issues, as well as problems with general boundary conditions, in
particular, problems with crack propagation. Consequently, we provide a general
calculation flow chart. The proposed computational framework is practical and
easily embedded into the existing computational algorithm. With this framework,
the computational cost is reduced from $O(N^2)$ to $O(N\log N)$, and the
storage request is reduced from $O(N^2)$ to $O(N)$, where N is the degree of
freedom. Finally, the vast reduction of the computational and memory
requirement is verified by numerical examples.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:28:43 GMT""}]","2023-01-30"
"2301.11829","Robin Kopp","Robin A. Kopp and Sabine H. L. Klapp","Spontaneous velocity alignment of Brownian particles with
  feedback-induced propulsion","7 pages, 5 figures",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on Brownian dynamics simulations we study the collective behavior of a
twodimensional system of repulsively interacting colloidal particles, where
each particle is propelled by a repulsive feedback force with time delay
$\tau$. Although the pair interactions are purely isotropic we observe a
spontaneous, large-scale alignment of the velocity vectors. This phenomenon
persists for long times and occurs in the absence of steady-state clustering.
We explain our observations by a combination of the effect of steric
interactions yielding local velocity ordering, and the effect of time delay,
that generates cluster dissolution, velocity persistence and velocity alignment
over large distances. Overall, the behavior reveals intriguing similarities,
but also differences, to that observed in models of active matter, such as
active Brownian particles and the Vicsek model.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:29:54 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 08:28:45 GMT""}]","2023-06-05"
"2301.11830","Linjie Chen","Linjie Chen, Marc Klein Wolt, Amin Aminaei, Stijn Buitink, Heino
  Falcke","Detection of Ultra High Energy Cosmic Rays and Neutrinos with Lunar
  Orbital Radio Telescope","Accepted for publication in European Physical Journal C, 18 pages, 11
  figures",,"10.1140/epjc/s10052-023-11245-z",,"astro-ph.IM astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Particle cascades induced by ultra-high-energy (UHE) cosmic rays and
neutrinos impacting on the lunar regolith usually radiate Cherenkov radio
emissions due to the presence of excess negative charge, which is known as
Askaryan effect. Several experiments have been carried out to detect the
Cherenkov radio emissions in the lunar regolith. To prepare for future lunar
Ultra-Long Wavelength (ULW, frequencies below 30 MHz) radio astronomy missions,
we study the detection of the Cherenkov radio emissions with the ULW radio
telescope that are operating at the lunar orbit. We have carried out instrument
modelling and analytic calculations for the analysis of aperture, flux and
event rate, and the analyses show the detectability of the Cherenkov radiation.
Based on the properties of the Cherenkov radiation, we have demonstrated that
the cosmic ray and neutrino events could be reconstructed with the three ULW
vector antennas onboard the lunar satellites via measurements of the Askaryan
radio pulse intensity, polarizations, etc. The results obtained by this study
would be useful for future lunar radio explorer mission, where the detections
of UHE cosmic rays and neutrinos could be successfully attempted.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:31:41 GMT""}]","2023-02-15"
"2301.11831","Binquan Guo","Binquan Guo, Hongyan Li, Ye Yan, Zhou Zhang, and Peng Wang","Data Volume-aware Computation Task Scheduling for Smart Grid Data
  Analytic Applications","Accepted to appear in IEEE ICC 2023. The source code is available at
  Github: https://github.com/wilixx/ICCTS",,,,"cs.DC cs.PF cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Emerging smart grid applications analyze large amounts of data collected from
millions of meters and systems to facilitate distributed monitoring and
real-time control tasks. However, current parallel data processing systems are
designed for common applications, unaware of the massive volume of the
collected data, causing long data transfer delay during the computation and
slow response time of smart grid systems. A promising direction to reduce delay
is to jointly schedule computation tasks and data transfers. We identify that
the smart grid data analytic jobs require the intermediate data among different
computation stages to be transmitted orderly to avoid network congestion. This
new feature prevents current scheduling algorithms from being efficient. In
this work, an integrated computing and communication task scheduling scheme is
proposed. The mathematical formulation of smart grid data analytic jobs
scheduling problem is given, which is unsolvable by existing optimization
methods due to the strongly coupled constraints. Several techniques are
combined to linearize it for adapting the Branch and Cut method. Based on the
topological information in the job graph, the Topology Aware Branch and Cut
method is further proposed to speed up searching for optimal solutions.
Numerical results demonstrate the effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:34:00 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 09:18:18 GMT""},{""version"":""v3"",""created"":""Thu, 2 Feb 2023 08:49:04 GMT""}]","2023-02-03"
"2301.11832","Masaki Adachi","Masaki Adachi, Satoshi Hayakawa, Saad Hamid, Martin J{\o}rgensen,
  Harald Oberhauser, Micheal A. Osborne","SOBER: Scalable Batch Bayesian Optimization and Quadrature using
  Recombination Constraints","24 pages, 9 figures",,,,"cs.LG cs.NA math.NA stat.CO stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Batch Bayesian optimisation (BO) has shown to be a sample-efficient method of
performing optimisation where expensive-to-evaluate objective functions can be
queried in parallel. However, current methods do not scale to large batch sizes
-- a frequent desideratum in practice (e.g. drug discovery or simulation-based
inference). We present a novel algorithm, SOBER, which permits scalable and
diversified batch BO with arbitrary acquisition functions, arbitrary input
spaces (e.g. graph), and arbitrary kernels. The key to our approach is to
reformulate batch selection for BO as a Bayesian quadrature (BQ) problem, which
offers computational advantages. This reformulation is beneficial in solving BQ
tasks reciprocally, which introduces the exploitative functionality of BO to
BQ. We show that SOBER offers substantive performance gains in synthetic and
real-world tasks, including drug discovery and simulation-based inference.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:36:33 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 02:30:24 GMT""}]","2023-01-31"
"2301.11833","Jack Rolph","Jack Rolph, Erika Garutti, Robert Klanner, Tobias Quadfasel, Joern
  Schwandt","PeakOTron: A Python Module for Fitting Charge Spectra of Silicon
  Photomultipliers",,,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Python program has been developed which fits a published detector-response
model to SiPM charge spectra to characterise SiPMs. Spectra for SiPMs
illuminated by low intensity pulsed light with Poisson-distributed number of
photons and a time spread of order nanoseconds or less, can be analysed. The
entire charge spectra, including the intervals in-between the photoelectron
peaks, are fitted, which allows determining, in addition to the mean number of
detected photons, gain, gain spread, prompt cross-talk, pedestal, and
electronics noise, the dark-count rate as well as the probability and time
constant of after-pulses. The starting values of the fit parameters are
extracted from the charge spectra.
  The program performance has been evaluated using simulated charge spectra
with the different SiPM parameters varied in a wide range. By analysing 100
simulated spectra for every parameter set, the biases and statistical
uncertainties of the individual parameters have been determined. It is found
that the parameters are precisely determined and that the entire spectra are
well described, in most cases with a $\chi ^2$/NDF close to 1. In addition,
measured spectra for two types of SiPMs for a wide range of over-voltages have
been analysed. The program achieves mostly a good description of the spectra,
and the parameters determined agree with the values from the producers and
expectations.
  The program can be used for detailed analyses of single spectra, but, as it
is compatible with the native \texttt{Python} multiprocessing module, also for
the automatic characterisation of large samples of SiPMs.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:38:39 GMT""}]","2023-01-30"
"2301.11834","Takato Ishida","Fumiaki Nakai and Takato Ishida","Gas Diffusion in Cement Pastes: An Analysis using a Fluctuating
  Diffusivity Model","29 pages, 9 figures",,,,"cond-mat.soft cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work propose an application of the concept of fluctuating diffusivity to
the diffusion of gas molecules in cementitious materials, particularly through
a two-state fluctuating diffusivity (2SFD) model. The 2SFD model is utilized to
investigate the diffusion of oxygen in cement pastes. The analysis provides a
reasonable description of the diffusion coefficient of oxygen in cement pastes,
and highlights the presence of non-Gaussian diffusion, which can be attributed
to the heterogeneous microstructure. The presence of non-Gaussianity in the
probability density of the molecule's displacement, characterized by heavier
tails than those of the Gaussian distribution, may have a significant impact on
the durability assessments of concrete structures.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:38:56 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 00:23:17 GMT""}]","2023-02-14"
"2301.11835","Rahul Halder","Rahul Halder, Murali Damodaran and Khoo Boo Cheong","Deep Learning-Driven Nonlinear Reduced-Order Models for Predicting
  Wave-Structure Interaction","24 pages , 20 figure",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Long Short-Term Memory (LSTM) network-driven Non-Intrusive Reduced Order
Model (NROM) for predicting the dynamics of a floating box on the water surface
in a wavemaker basin is addressed in this study. The ground truth or actual
data for these wave-structure interactions (WSI) problems, namely box
displacements and hydrodynamic forces and moments acting on the box due to wave
interaction corresponding to a particular wave profile, are computed using the
Smoothed Particle Hydrodynamics (SPH). The dimensionality of the system is
first reduced using the Discrete Empirical Interpolation Method (DEIM) and the
LSTM is applied to the reduced system resulting in a DEIM-LSTM network for
developing a surrogate for prediction. The network is further enhanced by
incorporating the physics information into the loss function resulting in a
physics-informed LSTM (LSTM-PINN) for predicting the rigid body dynamics of box
motion. The performance of predictions for these networks is assessed for the
two-dimensional wave basin WSI problem as a proof-of-concept demonstration.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:43:43 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 09:30:05 GMT""},{""version"":""v3"",""created"":""Mon, 6 Feb 2023 20:59:43 GMT""}]","2023-02-08"
"2301.11836","Bernd Freytag","Bernd Freytag and Susanne H\""ofner","Global 3D radiation-hydrodynamical models of AGB stars with dust-driven
  winds",,"A&A, Volume 669, 2023, A155","10.1051/0004-6361/202244992",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convection and mass loss by stellar winds are two dynamical processes that
shape asymptotic giant branch (AGB) stars and their evolution. Observations and
earlier 3D models indicate that giant convection cells cause high-contrast
surface intensity patterns, and contribute to the origin of clumpy dust clouds.
We study the formation and resulting properties of dust-driven winds from AGB
stars, using new global 3D simulations. The dynamical stellar interiors,
atmospheres, and wind acceleration zones of two M-type AGB stars were modeled
with the CO5BOLD code. These first global 3D simulations are based on
frequency-dependent gas opacities, and they feature time-dependent condensation
and evaporation of silicate grains. Convection and pulsations emerge
self-consistently, allowing us to derive wind properties (e.g., mass-loss rates
and outflow velocities), without relying on parameterized descriptions of these
processes. In contrast to 1D models with purely radial pulsations, the shocks
induced by convection and pulsation in the 3D models cover large parts, but not
the entirety, of the sphere, leading to a patchy, nonspherical structure of the
atmosphere. Since dust condensation critically depends on gas density, new dust
clouds form mostly in the dense wakes of atmospheric shocks, where the grains
can grow efficiently. The resulting clumpy distribution of newly formed dust
leads to a complex 3D morphology of the extended atmosphere and
wind-acceleration zone, with simultaneous infall and outflow regions close to
the star. Highly nonspherical isotherms and short-lived cool pockets of gas in
the stellar vicinity are prominent features. Efficient dust formation sets in
closer to the star than spherical averages of the temperature indicate, in
dense regions where grain growth rates are higher than average.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:44:42 GMT""}]","2023-01-30"
"2301.11837","Frederik Schiller","Alaa Mohammed Idris Bakhit, Khadiza Ali, Anna A. Makarova, Igor
  P\'i\v{s}, Federica Bondino, Roberto Sant, Saroj P. Dash, Rodrigo Castrillo,
  Yuri Hasegawa, J. Enrique Ortega, Laura Fernandez, Frederik Schiller","A ferromagnetic Eu-Pt surface compound grown below hexagonal boron
  nitride",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the fundamental applications for monolayer-thick 2D materials is their
use as protective layers of metal surfaces and in-situ intercalated reactive
materials in ambient conditions. Here we investigate the structural,
electronic, and magnetic properties, as well as the chemical stability in air
of a very reactive metal, Europium, after intercalation between a hexagonal
boron nitride (hBN) layer and a Pt substrate. We demonstrate that Eu
intercalation leads to a hBN-protected ferromagnetic EuPt$_2$ surface alloy
with divalent Eu$^{2+}$ atoms. We expose the system to ambient conditions and
find a partial shielding of the Eu-Pt interface, which remains ferromagnetic.
The use of a curved Pt substrate allows us to explore ferromagnetism and the
ambient pressure protection with other substrate planes. The interfacial
EuPt$_2$ surface alloy formation remains the same, but the resistance to
ambient conditions is reduced, likely due to a rougher surface and a more
discontinuous hBN coating.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:44:56 GMT""}]","2023-01-30"
"2301.11838","Michael Streif","Maximilian Amsler, Peter Deglmann, Matthias Degroote, Michael P.
  Kaicher, Matthew Kiser, Michael K\""uhn, Chandan Kumar, Andreas Maier, Georgy
  Samsonidze, Anna Schroeder, Michael Streif, Davide Vodola, Christopher Wever","Quantum-enhanced quantum Monte Carlo: an industrial view",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we test a recently developed method to enhance classical
auxiliary-field quantum Monte Carlo (AFQMC) calculations with quantum computers
against examples from chemistry and material science, representatives of
classes of industry-relevant systems. As molecular test cases, we calculate the
energy curve of H4 and relative energies of ozone and singlet molecular oxygen
with respect to triplet molecular oxygen, which are industrially relevant in
organic oxidation reactions. We find that trial wave functions beyond single
Slater determinants improve the performance of AFQMC and allow to generate
energies close to chemical accuracy compared to full configuration interaction
(FCI) or experimental results. As a representative for material science we
study a quasi-1D Fermi-Hubbard model derived from CuBr2, a compound displaying
electronic structure properties analogous to cuprates. We find that trial wave
functions with both, significantly larger fidelities and lower energies over a
Hartree-Fock solution, do not necessarily lead to better AFQMC results.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:45:12 GMT""}]","2023-01-30"
"2301.11839","Peiyao Zhang","Peiyao Zhang, Ji Woong Kim, Peter Gehlbach, Iulian Iordachita, and
  Marin Kobilarov","Autonomous Needle Navigation in Retinal Microsurgery: Evaluation in ex
  vivo Porcine Eyes",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Important challenges in retinal microsurgery include prolonged operating
time, inadequate force feedback, and poor depth perception due to a constrained
top-down view of the surgery. The introduction of robot-assisted technology
could potentially deal with such challenges and improve the surgeon's
performance. Motivated by such challenges, this work develops a strategy for
autonomous needle navigation in retinal microsurgery aiming to achieve precise
manipulation, reduced end-to-end surgery time, and enhanced safety. This is
accomplished through real-time geometry estimation and chance-constrained Model
Predictive Control (MPC) resulting in high positional accuracy while keeping
scleral forces within a safe level. The robotic system is validated using both
open-sky and intact (with lens and partial vitreous removal) ex vivo porcine
eyes. The experimental results demonstrate that the generation of safe control
trajectories is robust to small motions associated with head drift. The mean
navigation time and scleral force for MPC navigation experiments are 7.208 s
and 11.97 mN, which can be considered efficient and well within acceptable safe
limits. The resulting mean errors along lateral directions of the retina are
below 0.06 mm, which is below the typical hand tremor amplitude in retinal
microsurgery.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:45:38 GMT""}]","2023-01-30"
"2301.11840","Darya Yasinskaya","V. V. Konev, V. A. Ulitko, D. N. Yasinskaya, Y. D. Panov, A. S.
  Moskvin","Features of the Domain Boundaries of a Highly Anisotropic (S = 1)
  Antiferromagnet near the Transition to the Quantum Paramagnet Phase","3 pages, 2 figures","Konev, V. V., Ulitko, V. A., Yasinskaya, D. N., Panov, Y. D., &
  Moskvin, A. S. Bulletin of the Russian Academy of Sciences: Physics, 83,
  812-814 (2019)","10.3103/S1062873819070232",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  It is shown that the structure of antiphase domain boundaries in the
antiferromagnetic (AFM) phase of a highly anisotropic magnet with S = 1 on a
two-dimensional square lattice depends greatly on single-ion anisotropy
parameter D. Computer modeling on large square lattices illustrates the changes
in the boundary structure from the quantum paramagnet (QP) to the XY phase,
including the intermediate QP-XY phase at fairly small variations in positive
D.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:45:54 GMT""}]","2023-01-30"
"2301.11841","Tuur Stuyck","Oshri Halimi, Egor Larionov, Zohar Barzelay, Philipp Herholz, Tuur
  Stuyck","PhysGraph: Physics-Based Integration Using Graph Neural Networks",,,,,"cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics-based simulation of mesh based domains remains a challenging task.
State-of-the-art techniques can produce realistic results but require expert
knowledge. A major bottleneck in many approaches is the step of integrating a
potential energy in order to compute velocities or displacements. Recently,
learning based method for physics-based simulation have sparked interest with
graph based approaches being a promising research direction. One of the
challenges for these methods is to generate models that are mesh independent
and generalize to different material properties. Moreover, the model should
also be able to react to unforeseen external forces like ubiquitous collisions.
Our contribution is based on a simple observation: evaluating forces is
computationally relatively cheap for traditional simulation methods and can be
computed in parallel in contrast to their integration. If we learn how a system
reacts to forces in general, irrespective of their origin, we can learn an
integrator that can predict state changes due to the total forces with high
generalization power. We effectively factor out the physical model behind
resulting forces by relying on an opaque force module. We demonstrate that this
idea leads to a learnable module that can be trained on basic internal forces
of small mesh patches and generalizes to different mesh typologies,
resolutions, material parameters and unseen forces like collisions at inference
time. Our proposed paradigm is general and can be used to model a variety of
physical phenomena. We focus our exposition on the detail enhancement of coarse
clothing geometry which has many applications including computer games, virtual
reality and virtual try-on.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:47:10 GMT""}]","2023-01-30"
"2301.11842","Daniel Gratzer","Daniel Gratzer","Normalization for multimodal type theory","Extended version of the LICS paper by the same name (doi:
  10.1145/3531130.3532398, technical report: arxiv:2106.01414)",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We prove normalization for MTT, a general multimodal dependent type theory
capable of expressing modal type theories for guarded recursion, internalized
parametricity, and various other prototypical modal situations. We prove that
deciding type checking and conversion in MTT can be reduced to deciding the
equality of modalities in the underlying modal situation, immediately yielding
a type checking algorithm for all instantiations of MTT in the literature.
  This proof uses a generalization of synthetic Tait computability -- an
abstract approach to gluing proofs -- to account for modalities. This extension
is based on MTT itself, so that this proof also constitutes a significant case
study of MTT.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:47:10 GMT""}]","2023-01-30"
"2301.11843","Mubashara Akhtar","Mubashara Akhtar, Oana Cocarascu, Elena Simperl","Reading and Reasoning over Chart Images for Evidence-based Automated
  Fact-Checking","Accepted to EACL 2023 (Findings)",,,,"cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  Evidence data for automated fact-checking (AFC) can be in multiple modalities
such as text, tables, images, audio, or video. While there is increasing
interest in using images for AFC, previous works mostly focus on detecting
manipulated or fake images. We propose a novel task, chart-based fact-checking,
and introduce ChartBERT as the first model for AFC against chart evidence.
ChartBERT leverages textual, structural and visual information of charts to
determine the veracity of textual claims. For evaluation, we create ChartFC, a
new dataset of 15, 886 charts. We systematically evaluate 75 different
vision-language (VL) baselines and show that ChartBERT outperforms VL models,
achieving 63.8% accuracy. Our results suggest that the task is complex yet
feasible, with many challenges ahead.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:47:45 GMT""}]","2023-01-30"
"2301.11845","Gautier Dagan","Gautier Dagan, Frank Keller, Alex Lascarides","Learning the Effects of Physical Actions in a Multi-modal Environment",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large Language Models (LLMs) handle physical commonsense information
inadequately. As a result of being trained in a disembodied setting, LLMs often
fail to predict an action's outcome in a given environment. However, predicting
the effects of an action before it is executed is crucial in planning, where
coherent sequences of actions are often needed to achieve a goal. Therefore, we
introduce the multi-modal task of predicting the outcomes of actions solely
from realistic sensory inputs (images and text). Next, we extend an LLM to
model latent representations of objects to better predict action outcomes in an
environment. We show that multi-modal models can capture physical commonsense
when augmented with visual information. Finally, we evaluate our model's
performance on novel actions and objects and find that combining modalities
help models to generalize and learn physical commonsense reasoning better.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:49:52 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 12:29:30 GMT""}]","2023-02-06"
"2301.11847","Yikuan Li","Yikuan Li, Ramsey M. Wehbe, Faraz S. Ahmad, Hanyin Wang and Yuan Luo","A Comparative Study of Pretrained Language Models for Long Clinical Text","arXiv admin note: substantial text overlap with arXiv:2201.11838",,"10.1093/jamia/ocac225",,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Objective: Clinical knowledge enriched transformer models (e.g.,
ClinicalBERT) have state-of-the-art results on clinical NLP (natural language
processing) tasks. One of the core limitations of these transformer models is
the substantial memory consumption due to their full self-attention mechanism,
which leads to the performance degradation in long clinical texts. To overcome
this, we propose to leverage long-sequence transformer models (e.g., Longformer
and BigBird), which extend the maximum input sequence length from 512 to 4096,
to enhance the ability to model long-term dependencies in long clinical texts.
  Materials and Methods: Inspired by the success of long sequence transformer
models and the fact that clinical notes are mostly long, we introduce two
domain enriched language models, Clinical-Longformer and Clinical-BigBird,
which are pre-trained on a large-scale clinical corpus. We evaluate both
language models using 10 baseline tasks including named entity recognition,
question answering, natural language inference, and document classification
tasks.
  Results: The results demonstrate that Clinical-Longformer and
Clinical-BigBird consistently and significantly outperform ClinicalBERT and
other short-sequence transformers in all 10 downstream tasks and achieve new
state-of-the-art results.
  Discussion: Our pre-trained language models provide the bedrock for clinical
NLP using long texts. We have made our source code available at
https://github.com/luoyuanlab/Clinical-Longformer, and the pre-trained models
available for public download at:
https://huggingface.co/yikuan8/Clinical-Longformer.
  Conclusion: This study demonstrates that clinical knowledge enriched
long-sequence transformers are able to learn long-term dependencies in long
clinical text. Our methods can also inspire the development of other
domain-enriched long-sequence transformers.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:50:29 GMT""}]","2023-01-30"
"2301.11848","Minghan Chu","Minghan Chu and Weicheng Qian","Combination of Multi-Fidelity Data Sources For Uncertainty
  Quantification: A Lightweight CNN Approach",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reynolds Averaged Navier Stokes (RANS) modelling is notorious for introducing
the model-form uncertainty due to the Boussinesq turbulent viscosity
hypothesis. Recently, the eigenspace perturbation method (EPM) has been
developed to estimate the RANS model-form uncertainty. This approach estimates
model-form uncertainty through injecting perturbations to the predicted
Reynolds stress tensor. However, there is a need for a reliable machine
learning method for estimating the perturbed amplitude of the Reynolds stress
tensor. Machine learning models are often too complex and data intensive for
this application. We propose a lightweight convolutional neural network (CNN)
approach to learn a correction function for RANS from paired-samples of RANS
and DNS simulation results. The CNN learned RANS correction function
successfully facilitates the RANS uncertainty quantification (UQ), and our
findings suggest that the lightweight CNN approach is effective in combining
RANS and DNS simulation results to enrich the existing perturbation method in
estimating the RANS UQ more precisely.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:54:35 GMT""}]","2023-01-30"
"2301.11849","Maximilian Stahlberg","Max Klimm and Maximilian J. Stahlberg","Complexity of equilibria in binary public goods games on undirected
  graphs","To appear in the Proceedings of the 24th ACM Conference on Economics
  and Computation (EC 2023)",,"10.1145/3580507.3597780",,"cs.GT cs.CC","http://creativecommons.org/licenses/by/4.0/","  We study the complexity of computing equilibria in binary public goods games
on undirected graphs. In such a game, players correspond to vertices in a graph
and face a binary choice of performing an action, or not. Each player's
decision depends only on the number of neighbors in the graph who perform the
action and is encoded by a per-player binary pattern. We show that games with
decreasing patterns (where players only want to act up to a threshold number of
adjacent players doing so) always have a pure Nash equilibrium and that one is
reached from any starting profile by following a polynomially bounded sequence
of best responses. For non-monotonic patterns of the form $10^k10^*$ (where
players want to act alone or alongside $k + 1$ neighbors), we show that it is
$\mathsf{NP}$-hard to decide whether a pure Nash equilibrium exists. We further
investigate a generalization of the model that permits ties of varying
strength: an edge with integral weight $w$ behaves as $w$ parallel edges.
While, in this model, a pure Nash equilibrium still exists for decreasing
patters, we show that the task of computing one is $\mathsf{PLS}$-complete.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:56:06 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 13:23:55 GMT""},{""version"":""v3"",""created"":""Fri, 19 May 2023 15:56:32 GMT""}]","2023-05-22"
"2301.11850","Francielle Alves Vargas","Francielle Vargas, Kokil Jaidka, Thiago A. S. Pardo, Fabr\'icio
  Benevenuto","Predicting Sentence-Level Factuality of News and Bias of Media Outlets",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Predicting the factuality of news reporting and bias of media outlets is
surely relevant for automated news credibility and fact-checking. While prior
work has focused on the veracity of news, we propose a fine-grained reliability
analysis of the entire media. Specifically, we study the prediction of
sentence-level factuality of news reporting and bias of media outlets, which
may explain more accurately the overall reliability of the entire source. We
first manually produced a large sentence-level dataset, titled ""FactNews"",
composed of 6,191 sentences expertly annotated according to factuality and
media bias definitions from AllSides. As a result, baseline models for
sentence-level factuality prediction were presented by fine-tuning BERT.
Finally, due to the severity of fake news and political polarization in Brazil,
both dataset and baseline were proposed for Portuguese. However, our approach
may be applied to any other language.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:56:24 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 17:33:00 GMT""}]","2023-04-27"
"2301.11851","Javier D\'iaz","J. D\'iaz, L. M. \'Alvarez-Prado, S. M. Valvidares, I. Montoya, C.
  Redondo, R. Morales and M. V\'elez","Morphology and Magnetic vortex chiral symmetry of 2D arrays of magnetic
  trilayer disks with magnetostatic interlayer coupling determined by X ray
  resonant magnetic scattering","13 pages, 16 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  X ray resonant magnetic scattering (XRMS) was used to characterize the
magnetization of 2D arrays of trilayer submicron magnets. The interpretation of
the data required the understanding of the morphology of the magnets which was
also deduced from the scattered intensity. The magnets consisted of two
magnetostatically coupled ferromagnetic layers separated by a non-magnetic
spacer. The scattered intensity from the disks resulted to be dependent on the
disks surface curvature. This made the collected intensity at each Bragg
reflection (BR) to be correlated to the reflected light from locations of the
disk with the same angle of curvature. Due to this, quantitative information
was obtained, averaged over the disks illuminated by x rays, of the variations
in thickness and magnetization across the entire area of the disks. This
averaged magnetization mapping of the disks served to study their vortex
configuration in each of their magnetic layers, determining the average
location of the vortex, the chiral symmetry of its magnetic circulation, and
the specific locations where the vortex nucleation starts within the disks.
Chiral asymmetry appeared in the disks when the field was oriented at an
oblique angle with respect to the easy axis of the array. The local magnetic
sensitivity of the technique allowed to identify a non-centrosymmetric
distribution of the magnetization of the disks that explains the observed
chiral asymmetry. Unexpectedly, the magnetic circulation sense of the vortex
was the same in both ferromagnetic layers. In addition, the magnetization of
the buried layer was different in the descent branch than in the ascent branch
of its hysteresis loops.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:56:37 GMT""}]","2023-01-30"
"2301.11852","Bich Ngoc Vu","Bich Ngoc Vu, Vladimir Luke\v{s}, Michael Stingl and Eduard Rohan","A Sequential Global Programming Approach for Two-scale Optimization of
  Homogenized Multiphysics Problems with Application to Biot Porous Media","26 pages, 19 figures, 2 tables",,,,"cs.CE","http://creativecommons.org/licenses/by/4.0/","  We present a new approach and an algorithm for optimizing the material
configuration and behaviour of a fluid saturated porous medium in a two-scale
setting. The state problem is governed by the Biot model describing the
fluid-structure interaction in homogenized poroelastic structures. However, the
approach is widely applicable to multiphysics problems involving several
macroscopic fields where homogenization provides the relationship between the
microconfigurations and the macroscopic mathematical model. The optimization
variables describe the local microstructure design by virtue of the pore shape
which determines the effective medium properties - the material coefficients -
computed by the homogenization method. The main idea of the numerical
optimization strategy consists in a) employing a precomputed database of the
material coefficients associated to the geometric parameters and b) applying
the sequential global programming (SGP) method for solving the problem of
macroscopically optimized distribution of material coefficients. Although there
are similarities with the free material optimization (FMO) approach, only
effective material coefficients are considered admissible, for which a
well-defined set of corresponding configurable microstructures exist. Due to
the flexibility of the SGP approach, different types of microstructures with
fully independent parametrizations can easily be handled. The efficiency of the
concept is demonstrated by a series of numerical experiments. We show that the
SGP method can handle simultaneously multiple types of microstructures with
nontrivial parametrizations using a considerably low and stable number of state
problems to be solved.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:56:41 GMT""}]","2023-01-30"
"2301.11853","Darya Yasinskaya","Yu. D. Panov, V. A. Ulitko, K. S. Budrin, D. N. Yasinskaya, and A. A.
  Chikov","Competition between the Spin and Pseudospin Subsystems in a Model
  Cuprate","7 pages, 3 figures","Panov, Y. D., Ulitko, V. A., Budrin, K. S., Yasinskaya, D. N., &
  Chikov, A. A. (2019). Competition between the Spin and Pseudospin Subsystems
  in a Model Cuprate. Physics of the Solid State, 61, 707-713","10.1134/S106378341905024X",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The competition between the magnetic and charge orderings in a model cuprate
is considered in terms of a simplified static 2D spin-pseudospin model. This
model is equivalent to the 2D dilute antiferromagnetic (AFM) Ising model with
charged impurities. The mean-field approximation results are presented for the
system under study and briefly compared to the classical Monte Carlo (MC)
calculations. The numerical simulation shows that the cases of the strong
exchange and the strong charge correlation differ qualitatively. In the case of
a strong exchange, the AMF phase is instable with respect to the phase
separation (PS) into the pseudospin (charge) and magnetic (spin) subsystems
that behave as immiscible quantum liquids. The analytical expression has been
obtained for the PS temperature.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:58:23 GMT""}]","2023-01-30"
"2301.11854","Eduardo Quintana-Miranda","Eduardo Quintana-Miranda, Pierluigi Monaco and Luca Tornatore","GrGadget: an N-body TreePM relativistic code for cosmological
  simulations","15 pages, 14 figures",,"10.1093/mnras/stad1174",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We present the merging of the Particle-Mesh (PM) relativistic Gevolution code
with the TreePM Gadget-4 code, with the aim of studying general relativity
effects in cosmology. Our code, called GrGadget, is able to track the evolution
of metric perturbations in the weak field limit by using Gevolution's
implementation of a relativistic PM in the Poisson gauge. To achieve this,
starting from Gevolution we have written a C++ library called libgevolution,
that allows a code to access and use the same abstractions and resources that
Gevolution uses for its PM-only N-body simulations. The code works under the
assumption that particle interactions at short distances can be approximated as
Newtonian, so that we can combine the forces computed with a Newtonian Tree
with those computed with a relativistic PM. The result is a TreePM simulation
code that represents metric perturbations at the scales where they are
relevant, while resolving non-linear structures. We validate our code by
closely matching Gadget-4 forces, computed with the Tree switched off, with
those computed with libgevolution in the Newtonian limit. With GrGadget we
obtain a matter power spectrum that is compatible with Newtonian Gadget at
small scales and contains GR features at large scales that are consistent with
results obtained with Gevolution. We demonstrate that, due to the better
resolution of the highly non-linear regime, the representation of the
relativistic fields sampled on the mesh improves with respect to the PM-only
simulations.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:59:41 GMT""}]","2023-05-03"
"2301.11855","Doru Cristian Sticlet","Doru Sticlet and Fr\'ed\'eric Pi\'echon","Non-Lifshitz invariants corrections to Dzyaloshinskii-Moriya interaction
  energy","17 pages, 2 figures","Phys. Rev. B 107, 195404 (2023)","10.1103/PhysRevB.107.195404",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the continuum limit of two-dimensional chiral magnets in which
Dzyaloshinskii-Moriya interaction (DMI) is due to the interplay between a
smooth magnetic texture and spin-orbit coupling. The resulting free-energy
density of the system contains linear terms in the spatial gradient of the
magnetic texture, which mark an instability of the system towards the formation
of nontrivial magnetic orders such as skyrmions or chiral domain walls. We
perform a microscopic analysis of DMI tensors responsible for this contribution
to free energy based on a Berry phase formulation in the mixed space of
momentum and position, and reveal that they exhibit non-Lifshitz invariants
features. In particular, a perturbation theory shows in the case of Rashba
spin-orbit interactions the presence of non-Lifshitz invariants to third order
in the small spin-orbit interaction and fourth order in the small exchange
coupling. The higher-order terms may even lead to an enhancement of DMI
interaction at strong spin-orbit coupling due to divergences in the density of
states at the bottom of the conduction band. Finally, we also study the DMI
free energy generated from Rashba spin-orbit interaction in different symmetry
groups.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:59:43 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 15:42:14 GMT""}]","2023-05-05"
"2301.11856","Hui Wen Goh","Hui Wen Goh, Jonas Mueller","ActiveLab: Active Learning with Re-Labeling by Multiple Annotators",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In real-world data labeling applications, annotators often provide imperfect
labels. It is thus common to employ multiple annotators to label data with some
overlap between their examples. We study active learning in such settings,
aiming to train an accurate classifier by collecting a dataset with the fewest
total annotations. Here we propose ActiveLab, a practical method to decide what
to label next that works with any classifier model and can be used in
pool-based batch active learning with one or multiple annotators. ActiveLab
automatically estimates when it is more informative to re-label examples vs.
labeling entirely new ones. This is a key aspect of producing high quality
labels and trained models within a limited annotation budget. In experiments on
image and tabular data, ActiveLab reliably trains more accurate classifiers
with far fewer annotations than a wide variety of popular active learning
methods.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:00:11 GMT""}]","2023-01-30"
"2301.11857","Niko Grupen","Niko A. Grupen, Michael Hanlon, Alexis Hao, Daniel D. Lee, Bart Selman","Policy-Value Alignment and Robustness in Search-based Multi-Agent
  Learning","9 pages, 5 figures",,,,"cs.AI cs.LG cs.MA","http://creativecommons.org/licenses/by/4.0/","  Large-scale AI systems that combine search and learning have reached
super-human levels of performance in game-playing, but have also been shown to
fail in surprising ways. The brittleness of such models limits their efficacy
and trustworthiness in real-world deployments. In this work, we systematically
study one such algorithm, AlphaZero, and identify two phenomena related to the
nature of exploration. First, we find evidence of policy-value misalignment --
for many states, AlphaZero's policy and value predictions contradict each
other, revealing a tension between accurate move-selection and value estimation
in AlphaZero's objective. Further, we find inconsistency within AlphaZero's
value function, which causes it to generalize poorly, despite its policy
playing an optimal strategy. From these insights we derive VISA-VIS: a novel
method that improves policy-value alignment and value robustness in AlphaZero.
Experimentally, we show that our method reduces policy-value misalignment by up
to 76%, reduces value generalization error by up to 50%, and reduces average
value error by up to 55%.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:05:29 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 15:59:53 GMT""}]","2023-02-07"
"2301.11858","Asif ud-Doula","Asif ud-Doula, Stanley P. Owocki, Christopher Russell, Marc Gagne and
  Simon Daley-Yates","3D MHD models of the centrifugal magnetosphere from a massive star with
  an oblique dipole field","Accepted for publication in MNRAS",,"10.1093/mnras/stad345",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present results from new self-consistent 3D MHD simulations of the
magnetospheres from massive stars with a dipole magnetic axis that has a
non-zero obliquity angle ($\beta$) to the star's rotation axis. As an initial
direct application, we compare the global structure of co-rotating disks for
nearly aligned ($\beta=5^o$) versus half-oblique ($\beta=45^o$) models, both
with moderately rapid rotation ($\sim$ 0.5 critical). We find that accumulation
surfaces broadly resemble the forms predicted by the analytic Rigidly Rotating
Magnetosphere (RRM) model, but the mass buildup to near the critical level for
centrifugal breakout against magnetic confinement distorts the field from the
imposed initial dipole. This leads to an associated warping of the accumulation
surface toward the rotational equator, with the highest density concentrated in
{\em wings} centered on the intersection between the magnetic and rotational
equators. These MHD models can be used to synthesize rotational modulation of
photometric absorption and H$\alpha$ emission for a direct comparison with
observations.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:05:34 GMT""}]","2023-02-08"
"2301.11859","Daniel Paila\~nir","Damian Clarke, Daniel Paila\~nir, Susan Athey and Guido Imbens","Synthetic Difference In Differences Estimation","Corrected typos Corrected references",,,,"econ.EM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we describe a computational implementation of the Synthetic
difference-in-differences (SDID) estimator of Arkhangelsky et al. (2021) for
Stata. Synthetic difference-in-differences can be used in a wide class of
circumstances where treatment effects on some particular policy or event are
desired, and repeated observations on treated and untreated units are available
over time. We lay out the theory underlying SDID, both when there is a single
treatment adoption date and when adoption is staggered over time, and discuss
estimation and inference in each of these cases. We introduce the sdid command
which implements these methods in Stata, and provide a number of examples of
use, discussing estimation, inference, and visualization of results.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:05:42 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 17:43:20 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 13:21:05 GMT""}]","2023-02-14"
"2301.11860","Simon Forest","Pierre Clairambault, Simon Forest","The Cartesian Closed Bicategory of Thin Spans of Groupoids","29 pages",,,,"cs.LO math.CT","http://creativecommons.org/licenses/by/4.0/","  Recently, there has been growing interest in bicategorical models of
programming languages, which are ""proof-relevant"" in the sense that they keep
distinct account of execution traces leading to the same observable outcomes,
while assigning a formal meaning to reduction paths as isomorphisms.
  In this paper we introduce a new model, a bicategory called thin spans of
groupoids. Conceptually it is close to Fiore et al.'s generalized species of
structures and to Melli\`es' homotopy template games, but fundamentally differs
as to how replication of resources and the resulting symmetries are treated.
Where those models are saturated -- the interpretation is inflated by the fact
that semantic individuals may carry arbitrary symmetries -- our model is thin,
drawing inspiration from thin concurrent games: the interpretation of terms
carries no symmetries, but semantic individuals satisfy a subtle invariant
defined via biorthogonality, which guarantees their invariance under symmetry.
  We first build the bicategory $\mathbf{Thin}$ of thin spans of groupoids. Its
objects are certain groupoids with additional structure, its morphisms are
spans composed via plain pullback with identities the identity spans, and its
$2$-cells are span morphisms making the induced triangles commute only up to
natural isomorphism. We then equip $\mathbf{Thin}$ with a pseudocomonad $!$,
and finally show that the Kleisli bicategory $\mathbf{Thin}_{!}$ is cartesian
closed.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:05:56 GMT""}]","2023-01-30"
"2301.11861","Melisa Gianetti","Melisa M. Gianetti, Roberto Guerra, Andrea Vanossi, Michael Urbakh,
  Nicola Manini","Electric-field frictional effects in confined zwitterionic molecules",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We theoretically explore the effect of a transverse electric field on the
frictional response of a bi-layer of packed zwitterionic molecules. The
dipole-moment reorientation promoted by the electric field can lead to either
stick-slip or smooth sliding dynamics, with average shear stress values varying
over a wide range. A structure-property relation is revealed by investigating
the array of molecules and their mutual orientation and interlocking. Moreover,
the thermal friction enhancement previously observed in these molecules is
shown to be suppressed by the electric field, recovering the expected
thermolubricity at large-enough fields. The same holds for other basic
tribological quantities, such as the external load, which can influence
friction in opposite ways depending on the strength of the applied electric
field. Our findings open a route for the reversible control of friction forces
via electric polarization of the sliding surface.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:06:03 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 10:04:41 GMT""}]","2023-06-09"
"2301.11862","Anton Thielmann","Anton Thielmann, Ren\'e-Marcel Kruse, Thomas Kneib, Benjamin S\""afken","Neural Additive Models for Location Scale and Shape: A Framework for
  Interpretable Neural Regression Beyond the Mean",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) have proven to be highly effective in a variety
of tasks, making them the go-to method for problems requiring high-level
predictive power. Despite this success, the inner workings of DNNs are often
not transparent, making them difficult to interpret or understand. This lack of
interpretability has led to increased research on inherently interpretable
neural networks in recent years. Models such as Neural Additive Models (NAMs)
achieve visual interpretability through the combination of classical
statistical methods with DNNs. However, these approaches only concentrate on
mean response predictions, leaving out other properties of the response
distribution of the underlying data. We propose Neural Additive Models for
Location Scale and Shape (NAMLSS), a modelling framework that combines the
predictive power of classical deep learning models with the inherent advantages
of distributional regression while maintaining the interpretability of additive
models.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:06:13 GMT""}]","2023-01-30"
"2301.11863","Sergey Gusev","S. V. Gusev","Semiring identities of semigroups of reflexive relations and upper
  triangular boolean matrices",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the following semirings satisfy the same identities: the
semiring $\mathcal{R}_n$ of all reflexive binary relations on a set with $n$
elements, the semiring $\mathcal{U}_n$ of all $n\times n$ upper triangular
matrices over the boolean semiring, the semiring $\mathcal{C}_n$ of all order
preserving and extensive transformations of a chain with $n$ elements. In view
of the result of Kl\'ima and Pol\'ak, which states that $\mathcal{C}_n$ has a
finite basis of identities for all $n$, this implies that the identities of
$\mathcal{R}_n$ and $\mathcal{U}_n$ admit a finite basis as well.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:07:32 GMT""}]","2023-01-30"
"2301.11864","Matthew Moore","Matt R Moore and Alexander W Wray","Gravity can lead to multiple peaks in the early stages of coffee ring
  formation",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We consider the role of gravity in solute transport when a thin droplet
evaporates. Under the physically-relevant assumptions that the contact line is
pinned and the solutal P\'{e}clet number, $\mbox{Pe}$ is large, we identify two
fundamental regimes that depend on the size of the Bond number, $\mbox{Bo}$.
When $\mbox{Bo} = O(1)$, the asymptotic structure of solute transport follows
directly from the surface tension-dominated regime, whereby advection drives
solute towards the contact line, only to be countered by local diffusive
effects, leading to the formation of the famous ``coffee ring"". For larger Bond
numbers, we identify the distinguished limit in which
$\mbox{Bo}^{-1/2}\mbox{Pe}^{2/3} = O(1)$, where the diffusive boundary layer is
comparable to the surface tension boundary layer. In each regime, we perform a
systematic asymptotic analysis of the solute transport and compare our
predictions to numerical simulations of the full model. Our analysis identifies
the effect of gravity on the nascent coffee ring, providing quantitative
predictions of the size, location and shape of the solute mass profile.
Furthermore, we reveal that, for certain values of $\mbox{Bo}$, $\mbox{Pe}$ and
the evaporation time, a secondary peak may exist inside the classical coffee
ring. We find that the onset of this secondary peak is linked to the change in
behaviour of the critical point in the droplet centre. Both the onset and the
peak characteristics are shown to be independent of $\mbox{Pe}$, but solutal
diffusion may act to remove the secondary peak when the classical coffee ring
becomes so large as to subsume it.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:08:18 GMT""}]","2023-01-30"
"2301.11865","Zhehui Wang","Xin Yue, Shanny Lin, Wenting Li, Bradley T. Wolfe, Steven Clayton,
  Mark Makela, C. L. Morris, Simon Spannagel, Erik Ramberg, Juan Estrada, Hao
  Zhu, Jifeng Liu, Eric R. Fossum and Zhehui Wang","Ultrafast CMOS image sensors and data-enabled super-resolution for
  multimodal radiographic imaging and tomography","12 pages, 10 figures",,,"Los Alamos National Laboratory report number LA-UR-23-20744","physics.ins-det eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We summarize recent progress in ultrafast Complementary Metal Oxide
Semiconductor (CMOS) image sensor development and the application of neural
networks for post-processing of CMOS and charge-coupled device (CCD) image data
to achieve sub-pixel resolution (thus $super$-$resolution$). The combination of
novel CMOS pixel designs and data-enabled image post-processing provides a
promising path towards ultrafast high-resolution multi-modal radiographic
imaging and tomography applications.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:11:21 GMT""}]","2023-01-30"
"2301.11866","Page Thorn","Gerard Buskes and Page Thorn","On the Boolean algebra tensor product via Caratheodory spaces of place
  functions",,,,,"math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We show that the Carath\'{e}odory space of place functions on the free
product of two Boolean algebras is Riesz isomorphic with Fremlin's Archimedean
Riesz space tensor product of their respective Carath\'{e}odory spaces of place
functions. We provide a solution to Fremlin's problem 315Y(f) in
\cite{fremlin_measure} concerning completeness in the free product of Boolean
algebras by applying our results on the Archimedean Riesz space tensor product
to Carath\'{e}odory spaces of place functions.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:12:32 GMT""}]","2023-01-30"
"2301.11867","Mario Rom\'an","Matt Earnshaw, James Hefford, Mario Rom\'an","The Produoidal Algebra of Process Decomposition","56 pages, 41 figures",,,,"cs.LO math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the normal produoidal category of monoidal contexts over an
arbitrary monoidal category. In the same sense that a monoidal morphism
represents a process, a monoidal context represents an incomplete process: a
piece of a decomposition, possibly containing missing parts. We characterize
monoidal contexts in terms of universal properties. In particular, symmetric
monoidal contexts coincide with monoidal lenses, endowing them with a novel
universal property. We apply this algebraic structure to the analysis of
multi-party interaction protocols in arbitrary theories of processes.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:12:40 GMT""}]","2023-01-30"
"2301.11868","Erik Peterson","Erik R. Peterson, David O. Jones, Daniel Scolnic, Bruno O. S\'anchez,
  Aaron Do, Adam G. Riess, Sam M. Ward, Arianna Dwomoh, Thomas de Jaeger,
  Saurabh W. Jha, Kaisey S. Mandel, Justin D. R. Pierel, Brodie Popovic,
  Benjamin M. Rose, David Rubin, Benjamin J. Shappee, Stephen Thorp, John L.
  Tonry, R. Brent Tully, Maria Vincenzi","The DEHVILS Survey Overview and Initial Data Release: High-Quality
  Near-Infrared Type Ia Supernova Light Curves at Low Redshift","24 pages, 9 figures. Accepted by MNRAS",,"10.1093/mnras/stad1077",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the sample of optical Type Ia Supernova (SN Ia) light curves (LCs)
usable for cosmological parameter measurements surpasses 2000, the sample of
published, cosmologically viable near-infrared (NIR) SN Ia LCs, which have been
shown to be good ""standard candles,"" is still $\lesssim$ 200. Here, we present
high-quality NIR LCs for 83 SNe Ia ranging from $0.002 < z < 0.09$ as a part of
the Dark Energy, H$_0$, and peculiar Velocities using Infrared Light from
Supernovae (DEHVILS) survey. Observations are taken using UKIRT's WFCAM, where
the median depth of the images is 20.7, 20.1, and 19.3 mag (Vega) for $Y$, $J$,
and $H$-bands, respectively. The median number of epochs per SN Ia is 18 for
all three bands ($YJH$) combined and 6 for each band individually. We fit 47 SN
Ia LCs that pass strict quality cuts using three LC models, SALT3, SNooPy, and
BayeSN and find scatter on the Hubble diagram to be comparable to or better
than scatter from optical-only fits in the literature. Fitting NIR-only LCs, we
obtain standard deviations ranging from 0.128-0.135 mag. Additionally, we
present a refined calibration method for transforming 2MASS magnitudes to WFCAM
magnitudes using HST CALSPEC stars that results in a 0.03 mag shift in the
WFCAM $Y$-band magnitudes.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:16:29 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 20:06:23 GMT""}]","2023-04-19"
"2301.11869","David Wei","David Wei, Daniel Adler, Kritsana Srakaew, Suchita Agrawal, Pascal
  Weckesser, Immanuel Bloch, Johannes Zeiher","Observation of brane parity order in programmable optical lattices","Fixed typos and formatting",,,,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Mott-insulating phase of the two-dimensional (2d) Bose-Hubbard model is
expected to be characterized by a non-local brane parity order. Parity order
captures the presence of microscopic particle-hole fluctuations and
entanglement, whose properties depend on the underlying lattice geometry. We
realize 2d Bose-Hubbard models in dynamically tunable lattice geometries, using
neutral atoms in a novel passively phase-stable tunable optical lattice in
combination with programmable site-blocking potentials. We benchmark the
performance of our system by single-particle quantum walks in the square,
triangular, kagome and Lieb lattice. In the strongly correlated regime, we
microscopically characterize the geometry dependence of the quantum
fluctuations and experimentally validate the brane parity as a proxy for the
non-local order parameter signaling the superfluid-to-Mott insulating phase
transition.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:17:54 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 10:58:23 GMT""}]","2023-01-31"
"2301.11872","Siyang Wang","Siyang Wang, Paul Burdett, Edmund Lovell, Rachel Bettles, Neil Wilson,
  Mary P. Ryan, Finn Giuliani","Fracture properties of La(Fe,Mn,Si)13 magnetocaloric materials",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  La(Fe,Mn,Si)13 alloys are a promising material family for magnetic
refrigeration. Challenges associated with their structural integrity during
device assembly and operation requires deep understanding of the mechanical
properties. Here we developed a workflow to quantitatively study the fracture
properties of La(Fe,Mn,Si)13 plates used in magnetic cooling devices. We
employed microstructural characterisation, optical examination of defects, and
four-point bending tests of samples with known defect sizes to evaluate their
mechanical performance. We established the residual strength curve which
directly links observed defects to mechanical strength. The estimated fracture
toughness KC of hydrogenated La(Fe,Mn,Si)13 is approximately 4 MPa m^1/2 for
the geometry employed. The established relationship between strength and crack
length enables the prediction of mechanical performance through examination of
defects via optical microscopy, therefore can be used industrially for
directing plate selection to guarantee the mechanical stability of
refrigeration devices.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:26:43 GMT""}]","2023-01-30"
"2301.11873","Lasse Elsem\""uller","Lasse Elsem\""uller, Martin Schnuerch, Paul-Christian B\""urkner, Stefan
  T. Radev","A Deep Learning Method for Comparing Bayesian Hierarchical Models",,,,,"stat.ML cs.LG stat.ME","http://creativecommons.org/licenses/by/4.0/","  Bayesian model comparison (BMC) offers a principled approach for assessing
the relative merits of competing computational models and propagating
uncertainty into model selection decisions. However, BMC is often intractable
for the popular class of hierarchical models due to their high-dimensional
nested parameter structure. To address this intractability, we propose a deep
learning method for performing BMC on any set of hierarchical models which can
be instantiated as probabilistic programs. Since our method enables amortized
inference, it allows efficient re-estimation of posterior model probabilities
and fast performance validation prior to any real-data application. In a series
of extensive validation studies, we benchmark the performance of our method
against the state-of-the-art bridge sampling method and demonstrate excellent
amortized inference across all BMC settings. We then use our method to compare
four hierarchical evidence accumulation models that have previously been deemed
intractable for BMC due to partly implicit likelihoods. In this application, we
corroborate evidence for the recently proposed L\'evy flight model of
decision-making and show how transfer learning can be leveraged to enhance
training efficiency. Reproducible code for all analyses is provided.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:27:07 GMT""}]","2023-01-30"
"2301.11874","Nicolas Aimar","N. Aimar, A. Dmytriiev, F.H. Vincent, I.El Mellah, T. Paumard, G.
  Perrin, A. Zech","Magnetic reconnection plasmoid model for Sagittarius A* flares","20 pages, 14 figures, accepted in A&A","A&A 672, A62 (2023)","10.1051/0004-6361/202244936",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Sagittarius A*, the supermassive black hole at the center of our galaxy,
exhibits episodic near-infrared flares. The recent monitoring of three such
events by the GRAVITY instrument has shown that some flares are associated with
orbital motions in the close environment of the black hole with super Keplerian
velocity. We develop a semi-analytic model of Sagittarius~A* flares based on an
ejected large plasmoid, inspired by recent particle-in-cell global simulations
of black hole magnetospheres. We model the infrared astrometric and photometric
signatures associated to this model. We consider a spherical large plasmoid
ejected along a conical orbit around the black hole. This plasmoid is assumed
to be formed by successive mergers of smaller plasmoids produced through
magnetic reconnection. Non-thermal electrons are injected in the plasmoid. We
compute the evolution of the electron-distribution under the influence of
synchrotron cooling. We solve the radiative transfer problem and transport the
radiation along null geodesics of the Schwarzschild spacetime. We also take
into account the quiescent radiation of the accretion flow, on top of which the
flare evolves. For the first time, we successfully account for the astrometric
and flux variations of the GRAVITY data with a flare model that incorporates an
explicit modeling of the emission mechanism. We find good agreement between the
prediction of our model and the recent data. In particular, the azimuthal
velocity is set by the magnetic field line it belongs to, which is anchored in
the inner parts of the accretion flow, hence the super-Keplerian motion. The
astrometric track is also shifted with respect to the center of mass due to the
quiescent radiation, in agreement with the difference measured with the GRAVITY
data. These results support the picture of magnetic reconnection as a viable
model for Sagittarius~A* infrared flares.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:30:25 GMT""}]","2023-04-05"
"2301.11875","Riccardo Nagar","Simone Alioli, Georgios Billis, Alessandro Broggio, Alessandro
  Gavardi, Stefan Kallweit, Matthew A. Lim, Giulia Marinelli, Riccardo Nagar,
  Davide Napoletano","Refining the GENEVA method for Higgs boson production via gluon fusion","39 pages, 11 figures; v2: journal version, 1 appendix and 1 figure
  added","JHEP 05 (2023) 128","10.1007/JHEP05(2023)128","DESY 23-009, UWThPh-2023-2","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a number of improvements to the GENEVA method for matching NNLO
calculations to parton shower programs. In particular, we detail changes to the
resummed calculation used in the matching procedure, including disentangling
the cross section dependence on factorisation and beam scales, and an improved
treatment of timelike logarithms. We also discuss modifications in the
implementation of the splitting functions which serve to make the resummed
calculation differential in the higher multiplicity phase space. These changes
improve the stability of the numerical cancellation of the nonsingular term at
small values of the resolution parameter. As a case study, we consider the
gluon-initiated Higgs boson production process $gg\to H$. We validate the NNLO
accuracy of our predictions against independent calculations, and compare our
showered and hadronised results with recent data taken at the ATLAS and CMS
experiments in the diphoton decay channel, finding good agreement.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:36:06 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 16:42:25 GMT""}]","2023-05-25"
"2301.11876","Darya Yasinskaya","V. V. Konev, V. A. Ulitko, D. N. Yasinskaya, Yu. D. Panov, and A. S.
  Moskvin","Influence of Local Correlations on the ""Homogeneous
  Insulator-Superconductor"" Transition in the Domain Boundaries of the
  Charge-Order Phase of a 2D System of a Mixed Valence","3 pages, 2 figures","V.V. Konev, V.A. Ulitko, D.N. Yasinskaya et al. Phys. Solid State
  60, 2132-2134 (2018)","10.1134/S1063783418110136",,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  It is demonstrated in the (pseudo)spin S=1 formalism that the structure of
antiphase domain boundaries in the phase of charge ordering of a mixed-valence
system of the Cu1+, 2+, 3+ ""triplet"" type in cuprates on a two-dimensional
square lattice depends to a considerable extent on on-site correlation
parameter U. The results of computer modeling on large square lattices
illustrate the change in the boundary structure (from a homogeneous monovalent
nonconducting structure of the Cu2+ type to a filamentary superconducting one)
induced by a relatively small variation of positive U values.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:37:59 GMT""}]","2023-01-30"
"2301.11877","Andrei Mironov","A. Mironov, V. Mishnyakov, A. Morozov, A. Popolitov, Wei-Zhong Zhao","On KP-integrable skew Hurwitz $\tau$-functions and their
  $\beta$-deformations","13 pages, LaTeX","Physics Letters B839 (2023) 137805","10.1016/j.physletb.2023.137805","FIAN/TD-02/23; IITP/TH-02/23; ITEP/TH-02/23; MIPT/TH-02/23","hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the old formalism of cut-and-join operators in the theory of
Hurwitz $\tau$-functions to description of a wide family of KP-integrable {\it
skew} Hurwitz $\tau$-functions, which include, in particular, the newly
discovered interpolating WLZZ models. Recently, the simplest of them was
related to a superintegrable two-matrix model with two potentials and one
external matrix field. Now we provide detailed proofs, and a generalization to
a multi-matrix representation, and propose the $\beta$ deformation of the
matrix model as well. The general interpolating WLZZ model is generated by a
$W$-representation given by a sum of operators from a one-parametric
commutative sub-family (a commutative subalgebra of $w_\infty$). Different
commutative families are related by cut-and-join rotations. Two of these
sub-families (`vertical' and `45-degree') turn out to be nothing but the
trigonometric and rational Calogero-Sutherland Hamiltonians, the `horizontal'
family is represented by simple derivatives. Other families require an
additional analysis.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:42:52 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 20:09:19 GMT""}]","2023-03-03"
"2301.11878","Eric Church PhD","T. Bezerra, A. Borkum, E. Church, C. Cuesta, Z. Djurcic, J. Genovesi,
  J. Haiston, C. M. Jackson, I. Lazanu, B. Monreal, S. Munson, C. Ortiz, M.
  Parvu, S. J. M. Peeters, D. Pershey, S. S. Poudel, J. Reichenbacher, R.
  Saldanha, K. Scholberg, G. Sinev, S. Westerdale, J. Zennamo","Large Low Background kTon-Scale Liquid Argon Time Projection Chambers","arXiv admin note: substantial text overlap with arXiv:2203.08821","JPhysG Vol 50, 6, 9-May-2023","10.1088/1361-6471/acc394",,"hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find that it is possible to increase sensitivity to low energy physics in
a third or fourth DUNE-like module with careful controls over radiopurity and
targeted modifications to a detector similar to the DUNE Far Detector design.
In particular, sensitivity to supernova and solar neutrinos can be enhanced
with improved MeV-scale reach. A neutrinoless double beta decay search with
$^{136}$Xe loading appears feasible. Furthermore, sensitivity to
Weakly-Interacting Massive Particle (WIMP) Dark Matter (DM) becomes competitive
with the planned world program in such a detector, offering a unique seasonal
variation detection that is characteristic for the nature of WIMPs.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:47:16 GMT""}]","2023-05-11"
"2301.11879","Zhivar Sourati","Zhivar Sourati, Filip Ilievski, H\^ong-\^An Sandlin, Alain Mermoud","Case-Based Reasoning with Language Models for Classification of Logical
  Fallacies",,,,,"cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ease and speed of spreading misinformation and propaganda on the Web
motivate the need to develop trustworthy technology for detecting fallacies in
natural language arguments. However, state-of-the-art language modeling methods
exhibit a lack of robustness on tasks like logical fallacy classification that
require complex reasoning. In this paper, we propose a Case-Based Reasoning
method that classifies new cases of logical fallacy by language-modeling-driven
retrieval and adaptation of historical cases. We design four complementary
strategies to enrich input representation for our model, based on external
information about goals, explanations, counterarguments, and argument
structure. Our experiments in in-domain and out-of-domain settings indicate
that Case-Based Reasoning improves the accuracy and generalizability of
language models. Our ablation studies suggest that representations of similar
cases have a strong impact on the model performance, that models perform well
with fewer retrieved cases, and that the size of the case database has a
negligible effect on the performance. Finally, we dive deeper into the
relationship between the properties of the retrieved cases and the model
performance.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:49:16 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 20:13:59 GMT""}]","2023-05-19"
"2301.11880","Bin Duan","Bin Duan, Keshav Bhandari, Gaowen Liu and Yan Yan","Optical Flow Estimation in 360$^\circ$ Videos: Dataset, Model and
  Application","20 pages, 14 figures, conference extension. arXiv admin note:
  substantial text overlap with arXiv:2208.03620",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Optical flow estimation has been a long-lasting and fundamental problem in
the computer vision community. However, despite the advances of optical flow
estimation in perspective videos, the 360$^\circ$ videos counterpart remains in
its infancy, primarily due to the shortage of benchmark datasets and the
failure to accommodate the omnidirectional nature of 360$^\circ$ videos. We
propose the first perceptually realistic 360$^\circ$ filed-of-view video
benchmark dataset, namely FLOW360, with 40 different videos and 4,000 video
frames. We then conduct comprehensive characteristic analysis and extensive
comparisons with existing datasets, manifesting FLOW360's perceptual realism,
uniqueness, and diversity. Moreover, we present a novel Siamese representation
Learning framework for Omnidirectional Flow (SLOF) estimation, which is trained
in a contrastive manner via a hybrid loss that combines siamese contrastive and
optical flow losses. By training the model on random rotations of the input
omnidirectional frames, our proposed contrastive scheme accommodates the
omnidirectional nature of optical flow estimation in 360$^\circ$ videos,
resulting in significantly reduced prediction errors. The learning scheme is
further proven to be efficient by expanding our siamese learning scheme and
omnidirectional optical flow estimation to the egocentric activity recognition
task, where the classification accuracy is boosted up to $\sim$26%. To
summarize, we study the optical flow estimation in 360$^\circ$ videos problem
from perspectives of the benchmark dataset, learning model, and also practical
application. The FLOW360 dataset and code are available at
https://siamlof.github.io.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:50:09 GMT""}]","2023-01-30"
"2301.11881","A. Bashir","R. J. Hern\'andez-Pinto, L. X. Guti\'errez-Guerrero, A. Bashir, M. A.
  Bedolla, I. M. Higuera-Angulo","Electromagnetic Form Factors and Charge Radii of Pseudoscalar and Scalar
  Mesons: A Comprehensive Contact Interaction Analysis","13 pages, 13 figures",,"10.1103/PhysRevD.107.054002","JLAB-THY-23-3748","hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We carry out a comprehensive survey of electromagnetic form factors of all
light, heavy and heavy-light ground-state pseudoscalar and scalar mesons. Our
analysis is based upon a Schwinger-Dyson equations treatment of a vector
$\times$ vector contact interaction. It incorporates confinement and ensures
axial vector and vector Ward-Takahashi identities are satisfied along with the
corresponding corollaries such as the Goldberger-Treiman relations. The
algebraic simplicity of the model allows us to compute the form factors at
arbitrarily large virtualities of the probing photon momentum squared with
relative ease. Wherever possible and insightful, we compare our results for the
electromagnetic form factors and the charge radii with those obtained earlier
through Schwinger-Dyson equations, lattice and with experimental observations
available. We also comment on the scope and shortcomings of the model.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:53:00 GMT""}]","2023-03-15"
"2301.11882","Luke Sperling","Luke Sperling and Sandeep S Kulkarni","Privacy-Preserving Methods for Outlier-Resistant Average Consensus and
  Shallow Ranked Vote Leader Election","10 pages + references, 2 figures, 2 algorithms, 7 theorems",,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Consensus and leader election are fundamental problems in distributed
systems. Consensus is the problem in which all processes in a distributed
computation must agree on some value. Average consensus is a popular form of
consensus, where the agreed upon value is the average of the initial values of
all the processes. In a typical solution for consensus, each process learns the
value of others' to determine the final decision. However, this is undesirable
if processes want to keep their values secret from others.
  With this motivation, we present a solution to privacy-preserving average
consensus, where no process can learn the initial value of any other process.
Additionally, we augment our approach to provide outlier resistance, where
extreme values are not included in the average calculation. Privacy is fully
preserved at every stage, including preventing any process from learning the
identities of processes that hold outlier values. To our knowledge, this is the
first privacy-preserving average consensus algorithm featuring outlier
resistance.
  In the context of leader election, each process votes for the one that it
wants to be the leader. The goal is to ensure that the leader is elected in
such a way that each vote remains secret and the sum of votes remain secret
during the election. Only the final vote tally is available to all processes.
This ensures that processes that vote early are not able to influence the votes
of other processes. We augment our approach with shallow ranked voting by
allowing processes to not only vote for a single process, but to designate a
secondary process to vote towards in the event that their primary vote's
candidate does not win the election.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:54:16 GMT""}]","2023-01-30"
"2301.11883","Ivano Basile","Ivano Basile, Andrea Campoleoni, Joris Raeymaekers","A note on the admissibility of complex BTZ metrics","17 pages, 2 figures. V2: matches published version",,"10.1007/JHEP03(2023)187",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a nontrivial check of Witten's recently proposed admissibility
criterion for complex metrics. We consider the `quasi-Euclidean' metrics
obtained from continuing the BTZ class of metrics to imaginary time. Of special
interest are the overspinning metrics, which are smooth in this
three-dimensional context. Their inclusion as saddle points in the
gravitational path integral would lead to puzzling results in conflict with
those obtained using other methods. It is therefore encouraging that the
admissibility criterion discards them. For completeness, we perform an analysis
of smoothness and admissibility for the family of quasi-Euclidean BTZ metrics
at all values of the mass and angular momentum.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:55:03 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 09:13:47 GMT""}]","2023-03-28"
"2301.11884","Kazuki Ikeda","Kazuki Ikeda","Long-range quantum energy teleportation and distribution on a hyperbolic
  quantum network",,,,,"quant-ph cs.CY cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Teleporting energy to remote locations is new challenge for quantum
information science and technology. Developing a method for transferring local
energy in laboratory systems to remote locations will enable non-trivial energy
flows in quantum networks. From the perspective of quantum information
engineering, we propose a method for distributing local energy to a large
number of remote nodes using hyperbolic geometry. Hyperbolic networks are
suitable for energy allocation in large quantum networks since the number of
nodes grows exponentially. To realise long-range quantum energy teleportation,
we propose a hybrid method of quantum state telepotation and quantum energy
teleportation. By transmitting local quantum information through quantum
teleportation and performing conditional operations on that information,
quantum energy teleportation can theoretically be realized independent of
geographical distance. The method we present will provide new insights into new
applications of future large-scale quantum networks and potential applications
of quantum physics to information engineering.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:56:31 GMT""}]","2023-01-30"
"2301.11885","Anant Raj","Anant Raj and Lingjiong Zhu and Mert G\""urb\""uzbalaban and Umut
  \c{S}im\c{s}ekli","Algorithmic Stability of Heavy-Tailed SGD with General Loss Functions","The first two authors contributed equally to this work",,,,"stat.ML cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Heavy-tail phenomena in stochastic gradient descent (SGD) have been reported
in several empirical studies. Experimental evidence in previous works suggests
a strong interplay between the heaviness of the tails and generalization
behavior of SGD. To address this empirical phenomena theoretically, several
works have made strong topological and statistical assumptions to link the
generalization error to heavy tails. Very recently, new generalization bounds
have been proven, indicating a non-monotonic relationship between the
generalization error and heavy tails, which is more pertinent to the reported
empirical observations. While these bounds do not require additional
topological assumptions given that SGD can be modeled using a heavy-tailed
stochastic differential equation (SDE), they can only apply to simple quadratic
problems. In this paper, we build on this line of research and develop
generalization bounds for a more general class of objective functions, which
includes non-convex functions as well. Our approach is based on developing
Wasserstein stability bounds for heavy-tailed SDEs and their discretizations,
which we then convert to generalization bounds. Our results do not require any
nontrivial assumptions; yet, they shed more light to the empirical
observations, thanks to the generality of the loss functions.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:57:35 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 05:14:51 GMT""}]","2023-01-31"
"2301.11886","Dongsheng Yang","Dongsheng Yang, Daniel S. Berger, Kai Li, Wyatt Lloyd","A Learned Cache Eviction Framework with Minimal Overhead",,,,,"cs.OS cs.DC","http://creativecommons.org/licenses/by-sa/4.0/","  Recent work shows the effectiveness of Machine Learning (ML) to reduce cache
miss ratios by making better eviction decisions than heuristics. However,
state-of-the-art ML caches require many predictions to make an eviction
decision, making them impractical for high-throughput caching systems. This
paper introduces Machine learning At the Tail (MAT), a framework to build
efficient ML-based caching systems by integrating an ML module with a
traditional cache system based on a heuristic algorithm. MAT treats the
heuristic algorithm as a filter to receive high-quality samples to train an ML
model and likely candidate objects for evictions. We evaluate MAT on 8
production workloads, spanning storage, in-memory caching, and CDNs. The
simulation experiments show MAT reduces the number of costly ML
predictions-per-eviction from 63 to 2, while achieving comparable miss ratios
to the state-of-the-art ML cache system. We compare a MAT prototype system with
an LRU-based caching system in the same setting and show that they achieve
similar request rates.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:57:37 GMT""}]","2023-01-30"
"2301.11887","Chenning Tong","Chenning Tong","Symmetries and similarities of the zero-pressure-gradient turbulent
  boundary",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The symmetries and similarities of the zero-pressure-gradient turbulent
boundary layer (ZPGTBL) are investigated to derive the full set of similarity
variables, to derive the similarity equations, and to obtain a higher-order
approximate solution of the mean velocity profile. Previous analyses have not
resulted in all the similarity variables. We perform a symmetry analysis of the
equations for ZPGTBL using Lie dilation groups, and obtain local, leading-order
symmetries of the equations. The full set of similarity variables were obtained
in terms of the boundary layer parameters. The friction velocity was shown to
be the outer-layer velocity scale. The downstream evolution of the boundary
thickness and the friction velocity is obtained analytically. The dependent
similarity variables are written as asymptotic expansions. By asymptotically
matching the expansions, an approximate similarity solution up to the third
order in the overlapping layer are obtained. These results are obtained from
first principles without any major assumptions and a turbulence model. The
similarities and differences between ZPGTBL and turbulent channel flows in
terms of the similarity equations, the gauge functions and the approximate
solutions are discussed. In particular, the leading-order expansions are
identical for ZPGTBL and channel flows, supporting the notion of universality
of the near-wall layer. In addition, the logarithmic friction law for ZPGTBL is
accurate to all orders while it is only accurate at the leading order in
channel flows. The results will help further understand ZPGTBL and the issue of
universality of the near-wall layer in wall-bounded turbulent flows.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:01:54 GMT""}]","2023-01-30"
"2301.11888","Douglas Galvao","Raphael M. Tromer, Levi C. Felix, Ray H. Baughmann, Douglas S. Galvao,
  and Cristiano F. Woellner","Transforming 2D carbon allotropes into 3D ones through topological
  mapping: The case of biphenylene carbon (graphenylene)",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a new methodology for obtaining 3D carbon allotrope
structures from 2D ones through topological mapping. The idea is to select a 3D
target structure and 'slice' it along different structural directions, creating
a series of 2D structures. As a proof of concept, we chose the Tubulane
structure 12-hexa(3,3) as a target. Tubulanes are 3D carbon allotropes based on
cross-linked carbon nanotubes. One of obtained 2D 'sliced' structures was
mapped into the biphenylene carbon (BPC). We showed that compressing BPC along
different directions can generate not only the target Tubulane 12-hexa(3,3) but
at least two other structures, bcc-C6 and an unreported member of the Tubulane
family, which we called Tubulane X. The methodology proposed here is completely
general, it can be used coupled with any quantum method. Considering that new
2D carbon allotropes, such as the biphenylene carbon network, which is closely
related to BPC, have been recently synthesized, the approach proposed here
opens new perspectives to obtain new 3D carbon allotropes from 2D structures.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:04:08 GMT""}]","2023-01-30"
"2301.11889","Tanumoy Mandal","Arvind Bhaskar, Yash Chaurasia, Kuldeep Deka, Tanumoy Mandal, Subhadip
  Mitra, Ananya Mukherjee","Right-handed neutrino pair production via second-generation leptoquarks","9 pages, 4 figures, 3 tables",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are no direct experimental constraints on the Leptoquark (LQ) couplings
with quarks and right-handed neutrinos (RHNs). If a (scalar or vector) LQ
dominantly couples to RHNs, it can leave unique signatures at the LHC. The RHNs
can be produced copiously from LQ decays as long as they are lighter than the
LQs. The LQ-induced RHN production mechanism has never been searched for in
experiments. This channel can act as a simultaneous probe for both RHNs and LQs
that dominantly couple to RHNs. In this paper, we consider all possible
charge-$2/3$ and $1/3$ scalar and vector LQs that exclusively couple to a
second-generation quark and a RHN. We study the pair and single productions of
TeV-scale LQs and their subsequent decay to sub-TeV RHNs, realised in the
inverse seesaw framework. The single production contribution can be significant
for large LQ-RHN-quark couplings. We systematically combine the pair and single
production events leading to a pair of RHNs plus jets to study the prospects of
this channel. We analyse the monolepton and opposite-sign dilepton final states
and estimate the discovery reach at the high-luminosity LHC.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:06:14 GMT""}]","2023-01-30"
"2301.11890","Yuriy Shablya","Yuriy Shablya, Dmitry Kruchinin","Algorithms for ranking and unranking the combinatorial set of RNA
  secondary structures","14 pages",,,,"cs.DS cs.DM","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the combinatorial set of RNA secondary structures of
length $n$ with $m$ base-pairs. For a compact representation, we encode an RNA
secondary structure by the corresponding Motzkin word. For this combinatorial
set, we construct an AND/OR tree structure, find a bijection between the
combinatorial set and the set of variants of the AND/OR tree, and develop
algorithms for ranking and unranking the variants of the AND/OR tree. The
developed ranking and unranking algorithms have polynomial time complexity
$O(m^2 (n - m))$ for $m < n - 2 m$ and $O(m (n - m)^2)$ for $m > n - 2 m$. In
contrast to the existing algorithms, the new algorithms do not require
preprocessing steps and have better time complexity.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:07:34 GMT""}]","2023-01-30"
"2301.11891","Stephen Goss","Stephen A. Goss, Robert J. Steininger, Dhruv Narayanan, Daniel V.
  Oliven\c{c}a, Yutong Sun, Peng Qiu, Jim Amato, Eberhard O. Voit, Walter E.
  Voit, Eric J. Kildebeck","Polycraft World AI Lab (PAL): An Extensible Platform for Evaluating
  Artificial Intelligence Agents","27 pages, 5 figures",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  As artificial intelligence research advances, the platforms used to evaluate
AI agents need to adapt and grow to continue to challenge them. We present the
Polycraft World AI Lab (PAL), a task simulator with an API based on the
Minecraft mod Polycraft World. Our platform is built to allow AI agents with
different architectures to easily interact with the Minecraft world, train and
be evaluated in multiple tasks. PAL enables the creation of tasks in a flexible
manner as well as having the capability to manipulate any aspect of the task
during an evaluation. All actions taken by AI agents and external actors
(non-player-characters, NPCs) in the open-world environment are logged to
streamline evaluation. Here we present two custom tasks on the PAL platform,
one focused on multi-step planning and one focused on navigation, and
evaluations of agents solving them. In summary, we report a versatile and
extensible AI evaluation platform with a low barrier to entry for AI
researchers to utilize.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:08:04 GMT""}]","2023-01-30"
"2301.11892","Soumya Banerjee","Soumya Banerjee, Vinay Kumar Verma, Vinay P. Namboodiri","Streaming LifeLong Learning With Any-Time Inference","arXiv admin note: substantial text overlap with arXiv:2110.10741",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Despite rapid advancements in lifelong learning (LLL) research, a large body
of research mainly focuses on improving the performance in the existing
\textit{static} continual learning (CL) setups. These methods lack the ability
to succeed in a rapidly changing \textit{dynamic} environment, where an AI
agent needs to quickly learn new instances in a `single pass' from the
non-i.i.d (also possibly temporally contiguous/coherent) data streams without
suffering from catastrophic forgetting. For practical applicability, we propose
a novel lifelong learning approach, which is streaming, i.e., a single input
sample arrives in each time step, single pass, class-incremental, and subject
to be evaluated at any moment. To address this challenging setup and various
evaluation protocols, we propose a Bayesian framework, that enables fast
parameter update, given a single training example, and enables any-time
inference. We additionally propose an implicit regularizer in the form of
snap-shot self-distillation, which effectively minimizes the forgetting
further. We further propose an effective method that efficiently selects a
subset of samples for online memory rehearsal and employs a new replay buffer
management scheme that significantly boosts the overall performance. Our
empirical evaluations and ablations demonstrate that the proposed method
outperforms the prior works by large margins.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:09:19 GMT""}]","2023-01-30"
"2301.11893","Brian Lenardo","Scott J. Haselschwardt, Brian G. Lenardo, Timothy Daniels, Sean W.
  Finch, Forrest Q.L. Friesen, Calvin R. Howell, Collin R. Malone, Ethan
  Mancil, Werner Tornow","Observation of low-lying isomeric states in $^{136}$Cs: a new avenue for
  dark matter and solar neutrino detection in xenon detectors","Supplemental material available upon request",,,,"nucl-ex hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report on new measurements establishing the existence of low-lying
isomeric states in $^{136}$Cs using $\gamma$ rays produced in
$^{136}$Xe(p,n)$^{136}$Cs reactions. Two states with $\mathcal{O}(100)$~ns
lifetimes are placed in the decay sequence of the $^{136}$Cs levels that are
populated in charged-current interactions of solar neutrinos and fermionic dark
matter with $^{136}$Xe. Xenon-based experiments can therefore exploit a
delayed-coincidence tag of these interactions, greatly suppressing backgrounds
to enable spectroscopic studies of solar neutrinos and dark matter.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:10:16 GMT""}]","2023-01-30"
"2301.11894","Boris Tomasik","Jakub Cimerman, Iurii Karpenko, Boris Tomasik, Pasi Huovinen","Next-generation multi-fluid hydrodynamic model for RHIC BES","15 pages, 19 figures,",,,,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have developed a next-generation hybrid event-by-event three-fluid
hydrodynamic model, suitable for simulations of heavy-ion collisions in the
energy range from few up to tens of GeV per colliding NN pair. At such energies
the interpenetration time of the nuclei is of the same order as the lifetime of
the system, however this model treats the initial phase hydrodynamically.
Thanks to that it is more sensitive to the Equation of State than 1-fluid
models with initial states being parametrised or generated by transport
approach. Hence, our model is well designed for simulations at collision
energies, at which matter in vicinity of the QCD critical endpoint is expected.
The construction of the model is explained and basic observables like hadron
spectra in rapidity and transverse momentum, as well as elliptic flow are
calculated.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:12:23 GMT""}]","2023-01-30"
"2301.11895","Boryana Hadzhiyska","Boryana Hadzhiyska, Kevin Wolz, Susanna Azzoni, David Alonso, Carlos
  Garc\'ia-Garc\'ia, Jaime Ruiz-Zapatero, An\v{z}e Slosar","Cosmology with 6 parameters in the Stage-IV era: efficient
  marginalisation over nuisance parameters","17 pages, 6 figures, 3 tables",,,,"astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The analysis of photometric large-scale structure data is often complicated
by the need to account for many observational and astrophysical systematics.
The elaborate models needed to describe them often introduce many ``nuisance
parameters'', which can be a major inhibitor of an efficient parameter
inference. In this paper we introduce an approximate method to analytically
marginalise over a large number of nuisance parameters based on the Laplace
approximation. We discuss the mathematics of the method, its relation to
concepts such as volume effects and profile likelihood, and show that it can be
further simplified for calibratable systematics by linearising the dependence
of the theory on the associated parameters. We quantify the accuracy of this
approach by comparing it with traditional sampling methods in the context of
existing data from the Dark Energy Survey, as well as futuristic Stage-IV
photometric data. The linearised version of the method is able to obtain
parameter constraints that are virtually equivalent to those found by exploring
the full parameter space for a large number of calibratable nuisance
parameters, while reducing the computation time by a factor 3-10. Furthermore,
the non-linearised approach is able to analytically marginalise over a large
number of parameters, returning constraints that are virtually
indistinguishable from the brute-force method in most cases, accurately
reproducing both the marginalised uncertainty on cosmological parameters, and
the impact of volume effects associated with this marginalisation. We provide
simple recipes to diagnose when the approximations made by the method fail and
one should thus resort to traditional methods. The gains in sampling efficiency
associated with this method enable the joint analysis of multiple surveys,
typically hindered by the large number of nuisance parameters needed to
describe them.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:13:37 GMT""}]","2023-01-30"
"2301.11896","He-Ran Wang","He-Ran Wang, Bo Li, Fei Song, Zhong Wang","Scale-free non-Hermitian skin effect in a boundary-dissipated spin chain","23 pages, 8 figures",,,,"quant-ph cond-mat.quant-gas cond-mat.str-el math-ph math.MP physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the open XXZ spin chain with a PT-symmetric non-Hermitian boundary
field. We find an interaction-induced scale-free non-Hermitian skin effect by
using the coordinate Bethe ansatz. The steady state and the ground state in the
PT broken phase are constructed, and the formulas of their eigen-energies in
the thermodynamic limit are obtained. The differences between the many-body
scale-free states and the boundary string states are explored, and the
transition between the two at isotropic point is investigated. We also discuss
an experimental scheme to verify our results.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:14:11 GMT""}]","2023-01-30"
"2301.11897","Andrey Kistanov","Andrey A. Kistanov, Stepan A. Shcherbinin, Elena A. Korznikova, and
  Oleg V. Prezhdo","Prediction and Characterization of Two-Dimensional Zn2VN3",,,"10.1021/acs.jpclett.2c03796",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  A two-dimensional (2D) monolayer of a novel ternary nitride Zn2VN3 is
computationally designed, and its dynamical and thermal stability is
demonstrated. A synthesis strategy is proposed based on experimental works on
production of ternary nitride thin films, calculations of formation and
exfoliation energies, and ab initio molecular dynamics simulations. A
comprehensive characterization of 2D Zn2VN3, including investigation of its
optoelectronic and mechanical properties, is conducted. It is shown that 2D
Zn2VN3 is a semiconductor with an indirect band gap of 2.75 eV and a high work
function of 5.27 eV. Its light absorption covers visible and ultraviolet
regions. The band gap of 2D Zn2VN3 is found to be well tunable by applied
strain. At the same time 2D Zn2VN3 possesses high stability against mechanical
loads, point defects, and environmental impacts. Considering the unique
properties found for 2D Zn2VN3, it can be used for application in
optoelectronic and straintronic nanodevices.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:18:58 GMT""}]","2023-01-30"
"2301.11898","Valentina Zantedeschi Dr","Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt J. Kusner,
  Vlad Niculae","DAG Learning on the Permutahedron","The Eleventh International Conference on Learning Representations",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a continuous optimization framework for discovering a latent
directed acyclic graph (DAG) from observational data. Our approach optimizes
over the polytope of permutation vectors, the so-called Permutahedron, to learn
a topological ordering. Edges can be optimized jointly, or learned conditional
on the ordering via a non-differentiable subroutine. Compared to existing
continuous optimization approaches our formulation has a number of advantages
including: 1. validity: optimizes over exact DAGs as opposed to other
relaxations optimizing approximate DAGs; 2. modularity: accommodates any
edge-optimization procedure, edge structural parameterization, and optimization
loss; 3. end-to-end: either alternately iterates between node-ordering and
edge-optimization, or optimizes them jointly. We demonstrate, on real-world
data problems in protein-signaling and transcriptional network discovery, that
our approach lies on the Pareto frontier of two key metrics, the SID and SHD.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:22:25 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 19:45:06 GMT""}]","2023-02-14"
"2301.11899","Shvetank Prakash","Shvetank Prakash, Matthew Stewart, Colby Banbury, Mark Mazumder, Pete
  Warden, Brian Plancher, Vijay Janapa Reddi","Is TinyML Sustainable? Assessing the Environmental Impacts of Machine
  Learning on Microcontrollers","To appear in Communications of the ACM (CACM) in 2023",,,,"cs.LG cs.AR cs.CY","http://creativecommons.org/licenses/by/4.0/","  The sustained growth of carbon emissions and global waste elicits significant
sustainability concerns for our environment's future. The growing Internet of
Things (IoT) has the potential to exacerbate this issue. However, an emerging
area known as Tiny Machine Learning (TinyML) has the opportunity to help
address these environmental challenges through sustainable computing practices.
TinyML, the deployment of machine learning (ML) algorithms onto low-cost,
low-power microcontroller systems, enables on-device sensor analytics that
unlocks numerous always-on ML applications. This article discusses both the
potential of these TinyML applications to address critical sustainability
challenges, as well as the environmental footprint of this emerging technology.
Through a complete life cycle analysis (LCA), we find that TinyML systems
present opportunities to offset their carbon emissions by enabling applications
that reduce the emissions of other sectors. Nevertheless, when globally scaled,
the carbon footprint of TinyML systems is not negligible, necessitating that
designers factor in environmental impact when formulating new devices. Finally,
we outline research directions to enable further sustainable contributions of
TinyML.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:23:10 GMT""},{""version"":""v2"",""created"":""Fri, 19 May 2023 17:54:49 GMT""}]","2023-05-22"
"2301.11900","Molly Andersen","Molly P. Andersen, Linsey K. Rodenbach, Ilan T. Rosen, Stanley C. Lin,
  Lei Pan, Peng Zhang, Lixuan Tai, Kang L. Wang, Marc A. Kastner, David
  Goldhaber-Gordon","Low-damage electron beam lithography for nanostructures on
  Bi$_2$Te$_3$-class topological insulator thin films","10 pages, 5 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Nanostructured topological insulators (TIs) have the potential to impact a
wide array of condensed matter physics topics, ranging from Majorana physics to
spintronics. However, the most common TI materials, the Bi$_2$Se$_3$ family,
are easily damaged during nanofabrication of devices. In this paper, we show
that electron beam lithography performed with a 30 or 50 kV accelerating
voltage -- common for nanopatterning in academic facilities -- damages both
nonmagnetic TIs and their magnetically-doped counterparts at unacceptable
levels. We additionally demonstrate that electron beam lithography with a 10 kV
accelerating voltage produces minimal damage detectable through low-temperature
electronic transport. Although reduced accelerating voltages present challenges
in creating fine features, we show that with careful choice of processing
parameters, particularly the resist, 100 nm features are reliably achievable.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:23:54 GMT""}]","2023-01-30"
"2301.11901","David Lowry-Duda","Chan Ieong Kuan, David Lowry-Duda, Alexander Walker, Raphael S.
  Steiner","Sums of Cusp Form Coefficients Along Quadratic Sequences","22 pages, with a 14 page appendix from Raphael S. Steiner. This
  version corrects a mistake in the previous, where lifts of holomorphic
  modular forms to Maass forms were omitted; and it has an updated abstract",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $f(z) = \sum A(n) n^{(k-1)/2} e(nz)$ be a cusp form of weight $k \geq 3$
on $\Gamma_0(N)$ with character $\chi$. By studying a certain shifted
convolution sum, we prove that $\sum_{n \leq X} A(n^2+h) = c_{f,h} X +
O_{f,h,\epsilon}(X^{\frac{3}{4}+\epsilon})$ for $\epsilon>0$, which improves a
result of Blomer from 2008 with error $X^{\frac{6}{7}+\epsilon}$.
  This includes an appendix due to Raphael S. Steiner, proving stronger bounds
for certain spectral averages.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:26:47 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 17:29:48 GMT""},{""version"":""v3"",""created"":""Tue, 25 Apr 2023 19:08:33 GMT""}]","2023-04-27"
"2301.11902","Yuxiao Chen","Yuxiao Chen, Peter Karkus, Boris Ivanovic, Xinshuo Weng, and Marco
  Pavone","Tree-structured Policy Planning with Learned Behavior Models",,,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Autonomous vehicles (AVs) need to reason about the multimodal behavior of
neighboring agents while planning their own motion. Many existing trajectory
planners seek a single trajectory that performs well under \emph{all} plausible
futures simultaneously, ignoring bi-directional interactions and thus leading
to overly conservative plans. Policy planning, whereby the ego agent plans a
policy that reacts to the environment's multimodal behavior, is a promising
direction as it can account for the action-reaction interactions between the AV
and the environment. However, most existing policy planners do not scale to the
complexity of real autonomous vehicle applications: they are either not
compatible with modern deep learning prediction models, not interpretable, or
not able to generate high quality trajectories. To fill this gap, we propose
Tree Policy Planning (TPP), a policy planner that is compatible with
state-of-the-art deep learning prediction models, generates multistage motion
plans, and accounts for the influence of ego agent on the environment behavior.
The key idea of TPP is to reduce the continuous optimization problem into a
tractable discrete Markov Decision Process (MDP) through the construction of
two tree structures: an ego trajectory tree for ego trajectory options, and a
scenario tree for multi-modal ego-conditioned environment predictions. We
demonstrate the efficacy of TPP in closed-loop simulations based on real-world
nuScenes dataset and results show that TPP scales to realistic AV scenarios and
significantly outperforms non-policy baselines.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:27:26 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 04:30:38 GMT""}]","2023-02-28"
"2301.11903","Marco Skocaj","Marco Skocaj, Pedro Enrique Iturria Rivera, Roberto Verdone and Melike
  Erol-Kantarci","Uplink Scheduling in Federated Learning: an Importance-Aware Approach
  via Graph Representation Learning","6 pages, 6 figures, conference paper",,,,"cs.NI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Federated Learning (FL) has emerged as a promising framework for distributed
training of AI-based services, applications, and network procedures in 6G. One
of the major challenges affecting the performance and efficiency of 6G wireless
FL systems is the massive scheduling of user devices over resource-constrained
channels. In this work, we argue that the uplink scheduling of FL client
devices is a problem with a rich relational structure. To address this
challenge, we propose a novel, energy-efficient, and importance-aware metric
for client scheduling in FL applications by leveraging Unsupervised Graph
Representation Learning (UGRL). Our proposed approach introduces a relational
inductive bias in the scheduling process and does not require the collection of
training feedback information from client devices, unlike state-of-the-art
importance-aware mechanisms. We evaluate our proposed solution against baseline
scheduling algorithms based on recently proposed metrics in the literature.
Results show that, when considering scenarios of nodes exhibiting spatial
relations, our approach can achieve an average gain of up to 10% in model
accuracy and up to 17 times in energy efficiency compared to state-of-the-art
importance-aware policies.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:30:39 GMT""}]","2023-01-30"
"2301.11904","Nachiketa Chakraborty","Nachiketa Chakraborty, Harriet Turner, Mathew Owens, Matthew Lang","Causal Analysis of Influence of the Solar Cycle and Latitudinal
  Solar-Wind Structure on Corotation Forecasts",,,,,"astro-ph.SR physics.data-an physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Studying solar wind conditions is central to forecasting impact of space
weather on Earth. Under the assumption that the structure of this wind is
constant in time and corotates with the Sun, solar wind and thereby space
weather forecasts have been made quite effectively. Such corotation forecasts
are well studied with decades of observations from STEREO and near-Earth
spacecrafts. Forecast accuracy depends upon the latitudinal separation (or
offset $\Delta \theta$) between source and spacecraft, forecast lead time
($\Delta t$) and the solar cycle via the sunspot number (SSN). The precise
dependencies factoring in uncertain- ties however, are a mixture of influences
from each of these factors. And for high precision forecasts, it is important
to understand what drives the forecast accuracy and its uncertainty. Here we
present a causal inference approach based on information theoretic measures to
do this. Our framework can compute not only the direct (linear and non-linear)
dependencies of the forecast mean absolute error (MAE) on SSN, $\Delta t$ and
$\Delta t$, but also how these individual variables combine to enhance or
diminish the MAE. We provide an initial assessment of this with potential of
aiding data assimilation in the future.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:32:50 GMT""}]","2023-01-30"
"2301.11905","Elias Koutsoupias","George Christodoulou, Elias Koutsoupias, Annamaria Kovacs","A proof of the Nisan-Ronen conjecture",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noam Nisan and Amir Ronen conjectured that the best approximation ratio of
deterministic truthful mechanisms for makespan-minimization for $n$ unrelated
machines is $n$. This work validates the conjecture.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:33:34 GMT""}]","2023-01-30"
"2301.11906","Gustavo Garrigos","Gustavo Garrig\'os, Andreas Seeger and Tino Ullrich","A sufficient condition for Haar multipliers in Triebel-Lizorkin spaces","13 pages, 5 figures",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  We consider Haar multiplier operators $T_m$ acting on Sobolev spaces, and
more generally Triebel-Lizorkin spaces $F^s_{p,q}(\mathbb{R})$, for indices in
which the Haar system is not unconditional. When $m$ depends only on the Haar
frequency, we give a sufficient condition for the boundedness of $T_m$ in
$F^s_{p,q}$, in terms of the variation norms $\|m\|_{V_u}$, which is optimal in
$u$ (up to endpoints) when $p, q> 1$.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:44:39 GMT""}]","2023-01-30"
"2301.11907","Felipe Yukihide Yasumura","Felipe Yukihide Yasumura","Universal enveloping of a graded Lie algebra",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we construct a graded universal enveloping algebra of a
$G$-graded Lie algebra, where $G$ is not necessarily an abelian group. If the
grading group is abelian, then it coincides with the classical construction. We
prove the existence and uniqueness of the graded enveloping algebra. As
consequences, we prove a graded variant of Witt's Theorem on the universal
enveloping algebra of the free Lie algebra, and the graded version of Ado's
Theorem, which states that every finite-dimensional Lie algebra admits a
faithful finite dimensional representation. Furthermore we investigate if a Lie
grading is equivalent to an abelian grading.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:44:41 GMT""}]","2023-01-30"
"2301.11908","Prabhakar Palni","Om Shahi, Vaishnavi Desai, Prabhakar Palni","A modular perspective to the jet suppression from a small to large
  radius in very high transverse momentum jets",,,,,"hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  In this work, we extend the scope of the JETSCAPE framework to cover the jet
radius ($R$) dependence of the jet nuclear modification factor, ${R_{AA}}$, for
broader area jet cones, going all the way up to $R$ = 1.0. The primary focus of
this work has been the in-depth analysis of the high-${p_{T}}$ inclusive jets
and the quenching effects observed in the quark-gluon plasma formed in the
Pb-Pb collisions at ${\sqrt{\rm s_{NN}}}$= 5.02 TeV for the most-central
(0-10\%) collisions. The nuclear modification factor is calculated for
inclusive jets to compare with the experimental results collected at the ATLAS
and the CMS detectors in the jet transverse momentum (${p_{T}}$) ranging from
100 GeV up to 1 TeV. The results predicted by the JETSCAPE are consistent in
the high ${p_{T}}$ range as well as for extreme jet cone sizes, i.e. within
10-20\%. We also calculate the double ratio
(${R^{\mathrm{R}}_{\mathrm{AA}}/R^{\mathrm{R=small}}_{\mathrm{AA}}}$) as a
function of jet radius and jet-${p_{T}}$, where the observations are well
described by the JETSCAPE framework which is based on the hydrodynamic
multi-stage evolution of the parton shower. The calculations are then
replicated for different low-virtuality based evolution models like the MARTINI
and the AdS/CFT, which is followed by a rigorous comparison between the
predictions from the former model combinations to the measurements at the CMS
experiment.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:48:35 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 18:24:30 GMT""}]","2023-02-08"
"2301.11909","Pablo Zometa","Pablo Zometa and Timm Faulwasser","Quantized Deep Path-following Control on a Microcontroller",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Model predictive Path-Following Control (MPFC) is a viable option for motion
systems in many application domains. However, despite considerable progress on
tailored numerical methods for predictive control, the real-time implementation
of predictive control and MPFC on small-scale autonomous platforms with
low-cost embedded hardware remains challenging. While usual stabilizing MPC
formulations lead to static feedback laws, the MPFC feedback turns out to be
dynamic as the path parameter acts as an internal controller variable. In this
paper, we leverage deep learning to implement predictive path-following control
on microcontrollers. We show that deep neural networks can approximate the
dynamic MPFC feedback law accurately. Moreover, we illustrate and tackle the
challenges that arise if the target platform employs limited precision
arithmetic. Specifically, we draw upon a post-stabilization with an additional
feedback law to attenuate undesired quantization effects. Simulation examples
underpin the efficacy of the proposed approach.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:48:54 GMT""}]","2023-01-30"
"2301.11910","Tejbir Lohan","Krishnendu Gongopadhyay, Tejbir Lohan and Chandan Maity","Reversibility and Real Adjoint Orbits of Linear Maps","9 pages. arXiv admin note: substantial text overlap with
  arXiv:2211.11606",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend classical results on the classification of reversible elements of
the group $\mathrm{GL}(n, \mathbb{C})$ (and $\mathrm{GL}(n, \mathbb{R})$) to
$\mathrm{GL}(n, \mathbb{H})$ using an infinitesimal version of the classical
reversibility, namely adjoint reality in the Lie algebra set-up. We also
provide a new proof of such a classification for the general linear groups over
$\mathbb{R}$ and $\mathbb{C}$. Further, we classify the real adjoint orbits in
the Lie algebra $\mathfrak{gl}(n, \mathbb{D})$ for $ \mathbb{D}=\mathbb{R},
\mathbb{C}$ or $\mathbb{H} $.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:51:06 GMT""}]","2023-01-30"
"2301.11911","Johanna Vielhaben","Johanna Vielhaben, Stefan Bl\""ucher, Nils Strodthoff","Multi-dimensional concept discovery (MCD): A unifying framework with
  completeness guarantees","24 pages, 11 figures. This work builds on an earlier manuscript
  (arXiv:2203.06043) and crucially extends it. Code is available at
  https://github.com/jvielhaben/MCD-XAI",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The completeness axiom renders the explanation of a post-hoc XAI method only
locally faithful to the model, i.e. for a single decision. For the trustworthy
application of XAI, in particular for high-stake decisions, a more global model
understanding is required. Recently, concept-based methods have been proposed,
which are however not guaranteed to be bound to the actual model reasoning. To
circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD)
as an extension of previous approaches that fulfills a completeness relation on
the level of concepts. Our method starts from general linear subspaces as
concepts and does neither require reinforcing concept interpretability nor
re-training of model parts. We propose sparse subspace clustering to discover
improved concepts and fully leverage the potential of multi-dimensional
subspaces. MCD offers two complementary analysis tools for concepts in input
space: (1) concept activation maps, that show where a concept is expressed
within a sample, allowing for concept characterization through prototypical
samples, and (2) concept relevance heatmaps, that decompose the model decision
into concept contributions. Both tools together enable a detailed understanding
of the model reasoning, which is guaranteed to relate to the model via a
completeness relation. This paves the way towards more trustworthy
concept-based XAI. We empirically demonstrate the superiority of MCD against
more constrained concept definitions.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:53:19 GMT""}]","2023-01-30"
"2301.11912","Xingwu Guo","Xingwu Guo, Ziwei Zhou, Yueling Zhang, Guy Katz, Min Zhang","OccRob: Efficient SMT-Based Occlusion Robustness Verification of Deep
  Neural Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Occlusion is a prevalent and easily realizable semantic perturbation to deep
neural networks (DNNs). It can fool a DNN into misclassifying an input image by
occluding some segments, possibly resulting in severe errors. Therefore, DNNs
planted in safety-critical systems should be verified to be robust against
occlusions prior to deployment. However, most existing robustness verification
approaches for DNNs are focused on non-semantic perturbations and are not
suited to the occlusion case. In this paper, we propose the first efficient,
SMT-based approach for formally verifying the occlusion robustness of DNNs. We
formulate the occlusion robustness verification problem and prove it is
NP-complete. Then, we devise a novel approach for encoding occlusions as a part
of neural networks and introduce two acceleration techniques so that the
extended neural networks can be efficiently verified using off-the-shelf,
SMT-based neural network verification tools. We implement our approach in a
prototype called OccRob and extensively evaluate its performance on benchmark
datasets with various occlusion variants. The experimental results demonstrate
our approach's effectiveness and efficiency in verifying DNNs' robustness
against various occlusions, and its ability to generate counterexamples when
these DNNs are not robust.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:54:00 GMT""}]","2023-01-30"
"2301.11913","Max Ryabinin","Max Ryabinin, Tim Dettmers, Michael Diskin, Alexander Borzunov","SWARM Parallelism: Training Large Models Can Be Surprisingly
  Communication-Efficient","Work in progress. 23 pages, 8 figures",,,,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many deep learning applications benefit from using large models with billions
of parameters. Training these models is notoriously expensive due to the need
for specialized HPC clusters. In this work, we consider alternative setups for
training large models: using cheap ""preemptible"" instances or pooling existing
resources from multiple regions. We analyze the performance of existing
model-parallel algorithms in these conditions and find configurations where
training larger models becomes less communication-intensive. Based on these
findings, we propose SWARM parallelism, a model-parallel training algorithm
designed for poorly connected, heterogeneous and unreliable devices. SWARM
creates temporary randomized pipelines between nodes that are rebalanced in
case of failure. We empirically validate our findings and compare SWARM
parallelism with existing large-scale training approaches. Finally, we combine
our insights with compression strategies to train a large Transformer language
model with 1B shared parameters (approximately 13B before sharing) on
preemptible T4 GPUs with less than 200Mb/s network.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:55:19 GMT""}]","2023-01-30"
"2301.11914","Jim Fuller","Jim Fuller, Stephane Mathis","Linking the Interiors and Surfaces of Magnetic Stars","Submitted to MNRAS, comments welcome!",,"10.1093/mnras/stad475",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strong magnetic fields are observed in a substantial fraction of upper main
sequence stars and white dwarfs. Many such stars are observed to exhibit
photometric modulations as the magnetic poles rotate in and out of view, which
could be a consequence of magnetic perturbations to the star's thermal
structure. The magnetic pressure is typically larger than the gas pressure at
the star's photosphere, but much smaller than the gas pressure in the star's
interior, so the expected surface flux perturbations are not clear. We compute
magnetically perturbed stellar structures of young $3 \, M_\odot$ stars that
are in both hydrostatic and thermal equilibrium, and which contain both
poloidal and toroidal components of a dipolar magnetic field as expected for
stable fossil fields. This provides semi-analytical models of such fields in
baroclinic stably stratified regions. The star's internal pressure,
temperature, and flux perturbations can have a range of magnitudes, though we
argue the most likely configurations exhibit flux perturbations much smaller
than the ratio of surface magnetic pressure to surface gas pressure, but much
larger than the ratio of surface magnetic pressure to central gas pressure. The
magnetic pole is hotter than the equator in our models, but a cooler magnetic
pole is possible depending on the magnetic field configuration. The expected
flux variations for observed field strengths are $\delta L/L \! \lesssim \!
10^{-6}$, much smaller than those observed in magnetic stars, suggesting that
observed perturbations stem from changes to the emergent spectrum rather than
changes to the bolometric flux.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:56:17 GMT""}]","2023-02-22"
"2301.11915","Mingyu Ding","Jie Zhu, Jiyang Qi, Mingyu Ding, Xiaokang Chen, Ping Luo, Xinggang
  Wang, Wenyu Liu, Leye Wang, Jingdong Wang","Understanding Self-Supervised Pretraining with Part-Aware Representation
  Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are interested in understanding self-supervised pretraining
through studying the capability that self-supervised representation pretraining
methods learn part-aware representations. The study is mainly motivated by that
random views, used in contrastive learning, and random masked (visible)
patches, used in masked image modeling, are often about object parts.
  We explain that contrastive learning is a part-to-whole task: the projection
layer hallucinates the whole object representation from the object part
representation learned from the encoder, and that masked image modeling is a
part-to-part task: the masked patches of the object are hallucinated from the
visible patches. The explanation suggests that the self-supervised pretrained
encoder is required to understand the object part. We empirically compare the
off-the-shelf encoders pretrained with several representative methods on
object-level recognition and part-level recognition. The results show that the
fully-supervised model outperforms self-supervised models for object-level
recognition, and most self-supervised contrastive learning and masked image
modeling methods outperform the fully-supervised method for part-level
recognition. It is observed that the combination of contrastive learning and
masked image modeling further improves the performance.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:58:42 GMT""}]","2023-01-30"
"2301.11916","Xinyi Wang","Xinyi Wang, Wanrong Zhu, Michael Saxon, Mark Steyvers, William Yang
  Wang","Large Language Models Are Implicitly Topic Models: Explaining and
  Finding Good Demonstrations for In-Context Learning","code at:
  https://github.com/WANGXinyiLinda/concept-based-demonstration-selection",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, pre-trained large language models have demonstrated
remarkable efficiency in achieving an inference-time few-shot learning
capability known as in-context learning. However, existing literature has
highlighted the sensitivity of this capability to the selection of few-shot
demonstrations. The underlying mechanisms by which this capability arises from
regular language model pretraining objectives remain poorly understood. In this
study, we aim to examine the in-context learning phenomenon through a Bayesian
lens, viewing large language models as topic models that implicitly infer
task-related information from demonstrations. On this premise, we propose an
algorithm for selecting optimal demonstrations from a set of annotated data and
demonstrate a significant 12.5% improvement relative to the random selection
baseline, averaged over eight GPT2 and GPT3 models on eight different
real-world text classification datasets. Our empirical findings support our
hypothesis that large language models implicitly infer a latent concept
variable.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:59:01 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 15:09:50 GMT""}]","2023-05-05"
"2301.11917","Ruben Verresen","Ruben Verresen","Everything is a quantum Ising model","9.5 pages + appendix",,,,"quant-ph cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work shows that any $k$-local Hamiltonian of qubits can be obtained from
a 4-state 'Ising' model with $k$-local diagonal interactions and a single-site
transverse field -- giving a new theoretical and experimental handle on quantum
matter. In particular, the classical Ising interactions can be determined by
replacing each Pauli operator with a $4 \times 4$ diagonal matrix. Subsequently
tuning a large transverse field projects out two of the four states, recovering
the original qubit model, with qudit generalizations. This leads to striking
correspondences, such as the spin-1/2 XY and Heisenberg models arising from the
large-field limit of 3-state and 4-state Potts models, respectively. Similarly,
the Kitaev honeycomb model emerges from classical interactions which enforce
loop states on the honeycomb lattice. These generalized Ising models also
display rich physics for smaller fields, including quantum criticality and
topological phases of matter. This work expands what is experimentally
achievable by showing how to realize any quantum spin model using only diagonal
interactions and a tuneable field -- ingredients found in, e.g., tweezer arrays
of Rydberg atoms or polar molecules. More broadly, 4-state spins can also be
encoded in the positions of itinerant particles, exemplified by a Bose-Hubbard
model realizing the Kitaev honeycomb model -- giving an experimental path to
its $\mathbb Z_2$ and non-Abelian topological quantum liquids.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:59:02 GMT""}]","2023-01-30"
"2301.11918","Adam \'Spiewak","Krzysztof Bara\'nski, Yonatan Gutman, Adam \'Spiewak","Regularity of almost-surely injective projections in Euclidean spaces",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that if a finite Borel measure $\mu$ in a Euclidean space has
Hausdorff dimension smaller than a positive integer $k$, then the orthogonal
projection onto almost every $k$-dimensional linear subspace is injective on a
set of full $\mu$-measure. We study the regularity of the inverses of such
projections. We prove that if $\mu$ has a compact support $X$ and
(respectively) the Hausdorff, upper box-counting or Assouad dimension of $X$ is
smaller than $k$, then the inverse is (respectively) continuous, pointwise
H\""older for some $\alpha \in (0,1)$ or pointwise H\""older for every $\alpha
\in (0,1)$. The result generalizes to the case of typical linear perturbations
of Lipschitz maps. Additionally, we construct a non-trivial measure on the
plane which admits almost-surely injective projections in every direction, and
show that no homogeneous self-similar measure has this property.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:59:07 GMT""}]","2023-01-30"
"2301.11919","Tyler Josephson","Charles Fox, Neil Tran, Nikki Nacion, Samiha Sharlin, and Tyler R.
  Josephson","Incorporating Background Knowledge in Symbolic Regression using a
  Computer Algebra System",,,,,"cs.LG cs.SC physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Symbolic Regression (SR) can generate interpretable, concise expressions that
fit a given dataset, allowing for more human understanding of the structure
than black-box approaches. The addition of background knowledge (in the form of
symbolic mathematical constraints) allows for the generation of expressions
that are meaningful with respect to theory while also being consistent with
data. We specifically examine the addition of constraints to traditional
genetic algorithm (GA) based SR (PySR) as well as a Markov-chain Monte Carlo
(MCMC) based Bayesian SR architecture (Bayesian Machine Scientist), and apply
these to rediscovering adsorption equations from experimental, historical
datasets. We find that, while hard constraints prevent GA and MCMC SR from
searching, soft constraints can lead to improved performance both in terms of
search effectiveness and model meaningfulness, with computational costs
increasing by about an order-of-magnitude. If the constraints do not correlate
well with the dataset or expected models, they can hinder the search of
expressions. We find Bayesian SR is better these constraints (as the Bayesian
prior) than by modifying the fitness function in the GA
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:59:25 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 14:52:27 GMT""}]","2023-05-05"
"2301.11920","Victor Bittencourt","V. A. S. V. Bittencourt and C. A. Potts and Y. Huang and J. P. Davis
  and S. Viola Kusminskiy","Magnomechanical backaction corrections due to coupling to higher order
  Walker modes and Kerr nonlinearities","19 pages, 9 figures",,"10.1103/PhysRevB.107.144411",,"cond-mat.mes-hall quant-ph","http://creativecommons.org/licenses/by/4.0/","  The radiation pressure-like coupling between magnons and phonons in magnets
can modify the phonon frequency (magnomechanical spring effect) and decay rate
(magnomechanical decay) via dynamical backaction. Such effects have been
recently observed by coupling the uniform magnon mode of a magnetic sphere (the
Kittel mode) to a microwave cavity. In particular, the ability to evade
backaction effects was demonstrated [C.A. Potts et al., arXiv:2211.13766
[quant-ph] (2022)], a requisite for applications such as magnomechanical based
thermometry. However, deviations were observed from the predicted
magnomechanical decay rate within the standard theoretical model. In this work,
we account for these deviations by considering corrections due to (i) magnetic
Kerr nonlinearities and (ii) the coupling of phonons to additional magnon
modes. Provided that such additional modes couple weakly to the driven cavity,
our model yields a correction proportional to the average Kittel magnon mode
occupation. We focus our results on magnetic spheres, where we show that the
magnetostatic Walker modes couple to the relevant mechanical modes as
efficiently as the Kittel mode. Our model yields excellent agreement with the
experimental data.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 18:59:59 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 14:07:37 GMT""},{""version"":""v3"",""created"":""Mon, 13 Mar 2023 16:18:46 GMT""},{""version"":""v4"",""created"":""Fri, 14 Apr 2023 14:58:44 GMT""}]","2023-04-17"
"2301.11934","Doruk Efe G\""okmen","Doruk Efe G\""okmen, Sounak Biswas, Sebastian D. Huber, Zohar Ringel,
  Felix Flicker, Maciej Koch-Janusz","Compression theory for inhomogeneous systems","9 pages, 7 figures",,,,"cond-mat.stat-mech cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  The physics of complex systems stands to greatly benefit from the qualitative
changes in data availability and advances in data-driven computational methods.
Many of these systems can be represented by interacting degrees of freedom on
inhomogeneous graphs. However, the irregularity of the graph structure and the
vastness of configurational spaces present a fundamental challenge to
theoretical tools, such as the renormalization group, which were so successful
in characterizing the universal physical behaviour in critical phenomena. Here
we show that compression theory allows to extract relevant degrees of freedom
in arbitrary geometries, and develop efficient numerical tools to build an
effective theory from data. We demonstrate our method by applying it to a
strongly interacting system on an Ammann-Beenker quasicrystal, where it
discovers an exotic critical point with broken conformal symmetry.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 13:09:33 GMT""}]","2023-05-17"
"2301.11935","Lukas Burgholzer","Robert Wille and Lukas Burgholzer","MQT QMAP: Efficient Quantum Circuit Mapping","7 pages, 6 figures, invited paper for the International Symposium on
  Physical Design (ISPD '23)",,"10.1145/3569052.3578928",,"quant-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum computing is an emerging technology that has the potential to
revolutionize fields such as cryptography, machine learning, optimization, and
quantum simulation. However, a major challenge in the realization of quantum
algorithms on actual machines is ensuring that the gates in a quantum circuit
(i.e., corresponding operations) match the topology of a targeted architecture
so that the circuit can be executed while, at the same time, the resulting
costs (e.g., in terms of the number of additionally introduced gates, fidelity,
etc.) are kept low. This is known as the quantum circuit mapping problem. This
summary paper provides an overview of QMAP, an open-source tool that is part of
the Munich Quantum Toolkit (MQT) and offers efficient, automated, and
accessible methods for tackling this problem. To this end, the paper first
briefly reviews the problem. Afterwards, it shows how QMAP can be used to
efficiently map quantum circuits to quantum computing architectures from both a
user's and a developer's perspective. QMAP is publicly available as open-source
at https://github.com/cda-tum/qmap.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:00 GMT""}]","2023-01-31"
"2301.11936","Hayata Yamasaki","Hayata Yamasaki, Sathyawageeswar Subramanian, Satoshi Hayakawa, Sho
  Sonoda","Quantum Ridgelet Transform: Winning Lottery Ticket of Neural Networks
  with Quantum Computation","25 pages, 3 figures",,,,"quant-ph cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ridgelet transform has been a fundamental mathematical tool in the
theoretical studies of neural networks. However, the practical applicability of
ridgelet transform to conducting learning tasks was limited since its numerical
implementation by conventional classical computation requires an exponential
runtime $\exp(O(D))$ as data dimension $D$ increases. To address this problem,
we develop a quantum ridgelet transform (QRT), which implements the ridgelet
transform of a quantum state within a linear runtime $O(D)$ of quantum
computation. As an application, we also show that one can use QRT as a
fundamental subroutine for quantum machine learning (QML) to efficiently find a
sparse trainable subnetwork of large shallow wide neural networks without
conducting large-scale optimization of the original network. This application
discovers an efficient way in this regime to demonstrate the lottery ticket
hypothesis on finding such a sparse trainable neural network. These results
open an avenue of QML for accelerating learning tasks with commonly used
classical neural networks.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:00 GMT""}]","2023-01-31"
"2301.11937","Christopher Bambic","C. J. Bambic, H. R. Russell, C.S. Reynolds, A. C. Fabian, B. R.
  McNamara, and P. E. J. Nulsen","AGN Feeding and Feedback in M84: From Kiloparsec Scales to the Bondi
  Radius","17 pages, 9 figures, 2 tables, submitted to MNRAS",,"10.1093/mnras/stad824",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present the deepest Chandra observation to date of the galaxy M84 in the
Virgo Cluster, with over 840 kiloseconds of data provided by legacy
observations and a recent 730 kilosecond campaign. The increased
signal-to-noise allows us to study the origins of the accretion flow feeding
the supermassive black hole in the center of M84 from the kiloparsec scales of
the X-ray halo to the Bondi radius, $R_{\rm B}$. Temperature, metallicity, and
deprojected density profiles are obtained in four sectors about M84's AGN,
extending into the Bondi radius. Rather than being dictated by the potential of
the black hole, the accretion flow is strongly influenced by the AGN's bipolar
radio jets. Along the jet axis, the density profile is consistent with $n_e
\propto r^{-1}$; however, the profiles flatten perpendicular to the jet. Radio
jets produce a significant asymmetry in the flow, violating a key assumption of
Bondi accretion. Temperature in the inner kiloparsec is approximately constant,
with only a slight increase from 0.6 to 0.7 keV approaching $R_{\rm B}$, and
there is no evidence for a temperature rise imposed by the black hole. The
Bondi accretion rate $\dot{M}_{\rm B}$ exceeds the rate inferred from AGN
luminosity and jet power by over four orders of magnitude. In sectors
perpendicular to the jet, $\dot{M}_{\rm B}$ measurements agree; however, the
accretion rate is $> 4 \sigma$ lower in the North sector along the jet, likely
due to cavities in the X-ray gas. Our measurements provide unique insight into
the fueling of AGN responsible for radio mode feedback in galaxy clusters.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:00 GMT""}]","2023-05-17"
"2301.11938","Jakob Ehring","Jakob Ehring (1,2,3), Sajad Abbar (1), Hans-Thomas Janka (2), Georg
  Raffelt (1), Irene Tamborra (4) ((1) MPI Physik, (2) MPI Astrophysik, (3) TUM
  Garching, (4) Niels Bohr Institute)","Fast Neutrino Flavor Conversion in Core-Collapse Supernovae: A
  Parametric Study in 1D Models","20 pages, 10 figures, slightly extended version, accepted by PRD","Phys. Rev. D 107, 103034 (2023)","10.1103/PhysRevD.107.103034",,"astro-ph.HE gr-qc hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the impact of small-scale flavor conversions of neutrinos, the
so-called fast flavor conversions (FFCs), on the dynamical evolution and
neutrino emission of core-collapse supernovae (CCSNe). In order to do that, we
implement FFCs in the spherically symmetric (1D) CCSN simulations of a 20
solar-mass progenitor model parametrically, assuming that FFCs happen at
densities lower than a systematically varied threshold value and lead to an
immediate flavor equilibrium consistent with lepton number conservation. We
find that besides hardening the electron neutrino and antineutrino spectra,
which helps the expansion of the shock by enhanced postshock heating, FFCs can
cause significant, nontrivial modifications of the energy transport in the SN
environment via increasing the heavy-lepton neutrino luminosities. In our
non-exploding models this results in extra cooling of the layers around the
neutrinospheres, which triggers a faster contraction of the proto-neutron star
and hence, in our 1D models, hampers the CCSN explosion. Although our study is
limited by the 1D nature of our simulations, it provides valuable insights into
how neutrino flavor conversions in the deepest CCSN regions can impact the
neutrino release and the corresponding response of the stellar medium.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Sun, 2 Apr 2023 10:26:12 GMT""}]","2023-05-31"
"2301.11939","Tatsuya Matsumoto","Tatsuya Matsumoto, Brian D. Metzger","Synchrotron Afterglow Model for AT 2022cmc: Jetted Tidal Disruption
  Event or Engine-Powered Supernova?","11 pages, 9 figures, 2 tables, accepted for publication in MNRAS",,"10.1093/mnras/stad1182",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  AT 2022cmc is a luminous optical transient ($\nu L_{\nu} \gtrsim 10^{45}$ erg
s$^{-1}$) accompanied by decaying non-thermal X-rays (peak duration $t_{\rm X}
\lesssim$ days and isotropic energy $E_{\rm X,iso} \gtrsim 10^{53}$ erg) and a
long-lived radio/mm synchrotron afterglow, which has been interpreted as a
jetted tidal disruption event (TDE). Both an equipartition analysis and a
detailed afterglow model reveals the radio/mm emitting plasma to be expanding
mildly relativistically (Lorentz factor $\Gamma \gtrsim\,few$) with an opening
angle $\theta_{\rm j}\simeq0.1$ and roughly fixed energy $E_{\rm j,iso} \gtrsim
few \times 10^{53}$ erg into an external medium of density profile $n \propto
R^{-k}$ with $k \simeq 1.5-2$, broadly similar to that of the first jetted TDE
candidate Swift J1644+57 and consistent with Bondi accretion at a rate $\sim
10^{-3}\dot{M}_{\rm Edd}$ onto a $10^{6}M_{\odot}$ black hole before the
outburst. The rapidly decaying optical emission over the first days is
consistent with fast-cooling synchrotron radiation from the same forward shock
as the radio/mm emission, while the bluer slowly decaying phase to follow
likely represents a separate thermal emission component. Emission from the
reverse shock may have peaked during the first days, but whose non-detection in
the optical band places an upper bound $\Gamma_{\rm j} \lesssim 100$ on the
Lorentz factor of the unshocked jet. Although a TDE origin for AT 2022cmc is
indeed supported by some observations, the vast difference between the
short-lived jet activity phase $t_{\rm X} \lesssim$ days relative to the
months-long thermal optical emission, also challenges this scenario. A stellar
core-collapse event giving birth to a magnetar or black hole engine of peak
duration $\sim 1$ day offers an alternative model also consistent with the
circumburst environment, if interpreted as a massive-star wind.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 13:56:15 GMT""}]","2023-05-03"
"2301.11940","Weiyao Ke","Weiyao Ke and Ivan Vitev","Understanding parton evolution in matter from renormalization group
  analysis","5 pages, 1 figure, with supplementary materials",,,"LA-UR-23-20730","hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a renormalization group (RG) analysis of collinear hadron
production in deep inelastic scattering on nuclei. We consider the limit where
one of the dimensionless in-medium scale ratios $E/(\mu_D^2 L) \gg 1$, with
$L,\mu_D,E$ being the medium size, inverse scattering range and the parton
energy in the nuclear rest frame, while the opacity $L/\lambda_g$ remains
small. We identify the fixed order and leading $\ln[E/(\mu_D^2 L)]$ enhanced
medium contributions to the semi-inclusive cross sections and derive RG
equations which resum multiple emissions near the $x\rightarrow 0,1$ endpoints
of the splitting functions at first order in opacity. We find that the
evolution equations obtained in this work treat the same type of radiation
enhancement in matter as the modified DGLAP approach, but differ in the way one
chooses to regulate the endpoint divergences and provide unique analytic
insight into the problem of resummation. The new RG evolution framework is
applied to study fragmentation in $e$A reactions.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:01 GMT""}]","2023-01-31"
"2301.11941","Caroline Owen","Caroline B. Owen, Carl-Johan Haster, Scott Perkins, Neil J. Cornish,
  Nicol\'as Yunes","Waveform accuracy and systematic uncertainties in current gravitational
  wave observations","14 pages, 7 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The post-Newtonian formalism plays an integral role in the models used to
extract information from gravitational wave data, but models that incorporate
this formalism are inherently approximations. Disagreement between an
approximate model and nature will produce mismodeling biases in the parameters
inferred from data, introducing systematic error. We here carry out a
proof-of-principle study of such systematic error by considering signals
produced by quasi-circular, inspiraling black hole binaries through an
injection and recovery campaign. In particular, we study how unknown, but
calibrated, higher-order post-Newtonian corrections to the gravitational wave
phase impact systematic error in recovered parameters. As a first study, we
produce injected data of non-spinning binaries as detected by a current,
second-generation network of ground-based observatories and recover them with
models of varying PN order in the phase. We find that the truncation of higher
order (>3.5) post-Newtonian corrections to the phase can produce significant
systematic error even at signal-to-noise ratios of current detector networks.
We propose a method to mitigate systematic error by marginalizing over our
ignorance in the waveform through the inclusion of higher-order post-Newtonian
coefficients as new model parameters. We show that this method can reduce
systematic error greatly at the cost of increasing statistical error.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:01 GMT""}]","2023-01-31"
"2301.11942","Alina Boecker","Alina Boecker, Nadine Neumayer, Annalisa Pillepich, Neige Frankel,
  Rahul Ramesh, Ryan Leaman, Lars Hernquist","The Origin of Stars in the Inner 500 Parsecs in TNG50 Galaxies","24 pages, 13 Figures, published in MNRAS",,"10.1093/mnras/stac3759",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the origin of stars in the innermost $500\,\mathrm{pc}$ of
galaxies spanning stellar masses of $5\times10^{8-12}\,\mathrm{M}_{\odot}$ at
$\mathrm{z=0}$ using the cosmological magnetohydrodynamical TNG50 simulation.
Three different origins of stars comprise galactic centers: 1) in-situ (born in
the center), 2) migrated (born elsewhere in the galaxy and ultimately moved to
the center), 3) ex-situ (accreted from other galaxies). In-situ and migrated
stars dominate the central stellar mass budget on average with 73% and 23%
respectively. The ex-situ fraction rises above 1% for galaxies
$\gtrsim10^{11}\,\mathrm{M}_{\odot}$. Yet, only 9% of all galaxies exhibit no
ex-situ stars in their centers and the scatter of ex-situ mass is significant
($4-6\,\mathrm{dex}$). Migrated stars predominantly originate closely from the
center ($1-2\,\mathrm{kpc}$), but if they travelled together in clumps
distances reach $\sim10\,\mathrm{kpc}$. Central and satellite galaxies possess
similar amounts and origins of central stars. Star forming galaxies
($\gtrsim10^{10}\,\mathrm{M}_{\odot}$) have on average more ex-situ mass in
their centers than quenched ones. We predict readily observable stellar
population and dynamical properties: 1) migrated stars are distinctly young
($\sim2\,\mathrm{Gyr}$) and rotationally supported, especially for Milky Way
mass galaxies, 2) in-situ stars are most metal-rich and older than migrated
stars, 3) ex-situ stars are on random motion dominated orbits and typically the
oldest, most metal-poor and $\alpha$-enhanced population. We demonstrate that
the interaction history with other galaxies leads to diverse pathways of
building up galaxy centers in a $\Lambda$CDM universe. Our work highlights the
necessity for cosmological context in formation scenarios of central galactic
components and the potential to use galaxy centers as tracers of overall galaxy
assembly.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:01 GMT""}]","2023-01-31"
"2301.11943","Sourabh Paul","Sourabh Paul, Mario G. Santos, Zhaoting Chen, Laura Wolz","A first detection of neutral hydrogen intensity mapping on Mpc scales at
  $z\approx 0.32$ and $z\approx 0.44$","19 pages, 10 figures, submitted to ApJL",,,,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We report the first direct detection of the cosmological power spectrum using
the intensity signal from 21-cm emission of neutral hydrogen (HI), derived from
interferometric observations with the L-band receivers of the new MeerKAT radio
telescope. Intensity mapping is a promising technique to map the
three-dimensional matter distribution of the Universe at radio frequencies and
probe the underlying Cosmology. So far, detections have only been achieved
through cross-correlations with galaxy surveys. Here we present independent
measurements of the HI power spectrum at redshifts $0.32$ and $0.44$ with high
statistical significance using a foreground avoidance method (at $8.0\sigma$
and $11.5\sigma$ respectively). We constrain the rms of the fluctuations of the
HI distribution to be $\sigma_{\rm HI} = (0.44\pm 0.04)\,{\rm mK}$ and
$\sigma_{\rm HI} = (0.63\pm 0.03)\,{\rm mK}$ respectively at scales of 1.0 Mpc.
The information contained in the power spectrum measurements allows us to probe
the parameters of the HI mass function and HI halo model. These results are a
significant step towards precision cosmology with HI intensity mapping using
the new generation of radio telescopes.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:02 GMT""}]","2023-01-31"
"2301.11944","Antonios Alvertis","Antonios M. Alvertis, Jonah B. Haber, Edgar A. Engel, Sahar
  Sharifzadeh, Jeffrey B. Neaton","Phonon-induced localization of excitons in molecular crystals from first
  principles",,"Phys. Rev. Lett. 130, 086401 (2023)","10.1103/PhysRevLett.130.086401",,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  The spatial extent of excitons in molecular systems underpins their
photophysics and utility for optoelectronic applications. Phonons are reported
to lead to both exciton localization and delocalization. However, a microscopic
understanding of phonon-induced (de)localization is lacking, in particular how
localized states form, the role of specific vibrations, and the relative
importance of quantum and thermal nuclear fluctuations. Here we present a
first-principles study of these phenomena in solid pentacene, a prototypical
molecular crystal, capturing the formation of bound excitons, exciton-phonon
coupling to all orders, and phonon anharmonicity, using density functional
theory, the \emph{ab initio} $GW$-Bethe-Salpeter equation approach, finite
difference, and path integral techniques. We find that for pentacene zero-point
nuclear motion causes uniformly strong localization, with thermal motion
providing additional localization only for Wannier-Mott-like excitons.
Anharmonic effects drive temperature-dependent localization, and while such
effects prevent the emergence of highly delocalized excitons, we explore the
conditions under which these might be realized.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:05 GMT""}]","2023-02-27"
"2301.11945","Shivani Shah","Shivani P. Shah, Rana Ezzeddine, Alexander P. Ji, Terese Hansen, Ian
  U. Roederer, M\'arcio Catelan, Zoe Hackshaw, Erika M. Holmbeck, Timothy C.
  Beers, and Rebecca Surman","Uranium Abundances and Ages of $R$-process Enhanced Stars with Novel U
  II Lines","Resubmitted to ApJ",,"10.3847/1538-4357/acb8af",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The ages of the oldest stars shed light on the birth, chemical enrichment,
and chemical evolution of the Universe. Nucleocosmochronometry provides an
avenue to determining the ages of these stars independent from stellar
evolution models. The uranium abundance, which can be determined for metal-poor
$r$-process enhanced (RPE) stars, has been known to constitute one of the most
robust chronometers known. So far, U abundance determination has used a
$single$ U II line at $\lambda3859$ \r{A}. Consequently, U abundance has been
reliably determined for only five RPE stars. Here, we present the first
homogeneous U abundance analysis of four RPE stars using two novel U II lines
at $\lambda4050$ \r{A} and $\lambda4090$ \r{A}, in addition to the canonical
$\lambda3859$ \r{A} line. We find that the U II lines at $\lambda4050$ \r{A}
and $\lambda4090$ \r{A} are reliable and render U abundances in agreement with
the $\lambda3859$ U abundance, for all the stars. We, thus, determine revised U
abundances for RPE stars, 2MASS J09544277+5246414, RAVE J203843.2-002333, HE
1523-0901, and CS 31082-001, using multiple U II lines. We also provide
nucleocosmochronometric ages of these stars based on the newly derived U, Th,
and Eu abundances. The results of this study open up a new avenue to reliably
and homogeneously determine U abundance for a significantly larger number of
RPE stars. This will, in turn, enable robust constraints on the
nucleocosmochronometric ages of RPE stars, which can be applied to understand
the chemical enrichment and evolution in the early Universe, especially of
$r$-process elements.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:07 GMT""}]","2023-05-24"
"2301.11946","Anirudh Gundhi","Anirudh Gundhi and Angelo Bassi","Motion of an electron through vacuum fluctuations","published in PRA, typos corrected, presentation improved","Phys. Rev. A, 107, 2023, 062801","10.1103/PhysRevA.107.062801",,"quant-ph gr-qc hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the effects of the electromagnetic vacuum on the motion of a
nonrelativistic electron. First, we derive the equation of motion for the
expectation value of the electron's position operator. We show how this
equation has the same form as the classical Abraham-Lorentz equation but, at
the same time, is free of the well known runaway solution. Second, we study
decoherence induced by vacuum fluctuations. We show that decoherence due to
vacuum fluctuations that appears at the level of the reduced density matrix of
the electron, obtained after tracing over the radiation field, does not
correspond to actual irreversible loss of coherence.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:07 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 16:32:02 GMT""}]","2023-06-02"
"2301.11947","Mattia Sensi","Nicol\`o Cangiotti, Marco Capolli, Mattia Sensi, Sara Sottile","A survey on Lyapunov functions for epidemic compartmental models","18 pages, 4 figures","Bollettino dell'Unione Matematica Italiana (2023)","10.1007/s40574-023-00368-6",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this survey, we propose an overview on Lyapunov functions for a variety of
compartmental models in epidemiology. We exhibit the most widely employed
functions, together with a commentary on their use. Our aim is to provide a
comprehensive starting point to readers who are attempting to prove global
stability of systems of ODEs. The focus is on mathematical epidemiology,
however some of the functions and strategies presented in this paper can be
adapted to a wider variety of models, such as prey-predator or rumor spreading.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:12 GMT""},{""version"":""v2"",""created"":""Sun, 12 Feb 2023 10:59:28 GMT""}]","2023-06-09"
"2301.11948","Subhankar Khatua","Subhankar Khatua, Michel J. P. Gingras, Jeffrey G. Rau","Pseudo-Goldstone modes and dynamical gap generation from
  order-by-thermal-disorder","Main text: 7 pages and 3 figures. Supplemental material: 8 pages and
  3 figures",,,,"cond-mat.str-el cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accidental ground state degeneracies -- those not a consequence of global
symmetries of the Hamiltonian -- are inevitably lifted by fluctuations, often
leading to long-range order, a phenomenon known as ""order-by-disorder"" (ObD).
The detection and characterization of ObD in real materials currently lacks
clear, qualitative signatures that distinguish ObD from conventional energetic
selection. We show that for order-by-thermal-disorder (ObTD) such a signature
exists: a characteristic temperature dependence of the fluctuation-induced
pseudo-Goldstone gap. We demonstrate this in a minimal two-dimensional model
that exhibits ObTD, the ferromagnetic Heisenberg-compass model on a square
lattice. Using spin-dynamics simulations and self-consistent mean-field
calculations, we determine the pseudo-Goldstone gap, $\Delta $, and show that
at low temperatures it scales as the square root of temperature, $\sqrt{T} $.
We establish that a power-law temperature dependence of the gap is a general
consequence of ObTD, showing that all key features of this physics can be
captured in a simple model of a particle moving in an effective potential
generated by the fluctuation-induced free energy.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:00:55 GMT""}]","2023-01-31"
"2301.11949","Daniel Gamelin","Kimo Pressler, Thom J. Snoeren, Kelly M. Walsh, Daniel R. Gamelin","Magnetic Amplification at Yb3+ ""Designer Defects"" in the van der Waals
  Ferromagnet, CrI3","submitted to Nano Letters",,"10.1021/acs.nanolett.2c04533",,"cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The two-dimensional (2D) van der Waals ferromagnet CrI3 has been doped with
the magnetic optical impurity Yb3+ to yield materials that display sharp
multi-line Yb3+ photoluminescence (PL) controlled by the magnetism of CrI3.
Magneto-PL shows that Yb3+ magnetization is pinned to the magnetization of
CrI3. An effective internal field of ~10 T at Yb3+ is estimated, attributed to
strong in-plane Yb3+-Cr3+ superexchange coupling. The anomalously low energy of
Yb3+ PL in CrI3 reflects relatively high Yb3+-I- covalency, contributing to
Yb3+-Cr3+ superexchange coupling. The Yb3+ PL energy and linewidth both reveal
the effects of spontaneous zero-field CrI3 magnetic ordering within 2D layers
below TC, despite the absence of net magnetization in multilayer samples. These
results illustrate the use of optical impurities as ""designer defects"" to
introduce unique functionality to 2D magnets.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:02:26 GMT""}]","2023-04-26"
"2301.11950","Reed Hodges","Lin Dai, Sean Fleming, Reed Hodges, Thomas Mehen","Strong decays of $T_{cc}^+$ at NLO in an effective field theory","26 pages, 7 figures","Phys. Rev. D 107, 076001 (2023)","10.1103/PhysRevD.107.076001",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The $T_{cc}^+$ exotic meson, discovered by the LHCb Collaboration in 2021,
can be interpreted as a molecular state of $D^{(*)0}$ and $D^{(*)+}$ mesons. We
compute next-to-leading-order (NLO) contributions to the strong decay of
$T_{cc}^+$ in an effective field theory for $D$ mesons and pions, considering
contributions from one-pion exchange and final-state rescattering. Corrections
to the total width, as well as the differential distribution in the invariant
mass of the final-state $D$ meson pair are computed. The results remain in good
agreement with LHCb experimental results when the NLO contributions are added.
The leading uncertainties in the calculation come from terms which depend on
the scattering length and effective range in $D$ meson scattering.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:02:49 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 15:30:19 GMT""}]","2023-04-04"
"2301.11951","Alexander Moskvin","A.S. Moskvin and Yu.D. Panov","Topological structures in unconventional scenario for 2D cuprates","25 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:1409.5064","J Supercond Nov Magn (2019) 32, 61","10.1007/s10948-018-4896-0",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We introduce a minimal model to describe the charge degree of freedom in
cuprates with the on-site Hilbert space reduced to only the three valence
states CuO$_4^{7-,6-,5-}$ (nominally Cu$^{1+,2+,3+}$) and make use of the S=1
pseudospin formalism. The formalism constitutes a powerful method to study
complex phenomena in interacting quantum systems characterized by the
coexistence and competition of various ordered states. Overall, such a
framework provides a simple and systematic methodology to predict and discover
new kinds of orders. In particular, the pseudospin formalism provides the most
effective way to describe different topological structures, in particular, due
to a possibility of a geometrical two-vector description of the on-site states.
We introduce and analyze effective pseudospin Hamiltonian with on-site and
inter-site charge correlations, two types of a correlated one-particle transfer
and two-particle, or the composite boson transfer. The 2D S=1 pseudospin system
is prone to a creation of different topological structures, which form
topologically protected inhomogeneous distributions of the eight local S=1
pseudospin order parameters. We present a short overview of localized
topological structures, typical for S=1 (pseudo)spin systems, focusing on
unexpected antiphase domain walls in parent cuprates and so-called quadrupole
skyrmion, which are believed to be candidates for a topological charge
excitation in parent or underdoped cuprates. Puzzlingly, these unconventional
structures can be characterized by an uniform distribution of the mean on-site
charge, that makes these invisible for X-rays. Quasiclassical approximation and
computer simulation are applied to analyze localized topological defects and
evolution of the domain structures in ""negative-$U$"" model under charge
order-superfluid phase transition.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:05:19 GMT""}]","2023-01-31"
"2301.11952","Roman Chertovskih","Roman Chertovskih, Nikolay Pogodaev, Maxim Staritsyn, Joaquim Da Silva
  Sewane, Antonio Pedro Aguiar","Optimization of external stimuli for populations of theta neurons via
  mean-field feedback control",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a problem of designing ``robust'' external excitations for control
and synchronization of an assembly of homotypic harmonic oscillators
representing so-called theta neurons. The model of theta neurons (Theta model)
captures, in main, the bursting behavior of spiking cells in the brain of
biological beings, enduring periodic oscillations of the electric potential in
their membrane.
  We study the following optimization problem: to design an external stimulus
(control), which steers all neurons of a given population to their desired
phases (i.e., excites/slows down its spiking activity) with the highest
probability.
  This task is formulated as an optimal mean-field control problem for the
local continuity equation in the space of probability measures. To solve this
problem numerically, we propose an indirect deterministic descent method based
on an exact representation of the increment (infinite-order variation) of the
objective functional. We discuss some aspects of practical realization of the
proposed method, and provide results of numerical experiments.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:08:10 GMT""}]","2023-01-31"
"2301.11953","Cinzia Casagrande","Cinzia Casagrande","Fano 4-folds with $b_2>12$ are products of surfaces","13 pages, one figure",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Let X be a smooth, complex Fano 4-fold, and rho(X) its Picard number. We show
that if rho(X)>12, then X is a product of del Pezzo surfaces. The proof relies
on a careful study of divisorial elementary contractions f: X->Y such that the
image S of the exceptional divisor is a surface, together with the author's
previous work on Fano 4-folds. In particular, given f: X->Y as above, under
suitable assumptions we show that S is a smooth del Pezzo surface with -K_S
given by the restriction of -K_Y.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:12:30 GMT""}]","2023-01-31"
"2301.11954","Felipe Faria","F. F. Faria","Early universe nucleosynthesis in massive conformal gravity","17 pages, no figures, matches the published version","Eur. Phys. J. C 83, 81 (2023)","10.1140/epjc/s10052-023-11204-8",,"physics.gen-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamics of the early universe in massive conformal gravity. In
particular, we show that the theory is consistent with the observed values of
the primordial abundances of light elements if we consider the existence of
right-handed sterile neutrinos.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:12:40 GMT""}]","2023-02-15"
"2301.11955","Lyndon Duong","Lyndon R. Duong, David Lipshutz, David J. Heeger, Dmitri B.
  Chklovskii, Eero P. Simoncelli","Adaptive whitening in neural populations with gain-modulating
  interneurons","20 pages, 10 figures (incl. appendix). To appear in the Proceedings
  of the 40th International Conference on Machine Learning",,,,"q-bio.NC cs.LG eess.SP","http://creativecommons.org/licenses/by/4.0/","  Statistical whitening transformations play a fundamental role in many
computational systems, and may also play an important role in biological
sensory systems. Existing neural circuit models of adaptive whitening operate
by modifying synaptic interactions; however, such modifications would seem both
too slow and insufficiently reversible. Motivated by the extensive neuroscience
literature on gain modulation, we propose an alternative model that adaptively
whitens its responses by modulating the gains of individual neurons. Starting
from a novel whitening objective, we derive an online algorithm that whitens
its outputs by adjusting the marginal variances of an overcomplete set of
projections. We map the algorithm onto a recurrent neural network with fixed
synaptic weights and gain-modulating interneurons. We demonstrate numerically
that sign-constraining the gains improves robustness of the network to
ill-conditioned inputs, and a generalization of the circuit achieves a form of
local whitening in convolutional populations, such as those found throughout
the visual or auditory systems.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:13:41 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jun 2023 07:51:34 GMT""}]","2023-06-06"
"2301.11956","Truong Son Hy","Chen Cai, Truong Son Hy, Rose Yu, Yusu Wang","On the Connection Between MPNN and Graph Transformer",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Graph Transformer (GT) recently has emerged as a new paradigm of graph
learning algorithms, outperforming the previously popular Message Passing
Neural Network (MPNN) on multiple benchmarks. Previous work (Kim et al., 2022)
shows that with proper position embedding, GT can approximate MPNN arbitrarily
well, implying that GT is at least as powerful as MPNN. In this paper, we study
the inverse connection and show that MPNN with virtual node (VN), a commonly
used heuristic with little theoretical understanding, is powerful enough to
arbitrarily approximate the self-attention layer of GT.
  In particular, we first show that if we consider one type of linear
transformer, the so-called Performer/Linear Transformer (Choromanski et al.,
2020; Katharopoulos et al., 2020), then MPNN + VN with only O(1) depth and O(1)
width can approximate a self-attention layer in Performer/Linear Transformer.
Next, via a connection between MPNN + VN and DeepSets, we prove the MPNN + VN
with O(n^d) width and O(1) depth can approximate the self-attention layer
arbitrarily well, where d is the input feature dimension. Lastly, under some
assumptions, we provide an explicit construction of MPNN + VN with O(1) width
and O(n) depth approximating the self-attention layer in GT arbitrarily well.
On the empirical side, we demonstrate that 1) MPNN + VN is a surprisingly
strong baseline, outperforming GT on the recently proposed Long Range Graph
Benchmark (LRGB) dataset, 2) our MPNN + VN improves over early implementation
on a wide range of OGB datasets and 3) MPNN + VN outperforms Linear Transformer
and MPNN on the climate modeling task.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:15:31 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 20:10:28 GMT""}]","2023-02-07"
"2301.11957","Marco Castellani","Marco Castellani and Massimiliano Giuli","A continuity result for the adjusted normal cone operator",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The concept of adjusted sublevel set for a quasiconvex function was
introduced in \cite{AuHa05} and the local existence of a norm-to-weak$^*$ upper
semicontinuous base-valued submap of the normal operator associated to the
adjusted sublevel set was proved. When the space is finite dimensional, a
globally defined upper semicontinuous base-valued submap is obtained taking the
intersection of the unit sphere, which is compact, with the normal operator,
which is closed. Unfortunately, this technique does not work in the infinite
dimensional case. We propose a partition of unity technique to overcome this
problem in Banach spaces. Application is given to a quasiconvex
quasioptimization problem through the use of a new existence result for
generalized quasivariational inequalities which is based on the Schauder fixed
point theorem.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:18:28 GMT""}]","2023-01-31"
"2301.11958","Jinghui Cheng","Mitra Lashkari, Jinghui Cheng","""Finding the Magic Sauce"": Exploring Perspectives of Recruiters and Job
  Seekers on Recruitment Bias and Automated Tools","16 pages, 1 figure, CHI 2023",,"10.1145/3544548.3581548",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated recruitment tools are proliferating. While having the promise of
improving efficiency, various risks, including bias, challenges the potential
of these tools. An in-depth understanding of the perceived risk factors and
needs from the perspective of both recruiters and job seekers is needed. We
address this through an interview study in the high-tech industry to compare
and contrast the concerns of these two roles. We found that the importance of
clarifying position requirements and assessing candidates as ""whole
individuals"" are commonly discussed by both recruiters and job seekers. In
contrast, while recruiters tended to be more aware of cognitive bias and
desired more tool support during interviews, job seekers voiced more desire
towards a healthy candidate-company relationship. Additionally, both roles
considered the uncertainty of the current technology capability and reduced
human contact as concerns for using automated tools. Based on these results, we
provided design implications for automated recruitment tools and related
decision-support technologies.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:27:08 GMT""}]","2023-01-31"
"2301.11959","Wilhelm Stannat","Wilhelm Stannat, Alexander Vogler","Approximation of Optimal Feedback Controls for Stochastic
  Reaction-Diffusion Equations",,,,,"math.OC math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We approximate optimal feedback controls for stochastic reaction-diffusion
equations by using a general type of approximation that allows us to reduce the
control problem to an optimization over deterministic controls. Similar to
([Stannat, Wessels], Deterministic Control of stochastic reaction-diffusion
equations, Evolution Equations & Control Theory (2020)) we derive necessary
optimality conditions and prove the existence of an optimal control for the
reduced problem. Furthermore we derive explicit convergence rates and
numerically investigate a gradient descent algorithm for the approximation of
the optimal feedback control using a radial basis approximation as a particular
example.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:27:36 GMT""}]","2023-01-31"
"2301.11960","Timothy Heckman","Timothy M. Heckman and Philip N. Best","A Global Inventory of Feedback",,"Galaxies 2023, 11, 21","10.3390/galaxies11010021",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Feedback from both supermassive black holes and massive stars plays a
fundamental role in the evolution of galaxies and the inter-galactic medium. In
this paper we use available data to estimate the total amount of kinetic energy
and momentum created per co-moving volume element over the history of the
universe from three sources: massive stars and supernovae, radiation pressure
and winds driven by supermassive black holes, and radio jets driven by
supermassive black holes. Kinetic energy and momentum injection from jets peaks
at z ~ 1, while the other two sources peak at z ~ 2. Massive stars are the
dominant global source of momentum injection. For supermassive black holes, we
find that the amount of kinetic energy from jets is about an order-of-magnitude
larger than that from winds. We also find that amount of kinetic energy created
by massive stars is about 2.5 epsilon times that carried by jets (where epsilon
is the fraction of injected energy not lost to radiative cooling). We discuss
the implications of these results for the evolution of galaxies and the IGM.
Because the ratio of black hole mass to galaxy mass is a steeply increasing
function of mass, we show that the relative importance of black hole feedback
to stellar feedback likewise increases with mass. We show that there is a trend
in the present-day universe which, in the simplest picture, is consistent with
galaxies that have been dominated by black hole feedback being generally
quenched, while galaxies that have been dominated by stellar feedback are
star-forming. We also note that the amount of kinetic energy carried by jets
and winds appears sufficient to explain the properties of hot gas in massive
halos (> 10^13 solar masses).
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:29:51 GMT""}]","2023-01-31"
"2301.11961","Yuming Chen","Yuming Chen, Daniel Sanz-Alonso, Rebecca Willett","Reduced-Order Autodifferentiable Ensemble Kalman Filters",,,,,"stat.ML cs.LG math.DS stat.CO","http://creativecommons.org/licenses/by/4.0/","  This paper introduces a computational framework to reconstruct and forecast a
partially observed state that evolves according to an unknown or
expensive-to-simulate dynamical system. Our reduced-order autodifferentiable
ensemble Kalman filters (ROAD-EnKFs) learn a latent low-dimensional surrogate
model for the dynamics and a decoder that maps from the latent space to the
state space. The learned dynamics and decoder are then used within an ensemble
Kalman filter to reconstruct and forecast the state. Numerical experiments show
that if the state dynamics exhibit a hidden low-dimensional structure,
ROAD-EnKFs achieve higher accuracy at lower computational cost compared to
existing methods. If such structure is not expressed in the latent state
dynamics, ROAD-EnKFs achieve similar accuracy at lower cost, making them a
promising approach for surrogate state reconstruction and forecasting.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:32:02 GMT""}]","2023-01-31"
"2301.11962","Raghav Singhal","Raghav Singhal, Mukund Sudarshan, Anish Mahishi, Sri Kaushik, Luke
  Ginocchio, Angela Tong, Hersh Chandarana, Daniel K. Sodickson, Rajesh
  Ranganath, and Sumit Chopra","On the Feasibility of Machine Learning Augmented Magnetic Resonance for
  Point-of-Care Identification of Disease",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Early detection of many life-threatening diseases (e.g., prostate and breast
cancer) within at-risk population can improve clinical outcomes and reduce cost
of care. While numerous disease-specific ""screening"" tests that are closer to
Point-of-Care (POC) are in use for this task, their low specificity results in
unnecessary biopsies, leading to avoidable patient trauma and wasteful
healthcare spending. On the other hand, despite the high accuracy of Magnetic
Resonance (MR) imaging in disease diagnosis, it is not used as a POC disease
identification tool because of poor accessibility. The root cause of poor
accessibility of MR stems from the requirement to reconstruct high-fidelity
images, as it necessitates a lengthy and complex process of acquiring large
quantities of high-quality k-space measurements. In this study we explore the
feasibility of an ML-augmented MR pipeline that directly infers the disease
sidestepping the image reconstruction process. We hypothesise that the disease
classification task can be solved using a very small tailored subset of k-space
data, compared to image reconstruction. Towards that end, we propose a method
that performs two tasks: 1) identifies a subset of the k-space that maximizes
disease identification accuracy, and 2) infers the disease directly using the
identified k-space subset, bypassing the image reconstruction step. We validate
our hypothesis by measuring the performance of the proposed system across
multiple diseases and anatomies. We show that comparable performance to
image-based classifiers, trained on images reconstructed with full k-space
data, can be achieved using small quantities of data: 8% of the data for
detecting multiple abnormalities in prostate and brain scans, and 5% of the
data for knee abnormalities. To better understand the proposed approach and
instigate future research, we provide an extensive analysis and release code.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:32:27 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 18:21:48 GMT""}]","2023-02-03"
"2301.11963","Edvard Musaev","Sameer Kumar and Edvard T. Musaev","On 10 dimensional Exceptional Drinfel'd Algebras",,,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the Mubarakzyanov's classification of four-dimensional real Lie
Algebras, we classify ten-dimensional Exceptional Drinfel'd Algebras (EDA). The
classification is restricted to EDAs whose maximal isotropic (geometric)
subalgebras cannot be represented as a product of a 3D Lie algebra and a 1D
abelian factor. We show that all obtained EDAs are inequivalent and conclude
that there are no Nambu-Lie U-dualities between 11D supergravity backgrounds
within 10D EDAs.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:34:36 GMT""}]","2023-01-31"
"2301.11964","Ken St. Germain","Ken St. Germain, Josh Angichiodo","Adversarial Networks and Machine Learning for File Classification",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Correctly identifying the type of file under examination is a critical part
of a forensic investigation. The file type alone suggests the embedded content,
such as a picture, video, manuscript, spreadsheet, etc. In cases where a system
owner might desire to keep their files inaccessible or file type concealed, we
propose using an adversarially-trained machine learning neural network to
determine a file's true type even if the extension or file header is obfuscated
to complicate its discovery. Our semi-supervised generative adversarial network
(SGAN) achieved 97.6% accuracy in classifying files across 11 different types.
We also compared our network against a traditional standalone neural network
and three other machine learning algorithms. The adversarially-trained network
proved to be the most precise file classifier especially in scenarios with few
supervised samples available. Our implementation of a file classifier using an
SGAN is implemented on GitHub (https://ksaintg.github.io/SGAN-File-Classier).
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:40:03 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 13:14:11 GMT""}]","2023-02-03"
"2301.11965","Zachary Boyd","Zachary M. Boyd, Nick Callor, Taylor Gledhill, Abigail Jenkins, Robert
  Snellman, Benjamin Z. Webb, Raelynn Wonnacott","The persistent homology of genealogical networks",,"Applied Network Science, 2023",,,"q-bio.MN cs.DM physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Genealogical networks (i.e. family trees) are of growing interest, with the
largest known data sets now including well over one billion individuals.
Interest in family history also supports an 8.5 billion dollar industry whose
size is projected to double within 7 years (FutureWise report HC1137). Yet
little mathematical attention has been paid to the complex network properties
of genealogical networks, especially at large scales.
  The structure of genealogical networks is of particular interest due to the
practice of forming unions, e.g. marriages, that are typically well outside
one's immediate family. In most other networks, including other social
networks, no equivalent restriction exists on the distance at which
relationships form. To study the effect this has on genealogical networks we
use persistent homology to identify and compare the structure of 101
genealogical and 31 other social networks. Specifically, we introduce the
notion of a network's persistence curve, which encodes the network's set of
persistence intervals. We find that the persistence curves of genealogical
networks have a distinct structure when compared to other social networks. This
difference in structure also extends to subnetworks of genealogical and social
networks suggesting that, even with incomplete data, persistent homology can be
used to meaningfully analyze genealogical networks. Here we also describe how
concepts from genealogical networks, such as common ancestor cycles, are
represented using persistent homology. We expect that persistent homology tools
will become increasingly important in genealogical exploration as popular
interest in ancestry research continues to expand.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:42:58 GMT""}]","2023-01-31"
"2301.11966","Jos\'e Alexandre Nogueira","K. C. Lemos Filho, B. B. Dilem, J. C. Fabris and J. A. Nogueira","Generalized Uncertainty Principle for Entangled States of Two Identical
  Particles","15 pages",,,,"quant-ph gr-qc hep-th","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work we determine the consequences of the quantum entanglement of a
system of two identical particles when the generalized uncertainty principle
(GUP) is considered. GUP is usually associated with the existence of a minimal
length. We focus on the main formulations of the GUP and then we determine the
minimal uncertainties in position induced by those modified GUP's. Our results
point out that the minimal uncertainty is reduced by half of its usual value
independently of the GUP employed. This implies that the minimal length is also
reduced by half. On the other hand, it is generally expected that the minimal
length must not depend on physical system. We overcome this apparent paradox by
realizing that the entangled system is composed by two particles so that an
effective parameter related to the minimal length must be employed.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:46:27 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 20:10:14 GMT""}]","2023-02-07"
"2301.11967","SatyaJaswanth Badri","SatyaJaswanth Badri, Mukesh Saini, and Neeraj Goel","Mapi-Pro: An Energy Efficient Memory Mapping Technique for Intermittent
  Computing",,,,,"cs.AR","http://creativecommons.org/licenses/by-sa/4.0/","  Battery-less technology evolved to replace battery usage in space, deep
mines, and other environments to reduce cost and pollution. Non-volatile memory
(NVM) based processors were explored for saving the system state during a power
failure. Such devices have a small SRAM and large non-volatile memory. To make
the system energy efficient, we need to use SRAM efficiently. So we must select
some portions of the application and map them to either SRAM or FRAM. This
paper proposes an ILP-based memory mapping technique for Intermittently powered
IoT devices. Our proposed technique gives an optimal mapping choice that
reduces the system's Energy-Delay Product (EDP). We validated our system using
a TI-based MSP430FR6989 and MSP430F5529 development boards. Our proposed memory
configuration consumes 38.10% less EDP than the baseline configuration and
9.30% less EDP than the existing work under stable power. Our proposed
configuration achieves 15.97% less EDP than the baseline configuration and
21.99% less EDP than the existing work under unstable power. This work supports
intermittent computing and works efficiently during frequent power failures.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:46:40 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 06:01:23 GMT""}]","2023-05-18"
"2301.11968","Saeed Noori Gashti","Jafar Sadeghi, Mohammad Reza Alipour, Saeed Noori Gashti","Strong Cosmic Censorship in light of Weak Gravity Conjecture for Charged
  Black Holes","15 pages, Accepted version for publishing in the Journal of High
  Energy Physics","JHEP02(2023)236","10.1007/JHEP02(2023)236",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the strong cosmic censorship conjecture (SCC)
for charged black holes in the de Sitter space by considering the weak gravity
conjecture (WGC). Using analytical methods, we find that the SCC is preserved
for dS-charged black holes with respect to some restriction $qQ\gg1$ and
$r_+\geq Q$ with the help of the WGC condition viz $\frac{q}{m}\geq 1$ for
scalar fields. Where q, m are the charge and mass of the scalar field, and
$r_+$, Q determine the radius of the outer event horizon and the charge of the
black hole, respectively. In that case, when the (WGC) is valid, SCC will
definitely be satisfied for the dS-charged black holes. On the other hand, the
SCC is violated when the WGC is not satisfied. Also, we examined the RN-dS
charged black hole in the extremality state and found that SCC can be violated
with the condition $\Lambda r_+^2=1$.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:46:46 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 17:33:32 GMT""}]","2023-02-28"
"2301.11969","Stanislaw Kurdzialek","Jerzy Szuniewicz, Stanislaw Kurdzialek, Sanjukta Kundu, Wojciech
  Zwolinski, Rados{\l}aw Chrapkiewicz, Mayukh Lahiri, Radek Lapkiewicz","Noise Resistant Phase Imaging with Intensity Correlation",,,,,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Interferometric methods, renowned for their reliability and precision, play a
vital role in phase imaging. Interferometry typically requires high coherence
and stability between the measured and the reference beam. The presence of
rapid phase fluctuations averages out the interferogram, erasing the spatial
phase information. This difficulty can be circumvented by shortening the
measurement time. However, shortening the measurement time results in smaller
photon counting rates precluding its applicability to low-intensity phase
imaging. We introduce and experimentally demonstrate a phase imaging technique
that is immune to position-independent, time-dependent phase fluctuation. We
accomplish this by measuring intensity correlation instead of intensity. Our
method enables using long measurement times and is therefore advantageous when
the photon flux is very low. We use a Fisher information-based approach to show
that the precision of phase reconstruction achieved using our method is in fact
the best achievable precision in the scenario when two photons are detected per
phase stability time.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:56:26 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 10:54:41 GMT""}]","2023-02-06"
"2301.11970","Mark Keane","Saugat Aryal and Mark T Keane","Even if Explanations: Prior Work, Desiderata & Benchmarks for
  Semi-Factual XAI","14 pages, 4 Figures","32nd International Joint Conference on Artificial Intelligence
  (IJCAI-23), China, Macao, 2023",,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recently, eXplainable AI (XAI) research has focused on counterfactual
explanations as post-hoc justifications for AI-system decisions (e.g. a
customer refused a loan might be told: If you asked for a loan with a shorter
term, it would have been approved). Counterfactuals explain what changes to the
input-features of an AI system change the output-decision. However, there is a
sub-type of counterfactual, semi-factuals, that have received less attention in
AI (though the Cognitive Sciences have studied them extensively). This paper
surveys these literatures to summarise historical and recent breakthroughs in
this area. It defines key desiderata for semi-factual XAI and reports benchmark
tests of historical algorithms (along with a novel, naieve method) to provide a
solid basis for future algorithmic developments.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 19:58:12 GMT""},{""version"":""v2"",""created"":""Mon, 8 May 2023 18:06:32 GMT""}]","2023-05-10"
"2301.11971","Po-Hsuan Lin","Meng-Jhang Fong, Po-Hsuan Lin, Thomas R. Palfrey","Cursed Sequential Equilibrium","61 pages with 7 figures and 4 tables",,,,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper develops a framework to extend the strategic form analysis of
cursed equilibrium (CE) developed by Eyster and Rabin (2005) to multi-stage
games. The approach uses behavioral strategies rather than normal form mixed
strategies, and imposes sequential rationality. We define cursed sequential
equilibrium (CSE) and compare it to sequential equilibrium and standard
normal-form CE. We provide a general characterization of CSE and establish its
properties. We apply CSE to five applications in economics and political
science. These applications illustrate a wide range of differences between CSE
and Bayesian Nash equilibrium or CE: in signaling games; games with preplay
communication; reputation building; sequential voting; and the dirty faces game
where higher order beliefs play a key role. A common theme in several of these
applications is showing how and why CSE implies systematically different
behavior than Bayesian Nash equilibrium in dynamic games of incomplete
information with private values, while CE coincides with Bayesian Nash
equilibrium for such games.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:08:19 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 21:57:43 GMT""}]","2023-04-13"
"2301.11972","Alexandra Bremers","Alexandra Bremers, Alexandria Pabst, Maria Teresa Parreira, Wendy Ju","Using Social Cues to Recognize Task Failures for HRI: A Review of
  Current Research and Future Directions","29 pages, 5 figures",,,,"cs.RO cs.HC","http://creativecommons.org/licenses/by/4.0/","  Robots that carry out tasks and interact in complex environments will
inevitably commit errors. Error detection is thus an important ability for
robots to master, to work in an efficient and productive way. People leverage
social cues from others around them to recognize and repair their own mistakes.
With advances in computing and AI, it is increasingly possible for robots to
achieve a similar error detection capability. In this work, we review current
literature around the topic of how social cues can be used to recognize task
failures for human-robot interaction (HRI). This literature review unites
insights from behavioral science, human-robot interaction, and machine
learning, to focus on three areas: 1) social cues for error detection (from
behavioral science), 2) recognizing task failures in robots (from HRI), and 3)
approaches for autonomous detection of HRI task failures based on social cues
(from machine learning). We propose a taxonomy of error detection based on
self-awareness and social feedback. Finally, we leave recommendations for HRI
researchers and practitioners interested in developing robots that detect
(physical) task errors using social cues from bystanders.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:08:36 GMT""}]","2023-01-31"
"2301.11973","Roman Shakhovoy","Roman Shakhovoy, Elizaveta Maksimova","Gain-switched vcsel as a quantum entropy source: the problem of quantum
  and classical noise",,"St. Petersburg State Polytechnical University Journal. Physics and
  Mathematics. 15 (3.2), 201-205, 2022","10.18721/JPM.153.237",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of quantum noise extraction from polarization
swapping in a gain-switched VCSEL. The principle of operation of a quantum
random number generator is based on the generation of laser pulses with one of
two orthogonal polarization states, followed by digitization of
polarization-resolved pulses with a comparator. At intensity values of laser
pulses close to the threshold value of the comparator, the contribution of the
classical noise of the photodetector will have a crucial role in making a
decision on the choice of a logical zero or one. We show how to evaluate the
contribution of classical noise and how to calculate the quantum reduction
factor required for post-processing.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:09:00 GMT""}]","2023-01-31"
"2301.11974","Michael Stiglmayr","Julius Bau{\ss} and Michael Stiglmayr","Augmenting Bi-objective Branch and Bound by Scalarization-Based
  Information",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While Branch and Bound based algorithms are a standard approach to solve
single-objective (mixed-)integer optimization problems, multi-objective Branch
and Bound methods are only rarely applied compared to the predominant objective
space methods. In this paper we propose modifications to increase the
performance of multi-objective Branch and Bound algorithms by utilizing
scalarization-based information. We use the hypervolume indicator as a measure
for the gap between lower and upper bound set to implement a multi-objective
best-first strategy. By adaptively solving scalarizations in the root node to
integer optimality we improve both, upper and lower bound set. The obtained
lower bound can then be integrated into the lower bounds of all active nodes,
while the determined solution is added to the upper bound set. Numerical
experiments show that the number of investigated nodes can be significantly
reduced by up to 83% and the total computation time can be reduced by up to
80%.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:17:49 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 14:00:08 GMT""}]","2023-06-08"
"2301.11975","Nathan Fradet","Nathan Fradet, Jean-Pierre Briot, Fabien Chhel, Amal El Fallah
  Seghrouchni, Nicolas Gutowski","Byte Pair Encoding for Symbolic Music","Source code at https://github.com/Natooz/BPE-Symbolic-Music",,,,"cs.LG cs.AI cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  The symbolic music modality is nowadays mostly represented as discrete and
used with sequential models such as Transformers, for deep learning tasks.
Recent research put efforts on the tokenization, i.e. the conversion of data
into sequences of integers intelligible to such models. This can be achieved by
many ways as music can be composed of simultaneous tracks, of simultaneous
notes with several attributes. Until now, the proposed tokenizations are based
on small vocabularies describing the note attributes and time events, resulting
in fairly long token sequences. In this paper, we show how Byte Pair Encoding
(BPE) can improve the results of deep learning models while improving its
performances. We experiment on music generation and composer classification,
and study the impact of BPE on how models learn the embeddings, and show that
it can help to increase their isotropy, i.e., the uniformity of the variance of
their positions in the space.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:22:18 GMT""}]","2023-01-31"
"2301.11976","Philip Dawid","A. Philip Dawid and Stephen Senn","Personalised Decision-Making without Counterfactuals","15 pages. Submitted to Journal of Causal Inference",,,,"stat.ME math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  This article is a response to recent proposals by Pearl and others for a new
approach to personalised treatment decisions, in contrast to the traditional
one based on statistical decision theory. We argue that this approach is
dangerously misguided and should not be used in practice.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:26:03 GMT""}]","2023-01-31"
"2301.11977","Md. Rafat Rahman Tushar","Md. Rafat Rahman Tushar and Shahnewaz Siddique","A Memory Efficient Deep Reinforcement Learning Approach For Snake Game
  Autonomous Agents","AICT 2022","2022 IEEE 16th International Conference on Application of
  Information and Communication Technologies (AICT), 2022, pp. 1-6","10.1109/AICT55583.2022.10013603",,"cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To perform well, Deep Reinforcement Learning (DRL) methods require
significant memory resources and computational time. Also, sometimes these
systems need additional environment information to achieve a good reward.
However, it is more important for many applications and devices to reduce
memory usage and computational times than to achieve the maximum reward. This
paper presents a modified DRL method that performs reasonably well with
compressed imagery data without requiring additional environment information
and also uses less memory and time. We have designed a lightweight
Convolutional Neural Network (CNN) with a variant of the Q-network that
efficiently takes preprocessed image data as input and uses less memory.
Furthermore, we use a simple reward mechanism and small experience replay
memory so as to provide only the minimum necessary information. Our modified
DRL method enables our autonomous agent to play Snake, a classical control
game. The results show our model can achieve similar performance as other DRL
methods.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:26:48 GMT""}]","2023-01-31"
"2301.11978","Jaime Ruiz Zapatero","Jaime Ruiz-Zapatero, Boryana Hadzhiyska, David Alonso, Pedro G.
  Ferreira, Carlos Garc\'ia-Garc\'ia and Arrykrishna Mootoovaloo","Analytical marginalisation over photometric redshift uncertainties in
  cosmic shear analyses","11 pages, 8 figures, prepared for submission to MNRAS, comments
  welcome",,"10.1093/mnras/stad1192",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the statistical power of imaging surveys grows, it is crucial to account
for all systematic uncertainties. This is normally done by constructing a model
of these uncertainties and then marginalizing over the additional model
parameters. The resulting high dimensionality of the total parameter spaces
makes inferring the cosmological parameters significantly more costly using
traditional Monte-Carlo sampling methods. A particularly relevant example is
the redshift distribution, $p(z)$, of the source samples, which may require
tens of parameters to describe fully. However, relatively tight priors can be
usually placed on these parameters through calibration of the associated
systematics. In this paper we show, quantitatively, that a linearisation of the
theoretical prediction with respect to these calibratable systematic parameters
allows us to analytically marginalise over these extra parameters, leading to a
factor $\sim30$ reduction in the time needed for parameter inference, while
accurately recovering the same posterior distributions for the cosmological
parameters that would be obtained through a full numerical marginalisation over
160 $p(z)$ parameters. We demonstrate that this is feasible not only with
current data and current achievable calibration priors but also for future
Stage-IV datasets.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:29:20 GMT""}]","2023-05-03"
"2301.11979","Alexander Moskvin","A.S. Moskvin","DFT, L(S)DA, LDA+U, LDA+DMFT..., whether we do approach to a proper
  description of optical response for strongly correlated systems?","21 pages, 1 figure","Optics and Spectroscopy, 121, 467 (2016)","10.1134/S0030400X16100167",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  I present a critical overview of so-called ""{\it ab initio}"" DFT (density
fuctional theory) based calculation schemes for the description of the
electronic structure, energy spectrum, and optical response for strongly
correlated 3$d$ oxides, in particular, crystal-field and charge transfer
transitions as compared with an ""old""\, cluster model that does generalize
crystal-field and ligand-field theory. As a most instructive illustration of
validity of numerous calculation techniques I address the prototypical 3$d$
insulator NiO predicted to be a metal in frames of a standard LDA (local
density approximation) band theory.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:30:14 GMT""}]","2023-01-31"
"2301.11980","Flavio Abreu Araujo","Chlo\'e Chopin and Leandro Martins and Luana Benetti and Simon de
  Wergifosse and Alex Jenkins and Ricardo Ferreira and Flavio Abreu Araujo","A semi-analytical model to simulate the spin-diode effect and accelerate
  its use in neuromorphic computing","2 pages, 2 figures",,,,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin-diode effect is studied both experimentally and with our original
semi-analytical method. The latter is based on an improved version of the
Thiele equation approach (TEA) that we combine to micromagnetic simulation data
to accurately model the non-linear dynamics of spin-torque vortex oscillator
(STVO). This original method, called data-driven Thiele equation approach
(DD-TEA), absorbs the difference between the analytical model and micromagnetic
simulations to provide a both ultra-fast and quantitative model. The DD-TEA
model predictions also agree very well with the experimental data. The reversal
of the spin-diode effect with the chirality of the vortex, the impact of the
input current and the origin of a variation at half of the STVO frequency are
presented as well as the ability of the model to reproduce the experimental
behavior. Finally, the spin-diode effect and its simulation using the DD-TEA
model are discussed as a promising perspective in the framework of neuromorphic
computing.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:34:41 GMT""}]","2023-01-31"
"2301.11981","Ali Siahkoohi","Ali Siahkoohi, Rudy Morel, Maarten V. de Hoop, Erwan Allys, Gr\'egory
  Sainton, Taichi Kawamura","Unearthing InSights into Mars: Unsupervised Source Separation with
  Limited Data","ICML 2023",,,,"cs.LG astro-ph.EP eess.SP","http://creativecommons.org/licenses/by/4.0/","  Source separation involves the ill-posed problem of retrieving a set of
source signals that have been observed through a mixing operator. Solving this
problem requires prior knowledge, which is commonly incorporated by imposing
regularity conditions on the source signals, or implicitly learned through
supervised or unsupervised methods from existing data. While data-driven
methods have shown great promise in source separation, they often require large
amounts of data, which rarely exists in planetary space missions. To address
this challenge, we propose an unsupervised source separation scheme for domains
with limited data access that involves solving an optimization problem in the
wavelet scattering covariance representation space$\unicode{x2014}$an
interpretable, low-dimensional representation of stationary processes. We
present a real-data example in which we remove transient, thermally-induced
microtilts$\unicode{x2014}$known as glitches$\unicode{x2014}$from data recorded
by a seismometer during NASA's InSight mission on Mars. Thanks to the wavelet
scattering covariances' ability to capture non-Gaussian properties of
stochastic processes, we are able to separate glitches using only a few
glitch-free data snippets.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:38:07 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 18:08:10 GMT""}]","2023-06-02"
"2301.11982","Alex McAvoy","Qi Su, Alex McAvoy, Joshua B. Plotkin","Strategy evolution on dynamic networks","39 pages; minor typo corrections; comments welcome",,,,"physics.soc-ph cs.SI q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Models of strategy evolution on static networks help us understand how
population structure can promote the spread of traits like cooperation. One key
mechanism is the formation of altruistic spatial clusters, where neighbors of a
cooperative individual are likely to reciprocate, which protects prosocial
traits from exploitation. But most real-world interactions are ephemeral and
subject to exogenous restructuring, so that social networks change over time.
Strategic behavior on dynamic networks is difficult to study, and much less is
known about the resulting evolutionary dynamics. Here, we provide an analytical
treatment of cooperation on dynamic networks, allowing for arbitrary spatial
and temporal heterogeneity. We show that transitions among network structures
can favor the spread of cooperation, even if each individual social network
would inhibit cooperation when static. Furthermore, we show that spatial
heterogeneity tends to inhibit cooperation, whereas temporal heterogeneity
tends to promote it. Dynamic networks can have profound effects on the
evolution of prosocial traits, even when individuals have no agency over
network structures.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:43:01 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 19:22:55 GMT""}]","2023-02-03"
"2301.11983","Dragutin Mihailovic","Dragutin T. Mihailovic, Slavica Malinovic-Mili\'cevic, Jeongwoo Hanc
  and Vijay P. Singh","Complexity and chaotic behavior of the U.S. rivers and estimation of
  their prediction horizon","27 pages, 10 figures",,,,"physics.data-an","http://creativecommons.org/licenses/by/4.0/","  A streamflow time series encompasses a large amount of hidden information and
reliable prediction of its behavior in the future remains a challenge. It seems
that the use of information measures can significantly contribute to
determining the time horizon of rivers and improving predictability. Using the
Kolmogorov complexity (KC) and its derivatives (KC spectrum and its highest
value), and Lyapunov exponent (LE), it has previously been shown that the
degree of streamflow predictability depends on human activities, environmental
factors, and natural characteristics. This paper applied the KC and LE measures
to investigate the randomness and chaotic behavior of monthly streamflow of
1879 rivers from the United States for a period from 1950 to 2015 and evaluated
their time horizons via the Lyapunov and Kolmogorov time (LT and KT,
respectively).
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:43:55 GMT""}]","2023-01-31"
"2301.11984","Zhongguo Li","Zhongguo Li, Wen-Hua Chen, Jun Yang, Yunda Yan","Dual Control of Exploration and Exploitation for Self-Optimisation
  Control in Uncertain Environments",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper develops a dual control framework for exploration and exploitation
(DCEE) to solve a self-optimisation problem in unknown and uncertain
environment. In general, there is a fundamental conflict between tracking an
unknown optimal operational condition and parameter identification. Different
from existing adaptive control methods, the proposed DCEE does not need to
introduce additional perturbation signals, since it naturally embraces an
exploration effect to actively probe the uncertain environment to reduce belief
uncertainty. An ensemble based multi-estimator approach is developed to learn
the environmental parameters and in the meanwhile quantify the estimation
uncertainty in real time. The control action is devised with dual effects,
which not only minimises the tracking error between the current state and the
believed unknown optimal operational condition but also reduces belief
uncertainty by actively exploring the environment. Formal properties of the
proposed DCEE framework like convergence are established. A numerical example
is used to validate the effectiveness of the proposed DCEE. Simulation results
for maximum power point tracking are provided to further demonstrate the
potential of this new framework in real world applications.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:48:12 GMT""}]","2023-01-31"
"2301.11985","Simon de Wet","S. de Wet, T. Laskar, P.J. Groot, F. Cavallaro, A. Nicuesa Guelbenzu,
  S. Chastain, L. Izzo, A. Levan, D.B. Malesani, I.M. Monageng, A.J. van der
  Horst, W. Zheng, S. Bloemen, A.V. Filippenko, D.A. Kann, S. Klose, D.L.A.
  Pieterse, A. Rau, P.M. Vreeswijk, P. Woudt, Z.-P. Zhu","The triple-peaked afterglow of GRB 210731A from X-ray to radio
  frequencies","20 pages, 8 figures, accepted for publication in Astronomy &
  Astrophysics","2023, A&A, 671, A116","10.1051/0004-6361/202244917",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  GRB 210731A was a long-duration gamma-ray burst discovered by the Burst Alert
Telescope (BAT) aboard the Neil Gehrels Swift observatory. Swift triggered the
wide-field, robotic MeerLICHT optical telescope in Sutherland; it began
observing the BAT error circle 286 seconds after the Swift trigger and
discovered the optical afterglow of GRB 210731A in its first 60-second q-band
exposure. Multi-colour observations of the afterglow with MeerLICHT revealed a
light curve that showed three peaks of similar brightness within the first four
hours. We present the results of our follow-up campaign and interpret our
observations in the framework of the synchrotron forward shock model. We
performed temporal and spectral fits to determine the spectral regime and
external medium density profile, and performed detailed multi-wavelength
theoretical modelling of the afterglow following the last optical peak at 0.2
days to determine the intrinsic blast wave parameters. We find a preference for
a stellar wind density profile consistent with a massive star origin, while our
theoretical modelling results in fairly typical shock microphysics parameters.
Based on the energy released in gamma-rays and the kinetic energy in the blast
wave, we determine a low radiative efficiency of ~0.02. The first peak in the
optical light curve is likely the onset of the afterglow. We find that energy
injection into the forward shock offers the simplest explanation for the
subsequent light curve evolution, and that the blast wave kinetic energy
increasing by a factor of ~1000 from the first peak to the last peak is
indicative of substantial energy injection. Our highest-likelihood theoretical
model overpredicts the 1.4 GHz flux by a factor of approximately three with
respect to our upper limits, possibly implying a population of thermal
electrons within the shocked region.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:49:00 GMT""}]","2023-03-15"
"2301.11986","Soroush Hashemifar","Soroush Hashemifar, Abdolreza Marefat, Javad Hassannataj Joloudari and
  Hamid Hassanpour","FRA: A novel Face Representation Augmentation algorithm for face
  recognition",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  A low amount of training data for many state-of-the-art deep learning-based
Face Recognition (FR) systems causes a marked deterioration in their
performance. Although a considerable amount of research has addressed this
issue by inventing new data augmentation techniques, using either input space
transformations or Generative Adversarial Networks (GAN) for feature space
augmentations, these techniques have yet to satisfy expectations. In this
paper, we propose a novel method, named the Face Representation Augmentation
(FRA) algorithm, for augmenting face datasets. To the best of our knowledge,
FRA is the first method that shifts its focus towards manipulating the face
embeddings generated by any face representation learning algorithm in order to
generate new embeddings representing the same identity and facial emotion but
with an altered posture. Extensive experiments conducted in this study convince
the efficacy of our methodology and its power to provide noiseless, completely
new facial representations to improve the training procedure of any FR
algorithm. Therefore, FRA is able to help the recent state-of-the-art FR
methods by providing more data for training FR systems. The proposed method,
using experiments conducted on the Karolinska Directed Emotional Faces (KDEF)
dataset, improves the identity classification accuracies by 9.52 %, 10.04 %,
and 16.60 %, in comparison with the base models of MagFace, ArcFace, and
CosFace, respectively.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:54:58 GMT""}]","2023-01-31"
"2301.11987","Umberto D'Alesio","Umberto D'Alesio, Luca Maxia, Francesco Murgia, Cristian Pisano, and
  Sangem Rajesh","$J/\psi$ polarization in large-$P_T$ semi-inclusive deep-inelastic
  scattering at the EIC","14 pages, 7 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present a detailed phenomenological study of $J/\psi$ polarization in
semi-inclusive deep inelastic scattering processes, focusing on the kinematics
accessible at the future Electron-Ion Collider. We show theoretical estimates
for the standard polarization parameters for different frames usually adopted
in the literature, in the large $P_T$ region, namely $P_T\gg
\Lambda_\text{QCD}$, where collinear factorization is expected to hold. We
adopt both the Color Singlet Model and the Nonrelativistic QCD approach, paying
special attention to the role of different sets of Long Distance Matrix
Elements. Finally we present a preliminary analysis of some frame independent
polarization invariants.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:55:18 GMT""}]","2023-01-31"
"2301.11988","Pedro Montealegre","Pierre Fraigniaud, Pedro Montealegre, Ivan Rapaport and Ioan Todinca","Energy-Efficient Distributed Algorithms for Synchronous Networks",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  We study the design of energy-efficient algorithms for the LOCAL and CONGEST
models. Specifically, as a measure of complexity, we consider the maximum,
taken over all the edges, or over all the nodes, of the number of rounds at
which an edge, or a node, is active in the algorithm. We first show that every
Turing-computable problem has a CONGEST algorithm with constant node-activation
complexity, and therefore constant edge-activation complexity as well. That is,
every node (resp., edge) is active in sending (resp., transmitting) messages
for only $O(1)$ rounds during the whole execution of the algorithm. In other
words, every Turing-computable problem can be solved by an algorithm consuming
the least possible energy. In the LOCAL model, the same holds obviously, but
with the additional feature that the algorithm runs in $O(\mbox{poly}(n))$
rounds in $n$-node networks. However, we show that insisting on algorithms
running in $O(\mbox{poly}(n))$ rounds in the CONGEST model comes with a severe
cost in terms of energy. Namely, there are problems requiring
$\Omega(\mbox{poly}(n))$ edge-activations (and thus $\Omega(\mbox{poly}(n))$
node-activations as well) in the CONGEST model whenever solved by algorithms
bounded to run in $O(\mbox{poly}(n))$ rounds. Finally, we demonstrate the
existence of a sharp separation between the edge-activation complexity and the
node-activation complexity in the CONGEST model, for algorithms bounded to run
in $O(\mbox{poly}(n))$ rounds. Specifically, under this constraint, there is a
problem with $O(1)$ edge-activation complexity but $\tilde{\Omega}(n^{1/4})$
node-activation complexity.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 20:57:18 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 12:42:25 GMT""}]","2023-04-06"
"2301.11989","Antti Koskela","Antti Koskela and Tejas Kulkarni","Practical Differentially Private Hyperparameter Tuning with Subsampling","26 pages, 6 figures",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tuning the hyperparameters of differentially private (DP) machine learning
(ML) algorithms often requires use of sensitive data and this may leak private
information via hyperparameter values. Recently, Papernot and Steinke (2022)
proposed a certain class of DP hyperparameter tuning algorithms, where the
number of random search samples is randomized itself. Commonly, these
algorithms still considerably increase the DP privacy parameter $\varepsilon$
over non-tuned DP ML model training and can be computationally heavy as
evaluating each hyperparameter candidate requires a new training run. We focus
on lowering both the DP bounds and the computational cost of these methods by
using only a random subset of the sensitive data for the hyperparameter tuning
and by extrapolating the optimal values to a larger dataset. We provide a
R\'enyi differential privacy analysis for the proposed method and
experimentally show that it consistently leads to better privacy-utility
trade-off than the baseline method by Papernot and Steinke.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:01:58 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2023 19:13:04 GMT""}]","2023-06-06"
"2301.11990","Ilia Sucholutsky","Ilia Sucholutsky, Thomas L. Griffiths","Alignment with human representations supports robust few-shot learning",,,,,"cs.LG cs.AI cs.CV cs.HC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Should we care whether AI systems have representations of the world that are
similar to those of humans? We provide an information-theoretic analysis that
suggests that there should be a U-shaped relationship between the degree of
representational alignment with humans and performance on few-shot learning
tasks. We confirm this prediction empirically, finding such a relationship in
an analysis of the performance of 491 computer vision models. We also show that
highly-aligned models are more robust to both adversarial attacks and domain
shifts. Our results suggest that human-alignment is often a sufficient, but not
necessary, condition for models to make effective use of limited data, be
robust, and generalize well.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:03:19 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2023 15:01:39 GMT""}]","2023-06-06"
"2301.11991","Shuzhe Shi","Adrien Florio, David Frenklakh, Kazuki Ikeda, Dmitri Kharzeev,
  Vladimir Korepin, Shuzhe Shi, Kwangmin Yu","Real-time non-perturbative dynamics of jet production: quantum
  entanglement and vacuum modification","8 pages, 4 figures",,,,"hep-ph hep-ex hep-lat nucl-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The production of jets should allow to test the real-time response of the QCD
vacuum disturbed by the propagation of high-momentum color charges. Addressing
this problem theoretically requires a real-time, non-perturbative method. As a
step in developing such an approach, we report here on fully quantum
simulations of a massive Schwinger model coupled to external sources
representing quark and antiquark jets as produced in $e^+e^-$ annihilation. It
is well known that the Schwinger model [QED in $(1+1)$ dimensions] shares many
common properties with QCD, including confinement, chiral symmetry breaking and
the existence of vacuum fermion condensate. This allows us to study, for the
first time, the modification of the vacuum chiral condensate by the propagating
jets, and the quantum entanglement between the fragmenting jets. Our results
indicate strong entanglement between the fragmentation products of the two jets
at rapidity separations $\Delta \eta \leq 2$ that can potentially be studied in
experiment.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:05:43 GMT""}]","2023-01-31"
"2301.11992","J\""urgen D\""olz","J\""urgen D\""olz","Data sparse multilevel covariance estimation in optimal complexity",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the $\mathcal{H}^2$-formatted compression and computational
estimation of covariance functions on a compact set in $\mathbb{R}^d$. The
classical sample covariance or Monte Carlo estimator is prohibitively expensive
for many practically relevant problems, where often approximation spaces with
many degrees of freedom and many samples for the estimator are needed. In this
article, we propose and analyze a data sparse multilevel sample covariance
estimator, i.e., a multilevel Monte Carlo estimator. For this purpose, we
generalize the notion of asymptotically smooth kernel functions to a Gevrey
type class of kernels for which we derive new variable-order
$\mathcal{H}^2$-approximation rates. These variable-order
$\mathcal{H}^2$-approximations can be considered as a variant of
$hp$-approximations. Our multilevel sample covariance estimator then uses an
approximate multilevel hierarchy of variable-order
$\mathcal{H}^2$-approximations to compress the sample covariances on each
level. The non-nestedness of the different levels makes the reduction to the
final estimator nontrivial and we present a suitable algorithm which can handle
this task in linear complexity. This allows for a data sparse multilevel
estimator of Gevrey covariance kernel functions in the best possible complexity
for Monte Carlo type multilevel estimators, which is quadratic. Numerical
examples which estimate covariance matrices with tens of billions of entries
are presented.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:09:34 GMT""}]","2023-01-31"
"2301.11993","Yue Jiang","Yue Jiang, Yefeng Mei, Shengwang Du","Quantum Langevin theory for two coupled phase-conjugated electromagnetic
  waves",,"Phys. Rev. A 107, 053703 (2023)","10.1103/PhysRevA.107.053703",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While loss-gain-induced Langevin noises have been intensively studied in
quantum optics, the effect of a complex-valued nonlinear coupling coefficient
on the noises of two coupled phase-conjugated optical fields has never been
questioned before. Here, we provide a general macroscopic phenomenological
formula of quantum Langevin equations for two coupled phase-conjugated fields
with linear loss (gain) and complex nonlinear coupling coefficient. The
macroscopic phenomenological formula is obtained from the coupling matrix to
preserve the field commutation relations and correlations, which does not
require knowing the microscopic details of light-matter interaction and
internal atomic structures. To validate this phenomenological formula, we take
spontaneous four-wave mixing in a double-$\Lambda$ four-level atomic system as
an example to numerically confirm that our macroscopic phenomenological result
is consistent with that obtained from the microscopic Heisenberg-Langevin
theory. Finally, we apply the quantum Langevin equations to study the effects
of linear gain and loss, complex phase mismatching, as well as complex
nonlinear coupling coefficient in entangled photon pair (biphoton) generation,
particularly to their temporal quantum correlations.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:14:30 GMT""}]","2023-05-09"
"2301.11994","Rebecca Dorn","Rebecca Dorn, Yiwen Ma, Fred Morstatter, Kristina Lerman","Gender and Prestige Bias in Coronavirus News Reporting",,,,,"cs.SI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Journalists play a vital role in surfacing issues of societal importance, but
their choices of what to highlight and who to interview are influenced by
societal biases. In this work, we use natural language processing tools to
measure these biases in a large corpus of news articles about the Covid-19
pandemic. Specifically, we identify when experts are quoted in news and extract
their names and institutional affiliations. We enrich the data by classifying
each expert's gender, the type of organization they belong to, and for academic
institutions, their ranking. Our analysis reveals disparities in the
representation of experts in news. We find a substantial gender gap, where men
are quoted three times more than women. The gender gap varies by partisanship
of the news source, with conservative media exhibiting greater gender bias. We
also identify academic prestige bias, where journalists turn to experts from
highly-ranked academic institutions more than experts from less prestigious
institutions, even if the latter group has more public health expertise.
Liberal news sources exhibit slightly more prestige bias than conservative
sources. Equality of representation is essential to enable voices from all
groups to be heard. By auditing bias, our methods help identify blind spots in
news coverage.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:18:09 GMT""}]","2023-01-31"
"2301.11995","Randy Kuang","Randy Kuang and Maria Perepechaenko and Ryan Toth","A New Symmetric Homomorphic Functional Encryption over a Hidden Ring for
  Polynomial Public Key Encapsulations","21 pages, 1 figure",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a new homomorphic functional encryption using modular
multiplications over a hidden ring. Unlike traditional homomorphic encryption
where users can only passively perform ciphertext addition or multiplication,
the homomorphic functional encryption retains homomorphic addition and scalar
multiplication properties, but also allows for the user's inputs through
polynomial variables. The proposed homomorphic encryption can be applied to any
polynomials over a finite field, with their coefficients considered as their
privacy. We denote the polynomials before homomorphic encryption as plain
polynomials and after homomorphic encryption as cipher polynomials. A cipher
polynomial can be evaluated with variables from the finite field, GF(p), by
calculating the monomials of variables modulo a prime p. These properties allow
functional homomorphic encryption to be used for public key encryption of
certain asymmetric cryptosystems to hide the structure of its central map
construction. We propose a new variant of MPKC with homomorphic encryption of
its public key. We propose to use a single plaintext vector and a noise vector
of multiple variables to be associated with the central map, in place of the
secret plaintext vector to be encrypted in MPKC. We call this variant of
encrypted MPKC, a Homomorphic Polynomial Public Key algorithm or HPPK
algorithm. The HPPK algorithm holds the property of indistinguishability under
the chosen-plaintext attacks or IND-CPA. The overall classical complexity to
crack the HPPK algorithm is exponential in the size of the prime field GF(p).
We briefly report on benchmarking performance results using the SUPERCOP
toolkit. Benchmarking results demonstrate that HPPK offers rather fast
performance, which is comparable and in some cases outperforms the NIST PQC
finalists for key generation, encryption, and decryption.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:23:44 GMT""}]","2023-01-31"
"2301.11996","Lei Wu","Yan Guo and Lei Wu","$L^2$ Diffusive Expansion For Neutron Transport Equation","14 pages, 2 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grazing set singularity leads to a surprising counter-example and breakdown
of the classical mathematical theory for $L^{\infty}$ diffusive expansion of
neutron transport equation with in-flow boundary condition in term of the
Knudsen number $\varepsilon$, one of the most classical problems in the kinetic
theory. Even though a satisfactory new theory has been established by
constructing new boundary layers with favorable $\varepsilon$-geometric
correction for convex domains, the severe grazing singularity from non-convex
domains has prevented any positive mathematical progress. We develop a novel
and optimal $L^2$ expansion theory for general domain (including non-convex
domain) by discovering a surprising $\varepsilon^{\frac{1}{2}}$ gain for the
average of remainder.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:28:15 GMT""}]","2023-01-31"
"2301.11997","Guoqing Luo","Guoqing Luo, Yu Tong Han, Lili Mou, Mauajama Firdaus","Prompt-Based Editing for Text Style Transfer",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prompting approaches have been recently explored in text style transfer,
where a textual prompt is used to query a pretrained language model to generate
style-transferred texts word by word in an autoregressive manner. However, such
a generation process is less controllable and early prediction errors may
affect future word predictions. In this paper, we present a prompt-based
editing approach for text style transfer. Specifically, we prompt a pretrained
language model for style classification and use the classification probability
to compute a style score. Then, we perform discrete search with word-level
editing to maximize a comprehensive scoring function for the style-transfer
task. In this way, we transform a prompt-based generation problem into a
classification one, which is a training-free process and more controllable than
the autoregressive generation of sentences. In our experiments, we performed
both automatic and human evaluation on three style-transfer benchmark datasets,
and show that our approach largely outperforms the state-of-the-art systems
that have 20 times more parameters. Additional empirical analyses further
demonstrate the effectiveness of our approach.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:31:14 GMT""}]","2023-01-31"
"2301.11998","Danny Yuxing Huang","Stefany Cruz, Logan Danek, Shinan Liu, Christopher Kraemer, Zixin
  Wang, Nick Feamster, Danny Yuxing Huang, Yaxing Yao, Josiah Hester","Augmented Reality's Potential for Identifying and Mitigating Home
  Privacy Leaks",,"Workshop on Usable Security and Privacy (USEC) 2023","10.14722/usec.2023.238930",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Users face various privacy risks in smart homes, yet there are limited ways
for them to learn about the details of such risks, such as the data practices
of smart home devices and their data flow. In this paper, we present Privacy
Plumber, a system that enables a user to inspect and explore the privacy
""leaks"" in their home using an augmented reality tool. Privacy Plumber allows
the user to learn and understand the volume of data leaving the home and how
that data may affect a user's privacy -- in the same physical context as the
devices in question, because we visualize the privacy leaks with augmented
reality. Privacy Plumber uses ARP spoofing to gather aggregate network traffic
information and presents it through an overlay on top of the device in an
smartphone app. The increased transparency aims to help the user make privacy
decisions and mend potential privacy leaks, such as instruct Privacy Plumber on
what devices to block, on what schedule (i.e., turn off Alexa when sleeping),
etc. Our initial user study with six participants demonstrates participants'
increased awareness of privacy leaks in smart devices, which further
contributes to their privacy decisions (e.g., which devices to block).
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:36:23 GMT""}]","2023-02-01"
"2301.11999","Julien Pinske","Julien Pinske, Vincent Burgtorf, and Stefan Scheel","Particle-Number Threshold for Non-Abelian Geometric Phases",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  When a quantum state traverses a path, while being under the influence of a
gauge potential, it acquires a geometric phase that is often more than just a
scalar quantity.
  The variety of unitary transformations that can be realised by this form of
parallel transport depends crucially on the number of particles involved in the
evolution.
  Here, we introduce a particle-number threshold (PNT) that assesses a system's
capabilities to perform purely geometric manipulations of quantum states.
  This threshold gives the minimal number of particles necessary to fully
exploit a system's potential to generate non-Abelian geometric phases.
  Therefore, the PNT might be useful for evaluating the resource demands of a
holonomic quantum computer.
  We benchmark our findings on bosonic systems relevant to linear and nonlinear
quantum optics.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:38:55 GMT""}]","2023-01-31"
"2301.12000","Barbora Buhnova","Barbora Buhnova","Beyond Classroom: Making a Difference in Diversity in Tech","In Equity, Diversity, and Inclusion in Software Engineering: Best
  Practices and Insights. Apress, 2023",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  With all the opportunities and risks that technology holds in connection to
our safe and sustainable future, it is becoming increasingly important to
involve a larger portion of our society in becoming active co-creators of our
digitalized future -- moving from the passenger seat to the driver seat. Yet,
despite extensive efforts around the world, little progress has been made in
growing the representation of certain communities and groups in software
engineering. This chapter shares one successful project, called Czechitas,
triggering a major social change in Czechia, involving 1 000+ volunteers to
support 50 000+ women on their way towards software engineering education and
career.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:45:02 GMT""}]","2023-01-31"
"2301.12001","Jo\~ao Gabriel Zago","Jo\~ao Zago, Eduardo Camponogara and Eric Antonelo","Vertex-based reachability analysis for verifying ReLU deep neural
  networks",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Neural networks achieved high performance over different tasks, i.e. image
identification, voice recognition and other applications. Despite their
success, these models are still vulnerable regarding small perturbations, which
can be used to craft the so-called adversarial examples. Different approaches
have been proposed to circumvent their vulnerability, including formal
verification systems, which employ a variety of techniques, including
reachability, optimization and search procedures, to verify that the model
satisfies some property. In this paper we propose three novel reachability
algorithms for verifying deep neural networks with ReLU activations. The first
and third algorithms compute an over-approximation for the reachable set,
whereas the second one computes the exact reachable set. Differently from
previously proposed approaches, our algorithms take as input a V-polytope. Our
experiments on the ACAS Xu problem show that the Exact Polytope Network Mapping
(EPNM) reachability algorithm proposed in this work surpass the
state-of-the-art results from the literature, specially in relation to other
reachability methods.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:46:03 GMT""}]","2023-01-31"
"2301.12002","Miguel Madurga","M. Madurga, J.M. Christie, Z. Xu, R. Grzywacz, A. Poves, T. King, J.M.
  Allmond, A. Chester, I. Cox, J. Farr, I. Fletcher, J. Heideman, D. Hoskins,
  A. Laminack, S. Liddick, S. Neupane, A. L. Richard, N. Shimizu, P. Shuai, K.
  Siegl, Y. Utsuno, P. Wagenknecht, R. Yokoyama","New isomeric transition in $^{36}$Mg: Bridging the N=20 and N=28 islands
  of inversion","7 pages, 4 figures",,,,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We observed a new isomeric gamma transition at 168 keV in $^{36}$Mg, with a
half-life of T$_{1/2}$=[130-500]$(\pm40)(^{+800}_{-20})_{sys}$ ns. We propose
that the observed transition de-excites a new 0$^+$ isomeric state and
populates the previously known first 2$^+$ state. The existence of this isomer
is consistent with the predictions of the large-scale shell model calculations
of $^{36}$Mg using the sdpf-u-mix interaction. The observed excitation energy
of the second 0$^+$ state is caused by the small energy separation between two
prolate-deformed configurations where the intruder configuration corresponds to
two neutron excitations from the {\it sd} to the {\it pf} shell. Within this
interpretation, $^{36}$Mg becomes the crossing point between nuclei in which
ground state deformed/superdeformed configurations are caused by the dominance
of N=20 intruders ($^{32,34}$Mg) and nuclei where deformed configurations are
associated with N=28 intruders ($^{38}$Mg and beyond). We found the lack of
three-body monopole corrections in other effective interactions results in a
predominance of N=20 intruder configurations past $^{38}$Mg incompatible with
our observation. We conclude that $^{36}$Mg bridges the N=20 and N=28 islands
of inversion, forming the so-called Big Island of Deformation.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:48:31 GMT""},{""version"":""v2"",""created"":""Fri, 14 Apr 2023 18:39:46 GMT""}]","2023-04-18"
"2301.12003","Jong Chul Ye","Sangyun Lee, Beomsu Kim, Jong Chul Ye","Minimizing Trajectory Curvature of ODE-based Generative Models","ICML 2023",,,,"cs.LG cs.AI cs.CV stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent ODE/SDE-based generative models, such as diffusion models, rectified
flows, and flow matching, define a generative process as a time reversal of a
fixed forward process. Even though these models show impressive performance on
large-scale datasets, numerical simulation requires multiple evaluations of a
neural network, leading to a slow sampling speed. We attribute the reason to
the high curvature of the learned generative trajectories, as it is directly
related to the truncation error of a numerical solver. Based on the
relationship between the forward process and the curvature, here we present an
efficient method of training the forward process to minimize the curvature of
generative trajectories without any ODE/SDE simulation. Experiments show that
our method achieves a lower curvature than previous models and, therefore,
decreased sampling costs while maintaining competitive performance. Code is
available at https://github.com/sangyun884/fast-ode.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:52:03 GMT""},{""version"":""v2"",""created"":""Sun, 5 Feb 2023 14:37:02 GMT""},{""version"":""v3"",""created"":""Thu, 25 May 2023 11:33:13 GMT""}]","2023-05-26"
"2301.12004","Jessica Huynh","Jessica Huynh, Cathy Jiao, Prakhar Gupta, Shikib Mehri, Payal Bajaj,
  Vishrav Chaudhary, Maxine Eskenazi","Understanding the Effectiveness of Very Large Language Models on Dialog
  Evaluation","Accepted for publication at IWSDS 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Language models have steadily increased in size over the past few years. They
achieve a high level of performance on various natural language processing
(NLP) tasks such as question answering and summarization. Large language models
(LLMs) have been used for generation and can now output human-like text. Due to
this, there are other downstream tasks in the realm of dialog that can now
harness the LLMs' language understanding capabilities. Dialog evaluation is one
task that this paper will explore. It concentrates on prompting with LLMs:
BLOOM, OPT, GPT-3, Flan-T5, InstructDial and TNLGv2. The paper shows that the
choice of datasets used for training a model contributes to how well it
performs on a task as well as on how the prompt should be structured.
Specifically, the more diverse and relevant the group of datasets that a model
is trained on, the better dialog evaluation performs. This paper also
investigates how the number of examples in the prompt and the type of example
selection used affect the model's performance.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:02:27 GMT""}]","2023-01-31"
"2301.12005","Seungyeon Kim","Seungyeon Kim, Ankit Singh Rawat, Manzil Zaheer, Sadeep Jayasumana,
  Veeranjaneyulu Sadhanala, Wittawat Jitkrittum, Aditya Krishna Menon, Rob
  Fergus, Sanjiv Kumar","EmbedDistill: A Geometric Knowledge Distillation for Information
  Retrieval",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large neural models (such as Transformers) achieve state-of-the-art
performance for information retrieval (IR). In this paper, we aim to improve
distillation methods that pave the way for the deployment of such models in
practice. The proposed distillation approach supports both retrieval and
re-ranking stages and crucially leverages the relative geometry among queries
and documents learned by the large teacher model. It goes beyond existing
distillation methods in the IR literature, which simply rely on the teacher's
scalar scores over the training data, on two fronts: providing stronger signals
about local geometry via embedding matching and attaining better coverage of
data manifold globally via query generation. Embedding matching provides a
stronger signal to align the representations of the teacher and student models.
At the same time, query generation explores the data manifold to reduce the
discrepancies between the student and teacher where training data is sparse.
Our distillation approach is theoretically justified and applies to both dual
encoder (DE) and cross-encoder (CE) models. Furthermore, for distilling a CE
model to a DE model via embedding matching, we propose a novel dual
pooling-based scorer for the CE model that facilitates a distillation-friendly
embedding geometry, especially for DE student models.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:04:37 GMT""}]","2023-01-31"
"2301.12006","Aref Jafari","Aref Jafari, Mehdi Rezagholizadeh, Ali Ghodsi","Improved knowledge distillation by utilizing backward pass knowledge in
  neural networks",,,,,"cs.LG cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge distillation (KD) is one of the prominent techniques for model
compression. In this method, the knowledge of a large network (teacher) is
distilled into a model (student) with usually significantly fewer parameters.
KD tries to better-match the output of the student model to that of the teacher
model based on the knowledge extracts from the forward pass of the teacher
network. Although conventional KD is effective for matching the two networks
over the given data points, there is no guarantee that these models would match
in other areas for which we do not have enough training samples. In this work,
we address that problem by generating new auxiliary training samples based on
extracting knowledge from the backward pass of the teacher in the areas where
the student diverges greatly from the teacher. We compute the difference
between the teacher and the student and generate new data samples that maximize
the divergence. This is done by perturbing data samples in the direction of the
gradient of the difference between the student and the teacher. Augmenting the
training set by adding this auxiliary improves the performance of KD
significantly and leads to a closer match between the student and the teacher.
Using this approach, when data samples come from a discrete domain, such as
applications of natural language processing (NLP) and language understanding,
is not trivial. However, we show how this technique can be used successfully in
such applications. We evaluated the performance of our method on various tasks
in computer vision and NLP domains and got promising results.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:07:38 GMT""}]","2023-01-31"
"2301.12007","Pouya Sampourmahani","Pouya Sampourmahani, Mohammadhossein Mohammadisiahroudi, Tam\'as
  Terlaky","On Semidefinite Representations of Second-order Conic Optimization
  Problems",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Second-order conic optimization (SOCO) can be considered as a special case of
semidefinite optimization (SDO). In the literature it has been advised that a
SOCO problem can be embedded in an SDO problem using the arrow-head matrix
transformation. However, a primal-dual solution pair cannot be mapped
simultaneously using the arrow-head transformation as we might lose
complementarity and duality in some cases. To address this issue, we
investigate the relationship between SOCO problems, and their SDO counterpart.
Through derivation of standard semidefinite representations of SOCO problems,
we introduce admissible mappings. We show that the proposed mappings preserve
both feasibility and optimality. Further, we discuss how the optimal partition
of a SOCO problem maps to the optimal partition of its SDO counterpart.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:08:39 GMT""}]","2023-01-31"
"2301.12008","Ignacio Sanchez-Burgos","Ignacio Sanchez-Burgos, Maria Carolina Muniz, Jorge R. Espinosa and
  Athanassios Z. Panagiotopoulos","A Deep Potential model for liquid-vapor equilibrium and cavitation rates
  of water",,,"10.1063/5.0144500",,"cond-mat.soft physics.chem-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Computational studies of liquid water and its phase transition into vapor
have traditionally been performed using classical water models. Here we utilize
the Deep Potential methodology -- a machine learning approach -- to study this
ubiquitous phase transition, starting from the phase diagram in the
liquid-vapor coexistence regime. The machine learning model is trained on ab
initio energies and forces based on the SCAN density functional which has been
previously shown to reproduce solid phases and other properties of water. Here,
we compute the surface tension, saturation pressure and enthalpy of
vaporization for a range of temperatures spanning from 300 to 600 K, and
evaluate the Deep Potential model performance against experimental results and
the semi-empirical TIP4P/2005 classical model. Moreover, by employing the
seeding technique, we evaluate the free energy barrier and nucleation rate at
negative pressures for the isotherm of 296.4 K. We find that the nucleation
rates obtained from the Deep Potential model deviate from those computed for
the TIP4P/2005 water model, due to an underestimation in the surface tension
from the Deep Potential model. From analysis of the seeding simulations, we
also evaluate the Tolman length for the Deep Potential water model, which is
(0.091 $\pm$ 0.008) nm at 296.4 K. Lastly, we identify that water molecules
display a preferential orientation in the liquid-vapor interface, in which H
atoms tend to point towards the vapor phase to maximize the enthalpic gain of
interfacial molecules. We find that this behaviour is more pronounced for
planar interfaces than for the curved interfaces in bubbles. This work
represents the first application of Deep Potential models to the study of
liquid-vapor coexistence and water cavitation.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:14:18 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 20:14:19 GMT""}]","2023-05-24"
"2301.12009","Marc Ditzhaus","Marc Ditzhaus and {\L}ukasz Smaga","Inference for all variants of the multivariate coefficient of variation
  in factorial designs",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multivariate coefficient of variation (MCV) is an attractive and
easy-to-interpret effect size for the dispersion in multivariate data.
Recently, the first inference methods for the MCV were proposed by Ditzhaus and
Smaga (2022) for general factorial designs covering k-sample settings but also
complex higher-way layouts. However, two questions are still pending: (1) The
theory on inference methods for MCV is primarily derived for one special MCV
variant while there are several reasonable proposals. (2) When rejecting a
global null hypothesis in factorial designs, a more in-depth analysis is
typically of high interest to find the specific contrasts of MCV leading to the
aforementioned rejection. In this paper, we tackle both by, first, extending
the aforementioned nonparametric permutation procedure to the other MCV
variants and, second, by proposing a max-type test for post hoc analysis. To
improve the small sample performance of the latter, we suggest a novel
studentized bootstrap strategy and prove its asymptotic validity. The actual
performance of all proposed tests and post hoc procedures are compared in an
extensive simulation study and illustrated by a real data analysis.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:18:56 GMT""}]","2023-01-31"
"2301.12010","Ian Madden","Ian Madden and Simone Marras and Jenny Suckale","Leveraging Google's Tensor Processing Units for tsunami-risk mitigation
  planning in the Pacific Northwest and beyond",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Tsunami-risk and flood-risk mitigation planning has particular importance for
communities like those of the Pacific Northwest, where coastlines are extremely
dynamic and a seismically-active subduction zone looms large. The challenge
does not stop here for risk managers: mitigation options have multiplied since
communities have realized the viability and benefits of nature-based solutions.
To identify suitable mitigation options for their community, risk managers need
the ability to rapidly evaluate several different options through fast and
accessible tsunami models, but may lack high-performance computing
infrastructure. The goal of this work is to leverage the newly developed
Google's Tensor Processing Unit (TPU), a high-performance hardware accessible
via the Google Cloud framework, to enable the rapid evaluation of different
tsunami-risk mitigation strategies available to all communities. We establish a
starting point through a numerical solver of the nonlinear shallow-water
equations that uses a fifth-order Weighted Essentially Non-Oscillatory method
with the Lax-Friedrichs flux splitting, and a Total Variation Diminishing
third-order Runge-Kutta method for time discretization. We verify numerical
solutions through several analytical solutions and benchmarks, reproduce
several findings about one particular tsunami-risk mitigation strategy, and
model tsunami runup at Crescent City, California whose topography comes from a
high-resolution Digital Elevation Model. The direct measurements of the
simulations performance, energy usage, and ease of execution show that our code
could be a first step towards a community-based, user-friendly virtual
laboratory that can be run by a minimally trained user on the cloud thanks to
the ease of use of the Google Cloud Platform.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:20:01 GMT""}]","2023-01-31"
"2301.12011","Jan Williams","Jan P. Williams, Olivia Zahn, J. Nathan Kutz","Sensing with shallow recurrent decoder networks","11 pages, 6 figures",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  Sensing is a universal task in science and engineering. Downstream tasks from
sensing include inferring full state estimates of a system (system
identification), control decisions, and forecasting. These tasks are
exceptionally challenging to achieve with limited sensors, noisy measurements,
and corrupt or missing data. Existing techniques typically use current (static)
sensor measurements to perform such tasks and require principled sensor
placement or an abundance of randomly placed sensors. In contrast, we propose a
SHallow REcurrent Decoder (SHRED) neural network structure which incorporates
(i) a recurrent neural network (LSTM) to learn a latent representation of the
temporal dynamics of the sensors, and (ii) a shallow decoder that learns a
mapping between this latent representation and the high-dimensional state
space. By explicitly accounting for the time-history, or trajectory, of the
sensor measurements, SHRED enables accurate reconstructions with far fewer
sensors, outperforms existing techniques when more measurements are available,
and is agnostic towards sensor placement. In addition, a compressed
representation of the high-dimensional state is directly obtained from sensor
measurements, which provides an on-the-fly compression for modeling physical
and engineering systems. Forecasting is also achieved from the sensor
time-series data alone, producing an efficient paradigm for predicting temporal
evolution with an exceptionally limited number of sensors. In the example cases
explored, including turbulent flows, complex spatio-temporal dynamics can be
characterized with exceedingly limited sensors that can be randomly placed with
minimal loss of performance.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:28:00 GMT""}]","2023-01-31"
"2301.12012","Fernando Casta\~neda","Fernando Casta\~neda, Haruki Nishimura, Rowan McAllister, Koushil
  Sreenath, Adrien Gaidon","In-Distribution Barrier Functions: Self-Supervised Policy Filters that
  Avoid Out-of-Distribution States",,,,,"cs.RO cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning-based control approaches have shown great promise in performing
complex tasks directly from high-dimensional perception data for real robotic
systems. Nonetheless, the learned controllers can behave unexpectedly if the
trajectories of the system divert from the training data distribution, which
can compromise safety. In this work, we propose a control filter that wraps any
reference policy and effectively encourages the system to stay in-distribution
with respect to offline-collected safe demonstrations. Our methodology is
inspired by Control Barrier Functions (CBFs), which are model-based tools from
the nonlinear control literature that can be used to construct minimally
invasive safe policy filters. While existing methods based on CBFs require a
known low-dimensional state representation, our proposed approach is directly
applicable to systems that rely solely on high-dimensional visual observations
by learning in a latent state-space. We demonstrate that our method is
effective for two different visuomotor control tasks in simulation
environments, including both top-down and egocentric view settings.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:28:19 GMT""}]","2023-01-31"
"2301.12013","Elijah Pelofske","Elijah Pelofske, Lorie M. Liebrock, Vincent Urias","Cybersecurity Threat Hunting and Vulnerability Analysis Using a Neo4j
  Graph Database of Open Source Intelligence",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open source intelligence is a powerful tool for cybersecurity analysts to
gather information both for analysis of discovered vulnerabilities and for
detecting novel cybersecurity threats and exploits. However the scale of
information that is relevant for information security on the internet is always
increasing, and is intractable for analysts to parse comprehensively. Therefore
methods of condensing the available open source intelligence, and automatically
developing connections between disparate sources of information, is incredibly
valuable. In this research, we present a system which constructs a Neo4j graph
database formed by shared connections between open source intelligence text
including blogs, cybersecurity bulletins, news sites, antivirus scans, social
media posts (e.g., Reddit and Twitter), and threat reports. These connections
are comprised of possible indicators of compromise (e.g., IP addresses,
domains, hashes, email addresses, phone numbers), information on known exploits
and techniques (e.g., CVEs and MITRE ATT&CK Technique ID's), and potential
sources of information on cybersecurity exploits such as twitter usernames. The
construction of the database of potential IoCs is detailed, including the
addition of machine learning and metadata which can be used for filtering of
the data for a specific domain (for example a specific natural language) when
needed. Examples of utilizing the graph database for querying connections
between known malicious IoCs and open source intelligence documents, including
threat reports, are shown. We show that this type of relationship querying can
allow for more effective use of open source intelligence for threat hunting,
malware family clustering, and vulnerability analysis.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:29:22 GMT""}]","2023-01-31"
"2301.12014","Longyun Ding","Longyun Ding and Xu Wang","A hierarchy on non-archimedean Polish groups admitting a compatible
  complete left-invariant metric","19 pages, submitted",,,,"math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this article, a hierarchy named $\alpha$-CLI for $\alpha<\omega_1$ is
defined on non-archimedean Polish groups admitting a compatible complete
left-invariant metric. Then (1) $G$ is $0$-CLI iff $G=\{1_G\}$; and (2) $G$ is
$1$-CLI iff $G$ admit a compatible complete two sided invariant metric.
  This notion forms a proper hierarchy because, for any $\alpha<\omega_1$,
there exist non-archimedean CLI Polish groups $G_\alpha$ and $H_\alpha$ such
that $H_\alpha$ is $\alpha$-CLI but not contains any open subgroup which is
$\beta$-CLI for $\beta<\alpha$; and $G_\alpha$ is not $\alpha$-CLI but contains
an open subgroup which is $\alpha$-CLI, and hence $G_\alpha$ is
$(\alpha+1)$-CLI.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:33:52 GMT""}]","2023-01-31"
"2301.12015","Franziska Borer","Franziska Borer, Peter Elbau, Tobias Weth","A Variant Prescribed Curvature Flow on Closed Surfaces with Negative
  Euler Characteristic",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On a closed Riemannian surface $(M,\bar g)$ with negative Euler
characteristic, we study the problem of finding conformal metrics with
prescribed volume $A>0$ and the property that their Gauss curvatures
$f_\lambda= f + \lambda$ are given as the sum of a prescribed function $f \in
C^\infty(M)$ and an additive constant $\lambda$. Our main tool in this study is
a new variant of the prescribed Gauss curvature flow, for which we establish
local well-posedness and global compactness results. In contrast to previous
work, our approach does not require any sign conditions on $f$. Moreover, we
exhibit conditions under which the function $f_\lambda$ is sign changing and
the standard prescribed Gauss curvature flow is not applicable.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:35:28 GMT""}]","2023-01-31"
"2301.12016","Suhani Gupta","Suhani Gupta, Wojciech A. Hellwing, and Maciej Bilicki","Improved analytical modeling of the non-linear power spectrum in
  modified gravity cosmologies",,,"10.1103/PhysRevD.107.083525",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Reliable analytical modeling of the non-linear power spectrum (PS) of matter
perturbations is among the chief pre-requisites for cosmological analyses from
the largest sky surveys. This is especially true for the models that extend the
standard general-relativity paradigm by adding the fifth force, where numerical
simulations can be prohibitively expensive. Here we present a method for
building accurate PS models for two modified gravity (MG) variants: namely the
Hu-Sawicki $f(R)$, and the normal branch of the Dvali-Gabadadze-Porrati (nDGP)
braneworld. We start by modifying the standard halo model (HM) with respect to
the baseline Lambda-Cold-Dark-Matter ($\Lambda$CDM) scenario, by using the HM
components with specific MG extensions. We find that our $P(k)_{\text{HM}}$
retains 5% accuracy only up to mildly non-linear scales ($k \lesssim 0.3$
$h/\,\mbox{Mpc}$) when compared to PS from numerical simulations. At the same
time, our HM prescription much more accurately captures the ratio $\Upsilon(k)
= P(k)_{\text{MG}}/P(k)_{\Lambda \text{CDM}}$ up to non-linear scales. We show
that using HM-derived $\Upsilon(k)$ together with a viable non-linear
$\Lambda$CDM $P(k)$ prescription (such as HALOFIT), we render a much better and
more accurate PS predictions in MG. The new approach yields considerably
improved performance, with modeled $P(k)_{\text{MG}}$ being now accurate to
within 5% all the way to non-linear scales of $k \lesssim 2.5-3$
$h/\,\mbox{Mpc}$. The magnitude of deviations from GR as fostered by these MG
models is typically $\mathcal{O}(10\%)$ in these regimes. Therefore reaching 5%
PS modeling is enough for forecasting constraints on modern-era cosmological
observables.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:36:49 GMT""}]","2023-04-25"
"2301.12017","Xiaoixa Wu","Xiaoxia Wu, Cheng Li, Reza Yazdani Aminabadi, Zhewei Yao, Yuxiong He","Understanding INT4 Quantization for Transformer Models: Latency Speedup,
  Composability, and Failure Cases",,"Fortieth International Conference on Machine Learning 2023",,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Improving the deployment efficiency of transformer-based language models has
been challenging given their high computation and memory cost. While INT8
quantization has recently been shown to be effective in reducing both the
memory cost and latency while preserving model accuracy, it remains unclear
whether we can leverage INT4 (which doubles peak hardware throughput) to
achieve further latency improvement. In this study, we explore the feasibility
of employing INT4 weight and activation (W4A4) quantization for language
models. Our findings indicate that W4A4 quantization introduces no to
negligible accuracy degradation for encoder-only and encoder-decoder models,
but causes a significant accuracy drop for decoder-only models. To materialize
the performance gain using W4A4, we develop a highly optimized end-to-end W4A4
encoder inference pipeline supporting different quantization strategies. Our
INT4 pipeline is $8.5\times$ faster for latency-oriented scenarios and up to
$3\times$ for throughput-oriented scenarios compared to the inference of FP16,
and improves the SOTA BERT INT8 performance from FasterTransformer by up to
$1.7\times$. We provide insights into the failure cases when applying W4A4 to
decoder-only models, and further explore the compatibility of INT4 quantization
with other compression methods, like pruning and layer reduction.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 22:44:18 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 21:32:11 GMT""}]","2023-06-01"
"2301.12018","Alexander White","Vidushi Sharma, Lee A. Collins, Alexander J. White","Stochastic and Mixed Density Functional Theory within the projector
  augmented wave formalism for the simulation of warm dense matter",,,,"LA-UR-23-20795","physics.comp-ph cond-mat.mtrl-sci physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic and mixed stochastic-deterministic density functional theory (DFT)
are promising new approaches for the calculation of the equation-of-state and
transport properties in materials under extreme conditions. In the intermediate
warm dense matter regime, a state between correlated condensed matter and
kinetic plasma, electrons can range from being highly localized around nuclei
to delocalized over the whole simulation cell. The plane-wave basis
pseudo-potential approach is thus the typical tool of choice for modeling such
systems at the DFT level. Unfortunately, the stochastic DFT methods scale as
the square of the maximum plane-wave energy in this basis. To reduce the effect
of this scaling, and improve the overall description of the electrons within
the pseudo-potential approximation, we present stochastic and mixed DFT
developed and implemented within the projector augmented wave formalism. We
compare results between the different DFT approaches for both single-point and
molecular dynamics trajectories and present calculations of self-diffusion
coefficients of solid density carbon from 1 to 50 eV.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:04:17 GMT""}]","2023-01-31"
"2301.12019","Nicole Aretz","Nicole Aretz, Peng Chen, Denise Degen, Karen Veroy","A Greedy Sensor Selection Algorithm for Hyperparameterized Linear
  Bayesian Inverse Problems",,,,,"math.NA cs.CE cs.NA","http://creativecommons.org/licenses/by/4.0/","  We consider optimal sensor placement for a family of linear Bayesian inverse
problems characterized by a deterministic hyper-parameter. The hyper-parameter
describes distinct configurations in which measurements can be taken of the
observed physical system. To optimally reduce the uncertainty in the system's
model with a single set of sensors, the initial sensor placement needs to
account for the non-linear state changes of all admissible configurations. We
address this requirement through an observability coefficient which links the
posteriors' uncertainties directly to the choice of sensors. We propose a
greedy sensor selection algorithm to iteratively improve the observability
coefficient for all configurations through orthogonal matching pursuit. The
algorithm allows explicitly correlated noise models even for large sets of
candidate sensors, and remains computationally efficient for high-dimensional
forward models through model order reduction. We demonstrate our approach on a
large-scale geophysical model of the Perth Basin, and provide numerical studies
regarding optimality and scalability with regard to classic optimal
experimental design utility functions.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:04:26 GMT""}]","2023-01-31"
"2301.12020","H\'ector Ra\'ul Olivares S\'anchez","Hector R. Olivares S., Monika A. Moscibrodzka and Oliver Porth","General relativistic hydrodynamic simulations of perturbed transonic
  accretion","17 pages, 12 figures, submitted to Astronomy and Astrophysics",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Comparison of horizon-scale observations of Sgr A* and M87* with numerical
simulations has provided considerable insight in their interpretation. Most of
these simulations are variations of the same physical scenario consisting of a
rotation-supported torus seeded with poloidal magnetic fields. This setup has
several well known limitations, most notably, it differs in important ways from
what observed in simulations of accretion from large scales. We aim to study
the flow patterns that arise at horizon scales in more general scenarios, that
have a clearer connection with the large scale flow and are at the same time
controlled by a reduced set of parameters. As a first step in this direction,
we perform three dimensional general relativistic hydrodynamic simulations of
rotating transonic flows with velocity perturbations injected from a spherical
boundary located 1000 gravitational radii away from the central object. We
study the general properties of these flows with varying angular momentum and
perturbation amplitudes. We observe a rich phenomenology in accretion patterns,
that includes smooth Bondi-like flows, turbulent torus-like structures, shocks,
filaments, and complex sonic structures. For sufficiently large perturbations
and angular momentum, radial profiles deviate from the constant entropy and
angular momentum profiles used for initialization and resemble those of
advection dominated accretion flows, showing evidence of entropy generation and
angular momentum redistribution not mediated by magnetic fields. Fluctuations
are amplified and extend further in frequency than the injected white noise
spectrum, producing a red noise spectrum for synthetic Bremsstrahlung light
curves. Future inclusion of magnetic fields and radiative cooling could make
this type of simulations a viable alternative for numerical modeling of general
low-luminosity active galactic nuclei.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:13:24 GMT""}]","2023-01-31"
"2301.12021","Firdavs Rakhmonov","Alex Iosevich, Doowon Koh, Firdavs Rakhmonov","The quotient set of the quadratic distance set over finite fields","17 pages",,,,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathbb F_q^d$ be the $d$-dimensional vector space over the finite field
$\mathbb F_q$ with $q$ elements. For each non-zero $r$ in $\mathbb F_q$ and
$E\subset \mathbb F_q^d$, we define $W(r)$ as the number of quadruples
$(x,y,z,w)\in E^4$ such that $ Q(x-y)/Q(z-w)=r,$ where $Q$ is a non-degenerate
quadratic form in $d$ variables over $\mathbb F_q.$ When
$Q(\alpha)=\sum_{i=1}^d \alpha_i^2$ with $\alpha=(\alpha_1, \ldots,
\alpha_d)\in \mathbb F_q^d,$ Pham (2022) recently used the machinery of group
actions and proved that if $E\subset \mathbb F_q^2$ with $q\equiv 3 \pmod{4}$
and $|E|\ge C q$, then we have $W(r)\ge c |E|^4/q$ for any non-zero square
number $r \in \mathbb F_q,$ where $C$ is a sufficiently large constant, $ c$ is
some number between $0$ and $1,$ and $|E|$ denotes the cardinality of the set
$E.$
  In this article, we improve and extend Pham's result in two dimensions to
arbitrary dimensions with general non-degenerate quadratic distances. As a
corollary of our results, we also generalize the sharp results on the Falconer
type problem for the quotient set of distance set due to the first two authors
and Parshall (2019). Furthermore, we provide improved constants for the size
conditions of the underlying sets.
  The key new ingredient is to relate the estimate of the $W(r)$ to a quadratic
homogeneous variety in $2d$-dimensional vector space. This approach is fruitful
because it allows us to take advantage of Gauss sums which are more handleable
than the Kloosterman sums appearing in the standard distance type problems.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:16:47 GMT""}]","2023-01-31"
"2301.12022","Ang Li","Ang Li, Scott Mueller, Judea Pearl","Epsilon-Identifiability of Causal Quantities",,,,,"cs.AI math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Identifying the effects of causes and causes of effects is vital in virtually
every scientific field. Often, however, the needed probabilities may not be
fully identifiable from the data sources available. This paper shows how
partial identifiability is still possible for several probabilities of
causation. We term this epsilon-identifiability and demonstrate its usefulness
in cases where the behavior of certain subpopulations can be restricted to
within some narrow bounds. In particular, we show how unidentifiable causal
effects and counterfactual probabilities can be narrowly bounded when such
allowances are made. Often those allowances are easily measured and reasonably
assumed. Finally, epsilon-identifiability is applied to the unit selection
problem.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:16:57 GMT""}]","2023-01-31"
"2301.12023","Wonho Bae","Wonho Bae, Mohamed Osama Ahmed, Frederick Tung, Gabriel L. Oliveira","Meta Temporal Point Processes","Accepted to ICLR2023",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A temporal point process (TPP) is a stochastic process where its realization
is a sequence of discrete events in time. Recent work in TPPs model the process
using a neural network in a supervised learning framework, where a training set
is a collection of all the sequences. In this work, we propose to train TPPs in
a meta learning framework, where each sequence is treated as a different task,
via a novel framing of TPPs as neural processes (NPs). We introduce context
sets to model TPPs as an instantiation of NPs. Motivated by attentive NP, we
also introduce local history matching to help learn more informative features.
We demonstrate the potential of the proposed method on popular public benchmark
datasets and tasks, and compare with state-of-the-art TPP methods.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:21:07 GMT""}]","2023-01-31"
"2301.12024","Yunda Yan","Wen-Hua Chen and Yunda Yan","Stability of Finite Receding Horizon Control: A Complementary Approach",,,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents a complementary approach to establish stability of finite
receding horizon control with a terminal cost. First a new augmented stage cost
is defined by rotating the terminal cost. Then a one-step optimisation problem
is defined based on this augmented stage cost. It is shown that a slightly
modified Model Predictive Control (MPC) algorithm is stable if the value
function of the augmented one-step cost (OSVF) is a control Lyapunov function.
The proposed stability condition is completely complementary to the existing
terminal cost based MPC stability conditions in the sense that they are
mutually excluded with each other. By using this approach, we are able to
establish stability for MPC algorithms with zero terminal cost or even negative
terminal cost as special cases. Combining this new approach with the existing
MPC stability theory, we are able to significantly relax the stability
requirement on MPC and extend the design space where stability are guaranteed.
The proposed approach will help to further reduce the gap between stability
theory and practical applications of MPC and other optimisation based control
methods.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:22:00 GMT""}]","2023-01-31"
"2301.12025","Pranav Singh","Pranav Singh and Jacopo Cirrone","Cross-Architectural Positive Pairs improve the effectiveness of
  Self-Supervised Learning","24 pages, 14 figures, Under Review. arXiv admin note: text overlap
  with arXiv:2206.04170",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Existing self-supervised techniques have extreme computational requirements
and suffer a substantial drop in performance with a reduction in batch size or
pretraining epochs. This paper presents Cross Architectural - Self Supervision
(CASS), a novel self-supervised learning approach that leverages Transformer
and CNN simultaneously. Compared to the existing state-of-the-art
self-supervised learning approaches, we empirically show that CASS-trained CNNs
and Transformers across four diverse datasets gained an average of 3.8% with 1%
labeled data, 5.9% with 10% labeled data, and 10.13% with 100% labeled data
while taking 69% less time. We also show that CASS is much more robust to
changes in batch size and training epochs than existing state-of-the-art
self-supervised learning approaches. We have open-sourced our code at
https://github.com/pranavsinghps1/CASS.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:27:24 GMT""}]","2023-01-31"
"2301.12026","Jonathan Bartlett","Jonathan W. Bartlett, Camila Olarte Parra, Rhian M. Daniel","G-formula for causal inference via multiple imputation","14 pages, 3 tables, 0 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  G-formula is a popular approach for estimating treatment or exposure effects
from longitudinal data that are subject to time-varying confounding. G-formula
estimation is typically performed by Monte-Carlo simulation, with
non-parametric bootstrapping used for inference. We show that G-formula can be
implemented by exploiting existing methods for multiple imputation (MI) for
synthetic data. This involves using an existing modified version of Rubin's
variance estimator. In practice missing data is ubiquitous in longitudinal
datasets. We show that such missing data can be readily accommodated as part of
the MI procedure, and describe how MI software can be used to implement the
approach. We explore its performance using a simulation study.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:32:49 GMT""}]","2023-01-31"
"2301.12027","Omar Sleem","Omar M.Sleem, M.E. Ashour, N.S. Aybat and Constantino M. Lagoa","Lp Quasi-norm Minimization: Algorithm and Applications",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Sparsity finds applications in areas as diverse as statistics, machine
learning, and signal processing. Computations over sparse structures are less
complex compared to their dense counterparts, and their storage consumes less
space. This paper proposes a heuristic method for retrieving sparse approximate
solutions of optimization problems via minimizing the $\ell_{p}$ quasi-norm,
where $0<p<1$. An iterative two-block ADMM algorithm for minimizing the
$\ell_{p}$ quasi-norm subject to convex constraints is proposed. For $p=s/q<1$,
$s,q \in \mathbb{Z}_{+}$, the proposed algorithm requires solving for the roots
of a scalar degree $2q$ polynomial as opposed to applying a soft thresholding
operator in the case of $\ell_{1}$. The merit of that algorithm relies on its
ability to solve the $\ell_{p}$ quasi-norm minimization subject to any convex
set of constraints. However, it suffers from low speed, due to a convex
projection step in each iteration, and the lack of mathematical convergence
guarantee. We then aim to vanquish these shortcomings by relaxing the
assumption on the constraints set to be the set formed due to convex and
differentiable, with Lipschitz continuous gradient, functions, i.e.
specifically, polytope sets. Using a proximal gradient step, we mitigate the
convex projection step and hence enhance the algorithm speed while proving its
convergence. We then present various applications where the proposed algorithm
excels, namely, matrix rank minimization, sparse signal reconstruction from
noisy measurements, sparse binary classification, and system identification.
The results demonstrate the significant gains obtained by the proposed
algorithm compared to those via $\ell_{1}$ minimization.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:43:05 GMT""}]","2023-01-31"
"2301.12028","Melissa Antonelli","Melissa Antonelli and Ugo Dal Lago and Davide Davoli and Isabel
  Oitavem and Paolo Pistone","An Arithmetic Theory for the Poly-Time Random Functions","37 pages, pre-print",,,,"cs.CC cs.LO","http://creativecommons.org/licenses/by/4.0/","  We introduce a new bounded theory RS^1_2 and show that the functions which
are Sigma^b_1-representable in it are precisely random functions which can be
computed in polynomial time. Concretely, we pass through a class of oracle
functions over string, called POR, together with the theory of arithmetic
RS^1_2. Then, we show that functions computed by poly-time PTMs are
arithmetically characterized by a class of probabilistic bounded formulas.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:45:18 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 20:40:21 GMT""}]","2023-02-08"
"2301.12029","Ivana Malenica","Ivana Malenica, Rachael V. Phillips, Daniel Lazzareschi, Jeremy R.
  Coyle, Romain Pirracchio, Mark J. van der Laan","Multi-task Highly Adaptive Lasso",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel, fully nonparametric approach for the multi-task learning,
the Multi-task Highly Adaptive Lasso (MT-HAL). MT-HAL simultaneously learns
features, samples and task associations important for the common model, while
imposing a shared sparse structure among similar tasks. Given multiple tasks,
our approach automatically finds a sparse sharing structure. The proposed MTL
algorithm attains a powerful dimension-free convergence rate of $o_p(n^{-1/4})$
or better. We show that MT-HAL outperforms sparsity-based MTL competitors
across a wide range of simulation studies, including settings with nonlinear
and linear relationships, varying levels of sparsity and task correlations, and
different numbers of covariates and sample size.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:46:57 GMT""}]","2023-01-31"
"2301.12030","Anand Jayarajan","Anand Jayarajan, Wei Zhao, Yudi Sun, Gennady Pekhimenko","TiLT: A Time-Centric Approach for Stream Query Optimization and
  Parallelization",,"Proceedings of the 28th ACM International Conference on
  Architectural Support for Programming Languages and Operating Systems, Volume
  2, 2023","10.1145/3575693.3575704",,"cs.DB cs.PL","http://creativecommons.org/licenses/by/4.0/","  Stream processing engines (SPEs) are widely used for large scale streaming
analytics over unbounded time-ordered data streams. Modern day streaming
analytics applications exhibit diverse compute characteristics and demand
strict latency and throughput requirements. Over the years, there has been
significant attention in building hardware-efficient stream processing engines
(SPEs) that support several query optimization, parallelization, and execution
strategies to meet the performance requirements of large scale streaming
analytics applications. However, in this work, we observe that these strategies
often fail to generalize well on many real-world streaming analytics
applications due to several inherent design limitations of current SPEs. We
further argue that these limitations stem from the shortcomings of the
fundamental design choices and the query representation model followed in
modern SPEs. To address these challenges, we first propose TiLT, a novel
intermediate representation (IR) that offers a highly expressive temporal query
language amenable to effective query optimization and parallelization
strategies. We subsequently build a compiler backend for TiLT that applies such
optimizations on streaming queries and generates hardware-efficient code to
achieve high performance on multi-core stream query executions. We demonstrate
that TiLT achieves up to 326x (20.49x on average) higher throughput compared to
state-of-the-art SPEs (e.g., Trill) across eight real-world streaming analytics
applications. TiLT source code is available at
https://github.com/ampersand-projects/tilt.git.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:50:12 GMT""}]","2023-01-31"
"2301.12031","Zhengliang Liu","Zhengliang Liu, Xinyu He, Lei Liu, Tianming Liu, Xiaoming Zhai","Context Matters: A Strategy to Pre-train Language Model for Science
  Education",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  This study aims at improving the performance of scoring student responses in
science education automatically. BERT-based language models have shown
significant superiority over traditional NLP models in various language-related
tasks. However, science writing of students, including argumentation and
explanation, is domain-specific. In addition, the language used by students is
different from the language in journals and Wikipedia, which are training
sources of BERT and its existing variants. All these suggest that a
domain-specific model pre-trained using science education data may improve
model performance. However, the ideal type of data to contextualize pre-trained
language model and improve the performance in automatically scoring student
written responses remains unclear. Therefore, we employ different data in this
study to contextualize both BERT and SciBERT models and compare their
performance on automatic scoring of assessment tasks for scientific
argumentation. We use three datasets to pre-train the model: 1) journal
articles in science education, 2) a large dataset of students' written
responses (sample size over 50,000), and 3) a small dataset of students'
written responses of scientific argumentation tasks. Our experimental results
show that in-domain training corpora constructed from science questions and
responses improve language model performance on a wide variety of downstream
tasks. Our study confirms the effectiveness of continual pre-training on
domain-specific data in the education domain and demonstrates a generalizable
strategy for automating science education tasks with high accuracy. We plan to
release our data and SciEdBERT models for public use and community engagement.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 23:50:16 GMT""}]","2023-01-31"
"2301.12032","Ali Borji","Ali Borji","BinaryVQA: A Versatile Test Set to Evaluate the Out-of-Distribution
  Generalization of VQA Models",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  We introduce a new test set for visual question answering (VQA) called
BinaryVQA to push the limits of VQA models. Our dataset includes 7,800
questions across 1,024 images and covers a wide variety of objects, topics, and
concepts. For easy model evaluation, we only consider binary questions.
Questions and answers are formulated and verified carefully and manually.
Around 63% of the questions have positive answers. The median number of
questions per image and question length are 7 and 5, respectively. The state of
the art OFA model achieves 75% accuracy on BinaryVQA dataset, which is
significantly lower than its performance on the VQA v2 test-dev dataset
(94.7%). We also analyze the model behavior along several dimensions including:
a) performance over different categories such as text, counting and gaze
direction, b) model interpretability, c) the effect of question length on
accuracy, d) bias of models towards positive answers and introduction of a new
score called the ShuffleAcc, and e) sensitivity to spelling and grammar errors.
Our investigation demonstrates the difficulty of our dataset and shows that it
can challenge VQA models for next few years. Data and code are publicly
available at: DATA and CODE.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:03:44 GMT""}]","2023-01-31"
"2301.12033","Tomer Galanti","Tomer Galanti, Mengjia Xu, Liane Galanti, Tomaso Poggio","Norm-based Generalization Bounds for Compositionally Sparse Neural
  Networks",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the Rademacher complexity of deep sparse neural
networks, where each neuron receives a small number of inputs. We prove
generalization bounds for multilayered sparse ReLU neural networks, including
convolutional neural networks. These bounds differ from previous ones, as they
consider the norms of the convolutional filters instead of the norms of the
associated Toeplitz matrices, independently of weight sharing between neurons.
  As we show theoretically, these bounds may be orders of magnitude better than
standard norm-based generalization bounds and empirically, they are almost
non-vacuous in estimating generalization in various simple classification
problems. Taken together, these results suggest that compositional sparsity of
the underlying target function is critical to the success of deep neural
networks.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:06:22 GMT""}]","2023-01-31"
"2301.12034","Kosuke Nakayama","Takemi Kato, Yongkai Li, Min Liu, Kosuke Nakayama, Zhiwei Wang, Seigo
  Souma, Miho Kitamura, Koji Horiba, Hiroshi Kumigashira, Takashi Takahashi,
  Yugui Yao, and Takafumi Sato","Surface-termination-dependent electronic states in kagome
  superconductors AV3Sb5 (A = K, Rb, Cs) studied by micro-ARPES","10 pages, 8 figures",,,,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Recently discovered kagome superconductors AV3Sb5 (A = K, Rb, Cs) exhibit
exotic bulk and surface physical properties such as charge-density wave (CDW)
and chirality, whereas their origins remain unresolved. By using micro-focused
angle-resolved photoemission spectroscopy, we discovered that AV3Sb5 commonly
exhibits two distinct polar surfaces depending on the termination; electron-
and hole-doped ones for the A- and Sb-termination, respectively. We observed
that the kagome-derived band shows a clear splitting in the A-terminated
surface while it is absent in the Sb-terminated counterpart, indicative of the
polarity-dependent CDW at the surface. Close comparison of the band-dependent
splitting reveals that the three-dimensional CDW structure of the K-terminated
surface is different from that of the Rb- or Cs-terminated surface, suggesting
the diversity of the CDW ground state. These results provide important insight
into the origin of CDW in kagome superconductors AV3Sb5.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:11:24 GMT""}]","2023-01-31"
"2301.12035","Diana Marcela Viveros Melo","Diana M. V. Melo, Lukas T. N. Landau, Rodrigo C. de Lamare","State Machine-based Waveforms for Channels With 1-Bit Quantization and
  Oversampling With Time-Instance Zero-Crossing Modulation",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systems with 1-bit quantization and oversampling are promising for the
Internet of Things (IoT) devices in order to reduce the power consumption of
the analog-to-digital-converters. The novel time-instance zero-crossing (TI ZX)
modulation is a promising approach for this kind of channels but existing
studies rely on optimization problems with high computational complexity and
delay. In this work, we propose a practical waveform design based on the
established TI ZX modulation for a multiuser multi-input multi-output (MIMO)
downlink scenario with 1-bit quantization and temporal oversampling at the
receivers. In this sense, the proposed temporal transmit signals are
constructed by concatenating segments of coefficients which convey the
information into the time-instances of zero-crossings according to the TI ZX
mapping rules. The proposed waveform design is compared with other methods from
the literature. The methods are compared in terms of bit error rate and
normalized power spectral density. Numerical results show that the proposed
technique is suitable for multiuser MIMO system with 1-bit quantization while
tolerating some small amount of out-of-band radiation.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:20:01 GMT""},{""version"":""v2"",""created"":""Sat, 4 Feb 2023 00:40:38 GMT""},{""version"":""v3"",""created"":""Thu, 16 Mar 2023 15:42:01 GMT""}]","2023-03-17"
"2301.12036","Diyi Liu","Diyi Liu, Lanmin Liu, Lee D Han","Analyzing Robustness of the Deep Reinforcement Learning Algorithm in
  Ramp Metering Applications Considering False Data Injection Attack and
  Defense","15 pages, 6 figures",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Decades of practices of ramp metering, by controlling downstream volume and
smoothing the interweaving traffic, have proved that ramp metering can decrease
total travel time, mitigate shockwaves, decrease rear-end collisions, reduce
pollution, etc. Besides traditional methods like ALIENA algorithms, Deep
Reinforcement Learning algorithms have been established recently to build finer
control on ramp metering. However, those Deep Learning models may be venerable
to adversarial attacks. Thus, it is important to investigate the robustness of
those models under False Data Injection adversarial attack. Furthermore,
algorithms capable of detecting anomaly data from clean data are the key to
safeguard Deep Learning algorithm. In this study, an online algorithm that can
distinguish adversarial data from clean data are tested. Results found that in
most cases anomaly data can be distinguished from clean data, although their
difference is too small to be manually distinguished by humans. In practice,
whenever adversarial/hazardous data is detected, the system can fall back to a
fixed control program, and experts should investigate the detectors status or
security protocols afterwards before real damages happen.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:40:46 GMT""}]","2023-01-31"
"2301.12037","Gabriel Regnault","Gabriel Regnault, Mitchell A. Kirby, Ruikang K. Wang, Tueng T. Shen,
  Matthew O'Donnell and Ivan Pelivanov","Possible depth-resolved reconstruction of shear moduli in the cornea
  following collagen crosslinking (CXL) with optical coherence tomography and
  elastography","Main: 10 Pages, 6 Figures Supplemental: 12 Pages, 3 Figures",,,,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Collagen crosslinking of the cornea (CXL) is commonly employed to prevent or
treat keratoconus. Although the change of corneal stiffness induced by CXL
surgery can be monitored with non-contact dynamic Optical Coherence
Elastography (OCE) by tracking mechanical wave propagation, the depth
dependence of this change is still unclear if the cornea is not crosslinked
through the whole depth. Here we propose to combine phase-decorrelation
measurement applied to OCT structural images and acoustic micro-tapping
(A$\mu$T) OCE to explore possible depth reconstruction of stiffness within
crosslinked corneas in an ex vivo human cornea sample. The analysis of
experimental OCT images is used to define the penetration depth of CXL into the
cornea, which varies from $\sim$100$\mu m$ in the periphery to $\sim$150$\mu m$
in the central area and exhibits a sharp transition between areas. This
information was used in a two-layer analytical model to quantify the stiffness
of the treated layer. We also discuss how the elastic moduli of partially
CXL-treated cornea layers reconstructed from OCE measurements reflect the
effective mechanical stiffness of the entire cornea to properly quantify
surgical outcome.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:44:05 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 22:17:41 GMT""}]","2023-04-27"
"2301.12038","Amrit Singh Bedi","Souradip Chakraborty, Amrit Singh Bedi, Alec Koppel, Mengdi Wang,
  Furong Huang, Dinesh Manocha","STEERING: Stein Information Directed Exploration for Model-Based
  Reinforcement Learning",,,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Directed Exploration is a crucial challenge in reinforcement learning (RL),
especially when rewards are sparse. Information-directed sampling (IDS), which
optimizes the information ratio, seeks to do so by augmenting regret with
information gain. However, estimating information gain is computationally
intractable or relies on restrictive assumptions which prohibit its use in many
practical instances. In this work, we posit an alternative exploration
incentive in terms of the integral probability metric (IPM) between a current
estimate of the transition model and the unknown optimal, which under suitable
conditions, can be computed in closed form with the kernelized Stein
discrepancy (KSD). Based on KSD, we develop a novel algorithm STEERING:
\textbf{STE}in information dir\textbf{E}cted exploration for model-based
\textbf{R}einforcement Learn\textbf{ING}. To enable its derivation, we develop
fundamentally new variants of KSD for discrete conditional distributions. We
further establish that STEERING archives sublinear Bayesian regret, improving
upon prior learning rates of information-augmented MBRL, IDS included.
Experimentally, we show that the proposed algorithm is computationally
affordable and outperforms several prior approaches.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:49:28 GMT""}]","2023-01-31"
"2301.12039","Marwan Omar Dr","Marwan Omar","Harnessing the Power of Decision Trees to Detect IoT Malware",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Due to its simple installation and connectivity, the Internet of Things (IoT)
is susceptible to malware attacks. Being able to operate autonomously. As IoT
devices have become more prevalent, they have become the most tempting targets
for malware. Weak, guessable, or hard-coded passwords, and a lack of security
measures contribute to these vulnerabilities along with insecure network
connections and outdated update procedures. To understand IoT malware, current
methods and analysis ,using static methods, are ineffective. The field of deep
learning has made great strides in recent years due to their tremendous data
mining, learning, and expression capabilities, cybersecurity has enjoyed
tremendous growth in recent years. As a result, malware analysts will not have
to spend as much time analyzing malware. In this paper, we propose a novel
detection and analysis method that harnesses the power and simplicity of
decision trees. The experiments are conducted using a real word dataset,
MaleVis which is a publicly available dataset. Based on the results, we show
that our proposed approach outperforms existing state-of-the-art solutions in
that it achieves 97.23% precision and 95.89% recall in terms of detection and
classification. A specificity of 96.58%, F1-score of 96.40%, an accuracy of
96.43.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:56:10 GMT""}]","2023-01-31"
"2301.12040","Minghao Xu","Minghao Xu, Xinyu Yuan, Santiago Miret, Jian Tang","ProtST: Multi-Modality Learning of Protein Sequences and Biomedical
  Texts","Research project paper",,,,"q-bio.BM cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current protein language models (PLMs) learn protein representations mainly
based on their sequences, thereby well capturing co-evolutionary information,
but they are unable to explicitly acquire protein functions, which is the end
goal of protein representation learning. Fortunately, for many proteins, their
textual property descriptions are available, where their various functions are
also described. Motivated by this fact, we first build the ProtDescribe dataset
to augment protein sequences with text descriptions of their functions and
other important properties. Based on this dataset, we propose the ProtST
framework to enhance Protein Sequence pre-training and understanding by
biomedical Texts. During pre-training, we design three types of tasks, i.e.,
unimodal mask prediction, multimodal representation alignment and multimodal
mask prediction, to enhance a PLM with protein property information with
different granularities and, at the same time, preserve the PLM's original
representation power. On downstream tasks, ProtST enables both supervised
learning and zero-shot prediction. We verify the superiority of ProtST-induced
PLMs over previous ones on diverse representation learning benchmarks. Under
the zero-shot setting, we show the effectiveness of ProtST on zero-shot protein
classification, and ProtST also enables functional protein retrieval from a
large-scale database without any function annotation.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 00:58:48 GMT""}]","2023-01-31"
"2301.12041","Ningkun Zheng","Joshua Jaworski, Ningkun Zheng, Matthias Preindl, Bolun Xu","Vehicle-to-Grid Fleet Service Provision considering Nonlinear Battery
  Behaviors",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The surging adoption of electric vehicles (EV) calls for accurate and
efficient approaches to coordinate with the power grid operation. By being
responsive to distribution grid limits and time-varying electricity prices, EV
charging stations can minimize their charging costs while aiding grid operation
simultaneously. In this study, we investigate the economic benefit of
vehicle-to-grid (V2G) using real-time price data from New York State and a
real-world charging network dataset. We incorporate nonlinear battery models
and price uncertainty into the V2G management design to provide a realistic
estimation of cost savings from different V2G options. The proposed control
method is computationally tractable when scaling up to real-world applications.
We show that our proposed algorithm leads to an average of 35% charging cost
savings compared to uncontrolled charging when considering unidirectional
charging, and bi-directional V2G enables additional 18% cost savings compared
to unidirectional smart charging. Our result also shows the importance of using
more accurate nonlinear battery models in V2G controllers and evaluating the
cost of price uncertainties over V2G.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:15:01 GMT""}]","2023-01-31"
"2301.12042","Masanori Tomonaga","Masanori Tomonaga, Masumi Kasai, and Toshifumi Futamase","The gauge-invariant formulation of the local expansion rate driven by
  the local average density in an inhomogeneous universe","12 pages, this article supersedes arXiv:2203.14435",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The Hubble tension casts a blight on the standard cosmology. As a possible
solution to the problem, the local variation of the expansion rate has been
proposed where the spatial averaging over a finite domain was introduced in
order to restore the local Friedmannian behavior in an inhomogeneous cosmology.
So far, however, the approaches are limited to the particular choices of the
gauges, and it has been unclear whether the results are gauge-invariant. In
this paper, we present the gauge-invariant formulation of the local expansion
rate which is driven by the spatial average of the gauge-invariant
inhomogeneous density. We show that the local cosmological parameters in the
finite domain may change from the global parameters, and the relations between
them are expressed by the gauge-invariant averaged density.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:28:11 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 03:37:22 GMT""}]","2023-02-01"
"2301.12043","Omar Sleem","Omar M.Sleem and Constantino M. Lagoa","Parsimonious System Identification from Fragmented Quantized
  Measurements",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  Quantization is the process of mapping an input signal from an infinite
continuous set to a countable set with a finite number of elements. It is a
non-linear irreversible process, which makes the traditional methods of system
identification no longer applicable. In this work, we propose a method for
parsimonious linear time invariant system identification when only quantized
observations, discerned from noisy data, are available. More formally, given a
priori information on the system, represented by a compact set containing the
poles of the system, and quantized realizations, our algorithm aims at
identifying the least order system that is compatible with the available
information. The proposed approach takes also into account that the available
data can be subject to fragmentation. Our proposed algorithm relies on an ADMM
approach to solve a $\ell_{p},(0<p<1),$ quasi-norm objective problem. Numerical
results highlight the performance of the proposed approach when compared to the
$\ell_{1}$ minimization in terms of the sparsity of the induced solution.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:31:44 GMT""}]","2023-01-31"
"2301.12044","Nick Doudchenko","Aiyou Chen, Nick Doudchenko, Shunhua Jiang, Cliff Stein, Bicheng Ying","Supergeo Design: Generalized Matching for Geographic Experiments",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a generalization of the standard matched pairs design in which
experimental units (often geographic regions or geos) may be combined into
larger units/regions called ""supergeos"" in order to improve the average
matching quality. Unlike optimal matched pairs design which can be found in
polynomial time (Lu et al. 2011), this generalized matching problem is NP-hard.
We formulate it as a mixed-integer program (MIP) and show that experimental
design obtained by solving this MIP can often provide a significant improvement
over the standard design regardless of whether the treatment effects are
homogeneous or heterogeneous. Furthermore, we present the conditions under
which trimming techniques that often improve performance in the case of
homogeneous effects (Chen and Au, 2022), may lead to biased estimates and show
that the proposed design does not introduce such bias. We use empirical studies
based on real-world advertising data to illustrate these findings.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:36:12 GMT""}]","2023-01-31"
"2301.12045","Lei Shi","Lei Shi, Jingshen Wang and Peng Ding","Forward screening and post-screening inference in factorial designs","62 pages, 3 figures",,,,"stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Ever since the seminal work of R. A. Fisher and F. Yates, factorial designs
have been an important experimental tool to simultaneously estimate the
treatment effects of multiple factors. In factorial designs, the number of
treatment levels may grow exponentially with the number of factors, which
motivates the forward screening strategy based on the sparsity, hierarchy, and
heredity principles for factorial effects. Although this strategy is intuitive
and has been widely used in practice, its rigorous statistical theory has not
been formally established. To fill this gap, we establish design-based theory
for forward factor screening in factorial designs based on the potential
outcome framework. We not only prove its consistency property but also discuss
statistical inference after factor screening. In particular, with perfect
screening, we quantify the advantages of forward screening based on asymptotic
efficiency gain in estimating factorial effects. With imperfect screening in
higher-order interactions, we propose two novel strategies and investigate
their impact on subsequent inference. Our formulation differs from the existing
literature on variable selection and post-selection inference because our
theory is based solely on the physical randomization of the factorial design
and does not rely on a correctly-specified outcome model.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:44:36 GMT""}]","2023-01-31"
"2301.12046","Kun He Prof.","Yasmeen M. Khedr, Yifeng Xiong, Kun He","Semantic Adversarial Attacks on Face Recognition through Significant
  Attributes","13 pages, 8 figures, 3 tables",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face recognition is known to be vulnerable to adversarial face images.
Existing works craft face adversarial images by indiscriminately changing a
single attribute without being aware of the intrinsic attributes of the images.
To this end, we propose a new Semantic Adversarial Attack called SAA-StarGAN
that tampers with the significant facial attributes for each image. We predict
the most significant attributes by applying the cosine similarity or
probability score. The probability score method is based on training a Face
Verification model for an attribute prediction task to obtain a class
probability score for each attribute. The prediction process will help craft
adversarial face images more easily and efficiently, as well as improve the
adversarial transferability. Then, we change the most significant facial
attributes, with either one or more of the facial attributes for impersonation
and dodging attacks in white-box and black-box settings. Experimental results
show that our method could generate diverse and realistic adversarial face
images meanwhile avoid affecting human perception of the face recognition.
SAA-StarGAN achieves an 80.5% attack success rate against black-box models,
outperforming existing methods by 35.5% under the impersonation attack.
Concerning the black-box setting, SAA-StarGAN achieves high attack success
rates on various models. The experiments confirm that predicting the most
important attributes significantly affects the success of adversarial attacks
in both white-box and black-box settings and could enhance the transferability
of the crafted adversarial examples.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:50:35 GMT""}]","2023-01-31"
"2301.12047","Ferdinando Fioretto","James Kotary, My H. Dinh, Ferdinando Fioretto","Folded Optimization for End-to-End Model-Based Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The integration of constrained optimization models as components in deep
networks has led to promising advances in both these domains. A primary
challenge in this setting is backpropagation through the optimization mapping,
which typically lacks a closed form. A common approach is unrolling, which
relies on automatic differentiation through the operations of an iterative
solver. While flexible and general, unrolling can encounter accuracy and
efficiency issues in practice. These issues can be avoided by differentiating
the optimization mapping analytically, but current frameworks impose rigid
requirements on the optimization problem's form. This paper provides
theoretical insights into the backpropagation of unrolled optimizers, which
lead to a system for generating equivalent but efficiently solvable analytical
models. Additionally, it proposes a unifying view of unrolling and analytical
differentiation through constrained optimization mappings. Experiments over
various structured prediction and decision-focused learning tasks illustrate
the potential of the approach both computationally and in terms of enhanced
expressiveness.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:50:42 GMT""}]","2023-01-31"
"2301.12048","Yizhou Wang","Yizhou Wang, Can Qin, Yue Bai, Yi Xu, Xu Ma, Yun Fu","Making Reconstruction-based Method Great Again for Video Anomaly
  Detection","Accepted by ICDM 2022",,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Anomaly detection in videos is a significant yet challenging problem.
Previous approaches based on deep neural networks employ either
reconstruction-based or prediction-based approaches. Nevertheless, existing
reconstruction-based methods 1) rely on old-fashioned convolutional
autoencoders and are poor at modeling temporal dependency; 2) are prone to
overfit the training samples, leading to indistinguishable reconstruction
errors of normal and abnormal frames during the inference phase. To address
such issues, firstly, we get inspiration from transformer and propose ${\textbf
S}$patio-${\textbf T}$emporal ${\textbf A}$uto-${\textbf T}$rans-${\textbf
E}$ncoder, dubbed as $\textbf{STATE}$, as a new autoencoder model for enhanced
consecutive frame reconstruction. Our STATE is equipped with a specifically
designed learnable convolutional attention module for efficient temporal
learning and reasoning. Secondly, we put forward a novel reconstruction-based
input perturbation technique during testing to further differentiate anomalous
frames. With the same perturbation magnitude, the testing reconstruction error
of the normal frames lowers more than that of the abnormal frames, which
contributes to mitigating the overfitting problem of reconstruction. Owing to
the high relevance of the frame abnormality and the objects in the frame, we
conduct object-level reconstruction using both the raw frame and the
corresponding optical flow patches. Finally, the anomaly score is designed
based on the combination of the raw and motion reconstruction errors using
perturbed inputs. Extensive experiments on benchmark video anomaly detection
datasets demonstrate that our approach outperforms previous
reconstruction-based methods by a notable margin, and achieves state-of-the-art
anomaly detection performance consistently. The code is available at
https://github.com/wyzjack/MRMGA4VAD.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:57:57 GMT""}]","2023-01-31"
"2301.12049","Yukihiro Matsubayashi","Yukihiro Matsubayashi, Yusuke Masaki and Hiroaki Matsueda","Photoinduced pseudospin-wave emission from charge-density-wave domain
  wall with superconductivity","11 pages, 5 figures",,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study photoinduced dynamics triggered by an inhomogeneity due to
competition between charge density waves (CDWs) and superconductivity. As a
simple example, we consider the superconducting (SC) interface between two CDW
domains with opposite signs. The real-time dynamics are calculated within the
time-dependent Hartree--Fock--Bogoliubov framework, where the order parameter
dynamics and the nonequilibrium quasiparticle distribution functions are
studied. We also calculate the various dynamical response functions within a
generalized random phase approximation. Through comparisons between the real
time dynamics and the analysis of the response functions, it is found that the
photo-driven SC interface can emit collective modes of the SC order parameter.
This is analogous to the spin wave emission from the magnetic domain wall in an
antiferromagnet, particularly in the case of a low driving frequency, where the
order parameters can be mapped onto the pseudospin picture. In the
high-frequency case, we find a domain wall melting caused by changes in the
quasiparticle distribution, which induces superconductivity in the whole
system.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 01:58:48 GMT""}]","2023-01-31"
"2301.12050","Kolby Nottingham","Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi,
  Hannaneh Hajishirzi, Sameer Singh, Roy Fox","Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making
  using Language Guided World Modelling","in proceedings of ICML 23",,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) agents typically learn tabula rasa, without prior
knowledge of the world. However, if initialized with knowledge of high-level
subgoals and transitions between subgoals, RL agents could utilize this
Abstract World Model (AWM) for planning and exploration. We propose using
few-shot large language models (LLMs) to hypothesize an AWM, that will be
verified through world experience, to improve sample efficiency of RL agents.
Our DECKARD agent applies LLM-guided exploration to item crafting in Minecraft
in two phases: (1) the Dream phase where the agent uses an LLM to decompose a
task into a sequence of subgoals, the hypothesized AWM; and (2) the Wake phase
where the agent learns a modular policy for each subgoal and verifies or
corrects the hypothesized AWM. Our method of hypothesizing an AWM with LLMs and
then verifying the AWM based on agent experience not only increases sample
efficiency over contemporary methods by an order of magnitude but is also
robust to and corrects errors in the LLM, successfully blending noisy
internet-scale information from LLMs with knowledge grounded in environment
dynamics.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:04:07 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 15:14:01 GMT""}]","2023-04-28"
"2301.12051","Samuel Kim","Willie Kang, Sean Kim, Eliot Yoo, Samuel Kim","Predicting Students' Exam Scores Using Physiological Signals","submitted to EMBC 2023",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  While acute stress has been shown to have both positive and negative effects
on performance, not much is known about the impacts of stress on students
grades during examinations. To answer this question, we examined whether a
correlation could be found between physiological stress signals and exam
performance. We conducted this study using multiple physiological signals of
ten undergraduate students over three different exams. The study focused on
three signals, i.e., skin temperature, heart rate, and electrodermal activity.
We extracted statistics as features and fed them into a variety of binary
classifiers to predict relatively higher or lower grades. Experimental results
showed up to 0.81 ROC-AUC with k-nearest neighbor algorithm among various
machine learning algorithms.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:04:34 GMT""}]","2023-01-31"
"2301.12052","Yunjuan Wang","Gui Citovsky, Giulia DeSalvo, Sanjiv Kumar, Srikumar Ramalingam,
  Afshin Rostamizadeh, Yunjuan Wang","Leveraging Importance Weights in Subset Selection","ICLR 2023",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  We present a subset selection algorithm designed to work with arbitrary model
families in a practical batch setting. In such a setting, an algorithm can
sample examples one at a time but, in order to limit overhead costs, is only
able to update its state (i.e. further train model weights) once a large enough
batch of examples is selected. Our algorithm, IWeS, selects examples by
importance sampling where the sampling probability assigned to each example is
based on the entropy of models trained on previously selected batches. IWeS
admits significant performance improvement compared to other subset selection
algorithms for seven publicly available datasets. Additionally, it is
competitive in an active learning setting, where the label information is not
available at selection time. We also provide an initial theoretical analysis to
support our importance weighting approach, proving generalization and sampling
rate bounds.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:07:31 GMT""}]","2023-01-31"
"2301.12053","Juan Wang","Juan Wang and Bin Xia","Weakly Supervised Image Segmentation Beyond Tight Bounding Box
  Annotations","16 pages, 8 figures, 4 tables, under review",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Weakly supervised image segmentation approaches in the literature usually
achieve high segmentation performance using tight bounding box supervision and
decrease the performance greatly when supervised by loose bounding boxes.
However, compared with loose bounding box, it is much more difficult to acquire
tight bounding box due to its strict requirements on the precise locations of
the four sides of the box. To resolve this issue, this study investigates
whether it is possible to maintain good segmentation performance when loose
bounding boxes are used as supervision. For this purpose, this work extends our
previous parallel transformation based multiple instance learning (MIL) for
tight bounding box supervision by integrating an MIL strategy based on polar
transformation to assist image segmentation. The proposed polar transformation
based MIL formulation works for both tight and loose bounding boxes, in which a
positive bag is defined as pixels in a polar line of a bounding box with one
endpoint located inside the object enclosed by the box and the other endpoint
located at one of the four sides of the box. Moreover, a weighted smooth
maximum approximation is introduced to incorporate the observation that pixels
closer to the origin of the polar transformation are more likely to belong to
the object in the box. The proposed approach was evaluated on two public
datasets using dice coefficient when bounding boxes at different precision
levels were considered in the experiments. The results demonstrate that the
proposed approach achieves state-of-the-art performance for bounding boxes at
all precision levels and is robust to mild and moderate errors in the loose
bounding box annotations. The codes are available at
\url{https://github.com/wangjuan313/wsis-beyond-tightBB}.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:11:36 GMT""}]","2023-01-31"
"2301.12054","Abhinit Kumar Ambastha","Abhinit Kumar Ambastha, Leong Tze Yun","Adversarial Learning Networks: Source-free Unsupervised Domain
  Incremental Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents an approach for incrementally updating deep neural network
(DNN) models in a non-stationary environment. DNN models are sensitive to
changes in input data distribution, which limits their application to problem
settings with stationary input datasets. In a non-stationary environment,
updating a DNN model requires parameter re-training or model fine-tuning. We
propose an unsupervised source-free method to update DNN classification models.
The contributions of this work are two-fold. First, we use trainable Gaussian
prototypes to generate representative samples for future iterations; second,
using unsupervised domain adaptation, we incrementally adapt the existing model
using unlabelled data. Unlike existing methods, our approach can update a DNN
model incrementally for non-stationary source and target tasks without storing
past training data. We evaluated our work on incremental sentiment prediction
and incremental disease prediction applications and compared our approach to
state-of-the-art continual learning, domain adaptation, and ensemble learning
methods. Our results show that our approach achieved improved performance
compared to existing incremental learning methods. We observe minimal
forgetting of past knowledge over many iterations, which can help us develop
unsupervised self-learning systems.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:16:13 GMT""}]","2023-01-31"
"2301.12055","Abhinit Kumar Ambastha","Abhinit Kumar Ambastha, Leong Tze Yun","TIDo: Source-free Task Incremental Learning in Non-stationary
  Environments",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents an incremental learning approach for autonomous agents to
learn new tasks in a non-stationary environment. Updating a DNN model-based
agent to learn new target tasks requires us to store past training data and
needs a large labeled target task dataset. Few-shot task incremental learning
methods overcome the limitation of labeled target datasets by adapting trained
models to learn private target classes using a few labeled representatives and
a large unlabeled target dataset. However, the methods assume that the source
and target tasks are stationary. We propose a one-shot task incremental
learning approach that can adapt to non-stationary source and target tasks. Our
approach minimizes adversarial discrepancy between the model's feature space
and incoming incremental data to learn an updated hypothesis. We also use
distillation loss to reduce catastrophic forgetting of previously learned
tasks. Finally, we use Gaussian prototypes to generate exemplar instances
eliminating the need to store past training data. Unlike current work in task
incremental learning, our model can learn both source and target task updates
incrementally. We evaluate our method on various problem settings for
incremental object detection and disease prediction model update. We evaluate
our approach by measuring the performance of shared class and target private
class prediction. Our results show that our approach achieved improved
performance compared to existing state-of-the-art task incremental learning
methods.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:19:45 GMT""}]","2023-01-31"
"2301.12056","Qitong Gao","Qitong Gao, Ge Gao, Min Chi, Miroslav Pajic","Variational Latent Branching Model for Off-Policy Evaluation","Accepted to ICLR 2023",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Model-based methods have recently shown great potential for off-policy
evaluation (OPE); offline trajectories induced by behavioral policies are
fitted to transitions of Markov decision processes (MDPs), which are used to
rollout simulated trajectories and estimate the performance of policies.
Model-based OPE methods face two key challenges. First, as offline trajectories
are usually fixed, they tend to cover limited state and action space. Second,
the performance of model-based methods can be sensitive to the initialization
of their parameters. In this work, we propose the variational latent branching
model (VLBM) to learn the transition function of MDPs by formulating the
environmental dynamics as a compact latent space, from which the next states
and rewards are then sampled. Specifically, VLBM leverages and extends the
variational inference framework with the recurrent state alignment (RSA), which
is designed to capture as much information underlying the limited training
data, by smoothing out the information flow between the variational (encoding)
and generative (decoding) part of VLBM. Moreover, we also introduce the
branching architecture to improve the model's robustness against randomly
initialized model weights. The effectiveness of the VLBM is evaluated on the
deep OPE (DOPE) benchmark, from which the training trajectories are designed to
result in varied coverage of the state-action space. We show that the VLBM
outperforms existing state-of-the-art OPE methods in general.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:20:03 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 01:21:06 GMT""},{""version"":""v3"",""created"":""Wed, 1 Feb 2023 01:57:10 GMT""},{""version"":""v4"",""created"":""Fri, 3 Feb 2023 17:10:40 GMT""}]","2023-02-06"
"2301.12057","Kaijie Zhao","Kaijie Zhao, Haitao Zhao, Zhongze Wang, Jingchao Peng, Zhengwei Hu","Object Preserving Siamese Network for Single Object Tracking on Point
  Clouds",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Obviously, the object is the key factor of the 3D single object tracking
(SOT) task. However, previous Siamese-based trackers overlook the negative
effects brought by randomly dropped object points during backbone sampling,
which hinder trackers to predict accurate bounding boxes (BBoxes). Exploring an
approach that seeks to maximize the preservation of object points and their
object-aware features is of particular significance. Motivated by this, we
propose an Object Preserving Siamese Network
  (OPSNet), which can significantly maintain object integrity and boost
tracking performance. Firstly, the object highlighting module enhances the
object-aware features and extracts discriminative features from template and
search area. Then, the object-preserved sampling selects object candidates to
obtain object-preserved search area seeds and drop the background points that
contribute less to tracking. Finally, the object localization network precisely
locates 3D BBoxes based on the object-preserved search area seeds. Extensive
experiments demonstrate our method outperforms the state-of-the-art performance
(9.4% and 2.5% success gain on KITTI and Waymo Open Dataset respectively).
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:21:31 GMT""}]","2023-01-31"
"2301.12058","Liya Wang","Liya Wang, Alex Tien","Aerial Image Object Detection With Vision Transformer Detector (ViTDet)",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The past few years have seen an increased interest in aerial image object
detection due to its critical value to large-scale geo-scientific research like
environmental studies, urban planning, and intelligence monitoring. However,
the task is very challenging due to the birds-eye view perspective, complex
backgrounds, large and various image sizes, different appearances of objects,
and the scarcity of well-annotated datasets. Recent advances in computer vision
have shown promise tackling the challenge. Specifically, Vision Transformer
Detector (ViTDet) was proposed to extract multi-scale features for object
detection. The empirical study shows that ViTDet's simple design achieves good
performance on natural scene images and can be easily embedded into any
detector architecture. To date, ViTDet's potential benefit to challenging
aerial image object detection has not been explored. Therefore, in our study,
25 experiments were carried out to evaluate the effectiveness of ViTDet for
aerial image object detection on three well-known datasets: Airbus Aircraft,
RarePlanes, and Dataset of Object DeTection in Aerial images (DOTA). Our
results show that ViTDet can consistently outperform its convolutional neural
network counterparts on horizontal bounding box (HBB) object detection by a
large margin (up to 17% on average precision) and that it achieves the
competitive performance for oriented bounding box (OBB) object detection. Our
results also establish a baseline for future research.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:25:30 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 18:36:49 GMT""}]","2023-02-03"
"2301.12059","Janakiraman Balachandran","Soumya Sanyal, Arun Kumar Sagotra, Narendra Kumar, Sharad Rathi,
  Mohana Krishna, Nagesh Somayajula, Duraivelan Palanisamy, Ram R. Ratnakar,
  Suchismita Sanyal, Partha Talukdar, Umesh Waghmare and Janakiraman
  Balachandran","Potential energy surface prediction of Alumina polymorphs using graph
  neural network",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The process of design and discovery of new materials can be significantly
expedited and simplified if we can learn effectively from available data. Deep
learning (DL) approaches have recently received a lot of interest for their
ability to speed up the design of novel materials by predicting material
properties with precision close to experiments and ab-initio calculations. The
application of deep learning to predict materials properties measured by
experiments are valuable yet challenging due to the limited amount of
experimental data. Most of the existing approaches to predict properties from
computational data have also been directed towards specific material
properties. In this work, we extend this approach, by proposing Landscape
Crystal Graph Convolution Network(LCGCN), an accurate and transferable deep
learning framework based on graph convolutional networks. LCGCN directly learns
the potential energy surface (PES) from atomic configurations. This approach
can enable transferable models that can predict different material properties.
We apply this framework to bulk crystals (i.e. Al2O3), and test it by
calculating potential energy surfaces at different temperatures and across
different phases of crystal.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:27:47 GMT""}]","2023-01-31"
"2301.12060","Fengxia Liu","Zhiyong Zheng and Fengxia Liu and Kun Tian","An Unbounded Fully Homomorphic Encryption Scheme Based on Ideal Lattices
  and Chinese Remainder Theorem","NO",,,,"cs.CR math.RA","http://creativecommons.org/licenses/by/4.0/","  We propose an unbounded fully homomorphic encryption scheme, i.e. a scheme
that allows one to compute on encrypted data for any desired functions without
needing to decrypt the data or knowing the decryption keys. This is a rational
solution to an old problem proposed by Rivest, Adleman, and Dertouzos \cite{32}
in 1978, and to some new problems appeared in Peikert \cite{28} as open
questions 10 and open questions 11 a few years ago. Our scheme is completely
different from the breakthrough work \cite{14,15} of Gentry in 2009. Gentry's
bootstrapping technique constructs a fully homomorphic encryption (FHE) scheme
from a somewhat homomorphic one that is powerful enough to evaluate its own
decryption function. To date, it remains the only known way of obtaining
unbounded FHE. Our construction of unbounded FHE scheme is straightforward and
noise-free that can handle unbounded homomorphic computation on any refreshed
ciphertexts without bootstrapping transformation technique.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:29:18 GMT""}]","2023-01-31"
"2301.12061","Fengjiao Li","Fengjiao Li, Xingyu Zhou, and Bo Ji","(Private) Kernelized Bandits with Distributed Biased Feedback","This work has been accepted by ACM SIGMETRICS 2023",,,,"cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study kernelized bandits with distributed biased feedback.
This problem is motivated by several real-world applications (such as dynamic
pricing, cellular network configuration, and policy making), where users from a
large population contribute to the reward of the action chosen by a central
entity, but it is difficult to collect feedback from all users. Instead, only
biased feedback (due to user heterogeneity) from a subset of users may be
available. In addition to such partial biased feedback, we are also faced with
two practical challenges due to communication cost and computation complexity.
To tackle these challenges, we carefully design a new \emph{distributed
phase-then-batch-based elimination (\texttt{DPBE})} algorithm, which samples
users in phases for collecting feedback to reduce the bias and employs
\emph{maximum variance reduction} to select actions in batches within each
phase. By properly choosing the phase length, the batch size, and the
confidence width used for eliminating suboptimal actions, we show that
\texttt{DPBE} achieves a sublinear regret of
$\tilde{O}(T^{1-\alpha/2}+\sqrt{\gamma_T T})$, where $\alpha\in (0,1)$ is the
user-sampling parameter one can tune. Moreover, \texttt{DPBE} can significantly
reduce both communication cost and computation complexity in distributed
kernelized bandits, compared to some variants of the state-of-the-art
algorithms (originally developed for standard kernelized bandits). Furthermore,
by incorporating various \emph{differential privacy} models (including the
central, local, and shuffle models), we generalize \texttt{DPBE} to provide
privacy guarantees for users participating in the distributed learning process.
Finally, we conduct extensive simulations to validate our theoretical results
and evaluate the empirical performance.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:30:15 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 01:31:57 GMT""}]","2023-02-08"
"2301.12062","Kejun Chen","Kejun Chen, Yu Zhang","Physics-guided Residual Learning for Probabilistic Power Flow Analysis","Probabilistic power flow, data-driven, residual learning, neural
  network, physics-guided initialization",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Probabilistic power flow (PPF) analysis is critical to power system operation
and planning. It focuses on obtaining probability descriptions of system states
with stochastic power injections (e.g., renewable generations and load
demands). Monte Carlo Simulations are widely used in PPF analysis. Given random
samples of power injections, they repeatedly run power flow (PF) solvers to
obtain their corresponding voltage phasors. However, the cumulative
computational time is heavy because many simulations are necessary for
obtaining accurate probability descriptions. Therefore, reducing the
computational time of individual PF analysis can relieve the total
computational burden of PPF analysis. Inspired by residual neural networks
(ResNets) structure, we propose a novel neural network framework designed for
PF analysis. We add an extra fully connected linear layer between the inputs
and outputs to the multilayer perceptions (MLPs) structure. In addition, based
on our proposed framework, we design three methods to initialize the weights of
the shortcut connection layer according to the physical characteristics of
AC-PF equations. Numerical tests show that our proposed methods achieve higher
accuracy in estimating voltage phasors and branch flows than existing methods.
In addition, three meticulously designed initialization schemes help converge
faster than random initialization in the training process.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:32:47 GMT""}]","2023-01-31"
"2301.12063","Chengyu Sun","Chengyu Sun","HAT-GAE: Self-Supervised Graph Auto-encoders with Hierarchical Adaptive
  Masking and Trainable Corruption",,,,,"cs.AI","http://creativecommons.org/publicdomain/zero/1.0/","  Self-supervised auto-encoders have emerged as a successful framework for
representation learning in computer vision and natural language processing in
recent years, However, their application to graph data has been met with
limited performance due to the non-Euclidean and complex structure of graphs in
comparison to images or text, as well as the limitations of conventional
auto-encoder architectures. In this paper, we investigate factors impacting the
performance of auto-encoders on graph data and propose a novel auto-encoder
model for graph representation learning. Our model incorporates a hierarchical
adaptive masking mechanism to incrementally increase the difficulty of training
in order to mimic the process of human cognitive learning, and a trainable
corruption scheme to enhance the robustness of learned representations. Through
extensive experimentation on ten benchmark datasets, we demonstrate the
superiority of our proposed method over state-of-the-art graph representation
learning models.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:43:54 GMT""}]","2023-01-31"
"2301.12064","Madhur Mangalam","Madhur Mangalam, Taylor Wilson, Joel Sommerfeld, Aaron D Likens","Optimizing a Bayesian method for estimating the Hurst exponent in
  behavioral sciences","17 pages, 2 figures",,,,"q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Bayesian Hurst-Kolmogorov (HK) method estimates the Hurst exponent of a
time series more accurately than the age-old detrended fluctuation analysis
(DFA), especially when the time series is short. However, this advantage comes
at the cost of computation time. The computation time increases exponentially
with $N$, easily exceeding several hours for $N = 1024$, limiting the utility
of the HK method in real-time paradigms, such as biofeedback and brain-computer
interfaces. To address this issue, we have provided data on the estimation
accuracy of $H$ for synthetic time series as a function of \textit{a priori}
known values of $H$, the time series length, and the simulated sample size from
the posterior distribution -- a critical step in the Bayesian estimation
method. The simulated sample from the posterior distribution as small as $n =
25$ suffices to estimate $H$ with reasonable accuracy for a time series as
short as $256$ measurements. Using a larger simulated sample from the posterior
distribution -- i.e., $n > 50$ -- provides only marginal gain in accuracy,
which might not be worth trading off with computational efficiency. We suggest
balancing the simulated sample size from the posterior distribution of $H$ with
the computational resources available to the user, preferring a minimum of $n =
50$ and opting for larger sample sizes based on time and resource constraints
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:47:08 GMT""}]","2023-01-31"
"2301.12065","Hongteng Xu","Xiangfeng Wang and Hongteng Xu and Moyi Yang","Decentralized Entropic Optimal Transport for Privacy-preserving
  Distributed Distribution Comparison",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Privacy-preserving distributed distribution comparison measures the distance
between the distributions whose data are scattered across different agents in a
distributed system and cannot be shared among the agents. In this study, we
propose a novel decentralized entropic optimal transport (EOT) method, which
provides a privacy-preserving and communication-efficient solution to this
problem with theoretical guarantees. In particular, we design a mini-batch
randomized block-coordinate descent (MRBCD) scheme to optimize the
decentralized EOT distance in its dual form. The dual variables are scattered
across different agents and updated locally and iteratively with limited
communications among partial agents. The kernel matrix involved in the
gradients of the dual variables is estimated by a distributed kernel
approximation method, and each agent only needs to approximate and store a
sub-kernel matrix by one-shot communication and without sharing raw data. We
analyze our method's communication complexity and provide a theoretical bound
for the approximation error caused by the convergence error, the approximated
kernel, and the mismatch between the storage and communication protocols.
Experiments on synthetic data and real-world distributed domain adaptation
tasks demonstrate the effectiveness of our method.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:47:42 GMT""}]","2023-01-31"
"2301.12066","Liam Magee","Luke Munn, Liam Magee, Vanicka Arora","Truth Machines: Synthesizing Veracity in AI Language Models","20 pages, 3 figures",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  As AI technologies are rolled out into healthcare, academia, human resources,
law, and a multitude of other domains, they become de-facto arbiters of truth.
But truth is highly contested, with many different definitions and approaches.
This article discusses the struggle for truth in AI systems and the general
responses to date. It then investigates the production of truth in InstructGPT,
a large language model, highlighting how data harvesting, model architectures,
and social feedback mechanisms weave together disparate understandings of
veracity. It conceptualizes this performance as an operationalization of truth,
where distinct, often conflicting claims are smoothly synthesized and
confidently presented into truth-statements. We argue that these same logics
and inconsistencies play out in Instruct's successor, ChatGPT, reiterating
truth as a non-trivial problem. We suggest that enriching sociality and
thickening ""reality"" are two promising vectors for enhancing the
truth-evaluating capacities of future language models. We conclude, however, by
stepping back to consider AI truth-telling as a social practice: what kind of
""truth"" do we as listeners desire?
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:47:50 GMT""}]","2023-01-31"
"2301.12067","Moulik Choraria","Moulik Choraria, Ibtihal Ferwana, Ankur Mani, Lav R. Varshney","Learning Optimal Features via Partial Invariance","Presented at the 37th AAAI Conference on Artificial Intelligence,
  2023",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Learning models that are robust to distribution shifts is a key concern in
the context of their real-life applicability. Invariant Risk Minimization (IRM)
is a popular framework that aims to learn robust models from multiple
environments. The success of IRM requires an important assumption: the
underlying causal mechanisms/features remain invariant across environments.
When not satisfied, we show that IRM can over-constrain the predictor and to
remedy this, we propose a relaxation via $\textit{partial invariance}$. In this
work, we theoretically highlight the sub-optimality of IRM and then demonstrate
how learning from a partition of training domains can help improve invariant
models. Several experiments, conducted both in linear settings as well as with
deep neural networks on tasks over both language and image data, allow us to
verify our conclusions.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:48:14 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 16:05:50 GMT""}]","2023-04-04"
"2301.12068","Zuobai Zhang","Zuobai Zhang, Minghao Xu, Aur\'elie Lozano, Vijil Chenthamarakshan,
  Payel Das, Jian Tang","Physics-Inspired Protein Encoder Pre-Training via Siamese
  Sequence-Structure Diffusion Trajectory Prediction",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pre-training methods on proteins are recently gaining interest, leveraging
either protein sequences or structures, while modeling their joint energy
landscape is largely unexplored. In this work, inspired by the success of
denoising diffusion models, we propose the DiffPreT approach to pre-train a
protein encoder by sequence-structure multimodal diffusion modeling. DiffPreT
guides the encoder to recover the native protein sequences and structures from
the perturbed ones along the multimodal diffusion trajectory, which acquires
the joint distribution of sequences and structures. Considering the essential
protein conformational variations, we enhance DiffPreT by a physics-inspired
method called Siamese Diffusion Trajectory Prediction (SiamDiff) to capture the
correlation between different conformers of a protein. SiamDiff attains this
goal by maximizing the mutual information between representations of diffusion
trajectories of structurally-correlated conformers. We study the effectiveness
of DiffPreT and SiamDiff on both atom- and residue-level structure-based
protein understanding tasks. Experimental results show that the performance of
DiffPreT is consistently competitive on all tasks, and SiamDiff achieves new
state-of-the-art performance, considering the mean ranks on all tasks. The
source code will be released upon acceptance.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:48:20 GMT""}]","2023-01-31"
"2301.12069","Jacob Masur","Jacob Masur, Denys I. Bondar, Gerard McCaul","Dynamical Generation of Epsilon-Near-Zero Behaviour via Tracking and
  Feedback Control","5 pages + 2 pages of supplementary material, 3 figures",,,,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To date, epsilon near zero (ENZ) responses, characterized by an infinite
phase velocity, are primarily achieved by applying a monochromatic light source
to a tailored metamaterial. Here, we derive the equations for inducing a
dynamically generated broadband ENZ response in a large class of many-body
systems via tracking and feedback control. We further find that this response
leads to a current-energy relationship identical to that of an ideal inductor.
Using a Fermi-Hubbard model, we numerically confirm these results which have
the potential to advance optical computation on the nanoscale.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:49:04 GMT""}]","2023-01-31"
"2301.12070","Takahiro Yamada","Takahiro Yamada","Wright's Strict Finitistic Logic in the Classical Metatheory: The
  Propositional Case","21 pages. Already published","Journal of Philosophical Logic (2023)","10.1007/s10992-022-09698-w",,"math.LO","http://creativecommons.org/licenses/by/4.0/","  Crispin Wright in his 1982 paper argues for strict finitism, a constructive
standpoint that is more restrictive than intuitionism. In its appendix, he
proposes models of strict finitistic arithmetic. They are tree-like structures,
formed in his strict finitistic metatheory, of equations between numerals on
which concrete arithmetical sentences are evaluated. As a first step towards
classical formalisation of strict finitism, we propose their counterparts in
the classical metatheory with one additional assumption, and then extract the
propositional part of `strict finitistic logic' from it and investigate. We
will provide a sound and complete pair of a Kripke-style semantics and a
sequent calculus, and compare with other logics. The logic lacks the law of
excluded middle and Modus Ponens and is weaker than classical logic, but
stronger than any proper intermediate logics in terms of theoremhood. In fact,
all the other well-known classical theorems are found to be theorems. Finally,
we will make an observation that models of this semantics can be seen as nodes
of an intuitionistic model.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:54:40 GMT""}]","2023-01-31"
"2301.12071","Zixun Lan","Zixun Lan, Zuo Zeng, Binjie Hong, Zhenfu Liu and Fei Ma","RCsearcher: Reaction Center Identification in Retrosynthesis via Deep
  Q-Learning",,,,,"cs.LG q-bio.MN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reaction center consists of atoms in the product whose local properties
are not identical to the corresponding atoms in the reactants. Prior studies on
reaction center identification are mainly on semi-templated retrosynthesis
methods. Moreover, they are limited to single reaction center identification.
However, many reaction centers are comprised of multiple bonds or atoms in
reality. We refer to it as the multiple reaction center. This paper presents
RCsearcher, a unified framework for single and multiple reaction center
identification that combines the advantages of the graph neural network and
deep reinforcement learning. The critical insight in this framework is that the
single or multiple reaction center must be a node-induced subgraph of the
molecular product graph. At each step, it considers choosing one node in the
molecular product graph and adding it to the explored node-induced subgraph as
an action. Comprehensive experiments demonstrate that RCsearcher consistently
outperforms other baselines and can extrapolate the reaction center patterns
that have not appeared in the training set. Ablation experiments verify the
effectiveness of individual components, including the beam search and one-hop
constraint of action space.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:03:22 GMT""}]","2023-01-31"
"2301.12072","Chao Zheng","Chao Zheng and Jiangtao Pan","Unbiased estimators for the Heston model with stochastic interest rates",,,,,"q-fin.CP cs.NA math.NA math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine the unbiased estimators in Rhee and Glynn (Operations Research:
63(5), 1026-1043, 2015) and the Heston model with stochastic interest rates.
Specifically, we first develop a semi-exact log-Euler scheme for the Heston
model with stochastic interest rates, and then, under mild assumptions, we show
that the convergence rate in $L^2$ norm is $O(h)$, where $h$ is the step size.
The result applies to a large class of models, such as the Heston-Hull-While
model, the Heston-CIR model and the Heston-Black-Karasinski model. Numerical
experiments confirm our theoretical convergence rate.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:03:48 GMT""}]","2023-01-31"
"2301.12073","Zhixuan Liu","Zhixuan Liu, Youeun Shin, Beverley-Claire Okogwu, Youngsik Yun, Lia
  Coleman, Peter Schaldenbrand, Jihie Kim, Jean Oh","Towards Equitable Representation in Text-to-Image Synthesis Models with
  the Cross-Cultural Understanding Benchmark (CCUB) Dataset","Still on going work",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It has been shown that accurate representation in media improves the
well-being of the people who consume it. By contrast, inaccurate
representations can negatively affect viewers and lead to harmful perceptions
of other cultures. To achieve inclusive representation in generated images, we
propose a culturally-aware priming approach for text-to-image synthesis using a
small but culturally curated dataset that we collected, known here as
Cross-Cultural Understanding Benchmark (CCUB) Dataset, to fight the bias
prevalent in giant datasets. Our proposed approach is comprised of two
fine-tuning techniques: (1) Adding visual context via fine-tuning a pre-trained
text-to-image synthesis model, Stable Diffusion, on the CCUB text-image pairs,
and (2) Adding semantic context via automated prompt engineering using the
fine-tuned large language model, GPT-3, trained on our CCUB culturally-aware
text data. CCUB dataset is curated and our approach is evaluated by people who
have a personal relationship with that particular culture. Our experiments
indicate that priming using both text and image is effective in improving the
cultural relevance and decreasing the offensiveness of generated images while
maintaining quality.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:10:33 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 15:41:05 GMT""}]","2023-04-27"
"2301.12074","Masahiro Kaneko","Masahiro Kaneko, Danushka Bollegala, Naoaki Okazaki","Comparing Intrinsic Gender Bias Evaluation Measures without using Human
  Annotated Examples","EACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Numerous types of social biases have been identified in pre-trained language
models (PLMs), and various intrinsic bias evaluation measures have been
proposed for quantifying those social biases. Prior works have relied on human
annotated examples to compare existing intrinsic bias evaluation measures.
However, this approach is not easily adaptable to different languages nor
amenable to large scale evaluations due to the costs and difficulties when
recruiting human annotators. To overcome this limitation, we propose a method
to compare intrinsic gender bias evaluation measures without relying on
human-annotated examples. Specifically, we create multiple bias-controlled
versions of PLMs using varying amounts of male vs. female gendered sentences,
mined automatically from an unannotated corpus using gender-related word lists.
Next, each bias-controlled PLM is evaluated using an intrinsic bias evaluation
measure, and the rank correlation between the computed bias scores and the
gender proportions used to fine-tune the PLMs is computed. Experiments on
multiple corpora and PLMs repeatedly show that the correlations reported by our
proposed method that does not require human annotated examples are comparable
to those computed using human annotated examples in prior work.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:11:50 GMT""}]","2023-01-31"
"2301.12075","David McCune","Adam Graham-Squire and David McCune","An Examination of Ranked Choice Voting in the United States, 2004-2022",,,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From the perspective of social choice theory, ranked-choice voting (RCV) is
known to have many flaws. RCV can fail to elect a Condorcet winner and is
susceptible to monotonicity paradoxes and the spoiler effect, for example. We
use a database of 182 American ranked-choice elections for political office
from the years 2004-2022 to investigate empirically how frequently RCV's
deficiencies manifest in practice. Our general finding is that RCV's weaknesses
are rarely observed in real-world elections, with the exception that ballot
exhaustion frequently causes majoritarian failures.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:17:08 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 15:26:33 GMT""}]","2023-03-07"
"2301.12076","Guo-Liang Ma","Bang-Xiang Chen, Xin-Li Zhao, Guo-Liang Ma","On the difference between signal and background of the chiral magnetic
  effect relative to spectator and participant planes in isobar collisions at
  $\sqrt{s_{_{\rm NN}}} = 200$ GeV","8 pages, 9 figures",,,,"nucl-th hep-ph nucl-ex","http://creativecommons.org/publicdomain/zero/1.0/","  The search for the chiral magnetic effect (CME) in relativistic heavy-ion
collisions helps us understand the $\mathcal{CP}$ symmetry breaking in strong
interactions and the topological nature of the QCD vacuum. Since the background
and signal of the CME have different correlations with respect to the spectator
and participant planes, a two-plane method has been proposed to extract the
fraction of the CME signal inside the CME observable of $\Delta\gamma$ from the
experimental measurements relative to the two planes. Using a multiphase
transport model with different strengths of the CME, we reexamine the two-plane
method in isobar collisions at $\sqrt{s_{_{\rm NN}}} = 200$ GeV. The ratios of
the CME signal and background relative to the two different planes are found to
be different, which is inconsistent with the assumptions made in the current
experimental measurements. The difference arises from the decorrelation of the
chiral magnetic effect relative to spectator and participant planes, which
originates from final state interactions. Our finding suggests that the current
experimental measurements may overestimate the fraction of the CME signal in
the CME observable in relativistic heavy-ion collisions.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:31:22 GMT""}]","2023-01-31"
"2301.12077","Zheng Lian","Mingyu Xu, Zheng Lian, Lei Feng, Bin Liu, Jianhua Tao","ALIM: Adjusting Label Importance Mechanism for Noisy Partial Label
  Learning",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noisy partial label learning (noisy PLL) is an important branch of weakly
supervised learning. Unlike PLL where the ground-truth label must conceal in
the candidate label set, noisy PLL relaxes this constraint and allows the
ground-truth label may not be in the candidate label set. To address this
challenging problem, most of the existing works attempt to detect noisy samples
and estimate the ground-truth label for each noisy sample. However, detection
errors are unavoidable. These errors can accumulate during training and
continuously affect model optimization. To this end, we propose a novel
framework for noisy PLL with theoretical guarantees, called ``Adjusting Label
Importance Mechanism (ALIM)''. It aims to reduce the negative impact of
detection errors by trading off the initial candidate set and model outputs.
ALIM is a plug-in strategy that can be integrated with existing PLL approaches.
Experimental results on benchmark datasets demonstrate that our method can
achieve state-of-the-art performance on noisy PLL.
\textcolor[rgb]{0.93,0.0,0.47}{Our code can be found in Supplementary
Material}.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:42:53 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 02:07:54 GMT""}]","2023-05-19"
"2301.12078","Jos\'e Enrique Hern\'andez Ram\'irez","Jos\'e E H Ram\'irez and E R Oria","Division and new multiplication between vectors","6 pages and 1 figure",,,,"math.GM","http://creativecommons.org/licenses/by-sa/4.0/","  The division between two vectors belonging to the same vector space is
obtained by elementary procedures of vector algebra and is defined by a matrix.
This representation is obtained for two and three dimensional vector spaces. A
new vector multiplication is defined and an the inverse vector. Through this
multiplication we can obtain the division previously defined.The meaning of
vector division and multiplication are analyzed.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:44:24 GMT""}]","2023-01-31"
"2301.12079","David Williams","Jude T. Anderson, David M. Williams, and Andrew Corrigan","Surface and hypersurface meshing techniques for space-time finite
  element methods","31 pages, 16 figures, and 6 tables",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  A general method is introduced for constructing two-dimensional (2D) surface
meshes embedded in three-dimensional (3D) space time, and 3D hypersurface
meshes embedded in four-dimensional (4D) space time. In particular, we begin by
dividing the space-time domain into time slabs. Each time slab is equipped with
an initial plane (hyperplane), in conjunction with an unstructured simplicial
surface (hypersurface) mesh that covers the initial plane. We then obtain the
vertices of the terminating plane (hyperplane) of the time slab from the
vertices of the initial plane using a space-time trajectory-tracking approach.
Next, these vertices are used to create an unstructured simplicial mesh on the
terminating plane (hyperplane). Thereafter, the initial and terminating
boundary vertices are stitched together to form simplicial meshes on the
intermediate surfaces or sides of the time slab. After describing this new
mesh-generation method in rigorous detail, we provide the results of multiple
numerical experiments which demonstrate its validity and flexibility.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:47:04 GMT""}]","2023-01-31"
"2301.12080","Xuan-Quang Bui","Xuan-Quang Bui and Nguyen Van Minh","Yosida Distance and Existence of Invariant Manifolds in the
  Infinite-Dimensional Dynamical Systems",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new concept of Yosida distance between two (unbounded) linear
operators $A$ and $B$ in a Banach space $\mathbb{X}$ defined as
$d_Y(A,B):=\limsup_{\mu\to +\infty} \| A_\mu-B_\mu\|$, where $A_\mu$ and
$B_\mu$ are the Yosida approximations of $A$ and $B$, respectively, and then
study the persistence of evolution equations under small Yosida perturbation.
This new concept of distance is also used to define the continuity of the
proto-derivative of the operator $F$ in the equation $u'(t)=Fu(t)$, where $F
\colon D(F)\subset \mathbb{X} \rightarrow \mathbb{X}$ is a nonlinear operator.
We show that the above-mentioned equation has local stable and unstable
invariant manifolds near an exponentially dichotomous equilibrium if the
proto-derivative of $F$ is continuous. The Yosida distance approach to
perturbation theory allows us to free the requirement on the domains of the
perturbation operators. Finally, the obtained results seem to be new.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:49:33 GMT""}]","2023-01-31"
"2301.12081","Jitendra Prakash","Peter Bierhorst, Jitendra Prakash","A Hierarchy of Multipartite Nonlocality and Device-Independent Effect
  Witnesses","17 pages, 3 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  According to recent new definitions, a multi-party behavior is genuinely
multipartite nonlocal (GMNL) if it cannot be modeled by measurements on an
underlying network of bipartite-only nonlocal resources, possibly supplemented
with local (classical) resources shared by all parties. The new definitions
differ on whether to allow entangled measurements upon, and/or superquantum
behaviors among, the underlying bipartite resources. Here, we categorize the
full hierarchy of these new candidate definitions of GMNL in three-party
quantum networks, highlighting the intimate link to device-independent
witnesses of network effects. A key finding is the existence of a behavior in
the simplest nontrivial multi-partite measurement scenario (3 parties, 2
measurement settings, and 2 outcomes) that cannot be simulated in a bipartite
network prohibiting entangled measurements and superquantum resources -- thus
witnessing the most general form of GMNL -- but can be simulated with
bipartite-only quantum states with an entangled measurement, indicating an
approach to device independent certification of entangled measurements with
fewer settings than in previous protocols. Surprisingly, we also find that this
(3,2,2) behavior, as well as the others previously studied as
device-independent witnesses of entangled measurements, can all be simulated at
a higher echelon of the GMNL hierarchy that allows superquantum bipartite
resources while still prohibiting entangled measurements. This poses a
challenge to a theory-independent understanding of entangled measurements as an
observable phenomenon distinct from bipartite nonlocality.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:51:28 GMT""}]","2023-01-31"
"2301.12082","Guoyang Xie","Guoyang Xie, Jingbao Wang, Jiaqi Liu, Feng Zheng, Yaochu Jin","Pushing the Limits of Fewshot Anomaly Detection in Industry Vision:
  Graphcore",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In the area of fewshot anomaly detection (FSAD), efficient visual feature
plays an essential role in memory bank M-based methods. However, these methods
do not account for the relationship between the visual feature and its rotated
visual feature, drastically limiting the anomaly detection performance. To push
the limits, we reveal that rotation-invariant feature property has a
significant impact in industrial-based FSAD. Specifically, we utilize graph
representation in FSAD and provide a novel visual isometric invariant feature
(VIIF) as anomaly measurement feature. As a result, VIIF can robustly improve
the anomaly discriminating ability and can further reduce the size of redundant
features stored in M by a large amount. Besides, we provide a novel model
GraphCore via VIIFs that can fast implement unsupervised FSAD training and can
improve the performance of anomaly detection. A comprehensive evaluation is
provided for comparing GraphCore and other SOTA anomaly detection models under
our proposed fewshot anomaly detection setting, which shows GraphCore can
increase average AUC by 5.8%, 4.1%, 3.4%, and 1.6% on MVTec AD and by 25.5%,
22.0%, 16.9%, and 14.1% on MPDD for 1, 2, 4, and 8-shot cases, respectively.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 03:58:32 GMT""}]","2023-01-31"
"2301.12083","Amrit Singh Bedi","Wesley A. Suttle, Amrit Singh Bedi, Bhrij Patel, Brian M. Sadler, Alec
  Koppel, Dinesh Manocha","Beyond Exponentially Fast Mixing in Average-Reward Reinforcement
  Learning via Multi-Level Monte Carlo Actor-Critic",,,,,"cs.LG math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many existing reinforcement learning (RL) methods employ stochastic gradient
iteration on the back end, whose stability hinges upon a hypothesis that the
data-generating process mixes exponentially fast with a rate parameter that
appears in the step-size selection. Unfortunately, this assumption is violated
for large state spaces or settings with sparse rewards, and the mixing time is
unknown, making the step size inoperable. In this work, we propose an RL
methodology attuned to the mixing time by employing a multi-level Monte Carlo
estimator for the critic, the actor, and the average reward embedded within an
actor-critic (AC) algorithm. This method, which we call \textbf{M}ulti-level
\textbf{A}ctor-\textbf{C}ritic (MAC), is developed especially for
infinite-horizon average-reward settings and neither relies on oracle knowledge
of the mixing time in its parameter selection nor assumes its exponential
decay; it, therefore, is readily applicable to applications with slower mixing
times. Nonetheless, it achieves a convergence rate comparable to the
state-of-the-art AC algorithms. We experimentally show that these alleviated
restrictions on the technical conditions required for stability translate to
superior performance in practice for RL problems with sparse rewards.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:12:56 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 18:55:32 GMT""}]","2023-02-02"
"2301.12084","Dimitris Papamichail","Matthew Mccloskey, Gabrielle Curcio, Amulya Badineni, Kevin Mcgrath,
  and Dimitris Papamichail","Automated Arrangements of Multi-Part Music for Sets of Monophonic
  Instruments",,,,,"cs.SD cs.MM eess.AS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Arranging music for a different set of instruments that it was originally
written for is traditionally a tedious and time-consuming process, performed by
experts with intricate knowledge of the specific instruments and involving
significant experimentation. In this paper we study the problem of automating
music arrangements for music pieces written for monophonic instruments or
voices. We designed and implemented an algorithm that can always produce a
music arrangement when feasible by transposing the music piece to a different
scale, permuting the assigned parts to instruments/voices, and transposing
individual parts by one or more octaves. We also published open source software
written in Python that processes MusicXML files and allows musicians to
experiment with music arrangements. It is our hope that our software can serve
as a platform for future extensions that will include music reductions and
inclusion of polyphonic instruments.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:13:45 GMT""}]","2023-01-31"
"2301.12085","Xinyu Zhou","Xinyu Zhou, Yang Li, Jun Zhao","Resource Allocation of Federated Learning Assisted Mobile Augmented
  Reality System in the Metaverse","This paper appears in the Proceedings of IEEE International
  Conference on Communications (ICC) 2023. Please feel free to contact us for
  questions or remarks",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  Metaverse has become a buzzword recently. Mobile augmented reality (MAR) is a
promising approach to providing users with an immersive experience in the
Metaverse. However, due to limitations of bandwidth, latency and computational
resources, MAR cannot be applied on a large scale in the Metaverse yet.
Moreover, federated learning, with its privacy-preserving characteristics, has
emerged as a prospective distributed learning framework in the future Metaverse
world. In this paper, we propose a federated learning assisted MAR system via
non-orthogonal multiple access for the Metaverse. Additionally, to optimize a
weighted sum of energy, latency and model accuracy, a resource allocation
algorithm is devised by setting appropriate transmission power, CPU frequency
and video frame resolution for each user. Experimental results demonstrate that
our proposed algorithm achieves an overall good performance compared to a
random algorithm and greedy algorithm.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:14:43 GMT""},{""version"":""v2"",""created"":""Fri, 10 Mar 2023 06:36:42 GMT""}]","2023-03-13"
"2301.12086","Hao Lei","Hao Lei, Zhe Wang, Huahua Xiao, Jiayi Zhang, Bo Ai","Uplink Performance of Cell-Free Extremely Large-Scale MIMO Systems",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the uplink performance of cell-free (CF)
extremely large-scale multiple-input-multipleoutput (XL-MIMO) systems, which is
a promising technique for future wireless communications. More specifically, we
consider the practical scenario with multiple base stations (BSs) and multiple
user equipments (UEs). To this end, we derive exact achievable spectral
efficiency (SE) expressions for any combining scheme. It is worth noting that
we derive the closed-form SE expressions for the CF XL-MIMO with maximum ratio
(MR) combining. Numerical results show that the SE performance of the CF
XL-MIMO can be hugely improved compared with the small-cell XL-MIMO. It is
interesting that a smaller antenna spacing leads to a higher correlation level
among patch antennas. Finally, we prove that increasing the number of UE
antennas may decrease the SE performance with MR combining.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:19:40 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 07:41:19 GMT""}]","2023-02-15"
"2301.12087","Yi Zhang","Yi Zhang","Optimization and scheduling for a large scale urban transportation
  system in a fast-changing world","The Intelligent Transportation Systems Society (ITSS) held a
  competition in 2021 on the theme ""Shape the Future of ITS,"" asking
  contestants to present their ideas for transportation systems of the future,
  what they will look like, and the products and services they will offer. This
  paper has won the third prize of this competition",,"10.1109/MITS.2022.3189798",,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a set of technological solutions to transform existing
transport systems into more intelligent, interactive systems by utilizing
optimization and control methods that can be implemented in the near future.
This will result in improved public services and quality of life for residents.
Three application scenes that are closely related to people's daily life are
discussed. We first propose a traffic light scheduling strategy using a model
predictive control (MPC) method, with the aim of fairly minimizing delays for
both pedestrians and vehicles. Then, a combined dispatching-operation system is
proposed to increase control flexibility, with a corresponding implementation
solution for boarding control. Finally, a possible scheme to combine both
public transport and autonomous vehicle systems is proposed to improve existing
public transport systems.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:35:13 GMT""}]","2023-01-31"
"2301.12088","Hong Chen","Hong Chen, Terence D. Todd, Dongmei Zhao, George Karakostas","Wireless and Service Allocation for Mobile Computation Offloading with
  Task Deadlines","Submitted to IEEE Transactions on Mobile Computing (Second Round)",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In mobile computation offloading (MCO), mobile devices (MDs) can choose to
either execute tasks locally or to have them executed on a remote edge server
(ES). This paper addresses the problem of assigning both the wireless
communication bandwidth needed, along with the ES capacity that is used for the
task execution, so that task completion time constraints are satisfied. The
objective is to obtain these allocations so that the average power consumption
of the mobile devices is minimized, subject to a cost budget constraint. The
paper includes contributions for both soft and hard task completion deadline
constraints. The problems are first formulated as mixed integer nonlinear
programs (MINLPs). Approximate solutions are then obtained by decomposing the
problems into a collection of convex subproblems that can be efficiently
solved. Results are presented that demonstrate the quality of the proposed
solutions, which can achieve near optimum performance over a wide range of
system parameters.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:47:23 GMT""}]","2023-01-31"
"2301.12089","Jacob Turner","Jacob E. Turner, Daniel R. Stinebring, Maura A. McLaughlin, Anne M.
  Archibald, Timothy Dolch, and Ryan S. Lynch","Scattering Delay Mitigation in High Accuracy Pulsar Timing: Cyclic
  Spectroscopy Techniques","Accepted to ApJ",,"10.3847/1538-4357/acb6fd",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We simulate scattering delays from the interstellar medium to examine the
effectiveness of three estimators in recovering these delays in pulsar timing
data. Two of these estimators use the more traditional process of fitting
autocorrelation functions to pulsar dynamic spectra to extract scintillation
bandwidths, while the third estimator uses the newer technique of cyclic
spectroscopy on baseband pulsar data to recover the interstellar medium's
impulse response function. We find that either fitting a Lorentzian or Gaussian
distribution to an autocorrelation function or recovering the impulse response
function from the cyclic spectrum are, on average, accurate in recovering
scattering delays, although autocorrelation function estimators have a large
variance, even at high signal-to-noise ratio (S/N). We find that, given
sufficient S/N, cyclic spectroscopy is more accurate than both Gaussian and
Lorentzian fitting for recovering scattering delays at specific epochs,
suggesting that cyclic spectroscopy is a superior method for scattering
estimation in high quality data.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 04:51:53 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 17:18:19 GMT""}]","2023-02-28"
"2301.12090","Paola Spoletini","Alessio Ferrari, Paola Spoletini","Strategies, Benefits and Challenges of App Store-inspired Requirements
  Elicitation",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  App store-inspired elicitation is the practice of exploring competitors'
apps, to get inspiration for requirements. This activity is common among
developers, but little insight is available on its practical use, advantages,
and possible issues. This paper aims to study strategies, benefits, and
challenges of app store-inspired elicitation, and to compare this technique
with the more traditional requirements elicitation interviews. We conduct an
experimental simulation with 58 analysts and collect qualitative data. Our
results show that: (1) specific guidelines and procedures are required to
better conduct app store-inspired elicitation; (2) current search features made
available by app stores are not suitable for this practice, and more tool
support is required to help analysts in the retrieval and evaluation of
competing products; (3) while interviews focus on the why dimension of
requirements engineering (i.e., goals), app store-inspired elicitation focuses
on how (i.e., solutions), offering indications for implementation and improved
usability. Our study provides a framework for researchers to address existing
challenges and suggests possible benefits to foster app store-inspired
elicitation among practitioners.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:00:58 GMT""}]","2023-01-31"
"2301.12091","Hoda Heidari","Hoda Heidari, Solon Barocas, Jon Kleinberg, and Karen Levy","Informational Diversity and Affinity Bias in Team Growth Dynamics",,,,,"cs.GT cs.AI cs.CY cs.LG econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prior work has provided strong evidence that, within organizational settings,
teams that bring a diversity of information and perspectives to a task are more
effective than teams that do not. If this form of informational diversity
confers performance advantages, why do we often see largely homogeneous teams
in practice? One canonical argument is that the benefits of informational
diversity are in tension with affinity bias. To better understand the impact of
this tension on the makeup of teams, we analyze a sequential model of team
formation in which individuals care about their team's performance (captured in
terms of accurately predicting some future outcome based on a set of features)
but experience a cost as a result of interacting with teammates who use
different approaches to the prediction task. Our analysis of this simple model
reveals a set of subtle behaviors that team-growth dynamics can exhibit: (i)
from certain initial team compositions, they can make progress toward better
performance but then get stuck partway to optimally diverse teams; while (ii)
from other initial compositions, they can also move away from this optimal
balance as the majority group tries to crowd out the opinions of the minority.
The initial composition of the team can determine whether the dynamics will
move toward or away from performance optimality, painting a path-dependent
picture of inefficiencies in team compositions. Our results formalize a
fundamental limitation of utility-based motivations to drive informational
diversity in organizations and hint at interventions that may improve
informational diversity and performance simultaneously.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:02:40 GMT""}]","2023-01-31"
"2301.12092","Aron Laszka","Soodeh Atefi, Amutheezan Sivagnanam, Afiya Ayman, Jens Grossklags,
  Aron Laszka","The Benefits of Vulnerability Discovery and Bug Bounty Programs: Case
  Studies of Chromium and Firefox",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, bug-bounty programs have gained popularity and become a significant
part of the security culture of many organizations. Bug-bounty programs enable
organizations to enhance their security posture by harnessing the diverse
expertise of crowds of external security experts (i.e., bug hunters).
Nonetheless, quantifying the benefits of bug-bounty programs remains elusive,
which presents a significant challenge for managing them. Previous studies
focused on measuring their benefits in terms of the number of vulnerabilities
reported or based on the properties of the reported vulnerabilities, such as
severity or exploitability. However, beyond these inherent properties, the
value of a report also depends on the probability that the vulnerability would
be discovered by a threat actor before an internal expert could discover and
patch it. In this paper, we present a data-driven study of the Chromium and
Firefox vulnerability-reward programs. First, we estimate the difficulty of
discovering a vulnerability using the probability of rediscovery as a novel
metric. Our findings show that vulnerability discovery and patching provide
clear benefits by making it difficult for threat actors to find
vulnerabilities; however, we also identify opportunities for improvement, such
as incentivizing bug hunters to focus more on development releases. Second, we
compare the types of vulnerabilities that are discovered internally vs.
externally and those that are exploited by threat actors. We observe
significant differences between vulnerabilities found by external bug hunters,
internal security teams, and external threat actors, which indicates that
bug-bounty programs provide an important benefit by complementing the expertise
of internal teams, but also that external hunters should be incentivized more
to focus on the types of vulnerabilities that are likely to be exploited by
threat actors.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:05:03 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 03:02:22 GMT""}]","2023-02-27"
"2301.12093","Jerry Wang","Chenyi Wang, Huan Wang, Peiwen Pan","Local Contrast and Global Contextual Information Make Infrared Small
  Object Salient Again",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infrared small object detection (ISOS) aims to segment small objects only
covered with several pixels from clutter background in infrared images. It's of
great challenge due to: 1) small objects lack of sufficient intensity, shape
and texture information; 2) small objects are easily lost in the process where
detection models, say deep neural networks, obtain high-level semantic features
and image-level receptive fields through successive downsampling. This paper
proposes a reliable detection model for ISOS, dubbed UCFNet, which can handle
well the two issues. It builds upon central difference convolution (CDC) and
fast Fourier convolution (FFC). On one hand, CDC can effectively guide the
network to learn the contrast information between small objects and the
background, as the contrast information is very essential in human visual
system dealing with the ISOS task. On the other hand, FFC can gain image-level
receptive fields and extract global information while preventing small objects
from being overwhelmed.Experiments on several public datasets demonstrate that
our method significantly outperforms the state-of-the-art ISOS models, and can
provide useful guidelines for designing better ISOS deep models. Code are
available at https://github.com/wcyjerry/BasicISOS.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:18:13 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 04:02:40 GMT""},{""version"":""v3"",""created"":""Wed, 8 Mar 2023 16:30:18 GMT""}]","2023-03-09"
"2301.12094","J\'er\'emie Lespinasse","J\'er\'emie Lespinasse, Carole Dufouil, C\'ecile Proust-Lima and the
  MEMENTO study group","Disease progression model anchored around clinical diagnosis in
  longitudinal cohorts: example of Alzheimer's disease and related dementia",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background. Alzheimer's disease and related dementia (ADRD) are characterized
by multiple and progressive anatomo clinical changes. Yet, modeling changes
over disease course from cohort data is challenging as the usual timescales are
inappropriate and time-to-clinical diagnosis is available on small subsamples
of participants with short follow-up durations prior to diagnosis. One solution
to circumvent this challenge is to define the disease time as a latent
variable.
  Methods: We developed a multivariate mixed model approach that realigns
individual trajectories into the latent disease time to describe disease
progression. Our methodology exploits the clinical diagnosis information as a
partially observed and approximate reference to guide the estimation of the
latent disease time. The model estimation was carried out in the Bayesian
Framework using Stan. We applied the methodology to 2186 participants of the
MEMENTO study with 5-year follow-up. Repeated measures of 12 ADRD markers
stemmed from cerebrospinal fluid (CSF), brain imaging and cognitive tests were
analyzed.
  Result: The estimated latent disease time spanned over twenty years before
the clinical diagnosis. Considering the profile of a woman aged 70 with a high
level of education and APOE4 carrier (the main genetic risk factor for ADRD),
CSF markers of tau proteins accumulation preceded markers of brain atrophy by 5
years and cognitive decline by 10 years. We observed that individual
characteristics could substantially modify the sequence and timing of these
changes.
  Conclusion: Our disease progression model does not only realign trajectories
into the most homogeneous way. It accounts for the inherent residual
inter-individual variability in dementia progression to describe the long-term
changes according to the years preceding clinical diagnosis, and to provide
clinically meaningful information on the sequence of events.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:28:55 GMT""}]","2023-01-31"
"2301.12095","Yue Yu","Lu Zhang, Huaiqian You, Tian Gao, Mo Yu, Chung-Hao Lee, Yue Yu","MetaNO: How to Transfer Your Knowledge on Learning Hidden Physics",,,,,"cs.LG cs.NA math.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gradient-based meta-learning methods have primarily been applied to classical
machine learning tasks such as image classification. Recently, PDE-solving deep
learning methods, such as neural operators, are starting to make an important
impact on learning and predicting the response of a complex physical system
directly from observational data. Since the data acquisition in this context is
commonly challenging and costly, the call of utilization and transfer of
existing knowledge to new and unseen physical systems is even more acute.
Herein, we propose a novel meta-learning approach for neural operators, which
can be seen as transferring the knowledge of solution operators between
governing (unknown) PDEs with varying parameter fields. Our approach is a
provably universal solution operator for multiple PDE solving tasks, with a key
theoretical observation that underlying parameter fields can be captured in the
first layer of neural operator models, in contrast to typical final-layer
transfer in existing meta-learning methods. As applications, we demonstrate the
efficacy of our proposed approach on PDE-based datasets and a real-world
material modeling problem, illustrating that our method can handle complex and
nonlinear physical response learning tasks while greatly improving the sampling
efficiency in unseen tasks.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:30:51 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 17:22:07 GMT""}]","2023-02-06"
"2301.12096","Arif Ullah","Arif Ullah, Luis E. Herrera Rodriguez, Pavlo O. Dral and Alexei A.
  Kananenka","QD3SET-1: A Database with Quantum Dissipative Dynamics Data Sets","14 pages, 3 figures",,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Simulations of the dynamics of dissipative quantum systems utilize many
methods such as physics-based quantum, semiclassical, and quantum-classical as
well as machine learning-based approximations, development and testing of which
requires diverse data sets. Here we present a new database QD3SET-1 containing
eight data sets of quantum dynamical data for two systems of broad interest,
spin-boson (SB) model and the Fenna--Matthews--Olson (FMO) complex, generated
with two different methods solving the dynamics, approximate local thermalizing
Lindblad master equation (LTLME) and highly accurate hierarchy equations of
motion (HEOM). One data set was generated with the SB model which is a
two-level quantum system coupled to a harmonic environment using HEOM for 1,000
model parameters. Seven data sets were collected for the FMO complex of
different sizes(7- and 8-site monomer and 24-site trimer with LTLME and 8-site
monomer with HEOM) for 500--879 model parameters. Our QD3SET-1 database
contains both population and coherence dynamics data and part of it has been
already used for machine learning-based quantum dynamics studies.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:39:31 GMT""}]","2023-01-31"
"2301.12097","Hongyu Zhou","Hongyu Zhou, Xin Zhou, Lingzi Zhang, Zhiqi Shen","Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal
  Recommendation","17 pages, 3 figures",,,,"cs.IR cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  User interaction data in recommender systems is a form of dyadic relation
that reflects the preferences of users with items. Learning the representations
of these two discrete sets of objects, users and items, is critical for
recommendation. Recent multimodal recommendation models leveraging multimodal
features (e.g., images and text descriptions) have been demonstrated to be
effective in improving recommendation accuracy. However, state-of-the-art
models enhance the dyadic relations between users and items by considering
either user-user or item-item relations, leaving the high-order relations of
the other side (i.e., users or items) unexplored. Furthermore, we
experimentally reveal that the current multimodality fusion methods in the
state-of-the-art models may degrade their recommendation performance. That is,
without tainting the model architectures, these models can achieve even better
recommendation accuracy with uni-modal information. On top of the finding, we
propose a model that enhances the dyadic relations by learning Dual
RepresentAtions of both users and items via constructing homogeneous Graphs for
multimOdal recommeNdation. We name our model as DRAGON. Specifically, DRAGON
constructs the user-user graph based on the commonly interacted items and the
item-item graph from item multimodal features. It then utilizes graph learning
on both the user-item heterogeneous graph and the homogeneous graphs (user-user
and item-item) to obtain the dual representations of users and items. To
capture information from each modality, DRAGON employs a simple yet effective
fusion method, attentive concatenation, to derive the representations of users
and items. Extensive experiments on three public datasets and seven baselines
show that DRAGON can outperform the strongest baseline by 22.03% on average.
Various ablation studies are conducted on DRAGON to validate its effectiveness.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:40:28 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 01:58:48 GMT""},{""version"":""v3"",""created"":""Thu, 9 Feb 2023 06:01:38 GMT""}]","2023-02-10"
"2301.12098","Michael D. Graham","Alec J. Linot and Kevin Zeng and Michael D. Graham","Turbulence control in plane Couette flow using low-dimensional neural
  ODE-based models and deep reinforcement learning",,,,,"physics.flu-dyn cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The high dimensionality and complex dynamics of turbulent flows remain an
obstacle to the discovery and implementation of control strategies. Deep
reinforcement learning (RL) is a promising avenue for overcoming these
obstacles, but requires a training phase in which the RL agent iteratively
interacts with the flow environment to learn a control policy, which can be
prohibitively expensive when the environment involves slow experiments or
large-scale simulations. We overcome this challenge using a framework we call
""DManD-RL"" (data-driven manifold dynamics-RL), which generates a data-driven
low-dimensional model of our system that we use for RL training. With this
approach, we seek to minimize drag in a direct numerical simulation (DNS) of a
turbulent minimal flow unit of plane Couette flow at Re=400 using two slot jets
on one wall. We obtain, from DNS data with $\mathcal{O}(10^5)$ degrees of
freedom, a 25-dimensional DManD model of the dynamics by combining an
autoencoder and neural ordinary differential equation. Using this model as the
environment, we train an RL control agent, yielding a 440-fold speedup over
training on the DNS, with equivalent control performance. The agent learns a
policy that laminarizes 84% of unseen DNS test trajectories within 900 time
units, significantly outperforming classical opposition control (58%), despite
the actuation authority being much more restricted. The agent often achieves
laminarization through a counterintuitive strategy that drives the formation of
two low-speed streaks, with a spanwise wavelength that is too small to be
self-sustaining. The agent demonstrates the same performance when we limit
observations to wall shear rate.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:47:10 GMT""}]","2023-01-31"
"2301.12099","Wenjie Xu","Wenjie Xu, Colin N Jones, Bratislav Svetozarevic, Christopher R.
  Laughman, Ankush Chakrabarty","Violation-Aware Contextual Bayesian Optimization for Controller
  Performance Optimization with Unmodeled Constraints","arXiv admin note: substantial text overlap with arXiv:2110.07479",,,,"cs.LG math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the problem of performance optimization of closed-loop control
systems with unmodeled dynamics. Bayesian optimization (BO) has been
demonstrated to be effective for improving closed-loop performance by
automatically tuning controller gains or reference setpoints in a model-free
manner. However, BO methods have rarely been tested on dynamical systems with
unmodeled constraints and time-varying ambient conditions. In this paper, we
propose a violation-aware contextual BO algorithm (VACBO) that optimizes
closed-loop performance while simultaneously learning constraint-feasible
solutions under time-varying ambient conditions. Unlike classical constrained
BO methods which allow unlimited constraint violations, or 'safe' BO algorithms
that are conservative and try to operate with near-zero violations, we allow
budgeted constraint violations to improve constraint learning and accelerate
optimization. We demonstrate the effectiveness of our proposed VACBO method for
energy minimization of industrial vapor compression systems under time-varying
ambient temperature and humidity.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:48:40 GMT""}]","2023-01-31"
"2301.12100","Chi Zhang","Chi Zhang, Wenjie Ruan, Peipei Xu","Reachability Analysis of Neural Network Control Systems","accepted by AAAI 2023",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural network controllers (NNCs) have shown great promise in autonomous and
cyber-physical systems. Despite the various verification approaches for neural
networks, the safety analysis of NNCs remains an open problem. Existing
verification approaches for neural network control systems (NNCSs) either can
only work on a limited type of activation functions, or result in non-trivial
over-approximation errors with time evolving. This paper proposes a
verification framework for NNCS based on Lipschitzian optimisation, called
DeepNNC. We first prove the Lipschitz continuity of closed-loop NNCSs by
unrolling and eliminating the loops. We then reveal the working principles of
applying Lipschitzian optimisation on NNCS verification and illustrate it by
verifying an adaptive cruise control model. Compared to state-of-the-art
verification approaches, DeepNNC shows superior performance in terms of
efficiency and accuracy over a wide range of NNCs. We also provide a case study
to demonstrate the capability of DeepNNC to handle a real-world, practical, and
complex system. Our tool \textbf{DeepNNC} is available at
\url{https://github.com/TrustAI/DeepNNC}.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:57:37 GMT""}]","2023-01-31"
"2301.12101","Weidong Cao","Weidong Cao and Hua Wang and Xuan Zhang","Non-Hermitian Physics-Inspired Voltage-Controlled Oscillators with
  Resistive Tuning","5 Pages, 6 figures, accepted by ISCAS 2023",,,,"cs.ET cs.AR","http://creativecommons.org/licenses/by/4.0/","  This paper presents a non-Hermitian physics-inspired voltage-controlled
oscillator (VCO) topology, which is termed parity-time-symmetric topology. The
VCO consists of two coupled inductor-capacitor (LC) cores with a balanced gain
and loss profile. Due to the interplay between the gain/loss and their
coupling, an extra degree of freedom is enabled via resistive tuning, which can
enhance the frequency tuning range (FTR) beyond the bounds of conventional
capacitive or inductive tuning. A silicon prototype is implemented in a
standard 130 nm bulk CMOS process with a core area of 0.15mm^2. Experimental
results show that it achieves a 3.1x FTR improvement and 30% phase noise
reduction of the baseline VCO with the same amount of capacitive tuning
ability.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 05:58:57 GMT""}]","2023-01-31"
"2301.12102","Yixuan Zhang","Yixuan Zhang, Shangtong Cao, Haoyu Wang, Zhenpeng Chen, Xiapu Luo,
  Dongliang Mu, Yun Ma, Gang Huang, Xuanzhe Liu","Characterizing and Detecting WebAssembly Runtime Bugs",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  WebAssembly (abbreviated WASM) has emerged as a promising language of the Web
and also been used for a wide spectrum of software applications such as mobile
applications and desktop applications. These applications, named as WASM
applications, commonly run in WASM runtimes. Bugs in WASM runtimes are
frequently reported by developers and cause the crash of WASM applications.
However, these bugs have not been well studied. To fill in the knowledge gap,
we present a systematic study to characterize and detect bugs in WASM runtimes.
We first harvest a dataset of 311 real-world bugs from hundreds of related
posts on GitHub. Based on the collected high-quality bug reports, we distill 31
bug categories of WASM runtimes and summarize their common fix strategies.
Furthermore, we develop a pattern-based bug detection framework to
automatically detect bugs in WASM runtimes. We apply the detection framework to
five popular WASM runtimes and successfully uncover 53 bugs that have never
been reported previously, among which 14 have been confirmed and 6 have been
fixed by runtime developers.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:03:04 GMT""}]","2023-01-31"
"2301.12103","Li Tang","Hai-Nan Lin and Li Tang and Rui Zou","Revised constraints on the photon mass from well-localized fast radio
  bursts","9 pages, 4 figures","MNRAS 520, 1324-1331 (2023)","10.1093/mnras/stad228",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We constrain the photon mass from well-localized fast radio bursts (FRBs)
using Bayes inference method. The probability distributions of dispersion
measures (DM) of host galaxy and intergalactic medium are properly taken into
account. The photon mass is tightly constrained from 17 well-localized FRBs in
the redshift range $0<z<0.66$. Assuming that there is no redshift evolution of
host DM, the $1\sigma$ and $2\sigma$ upper limits of photon mass are
constrained to be $m_\gamma<4.8\times 10^{-51}$ kg and $m_\gamma<7.1\times
10^{-51}$ kg, respectively. Monte Carlo simulations show that, even enlarging
the FRB sample to 200 and extending the redshift range to $0<z<3$ couldn't
significantly improve the constraining ability on photon mass. This is because
of the large uncertainty on the DM of intergalactic medium.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:09:31 GMT""}]","2023-03-07"
"2301.12104","Cheng Ji","Cheng Ji, Jianxin Li, Hao Peng, Jia Wu, Xingcheng Fu, Qingyun Sun,
  Phillip S. Yu","Unbiased and Efficient Self-Supervised Incremental Contrastive Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive Learning (CL) has been proved to be a powerful self-supervised
approach for a wide range of domains, including computer vision and graph
representation learning. However, the incremental learning issue of CL has
rarely been studied, which brings the limitation in applying it to real-world
applications. Contrastive learning identifies the samples with the negative
ones from the noise distribution that changes in the incremental scenarios.
Therefore, only fitting the change of data without noise distribution causes
bias, and directly retraining results in low efficiency. To bridge this
research gap, we propose a self-supervised Incremental Contrastive Learning
(ICL) framework consisting of (i) a novel Incremental InfoNCE (NCE-II) loss
function by estimating the change of noise distribution for old data to
guarantee no bias with respect to the retraining, (ii) a meta-optimization with
deep reinforced Learning Rate Learning (LRL) mechanism which can adaptively
learn the learning rate according to the status of the training processes and
achieve fast convergence which is critical for incremental learning.
Theoretically, the proposed ICL is equivalent to retraining, which is based on
solid mathematical derivation. In practice, extensive experiments in different
domains demonstrate that, without retraining a new model, ICL achieves up to
16.7x training speedup and 16.8x faster convergence with competitive results.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:11:31 GMT""}]","2023-01-31"
"2301.12105","Junsu Cho","Junsu Cho, Dongmin Hyun, Dong won Lim, Hyeon jae Cheon, Hyoung-iel
  Park, Hwanjo Yu","Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation","accepted to AAAI 2023",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential Recommender Systems (SRSs) aim to predict the next item that users
will consume, by modeling the user interests within their item sequences. While
most existing SRSs focus on a single type of user behavior, only a few pay
attention to multi-behavior sequences, although they are very common in
real-world scenarios. It is challenging to effectively capture the user
interests within multi-behavior sequences, because the information about user
interests is entangled throughout the sequences in complex relationships. To
this end, we first address the characteristics of multi-behavior sequences that
should be considered in SRSs, and then propose novel methods for Dynamic
Multi-behavior Sequence modeling named DyMuS, which is a light version, and
DyMuS+, which is an improved version, considering the characteristics. DyMuS
first encodes each behavior sequence independently, and then combines the
encoded sequences using dynamic routing, which dynamically integrates
information required in the final result from among many candidates, based on
correlations between the sequences. DyMuS+, furthermore, applies the dynamic
routing even to encoding each behavior sequence to further capture the
correlations at item-level. Moreover, we release a new, large and up-to-date
dataset for multi-behavior recommendation. Our experiments on DyMuS and DyMuS+
show their superiority and the significance of capturing the characteristics of
multi-behavior sequences.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:18:36 GMT""}]","2023-01-31"
"2301.12106","Alexander Levis","Alexander W. Levis, Matteo Bonvini, Zhenghao Zeng, Luke Keele, Edward
  H. Kennedy","Covariate-assisted bounds on causal effects with instrumental variables","40 pages, 2 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When an exposure of interest is confounded by unmeasured factors, an
instrumental variable (IV) can be used to identify and estimate certain causal
contrasts. Identification of the marginal average treatment effect (ATE) from
IVs relies on strong untestable structural assumptions. When one is unwilling
to assert such structure, IVs can nonetheless be used to construct bounds on
the ATE. Famously, Balke and Pearl (1997) proved tight bounds on the ATE for a
binary outcome, in a randomized trial with noncompliance and no covariate
information. We demonstrate how these bounds remain useful in observational
settings with baseline confounders of the IV, as well as randomized trials with
measured baseline covariates. The resulting bounds on the ATE are non-smooth
functionals, and thus standard nonparametric efficiency theory is not
immediately applicable. To remedy this, we propose (1) under a novel margin
condition, influence function-based estimators of the bounds that can attain
parametric convergence rates when the nuisance functions are modeled flexibly,
and (2) estimators of smooth approximations of these bounds. We propose
extensions to continuous outcomes, explore finite sample properties in
simulations, and illustrate the proposed estimators in a randomized field
experiment studying the effects of canvassing on resulting voter turnout.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:23:33 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 14:43:57 GMT""},{""version"":""v3"",""created"":""Tue, 9 May 2023 19:34:46 GMT""}]","2023-05-11"
"2301.12107","Himanshu Chaudhary","Amine Bouali, Himanshu Chaudhary, Ujjal Debnath, Tanusree Roy,
  G.Mustafa","Constraints on the Parameterized Deceleration Parameter in FRW Universe",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Confirmation of accelerated expansion of the universe probed the concept of
dark energy theory, and since then, numerous models have been introduced to
explain its origin and nature. The present work is based on reconstructing dark
energy by parametrization of the deceleration parameter in the FRW universe
filled with radiation, dark matter, and dark energy. We have chosen some
well-motivated parametrized models 1-3 in an attempt to investigate the energy
density in terms of deceleration parameters by estimating the cosmological
parameters with the help of different observational datasets. Also, we have
introduced a new model 4 for the parametrization of the deceleration parameter.
Then we analyzed the cosmography parameters using the best-fit values of the
parameters. Using the information criteria, we have examined the viability of
the models.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:33:50 GMT""}]","2023-01-31"
"2301.12108","Ning-Hua Tong","Ning-Hua Tong and Pietro Salvatori","Positive Correlation between Heavy Alcoholic Drinking and SARS-Cov-2
  Not-infection Rate","16 pages, 4 figures, 1 table",,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  An investigation on the correlation between the strong alcoholic drinking and
SARS-Cov-2 uninfection rate is carried out. The investigation is done through a
simple survey in China based on the social media software Weixin and the survey
mini program Wenjuanxin, during 15:00 Jan.1, 2023 to 12:35 Jan.3, 2023. From
the $211$ survey questionnaires collected, we find a significant positive
correlation between the frequent (no less than three times a week) strong
liquor (higher than $40\%$ alcoholic content in volume) drinking and the higher
SARS-Cov-2 uninfection rate ($38.6\%$ compared to the value $25.1\%$ for
general population). The p-value of this statistical result shows that the
correlation is significant.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:34:30 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 15:21:30 GMT""},{""version"":""v3"",""created"":""Thu, 23 Feb 2023 01:40:34 GMT""}]","2023-02-24"
"2301.12109","Eric Gaidos","Eric Gaidos, Zachary Claytor, Ryan Dungee, Aleezah Ali, Gregory A.
  Feiden","The TIME Table: Rotation and Ages of Cool Exoplanet Host Stars","accepted to MNRAS. Full Table 1 in CDS machine-readable format
  included as ancillary file time_table.mrt",,"10.1093/mnras/stad343",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Age is a stellar parameter that is both fundamental and difficult to
determine. Among middle-aged M dwarfs, the most prolific hosts of close-in and
detectable exoplanets, gyrochronology is the most promising method to assign
ages, but requires calibration by rotation-temperature sequences (gyrochrones)
in clusters of known ages. We curated a catalog of 249 late K- and M-type
(($T_{eff}$=3200-4200K) exoplanet host stars with established rotation periods,
and applied empirical, temperature-dependent rotation-age relations based on
relevant published gyrochrones, including one derived from observations of the
4 Gyr-old open cluster M67. We estimated ages for 227 of these stars, and upper
limits for 8 others, excluding 14 which have too rapidly rotating or are
otherwise outside the valid parameter range of our gyrochronology. We estimated
uncertainties based on observed scatter in rotation periods in young clusters,
error in the gyrochrones, and uncertainties in temperature and non-solar
metallicity. For those stars with measured metallicities, we provide but do not
incorporate a correction for the effects of deviation from solar metallicity.
The age distribution of our sample declines to near zero at 10 Gyr, the age of
the Galactic disk, with the handful of outliers explainable by large
uncertainties. Continued addition or extension of cluster rotation sequences to
more thoroughly calibrate the gyrochronology in time and temperature space,
more precise and robust measurement of rotation periods, and more accurate
stellar parameter measurements will enable continued improvements in the age
estimates of these important exoplanet host stars.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:38:46 GMT""}]","2023-02-08"
"2301.12110","Slava Naprienko","Slava Naprienko","Free Fermionic Schur Functions",,,,,"math.CO math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We introduce a new family of Schur functions $s_{\lambda/\mu;a,b}(x/y)$ that
depend on two sets of variables and two sequences of parameters. These free
fermionic Schur functions have a hidden symmetry between the two sets of
parameters that allows us to generalize and unify factorial, supersymmetric,
and dual Schur functions from literature.
  We then prove that these functions satisfy the supersymmetric Cauchy identity
$$
  \sum_{\lambda}s_{\lambda;a,b}(x/y)\widehat{s}_{\lambda;a,b}(z/w) =
\prod_{i,j}\frac{1+y_iz_j}{1-x_iz_j}\frac{1+x_iw_j}{1-y_iw_j}, $$ where
$\widehat{s}_{\lambda;a,b}(z/w) = s_{\lambda';b',a'}(w/z)$ are the dual
functions.
  Our approach is based on the integrable six vertex model with free fermionic
Boltzmann weights. We show that these weights satisfy the \textit{refined
Yang-Baxter equation}, which allows us to prove well-known properties of Schur
functions: supersymmetry, combinatorial descriptions, the Jacobi-Trudi
identity, the N\""agelsbach-Kostka formula, the Giambelli formula, the Ribbon
formula, the Weyl determinant formula, the Berele-Regev factorization, dual
Cauchy identity, the flagged determinant formula, and many others. We emphasize
that many of these results are novel even in special cases.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:45:14 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 22:46:01 GMT""}]","2023-03-01"
"2301.12111","Matthew Goodbred","Matthew Goodbred and Yi-Hsin Liu","First-Principles Theory of the Relativistic Magnetic Reconnection Rate
  in Astrophysical Pair Plasmas","7 pages, 3 figures","Phys.Rev.Lett. 129,26 (2022) 265101-265107","10.1103/PhysRevLett.129.265101",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a first-principles model for the relativistic magnetic
reconnection rate in strongly magnetized pair plasmas. By considering the
energy budget and required current density near the x-line, we analytically
show that in the magnetically-dominated relativistic regime, the x-line thermal
pressure is significantly lower than the upstream magnetic pressure due to the
extreme energy needed to sustain the current density, consistent with kinetic
simulations. This causes the upstream magnetic field lines to collapse in,
producing the open outflow geometry which enables fast reconnection. The result
is important for understanding a wide range of extreme astrophysical
environments, where fast reconnection has been evoked to explain observations
such as transient flares and nonthermal particle signatures.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:58:53 GMT""}]","2023-01-31"
"2301.12112","Danqing Wang","Danqing Wang, Fei Ye, Hao Zhou","On Pre-trained Language Models for Antibody","Accepted in ICLR 2023",,,,"cs.CL q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Antibodies are vital proteins offering robust protection for the human body
from pathogens. The development of general protein and antibody-specific
pre-trained language models both facilitate antibody prediction tasks. However,
there have been limited studies that comprehensively explore the representation
capability of distinct pre-trained language models on different antibody tasks.
To investigate the problem, we aim to answer several key questions in this
paper, such as how pre-trained language models perform in antibody tasks with
different specificity and how introducing specific biological mechanisms to the
pre-training process can benefit the model. Additionally, we evaluate if the
learned antibody pre-trained representations can be applied to real-world
antibody problems, like drug discovery and immune process understanding.
Previously, no benchmark available largely hindered the study to answer these
questions. To aid in our investigation, we provide an AnTibody Understanding
Evaluation (ATUE) benchmark. We comprehensively evaluate the performance of
protein pre-trained language models by empirical study along with conclusions
and new insights. Our ATUE and code are released at
https://github.com/dqwang122/EATLM.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:05:15 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 20:18:25 GMT""}]","2023-03-03"
"2301.12113","Jianming Cai","Yaoming Chu, Xiangbei Li, and Jianming Cai","Strong quantum metrological limit from many-body physics","7 pages, 3 figures + supplementary information (14 pages)","Phys. Rev. Lett. 130, 170801 (2023)","10.1103/PhysRevLett.130.170801",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surpassing the standard quantum limit and even reaching the Heisenberg limit
using quantum entanglement, represents the Holy Grail of quantum metrology.
However, quantum entanglement is a valuable resource that does not come without
a price. The exceptional time overhead for the preparation of large-scale
entangled states raises disconcerting concerns about whether the Heisenberg
limit is fundamentally achievable. Here we find a universal speed limit set by
the Lieb-Robinson light cone for the quantum Fisher information growth to
characterize the metrological potential of quantum resource states during their
preparation. Our main result establishes a strong precision limit of quantum
metrology accounting for the complexity of many-body quantum resource state
preparation and reveals a fundamental constraint for reaching the Heisenberg
limit in a generic many-body lattice system with bounded one-site energy. It
enables us to identify the essential features of quantum many-body systems that
are crucial for achieving the quantum advantage of quantum metrology, and
brings an interesting connection between many-body quantum dynamics and quantum
metrology.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:08:35 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 02:43:26 GMT""}]","2023-04-28"
"2301.12114","Lei Du","Lei Du, Yashuang Ma, Jiangnan Xv and Yanhong Bao","Cohomologies and deformations of coassociative coderivations","To appear in Communications in Algebra",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The motivation of this paper is to construct a deformation theory of
coderivations of coassociative coalgebras. We introduce a notion of a Coder
pair, that is, a coassociative coalgebra with a coderivation. Then we define a
proper corepresentation of a Coder pair and study the corresponding cohomology.
Finally, we show that a Coder pair is rigid, provided that the second
cohomology group is trivial and point out that a deformation of finite order is
extensible to higher order deformations if the obstruction class, which is
defined to be in the third cohomology group, is trivial.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:19:54 GMT""}]","2023-01-31"
"2301.12115","Markus Hegland","Markus Hegland and Zbigniew Stachurski and Conrad J. Burden","Computing expected moments of the R\'enyi parking problem on the circle",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  A highly accurate and efficient method to compute the expected values of the
count and sum of the centre vectors of a random maximal sized collection of
non-overlapping unit diameter disks touching a fixed unit-diameter disk is
presented. This extends earlier work on R\'enyi's parking problem [Magyar Tud.
Akad. Mat. Kutat\'{o} Int. K\""{o}zl. 3 (1-2), 1958, pp. 109-127]. Underlying
the method is a splitting of the the problem conditional on the value of the
first disk. This splitting is proven and then used to derive integral equations
for the expectations. These equations take a lower block triangular form. They
are solved using substitution and approximation of the integrals to very high
accuracy using a high degree polynomial approximation within the blocks.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:36:49 GMT""}]","2023-01-31"
"2301.12116","Yuki Izumida","Yuki Izumida","Non-quasistatic response coefficients and dissipated availability for
  macroscopic thermodynamic systems","7 pages, 3 figures",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The characterization of finite-time thermodynamic processes is of crucial
importance for extending equilibrium thermodynamics to nonequilibrium
thermodynamics. The central issue is to quantify responses of thermodynamic
variables and irreversible dissipation associated with non-quasistatic changes
of thermodynamic forces applied to the system. In this study, we derive a
simple formula that incorporates the non-quasistatic response coefficients with
Onsager's kinetic coefficients, where the Onsager coefficients characterize the
relaxation dynamics of fluctuation of extensive thermodynamic variables of
semi-macroscopic systems. Moreover, the dissipated availability that quantifies
the efficiency of the irreversible thermodynamic process is formulated in terms
of the derived non-quasistatic response coefficients. The present results are
demonstrated by using an ideal gas model. The present results are, in
principle, verifiable through experiments and are thus expected to provide a
guiding principle for the nonequilibrium control of macroscopic thermodynamic
systems.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:37:12 GMT""},{""version"":""v2"",""created"":""Sun, 30 Apr 2023 13:55:04 GMT""}]","2023-05-02"
"2301.12117","Junxi Duan","Jinrui Zhong, Junxi Duan, Shihao Zhang, Huimin Peng, Qi Feng, Yuqin
  Hu, Qinsheng Wang, Jinhai Mao, Jianpeng Liu, Yugui Yao","Effective manipulation and realization of a colossal nonlinear Hall
  effect in an electric-field tunable moir\'e system","17 pages, 4 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The second-order nonlinear Hall effect illuminates a frequency-doubling
transverse current emerging in quantum materials with broken inversion symmetry
even when time-reversal symmetry is preserved. This nonlinear response
originates from both the Berry curvature dipole and the chiral Bloch electron
skew scatterings, reflecting various information of the lattice symmetries,
band dispersions, and topology of the electron wavefunctions. Even though many
efforts have been put in detecting the nonlinear Hall effect in diverse
condensed matter systems, effective manipulation of the two principal
mechanisms in a single system has been lacking, and the reported response is
relatively weak. Here, we report effective manipulation of the nonlinear Hall
effect and realization of a colossal second-order Hall conductivity, $\sim500
{\mu}mSV^{-1}$, orders of magnitudes higher than the reported values, in AB-BA
stacked twisted double bilayer graphene. A Berry-curvature-dipole-dominated
nonlinear Hall effect, as well as its controllable transition to
skew-scattering-dominated response, is identified near the band edge. The
colossal response, on the other hand, is detected near the van Hove
singularities, mainly determined by the skew scattering of the chiral Bloch
electrons. Our findings establish electrically tunable moir\'e systems
promising for nonlinear Hall effect manipulations and applications.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:52:43 GMT""}]","2023-01-31"
"2301.12118","Siddharth Nand","Siddharth Nand, Yuecheng Cai","Physics-informed Neural Network: The Effect of Reparameterization in
  Solving Differential Equations","The University of British Columbia, CSPC 340/532M Research Project,
  2022",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Differential equations are used to model and predict the behaviour of complex
systems in a wide range of fields, and the ability to solve them is an
important asset for understanding and predicting the behaviour of these
systems. Complicated physics mostly involves difficult differential equations,
which are hard to solve analytically. In recent years, physics-informed neural
networks have been shown to perform very well in solving systems with various
differential equations. The main ways to approximate differential equations are
through penalty function and reparameterization. Most researchers use penalty
functions rather than reparameterization due to the complexity of implementing
reparameterization. In this study, we quantitatively compare physics-informed
neural network models with and without reparameterization using the
approximation error. The performance of reparameterization is demonstrated
based on two benchmark mechanical engineering problems, a one-dimensional bar
problem and a two-dimensional bending beam problem. Our results show that when
dealing with complex differential equations, applying reparameterization
results in a lower approximation error.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 07:53:26 GMT""}]","2023-01-31"
"2301.12119","Xinguo Ren","Igor Ying Zhang and Xinguo Ren","Introduction to the Fifth-rung Density Functional Approximations:
  Concept, Formulation, and Applications","43 pages, 10 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The widespread use of (generalized) Kohn-Sham density functional theory
(KS-DFT) lies in the fact that hierarchical sets of approximations of the
exchange-correlation (XC) energy functional can be designed, offering versatile
choices to satisfy different levels of accuracy needs. The XC functionals
standing on the fifth (top) rung of the Jacob's ladder incorporate the
information of unoccupied Kohn-Sham orbitals, and by doing so can describe
seamlessly non-local electron correlations that the lower-rung functionals fail
to capture. The doubly hybrid approximations (DHAs) and random phase
approximation (RPA) based methods are two representative classes of fifth-rung
functionals that have been under active development over the past two decades.
In this review, we recapitulate the basic concepts of DHAs and RPA, derive
their underlying theoretical formulation from the perspective of
adiabatic-connection fluctuation-dissipation theory, and describe the
implementation algorithms based on the resolution-of-identity technique within
an atomic-orbital basis-set framework. Illustrating examples of practical
applications of DHAs and RPA are presented, highlighting the usefulness of
these functionals in resolving challenging problems in computational materials
science. The most recent advances in the realms of these two types of
functionals are briefly discussed.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:09:37 GMT""}]","2023-01-31"
"2301.12120","Rupert Coy","Rupert Coy","A forgotten fermion: the hypercharge -3/2 doublet, its phenomenology and
  connections to dark matter","29 pages, 5 figures",,"10.1007/JHEP04(2023)133","ULB-TH/23-02","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A weak-doublet with hypercharge $-3/2$ is one of only a handful of fermions
which has a renormalisable interaction with Standard Model fields. This should
make it worthy of attention, but it has thus far received little consideration
in the literature. In this paper, we perform a thorough investigation of the
phenomenology which results from the introduction of this field, $F$. After
expressing the model in terms of its effective field theory at dimension-6, we
compute a range of electroweak and leptonic observables, the most stringent of
which probe up to $M_F \sim 300$ TeV. The simplicity of this scenario makes it
very predictive and allows us to correlate the different processes. We then
study how this new fermion can connect the SM to various simple but distinct
dark sectors. Some of the most minimal cases of $F$-mediated dark matter (DM)
involve frozen-in keV-scale scalar DM, which may produce x-ray lines, and
frozen-out TeV-scale fermionic DM.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:10:26 GMT""}]","2023-05-17"
"2301.12121","Guobin Liu Dr","Erwei Li, Qianjin Ma, Guobin Liu, Peter Yun and Shougang Zhang","Self-driven Hybrid Atom Spin Oscillator","5 pages,4 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  A self-driven hybrid atom spin oscillator is demonstrated in theory and
experiment with a vapor Rb-Xe dual-spin system. The raw signal of Rb spin
oscillation is amplified, phase-shifted and sent back to drive the Xe spins
coherently. By fine tuning the driving field strength and phase, a
self-sustaining spin oscillation signal with zero frequency shift is obtained.
The effective coherence time is infinitely prolonged beyond the intrinsic
coherence time of Xe spins, forming a hybrid atom spin oscillator. Spectral
analysis indicates that a frequency resolution of 13.1 nHz is achieved,
enhancing the detection sensitivity for magnetic field. Allan deviation
analysis shows that the spin oscillator can operate in continuous wave mode
like a spin maser. The prototype spin oscillator can be easily implanted into
other hybrid spin systems and enhance the detection sensitivity of alkali
metal-noble gas comagnetometers.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:17:36 GMT""}]","2023-01-31"
"2301.12122","Shenggen Zheng","Jiaxi Zhang, Shenggen Zheng, Liwei Ni, Huawei Li, Guojie Luo","Rethinking NPN Classification from Face and Point Characteristics of
  Boolean Functions","Accepted to DATE'23",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  NPN classification is an essential problem in the design and verification of
digital circuits. Most existing works explored variable symmetries and cofactor
signatures to develop their classification methods. However, cofactor
signatures only consider the face characteristics of Boolean functions. In this
paper, we propose a new NPN classifier using both face and point
characteristics of Boolean functions, including cofactor, influence, and
sensitivity. The new method brings a new perspective to the classification of
Boolean functions. The classifier only needs to compute some signatures, and
the equality of corresponding signatures is a prerequisite for NPN equivalence.
Therefore, these signatures can be directly used for NPN classification, thus
avoiding the exhaustive transformation enumeration. The experiments show that
the proposed NPN classifier gains better NPN classification accuracy with
comparable speed.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:21:08 GMT""}]","2023-01-31"
"2301.12123","Alexei Stepanov","Alexei Stepanov","Note on the First Part of Borel-Cantelli Lemma",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In this short note, we briefly discuss the Borel-Cantelli lemma and propose a
new generalization of the first part of it.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:26:33 GMT""}]","2023-01-31"
"2301.12124","Junxiong Hu Doc.","Junxiong Hu, Junyou Tan, Mohammed M. Al Ezzi, Udvas Chattopadhyay,
  Jian Gou, Yuntian Zheng, Zihao Wang, Jiayu Chen, Reshmi Thottathil, Jiangbo
  Luo, Kenji Watanabe, Takashi Taniguchi, Andrew Thye Shen Wee, Shaffique Adam,
  Ariando Ariando","Controlled alignment of supermoir\'e lattice in double-aligned graphene
  heterostructures","20 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The supermoir\'e lattice, built by stacking two moir\'e patterns, provides a
platform for creating flat mini-bands and studying electron correlations. An
ultimate challenge in assembling a graphene supermoir\'e lattice is in the
deterministic control of its rotational alignment, which is made highly
probabilistic due to the random nature of the edge chirality and crystal
symmetry of each component layer. In this work, we present an experimental
strategy to overcome this challenge and realize the controlled alignment of
double-aligned hBN/graphene/hBN supermoir\'e lattice, where graphene is
precisely aligned with both top hBN and bottom hBN. Remarkably, we find that
the crystallographic edge of neighboring graphite can be used to better guide
the stacking alignment, as demonstrated by the controlled production of 20
moir\'e samples with an accuracy better than 0.2 degree. Employing this
technique, we are first time to fabricate the perfect double-aligned graphene
supermoir\'e lattice and to observe the sharp resistivity peaks at band filling
of 0, -4 and -8 electrons per moir\'e unit cell. Finally, we extend our
technique to other strongly correlated electron systems, such as low-angle
twisted bilayer graphene and ABC-stacked trilayer graphene, providing a
strategy for flat-band engineering in these moir\'e materials.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:43:45 GMT""}]","2023-01-31"
"2301.12125","Yuan-Pei Yang","Yuan-Pei Yang and Bing Zhang","Coherent Curvature Radiation Spectrum by Dynamically Fluctuating Bunches
  in Magnetospheres","12 pages, 6 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stad1311",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Coherent curvature radiation by charged bunches has been discussed as the
radiation mechanism for radio pulsars and fast radio bursts. Important issues
for this radiation mechanism include how the bunches form and disperse in the
magnetosphere of a pulsar or magnetar. More likely, bunches form and disperse
continuously and it remains unclear what the spectral features are for these
fluctuating bunches. In this work, we consider that the bunches in a
magnetosphere have a formation rate of $\lambda_B$, a lifetime of $\tau_B$, and
a typical Lorentz factor of $\gamma$, and analyze the spectral features of
coherent curvature radiation by these fluctuating bunches. We find that the
emission spectrum by a single fluctuating bunch is suppressed by a factor of
$\sim(\lambda_B\tau_B)^2$ compared with that of a single persistent bunch, and
there is a quasi-white noise in a wider band in the frequency domain. The
high-frequency cutoff of the spectrum is at $\sim\max(\omega_{\rm
peak},2\gamma^2/\tau_B)$, where $\omega_{\rm peak}$ is the peak frequency of
curvature radiation. If the observed spectrum is not white-noise-like, the
condition of $2\gamma^2\lambda_B\gtrsim \min(\omega_{\rm
peak},2\gamma^2/\tau_B)$ would be required. Besides, the radiation by multiple
fluctuating bunches along a field line is the incoherent summation of the
radiation by single bunches if the bunch separation is longer than the
wavelength. Conversely, a coherent summation should be involved. We also
discuss the effects of bunch structures and the mechanism of bunch formation
and dispersion.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:44:01 GMT""},{""version"":""v2"",""created"":""Fri, 28 Apr 2023 08:45:01 GMT""}]","2023-05-10"
"2301.12126","Naoki Kitazawa","Naoki Kitazawa","Smooth maps like special generic maps","20 pages, 1 figure, this version is a revised version of th previous
  version, submitted to a refereed journal, Theorems etc. added as new our work
  after the submission",,,,"math.GN math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In our paper, we introduce special-generic-like maps or SGL maps as smooth
maps and study their several algebraic topological and differential topological
properties.
  The new class generalize the class of so-called special generic maps. Special
generic maps are smooth maps which are locally projections or the product maps
of Morse functions and the identity maps on disks. Morse functions with exactly
two singular points on spheres or Morse functions in Reeb's theorem are
simplest examples. Special generic maps and the manifolds of their domains have
been studied well. Their structures are simple and this help us to study
explicitly. As important properties, they have been shown to restrict the
topologies and the differentiable structures of the manifolds strongly by Saeki
and Sakuma, followed by Nishioka, Wrazidlo and the author. To cover wider
classes of manifolds as the domains, the author previously introduced a class
generalizing the class of special generic maps and smaller than our class:
simply generalized special generic maps.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:45:27 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 13:29:32 GMT""},{""version"":""v3"",""created"":""Sat, 11 Feb 2023 19:35:02 GMT""}]","2023-02-14"
"2301.12127","Gerd Kortemeyer","Gerd Kortemeyer","Could an Artificial-Intelligence agent pass an introductory physics
  course?",,,"10.1103/PhysRevPhysEducRes.19.010132",,"physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  Massive pre-trained language models have garnered attention and controversy
due to their ability to generate human-like responses: attention due to their
frequent indistinguishability from human-generated phraseology and narratives,
and controversy due to the fact that their convincingly presented arguments and
facts are frequently simply false. Just how human-like are these responses when
it comes to dialogues about physics, in particular about the standard content
of introductory physics courses? This study explores that question by having
ChatGTP, the pre-eminent language model in 2023, work through representative
assessment content of an actual calculus-based physics course and grading the
responses in the same way human responses would be graded. As it turns out,
ChatGPT would narrowly pass this course while exhibiting many of the
preconceptions and errors of a beginning learner.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:45:30 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 17:22:16 GMT""}]","2023-05-23"
"2301.12128","Yoshihiko Suyama","Nozomu Matsuura and Yoshihiko Suyama","Curvature surfaces in generic conformally flat hypersurfaces arising
  from Poincar\'{e} metric -- Extension and approximation",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study generic conformally flat (analytic-)hypersurfaces in the Euclidean
$4$-space $\mathbb{R}^4$. Such a local-hypersurface is obtained as an evolution
of surfaces issuing from a certain surface in $\mathbb{R}^4$, and then, in
consequence, the original surface is a (principal-)curvature surface of the
hypersurface. The Poincar\'{e} metric ${\check g}_H$ of the upper half plane
leads to a $6$-dimensional set of singular (analytic-)Riemannian $2$-metrics
$g_0$ of $\mathbb{R}^2$: on a simply connected open set in the regular domain
of $g_0$, a curvature surface with the metric $g_0$ is determined. In this
paper, we choose a suitable singular metric $g_0$ for ${\check g}_H$ and
clarify the structure of the curvature surfaces: the curvature surfaces extend
analytically to what kind set of $\mathbb{R}^2$ beyond the regular set of
$g_0$; we explicitly catch the singularities and the points of infinity of
$g_0$ for the surface. In this case, all principal curvature lines in the
extended surface are expressed by a frame field of $\mathbb{R}^4$ induced on
the surface from hypersurfaces and they lie on some standard $2$-spheres
$\mathbb{S}^2$, respectively. We also provide a general method of constructing
an approximation of such frame fields, and obtain the figures of those lines
including the singular points of $g_0$.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:47:09 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 05:20:15 GMT""},{""version"":""v3"",""created"":""Thu, 25 May 2023 03:16:09 GMT""}]","2023-05-26"
"2301.12129","Yuanxi Wu","Yuanxi Wu, Zhi Wu, Wei Gu, Zheng Xu, Shu Zheng, Qirun Sun","Decentralized Energy Market Integrating Carbon Allowance Trade and
  Uncertainty Balance in Energy Communities",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the sustained attention on carbon neutrality, the personal carbon
trading (PCT) scheme has been embraced as an auspicious paradigm for scaling
down carbon emissions. To facilitate the simultaneous clearance of energy and
carbon allowance inside the energy community while hedging against uncertainty,
a joint trading framework is proposed in this article. The energy trading is
implemented in a peer-to-peer (P2P) manner without the intervention of a
central operator, and the uncertainty trading is materialized through procuring
reserve of conventional generators and flexibility of users. Under the PCT
scheme, carbon allowance is transacted via a sharing mechanism. Possible
excessive carbon emissions due to uncertainty balance are tackled by obliging
renewable agents to procure sufficient carbon allowances, following the
consumption responsibility principle. A two-stage iterative method consisting
of tightening McCormick envelope and alternating direction method of
multipliers (ADMM) is devised to transform the model into a mixed-integer
second-order cone program (MISOCP) and to allow for a fully decentralized
market-clearing procedure. Numerical results have validated the effectiveness
of the proposed market model.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:47:50 GMT""}]","2023-01-31"
"2301.12130","Wenjia Wang","Jing Zhang, Chi Zhang, Wenjia Wang, Bing-Yi Jing","APAC: Authorized Probability-controlled Actor-Critic For Offline
  Reinforcement Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the inability to interact with the environment, offline reinforcement
learning (RL) methods face the challenge of estimating the Out-of-Distribution
(OOD) points. Most existing methods exclude the OOD areas or restrict the value
of $Q$ function. However, these methods either are over-conservative or suffer
from model uncertainty prediction. In this paper, we propose an authorized
probabilistic-control policy learning (APAC) method. The proposed method learns
the distribution characteristics of the feasible states/actions by utilizing
the flow-GAN model. Specifically, APAC avoids taking action in the low
probability density region of behavior policy, while allows exploration in the
authorized high probability density region. Theoretical proofs are provided to
justify the advantage of APAC. Empirically, APAC outperforms existing
alternatives on a variety of simulated tasks, and yields higher expected
returns.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:48:26 GMT""}]","2023-01-31"
"2301.12131","Zeyuan Yang","Zeyuan Yang, Zonghan Yang, Peng Li, Yang Liu","Restricted Orthogonal Gradient Projection for Continual Learning","19 pages, 9 figures and 17 tables",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continual learning aims to avoid catastrophic forgetting and effectively
leverage learned experiences to master new knowledge. Existing gradient
projection approaches impose hard constraints on the optimization space for new
tasks to minimize interference, which simultaneously hinders forward knowledge
transfer. To address this issue, recent methods reuse frozen parameters with a
growing network, resulting in high computational costs. Thus, it remains a
challenge whether we can improve forward knowledge transfer for gradient
projection approaches using a fixed network architecture. In this work, we
propose the Restricted Orthogonal Gradient prOjection (ROGO) framework. The
basic idea is to adopt a restricted orthogonal constraint allowing parameters
optimized in the direction oblique to the whole frozen space to facilitate
forward knowledge transfer while consolidating previous knowledge. Our
framework requires neither data buffers nor extra parameters. Extensive
experiments have demonstrated the superiority of our framework over several
strong baselines. We also provide theoretical guarantees for our relaxing
strategy.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:50:48 GMT""}]","2023-01-31"
"2301.12132","Han Zhou","Han Zhou, Xingchen Wan, Ivan Vuli\'c, Anna Korhonen","AutoPEFT: Automatic Configuration Search for Parameter-Efficient
  Fine-Tuning","17 pages, 7 figures, 9 tables",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large pretrained language models are widely used in downstream NLP tasks via
task-specific fine-tuning, but such procedures can be costly. Recently,
Parameter-Efficient Fine-Tuning (PEFT) methods have achieved strong task
performance while updating a much smaller number of parameters compared to full
model fine-tuning (FFT). However, it is non-trivial to make informed design
choices on the PEFT configurations, such as their architecture, the number of
tunable parameters, and even the layers in which the PEFT modules are inserted.
Consequently, it is highly likely that the current, manually designed
configurations are suboptimal in terms of their performance-efficiency
trade-off. Inspired by advances in neural architecture search, we propose
AutoPEFT for automatic PEFT configuration selection: we first design an
expressive configuration search space with multiple representative PEFT modules
as building blocks. Using multi-objective Bayesian optimisation in a low-cost
setup, we then discover a Pareto-optimal set of configurations with strong
performance-cost trade-offs across different numbers of parameters that are
also highly transferable across different tasks. Empirically, on GLUE and
SuperGLUE tasks, we show that AutoPEFT-discovered configurations significantly
outperform existing PEFT methods and are on par or better than FFT, without
incurring substantial training efficiency costs.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:51:23 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 17:07:23 GMT""}]","2023-06-07"
"2301.12133","Tiberiu Harko","Zahra Haghani, Tiberiu Harko, Shahab Shahidi","The first variation of the matter energy-momentum tensor with respect to
  the metric, and its implications on modified gravity theories","9 pages, 4 figures",,,,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The first order variation of the matter energy-momentum tensor $T_{\mu \nu}$
with respect to the metric tensor $g^{\alpha \beta}$ plays an important role in
modified gravity theories with geometry-matter coupling, and in particular in
the $f(R,T)$ modified gravity theory. We obtain the expression of the variation
$\delta T_{\mu \nu}/\delta g^{\alpha \beta}$ for the baryonic matter described
by an equation given in a parametric form, with the basic thermodynamic
variables represented by the particle number density, and by the specific
entropy, respectively. The first variation of the matter energy-momentum tensor
turns out to be independent on the matter Lagrangian, and can be expressed in
terms of the pressure, the energy-momentum tensor itself, and the matter fluid
four-velocity. We apply the obtained results for the case of the $f(R,T)$
gravity theory, where $R$ is the Ricci scalar, and $T$ is the trace of the
matter energy-momentum tensor, which thus becomes a unique theory, also
independent on the choice of the matter Lagrangian. A simple cosmological
model, in which the Hilbert-Einstein Lagrangian is generalized through the
addition of a term proportional to $T^n$ is considered in detail, and it is
shown that it gives a very good description of the observational values of the
Hubble parameter up to a redshift of $z\approx 2.5$.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:03:21 GMT""},{""version"":""v2"",""created"":""Sun, 14 May 2023 12:01:59 GMT""}]","2023-05-16"
"2301.12134","Parth Parekh","Parth Parekh, Cedric McGuire, Jake Imyak","Underwater Robotics Semantic Parser Assistant","6 Pages, 4 figures",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Semantic parsing is a means of taking natural language and putting it in a
form that a computer can understand. There has been a multitude of approaches
that take natural language utterances and form them into lambda calculus
expressions -- mathematical functions to describe logic. Here, we experiment
with a sequence to sequence model to take natural language utterances, convert
those to lambda calculus expressions, when can then be parsed, and place them
in an XML format that can be used by a finite state machine. Experimental
results show that we can have a high accuracy model such that we can bridge the
gap between technical and nontechnical individuals in the robotics field.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:04:43 GMT""}]","2023-01-31"
"2301.12135","Yu Chen","Yu Chen, Zihao Yu, Shu Song, Tianning Yu, Jianming Li, Gim Hee Lee","AdaSfM: From Coarse Global to Fine Incremental Adaptive Structure from
  Motion","accepted by ICRA 2023",,,,"cs.CV cs.DC","http://creativecommons.org/licenses/by/4.0/","  Despite the impressive results achieved by many existing Structure from
Motion (SfM) approaches, there is still a need to improve the robustness,
accuracy, and efficiency on large-scale scenes with many outlier matches and
sparse view graphs. In this paper, we propose AdaSfM: a coarse-to-fine adaptive
SfM approach that is scalable to large-scale and challenging datasets. Our
approach first does a coarse global SfM which improves the reliability of the
view graph by leveraging measurements from low-cost sensors such as Inertial
Measurement Units (IMUs) and wheel encoders. Subsequently, the view graph is
divided into sub-scenes that are refined in parallel by a fine local
incremental SfM regularised by the result from the coarse global SfM to improve
the camera registration accuracy and alleviate scene drifts. Finally, our
approach uses a threshold-adaptive strategy to align all local reconstructions
to the coordinate frame of global SfM. Extensive experiments on large-scale
benchmark datasets show that our approach achieves state-of-the-art accuracy
and efficiency.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:06:50 GMT""}]","2023-01-31"
"2301.12136","Vasilis Oikonomou","V.K. Oikonomou","$R^p$ Attractors Static Neutron Star Phenomenology","MNRAS Accepted",,"10.1093/mnras/stad326",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study the neutron star phenomenology of $R^p$ attractor
theories in the Einstein frame. The Einstein frame $R^p$ attractor theories
have the attractor property that they originate from a large class of Jordan
frame scalar theories with arbitrary non-minimal coupling. These theories in
the Einstein frame provide a viable class of inflationary models, and in this
work we investigate their implications on static neutron stars. We numerically
solve the Tolman-Oppenheimer-Volkoff equations in the Einstein frame, for three
distinct equations of state, and we provide the mass-radius diagrams for
several cases of interest of the $R^p$ attractor theories. We confront the
results with several timely constraints on the radii of specific mass neutron
stars, and as we show, only a few cases corresponding to specific equations of
state pass the stringent tests on neutron stars phenomenology.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:07:40 GMT""}]","2023-02-08"
"2301.12137","Apostolos Vourdas","C. Lei, A. Vourdas","Unitarily inequivalent local and global Fourier transforms in
  multipartite quantum systems",,"Quantum Information Processing 22, 78 (2023)",,,"quant-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A multipartite system comprised of $n$ subsystems, each of which is described
with `local variables' in ${\mathbb Z}(d)$ and with a $d$-dimensional Hilbert
space $H(d)$, is considered. Local Fourier transforms in each subsystem are
defined and related phase space methods are discussed (displacement operators,
Wigner and Weyl functions, etc). A holistic view of the same system might be
more appropriate in the case of strong interactions, which uses `global
variables' in ${\mathbb Z}(d^n)$ and a $d^n$-dimensional Hilbert space
$H(d^n)$. A global Fourier transform is then defined and related phase space
methods are discussed. The local formalism is compared and contrasted with the
global formalism. Depending on the values of $d,n$ the local Fourier transform
is unitarily inequivalent or unitarily equivalent to the global Fourier
transform. Time evolution of the system in terms of both local and global
variables, is discussed. The formalism can be useful in the general area of
Fast Fourier transforms.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:16:22 GMT""}]","2023-01-31"
"2301.12138","Jing-ning Zhang","Xue-Gang Li, Hui-Kai Xu, Jun-Hua Wang, Ling-Zhi Tang, Dan-Wei Zhang,
  Chu-Hong Yang, Tang Su, Chen-Lu Wang, Zhen-Yu Mi, Wei-Jie Sun, Xue-Hui Liang,
  Mo Chen, Cheng-Yao Li, Ying-Shan Zhang, Ke-Huan Linghu, Jia-Xiu Han, Wei-Yang
  Liu, Yu-Long Feng, Pei Liu, Guang-Ming Xue, Jing-Ning Zhang, Yi-Rong Jin,
  Shi-Liang Zhu, Hai-Feng Yu, Qi-Kun Xue","Mapping a topology-disorder phase diagram with a quantum simulator",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The competition and interplay of topology and disorder has been one of the
most famous topics in the field of condensed matter physics. In addition to the
intuitive tendency to bring the system into a topologically trivial and
localized phase, it has been discovered that disorder can also induce
nontrivial topology and transport. To reveal rich and diverse phase structures,
mapping phase diagrams plays an important role in both theoretical and
experimental sides. Quantum simulation provides a prospective way to study the
target model, explore the phase diagram and reveal the underlying mechanism.
Thanks to the unprecedented controllability, superconducting quantum simulators
have been introduced to investigate complex many-body physics and bring thought
experiments into reality. To our best knowledge, the effort to map a phase
diagram with a rich structure is still lacking. Here we report a systematic
experimental study of the topology-disorder phase diagram with 32 qubits on a
programmable analog quantum simulator. We implement one-dimensional (1D)
disordered dimerized tight-binding models over a wide parameter range and
observe diverse phases, including the topological Anderson insulator (TAI) and
the inverse Anderson localization (IAL). Our experiment manifests the
efficiency, accuracy and flexibility of the superconducting-circuit device and
paves the way to the demonstration and understanding of many-body phenomena
with noisy intermediate-scale quantum simulators.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:19:41 GMT""}]","2023-01-31"
"2301.12139","Tosin Adewumi","Tosin Adewumi, Isabella S\""odergren, Lama Alkhaled, Sana Sabah Sabry,
  Foteini Liwicki and Marcus Liwicki","Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark
  Datasets","7 pages, 13 figures",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We evaluate five English NLP benchmark datasets (available on the superGLUE
leaderboard) for bias, along multiple axes. The datasets are the following:
Boolean Question (Boolq), CommitmentBank (CB), Winograd Schema Challenge (WSC),
Winogender diagnostic (AXg), and Recognising Textual Entailment (RTE). Bias can
be harmful and it is known to be common in data, which ML models learn from. In
order to mitigate bias in data, it is crucial to be able to estimate it
objectively. We use bipol, a novel multi-axes bias metric with explainability,
to quantify and explain how much bias exists in these datasets. Multilingual,
multi-axes bias evaluation is not very common. Hence, we also contribute a new,
large labelled Swedish bias-detection dataset, with about 2 million samples;
translated from the English version. In addition, we contribute new multi-axes
lexica for bias detection in Swedish. We train a SotA model on the new dataset
for bias detection. We make the codes, model, and new dataset publicly
available.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:28:19 GMT""}]","2023-01-31"
"2301.12140","Yun Chen","Weikang Wang, Guanhua Chen, Hanqing Wang, Yue Han, Yun Chen","Multilingual Sentence Transformer as A Multilingual Word Aligner","Published at Findings of EMNLP 2022",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multilingual pretrained language models (mPLMs) have shown their
effectiveness in multilingual word alignment induction. However, these methods
usually start from mBERT or XLM-R. In this paper, we investigate whether
multilingual sentence Transformer LaBSE is a strong multilingual word aligner.
This idea is non-trivial as LaBSE is trained to learn language-agnostic
sentence-level embeddings, while the alignment extraction task requires the
more fine-grained word-level embeddings to be language-agnostic. We demonstrate
that the vanilla LaBSE outperforms other mPLMs currently used in the alignment
task, and then propose to finetune LaBSE on parallel corpus for further
improvement. Experiment results on seven language pairs show that our best
aligner outperforms previous state-of-the-art models of all varieties. In
addition, our aligner supports different language pairs in a single model, and
even achieves new state-of-the-art on zero-shot language pairs that does not
appear in the finetuning process.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:28:55 GMT""}]","2023-01-31"
"2301.12141","Pu Cao","Pu Cao, Lu Yang, Dongxu Liu, Shan Li, Yao Zhang, Qing Song","What Decreases Editing Capability? Domain-Specific Hybrid Refinement for
  Improved GAN Inversion",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recently, inversion methods have focused on additional high-rate information
in the generator (e.g., weights or intermediate features) to refine inversion
and editing results from embedded latent codes. Although these techniques gain
reasonable improvement in reconstruction, they decrease editing capability,
especially on complex images (e.g., containing occlusions, detailed
backgrounds, and artifacts). A vital crux is refining inversion results,
avoiding editing capability degradation. To tackle this problem, we introduce
Domain-Specific Hybrid Refinement (DHR), which draws on the advantages and
disadvantages of two mainstream refinement techniques to maintain editing
ability with fidelity improvement. Specifically, we first propose
Domain-Specific Segmentation to segment images into two parts: in-domain and
out-of-domain parts. The refinement process aims to maintain the editability
for in-domain areas and improve two domains' fidelity. We refine these two
parts by weight modulation and feature modulation, which we call Hybrid
Modulation Refinement. Our proposed method is compatible with all latent code
embedding methods. Extension experiments demonstrate that our approach achieves
state-of-the-art in real image inversion and editing. Code is available at
https://github.com/caopulan/GANInverter/tree/main/configs/dhr.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:31:20 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 10:58:20 GMT""}]","2023-03-17"
"2301.12142","Zaili Yan","Hui Zhang and Zaili Yan","The moment map for the variety of associative algebras",,,,,"math.DG math.RA","http://creativecommons.org/licenses/by/4.0/","  We consider the moment map $m:\mathbb{P}V_n\rightarrow
\text{i}\mathfrak{u}(n)$ for the action of $\text{GL}(n)$ on
$V_n=\otimes^{2}(\mathbb{C}^{n})^{*}\otimes\mathbb{C}^{n}$, and study the
critical points of the functional $F_n=\|m\|^{2}: \mathbb{P} V_n \rightarrow
\mathbb{R}$. Firstly, we prove that $[\mu]\in \mathbb{P}V_n$ is a critical
point if and only if $\text{M}_{\mu}=c_{\mu} I+D_{\mu}$ for some $c_{\mu} \in
\mathbb{R}$ and $D_{\mu} \in \text{Der}(\mu),$ where
$m([\mu])=\frac{\text{M}_{\mu}}{\|\mu\|^{2}}$. Then we show that any algebra
$\mu$ admits a Nikolayevsky derivation $\phi_\mu$ which is unique up to
automorphism, and if moreover, $[\mu]$ is a critical point of $F_n$, then
$\phi_\mu=-\frac{1}{c_\mu}D_\mu.$ Secondly, we characterize the maxima and
minima of the functional $F_n: \mathcal{A}_n \rightarrow \mathbb{R}$, where
$\mathcal{A}_n$ denotes the projectivization of the algebraic varieties of all
$n$-dimensional associative algebras. Furthermore, for an arbitrary critical
point $[\mu]$ of $F_n: \mathcal{A}_n \rightarrow \mathbb{R}$, we also obtain a
description of the algebraic structure of $[\mu]$. Finally, we classify the
critical points of $F_n: \mathcal{A}_n \rightarrow \mathbb{R}$ for $n=2$, $3$,
respectively.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:36:22 GMT""}]","2023-01-31"
"2301.12143","Hiroshi Ishimoto","Hiroshi Ishimoto","The endoscopic classification of representations of non-quasi-split odd
  special orthogonal groups","68 pages. Any comments are welcome",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In an earlier book of Arthur, the endoscopic classification of
representations of quasi-split orthogonal and symplectic groups was
established. Later Mok gave that of quasi-split unitary groups. After that,
Kaletha, Minguez, Shin, and White gave that of non-quasi-split unitary groups
for generic parameters. In this paper we prove the endoscopic classification of
representations of non-quasi-split odd special orthogonal groups for generic
parameters, following Kaletha, Minguez, Shin, and White.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:38:41 GMT""}]","2023-01-31"
"2301.12144","Zhong Zheng","Zhong Zheng, Siqiang Wang, Zesong Fei, Zhi Sun, Jinhong Yuan","On the Mutual Information of Multi-RIS Assisted MIMO: From
  Operator-Valued Free Probability Aspect","30 pages, 5 figures",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  The reconfigurable intelligent surface (RIS) is useful to effectively improve
the coverage and data rate of end-to-end communications. In contrast to the
well-studied coverage-extension use case, in this paper, multiple RIS panels
are introduced, aiming to enhance the data rate of multi-input multi-output
(MIMO) channels in presence of insufficient scattering. Specifically, via the
operator-valued free probability theory, the asymptotic mutual information of
the large-dimensional RIS-assisted MIMO channel is obtained under the Rician
fading with Weichselberger's correlation structure, in presence of both the
direct and the reflected links. Although the mutual information of Rician MIMO
channels scales linearly as the number of antennas and the signal-to-noise
ratio (SNR) in decibels, numerical results show that it requires sufficiently
large SNR, proportional to the Rician factor, in order to obtain the
theoretically guaranteed linear improvement. This paper shows that the proposed
multi-RIS deployment is especially effective to improve the mutual information
of MIMO channels under the large Rician factor conditions. When the reflected
links have similar arriving and departing angles across the RIS panels, a small
number of RIS panels are sufficient to harness the spatial degree of freedom of
the multi-RIS assisted MIMO channels.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:56:49 GMT""}]","2023-01-31"
"2301.12145","Nicolas Privault","Qingwei Liu and Nicolas Privault","Normal approximation of subgraph counts in the random-connection model",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper derives normal approximation results for subgraph counts written
as multiparameter stochastic integrals in a random-connection model based on a
Poisson point process. By combinatorial arguments we express the cumulants of
general subgraph counts using sums over connected partition diagrams, after
cancellation of terms obtained by M\""obius inversion. Using the
Statulevi\v{c}ius condition, we deduce convergence rates in the Kolmogorov
distance by studying the growth of subgraph count cumulants as the intensity of
the underlying Poisson point process tends to infinity. Our analysis covers
general subgraphs in the dilute and full random graph regimes, and tree-like
subgraphs in the sparse random graph regime.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 09:57:18 GMT""},{""version"":""v2"",""created"":""Sun, 9 Apr 2023 07:52:47 GMT""}]","2023-04-11"
"2301.12146","Luke Pebody","Luke Pebody","On Tribonacci Sequences",,,,,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  Let a tribonacci sequence be a sequence of integers satisfying
$a_k=a_{k-1}+a_{k-2}+a_{k-3}$ for all $k\ge 4$. For any positive integers $k$
and $n$, denote by $f_k(n)$ the number of tribonacci sequences with $a_1, a_2,
a_3>0$ and with $a_k=n$. For all $n$, there is a maximum $k$ such that $f_k(n)$
is non-zero. Answering a question of Spiro \cite{Spiro}, we show that there is
a finite upper bound (we specifically prove 561001) on $f_k(n)$ for any
positive integer $n\ge 3$ and this maximum $k$. We do this by showing that
$f_k(n)$ has transitions in $n$ around constant multiples of $\phi^{3k/2}$
(where $\phi$ is the real root of $\phi^3=\phi^2+\phi+1$): there exists a
constant $C$ such that $f_k(n)>0$ whenever $n>C\phi^{3k/2}$ and for any
constant $T$, the values of $f_k(n)$ with $n<T\phi^{3k/2}$ have an upper bound
independent of $k$.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:04:35 GMT""}]","2023-01-31"
"2301.12147","Kenichiro Umezu","Kenichiro Umezu","Logistic elliptic equation with a nonlinear boundary condition arising
  from coastal fishery harvesting II","21 pages, 3 figures",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the positive solutions of the logistic elliptic equation with a
nonlinear Neumann boundary condition that models coastal fishery harvesting
([18]). An essential role is played by the smallest eigenvalue of the Dirichlet
eigenvalue problem, with respect to which a noncritical case is studied in
[32]. In this paper, we extend our analysis to the critical case and further
study the noncritical case for a more precise description of the positive
solution set. Our approach relies on the energy method, sub- and
supersolutions, and implicit function analysis.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:05:21 GMT""}]","2023-01-31"
"2301.12148","Ryoji Tanabe","Ryoji Tanabe and Ke Li","Quality Indicators for Preference-based Evolutionary Multi-objective
  Optimization Using a Reference Point: A Review and Analysis",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some quality indicators have been proposed for benchmarking preference-based
evolutionary multi-objective optimization algorithms using a reference point.
Although a systematic review and analysis of the quality indicators are helpful
for both benchmarking and practical decision-making, neither has been
conducted. In this context, first, this paper reviews existing regions of
interest and quality indicators for preference-based evolutionary
multi-objective optimization using the reference point. We point out that each
quality indicator was designed for a different region of interest. Then, this
paper investigates the properties of the quality indicators. We demonstrate
that an achievement scalarizing function value is not always consistent with
the distance from a solution to the reference point in the objective space. We
observe that the regions of interest can be significantly different depending
on the position of the reference point and the shape of the Pareto front. We
identify undesirable properties of some quality indicators. We also show that
the ranking of preference-based evolutionary multi-objective optimization
algorithms depends on the choice of quality indicators.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:21:37 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 03:04:16 GMT""}]","2023-06-02"
"2301.12149","Yuanqi Chang","Jiawei Mao, Rui Xu, Xuesong Yin, Yuanqi Chang, Binling Nie, Aibin
  Huang","POSTER++: A simpler and stronger facial expression recognition network",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Facial expression recognition (FER) plays an important role in a variety of
real-world applications such as human-computer interaction. POSTER achieves the
state-of-the-art (SOTA) performance in FER by effectively combining facial
landmark and image features through two-stream pyramid cross-fusion design.
However, the architecture of POSTER is undoubtedly complex. It causes expensive
computational costs. In order to relieve the computational pressure of POSTER,
in this paper, we propose POSTER++. It improves POSTER in three directions:
cross-fusion, two-stream, and multi-scale feature extraction. In cross-fusion,
we use window-based cross-attention mechanism replacing vanilla cross-attention
mechanism. We remove the image-to-landmark branch in the two-stream design. For
multi-scale feature extraction, POSTER++ combines images with landmark's
multi-scale features to replace POSTER's pyramid design. Extensive experiments
on several standard datasets show that our POSTER++ achieves the SOTA FER
performance with the minimum computational cost. For example, POSTER++ reached
92.21% on RAF-DB, 67.49% on AffectNet (7 cls) and 63.77% on AffectNet (8 cls),
respectively, using only 8.4G floating point operations (FLOPs) and 43.7M
parameters (Param). This demonstrates the effectiveness of our improvements.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:23:44 GMT""},{""version"":""v2"",""created"":""Sun, 12 Feb 2023 11:04:37 GMT""}]","2023-02-14"
"2301.12150","Ali Azadbakht","Ali Azadbakht, Billie Meadowcroft, Thijs Varkevisser, Andela Saric,
  Daniela J. Kraft","Wrapping pathways of anisotropic dumbbell particles by giant unilamellar
  vesicles",,,"10.1021/acs.nanolett.3c00375",,"cond-mat.soft physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Endocytosis is a key cellular process involved in the uptake of nutrients,
pathogens or the diagnosis and therapy of diseases. Most studies have focused
on spherical objects, whereas biologically relevant shapes can be highly
anisotropic. In this letter, we use an experimental model system based on Giant
Unilamellar Vesicles (GUVs) and dumbbell-shaped colloidal particles to mimic
and investigate the first stage of the passive endocytic process: engulfment of
an anisotropic object by the membrane. Our model has specific ligand-receptor
interactions realized by mobile receptors on the vesicles and immobile ligands
on the particles. Through a series of experiments, theory and molecular
dynamics simulations, we quantify the wrapping process of anisotropic dumbbells
by GUVs and identify distinct stages of the wrapping pathway. We find that the
strong curvature variation in the neck of the dumbbell as well as membrane
tension are crucial in determining both the speed of wrapping and the final
states.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:24:33 GMT""}]","2023-06-07"
"2301.12151","Holger Trittenbach","Jona Klemenc, Holger Trittenbach","Selecting Models based on the Risk of Damage Caused by Adversarial
  Attacks",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regulation, legal liabilities, and societal concerns challenge the adoption
of AI in safety and security-critical applications. One of the key concerns is
that adversaries can cause harm by manipulating model predictions without being
detected. Regulation hence demands an assessment of the risk of damage caused
by adversaries. Yet, there is no method to translate this high-level demand
into actionable metrics that quantify the risk of damage.
  In this article, we propose a method to model and statistically estimate the
probability of damage arising from adversarial attacks. We show that our
proposed estimator is statistically consistent and unbiased. In experiments, we
demonstrate that the estimation results of our method have a clear and
actionable interpretation and outperform conventional metrics. We then show how
operators can use the estimation results to reliably select the model with the
lowest risk.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:24:38 GMT""}]","2023-01-31"
"2301.12152","Anfeng Cheng","Anfeng Cheng, Yiding Liu, Weibin Li, Qian Dong, Shuaiqiang Wang,
  Zhengjie Huang, Shikun Feng, Zhicong Cheng and Dawei Yin","Layout-aware Webpage Quality Assessment","10 pages, 5 figures",,,,"cs.IR cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Identifying high-quality webpages is fundamental for real-world search
engines, which can fulfil users' information need with the less cognitive
burden. Early studies of \emph{webpage quality assessment} usually design
hand-crafted features that may only work on particular categories of webpages
(e.g., shopping websites, medical websites). They can hardly be applied to
real-world search engines that serve trillions of webpages with various types
and purposes. In this paper, we propose a novel layout-aware webpage quality
assessment model currently deployed in our search engine. Intuitively, layout
is a universal and critical dimension for the quality assessment of different
categories of webpages. Based on this, we directly employ the meta-data that
describes a webpage, i.e., Document Object Model (DOM) tree, as the input of
our model. The DOM tree data unifies the representation of webpages with
different categories and purposes and indicates the layout of webpages. To
assess webpage quality from complex DOM tree data, we propose a graph neural
network (GNN) based method that extracts rich layout-aware information that
implies webpage quality in an end-to-end manner. Moreover, we improve the GNN
method with an attentive readout function, external web categories and a
category-aware sampling method. We conduct rigorous offline and online
experiments to show that our proposed solution is effective in real search
engines, improving the overall usability and user experience.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:27:53 GMT""},{""version"":""v2"",""created"":""Sun, 5 Feb 2023 08:51:10 GMT""}]","2023-02-07"
"2301.12153","Eduardo Garc\'ia-Ju\'arez","Eduardo Garc\'ia-Ju\'arez, Po-Chun Kuo, Yoichiro Mori, Robert M.
  Strain","Well-Posedness of the 3D Peskin Problem","93 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the 3D Peskin problem: a two-dimensional elastic
membrane immersed in a three-dimensional steady Stokes flow. We obtain the
equations that model this free boundary problem and show that they admit a
boundary integral reduction, providing an evolution equation for the elastic
interface. We consider general nonlinear elastic laws, i.e., the fully
nonlinear Peskin problem, and prove that the problem is well-posed in
low-regularity H\""older spaces. Moreover, we prove that the elastic membrane
becomes smooth instantly in time.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:31:56 GMT""}]","2023-01-31"
"2301.12154","Javier LLorca","Mingdi Yu, Yuchi Cui, Jingya Wang, Yiwen Chen, Zhigang Ding, Tao Ying,
  Javier Llorca, Xiaoqin Zeng","Critical resolved shear stresses for slip and twinning in Mg-Y-Ca alloys
  and their effect on the ductility",,"International Journal of Plasticity, 162, 103525, 2023",,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The deformation mechanisms of an extruded Mg-5Y-0.08Ca (wt. %) alloy were
analyzed by means of micropillar compression tests on single crystals along
different orientations -- selected to activate specific deformation modes -- as
well as slip trace analysis, transmission electron microscopy and transmission
Kikuchi diffraction. The polycrystalline alloy presented a remarkable ductility
in tension (~32%) and negligible differences in the yield strength between
tension and compression. It was found that the presence of Y and Ca in solid
solution led to a huge increase in the CRSS for <a> basal slip (29 $\pm$ 5
MPa), <c+a> pyramidal slip (203 $\pm$ 7 MPa) and tensile twin nucleation (above
148 MPa), while the CRSS for <a> prismatic slip only increases up to 105 $\pm$
4 MPa. The changes in the CRSS for slip and tensile twinning in Mg-Y-Ca alloys
expectedly modify the dominant deformation mechanisms in polycrystals. In
particular, tensile twinning is replaced by <a> prismatic slip during
compressive deformation along the a-axis. The reduction of twinning (which
generally induces strong anisotropy in the plastic deformation in textured
alloys), and the activation of <a> prismatic slip (which provides an additional
plastic deformation mechanism with limited hardening) were responsible for the
large tensile ductility of the alloy.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:33:58 GMT""}]","2023-01-31"
"2301.12155","Yuting Li Dr","Yuting Irene Li, Rosalba Garcia-Millan, Michael E. Cates, \'Etienne
  Fodor","Towards a liquid-state theory for active matter","2 figures",,,,"cond-mat.soft cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In equilibrium, the collective behaviour of particles interacting via steep,
short-ranged potentials is well captured by the virial expansion of the free
energy at low density. Here, we extend this approach beyond equilibrium to the
case of active matter with self-propelled particles. Given that active systems
do not admit any free-energy description in general, our aim is to build the
dynamics of the coarse-grained density from first principles without any
equilibrium assumption. Starting from microscopic equations of motion, we
obtain the hierarchy of density correlations, which we close with an ansatz for
the two-point density valid in the dilute regime at small activity. This
closure yields the nonlinear dynamics of the one-point density, with
hydrodynamic coefficients depending explicitly on microscopic interactions, by
analogy with the equilibrium virial expansion. This dynamics admits a spinodal
instability for purely repulsive interactions, a signature of motility-induced
phase separation. Therefore, although our approach should be restricted to
dilute, weakly-active systems a priori, it actually captures the features of a
broader class of active matter.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:34:10 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 09:29:19 GMT""}]","2023-05-25"
"2301.12156","Matthias Schmidt","Daniel de las Heras, Toni Zimmermann, Florian Samm\""uller, Sophie
  Hermann, and Matthias Schmidt","Perspective: How to overcome dynamical density functional theory","21 pages, 5 figures. J. Phys.: Condens. Matter (invited Perspective)",,"10.1088/1361-648X/accb33",,"cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We argue in favour of developing a comprehensive dynamical theory for
rationalizing, predicting, designing, and machine learning nonequilibrium
phenomena that occur in soft matter. To give guidance for navigating the
theoretical and practical challenges that lie ahead, we discuss and exemplify
the limitations of dynamical density functional theory. Instead of the implied
adiabatic sequence of equilibrium states that this approach provides as a
makeshift for the true time evolution, we posit that the pending theoretical
tasks lie in developing a systematic understanding of the dynamical functional
relationships that govern the genuine nonequilibrium physics. While static
density functional theory gives a comprehensive account of the equilibrium
properties of many-body systems, we argue that power functional theory is the
only present contender to shed similar insights into nonequilibrium dynamics,
including the recognition and implementation of exact sum rules that result
from the Noether theorem. As~a~demonstration of the power functional point of
view, we consider an idealized steady sedimentation flow of the
three-dimensional Lennard-Jones fluid and machine-learn the kinematic map from
the mean motion to the internal force field. The trained model is capable of
both predicting and designing the steady state dynamics universally for various
target density modulations. This demonstrates the significant potential of
using such techniques in nonequilibrium many-body physics and overcomes both
the conceptual constraints of dynamical density functional theory as well as
the limited availability of its analytical functional approximations.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:46:51 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 21:03:58 GMT""}]","2023-04-11"
"2301.12157","Evgenii Vasinovich","A. S. Moskvin, E. V. Vasinovich, A. V. Shadrin","Simple Realistic Model of Spin Reorientation in 4f-3d Compounds",,"Magnetochemistry 8, 45 (2022)","10.3390/magnetochemistry8040045",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Spin reorientation is an important phenomenon of rare-earth perovskites,
orthoferrites and orthochromites. In this study, we consider a simple but
realistic microscopic theory of the spontaneous spin-reorientation transitions
induced by the 4f-3d interaction, more specifically, the interaction of the
main Kramers doublet or non-Kramers quasi-doublet of the 4f ion with an
effective magnetic field induced by the 3d sublattice. The obtained results
indicate that the cause of both the temperature and the character of the
spin-reorientation transition is a competition between the second and fourth
order spin anisotropy of the 3d sublattice, the crystal field for 4f ions, and
the 4f-3d interaction.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:56:05 GMT""}]","2023-01-31"
"2301.12158","Debayan Banerjee","Debayan Banerjee, Mathis Poser, Christina Wiethof, Varun Shankar
  Subramanian, Richard Paucar, Eva A. C. Bittner, Chris Biemann","A System for Human-AI collaboration for Online Customer Support",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  AI enabled chat bots have recently been put to use to answer customer service
queries, however it is a common feedback of users that bots lack a personal
touch and are often unable to understand the real intent of the user's
question. To this end, it is desirable to have human involvement in the
customer servicing process. In this work, we present a system where a human
support agent collaborates in real-time with an AI agent to satisfactorily
answer customer queries. We describe the user interaction elements of the
solution, along with the machine learning techniques involved in the AI agent.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:07:23 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 09:31:26 GMT""}]","2023-02-08"
"2301.12159","Ahmed Abbas","Ahmed Abbas and Paul Swoboda","ClusterFuG: Clustering Fully connected Graphs by Multicut","ICML 2023",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a graph clustering formulation based on multicut (a.k.a. weighted
correlation clustering) on the complete graph. Our formulation does not need
specification of the graph topology as in the original sparse formulation of
multicut, making our approach simpler and potentially better performing. In
contrast to unweighted correlation clustering we allow for a more expressive
weighted cost structure. In dense multicut, the clustering objective is given
in a factorized form as inner products of node feature vectors. This allows for
an efficient formulation and inference in contrast to multicut/weighted
correlation clustering, which has at least quadratic representation and
computation complexity when working on the complete graph. We show how to
rewrite classical greedy algorithms for multicut in our dense setting and how
to modify them for greater efficiency and solution quality. In particular, our
algorithms scale to graphs with tens of thousands of nodes. Empirical evidence
on instance segmentation on Cityscapes and clustering of ImageNet datasets
shows the merits of our approach.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:10:50 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 08:56:05 GMT""}]","2023-06-06"
"2301.12160","Linlin Lei","Linlin Lei, Shuyuan Xiao, Wenxing Liu, Qinghua Liao, Lingjuan He, and
  Tianbao Yu","Polarization-independent second-order photonic topological corner states",,,,,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Recently, much attention has been paid to second-order photonic topological
insulators (SPTIs), because of their support for highly localized corner states
with excellent robustness. SPTIs have been implemented in either transverse
magnetic (TM) or transverse electric (TE) polarizations in two-dimensional (2D)
photonic crystals (PCs), and the resultant topological corner states are
polarization-dependent, which limits their application in
polarization-independent optics. However, to achieve polarization-independent
corner states is not easy, since they are usually in-gap and the exact location
in the topological bandgap is not known in advance. Here, we report on a SPTI
based on a 2D square-lattice PC made of an elliptic metamaterial, and whether
the bandgap is topological or trivial depends on the choice of the unit cell.
It is found that locations of topological bandgaps of TM and TE polarizations
in the frequency spectrum can be independently controlled by the out-of-plane
permittivity $\varepsilon_\perp$ and in-plane permittivity
$\varepsilon_{\varparallel}$, respectively, and more importantly, the location
of in-gap corner states can also be separately manipulated by them. From this,
we achieve topological corner states for both TM and TE polarizations with the
same frequency in the PC by adjusting $\varepsilon_\perp$ and
$\varepsilon_\varparallel$, and their robustness against disorders and defects
are numerically demonstrated. The proposed SPTI provides a potential
application scenario for polarization-independent topological photonic devices.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:13:33 GMT""}]","2023-01-31"
"2301.12161","Sachin Kadam","Sachin Kadam, Dong In Kim","Knowledge-Aware Semantic Communication System Design","Accepted for publication in ICC 2023 - IEEE International Conference
  on Communications, Rome, Italy, May 2023. arXiv admin note: substantial text
  overlap with arXiv:2301.03468",,,,"cs.NI cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent emergence of 6G raises the challenge of increasing the
transmission data rate even further in order to break the barrier set by the
Shannon limit. Traditional communication methods fall short of the 6G goals,
paving the way for Semantic Communication (SemCom) systems. These systems find
applications in wide range of fields such as economics, metaverse, autonomous
transportation systems, healthcare, smart factories, etc. In SemCom systems,
only the relevant information from the data, known as semantic data, is
extracted to eliminate unwanted overheads in the raw data and then transmitted
after encoding. In this paper, we first use the shared knowledge base to
extract the keywords from the dataset. Then, we design an auto-encoder and
auto-decoder that only transmit these keywords and, respectively, recover the
data using the received keywords and the shared knowledge. We show analytically
that the overall semantic distortion function has an upper bound, which is
shown in the literature to converge. We numerically compute the accuracy of the
reconstructed sentences at the receiver. Using simulations, we show that the
proposed methods outperform a state-of-the-art method in terms of the average
number of words per sentence.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:17:24 GMT""}]","2023-01-31"
"2301.12162","Anastasia Batsheva","Anastasia Batsheva, Andrei Chertkov, Gleb Ryzhakov, Ivan Oseledets","PROTES: Probabilistic Optimization with Tensor Sampling",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We developed a new method PROTES for black-box optimization, which is based
on the probabilistic sampling from a probability density function given in the
low-parametric tensor train format. We tested it on complex multidimensional
arrays and discretized multivariable functions taken, among others, from
real-world applications, including unconstrained binary optimization and
optimal control problems, for which the possible number of elements is up to
$2^{100}$. In numerical experiments, both on analytic model functions and on
complex problems, PROTES outperforms existing popular discrete optimization
methods (Particle Swarm Optimization, Covariance Matrix Adaptation,
Differential Evolution, and others).
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:18:54 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 14:10:27 GMT""}]","2023-05-23"
"2301.12163","Herve Moulin","Anna Bogomolnaia, Herve Moulin","The congested assignment problem","20 pages",,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a fair and efficient solution for assigning agents to m posts
subject to congestion, when agents care about both their post and its
congestion. Examples include assigning jobs to busy servers, students to
crowded schools or crowded classes, commuters to congested routes, workers to
crowded office spaces or to team projects etc... Congestion is anonymous (it
only depends on the number n of agents in a given post). A canonical
interpretation of ex ante fairness allows each agent to choose m post-specific
caps on the congestion they tolerate: these requests are mutually feasible if
and only if the sum of the caps is n. For ex post fairness we impose a
competitive requirement close to envy freeness: taking the congestion profile
as given each agent is assigned to one of her best posts. If a competitive
assignment exists, it delivers unique congestion and welfare profiles and is
also efficient and ex ante fair. In a fractional (randomised or time sharing)
version of our model, a unique competitive congestion profile always exists. It
is approximately implemented by a mixture of ex post deterministic assignments:
with an approxination factor equal to the largest utility loss from one more
unit of congestion, the latter deliver identical welfare profiles and are
weakly efficient. Our approach to ex ante fairness generalises to the model
where each agent's congestion is weighted. Now the caps on posts depend only
upon own weight and total congestion, not on the number of other agents
contributing to it. Remarkably in both models these caps are feasible if and
only if they give to each agent the right to veto all but (1/m) of their
feasible allocations.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:21:04 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 12:48:27 GMT""}]","2023-05-29"
"2301.12164","Cosimo Bambi","Jiahao Tao, Shafqat Riaz, Biao Zhou, Askar B. Abdikamalov, Cosimo
  Bambi, Daniele Malafarina","Testing the $\delta$-Kerr metric with black hole X-ray data","12 pages, 4 figures",,,,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spacetime around astrophysical black holes is thought to be described by
the Kerr solution. However, even within general relativity, there is not yet a
proof that the final product of the complete collapse of an uncharged body can
only be a Kerr black hole. We can thus speculate on the possibility that the
spacetime around astrophysical black holes may be described by other solutions
of the Einstein Equations and we can test such a hypothesis with observations.
In this work, we consider the $\delta$-Kerr metric, which is an exact solution
of the field equations in vacuum and can be obtained from a non-linear
superposition of the Kerr metric with a static axially symmetric solution,
often referred to as the $\delta$-metric. The parameter $\delta=1+q$ quantifies
the departure of the source from the Kerr metric and for $q=0$ we recover the
Kerr solution. From the analysis of the reflection features in the X-ray
spectrum of the Galactic black hole in EXO 1846-031, we find $-0.1 < q < 0.7$
(90% CL), which is consistent with the hypothesis that the spacetime around the
compact object in EXO 1846-031 is a Kerr black hole but does not entirely rule
out the $\delta$-Kerr metric.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:31:47 GMT""}]","2023-01-31"
"2301.12165","Jianqiang Wang","Jianqiang Wang, Dandan Ding, Hao Chen, Zhan Ma","Dynamic Point Cloud Geometry Compression Using Multiscale Inter
  Conditional Coding","5 pages",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work extends the Multiscale Sparse Representation (MSR) framework
developed for static Point Cloud Geometry Compression (PCGC) to support the
dynamic PCGC through the use of multiscale inter conditional coding. To this
end, the reconstruction of the preceding Point Cloud Geometry (PCG) frame is
progressively downscaled to generate multiscale temporal priors which are then
scale-wise transferred and integrated with lower-scale spatial priors from the
same frame to form the contextual information to improve occupancy probability
approximation when processing the current PCG frame from one scale to another.
Following the Common Test Conditions (CTC) defined in the standardization
committee, the proposed method presents State-Of-The-Art (SOTA) compression
performance, yielding 78% lossy BD-Rate gain to the latest standard-compliant
V-PCC and 45% lossless bitrate reduction to the latest G-PCC. Even for
recently-emerged learning-based solutions, our method still shows significant
performance gains.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:34:06 GMT""}]","2023-01-31"
"2301.12166","Alberto Archetti","Alberto Archetti, Eugenio Lomurno, Francesco Lattari, Andr\'e Martin,
  Matteo Matteucci","Heterogeneous Datasets for Federated Survival Analysis Simulation",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Survival analysis studies time-modeling techniques for an event of interest
occurring for a population. Survival analysis found widespread applications in
healthcare, engineering, and social sciences. However, the data needed to train
survival models are often distributed, incomplete, censored, and confidential.
In this context, federated learning can be exploited to tremendously improve
the quality of the models trained on distributed data while preserving user
privacy. However, federated survival analysis is still in its early
development, and there is no common benchmarking dataset to test federated
survival models. This work provides a novel technique for constructing
realistic heterogeneous datasets by starting from existing non-federated
datasets in a reproducible way. Specifically, we propose two dataset-splitting
algorithms based on the Dirichlet distribution to assign each data sample to a
carefully chosen client: quantity-skewed splitting and label-skewed splitting.
Furthermore, these algorithms allow for obtaining different levels of
heterogeneity by changing a single hyperparameter. Finally, numerical
experiments provide a quantitative evaluation of the heterogeneity level using
log-rank tests and a qualitative analysis of the generated splits. The
implementation of the proposed methods is publicly available in favor of
reproducibility and to encourage common practices to simulate federated
environments for survival analysis.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:37:07 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 17:25:15 GMT""}]","2023-02-22"
"2301.12167","Wolfgang Konen K","Wolfgang Konen","Towards Learning Rubik's Cube with N-tuple-based Reinforcement Learning","43 pages",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  This work describes in detail how to learn and solve the Rubik's cube game
(or puzzle) in the General Board Game (GBG) learning and playing framework. We
cover the cube sizes 2x2x2 and 3x3x3. We describe in detail the cube's state
representation, how to transform it with twists, whole-cube rotations and color
transformations and explain the use of symmetries in Rubik's cube. Next, we
discuss different n-tuple representations for the cube, how we train the agents
by reinforcement learning and how we improve the trained agents during
evaluation by MCTS wrapping. We present results for agents that learn Rubik's
cube from scratch, with and without MCTS wrapping, with and without symmetries
and show that both, MCTS wrapping and symmetries, increase computational costs,
but lead at the same time to much better results. We can solve the 2x2x2 cube
completely, and the 3x3x3 cube in the majority of the cases for scrambled cubes
up to p = 15 (QTM). We cannot yet reliably solve 3x3x3 cubes with more than 15
scrambling twists. Although our computational costs are higher with MCTS
wrapping and with symmetries than without, they are still considerably lower
than in the approaches of McAleer et al. (2018, 2019) and Agostinelli et al.
(2019) who provide the best Rubik's cube learning agents so far.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:38:10 GMT""}]","2023-01-31"
"2301.12168","Eugenio Lomurno","Simone Sarti, Eugenio Lomurno, Matteo Matteucci","Anticipate, Ensemble and Prune: Improving Convolutional Neural Networks
  via Aggregated Early Exits",,,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Today, artificial neural networks are the state of the art for solving a
variety of complex tasks, especially in image classification. Such
architectures consist of a sequence of stacked layers with the aim of
extracting useful information and having it processed by a classifier to make
accurate predictions. However, intermediate information within such models is
often left unused. In other cases, such as in edge computing contexts, these
architectures are divided into multiple partitions that are made functional by
including early exits, i.e. intermediate classifiers, with the goal of reducing
the computational and temporal load without extremely compromising the accuracy
of the classifications. In this paper, we present Anticipate, Ensemble and
Prune (AEP), a new training technique based on weighted ensembles of early
exits, which aims at exploiting the information in the structure of networks to
maximise their performance. Through a comprehensive set of experiments, we show
how the use of this approach can yield average accuracy improvements of up to
15% over traditional training. In its hybrid-weighted configuration, AEP's
internal pruning operation also allows reducing the number of parameters by up
to 41%, lowering the number of multiplications and additions by 18% and the
latency time to make inference by 16%. By using AEP, it is also possible to
learn weights that allow early exits to achieve better accuracy values than
those obtained from single-output reference models.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:45:11 GMT""}]","2023-01-31"
"2301.12169","Christoph Treude","Christoph Treude","Navigating Complexity in Software Engineering: A Prototype for Comparing
  GPT-n Solutions",,,,,"cs.SE cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Navigating the diverse solution spaces of non-trivial software engineering
tasks requires a combination of technical knowledge, problem-solving skills,
and creativity. With multiple possible solutions available, each with its own
set of trade-offs, it is essential for programmers to evaluate the various
options and select the one that best suits the specific requirements and
constraints of a project. Whether it is choosing from a range of libraries,
weighing the pros and cons of different architecture and design solutions, or
finding unique ways to fulfill user requirements, the ability to think
creatively is crucial for making informed decisions that will result in
efficient and effective software. However, the interfaces of current chatbot
tools for programmers, such as OpenAI's ChatGPT or GitHub Copilot, are
optimized for presenting a single solution, even for complex queries. While
other solutions can be requested, they are not displayed by default and are not
intuitive to access. In this paper, we present our work-in-progress prototype
""GPTCompare"", which allows programmers to visually compare multiple source code
solutions generated by GPT-n models for the same programming-related query by
highlighting their similarities and differences.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:47:03 GMT""}]","2023-01-31"
"2301.12170","Akihiro Ishibashi","Akihiro Ishibashi, Kengo Maeda, and Takashi Okamura","Semiclassical Einstein equations from holography and boundary dynamics","34 page, 3 figures",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider a prescription for formulating semiclassical
problems in the context of the AdS/CFT correspondence, based on the proposal of
Compere and Marolf. The prescription consists of the effective action that
includes the self-action term of boundary dynamical fields and that can be
viewed as imposing mixed boundary conditions for the gravity dual. We derive
the semiclassical Einstein equations sourced with boundary CFT stress-energy
tensor. Analyzing perturbations of the holographic semiclassical Einstein
equations, we find a universal parameter $\gamma_d$ which controls the
contribution from boundary CFTs and specifies dynamics on the AdS boundary. As
a simple example, we examine the semiclassical Einstein equations in
$3$-dimensions with $4$-dimensional AdS gravity dual, and show that the
boundary BTZ black hole with vanishing expectation value of the stress-energy
tensor exhibits instability due to the backreaction from quantum stress-energy
tensor when the parameter $\gamma_d$ exceeds a certain critical value.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:48:31 GMT""}]","2023-01-31"
"2301.12171","Jong Chul Ye","Kwanyoung Kim, Yujin Oh, Jong Chul Ye","ZegOT: Zero-shot Segmentation Through Optimal Transport of Text Prompts","18pages, 8 figures",,,,"cs.CV cs.AI cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Recent success of large-scale Contrastive Language-Image Pre-training (CLIP)
has led to great promise in zero-shot semantic segmentation by transferring
image-text aligned knowledge to pixel-level classification. However, existing
methods usually require an additional image encoder or retraining/tuning the
CLIP module. Here, we propose a novel Zero-shot segmentation with Optimal
Transport (ZegOT) method that matches multiple text prompts with frozen image
embeddings through optimal transport. In particular, we introduce a novel
Multiple Prompt Optimal Transport Solver (MPOT), which is designed to learn an
optimal mapping between multiple text prompts and visual feature maps of the
frozen image encoder hidden layers. This unique mapping method facilitates each
of the multiple text prompts to effectively focus on distinct visual semantic
attributes. Through extensive experiments on benchmark datasets, we show that
our method achieves the state-of-the-art (SOTA) performance over existing
Zero-shot Semantic Segmentation (ZS3) approaches.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 11:51:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 13:46:57 GMT""}]","2023-05-31"
"2301.12172","Titus K Mathew","Rosemin John, Sarath N. and Titus K. Mathew","Thermal evolution and stability analysis of PEDE model","20 pages, 10 figures",,,,"gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  The phenomenologically emergent dark energy(PEDE) model is a varying dark
energy model with no extra degrees of freedom proposed initially to alleviate
the Hubble tension by Li and Shafieloo\cite{Li_2019}. The statistical
consistency of the model have been discussed by many authors. Since the model
presents a phantom dark energy which is an increasing function of redshift, its
cosmological evolution especially during the late phase needs to be discussed.
We find the evolution of Hubble and deceleration parameter shows a peculiar
behaviour in the future different from $\Lambda$CDM cosmology. We find the
model also follows a distinct evolution in statefinder plane. The phantom
nature of the model further leads to the violation of null energy condition and
a decreasing horizon entropy. The de-Sitter epoch also seems to be unstable
based on our dynamical system analysis as well as stability analysis based on
dark energy sound speed.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:00:09 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 10:22:07 GMT""}]","2023-02-14"
"2301.12173","Marisa Girardi Dr.","M. Girardi, S. Zarattini, W. Boschin, M. Nonino, I. Bartalucci, A.
  Mercurio, N. Nocerino, P. Rosati","A newly identified galaxy group thanks to tidal streams of intragroup
  light","Astronomy & Astrophysics accepted, 13 pages, 10 figures","A&A 671, A83 (2023)","10.1051/0004-6361/202244652",,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the accretion-driven growth scenario, part of the intracluster light is
formed in the group environment. We report the serendipitous discovery of a
group of galaxies with signs of diffuse light in the foreground of the known
galaxy cluster MACS J0329-0211 at z=0.45. Our investigation began with the
detection of diffuse light streams around a pair of bright galaxies in the
southeastern region of a Suprime-Cam image of the galaxy cluster MACS
J0329-0211. Our analysis is based on the extended CLASH-VLT redshift catalog
and on new spectroscopic data obtained ad hoc with the Italian Telescopio
Nazionale Galileo. We use the density reconstruction method to analyze the
redshift distribution of the galaxies in the region around the galaxy pair. We
also use available photometric and X-ray data to better characterize the
properties of the group. Thanks to the large amount of redshift data collected
in this region, we have been able to discover the existence of a group of
galaxies, here called GrG J0330-0218, which is associated with the pair of
galaxies. These are the two brightest group galaxies (BGG1 and BGG2). We
extracted 41 group members from the redshift catalog and estimate a mean
redshift z=0.1537 and a line-of-sight velocity dispersion sigmav=370 km/s. In
the phase-space diagram, the distribution of the galaxies of GrG J0330-0218
follows the characteristic trumpet-shaped pattern, which is related to the
escape velocity of galaxy clusters, suggesting that the group is a virialized
structure. Under this assumption, the mass of the group is M200 about 6E13
Msun. We also measured a mass-to-light ratio of 130 Msun/Lsun and a luminosity
fraction of diffuse light of about 20% within 0.5 R200. We conjecture that
galaxy pairs that are surrounded by diffuse light, probably due to tidal
interactions, can serve as signposts for groups.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:04:47 GMT""}]","2023-03-15"
"2301.12174","Qi Deng","Jinsong Liu, Chenghan Xie, Qi Deng, Dongdong Ge, Yinyu Ye","Stochastic Dimension-reduced Second-order Methods for Policy
  Optimization",,,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose several new stochastic second-order algorithms for
policy optimization that only require gradient and Hessian-vector product in
each iteration, making them computationally efficient and comparable to policy
gradient methods. Specifically, we propose a dimension-reduced second-order
method (DR-SOPO) which repeatedly solves a projected two-dimensional trust
region subproblem. We show that DR-SOPO obtains an
$\mathcal{O}(\epsilon^{-3.5})$ complexity for reaching approximate first-order
stationary condition and certain subspace second-order stationary condition. In
addition, we present an enhanced algorithm (DVR-SOPO) which further improves
the complexity to $\mathcal{O}(\epsilon^{-3})$ based on the variance reduction
technique. Preliminary experiments show that our proposed algorithms perform
favorably compared with stochastic and variance-reduced policy gradient
methods.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:09:58 GMT""}]","2023-01-31"
"2301.12175","Lorenzo Lamberti","Lorenzo Lamberti, Luca Bompani, Victor Javier Kartsch, Manuele Rusci,
  Daniele Palossi, Luca Benini","Bio-inspired Autonomous Exploration Policies with CNN-based Object
  Detection on Nano-drones","6 pages, 6 figures, 4 tables, conference: DATE: Design, Automation,
  and Test in Europe (2023)",,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nano-sized drones, with palm-sized form factor, are gaining relevance in the
Internet-of-Things ecosystem. Achieving a high degree of autonomy for complex
multi-objective missions (e.g., safe flight, exploration, object detection) is
extremely challenging for the onboard chip-set due to tight size, payload
(<10g), and power envelope constraints, which strictly limit both memory and
computation. Our work addresses this complex problem by combining bio-inspired
navigation policies, which rely on time-of-flight distance sensor data, with a
vision-based convolutional neural network (CNN) for object detection. Our
field-proven nano-drone is equipped with two microcontroller units (MCUs), a
single-core ARM Cortex-M4 (STM32) for safe navigation and exploration policies,
and a parallel ultra-low power octa-core RISC-V (GAP8) for onboard CNN
inference, with a power envelope of just 134mW, including image sensors and
external memories. The object detection task achieves a mean average precision
of 50% (at 1.6 frame/s) on an in-field collected dataset. We compare four
bio-inspired exploration policies and identify a pseudo-random policy to
achieve the highest coverage area of 83% in a ~36m^2 unknown room in a 3
minutes flight. By combining the detection CNN and the exploration policy, we
show an average detection rate of 90% on six target objects in a
never-seen-before environment.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:15:01 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 17:40:34 GMT""}]","2023-02-02"
"2301.12176","Seyed Muhammad Hossein Mousavi","S. Muhammad Hossein Mousavi","Neural Gas Network Image Features and Segmentation for Brain Tumor
  Detection Using Magnetic Resonance Imaging Data","7 pages",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Accurate detection of brain tumors could save lots of lives and increasing
the accuracy of this binary classification even as much as a few percent has
high importance. Neural Gas Networks (NGN) is a fast, unsupervised algorithm
that could be used in data clustering, image pattern recognition, and image
segmentation. In this research, we used the metaheuristic Firefly Algorithm
(FA) for image contrast enhancement as pre-processing and NGN weights for
feature extraction and segmentation of Magnetic Resonance Imaging (MRI) data on
two brain tumor datasets from the Kaggle platform. Also, tumor classification
is conducted by Support Vector Machine (SVM) classification algorithms and
compared with a deep learning technique plus other features in train and test
phases. Additionally, NGN tumor segmentation is evaluated by famous performance
metrics such as Accuracy, F-measure, Jaccard, and more versus ground truth data
and compared with traditional segmentation techniques. The proposed method is
fast and precise in both tasks of tumor classification and segmentation
compared with other methods. A classification accuracy of 95.14 % and
segmentation accuracy of 0.977 is achieved by the proposed method.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:16:37 GMT""}]","2023-01-31"
"2301.12177","Yichen Yang","Ruo Li and Yichen Yang","Slip and Jump Coefficients for General Gas-Surface Interactions
  According to the Moment Method",,,"10.1063/5.0142861",,"physics.flu-dyn cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a moment method based on the Hermite series of arbitrary order to
calculate viscous-slip, thermal-slip, and temperature-jump coefficients for
general gas-surface scattering kernels. Under some usual assumptions of
scattering kernels, the solvability is obtained by showing the positive
definiteness of the symmetric coefficient matrix in the boundary conditions.
For gas flows with the Cercignani-Lampis gas-surface interaction and
inverse-power-law intermolecular potentials, the model can capture the slip and
jump coefficients accurately with elegant analytic expressions. On the one
hand, the proposed method can apply to the cases of arbitrary order moments
with increasing accuracy. On the other hand, the explicit formulae for
low-order situations are simpler and more accurate than some existing results
in references. Therefore, one may apply these formulae in slip and jump
conditions to improve the accuracy of macroscopic fluid dynamic models for gas
flows.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:19:50 GMT""}]","2023-03-29"
"2301.12178","Yuzhen Qin","Yuzhen Qin, Li Sun, Hui Chen, Wei-qiang Zhang, Wenming Yang, Jintao
  Fei, Guijin Wang","MVKT-ECG: Efficient Single-lead ECG Classification on Multi-Label
  Arrhythmia by Multi-View Knowledge Transferring",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The widespread emergence of smart devices for ECG has sparked demand for
intelligent single-lead ECG-based diagnostic systems. However, it is
challenging to develop a single-lead-based ECG interpretation model for
multiple diseases diagnosis due to the lack of some key disease information. In
this work, we propose inter-lead Multi-View Knowledge Transferring of ECG
(MVKT-ECG) to boost single-lead ECG's ability for multi-label disease
diagnosis. This training strategy can transfer superior disease knowledge from
multiple different views of ECG (e.g. 12-lead ECG) to single-lead-based ECG
interpretation model to mine details in single-lead ECG signals that are easily
overlooked by neural networks. MVKT-ECG allows this lead variety as a
supervision signal within a teacher-student paradigm, where the teacher
observes multi-lead ECG educates a student who observes only single-lead ECG.
Since the mutual disease information between the single-lead ECG and muli-lead
ECG plays a key role in knowledge transferring, we present a new disease-aware
Contrastive Lead-information Transferring(CLT) to improve the mutual disease
information between the single-lead ECG and muli-lead ECG. Moreover, We modify
traditional Knowledge Distillation to multi-label disease Knowledge
Distillation (MKD) to make it applicable for multi-label disease diagnosis. The
comprehensive experiments verify that MVKT-ECG has an excellent performance in
improving the diagnostic effect of single-lead ECG.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:28:39 GMT""}]","2023-01-31"
"2301.12179","Srikanth Sastry","Varghese Babu, H.A Vinutha, Dapeng Bi, Srikanth Sastry","Discontinuous rigidity transition associated with shear jamming in
  granular simulations",,,,,"cond-mat.soft cond-mat.dis-nn cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We investigate the rigidity transition associated with shear jamming in
frictionless, as well as frictional, disk packings in the quasi-static regime
and at low shear rates. For frictionless disks, the transition is under
quasistatic shear is discontinuous, with an instantaneous emergence of a system
spanning rigid cluster at the jamming transition. For frictional systems, the
transition appears continuous for finite shear rates, but becomes sharper for
lower shear rates. In the quasi-static limit, it is discontinuous as in the
frictionless case. Thus, our results show that the rigidity transition
associated with shear jamming is discontinuous, as demonstrated in a past for
isotropic jamming of frictionless particles, and therefore a unifying feature
of the jamming transition in general.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:32:59 GMT""}]","2023-01-31"
"2301.12180","Oleg Kashurin","Oleg Kashurin, Nikolay Kondratyuk, Alexander Lankin, Henry Norman","Molecular dynamics simulation of diisopropyl ether using various
  interatomic potentials","19 pages, 4 figures, in Russian",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  For diisopropyl ether, a comparative assessment of the accuracy of
determining the density and viscosity is carried out using the method of
classical molecular dynamics using three potentials. The accuracy of
determining the viscosity coefficients when using equilibrium and
non-equilibrium calculation methods is also investigated.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:34:49 GMT""}]","2023-01-31"
"2301.12181","Ying Wu","Ying Wu, Chuangtao Chen, Weihua Xiao, Xuan Wang, Chenyi Wen, Jie Han,
  Xunzhao Yin, Weikang Qian, Cheng Zhuo","A Survey on Approximate Multiplier Designs for Energy Efficiency: From
  Algorithms to Circuits","36 pages, 36 figures",,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the stringent requirements of energy efficiency for Internet-of-Things
edge devices, approximate multipliers have recently received growing attention,
especially in error-resilient applications. The computation error and energy
efficiency largely depend on how and where the approximation is introduced into
a design. Thus, this article aims to provide a comprehensive review of the
approximation techniques in multiplier designs ranging from algorithms and
architectures to circuits. We have implemented representative approximate
multiplier designs in each category to understand the impact of the design
techniques on accuracy and efficiency. The designs can then be effectively
deployed in high level applications, such as machine learning, to gain energy
efficiency at the cost of slight accuracy loss.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:35:09 GMT""}]","2023-01-31"
"2301.12182","Matthias Schymura","Matthias Beck and Matthias Schymura","Deep lattice points in zonotopes, lonely runners, and lonely rabbits","17 pages",,,,"math.MG math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $K \subseteq \mathbb{R}^d$ be a convex body and let $\mathbf{w} \in
\operatorname{int}(K)$ be an interior point of $K$. The coefficient of
asymmetry $\operatorname{ca}(K,\mathbf{w}) := \min\{ \lambda \geq 1 :
\mathbf{w} - K \subseteq \lambda (K - \mathbf{w}) \}$ has been studied
extensively in the realm of Hensley's conjecture on the maximal volume of a
$d$-dimensional lattice polytope that contains a fixed positive number of
interior lattice points. We study the coefficient of asymmetry for lattice
zonotopes, i.e., Minkowski sums of line segments with integer endpoints. Our
main result gives the existence of an interior lattice point whose coefficient
of asymmetry is bounded above by an explicit constant in $\Theta(d \log\log
d)$, for any lattice zonotope that has an interior lattice point. Our work is
both inspired by and feeds on Wills' lonely runner conjecture from Diophantine
approximation: we make intensive use of a discrete version of this conjecture,
and reciprocally, we reformulate the lonely runner conjecture in terms of the
coefficient of asymmetry of a zonotope.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:46:39 GMT""}]","2023-01-31"
"2301.12183","Bin Chen","Bin Chen (1), Jason E. Kooi (2), David B. Wexler (3), Dale E. Gary
  (1), Sijie Yu (1), Surajit Mondal (1), Adam R. Kobelski (4), Daniel B. Seaton
  (5), Matthew J. West (5), Stephen M. White (6), Gregory D. Fleishman (1),
  Pascal Saint-Hilaire (7), Peijin Zhang (8), Chris R. Gilly (9), James P.
  Mason (10), Hamish Reid (11) ((1) New Jersey Institute of Technology, (2)
  Naval Research Laboratory, (3) University of Massachusetts, Lowell, (4) NASA
  Marshall Space Flight Center, (5) Southwest Research Institute, (6) Air Force
  Research Laboratory, (7) University of California, Berkeley, (8) Bulgaria
  Academy of Sciences, Bulgaria, (9) Laboratory for Atmospheric and Space
  Physics, (10) Johns Hopkins University Applied Physics Laboratory, (11)
  University College London)","Radio Studies of the Middle Corona: Current State and New Prospects in
  the Next Decade","Science white paper submitted to the 2024 Solar and Space Physics
  Decadal Survey. All submitted white papers (including this one) are available
  at
  https://www.nationalacademies.org/our-work/decadal-survey-for-solar-and-space-physics-heliophysics-2024-2033.
  arXiv admin note: text overlap with arXiv:2208.04485",,,,"astro-ph.IM astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  The ""middle corona,"" defined by West et al. (2022) as the region between
~1.5-6 solar radii, is a critical transition region that connects the highly
structured lower corona to the outer corona where the magnetic field becomes
predominantly radial. At radio wavelengths, remote-sensing of the middle corona
falls in the meter-decameter wavelength range where a critical transition of
radio emission mechanisms occurs. In addition, plasma properties of the middle
corona can be probed by trans-coronal radio propagation methods including radio
scintillation and Faraday rotation techniques. Together they offer a wealth of
diagnostic tools for the middle corona, complementing current and planned
missions at other wavelengths. These diagnostics include unique means for
detecting and measuring the magnetic field and energetic electrons associated
with coronal mass ejections, mapping coronal shocks and electron beam
trajectories, as well as constraining the plasma density, magnetic field, and
turbulence of the ""young"" solar wind. Following a brief overview of pertinent
radio diagnostic methods, this white paper will discuss the current state of
radio studies on the middle corona, challenges to obtaining a more
comprehensive picture, and recommend an outlook in the next decade. Our
specific recommendations for advancing the middle coronal sciences from the
radio perspective are: (1) Prioritizing solar-dedicated radio facilities in the
~0.1-1 GHz range with broadband, high-dynamic-range imaging spectropolarimetry
capabilities. (2) Developing facilities and techniques to perform
multi-perspective, multiple lines-of-sight trans-coronal radio Faraday Rotation
measurements.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:57:37 GMT""}]","2023-01-31"
"2301.12184","Sara Venturini","Sara Venturini, Andrea Cristofari, Francesco Rinaldi, Francesco
  Tudisco","Laplacian-based Semi-Supervised Learning in Multilayer Hypergraphs by
  Coordinate Descent","24 pages, 10 figures",,,,"cs.LG cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Semi-Supervised learning is an important data analysis tool, where
given a graph and a set of labeled nodes, the aim is to infer the labels to the
remaining unlabeled nodes. In this paper, we start by considering an
optimization-based formulation of the problem for an undirected graph, and then
we extend this formulation to multilayer hypergraphs. We solve the problem
using different coordinate descent approaches and compare the results with the
ones obtained by the classic gradient descent method. Experiments on synthetic
and real-world datasets show the potential of using coordinate descent methods
with suitable selection rules.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 12:59:07 GMT""}]","2023-01-31"
"2301.12185","William Howard","William W. Howard and R. Michael Buehrer","Hybrid Cognition for Target Tracking in Cognitive Radar Networks","34 pages, single-column, 10 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work investigates online learning techniques for a cognitive radar
network utilizing feedback from a central coordinator. The available spectrum
is divided into channels, and each radar node must transmit in one channel per
time step. The network attempts to optimize radar tracking accuracy by learning
the optimal channel selection for spectrum sharing and radar performance. We
define optimal selection for such a network in relation to the radar
observation quality obtainable in a given channel. This is a difficult problem
since the network must seek the optimal assignment from nodes to channels,
rather than just seek the best overall channel. Since the presence of primary
users appears as interference, the approach also improves spectrum sharing
performance. In other words, maximizing radar performance also minimizes
interference to primary users. Each node is able to learn the quality of
several available channels through repeated sensing. We define hybrid cognition
as the condition where both the independent radar nodes as well as the central
coordinator are modeled as cognitive agents, with restrictions on the amount of
information that can be exchanged between the radars and the coordinator.
Importantly, each part of the network acts as an online learner, observing the
environment to inform future actions. We show that in interference-limited
spectrum, where the signal-to-interference-plus-noise ratio varies by channel
and over time for a target with fixed radar cross section, a cognitive radar
network is able to use information from the central coordinator in order to
reduce the amount of time necessary to learn the optimal channel selection. We
also show that even limited use of a central coordinator can eliminate
collisions, which occur when two nodes select the same channel.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:01:23 GMT""},{""version"":""v2"",""created"":""Sat, 22 Apr 2023 17:00:48 GMT""}]","2023-04-25"
"2301.12186","Daniel Jaud","Daniel Jaud","Gravitational billiards -- bouncing inside a paraboloid cavity","12 pages, 7 figures",,"10.13140/RG.2.2.15184.58888",,"math.DS math-ph math.MG math.MP physics.class-ph","http://creativecommons.org/licenses/by-sa/4.0/","  In this work the confined domains for a point-like particle propagating
within the boundary of an ideally reflecting paraboloid mirror are derived.
Thereby it is proven that all consecutive flight parabola foci points lie on
the surface of a common sphere of radius $R$. The main results are illustrated
in various limiting cases and are compared to its two-dimensional counterpart.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:01:40 GMT""}]","2023-01-31"
"2301.12187","Jinuk Kim","Jinuk Kim, Yeonwoo Jeong, Deokjae Lee, Hyun Oh Song","Efficient Latency-Aware CNN Depth Compression via Two-Stage Dynamic
  Programming","ICML 2023; Codes at
  https://github.com/snu-mllab/Efficient-CNN-Depth-Compression",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works on neural network pruning advocate that reducing the depth of
the network is more effective in reducing run-time memory usage and
accelerating inference latency than reducing the width of the network through
channel pruning. In this regard, some recent works propose depth compression
algorithms that merge convolution layers. However, the existing algorithms have
a constricted search space and rely on human-engineered heuristics. In this
paper, we propose a novel depth compression algorithm which targets general
convolution operations. We propose a subset selection problem that replaces
inefficient activation layers with identity functions and optimally merges
consecutive convolution operations into shallow equivalent convolution
operations for efficient end-to-end inference latency. Since the proposed
subset selection problem is NP-hard, we formulate a surrogate optimization
problem that can be solved exactly via two-stage dynamic programming within a
few seconds. We evaluate our methods and baselines by TensorRT for a fair
inference latency comparison. Our method outperforms the baseline method with
higher accuracy and faster inference speed in MobileNetV2 on the ImageNet
dataset. Specifically, we achieve $1.41\times$ speed-up with $0.11$\%p accuracy
gain in MobileNetV2-1.0 on the ImageNet.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:08:54 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 15:46:38 GMT""}]","2023-06-05"
"2301.12188","Bin Chen","Bin Chen (1), Timothy S. Bastian (2), Sarah Gibson (3), Yuhong Fan
  (3), Stephen M. White (4), Dale E. Gary (1), Angelos Vourlidas (5), Sijie Yu
  (1), Surajit Mondal (1), Gregory D. Fleishman (1), Pascal Saint-Hilaire (6)
  ((1) New Jersey Institute of Technology, (2) National Radio Astronomy
  Observatory, (3) High Altitude Observatory, (4) Air Force Research
  Laboratory, (5) JHU Applied Physics Laboratory, (6) University of California,
  Berkeley)","Radio Imaging Spectropolarimetry of CMEs and CME Progenitors","Science white paper submitted to the 2024 Solar and Space Physics
  Decadal Survey. All submitted white papers (including this one) are available
  at
  https://www.nationalacademies.org/our-work/decadal-survey-for-solar-and-space-physics-heliophysics-2024-2033",,,,"astro-ph.IM astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Coronal mass ejections (CMEs) are the most important drivers of space
weather. Central to most CMEs is thought to be the eruption of a bundle of
highly twisted magnetic field lines known as magnetic flux ropes. A
comprehensive understanding of CMEs and their impacts hence requires detailed
observations of physical parameters that lead to the formation,
destabilization, and eventual eruption of the magnetic flux ropes. Recent
advances in remote-sensing observations of coronal cavities, filament channels,
sigmoids, EUV ""hot channels,"" white light CMEs, and in situ observations of
magnetic clouds points to the possibility of significant progress in
understanding CMEs. In this white paper, we provide a brief overview of the
potential of radio diagnostics for CMEs and CME progenitors, with a particular
focus on the unique means for constraining their magnetic field and energetic
electron population. Using synthetic observations based on realistic 3D MHD
models, we also demonstrate the transformative potential of advancing such
diagnostics by using broadband radio imaging spectropolarimetry with a high
image dynamic range and high image fidelity. To achieve this goal, a
solar-dedicated radio facility with such capabilities is recommended for
implementation in the coming decade.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:13:18 GMT""}]","2023-01-31"
"2301.12189","Wenjia Wang","Jiajun Ma, Tianyang Hu, Wenjia Wang","Deciphering the Projection Head: Representation Evaluation
  Self-supervised Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning (SSL) aims to learn intrinsic features without
labels. Despite the diverse architectures of SSL methods, the projection head
always plays an important role in improving the performance of the downstream
task. In this work, we systematically investigate the role of the projection
head in SSL. Specifically, the projection head targets the uniformity part of
SSL, which pushes the dissimilar samples away from each other, thus enabling
the encoder to focus on extracting semantic features. Based on this
understanding, we propose a Representation Evaluation Design (RED) in SSL
models in which a shortcut connection between the representation and the
projection vectors is built. Extensive experiments with different
architectures, including SimCLR, MoCo-V2, and SimSiam, on various datasets,
demonstrate that the representation evaluation design can consistently improve
the baseline models in the downstream tasks. The learned representation from
the RED-SSL models shows superior robustness to unseen augmentations and
out-of-distribution data.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:13:53 GMT""}]","2023-01-31"
"2301.12190","Luca Salasnich","L. Salasnich","Density of states for the Unitary Fermi gas and the Schwarzschild black
  hole","10 pages, 6 figures, invited paper (short review) for the Special
  Issue ""Cooperative Effects in Finite Systems"" of the journal Symmetry (MDPI)","Symmetry 15, 350 (2023)","10.3390/sym15020350",,"cond-mat.quant-gas cond-mat.stat-mech gr-qc","http://creativecommons.org/licenses/by/4.0/","  The density of states of a quantum system can be calculated from its
definition but, in some cases, this approach is quite cumbersome.
Alternatively, the density of states can be deduced from the microcanonical
entropy or from the canonical partition function. After discussing the
relationship among these procedures, we suggest a simple numerical method,
which is equivalent in the thermodynamic limit to perform a Legendre
transformation, to obtain the density of states from the Helmholtz free energy.
We apply this method to determine the many-body density of states of the
unitary Fermi gas, a very dilute system of identical fermions interacting with
divergent scattering length. The unitary Fermi gas is highy symmetric due to
the absence of any internal scale except for the average distance between two
particles and, for this reason, its equation of state is called universal. In
the last part of the paper, by using the same thermodynamical techniques, we
review some properties of} the density of states of a Schwarzschild black hole,
which shares with the unitary Fermi gas the problem of finding the density of
states directly from its definition.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:20:41 GMT""}]","2023-01-31"
"2301.12191","Vignesh V Menon","Vignesh V Menon","Multi-resolution encoding and optimization for next generation video
  compression","Degree project in Electrical Engineering, Second Cycle, School of
  Electrical Engineering and Computer Science, KTH Royal Institute of
  Technology (16 October 2020)",,,,"cs.MM","http://creativecommons.org/licenses/by/4.0/","  Multi-encoding implies encoding the same content in multiple spatial
resolutions and multiple bitrates. This work evaluates the encoder analysis
correlations across 2160p, 1080p, and 540p encodings of the same video for
conventional ABR bitrates. A multi-resolution tier multi-ABR encoding scheme is
modeled and evaluated, which significantly improves the computational
efficiency of conventional ABR encoding. Video content is first encoded at the
lower resolution with the median bitrate. Encoder analysis decisions, such as
motion vectors and CU block structure, are then used in the other encodes in
the same resolution tier. The analysis is then extrapolated and refined to be
used in higher-resolution encodes. The scheme is validated using x265 HEVC
video encoder. The proposed multi-resolution tier multi-bitrate encoding scheme
achieves overall speed-ups of up to 2.5x, compared to the conventional
single-instance encoding approach. Furthermore, this speed-up is achieved
without substantial losses in coding efficiency. SIMD Vector units in CPUs have
become the de-facto standard for accelerating media and other kernels that
exhibit parallelism. This work also demonstrates the impact of hardware-aware
optimizations on the encoding speeds of the next-generation video codecs. The
work is evaluated using the Arowana XVC encoder.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:20:48 GMT""}]","2023-01-31"
"2301.12192","Bin Chen","Bin Chen (1), Dale E. Gary (1), Sijie Yu (1), Surajit Mondal (1),
  Gregory D. Fleishman (1), Xiaocan Li (2), Chengcai Shen (3), Fan Guo (4),
  Stephen M. White (5), Timothy S. Bastian (6), Pascal Saint-Hilaire (7), James
  F. Drake (8), Joel Dahlin (9), Lindsay Glesener (10), Hantao Ji (11), Astrid
  Veronig (12), Mitsuo Oka (7), Katharine K. Reeves (3), Judith Karpen (9) ((1)
  New Jersey Institute of Technology, (2) Dartmouth College, (3)
  Harvard-Smithsonian Center for Astrophysics, (4) Los Alamos National
  Laboratory, (5) Air Force Research Laboratory, (6) National Radio Astronomy
  Observatory, (7) University of California, Berkeley, (8) University of
  Maryland, (9) NASA Goddard Space Flight Center, (10) University of Minnesota,
  (11) Princeton University, (12) University of Graz)","Quantifying Energy Release in Solar Flares and Solar Eruptive Events:
  New Frontiers with a Next-Generation Solar Radio Facility","Science white paper submitted to the 2024 Solar and Space Physics
  Decadal Survey. All submitted white papers (including this one) are available
  at
  https://www.nationalacademies.org/our-work/decadal-survey-for-solar-and-space-physics-heliophysics-2024-2033",,,,"astro-ph.IM astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Solar flares and the often associated solar eruptive events serve as an
outstanding laboratory to study the magnetic reconnection and the associated
energy release and conversion processes under plasma conditions difficult to
reproduce in the laboratory, and with considerable spatiotemporal details not
possible elsewhere in the universe. In the past decade, thanks to advances in
multi-wavelength imaging spectroscopy, as well as developments in theories and
numerical modeling, significant progress has been made in improving our
understanding of solar flare/eruption energy release. In particular, broadband
imaging spectroscopy at microwave wavelengths offered by the Expanded Owens
Valley Solar Array (EOVSA) has enabled the revolutionary capability of
measuring the time-evolving coronal magnetic fields at or near the flare
reconnection region. However, owing to EOVSA's limited dynamic range, imaging
fidelity, and angular resolution, such measurements can only be done in a
region around the brightest source(s) where the signal-to-noise is sufficiently
large. In this white paper, after a brief introduction to the outstanding
questions and challenges pertinent to magnetic energy release in solar flares
and eruptions, we will demonstrate how a next-generation radio facility with
many (~100-200) antenna elements can bring the next revolution by enabling high
dynamic range, high fidelity broadband imaging spectropolarimetry along with a
sub-second time resolution and arcsecond-level angular resolution. We recommend
to prioritize the implementation of such a ground-based instrument within this
decade. We also call for facilitating multi-wavelength, multi-messenger
observations and advanced numerical modeling in order to achieve a
comprehensive understanding of the ""system science"" of solar flares and
eruptions.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:24:45 GMT""}]","2023-01-31"
"2301.12193","Pengyu Zhang","Pengyu Zhang, Yingbo Zhou, Ming Hu, Xin Fu, Xian Wei, and Mingsong
  Chen","CyclicFL: A Cyclic Model Pre-Training Approach to Efficient Federated
  Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since random initial models in Federated Learning (FL) can easily result in
unregulated Stochastic Gradient Descent (SGD) processes, existing FL methods
greatly suffer from both slow convergence and poor accuracy, especially for
non-IID scenarios. To address this problem, we propose a novel FL method named
CyclicFL, which can quickly derive effective initial models to guide the SGD
processes, thus improving the overall FL training performance. Based on the
concept of Continual Learning (CL), we prove that CyclicFL approximates
existing centralized pre-training methods in terms of classification and
prediction performance. Meanwhile, we formally analyze the significance of data
consistency between the pre-training and training stages of CyclicFL, showing
the limited Lipschitzness of loss for the pre-trained models by CyclicFL.
Unlike traditional centralized pre-training methods that require public proxy
data, CyclicFL pre-trains initial models on selected clients cyclically without
exposing their local data. Therefore, they can be easily integrated into any
security-critical FL methods. Comprehensive experimental results show that
CyclicFL can not only improve the classification accuracy by up to 16.21%, but
also significantly accelerate the overall FL training processes.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:28:34 GMT""}]","2023-01-31"
"2301.12194","Anton Kuncinas","A. Kun\v{c}inas, O. M. Ogreid, P. Osland, M. N. Rebelo","Revisiting two dark matter candidates in $S_3$-symmetric
  three-Higgs-doublet models","8 pages, 5 figures, to be published in the Proceedings of DISCRETE
  2022: 8th Symposium on Prospects in the Physics of Discrete Symmetries, 7-11
  November, 2022, Baden-Baden, Germany",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Models with an extended scalar electroweak sector are well motivated. Such
models could accommodate a dark matter candidate if there is an additional
scalar representation with a vanishing vacuum expectation value and, in
addition, there are no couplings between fermions and the dark matter
candidate. The most natural way to have these conditions implemented is to
consider models where an underlying symmetry is imposed. Governed by this, we
consider a three-Higgs-doublet model with an $S_3$ symmetry. Within this
framework there are different implementations which could possibly accommodate
a dark matter candidate. The family of $S_3$-symmetric three-Higgs-doublet
implementations arises due to different vacua and, as a result, different
minimisation conditions. In this framework the dark matter candidate falls into
the class of weakly interacting massive particles. The dark matter candidate is
associated with an $\mathbb{Z}_2$ symmetry which survives spontaneous symmetry
breaking and is a remnant of the $S_3$ symmetry. We explore two cases, they
share many aspects of the Type-I two-Higgs-doublet model plus an inert SU(2)
doublet. The main difference between these two cases is the presence of an
irremovable phase, which leads to CP violation in one of the implementations.
The two candidate cases differ from other previously studied models with three
scalar doublets by the fact that they do not allow for heavy dark matter
candidates, $\mathcal{O}(500)\text{ GeV}$. Valid dark matter regions were
identified as $m_\mathrm{DM} \in [52.5,\,89]~\text{GeV}$ for a model without CP
violation and $m_\mathrm{DM} \in [6.5,\,44.5]~\text{GeV}$ for a model with CP
violation. In the present work we refine the parameter space by applying
additional checks to our previous work coming from LHC data and from indirect
detection data.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:32:39 GMT""}]","2023-01-31"
"2301.12195","Tianyu Pang","Haozhe Feng, Tianyu Pang, Chao Du, Wei Chen, Shuicheng Yan, Min Lin","Does Federated Learning Really Need Backpropagation?",,,,,"cs.LG cs.AI cs.CR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) is a general principle for decentralized clients to
train a server model collectively without sharing local data. FL is a promising
framework with practical applications, but its standard training paradigm
requires the clients to backpropagate through the model to compute gradients.
Since these clients are typically edge devices and not fully trusted, executing
backpropagation on them incurs computational and storage overhead as well as
white-box vulnerability. In light of this, we develop backpropagation-free
federated learning, dubbed BAFFLE, in which backpropagation is replaced by
multiple forward processes to estimate gradients. BAFFLE is 1) memory-efficient
and easily fits uploading bandwidth; 2) compatible with inference-only hardware
optimization and model quantization or pruning; and 3) well-suited to trusted
execution environments, because the clients in BAFFLE only execute forward
propagation and return a set of scalars to the server. Empirically we use
BAFFLE to train deep models from scratch or to finetune pretrained models,
achieving acceptable results. Code is available in
https://github.com/FengHZ/BAFFLE.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:34:36 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 13:05:38 GMT""}]","2023-05-29"
"2301.12196","Vitaly Ryumshin","V. S. Ryumshin, V. A. Chernyshev","Structure and Dynamics of a Lattice of Tetragonal Germanates R2Ge2O7 (R
  = Tb-Lu, Y): Ab Initio Calculation",,,"10.1134/S1063783421060196",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The crystal structure, phonon spectrum, and elastic constants of a series of
rare-earth germanates (including yttrium germanate R2Ge2O7 (R = Tb-Lu, Y)) with
a tetragonal structure have been ab initio calculated within the density
functional theory. The frequencies and types of fundamental vibrations and the
intensities of IR and Raman modes are determined. The degrees of participation
of ions in each mode are determined by analyzing the displacement vectors
obtained as a result of the ab initio calculations. The calculations have been
performed for the first time; there are no corresponding experimental data for
the entire series of compounds (except for the IR and Raman spectra of yttrium
germanate). The performed calculations made it possible to interpret and
supplement the known data in the literature on IR and Raman spectra of yttrium
germanate Y2Ge2O7.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:35:44 GMT""}]","2023-01-31"
"2301.12197","Ziwei Fan","Ziwei Fan, Zhiwei Liu, Hao Peng, Philip S Yu","Mutual Wasserstein Discrepancy Minimization for Sequential
  Recommendation","This paper is accepted by The Web Conference 2023. 11 pages",,,,"cs.LG cs.AI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised sequential recommendation significantly improves
recommendation performance by maximizing mutual information with well-designed
data augmentations. However, the mutual information estimation is based on the
calculation of Kullback Leibler divergence with several limitations, including
asymmetrical estimation, the exponential need of the sample size, and training
instability. Also, existing data augmentations are mostly stochastic and can
potentially break sequential correlations with random modifications. These two
issues motivate us to investigate an alternative robust mutual information
measurement capable of modeling uncertainty and alleviating KL divergence
limitations. To this end, we propose a novel self-supervised learning framework
based on Mutual WasserStein discrepancy minimization MStein for the sequential
recommendation. We propose the Wasserstein Discrepancy Measurement to measure
the mutual information between augmented sequences. Wasserstein Discrepancy
Measurement builds upon the 2-Wasserstein distance, which is more robust, more
efficient in small batch sizes, and able to model the uncertainty of stochastic
augmentation processes. We also propose a novel contrastive learning loss based
on Wasserstein Discrepancy Measurement. Extensive experiments on four benchmark
datasets demonstrate the effectiveness of MStein over baselines. More
quantitative analyses show the robustness against perturbations and training
efficiency in batch size. Finally, improvements analysis indicates better
representations of popular users or items with significant uncertainty. The
source code is at https://github.com/zfan20/MStein.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:38:48 GMT""}]","2023-01-31"
"2301.12198","Wonwoo Lee","Soyeon Jeong, Bum-Hoon Lee, Hocheol Lee, Wonwoo Lee","Homoclinic orbit and the violation of the chaos bound around a black
  hole with anisotropic matter fields","19 pages, 27 figures, references added, version to appear in PRD","Phys. Rev. D 107, 104037 2023","10.1103/PhysRevD.107.104037","CQUeST-2023-0718","gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the homoclinic orbit and the violation of chaos bound, which are
obtained by particle motions around a black hole that coexist with anisotropic
matter fields. The homoclinic one is associated with an unstable local maximum
of the effective potential. By perturbing a particle located slightly away from
the homoclinic one, we numerically compute Lyapunov exponents indicating the
sensitivity of the initial value. Our results demonstrate that the violation of
the chaos bound increases with higher angular momentum, and the anisotropic
matter gives rise to violating the chaos bound further, even in the case of the
nonextremal black hole. We utilize the Hamiltonian-Jacobi formalism to
explicitly illustrate how the geodesic motion of a particle can be integrable
in the procedure of obtaining our findings.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:39:40 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 08:21:16 GMT""}]","2023-05-31"
"2301.12199","Xuewen Liu","Yu Liu, Xuewen Liu, Bin Zhu","Early Kinetic Decoupling Effect on the Forbidden Dark Matter
  Annihilations into Standard Model Particles","10 pages, two columns",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The early kinetic decoupling (eKD) effect is an inevitable ingredient in
calculating the relic density of dark matter (DM) for various well-motivated
scenarios. It appears naturally in forbidden dark matter annihilation, the main
focus of this work, which contains fermionic DM and a light singlet scalar that
connects the DM and Standard Model leptons. The strong suppression of the
scattering between DM and SM particles happens quite early in the DM depletion
history, where the DM temperature drops away from the thermal equilibrium,
$T_\chi < T_{\rm SM}$, leading to the decreased kinetic energy of DM. The
forbidden annihilation thus becomes inefficient since small kinetic energy
cannot help exceed the annihilation threshold, naturally leading to a larger
abundance. To show the eKD discrepancy, we numerically solve the coupled
Boltzmann equations that govern the evolution of DM number density and
temperature. It is found that eKD significantly affects the DM abundance,
resulting in almost an order of magnitude higher than that by the traditional
calculation. We also discuss the constraints from experimental searches on the
model parameters, where the viable parameter space shrinks when considering the
eKD effect.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:40:04 GMT""}]","2023-01-31"
"2301.12200","Yan-Ting Xie","Yan-Ting Xie, Yong-De Feng, Shou-Jun Xu","A characterization of regular partial cubes whose all convex cycles have
  the same lengths","8 pages, 0 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Partial cubes are graphs that can be isometrically embedded into hypercubes.
Convex cycles play an important role in the study of partial cubes. In this
paper, we prove that a regular partial cube is a hypercube (resp., a doubled
Odd graph, an even cycle of length $2n$ where $n\geqslant 4$) if and only if
all its convex cycles are 4-cycles (resp., 6-cycles, $2n$-cycles). In
particular, the partial cubes whose all convex cycles are 4-cycles are
equivalent to almost-median graphs, so we obtain that regular almost-median
graphs are exactly hypercubes, which generate the result by Mulder [J. Graph
Theory, 4 (1980) 107--110] -- regular median graphs are hypercubes.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:41:09 GMT""}]","2023-01-31"
"2301.12201","Qihang Liu","Ao Zhang, Ke Deng, Jieming Sheng, Pengfei Liu, Shiv Kumar, Kenya
  Shimada, Zhicheng Jiang, Zhengtai Liu, Dawei Shen, Jiayu Li, Jun Ren, Le
  Wang, Liang Zhou, Yoshihisa Ishikawa, Qiang Zhang, Garry McIntyre, Dehong Yu,
  Enke Liu, Liusuo Wu, Chaoyu Chen, Qihang Liu","Chiral Dirac fermion in a collinear antiferromagnet","20 pages, 4 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The Dirac equation combines the two cornerstones of modern physics-quantum
mechanics and relativity. There are several manifestations of the Dirac
equation in condensed matter systems, such as the quasiparticle dispersion in
graphene, topological insulators, Dirac semimetals (DSMs), Weyl semimetals, and
d-wave high-temperature superconductors. In a DSM, the massless Dirac fermion
has zero chirality, leading to surface states connected adiabatically to a
topologically trivial surface state as well as vanishing anomalous Hall effect
(AHE). Recently, it is predicted that in the nonrelativistic limit of certain
antiferromagnets, there exists a type of chiral 'Dirac-like' fermion, whose
dispersion manifests four-fold degenerate crossing points formed by doubly
degenerate linear bands, with topologically protected Fermi arcs. Such
unconventional chiral fermion, protected by a hidden SU(2) symmetry in the
hierarchy of an enhanced crystallographic group, namely spin space group, is
not experimentally verified yet. Here, by combining neutron diffraction,
angle-resolved photoemission spectroscopy and first-principles calculations, we
reveal the existence of the Fermi-arc surface states induced by chiral
Dirac-like fermions in collinear antiferromagnet CoNb3S6, which caught great
interest due to its surprisingly large AHE. Our transport measurements and
theoretical calculations provide a scenario that large Berry curvature embedded
in the chiral fermions and weak symmetry breaking are responsible for the
emergent AHE. Our work evidences the existence of chiral Dirac-like fermion in
CoNb3S6, paving an avenue for exploring new emergent phenomena in quantum
materials with unconventional quasiparticle excitations.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:53:11 GMT""}]","2023-01-31"
"2301.12202","Daniele Di Pompeo","Francesco Basciani, Daniele Di Pompeo, Juri Di Rocco, Alfonso
  Pierantonio","A customizable approach to assess software quality through
  Multi-Criteria Decision Making","8 pages -- 3rd International Workshop on Model-Driven Engineering for
  Software Architecture (MDE4SA 2023)",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Over the years, Software Quality Engineering has increased interest,
demonstrated by significant research papers published in this area. Determining
when a software artifact is qualitatively valid is tricky, given the
impossibility of providing an objective definition valid for any perspective,
context, or stakeholder. Many quality model solutions have been proposed that
reference specific quality attributes in this context. However, these
approaches do not consider the context in which the artifacts will operate and
the stakeholder's perspective who evaluate its validity. Furthermore, these
solutions suffer from the limitations of being artifact-specific and not
extensible.
  In this paper, we provide a generic and extensible mechanism that makes it
possible to aggregate and prioritize quality attributes. The user, taking into
account his perspective and the context in which the software artifact will
operate, is guided in defining all the criteria for his quality model. The
management of these criteria is then facilitated through Multi-Criteria
Decision Making (MCDM). In addition, we present the PRETTEF model, a concrete
instance of the proposed approach for assessing and selecting MVC frameworks.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:53:43 GMT""}]","2023-01-31"
"2301.12203","Linrui Zhang","Qin Zhang and Linrui Zhang and Haoran Xu and Li Shen and Bowen Wang
  and Yongzhe Chang and Xueqian Wang and Bo Yuan and Dacheng Tao","SaFormer: A Conditional Sequence Modeling Approach to Offline Safe
  Reinforcement Learning",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Offline safe RL is of great practical relevance for deploying agents in
real-world applications. However, acquiring constraint-satisfying policies from
the fixed dataset is non-trivial for conventional approaches. Even worse, the
learned constraints are stationary and may become invalid when the online
safety requirement changes. In this paper, we present a novel offline safe RL
approach referred to as SaFormer, which tackles the above issues via
conditional sequence modeling. In contrast to existing sequence models, we
propose cost-related tokens to restrict the action space and a posterior safety
verification to enforce the constraint explicitly. Specifically, SaFormer
performs a two-stage auto-regression conditioned by the maximum remaining cost
to generate feasible candidates. It then filters out unsafe attempts and
executes the optimal action with the highest expected return. Extensive
experiments demonstrate the efficacy of SaFormer featuring (1) competitive
returns with tightened constraint satisfaction; (2) adaptability to the
in-range cost values of the offline data without retraining; (3)
generalizability for constraints beyond the current dataset.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:57:01 GMT""}]","2023-01-31"
"2301.12204","Ferdinando Fioretto","Keyu Zhu, Ferdinando Fioretto, Pascal Van Hentenryck, Saswat Das,
  Christine Task","Privacy and Bias Analysis of Disclosure Avoidance Systems",,,,,"cs.CR cs.AI cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Disclosure avoidance (DA) systems are used to safeguard the confidentiality
of data while allowing it to be analyzed and disseminated for analytic
purposes. These methods, e.g., cell suppression, swapping, and k-anonymity, are
commonly applied and may have significant societal and economic implications.
However, a formal analysis of their privacy and bias guarantees has been
lacking. This paper presents a framework that addresses this gap: it proposes
differentially private versions of these mechanisms and derives their privacy
bounds. In addition, the paper compares their performance with traditional
differential privacy mechanisms in terms of accuracy and fairness on US Census
data release and classification tasks. The results show that, contrary to
popular beliefs, traditional differential privacy techniques may be superior in
terms of accuracy and fairness to differential private counterparts of widely
used DA mechanisms.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:58:25 GMT""}]","2023-01-31"
"2301.12205","Harish R","R. Dhanya, R. Harish, Sarbani Pramanik","On a class of infinite semipositone problems for (p,q) Laplace operator",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We analyze a non-linear elliptic boundary value problem, that involves $(p,
q)$ Laplace operator, for the existence of its positive solution in an
arbitrary smooth bounded domain. The non-linearity here is driven by a
continuous function in $(0,\infty)$ which is singular, monotonically increasing
and eventually positive. We prove the existence of a positive solution of this
problem using a fixed point theorem due to Amann\cite{amann1976fixed}. In
addition, for a specific nonlinearity we derive that the obtained solution is
maximal in nature. The main results obtained here are first of its kind for a
$(p, q)$ Laplace operator in an arbitrary bounded domain.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:58:59 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 14:22:34 GMT""}]","2023-02-01"
"2301.12206","Farshad Noravesh","Farshad Noravesh","Semantic Tagging with LSTM-CRF",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In the present paper, two models are presented namely LSTM-CRF and
BERT-LSTM-CRF for semantic tagging of universal semantic tag dataset. The
experiments show that the first model is much easier to converge while the
second model that leverages BERT embedding, takes a long time to converge and
needs a big dataset for semtagging to be effective.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:06:17 GMT""}]","2023-01-31"
"2301.12207","Qizhong Zhu","Di Zhang, Sha Deng, Dawei Zhai, Wang Yao, and Qizhong Zhu","Single photon emitters with polarization and orbital angular momentum
  locking in monolayer semiconductors","10 pages, 5 figures","Nano Lett. 23, 3851 (2023)","10.1021/acs.nanolett.3c00459",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Excitons in monolayer transition metal dichalcogenide are endowed with
intrinsic
  valley-orbit coupling between their center-of-mass motion and valley
pseudospin.
  When trapped in a confinement potential, e.g., generated by strain field, we
find
  that intralayer excitons are valley and orbital
  angular momentum (OAM) entangled. By tuning trap profile and external
magnetic
  field, one can engineer the exciton states at ground state, and realize a
  series of valley-OAM entangled states. We further show that the OAM of
excitons can be
  transferred to emitted photons, and these novel
  exciton states can naturally serve as polarization-OAM locked single photon
  emitters, which under certain circumstance become polarization-OAM entangled,
  highly tunable by strain trap and magnetic field. Our proposal
  demonstrates a novel scheme to generate polarization-OAM locked/entangled
  photons at nanoscale with high degree of integrability and tunability,
pointing to exciting
  opportunities for quantum information applications.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:16:44 GMT""}]","2023-05-11"
"2301.12208","Simon Chandler-Wilde Prof","Simon N. Chandler-Wilde, Raffael Hagger, Karl-Mikael Perfekt, Jani A.
  Virtanen","On the spectrum of the double-layer operator on
  locally-dilation-invariant Lipschitz domains",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We say that $\Gamma$, the boundary of a bounded Lipschitz domain, is locally
dilation invariant if, at each $x\in \Gamma$, $\Gamma$ is either locally $C^1$
or locally coincides (in some coordinate system centred at $x$) with a
Lipschitz graph $\Gamma_x$ such that $\Gamma_x=\alpha_x\Gamma_x$, for some
$\alpha_x\in (0,1)$. In this paper we study, for such $\Gamma$, the essential
spectrum of $D_\Gamma$, the double-layer (or Neumann-Poincar\'e) operator of
potential theory, on $L^2(\Gamma)$. We show, via localisation and
Floquet-Bloch-type arguments, that this essential spectrum is the union of the
spectra of related continuous families of operators $K_t$, for $t\in
[-\pi,\pi]$; moreover, each $K_t$ is compact if $\Gamma$ is $C^1$ except at
finitely many points. For the 2D case where, additionally, $\Gamma$ is
piecewise analytic, we construct convergent sequences of approximations to the
essential spectrum of $D_\Gamma$; each approximation is the union of the
eigenvalues of finitely many finite matrices arising from Nystr\""om-method
approximations to the operators $K_t$. Through error estimates with explicit
constants, we also construct functionals that determine whether any particular
locally-dilation-invariant piecewise-analytic $\Gamma$ satisfies the well-known
spectral radius conjecture, that the essential spectral radius of $D_\Gamma$ on
$L^2(\Gamma)$ is $<1/2$ for all Lipschitz $\Gamma$. We illustrate this theory
with examples; for each we show that the essential spectral radius is $<1/2$,
providing additional support for the conjecture. We also, via new results on
the invariance of the essential spectral radius under locally-conformal
$C^{1,\beta}$ diffeomorphisms, show that the spectral radius conjecture holds
for all Lipschitz curvilinear polyhedra.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:18:06 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 11:29:47 GMT""}]","2023-04-06"
"2301.12209","Shenghao Li","Shenghao Li, Jagmohan Chauhan","who is snoring? snore based user recognition",,,,,"cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Snoring is one of the most prominent symptoms of Obstructive Sleep
Apnea-Hypopnea Syndrome (OSAH), a highly prevalent disease that causes
repetitive collapse and cessation of the upper airway. Thus, accurate snore
sound monitoring and analysis is crucial. However, the traditional monitoring
method polysomnography (PSG) requires the patients to stay at a sleep clinic
for the whole night and be connected to many pieces of equipment. An
alternative and less invasive way is passive monitoring using a smartphone at
home or in the clinical settings. But, there is a challenge: the environment
may be shared by people such that the raw audio may contain the snore
activities of the bed partner or other person. False capturing of the snoring
activity could lead to critical false alarms and misdiagnosis of the patients.
To address this limitation, we propose a hypothesis that snore sound contains
unique identity information which can be used for user recognition. We analyzed
various machine learning models: Gaussian Mixture Model (GMM), GMM-UBM
(Universial Background Model), and a Deep Neural Network (DNN) on MPSSC - an
open source snoring dataset to evaluate the validity of our hypothesis. Our
results are promising as we achieved around 90% accuracy in identification and
verification tasks. This work marks the first step towards understanding the
practicality of snore based user monitoring to enable multiple healthcare
applicaitons.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:28:57 GMT""}]","2023-01-31"
"2301.12210","Tony Gracious","Tony Gracious, Arman Gupta, Ambedkar Dukkipati","Neural Temporal Point Process for Forecasting Higher Order and
  Directional Interactions","12 pages, 3 figures, 5 tables",,,,"cs.LG cs.AI cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world systems are made of interacting entities that evolve with time.
Creating models that can forecast interactions by learning the dynamics of
entities is an important problem in numerous fields. Earlier works used dynamic
graph models to achieve this. However, real-world interactions are more complex
than pairwise, as they involve more than two entities, and many of these
higher-order interactions have directional components. Examples of these can be
seen in communication networks such as email exchanges that involve a sender,
and multiple recipients, citation networks, where authors draw upon the work of
others, and so on. In this paper, we solve the problem of higher-order directed
interaction forecasting by proposing a deep neural network-based model
\textit{Directed HyperNode Temporal Point Process} for directed hyperedge event
forecasting, as hyperedge provides native framework for modeling relationships
among the variable number of nodes. Our proposed technique reduces the search
space of possible candidate hyperedges by first forecasting the nodes at which
events will be observed, based on which it generates candidate hyperedges. To
demonstrate the efficiency of our model, we curated four datasets and conducted
an extensive empirical study. We believe that this is the first work that
solves the problem of forecasting higher-order directional interactions.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:32:14 GMT""}]","2023-01-31"
"2301.12211","Jan N. Kirchhof","Jan N. Kirchhof, Yuefeng Yu, Denis Yagodkin, Nele Stetzuhn, Daniel B.
  de Ara\'ujo, Kostas Kanellopulos, Samuel Manas-Valero, Eugenio Coronado,
  Herre van der Zant, Stephanie Reich, Silvan Schmid, Kirill I. Bolotin","Nanomechanical absorption spectroscopy of 2D materials with femtowatt
  sensitivity",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nanomechanical spectroscopy (NMS) is a recently developed approach to
determine optical absorption spectra of nanoscale materials via mechanical
measurements. It is based on measuring changes in the resonance frequency of a
membrane resonator vs. the photon energy of incoming light. This method is a
direct measurement of absorption, which has practical advantages compared to
common optical spectroscopy approaches. In the case of two-dimensional (2D)
materials, NMS overcomes limitations inherent to conventional optical methods,
such as the complications associated with measurements at high magnetic fields
and low temperatures. In this work, we develop a protocol for NMS of 2D
materials that yields two orders of magnitude improved sensitivity compared to
previous approaches, while being simpler to use. To this end, we use electrical
sample actuation, which simplifies the experiment and provides a reliable
calibration for greater accuracy. Additionally, the use of low-stress silicon
nitride membranes as our substrate reduces the noise-equivalent power to $NEP =
890 fW/\sqrt{Hz}$, comparable to commercial semiconductor photodetectors. We
use our approach to spectroscopically characterize a two-dimensional transition
metal dichalcogenide (WS$_2$), a layered magnetic semiconductor (CrPS$_4$), and
a plasmonic supercrystal consisting of gold nanoparticles.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:35:37 GMT""}]","2023-01-31"
"2301.12212","Marcel Wien\""obst","Marcel Wien\""obst and Malte Luttermann and Max Bannach and Maciej
  Li\'skiewicz","Efficient Enumeration of Markov Equivalent DAGs","Extended version of paper accepted to the Proceedings of the 37th
  AAAI Conference on Artificial Intelligence (AAAI-2023)",,,,"cs.AI cs.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Enumerating the directed acyclic graphs (DAGs) of a Markov equivalence class
(MEC) is an important primitive in causal analysis. The central resource from
the perspective of computational complexity is the delay, that is, the time an
algorithm that lists all members of the class requires between two consecutive
outputs. Commonly used algorithms for this task utilize the rules proposed by
Meek (1995) or the transformational characterization by Chickering (1995), both
resulting in superlinear delay. In this paper, we present the first linear-time
delay algorithm. On the theoretical side, we show that our algorithm can be
generalized to enumerate DAGs represented by models that incorporate background
knowledge, such as MPDAGs; on the practical side, we provide an efficient
implementation and evaluate it in a series of experiments. Complementary to the
linear-time delay algorithm, we also provide intriguing insights into Markov
equivalence itself: All members of an MEC can be enumerated such that two
successive DAGs have structural Hamming distance at most three.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:35:39 GMT""}]","2023-01-31"
"2301.12213","Weijia Yao","Weijia Yao, Bohuan Lin, Brian D. O. Anderson, and Ming Cao","The Domain of Attraction of the Desired Path in Vector-field Guided Path
  Following",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the vector-field guided path-following problem, a sufficiently smooth
vector field is designed such that its integral curves converge to and move
along a one-dimensional geometric desired path. The existence of singular
points where the vector field vanishes creates a topological obstruction to
global convergence to the desired path and some associated topological analysis
has been conducted in our previous work. In this paper, we strengthen the
result in our previous work by showing that the domain of attraction of the
desired path, which is a compact asymptotically stable one-dimensional embedded
submanifold of an $n$-dimensional ambient manifold $\mathcal{M}$, is
homeomorphic to $\mathbb{R}^{n-1} \times \mathbb{S}^1$, and not just homotopy
equivalent to $\mathbb{S}^1$. This result is extended for a $k$-dimensional
compact manifold for $k \ge 2$.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:40:58 GMT""}]","2023-01-31"
"2301.12214","Marcos Petrucio Cavalcante","Marcos P. Cavalcante, Darlan F. de Oliveira, Robson dos S. Silva","Index bounds for closed minimal surfaces in 3-manifolds with the Killing
  property","Dedicated to Professor Renato Tribuzy on the occasion of his 75th
  birthday","Mat. Contemp. 50 (2022) 38-53","10.21711/231766362022/rmc4914",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Sigma$ be a closed minimal surface immersed in a Riemannian 3-manifold
carrying an orthonormal Killing frame. This class of ambient spaces includes
Lie groups with a bi-invariant metric. In this paper, we prove that the sum of
the Morse index and the nullity of $\Sigma$ is bounded from below by a constant
times its genus.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:42:06 GMT""}]","2023-01-31"
"2301.12215","Marcos Petrucio Cavalcante","Francisco G. de S. Carvalho and Marcos Petrucio Cavalcante","On the fundamental tone of the $p$-Laplacian on Riemannian manifolds and
  applications",,"J. Math. Anal. Appl. 506 (2022) 125703","10.1016/j.jmaa.2021.125703",,"math.DG math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general lower bound for the fundamental tone for the
$p$-Laplacian on Riemannian manifolds carrying a special kind of function. We
then apply our result to the cases of negatively curved simply connected
manifolds, a class of warped product manifolds and for a class of Riemannian
submersions.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:42:24 GMT""}]","2023-01-31"
"2301.12216","Ivan Izotov","S.V. Golubev, I.V. Izotov, V.A. Skalyga, S.S. Vybin, E.M. Kiseleva,
  R.L. Lapin, S.V. Razin, A.F. Bokhanov, M.Yu. Kazakov, S.P. Shlepnev","Source of pure proton beams",,,,,"physics.plasm-ph physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the quasi-gasdynamic high-current ion source described in this work, the
plasma is sustained by high-power millimeter-wave radiation under the electron
cyclotron resonance (ECR) condition. In such facilities, it is possible to
achieve high volumetric energy input of up to $250$ $W/cm^3$ and obtain pure
proton beams with a minimum amount of impurities and molecular ions.
Experiments conducted on the GISMO facility demonstrated the possibility of a
proton beam formation with a current of $50$ mA and an extremely high
($99.9$\%) content of atomic ions.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:44:14 GMT""}]","2023-01-31"
"2301.12217","Laura Perez-Beltrachini","Laura Perez-Beltrachini, Parag Jain, Emilio Monti, Mirella Lapata","Semantic Parsing for Conversational Question Answering over Knowledge
  Graphs","EACL 2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are interested in developing semantic parsers which
understand natural language questions embedded in a conversation with a user
and ground them to formal queries over definitions in a general purpose
knowledge graph (KG) with very large vocabularies (covering thousands of
concept names and relations, and millions of entities). To this end, we develop
a dataset where user questions are annotated with Sparql parses and system
answers correspond to execution results thereof. We present two different
semantic parsing approaches and highlight the challenges of the task: dealing
with large vocabularies, modelling conversation context, predicting queries
with multiple entities, and generalising to new questions at test time. We hope
our dataset will serve as useful testbed for the development of conversational
semantic parsers. Our dataset and models are released at
https://github.com/EdinburghNLP/SPICE.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:45:11 GMT""}]","2023-01-31"
"2301.12218","Hongyu Liu","Rongliang Chen, Youjun Deng, Yang Gao, Jingzhi Li and Hongyu Liu","Locating multiple magnetized anomalies by geomagnetic monitoring",,,,,"math.NA cs.NA math.AP physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The presence of magnetized anomalies in the shell of the Earth interrupts its
geomagnetic field. We consider the inverse problem of identifying the anomalies
by monitoring the variation of the geomagnetic field. Motivated by the
theoretical unique identifiability result in [5], we develop a novel numerical
scheme of locating multiple magnetized anomalies. In our study, we do not
assume that the source that generates the geomagnetic field, and the medium
configurations of the Earth's core and the magnetized anomalies are a-priori
known. The core of the reconstruction scheme is a novel imaging functional
whose quantitative behaviours can be used to identify the anomalies. Both
rigorous analysis and extensive numerical experiments are provided to verify
the effectiveness and promising features of the proposed reconstruction scheme.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:47:29 GMT""}]","2023-01-31"
"2301.12219","Xin Wei","Xin Wei, Lei Zhang, Jianwei Zhang, Junyou Wang, Wenjie Liu, Jiaqi Li
  and Xian Jiang","Towards Accurate Acne Detection via Decoupled Sequential Detection Head","9 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate acne detection plays a crucial role in acquiring precise diagnosis
and conducting proper therapy. However, the ambiguous boundaries and arbitrary
dimensions of acne lesions severely limit the performance of existing methods.
In this paper, we address these challenges via a novel Decoupled Sequential
Detection Head (DSDH), which can be easily adopted by mainstream two-stage
detectors. DSDH brings two simple but effective improvements to acne detection.
Firstly, the offset and scaling tasks are explicitly introduced, and their
incompatibility is settled by our task-decouple mechanism, which improves the
capability of predicting the location and size of acne lesions. Second, we
propose the task-sequence mechanism, and execute offset and scaling
sequentially to gain a more comprehensive insight into the dimensions of acne
lesions. In addition, we build a high-quality acne detection dataset named
ACNE-DET to verify the effectiveness of DSDH. Experiments on ACNE-DET and the
public benchmark ACNE04 show that our method outperforms the state-of-the-art
methods by significant margins. Our code and dataset are publicly available at
(temporarily anonymous).
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:58:51 GMT""}]","2023-01-31"
"2301.12220","Bakhtiyor Baizakov","K. K. Ismailov, B. B. Baizakov, F. Kh. Abdullaev and M. Salerno","Dynamics of imbalanced quasi-one-dimensional binary Bose-Einstein
  condensate in external potentials","8 pages, 6 figures",,,,"cond-mat.quant-gas","http://creativecommons.org/publicdomain/zero/1.0/","  In the framework of coupled 1D Gross-Pitaevskii equations, we explore the
dynamics of a binary Bose-Einstein condensate where the intra-component
interaction is repulsive, while the inter-component one is attractive. The
existence regimes of stable self-trapped localized states in the form of
symbiotic solitons have been analyzed. Imbalanced mixtures, where the number of
atoms in one component exceeds the number of atoms in the other component, are
considered in parabolic potential and box-like trap. When all the intra-species
and inter-species interactions are repulsive, we numerically find a new type of
symbiotic solitons resembling dark-bright solitons. A variational approach has
been developed which allows us to find the stationary state of the system and
frequency of small amplitude dynamics near the equilibrium. It is shown that
the strength of inter-component coupling can be retrieved from the frequency of
the localized state's vibrations.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 14:59:25 GMT""}]","2023-01-31"
"2301.12221","Luigi Frunzo","F. Russo, A. Tenore, M.R. Mattei, L. Frunzo","Multiscale modelling of heavy metals adsorption on algal-bacterial
  photogranules","43 pages, 18 figures, preprint version",,,,"q-bio.CB physics.bio-ph q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A multiscale mathematical model describing the genesis and ecology of
algal-bacterial photogranules and the metals biosorption on their solid matrix
within a sequencing batch reactor (SBR) is presented. The granular biofilm is
modelled as a spherical free boundary domain with radial symmetry and a
vanishing initial value. The free boundary evolution is governed by an ODE
accounting for microbial growth, attachment and detachment phenomena. The model
is based on systems of PDEs derived from mass conservation principles.
Specifically, two systems of nonlinear hyperbolic PDEs model the growth of
attached species and the dynamics of free adsorption sites; and two systems of
quasi-linear parabolic PDEs govern the diffusive transport and conversion of
nutrients and metals. The model is completed with systems of impulsive ordinary
differential equations (IDEs) describing the evolution of dissolved substrates,
metals, and planktonic and detached biomasses within the granular-based SBR.
All main phenomena involved in the process are considered in the mathematical
model. Moreover, the dual effect of metal presence on the formation process of
photogranules is accounted: metal stimulates the production of EPS by sessile
species and negatively affects the metabolic activities of microbial species.
To describe the effects related to metal presence, a stimulation term for EPS
production and an inhibition term for metal are included in all microbial
kinetics. The model is used to examine the role of the microbial species and
EPS in the adsorption process, and the effect of metal concentration and
adsorption proprieties of biofilm components on the metal removal. Numerical
results show that the model accurately describes the photogranules evolution
and ecology and confirm the applicability of algal-bacterial photogranules
systems for metal-rich wastewater treatment.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:02:17 GMT""}]","2023-01-31"
"2301.12222","Aleksandar Vakanski","Fadi Alharbi and Aleksandar Vakanski","Machine Learning Methods for Cancer Classification Using Gene Expression
  Data: A Review","29 pages, 1 figure, 11 tables","Bioengineering 2023, 10(2), 173","10.3390/bioengineering10020173",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Cancer is a term that denotes a group of diseases caused by abnormal growth
of cells that can spread in different parts of the body. According to the World
Health Organization (WHO), cancer is the second major cause of death after
cardiovascular diseases. Gene expression can play a fundamental role in the
early detection of cancer, as it is indicative of the biochemical processes in
tissue and cells, as well as the genetic characteristics of an organism.
Deoxyribonucleic Acid (DNA) microarrays and Ribonucleic Acid (RNA)- sequencing
methods for gene expression data allow quantifying the expression levels of
genes and produce valuable data for computational analysis. This study reviews
recent progress in gene expression analysis for cancer classification using
machine learning methods. Both conventional and deep learning-based approaches
are reviewed, with an emphasis on the ap-plication of deep learning models due
to their comparative advantages for identifying gene patterns that are
distinctive for various types of cancers. Relevant works that employ the most
commonly used deep neural network architectures are covered, including
multi-layer perceptrons, convolutional, recurrent, graph, and transformer
networks. This survey also presents an overview of the data collection methods
for gene expression analysis and lists important datasets that are commonly
used for supervised machine learning for this task. Furthermore, reviewed are
pertinent techniques for feature engineering and data preprocessing that are
typically used to handle the high dimensionality of gene expression data,
caused by a large number of genes present in data samples. The paper concludes
with a discussion of future research directions for machine learning-based gene
expression analysis for cancer classification.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:03:03 GMT""}]","2023-01-31"
"2301.12223","Bin Yue","Xin Zhang, Bin Yue, Yuan Shi, Fengquan Wu, Xuelei Chen","On Measuring the 21 cm Global Spectrum of the Cosmic Dawn with an
  Interferometer Array","18 pages, 23 figures, accepted for publication in ApJ",,"10.3847/1538-4357/acb6fe",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We theoretically investigate the recovery of global spectrum (monopole) from
visibilities (cross-correlation only) measured by the interferometer array and
the feasibility of extracting 21 cm signal of cosmic dawn. In our approach, the
global spectrum is obtained by solving the monopole and higher-order components
simultaneously from the visibilities measured with up to thousands of
baselines. Using this algorithm, the monopole of both foreground and the 21 cm
signal can be correctly recovered in a broad range of conditions. We find that
a 3D baseline distribution can have much better performance than a 2D (planar)
baseline distribution, particularly when there is a lack of shorter baselines.
We simulate for ground-based 2D and 3D array configurations, and a cross-shaped
space array located at the Sun-Earth L2 point that can form 3D baselines
through orbital precession. In all simulations we obtain good recovered global
spectrum, and successfully extract the 21 cm signal from it, with reasonable
number of antennas and observation time.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:06:40 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 07:42:33 GMT""}]","2023-03-29"
"2301.12224","Alessandro Mariani","A. Mariani, S. Pradhan, E. Ercolessi","Hamiltonians and gauge-invariant Hilbert space for lattice
  Yang-Mills-like theories with finite gauge group","28 pages, 10 figures",,,,"quant-ph hep-lat","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Motivated by quantum simulation, we consider lattice Hamiltonians for
Yang-Mills gauge theories with finite gauge group, for example a finite
subgroup of a compact Lie group. We show that the electric Hamiltonian admits
an interpretation as a certain natural, non-unique Laplacian operator on the
finite Abelian or non-Abelian group, and derive some consequences from this
fact. Independently of the chosen Hamiltonian, we provide a full explicit
description of the physical, gauge-invariant Hilbert space for pure gauge
theories and derive a simple formula to compute its dimension. We illustrate
the use of the gauge-invariant basis to diagonalize a dihedral gauge theory on
a small periodic lattice.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:16:33 GMT""}]","2023-01-31"
"2301.12225","Liming Wang","Liming Wang, Hong Xie, Ye Li, Jian Tan and John C.S. Lui","Interactive Log Parsing via Light-weight User Feedback",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Template mining is one of the foundational tasks to support log analysis,
which supports the diagnosis and troubleshooting of large scale Web
applications. This paper develops a human-in-the-loop template mining framework
to support interactive log analysis, which is highly desirable in real-world
diagnosis or troubleshooting of Web applications but yet previous template
mining algorithms fails to support it. We formulate three types of light-weight
user feedbacks and based on them we design three atomic human-in-the-loop
template mining algorithms. We derive mild conditions under which the outputs
of our proposed algorithms are provably correct. We also derive upper bounds on
the computational complexity and query complexity of each algorithm. We
demonstrate the versatility of our proposed algorithms by combining them to
improve the template mining accuracy of five representative algorithms over
sixteen widely used benchmark datasets.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:19:43 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 17:14:48 GMT""}]","2023-02-28"
"2301.12226","Xinyan Su","Xinyan Su, Zhiheng Zhang","Causal Influence Maximization in Hypergraph",,,,,"cs.SI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Influence Maximization (IM) is the task of selecting a fixed number of seed
nodes in a given network to maximize dissemination benefits. Although the
research for efficient algorithms has been dedicated recently, it is usually
neglected to further explore the graph structure and the objective function
inherently. With this motivation, we take the first attempt on the
hypergraph-based IM with a novel causal objective. We consider the case that
each hypergraph node carries specific attributes with Individual Treatment
Effect (ITE), namely the change of potential outcomes before/after infections
in a causal inference perspective. In many scenarios, the sum of ITEs of the
infected is a more reasonable objective for influence spread, whereas it is
difficult to achieve via current IM algorithms. In this paper, we introduce a
new algorithm called \textbf{CauIM}. We first recover the ITE of each node with
observational data and then conduct a weighted greedy algorithm to maximize the
sum of ITEs of the infected. Theoretically, we mainly present the generalized
lower bound of influence spread beyond the well-known $(1-\frac{1}{e})$ optimal
guarantee and provide the robustness analysis. Empirically, in real-world
experiments, we demonstrate the effectiveness and robustness of \textbf{CauIM}.
It outperforms the previous IM and randomized methods significantly.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:34:03 GMT""}]","2023-01-31"
"2301.12227","Ke Chen","Ke Chen, Chunmei Wang, and Haizhao Yang","Deep Operator Learning Lessens the Curse of Dimensionality for PDEs",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) have achieved remarkable success in numerous
domains, and their application to PDE-related problems has been rapidly
advancing. This paper provides an estimate for the generalization error of
learning Lipschitz operators over Banach spaces using DNNs with applications to
various PDE solution operators. The goal is to specify DNN width, depth, and
the number of training samples needed to guarantee a certain testing error.
Under mild assumptions on data distributions or operator structures, our
analysis shows that deep operator learning can have a relaxed dependence on the
discretization resolution of PDEs and, hence, lessen the curse of
dimensionality in many PDE-related problems including elliptic equations,
parabolic equations, and Burgers equations. Our results are also applied to
give insights about discretization-invariant in operator learning.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:35:52 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 16:07:59 GMT""}]","2023-05-31"
"2301.12228","Henrik Koch","Sarai Dery Folkestad, Bendik St{\o}a Sannes, and Henrik Koch","Entanglement Coupled Cluster Theory: Exact Spin-Adaptation","17 pages, 3 figures and 7 tables",,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We present a novel approach to spin-adapted coupled cluster theory. This
approach is based on the entanglement of an open-shell molecule with electrons
in a non-interacting bath; together they form a closed-shell state. For the
total system, electron correlation can be added with the standard spin-adapted
closed-shell coupled cluster formalism. A projection operator, which enforces
conditions on the electrons in the bath, is used to obtain the desired state of
the molecular system. This entanglement coupled cluster theory is detailed and
proof-of-concept calculations for doublet states are reported. The approach is
extendable to open-shell systems with other values of the total spin.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:38:23 GMT""},{""version"":""v2"",""created"":""Fri, 19 May 2023 15:49:13 GMT""}]","2023-05-22"
"2301.12229","Zhuangzhuang Cui","Zhuangzhuang Cui, Abdul Saboor, Achiel Colpaert, Sofie Pollin","Path Loss Analysis for Low-Altitude Air-to-Air Millimeter-Wave Channel
  in Built-Up Area","6 pages, 6 figures, to appear in IEEE ICC 2023",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Communications between unmanned aerial vehicles (UAVs) play an important role
in deploying aerial networks. Although some studies reveal that drone-based
air-to-air (A2A) channels are relatively clear and thus can be modeled as
free-space propagation, such an assumption may not be applicable to drones
flying in low altitudes of built-up environments. In practice, low-altitude A2A
channel modeling becomes more challenging in urban scenarios since buildings
can obstruct the line-of-sight (LOS) path, and multipaths from buildings lead
to additional losses. Therefore, we herein focus on modeling low-altitude A2A
channels considering a generic urban deployment, where we introduce the
evidence of the small-size first Fresnel zone at the millimeter-wave (mmWave)
band to approximately derive the LOS probability. Then, the path loss under
different propagation conditions is investigated to obtain an integrated path
loss model. In addition, we incorporate the impact of imperfect beam alignment
on the path loss, where the relation between path loss fluctuation and beam
misalignment level is modeled as an exponential form. Finally, comparisons with
the 3GPP model show the effectiveness of the proposed analytical model.
Numerical simulations in different environments and heights provide practical
deployment guidance for aerial networks.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:38:46 GMT""}]","2023-01-31"
"2301.12230","QiAo Yuan","Qiao Yuan, Sheng-Uei Guan, Pin Ni, Tianlun Luo, Ka Lok Man, Prudence
  Wong, Victor Chang","Continual Graph Learning: A Survey","38 pages, 7 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research on continual learning (CL) mainly focuses on data represented in the
Euclidean space, while research on graph-structured data is scarce.
Furthermore, most graph learning models are tailored for static graphs.
However, graphs usually evolve continually in the real world. Catastrophic
forgetting also emerges in graph learning models when being trained
incrementally. This leads to the need to develop robust, effective and
efficient continual graph learning approaches. Continual graph learning (CGL)
is an emerging area aiming to realize continual learning on graph-structured
data. This survey is written to shed light on this emerging area. It introduces
the basic concepts of CGL and highlights two unique challenges brought by
graphs. Then it reviews and categorizes recent state-of-the-art approaches,
analyzing their strategies to tackle the unique challenges in CGL. Besides, it
discusses the main concerns in each family of CGL methods, offering potential
solutions. Finally, it explores the open issues and potential applications of
CGL.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:42:49 GMT""}]","2023-01-31"
"2301.12231","Vukan Ninkovic","Vukan Ninkovic, Dejan Vukobratovic, Christian H\""ager, Henk Wymeersch,
  Alexandre Graell i Amat","Rateless Autoencoder Codes: Trading off Decoding Delay and Reliability","6 pages, 7 figures, to appear at IEEE ICC 2023",,,,"cs.IT cs.LG eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Most of today's communication systems are designed to target reliable message
recovery after receiving the entire encoded message (codeword). However, in
many practical scenarios, the transmission process may be interrupted before
receiving the complete codeword. This paper proposes a novel rateless
autoencoder (AE)-based code design suitable for decoding the transmitted
message before the noisy codeword is fully received. Using particular dropout
strategies applied during the training process, rateless AE codes allow to
trade off between decoding delay and reliability, providing a graceful
improvement of the latter with each additionally received codeword symbol. The
proposed rateless AEs significantly outperform the conventional AE designs for
scenarios where it is desirable to trade off reliability for lower decoding
delay.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:47:14 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 09:29:19 GMT""}]","2023-02-01"
"2301.12232","Tien Mai","Tien Mai and Avinandan Bose and Arunesh Sinha and Thanh H. Nguyen","Tackling Stackelberg Network Interdiction against a Boundedly Rational
  Adversary",,,,,"math.OC cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies Stackelberg network interdiction games -- an important
class of games in which a defender first allocates (randomized) defense
resources to a set of critical nodes on a graph while an adversary chooses its
path to attack these nodes accordingly. We consider a boundedly rational
adversary in which the adversary's response model is based on a dynamic form of
classic logit-based discrete choice models. We show that the problem of finding
an optimal interdiction strategy for the defender in the rational setting is
NP-hard. The resulting optimization is in fact non-convex and additionally,
involves complex terms that sum over exponentially many paths. We tackle these
computational challenges by presenting new efficient approximation algorithms
with bounded solution guarantees. First, we address the exponentially-many-path
challenge by proposing a polynomial-time dynamic programming-based formulation.
We then show that the gradient of the non-convex objective can also be computed
in polynomial time, which allows us to use a gradient-based method to solve the
problem efficiently. Second, we identify a restricted problem that is convex
and hence gradient-based methods find the global optimal solution for this
restricted problem. We further identify mild conditions under which this
restricted problem provides a bounded approximation for the original problem.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:48:20 GMT""}]","2023-01-31"
"2301.12233","Yong Zheng","Yong Zheng, Yakov Faerman, Benjamin D. Oppenheimer, Mary E. Putman,
  Kristen B. W. McQuinn, Evan N. Kirby, Joseph N. Burchett, O. Grace Telford,
  Jessica K. Werk, Doyeon A. Kim","A Comprehensive Investigation of Metals in the Circumgalactic Medium of
  Nearby Dwarf Galaxies","Submitted to ApJ; comments welcome",,"10.17909/ve0k-ps78",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Dwarf galaxies are found to have lost most their metals via feedback
processes; however, there still lacks consistent assessment on the retention
rate of metals in their circumgalactic medium (CGM). Here we investigate the
metal content in the CGM of 49 isolated dwarf galaxies with
$M_*=10^{6.5-9.5}~M_\odot$ ($M_{\rm 200m}=10^{10.0-11.5}~M_\odot$) using
HST/COS spectroscopy. While HI (Ly$\alpha$) is ubiquitously detected ($89\%$)
within the CGM, we find low detection rates ($\approx5-21\%$) in CII, CIV,
SiII, SiIII, and SiIV, largely consistent with literature values. Assuming
these ions form in the cool ($T\approx10^4$ K) CGM with photoionization
equilibrium, the observed HI and metal column density profiles can be best
explained by an empirical model with low gas density and high volume filling
factor. For a typical galaxy with $M_{\rm 200m}=10^{10.9}~M_\odot$ (median of
the sample), our model predicts a cool gas mass of $M_{\rm
CGM,cool}\sim10^{8.4}~M_\odot$, corresponding to $\sim2\%$ of the galaxy's
baryonic budget. Assuming a metallicity of $0.3Z_\odot$, we estimate that the
dwarf galaxy's cool CGM only harbors $\sim10\%$ of the metals ever produced,
with the rest either in warmer phases yet to be detected, or transported to the
intergalactic medium. We further examine the EAGLE simulation and show that HI
and low ions may arise from a dense cool medium, while CIV from a diffuse
warmer medium. Our work provides the community a uniform dataset on dwarf
galaxies' CGM that combines our recent observations, additional archival data
and literature compilation, which can be used to test various theoretical
models of dwarf galaxies.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:48:43 GMT""}]","2023-01-31"
"2301.12234","Paulo E. Faria Junior Dr","Paulo E. Faria Junior, Thomas Naimer, Kathleen M. McCreary, Berend T.
  Jonker, Jonathan J. Finley, Scott A. Crooker, Jaroslav Fabian, Andreas V.
  Stier","Proximity-enhanced valley Zeeman splitting at the WS$_2$/graphene
  interface","14 pages, 6 figures, 3 tables",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The valley Zeeman physics of excitons in monolayer transition metal
dichalcogenides provides valuable insight into the spin and orbital degrees of
freedom inherent to these materials. Being atomically-thin materials, these
degrees of freedom can be influenced by the presence of adjacent layers, due to
proximity interactions that arise from wave function overlap across the 2D
interface. Here, we report 60 T magnetoreflection spectroscopy of the A- and B-
excitons in monolayer WS$_2$, systematically encapsulated in monolayer
graphene. While the observed variations of the valley Zeeman effect for the A-
exciton are qualitatively in accord with expectations from the bandgap
reduction and modification of the exciton binding energy due to the
graphene-induced dielectric screening, the valley Zeeman effect for the B-
exciton behaves markedly different. We investigate prototypical WS$_2$/graphene
stacks employing first-principles calculations and find that the lower
conduction band of WS$_2$ at the $K/K'$ valleys (the $CB^-$ band) is strongly
influenced by the graphene layer on the orbital level. This leads to variations
in the valley Zeeman physics of the B- exciton, consistent with the
experimental observations. Our detailed microscopic analysis reveals that the
conduction band at the $Q$ point of WS$_2$ mediates the coupling between $CB^-$
and graphene due to resonant energy conditions and strong coupling to the Dirac
cone. Our results therefore expand the consequences of proximity effects in
multilayer semiconductor stacks, showing that wave function hybridization can
be a multi-step process with different bands mediating the interlayer
interactions. Such effects can be exploited to resonantly engineer the
spin-valley degrees of freedom in van der Waals and moir\'e heterostructures.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:56:44 GMT""}]","2023-01-31"
"2301.13627","Kazuharu Bamba","Riasat Ali, Zunaira Akhtar, Kazuharu Bamba, M. Umar Khan","Tunneling and thermodynamics evolution of the magnetized Ernst-like
  black hole","12 pages, 8 figures, version accepted for publication in General
  Relativity and Gravitation. arXiv admin note: text overlap with
  arXiv:2301.02216",,"10.1007/s10714-023-03080-0","FU-PCG-108","gr-qc","http://creativecommons.org/licenses/by/4.0/","  We investigate the tunneling phenomenon of particles through the horizon of a
magnetized Ernst-like black hole. We employ the modified Lagrangian equation
with the extended uncertainty principle for this black hole. We determine a
tunneling rate and the related Hawking temperature for this black hole by using
the WKB approach in the field equation. In addition, we examine the graph
behavior of the Hawking temperature in relation to the black hole event
horizon. We explore the stability analysis of this black hole by taking into
account the impact of quantum gravity on Hawking temperatures. The temperature
for a magnetized Ernst-like black hole rises as the correction parameter is
decreased. Moreover, we analyze the thermodynamics quantities such as Hawking
temperature, heat capacity and Bekenstein entropy by using the different
approach. We obtain the corrected entropy to study the impact of logarithmic
corrections on the different thermodynamic quantities. It is shown that these
correction terms makes the system stable under thermal fluctuations.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 10:24:03 GMT""}]","2023-02-01"
"2301.13632","Wayne Goddard","Wayne Goddard","There are 2-tough 4-regular graphs with claws",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that there are 2-tough 4-regular graphs with claws
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 17:02:41 GMT""}]","2023-02-01"
"2301.13825","Sundeep Kapila","Sundeep Kapila and Pradeep R. Nair","Geometry aware predictive models for exocytosis",,,,,"physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inter neuron communication happens through the exchange of neurotransmitters
at the synapse by a process known as exocytosis. This makes exocytosis a
fundamental process of information exchange in the body. The exocytosis process
has a distinct geometry as it involves a vesicle that attaches to the cell
membrane and then releases the neurotransmitters through a pore. Significant
recent research, both experimental and numerical, attempt to understand the
time dynamics of exocytosis. In this manuscript, we share an analytical model
that predicts the key output parameters of exocytosis based on the geometry of
the vesicle and pore. Our analytical predictions are well supported by detailed
numerical simulations. This model could help extract geometrical parameters
from experimental data and hence could be of broad interest.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 13:17:33 GMT""}]","2023-02-01"
"2302.00090","Aaron Hendrickson","Aaron Hendrickson and David P. Haefner","Photon Counting Histogram Expectation Maximization Algorithm for
  Characterization of Deep Sub-Electron Read Noise Sensors","8 pages, 6 figures",,,,"physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  We develop a novel algorithm for characterizing Deep Sub-Electron Read Noise
(DSERN) image sensors. This algorithm is able to simultaneously compute maximum
likelihood estimates of quanta exposure, conversion gain, bias, and read noise
of DSERN pixels from a single sample of data with less uncertainty than the
traditional photon transfer method. Methods for estimating the starting point
of the algorithm are also provided to allow for automated analysis.
Demonstration through Monte Carlo numerical experiments are carried out to show
the effectiveness of the proposed technique. In support of the reproducible
research effort, all of the simulation and analysis tools developed are
available on the MathWorks file exchange [1].
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:41:35 GMT""}]","2023-02-02"
"2302.05425","Erdi Kara","Erdi Kara, George Zhang, Joseph J. Williams, Gonzalo Ferrandez-Quinto,
  Leviticus J. Rhoden, Maximilian Kim, J. Nathan Kutz, Aminur Rahman","Deep Learning Based Object Tracking in Walking Droplet and Granular
  Intruder Experiments",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present a deep-learning based tracking objects of interest in walking
droplet and granular intruder experiments. In a typical walking droplet
experiment, a liquid droplet, known as \textit{walker}, propels itself
laterally on the free surface of a vibrating bath of the same liquid. This
motion is the result of the interaction between the droplets and the surface
waves generated by the droplet itself after each successive bounce. A walker
can exhibit a highly irregular trajectory over the course of its motion,
including rapid acceleration and complex interactions with the other walkers
present in the same bath. In analogy with the hydrodynamic experiments, the
granular matter experiments consist of a vibrating bath of very small solid
particles and a larger solid \textit{intruder}. Like the fluid droplets, the
intruder interacts with and travels the domain due to the waves of the bath but
tends to move much slower and much less smoothly than the droplets. When
multiple intruders are introduced, they also exhibit complex interactions with
each other. We leverage the state-of-art object detection model YOLO and the
Hungarian Algorithm to accurately extract the trajectory of a walker or
intruder in real-time. Our proposed methodology is capable of tracking
individual walker(s) or intruder(s) in digital images acquired from a broad
spectrum of experimental settings and does not suffer from any identity-switch
issues. Thus, the deep learning approach developed in this work could be used
to automatize the efficient, fast and accurate extraction of observables of
interests in walking droplet and granular flow experiments. Such extraction
capabilities are critically enabling for downstream tasks such as building
data-driven dynamical models for the coarse-grained dynamics and interactions
of the objects of interest.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 16:40:54 GMT""}]","2023-02-13"
"2302.06388","Enrique Garc\'ia Mac\'ias Mr","Hasan Borke Birgin, Enrique Garc\'ia-Mac\'ias, Antonella D'Alessandro,
  Filippo Ubertini","Self-powered weigh-in-motion system combining vibration energy
  harvesting and self-sensing composite pavements",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Overloaded vehicles are the primary cause of accelerated degradation of road
infrastructures. In this context, although weigh-in-motion (WIM) systems are
most efficient to enforce weight regulations, current technologies require
costly investments limiting their extensive implementation. Recent advances in
multifunctional composites enabled cost-efficient alternatives in the form of
smart pavements. Nevertheless, the need for a stable power supply still
represents a major practical limitation. This work presents a novel
proof-of-concept self-sustainable WIM technology combining smart pavements and
vibration-based energy harvesting (EH). The feasibility of piezoelectric
bimorph cantilevered beams to harvest traffic-induced vibrations is firstly
investigated, followed by the demonstration of the proposed technology under
laboratory conditions. The main original contributions of this work comprise
(i) the development of a new self-powered data acquisition system, (ii) a novel
approach for the fabrication and electromechanical testing of the
piezoresistive composite pavement, and (iii) laboratory feasibility analysis of
the developed EH unit to conduct traffic load identification through electrical
resistivity measurements of the smart pavement. While the presented results
conclude the need for dense EH networks or combinations of different EH
technologies to attain complete self-sustainability, this work represents an
initial feasibility evidence paving the way towards the development of
self-powered low-cost WIM systems.
","[{""version"":""v1"",""created"":""Fri, 27 Jan 2023 21:05:38 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 08:25:02 GMT""}]","2023-02-15"
"2302.10804","Yang Sun","Yang Sun and Yifan Xie","GDBN: a Graph Neural Network Approach to Dynamic Bayesian Network","The first edition",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Identifying causal relations among multi-variate time series is one of the
most important elements towards understanding the complex mechanisms underlying
the dynamic system. It provides critical tools for forecasting, simulations and
interventions in science and business analytics. In this paper, we proposed a
graph neural network approach with score-based method aiming at learning a
sparse DAG that captures the causal dependencies in a discretized time temporal
graph. We demonstrate methods with graph neural network significantly
outperformed other state-of-the-art methods with dynamic bayesian networking
inference. In addition, from the experiments, the structural causal model can
be more accurate than a linear SCM discovered by the methods such as Notears.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 02:49:13 GMT""}]","2023-02-22"
"2302.10824","Niloufar Delfan","Mohammadreza Shahsavari, Niloufar Delfan, Mohamad Forouzanfar","Localizing the Origin of Idiopathic Ventricular Arrhythmia from ECG
  Using an Attention-Based Recurrent Convolutional Neural Network",,,,,"eess.SP cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Idiopathic ventricular arrhythmia (IVAs) is extra abnormal heartbeats
disturbing the regular heart rhythm that can become fatal if left untreated.
Cardiac catheter ablation is the standard approach to treat IVAs, however, a
crucial prerequisite for the ablation is the localization of IVAs' origin. The
current IVA localization techniques are invasive, rely on expert
interpretation, or are inaccurate. In this study, we developed a new
deep-learning algorithm that can automatically identify the origin of IVAs from
ECG signals without the need for expert manual analysis. Our developed deep
learning algorithm was comprised of a spatial fusion to extract the most
informative features from multichannel ECG data, temporal modeling to capture
the evolving pattern of the ECG time series, and an attention mechanism to
weigh the most important temporal features and improve the model
interpretability. The algorithm was validated on a 12-lead ECG dataset
collected from 334 patients (230 females) who experienced IVA and successfully
underwent a catheter ablation procedure that determined IVA's exact origins.
The proposed method achieved an area under the curve of 93%, an accuracy of
94%, a sensitivity of 97%, a precision of 95%, and an F1 score of 96% in
locating the origin of IVAs and outperformed existing automatic and
semi-automatic algorithms. The proposed method shows promise toward automatic
and noninvasive evaluation of IVA patients before cardiac catheter ablation.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 08:01:10 GMT""}]","2023-02-22"
"2302.10983","Sophia Sandholm","Sophia Sandholm","Do Orcas Have Semantic Language? Machine Learning to Predict Orca
  Behaviors Using Partially Labeled Vocalization Data",,,,,"cs.SD cs.CL cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Orcinus orca (killer whales) exhibit complex calls. They last about a second.
In a call, an orca typically uses multiple frequencies simultaneously, varies
the frequencies, and varies their volumes. Behavior data is hard to obtain
because orcas live under water and travel quickly. Sound data is relatively
easy to capture. As a science goal, we would like to know whether orca
vocalizations constitute a semantic language. We do this by studying whether
machine learning can predict behavior from vocalizations. Such prediction would
also help scientific research and safety applications because one would like to
predict behavior while only having to capture sound. A significant challenge in
this process is lack of labeled data. We work with recent recordings of McMurdo
Sound orcas [Wellard et al. 2020] where each recording is labeled with the
behaviors observed during the recording. This yields a dataset where sound
segments - continuous vocalizations that can be thought of as call sequences or
more general structures - within the recordings are labeled with superfluous
behaviors. Despite that, with a careful combination of recent machine learning
techniques, we achieve 96.4% classification accuracy. This suggests that orcas
do use a semantic language. It is also promising for research and applications.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:04:22 GMT""}]","2023-02-23"
"2302.12002","Sven Elflein","Sven Elflein","Master's Thesis: Out-of-distribution Detection with Energy-based Models","Master's Thesis",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today, deep learning is increasingly applied in security-critical situations
such as autonomous driving and medical diagnosis. Despite its success, the
behavior and robustness of deep networks are not fully understood yet, posing a
significant risk. In particular, researchers recently found that neural
networks are overly confident in their predictions, even on data they have
never seen before. To tackle this issue, one can differentiate two approaches
in the literature. One accounts for uncertainty in the predictions, while the
second estimates the underlying density of the training data to decide whether
a given input is close to the training data, and thus the network is able to
perform as expected.In this thesis, we investigate the capabilities of EBMs at
the task of fitting the training data distribution to perform detection of
out-of-distribution (OOD) inputs. We find that on most datasets, EBMs do not
inherently outperform other density estimators at detecting OOD data despite
their flexibility. Thus, we additionally investigate the effects of
supervision, dimensionality reduction, and architectural modifications on the
performance of EBMs. Further, we propose Energy-Prior Network (EPN) which
enables estimation of various uncertainties within an EBM for classification,
bridging the gap between two approaches for tackling the OOD detection problem.
We identify a connection between the concentration parameters of the Dirichlet
distribution and the joint energy in an EBM. Additionally, this allows
optimization without a held-out OOD dataset, which might not be available or
costly to collect in some applications. Finally, we empirically demonstrate
that Energy-Prior Network (EPN) is able to detect OOD inputs, datasets shifts,
and adversarial examples. Theoretically, EPN offers favorable properties for
the asymptotic case when inputs are far from the training data.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 15:40:30 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 15:27:06 GMT""}]","2023-03-27"
"2302.14032","Teng Huang","Teng Huang and Qiang Tan","$L^{2}$-Hodge theory on complete almost K\""{a}hler manifold and its
  application","33 pages, Submitted. We have added some references. Since Proposition
  4.5 can be obtained directly from Lemma 3.2 in [43], we remove its proof",,,,"math.DG","http://creativecommons.org/publicdomain/zero/1.0/","  Let $(X,J,\omega)$ be a complete $2n$-dimensional almost K\""{a}hler manifold.
First part of this article, we construct some identities of various Laplacians,
generalized Hodge and Serre dualities, a generalized hard Lefschetz duality,
and a Lefschetz decomposition, all on the space of
$\ker{\Delta_{\partial}}\cap\ker{\Delta_{\bar{\partial}}}$ on pure bidegree. In
the second part, as some applications of those identities, we establish some
vanishing theorems on the spaces of $L^{2}$-harmonic $(p,q)$-forms on $X$ under
some growth assumptions on the K\""{a}her form $\omega$. We also give some
$L^{2}$-estimates to sharpen the vanishing theorems in two specific cases. At
last of the article, as an application, we study the topology and geometry of
the compact almost K\""{a}hler manifold with negative sectional curvature.
","[{""version"":""v1"",""created"":""Sat, 28 Jan 2023 06:52:02 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 10:16:43 GMT""}]","2023-03-17"
