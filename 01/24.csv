"2301.09507","Nikolaos Nakis","Nikolaos Nakis and Abdulkadir \c{C}elikkanat and Louis Boucherie and
  Christian Djurhuus and Felix Burmester and Daniel Mathias Holmelund and
  Monika Frolcov\'a and Morten M{\o}rup","Characterizing Polarization in Social Networks using the Signed
  Relational Latent Distance Model","CAMERA READY version - Proceedings of the 26th International
  Conference on Artificial Intelligence and Statistics (AISTATS) 2023,
  Valencia, Spain. PMLR: Volume 206. Copyright 2023 by the author(s)",,,,"stat.ML cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Graph representation learning has become a prominent tool for the
characterization and understanding of the structure of networks in general and
social networks in particular. Typically, these representation learning
approaches embed the networks into a low-dimensional space in which the role of
each individual can be characterized in terms of their latent position. A major
current concern in social networks is the emergence of polarization and filter
bubbles promoting a mindset of ""us-versus-them"" that may be defined by extreme
positions believed to ultimately lead to political violence and the erosion of
democracy. Such polarized networks are typically characterized in terms of
signed links reflecting likes and dislikes. We propose the latent Signed
relational Latent dIstance Model (SLIM) utilizing for the first time the
Skellam distribution as a likelihood function for signed networks and extend
the modeling to the characterization of distinct extreme positions by
constraining the embedding space to polytopes. On four real social signed
networks of polarization, we demonstrate that the model extracts
low-dimensional characterizations that well predict friendships and animosity
while providing interpretable visualizations defined by extreme positions when
endowing the model with an embedding space restricted to polytopes.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:01:26 GMT""},{""version"":""v2"",""created"":""Sat, 28 Jan 2023 14:26:50 GMT""},{""version"":""v3"",""created"":""Fri, 3 Mar 2023 14:30:23 GMT""}]","2023-03-06"
"2301.09508","Kavita Kumari","Kavita Kumari, Phillip Rieger, Hossein Fereidooni, Murtuza Jadliwala,
  Ahmad-Reza Sadeghi","BayBFed: Bayesian Backdoor Defense for Federated Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Federated learning (FL) allows participants to jointly train a machine
learning model without sharing their private data with others. However, FL is
vulnerable to poisoning attacks such as backdoor attacks. Consequently, a
variety of defenses have recently been proposed, which have primarily utilized
intermediary states of the global model (i.e., logits) or distance of the local
models (i.e., L2-norm) from the global model to detect malicious backdoors.
However, as these approaches directly operate on client updates, their
effectiveness depends on factors such as clients' data distribution or the
adversary's attack strategies. In this paper, we introduce a novel and more
generic backdoor defense framework, called BayBFed, which proposes to utilize
probability distributions over client updates to detect malicious updates in
FL: it computes a probabilistic measure over the clients' updates to keep track
of any adjustments made in the updates, and uses a novel detection algorithm
that can leverage this probabilistic measure to efficiently detect and filter
out malicious updates. Thus, it overcomes the shortcomings of previous
approaches that arise due to the direct usage of client updates; as our
probabilistic measure will include all aspects of the local client training
strategies. BayBFed utilizes two Bayesian Non-Parametric extensions: (i) a
Hierarchical Beta-Bernoulli process to draw a probabilistic measure given the
clients' updates, and (ii) an adaptation of the Chinese Restaurant Process
(CRP), referred by us as CRP-Jensen, which leverages this probabilistic measure
to detect and filter out malicious updates. We extensively evaluate our defense
approach on five benchmark datasets: CIFAR10, Reddit, IoT intrusion detection,
MNIST, and FMNIST, and show that it can effectively detect and eliminate
malicious updates in FL without deteriorating the benign performance of the
global model.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:01:30 GMT""}]","2023-01-24"
"2301.09509","Masaki Gen","M. Gen, A. Ikeda, K. Aoyama, H. O. Jeschke, Y. Ishii, H. Ishikawa, T.
  Yajima, Y. Okamoto, D. Nakamura, S. Takeyama, K. Kindo, Y. H. Matsuda, and Y.
  Kohama","Spin-lattice-coupled superstructure induced by ultrahigh magnetic fields
  in a breathing pyrochlore antiferromagnet","9 pages, 5 figures, SM: 15 pages, 14 figures",,,,"cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The mutual coupling of spin and lattice degrees of freedom is ubiquitous in
magnetic materials and potentially creates exotic magnetic states in response
to the external magnetic field. Here, we investigate phase transitions of a
geometrically frustrated Heisenberg antiferromagnet LiGaCr$_{4}$O$_{8}$,
comprised of a breathing pyrochlore network of spin-3/2 Cr$^{3+}$ ions, up to
600 T by means of magnetization and magnetostriction measurements. We observe a
two-step magnetostructural transition between 150 T and 200 T prior to a
half-magnetization plateau. Considering a microscopic magnetoelastic theory,
the intermediate-field phase can be assigned to a magnetic superstructure with
a three-dimensional periodic array of 3-up-1-down spin molecules and canted
2-up-2-down ones. We attribute the emergence of the magnetic superstructure to
a unique combination of the strong spin-lattice coupling and large breathing
anisotropy.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:02:05 GMT""},{""version"":""v2"",""created"":""Tue, 24 Jan 2023 03:59:56 GMT""}]","2023-01-25"
"2301.09510","Peter Thomas","Peter A. Thomas, Christopher C. Lovell, Maxwell G. A. Maltz, Aswin P.
  Vijayan, Stephen M. Wilkins, Dimitrios Irodotou, William J. Roper, Louise
  Seeyave","First Light and Reionisation Epoch Simulations (FLARES) X: Environmental
  Galaxy Bias and Survey Variance at High Redshift","14 pages, 17 figures. Paper 10 in the First Light and Reionisation
  Epoch Simulations (FLARES) series",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Upcoming deep galaxy surveys with JWST will probe galaxy evolution during the
epoch of reionisation (EoR, $5\leq z\leq10$) over relatively compact areas
(e.g. $\sim$ 300\,arcmin$^2$ for the JADES GTO survey). It is therefore
imperative that we understand the degree of survey variance, to evaluate how
representative the galaxy populations in these studies will be. We use the
First Light And Reionisation Epoch Simulations (FLARES) to measure the galaxy
bias of various tracers over an unprecedentedly large range in overdensity for
a hydrodynamic simulation, and use these relations to assess the impact of bias
and clustering on survey variance in the EoR. Star formation is highly biased
relative to the underlying dark matter distribution, with the mean ratio of the
stellar to dark matter density varying by a factor of 100 between regions of
low and high matter overdensity (smoothed on a scale of 14\,$h^{-1}$cMpc). This
is reflected in the galaxy distribution -- the most massive galaxies are found
solely in regions of high overdensity. As a consequence of the above, galaxies
in the EoR are highly clustered, which can lead to large variance in survey
number counts. For mean number counts $N\lesssim 100$ (1000), in a unit
redshift slice of angular area 300\,arcmin$^2$ (1.4\,deg$^2$), the 2-sigma
range in $N$ is roughly a factor of four (two). We present relations between
the expected variance and survey area for different survey geometries; these
relations will be of use to observers wishing to understand the impact of
survey variance on their results.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:02:06 GMT""}]","2023-01-24"
"2301.09511","Lu Xia","Lu Xia and Michiel E. Hochstenbach and Stefano Massei","On the Convergence of the Gradient Descent Method with Stochastic
  Fixed-point Rounding Errors under the Polyak-Lojasiewicz Inequality",,,,,"stat.ML cs.LG cs.NA math.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When training neural networks with low-precision computation, rounding errors
often cause stagnation or are detrimental to the convergence of the optimizers;
in this paper we study the influence of rounding errors on the convergence of
the gradient descent method for problems satisfying the Polyak-Lojasiewicz
inequality. Within this context, we show that, in contrast, biased stochastic
rounding errors may be beneficial since choosing a proper rounding strategy
eliminates the vanishing gradient problem and forces the rounding bias in a
descent direction. Furthermore, we obtain a bound on the convergence rate that
is stricter than the one achieved by unbiased stochastic rounding. The
theoretical analysis is validated by comparing the performances of various
rounding strategies when optimizing several examples using low-precision
fixed-point number formats.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:02:54 GMT""}]","2023-01-24"
"2301.09512","Sergii Kutnii","Sergii Kutnii","Dirac: a command-line $\gamma$-matrix calculator",,,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  A software for simplification of Dirac matrix polynomials that arise in
particle physics problems is implemented.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:04:17 GMT""},{""version"":""v2"",""created"":""Tue, 24 Jan 2023 14:47:28 GMT""}]","2023-01-25"
"2301.09513","Arup Chattopadhyay","Arup Chattopadhyay, Chandan Pradhan, Anna Skripka","Approximation of the spectral action functional in the case of
  $\tau$-compact resolvents","13 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish estimates and representations for the remainders of Taylor
approximations of the spectral action functional $V\mapsto\tau(f(H_0+V))$ on
bounded self-adjoint perturbations, where $H_0$ is a self-adjoint operator with
$\tau$-compact resolvent in a semifinite von Neumann algebra and $f$ belongs to
a broad set of compactly supported functions including $n$-times differentiable
functions with bounded $n$-th derivative. Our results significantly extend
analogous results in \cite{SkAnJOT}, where $f$ was assumed to be compactly
supported and $(n+1)$-times continuously differentiable. If, in addition, the
resolvent of $H_0$ belongs to the noncommutative $L^n$-space, stronger
estimates are derived and extended to noncompactly supported functions with
suitable decay at infinity.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:05:09 GMT""}]","2023-01-24"
"2301.09514","Thimo Preis","J\""urgen Berges, Razvan Gurau, and Thimo Preis","Asymptotic freedom in a strongly interacting scalar quantum field theory
  in four space-time dimensions","5 pages, 2 figures",,,,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that scalar quantum field theory in four space-time dimensions with
global $O(N)^3$ symmetry and imaginary tetrahedral coupling is asymptotically
free and bounded from below in the large-N limit. The full quantum effective
action for the large-N theory only depends on the square of that coupling which
is real. A perturbative analysis uncovers that the renormalization group flow
of the quartic couplings connects a Gaussian ultraviolet fixed point to a
strongly interacting theory in the infrared. This realizes a renormalizable
field theory which exhibits non-trivial dynamics, such as direct scattering,
while still being analytically tractable also non-perturbatively. Our findings
open up a way to address outstanding problems, such as the possible existence
of quantum bounds on dynamical observables in strongly coupled field theories,
from first principles.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:05:12 GMT""}]","2023-01-24"
"2301.09515","Axel Sauer","Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, Timo Aila","StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale
  Text-to-Image Synthesis","Project page: https://sites.google.com/view/stylegan-t/",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-to-image synthesis has recently seen significant progress thanks to
large pretrained language models, large-scale training data, and the
introduction of scalable model families such as diffusion and autoregressive
models. However, the best-performing models require iterative evaluation to
generate a single sample. In contrast, generative adversarial networks (GANs)
only need a single forward pass. They are thus much faster, but they currently
remain far behind the state-of-the-art in large-scale text-to-image synthesis.
This paper aims to identify the necessary steps to regain competitiveness. Our
proposed model, StyleGAN-T, addresses the specific requirements of large-scale
text-to-image synthesis, such as large capacity, stable training on diverse
datasets, strong text alignment, and controllable variation vs. text alignment
tradeoff. StyleGAN-T significantly improves over previous GANs and outperforms
distilled diffusion models - the previous state-of-the-art in fast
text-to-image synthesis - in terms of sample quality and speed.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:05:45 GMT""}]","2023-01-24"
"2301.09516","Yue Zhao","Wenquan Cui, Yue Zhao, Jianjun Xu, Haoyang Cheng","Online Kernel Sliced Inverse Regression",,,,,"stat.CO math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Online dimension reduction is a common method for high-dimensional streaming
data processing. Online principal component analysis, online sliced inverse
regression, online kernel principal component analysis and other methods have
been studied in depth, but as far as we know, online supervised nonlinear
dimension reduction methods have not been fully studied. In this article, an
online kernel sliced inverse regression method is proposed. By introducing the
approximate linear dependence condition and dictionary variable sets, we
address the problem of increasing variable dimensions with the sample size in
the online kernel sliced inverse regression method, and propose a reduced-order
method for updating variables online. We then transform the problem into an
online generalized eigen-decomposition problem, and use the stochastic
optimization method to update the centered dimension reduction directions.
Simulations and the real data analysis show that our method can achieve close
performance to batch processing kernel sliced inverse regression.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:05:51 GMT""}]","2023-01-24"
"2301.09517","Satoshi Hayakawa","Satoshi Hayakawa, Harald Oberhauser, Terry Lyons","Sampling-based Nystr\""om Approximation and Kernel Quadrature","22 pages, ICML 2023 camera-ready version. Typos fixed",,,,"math.NA cs.LG cs.NA stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze the Nystr\""om approximation of a positive definite kernel
associated with a probability measure. We first prove an improved error bound
for the conventional Nystr\""om approximation with i.i.d. sampling and
singular-value decomposition in the continuous regime; the proof techniques are
borrowed from statistical learning theory. We further introduce a refined
selection of subspaces in Nystr\""om approximation with theoretical guarantees
that is applicable to non-i.i.d. landmark points. Finally, we discuss their
application to convex kernel quadrature and give novel theoretical guarantees
as well as numerical observations.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:05:56 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 02:17:45 GMT""},{""version"":""v3"",""created"":""Tue, 23 May 2023 01:18:39 GMT""}]","2023-05-24"
"2301.09518","Raphael Bennett-Tennenhaus","Raphael Bennett-Tennenhaus","Corner replacement for Morita contexts","16 pages, comments welcome",,,,"math.RT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider how Morita equivalences are compatible with the notion of a
corner subring. Namely, we outline a canonical way to replace a corner subring
of a given ring with one which is Morita equivalent, and look at how such an
equivalence ascends.
  We use the language of Morita contexts, and then specify these more general
results. We work in the setting of rings with local units and unital bimodules,
to extend the reach of potential applications, say to categories of functors.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:06:47 GMT""}]","2023-01-24"
"2301.09519","Ainesh Bakshi","Ainesh Bakshi, Allen Liu, Ankur Moitra and Morris Yau","A New Approach to Learning Linear Dynamical Systems",,,,,"math.OC cs.DS cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Linear dynamical systems are the foundational statistical model upon which
control theory is built. Both the celebrated Kalman filter and the linear
quadratic regulator require knowledge of the system dynamics to provide
analytic guarantees. Naturally, learning the dynamics of a linear dynamical
system from linear measurements has been intensively studied since Rudolph
Kalman's pioneering work in the 1960's. Towards these ends, we provide the
first polynomial time algorithm for learning a linear dynamical system from a
polynomial length trajectory up to polynomial error in the system parameters
under essentially minimal assumptions: observability, controllability, and
marginal stability. Our algorithm is built on a method of moments estimator to
directly estimate Markov parameters from which the dynamics can be extracted.
Furthermore, we provide statistical lower bounds when our observability and
controllability assumptions are violated.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:07:57 GMT""}]","2023-01-24"
"2301.09520","Holger Fehske","Lennard Berg, Andreas Alvermann, and Holger Fehske","Does quantized charge transport in disordered Floquet topological
  insulators require Anderson localization?","8 pages, 7 figures",,,,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a numerical study of Floquet topological insulators with temporal
disorder to investigate the existence of quantized charge transport without
Anderson localization. We first argue that in setups with temporal
imperfections Anderson localization can not be expected but bulk transport is
diffusive in the long-time limit. In a second step we compute the corrections
to the cumulative averaged pumped charge due to the temporal disorder and show
that transport is characterized by two regimes: the transient regime,
represented by a plateau for uncorrelated disorder, and the long-time behavior
with a common scaling law for both uncorrelated and correlated disorder. Most
notably, our numerical results indicate that the dynamic corrections vanish in
the long-time limit such that quantized charge transport and diffusive bulk
motion can coexist in temporally disordered Floquet topological insulators.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:08:34 GMT""}]","2023-01-24"
"2301.09521","Ralph Peeters","Ralph Peeters, Reng Chiz Der, Christian Bizer","WDC Products: A Multi-Dimensional Entity Matching Benchmark",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The difficulty of an entity matching task depends on a combination of
multiple factors such as the amount of corner-case pairs, the fraction of
entities in the test set that have not been seen during training, and the size
of the development set. Current entity matching benchmarks usually represent
single points in the space along such dimensions or they provide for the
evaluation of matching methods along a single dimension, for instance the
amount of training data. This paper presents WDC Products, an entity matching
benchmark which provides for the systematic evaluation of matching systems
along combinations of three dimensions while relying on real-word data. The
three dimensions are (i) amount of corner-cases (ii) generalization to unseen
entities, and (iii) development set size. Generalization to unseen entities is
a dimension not covered by any of the existing benchmarks yet but is crucial
for evaluating the robustness of entity matching systems. WDC Products is based
on heterogeneous product data from thousands of e-shops which mark-up products
offers using schema.org annotations. Instead of learning how to match entity
pairs, entity matching can also be formulated as a multi-class classification
task that requires the matcher to recognize individual entities. WDC Products
is the first benchmark that provides a pair-wise and a multi-class formulation
of the same tasks and thus allows to directly compare the two alternatives. We
evaluate WDC Products using several state-of-the-art matching systems,
including Ditto, HierGAT, and R-SupCon. The evaluation shows that all matching
systems struggle with unseen entities to varying degrees. It also shows that
some systems are more training data efficient than others.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:12:18 GMT""}]","2023-01-24"
"2301.09522","Dengyu Wu","Dengyu Wu and Gaojie Jin and Han Yu and Xinping Yi and Xiaowei Huang","Optimising Event-Driven Spiking Neural Network with Regularisation and
  Cutoff",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Spiking neural networks (SNNs), a variant of artificial neural networks
(ANNs) with the benefit of energy efficiency, have achieved the accuracy close
to its ANN counterparts, on benchmark datasets such as CIFAR10/100 and
ImageNet. However, comparing with frame-based input (e.g., images), event-based
inputs from e.g., Dynamic Vision Sensor (DVS) can make a better use of SNNs
thanks to the SNNs' asynchronous working mechanism. In this paper, we
strengthen the marriage between SNNs and event-based inputs with a proposal to
consider anytime optimal inference SNNs, or AOI-SNNs, which can terminate
anytime during the inference to achieve optimal inference result. Two novel
optimisation techniques are presented to achieve AOI-SNNs: a regularisation and
a cutoff. The regularisation enables the training and construction of SNNs with
optimised performance, and the cutoff technique optimises the inference of SNNs
on event-driven inputs. We conduct an extensive set of experiments on multiple
benchmark event-based datasets, including CIFAR10-DVS, N-Caltech101 and DVS128
Gesture. The experimental results demonstrate that our techniques are superior
to the state-of-the-art with respect to the accuracy and latency.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:14:09 GMT""}]","2023-01-24"
"2301.09523","G. Ambrosio","G. Ambrosio (1), K. Amm (2), M. Anerella (2), G. Apollinari (1), G.
  Arnau Izquierdo (5), M. Baldini (1), A. Ballarino (5), C. Barth (5), A. Ben
  Yahia (2), J. Blowers (1), P. Borges De Sousa (5), R. Bossert (1), B. Bulat
  (5), R. Carcagno (1), D. W. Cheng (3), G. Chlachidze (1), L. Cooley (4), M.
  Crouvizier (5), A. Devred (5), J. DiMarco (1), S. Feher (1), P. Ferracin (3),
  J. Ferradas Troitino (5), L. Garcia Fajardo (3), S. Gourlay, H. M. Hocker
  (2), S. Izquierdo Bermudez (5), P. Joshi (2), S. Krave (1), E. M. Lee (3), J.
  Levitan (4), V. Lombardo (1), J. Lu (4), M. Marchevsky (3), V. Marinozzi (1),
  A. Moros (5), J. Muratore (2), M. Naus (3), F. Nobrega (1), T. Page (1), I.
  Pong (3), J.C. Perez (5), S. Prestemon (3), E. Ravaioli (5), K. L. Ray (3),
  G. Sabbi (3), J. Schmalzle (2), J. Seyl (1), S. Sgobba (5), S. Stoynev (1),
  T. Strauss (1), E. Todesco (5), D. Turrioni (1), G. Vallone (3), R. Van
  Weelderen (5), P. Wanderer (2), X. Wang (3), M. Yu (1) ((1) Fermilab, (2)
  Brookhaven National Laboratory, (3) LBNL, Berkeley, (4) National High
  Magnetic Laboratory, (5) CERN)","Challenges and Lessons Learned from fabrication, testing and analysis of
  eight MQXFA Low Beta Quadrupole magnets for HL-LHC",,,"10.1109/TASC.2023.3261842","FERMILAB-PUB-22-855-TD","physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  By the end of October 2022, the US HL-LHC Accelerator Upgrade Project (AUP)
had completed fabrication of ten MQXFA magnets and tested eight of them. The
MQXFA magnets are the low beta quadrupole magnets to be used in the Q1 and Q3
Inner Triplet elements of the High Luminosity LHC. This AUP effort is shared by
BNL, Fermilab, and LBNL, with strand verification tests at NHMFL. An important
step of the AUP QA plan is the testing of MQXFA magnets in a vertical cryostat
at BNL. The acceptance criteria that could be tested at BNL were all met by the
first four production magnets (MQXFA03-MQXFA06). Subsequently, two magnets
(MQXFA07 and MQXFA08) did not meet some criteria and were disassembled. Lessons
learned during the disassembly of MQXFA07 caused a revision to the assembly
specifications that were used for MQXFA10 and subsequent magnets. In this
paper, we present a summary of: 1) the fabrication and test data of all the
MQXFA magnets; 2) the analysis of MQXFA07/A08 test results with
characterization of the limiting mechanism; 3) the outcome of the
investigation, including the lessons learned during MQXFA07 disassembly; and 4)
the finite element analysis correlating observations with test performance.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:14:52 GMT""}]","2023-05-03"
"2301.09524","Tome Eftimov","Ana Nikolikj, Carola Doerr, Tome Eftimov","RF+clust for Leave-One-Problem-Out Performance Prediction","To appear at EvoApps 2023",,,,"cs.NE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Per-instance automated algorithm configuration and selection are gaining
significant moments in evolutionary computation in recent years. Two crucial,
sometimes implicit, ingredients for these automated machine learning (AutoML)
methods are 1) feature-based representations of the problem instances and 2)
performance prediction methods that take the features as input to estimate how
well a specific algorithm instance will perform on a given problem instance.
Non-surprisingly, common machine learning models fail to make predictions for
instances whose feature-based representation is underrepresented or not covered
in the training data, resulting in poor generalization ability of the models
for problems not seen during training.In this work, we study
leave-one-problem-out (LOPO) performance prediction. We analyze whether
standard random forest (RF) model predictions can be improved by calibrating
them with a weighted average of performance values obtained by the algorithm on
problem instances that are sufficiently close to the problem for which a
performance prediction is sought, measured by cosine similarity in feature
space. While our RF+clust approach obtains more accurate performance prediction
for several problems, its predictive power crucially depends on the chosen
similarity threshold as well as on the feature portfolio for which the cosine
similarity is measured, thereby opening a new angle for feature selection in a
zero-shot learning setting, as LOPO is termed in machine learning.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:14:59 GMT""},{""version"":""v2"",""created"":""Tue, 24 Jan 2023 09:38:54 GMT""}]","2023-01-25"
"2301.09525","Nima Hatami","Nima Hatami","DeepFEL: Deep Fastfood Ensemble Learning for Histopathology Image
  Analysis","arXiv admin note: substantial text overlap with arXiv:2104.00669",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Computational pathology tasks have some unique characterises such as
multi-gigapixel images, tedious and frequently uncertain annotations, and
unavailability of large number of cases [13]. To address some of these issues,
we present Deep Fastfood Ensembles - a simple, fast and yet effective method
for combining deep features pooled from popular CNN models pre-trained on
totally different source domains (e.g., natural image objects) and projected
onto diverse dimensions using random projections, the so-called Fastfood [11].
The final ensemble output is obtained by a consensus of simple individual
classifiers, each of which is trained on a different collection of random basis
vectors. This offers extremely fast and yet effective solution, especially when
training times and domain labels are of the essence. We demonstrate the
effectiveness of the proposed deep fastfood ensemble learning as compared to
the state-of-the-art methods for three different tasks in histopathology image
analysis.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:16:24 GMT""}]","2023-01-24"
"2301.09526","Krystian Kazaniecki","Krystian Kazaniecki and Micha{\l} Wojciechowski","On the analytic version of the Mitiagin-DeLeeuw-Mirkhil non-inequality
  on bi-disc",,,,,"math.FA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the method of Rudin-Shapiro polynomials we prove the analytic version
of the Mitiagin-DeLeeuw-Mirkhil non-inequality for complex partial differential
operators with constant coefficients on bi-disc.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:17:34 GMT""}]","2023-01-24"
"2301.09527","Chandrika Sadanand","Chandrika Sadanand","Heegaard splittings and virtually special square complexes","41 pages, 26 figures",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  We give a new characterization of irreducibility of Heegaard splittings for
most 3-manifolds: a Heegaard splitting is irreducible if and only if it has an
augmented Heegaard diagram that is a surface. A Heegaard splitting is a
decomposition of a closed orientable $3$-manifold into two isomorphic handle
bodies that have a shared boundary surface. Usually, a number of curves on the
shared boundary surface, called a Heegaard diagram, are used to describe a
Heegaard splitting. We define a more complete object, the augmented Heegaard
diagram, by building on a method used by Stallings to encode the information of
a Heegaard splitting.
  Augmented Heegaard diagrams have several desirable properties: each 2-cell is
a square, they have non-positive combinatorial curvature and they are virtually
special. Restricting to manifolds that do not have $S^1 \times S^2$ as a
connect summand, augmented Heegaard diagrams lend themselves well to
understanding the decomposition of a $3$-manifold via connect sum, leading to
the characterization of irreducibility above. Along the way to proving this
result, we find combinatorial methods to simplify Stallings's description of
Heegaard splittings and find a connection to Guirardel's notion of a core.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:20:22 GMT""}]","2023-01-24"
"2301.09528","Asim Ghosh Mr","Asim Ghosh and Bikas K. Chakrabarti","Scaling and Kinetic Exchange Like Behavior of Hirsch Index and Total
  Citation Distributions: Scopus-CiteScore Data Analysis","8 pages, 6 figures",,,,"physics.soc-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We analyse the data distributions $f(h)$, $f(N_c$) and $f(N_p)$ of the Hirsch
index $(h)$, total citations ($N_c$) and total number of papers ($N_p$) of the
top scoring 120,000 authors (scientists) from the Stanford cite-score (2022)
list and their corresponding $h$ ($3 \le h \le 284$), $N_c (1009 \le Nc \le
428620$) and $N_p$ ($3\le N_p \le 3791$) statistics from the Scopus data,
dividing the data into six equal Groups, each containing 20,000 authors or
scientists. We find, in each Group, $f(h)$, $f(N_c)$ and $f(N_p)$ fit well with
the kinetic exchange (model with fixed ``wealth saving propensity"") wealth
distribution: For example like Gamma function distributions $f(h) \sim
h^{\gamma_h} exp (-h/T_h)$, having similar relations between the fitting noise
level or temperature level ($T_h$) and average value of $h$, where the power
$\gamma_h$ is determined by the ``citation saving propensity"" in each group.
The observation that $h = D_c N_c^{\alpha_c} = D_p N_p^{\alpha_p}$, with
$\alpha_c = 1/2 = \alpha_p$, suggesting the average coordination (Dunbar-like)
number of the citation network, given by the average citations per paper (in
each group) equal to $N_c/N_p = (D_p/D_c)^2$ ranges from 58 to 29.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:25:53 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 15:58:16 GMT""}]","2023-01-31"
"2301.09529","Helmut L\""anger","Ivan Chajda, Davide Fazio, Helmut L\""anger, Antonio Ledda and Jan
  Paseka","Implication in sharply paraorthomodular and relatively paraorthomodular
  posets",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  In this paper we show that several classes of partially ordered structures
having paraorthomodular reducts, or whose sections may be regarded as
paraorthomodular posets, admit a quite natural notion of implication, that
admits a suitable notion of adjointness. Within this framework, we propose a
smooth generalization of celebrated Greechie's theorems on amalgams of finite
Boolean algebras to the realm of Kleene lattices.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:27:11 GMT""}]","2023-01-24"
"2301.09530","Katherine Tung","Katherine Tung","A bijection between evil-avoiding and rectangular permutations","19 pages, 2 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evil-avoiding permutations, introduced by Kim and Williams in 2022, arise in
the study of the inhomogeneous totally asymmetric simple exclusion process.
Rectangular permutations, introduced by Chiriv\`i, Fang, and Fourier in 2021,
arise in the study of Schubert varieties and Demazure modules. Taking a
suggestion of Kim and Williams, we supply an explicit bijection between
evil-avoiding and rectangular permutations in $S_n$ that preserves the number
of recoils. We encode these classes of permutations as regular languages and
construct a length-preserving bijection between words in these regular
languages. We extend the bijection to another Wilf-equivalent class of
permutations, namely the $1$-almost-increasing permutations, and exhibit a
bijection between rectangular permutations and walks of length $2n-2$ in a path
of seven vertices starting and ending at the middle vertex.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:30:22 GMT""}]","2023-01-24"
"2301.09531","Daniele Di Pompeo","Vittorio Cortellessa, Daniele Di Pompeo, Vincenzo Stoico, Michele
  Tucci","Many-Objective Optimization of Non-Functional Attributes based on
  Refactoring of Software Models","Accepted for publication in Information and Software Technologies.
  arXiv admin note: substantial text overlap with arXiv:2107.06127",,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Software quality estimation is a challenging and time-consuming activity, and
models are crucial to face the complexity of such activity on modern software
applications. In this context, software refactoring is a crucial activity
within development life-cycles where requirements and functionalities rapidly
evolve. One main challenge is that the improvement of distinctive quality
attributes may require contrasting refactoring actions on software, as for
trade-off between performance and reliability (or other non-functional
attributes). In such cases, multi-objective optimization can provide the
designer with a wider view on these trade-offs and, consequently, can lead to
identify suitable refactoring actions that take into account independent or
even competing objectives. In this paper, we present an approach that exploits
NSGA-II as the genetic algorithm to search optimal Pareto frontiers for
software refactoring while considering many objectives. We consider performance
and reliability variations of a model alternative with respect to an initial
model, the amount of performance antipatterns detected on the model
alternative, and the architectural distance, which quantifies the effort to
obtain a model alternative from the initial one. We applied our approach on two
case studies: a Train Ticket Booking Service, and CoCoME. We observed that our
approach is able to improve performance (by up to 42\%) while preserving or
even improving the reliability (by up to 32\%) of generated model alternatives.
We also observed that there exists an order of preference of refactoring
actions among model alternatives. We can state that performance antipatterns
confirmed their ability to improve performance of a subject model in the
context of many-objective optimization. In addition, the metric that we adopted
for the architectural distance seems to be suitable for estimating the
refactoring effort.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:32:55 GMT""}]","2023-01-24"
"2301.09532","Toni Annala","Toni Annala, Hermanni Rajam\""aki, Mikko M\""ott\""onen","Bordism invariants of colored links and topologically protected
  tricolorings","22 pages, 9 figures. Comments welcome!",,,,"math.GT cond-mat.quant-gas math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct invariants of colored links using equivariant bordism groups of
Conner and Floyd. We employ this bordism invariant to find the first examples
of topological vortex knots, the knot structure of which is protected from
decaying via topologically allowed local surgeries, i.e., by reconnections and
strand crossings permitted by the topology of the vortex-supporting medium.
Moreover, we show that, up to the aforementioned local surgeries, each
tricolored link either decays into unlinked simple loops, or can be transformed
into either a left-handed or a right-handed tricolored trefoil knot.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:33:40 GMT""}]","2023-01-24"
"2301.09533","Milo Roucairol","Milo Roucairol and Tristan Cazenave","Solving the HP model with Nested Monte Carlo Search","Accepted to AAAI's workshop AI2ASE 2023: 2nd Annual AAAI Workshop on
  AI to Accelerate Science and Engineering. 6 pages, 1 for references",,,,"cs.AI cs.CE","http://creativecommons.org/licenses/by/4.0/","  In this paper we present a new Monte Carlo Search (MCS) algorithm for finding
the ground state energy of proteins in the HP-model. We also compare it briefly
to other MCS algorithms not usually used on the HP-model and provide an
overview of the algorithms used on HP-model. The algorithm presented in this
paper does not beat state of the art algorithms, see PERM (Hsu and Grassberger
2011), REMC (Thachuk, Shmygelska, and Hoos 2007) or WLRE (W\""ust and Landau
2012) for better results.
  Hsu, H.-P.; and Grassberger, P. 2011. A review of Monte Carlo simulations of
polymers with PERM. Journal of Statistical Physics, 144 (3): 597 to 637.
  Thachuk, C.; Shmygelska, A.; and Hoos, H. H. 2007. A replica exchange Monte
Carlo algorithm for protein folding in the HP model. BMC Bioinformatics, 8(1):
342.
  W\""ust, T.; and Landau, D. P. 2012. Optimized Wang-Landau sampling of lattice
polymers: Ground state search and folding thermodynamics of HP model proteins.
The Journal of Chemical Physics, 137(6): 064903.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:35:51 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 15:19:27 GMT""}]","2023-01-26"
"2301.09534","Philip Keicher","Philip Keicher","Machine Learning in Top Physics in the ATLAS and CMS Collaborations","Talk at the 15th International Workshop on Top Quark Physics, Durham,
  UK, 4-9 September 2022",,,"CR-2023/006","hep-ex","http://creativecommons.org/licenses/by/4.0/","  Machine learning is essential in many aspects of top-quark related physics in
the ATLAS and CMS Collaborations. This work aims to give a brief overview over
current applications in the two collaborations as well as on-going studies for
future applications. Copyright 2023 CERN for the benefit of the ATLAS and CMS
Collaborations. Reproduction of this article or parts of it is allowed as
specified in the CC-BY-4.0 license
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:37:19 GMT""}]","2023-01-24"
"2301.09535","Andreas Sturm","Andreas Sturm","Theory and Implementation of the Quantum Approximate Optimization
  Algorithm: A Comprehensible Introduction and Case Study Using Qiskit and IBM
  Quantum Computers",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present tutorial aims to provide a comprehensible and easily accessible
introduction into the theory and implementation of the famous Quantum
Approximate Optimization Algorithm (QAOA). We lay our focus on practical
aspects and step-by-step guide through the realization of a proof of concept
quantum application based on a real-world use case. In every step we first
explain the underlying theory and subsequently provide the implementation using
IBM's Qiskit. In this way we provide a thorough understanding of the
mathematical modelling and the (quantum) algorithms as well as the equally
important knowledge how to properly write the code implementing those
theoretical concepts. As another central aspect of this tutorial we provide
extensive experiments on the 27 qubits state-of-the-art quantum computer
ibmq_ehningen. From the discussion of these experiments we gain an overview on
the current status of quantum computers and deduce which problem sizes can
meaningfully be executed on today's hardware.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:38:06 GMT""}]","2023-01-24"
"2301.09536","Harleen Dahiya Dr.","Shubham Sharma and Harleen Dahiya","Twist-4 T-even proton TMDs in the light-front quark-diquark model","Accepted in International Journal of Modern Physics A","Int. Jol. of Mod. Phys. A, Vol. 37, 2250205, (2022)","10.1142/S0217751X22502050",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have dealt with the twist-4 T-even transverse momentum-dependent parton
distributions (TMDs) for the case of proton in the light-front quark-diquark
model (LFQDM). By decoding the unintegrated quark-quark correlator for the
semi-inclusive deep inelastic scattering (SIDIS), we have specifically obtained
the overlap form for the unpolarized \bigg($f_{3}^{\nu}(x, {\bf
p_\perp^2})$\bigg), longitudinally polarized \bigg($ g_{3L}^{\nu}(x, {\bf
p_\perp^2}),~h_{3L}^{\perp\nu}(x, {\bf p_\perp^2})$\bigg) and transversely
polarized \bigg( ${g}^{\nu }_{3T}(x, {\bf p_\perp^2}),~{h}^{\nu }_{3T}(x, {\bf
p_\perp^2})$ and ${h}^{\nu\perp}_{3T}(x, {\bf p_\perp^2})$\bigg) proton TMDs.
We have provided the explicit expressions for both the cases of the diquark
being a scalar or a vector. Average transverse momenta and the average square
transverse momenta for the TMDs have been calculated and the results have been
tabulated with corresponding leading twist TMDs. In addition, the value of
average transverse momentum and average square transverse momentum for TMD
${f}^{\nu }_3(x, {\bf p_\perp^2})$ has been compared with the available
light-front constituent quark model (LFCQM) results. From TMDs, we have also
obtained and discussed the transverse momentum-dependent parton distribution
functions (TMDPDFs). The model relations of the twist-4 T-even TMDs with the
available leading twist T-even TMDs have also been obtained.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:41:21 GMT""}]","2023-02-22"
"2301.09537","G. Ambrosio","J. Ferradas Troitino (1), G. Ambrosio (2), N. Bourcey (1), D. Cheng
  (3), A. Devred (1), H. Felice (4), P. Ferracin (3), M. Guinchard (1), S.
  Izquierdo Bermudez (1), K. Kandemir (1), N. Lusa (1), A. Milanese (1), S.
  Mugnier (1), J.C. Perez (1), E. Todesco (1), S. Triquet (1), G. Vallone (3)
  ((1) CERN, (2) Fermilab, (3) LBNL, Berkeley, (4) IRFU, Saclay)","Optimizing the use of pressurized bladders for the assembly of HL-LHC
  MQXFB magnets",,,"10.1088/1361-6668/acc366","FERMILAB-PUB-22-911-TD","physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The use of pressurized bladders for stress control of superconducting magnets
was firstly proposed at Lawrence Berkeley National Laboratory (LBNL) in the
early 2000s. Since then, the so-called bladders and keys procedure has become
one of the reference techniques for the assembly of high-field accelerator
magnets and demonstrators. Exploiting the advantages of this method is today of
critical importance for Nb3Sn-based accelerator magnets, whose production
requires the preservation of tight stress targets in the superconducting coils
to limit the effects of the strain sensitivity and brittleness of the
conductor. The present manuscript reports on the results of an experimental
campaign focused on the optimization of the bladders and keys assembly process
in the MQXFB quadrupoles. These 7.2 m long magnets shall be among the first
Nb3Sn cryomagnets to be installed in a particle accelerator as a part of the
High Luminosity upgrade of the LHC. One of the main practical implications of
the bladders technique, especially important when applied to long magnets like
MQXFB, is that to insert the loading keys, the opening of a certain clearance
in the support structure is required. The procedure used so far for MQXF
magnets involved an overstress in the coils during bladder inflation. The work
presented here shows that such an overshoot can be eliminated thanks to
additional bladders properly positioned in the structure. This optimized method
was validated in a short model magnet and in a full-length mechanical model,
becoming the new baseline for the series production at CERN. Furthermore, the
results are supported by numerical predictions using Finite Element models.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:46:11 GMT""}]","2023-05-03"
"2301.09538","Barbara J. Anthony-Twarog","Bruce A. Twarog (1), Barbara J. Anthony-Twarog (1) and Constantine P.
  Deliyannis (2) ((1) University of Kansas, (2) Indiana University)","A uvbyCaHbeta CCD Analysis of the Open Cluster Standard, M67,and its
  Relation to NGC 752","36 pages, 8 figures. Accepted for Astronomical Journal",,"10.3847/1538-3881/acb0ce",,"astro-ph.SR astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Precision CCD uvbyCaHbeta photometry is presented of the old cluster, M67,
covering one square degree with typical internal precision at the 0.005-0.020
mag level to V~17. The photometry is calibrated using standards over a wide
range in luminosity and temperature from NGC 752 and zeroed to the standard
system via published photoelectric observations. Relative to NGC 752,
differential offsets in reddening and metallicity are derived using astrometric
members, supplemented by radial-velocity information. From single-star members,
offsets in the sense (M67 - NGC 752) are Delta E(b-y) = -0.005 +/-0.001 (sem)
mag from 327 F/G dwarfs and Delta [Fe/H] = 0.062 +/- 0.006 (sem) dex from the
combined m1 and hk indices of 249 F dwarfs, leading to E(b-y) = 0.021 +/- 0.004
(sem), and [Fe/H] = +0.030 +/- 0.016 (sem) for M67, assuming [Fe/H]{Hyades} =
+0.12. With probable binaries eliminated using c1,(b-y) indices, 83 members
with relative parallax errors < 0.02 generate (m-M)_0 = 8.220 +/- 0.005 (sem)
for NGC 752 and an isochronal age of 1.45 +/- 0.05 Gyr. Using the same parallax
restriction for 312 stars, M67 has (m-M) = 9.77 +/- 0.02 (sem), leading to an
age tied solely to the luminosity of the subgiant branch of 3.70 +/- 0.03 Gyr.
The turnoff color spread implies +/- 0.1 Gyr, but the turnoff morphology
defines a younger age/higher mass for the stars, consistent with recent binary
analysis and broad-band photometry indicating possible missing physics in the
isochrones. Anomalous stars positioned blueward of the turnoff are discussed.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:48:09 GMT""}]","2023-02-22"
"2301.09539","Julien Lam","Julien Lam, Fabio Pietrucci","A critical comparison of general-purpose collective variables for
  crystal nucleation",,,"10.1103/PhysRevE.107.L012601",,"physics.comp-ph cond-mat.stat-mech physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The nucleation of crystals is a prominent phenomenon in science and
technology that still lacks a full atomic-scale understanding. Much work has
been devoted to identifying order parameters able to track the process, from
the inception of early nuclei to their maturing to critical size until growth
of an extended crystal. We critically assess and compare two powerful
distance-based collective variables, an effective entropy derived from liquid
state theory and the path variable based on permutation invariant vectors using
the Kob-Andersen binary mixture and a combination of enhanced-sampling
techniques. Our findings reveal a comparable ability to drive nucleation when a
bias potential is applied, and comparable free-energy barriers and structural
features. Yet, we also found an imperfect correlation with the committor
probability on the barrier top which was bypassed by changing the order
parameter definition.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:48:30 GMT""}]","2023-02-08"
"2301.09540","Sibel \""Ozcan","S. \""Ozcan, B. Biel","Sc2CX (X=N2, ON, O2) MXenes as a promising anode material: A
  first-principles study",,,"10.1063/5.0131621",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  MXenes' tunable properties make them excellent candidates for many
applications in future nanoelectronics. In this work, we explore the
suitability of Sc$_2$CX (X=N$_2$, ON, O$_2$) MXenes to act as the active anode
materials in Na-ion based batteries (NIBs) by means of \textsl{ab initio}
simulations. After analyzing the structural and elastic properties of all the
possible models to evaluate the energetically favorable N and O
functionalization sites, our calculations show that both Sc$_2$CON and
Sc$_2$CN$_2$ present a clear metallic character, making them potential
candidates as anode materials. The investigation of the most relevant features
for anode performance, such as the adsorption and diffusion of Na atoms, the
intrinsic capacity, the open circuit voltage, and the storage capacity show
that both systems are serious alternatives to the most common 2D materials
currently employed in alkali metal batteries. In particular, Sc$_2$CN$_2$
presents a better diffusion behavior thanks to the absence of Na clustering on
its surface, with optimal diffusion barriers comparable to other 2D materials
such as MoN$_2$, while the values of diffusion barriers for Sc$_2$CON are at
least three times smaller than those found for other anode candidates.
Similarly, while the capacity of Sc$_2$CON is close to the one reported for 2D
Sc$_2$C, Sc$_2$CN$_2$ possesses a power density more than twice higher than the
ones of 2D materials such as Sc$_2$C, graphite, and MoS$_2$. Our results thus
confirm the urge for further experimental exploration of the MXene Sc$_2$CX
(X=N$_2$, ON, O$_2$) family as anode material in NIBs.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:53:35 GMT""}]","2023-01-24"
"2301.09541","Paul Monderkamp","Paul A. Monderkamp, Rika S. Windisch, Ren\'e Wittmann, Hartmut L\""owen","Network topology of interlocked chiral particles","11 pages, 11 figures",,"10.1063/5.0143417",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Self-assembly of chiral particles with an L-shape is explored by Monte-Carlo
computer simulations in two spatial dimensions. For sufficiently high packing
densities in confinement, a carpet-like texture emerges due to the interlocking
of L-shaped particles, resembling a distorted smectic liquid crystalline layer
pattern. From the positions of either of the two axes of the particles, two
different types of layers can be extracted, which form distinct but
complementary entangled networks. These coarse-grained network structures are
then analyzed from a topological point of view. We propose a global charge
conservation law by using an analogy to uniaxial smectics and show that the
individual network topology can be steered by both confinement and particle
geometry. Our topological analysis provides a general classification framework
for applications to other intertwined dual networks.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:53:56 GMT""},{""version"":""v2"",""created"":""Sat, 1 Apr 2023 10:07:03 GMT""}]","2023-05-10"
"2301.09542","Juan Tapia Dr.","Sebastian Gonzalez, Juan Tapia","Improving Presentation Attack Detection for ID Cards on Remote
  Verification Systems",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, an updated two-stage, end-to-end Presentation Attack Detection
method for remote biometric verification systems of ID cards, based on
MobileNetV2, is presented. Several presentation attack species such as printed,
display, composite (based on cropped and spliced areas), plastic (PVC), and
synthetic ID card images using different capture sources are used. This
proposal was developed using a database consisting of 190.000 real case Chilean
ID card images with the support of a third-party company. Also, a new framework
called PyPAD, used to estimate multi-class metrics compliant with the ISO/IEC
30107-3 standard was developed, and will be made available for research
purposes. Our method is trained on two convolutional neural networks
separately, reaching BPCER\textsubscript{100} scores on ID cards attacks of
1.69\% and 2.36\% respectively. The two-stage method using both models together
can reach a BPCER\textsubscript{100} score of 0.92\%.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:59:26 GMT""}]","2023-01-24"
"2301.09543","Dmitriy Kunisky","Dmitriy Kunisky","Generic MANOVA limit theorems for products of projections","49 pages, 1 figure",,,,"math.PR cs.IT math.CO math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the convergence of the empirical spectral distribution of
$\mathbf{A} \mathbf{B} \mathbf{A}$ for $N \times N$ orthogonal projection
matrices $\mathbf{A}$ and $\mathbf{B}$, where
$\frac{1}{N}\mathrm{Tr}(\mathbf{A})$ and $\frac{1}{N}\mathrm{Tr}(\mathbf{B})$
converge as $N \to \infty$, to Wachter's MANOVA law. Using free probability, we
show mild sufficient conditions for convergence in moments and in probability,
and use this to prove a conjecture of Haikin, Zamir, and Gavish (2017) on
random subsets of unit-norm tight frames. This result generalizes previous ones
of Farrell (2011) and Magsino, Mixon, and Parshall (2021). We also derive an
explicit recursion for the difference between the empirical moments
$\frac{1}{N}\mathrm{Tr}((\mathbf{A} \mathbf{B} \mathbf{A})^k)$ and the limiting
MANOVA moments, and use this to prove a sufficient condition for convergence in
probability of the largest eigenvalue of $\mathbf{A} \mathbf{B} \mathbf{A}$ to
the right edge of the support of the limiting law in the special case where
that law belongs to the Kesten-McKay family. As an application, we give a new
proof of convergence in probability of the largest eigenvalue when $\mathbf{B}$
is unitarily invariant; equivalently, this determines the limiting operator
norm of a rectangular submatrix of size $\frac{1}{2}N \times \alpha N$ of a
Haar-distributed $N \times N$ unitary matrix for any $\alpha \in (0, 1)$.
Unlike previous proofs, we use only moment calculations and non-asymptotic
bounds on the unitary Weingarten function, which we believe should pave the way
to analyzing the largest eigenvalue for products of random projections having
other distributions.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:59:35 GMT""}]","2023-01-24"
"2301.09544","Wenhao Ding","Wenhao Ding, Nathalie Majcherczyk, Mohit Deshpande, Xuewei Qi, Ding
  Zhao, Rajasimman Madhivanan, Arnie Sen","Learning to View: Decision Transformers for Active Object Detection","Accepted to ICRA 2023",,,,"cs.RO cs.CV","http://creativecommons.org/licenses/by/4.0/","  Active perception describes a broad class of techniques that couple planning
and perception systems to move the robot in a way to give the robot more
information about the environment. In most robotic systems, perception is
typically independent of motion planning. For example, traditional object
detection is passive: it operates only on the images it receives. However, we
have a chance to improve the results if we allow planning to consume detection
signals and move the robot to collect views that maximize the quality of the
results. In this paper, we use reinforcement learning (RL) methods to control
the robot in order to obtain images that maximize the detection quality.
Specifically, we propose using a Decision Transformer with online fine-tuning,
which first optimizes the policy with a pre-collected expert dataset and then
improves the learned policy by exploring better solutions in the environment.
We evaluate the performance of proposed method on an interactive dataset
collected from an indoor scenario simulator. Experimental results demonstrate
that our method outperforms all baselines, including expert policy and pure
offline RL methods. We also provide exhaustive analyses of the reward
distribution and observation space.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:00:48 GMT""}]","2023-01-24"
"2301.09545","Jesse Josua Benjamin","Jesse Josua Benjamin, Heidi Biggs, Arne Berger, Julija Rukanskait\.e,
  Michael Heidt, Nick Merrill, James Pierce, Joseph Lindley","The Entoptic Field Camera as Metaphor-Driven Research-through-Design
  with AI Technologies","To be published in Proceedings of the 2023 CHI Conference on Human
  Factors in Computing Systems (CHI '23), April 23--28, 2023, Hamburg, Germany",,"10.1145/3544548.3581175",,"cs.HC cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Artificial intelligence (AI) technologies are widely deployed in smartphone
photography; and prompt-based image synthesis models have rapidly become
commonplace. In this paper, we describe a Research-through-Design (RtD) project
which explores this shift in the means and modes of image production via the
creation and use of the Entoptic Field Camera. Entoptic phenomena usually refer
to perceptions of floaters or bright blue dots stemming from the physiological
interplay of the eye and brain. We use the term entoptic as a metaphor to
investigate how the material interplay of data and models in AI technologies
shapes human experiences of reality. Through our case study using first-person
design and a field study, we offer implications for critical, reflective,
more-than-human and ludic design to engage AI technologies; the
conceptualisation of an RtD research space which contributes to AI literacy
discourses; and outline a research trajectory concerning materiality and design
affordances of AI technologies.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:03:54 GMT""}]","2023-01-24"
"2301.09546","Piotr Nowakowski","Piotr Nowakowski","Characterization of the algebraic difference of special affine Cantor
  sets","This paper was previously a part of the submission arXiv:2102.11194v1",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate some self-similar Cantor sets $C(l,r,p)$, which we call
S-Cantor sets, generated by numbers $l,r,p \in \mathbb{N}$, $l+r<p$. We give a
full characterization of the set $C(l_1,r_1,p)-C(l_2,r_2,p)$ which can take one
of the form: the interval $[-1,1]$, a Cantor set, an L-Cantorval, an
R-Cantorval or an M-Cantorval. As corollaries we give examples of Cantor sets
and Cantorvals, which can be easily described using some positional numeral
systems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:03:56 GMT""}]","2023-01-24"
"2301.09547","Richard M. H\""ofer","Matthieu Hillairet, Richard M. H\""ofer","Hindered Settling of Well-Separated Particle Suspensions","All comments welcome!",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider $N$ identical inertialess rigid spherical particles in a Stokes
flow in a domain $\Omega \subset \mathbb R^3$. We study the average
sedimentation velocity of the particles when an identical force acts on each
particle. If the particles are homogeneously distributed in directions
orthogonal to this force, then they hinder each other leading to a mean
sedimentation velocity which is smaller than the sedimentation velocity of a
single particle in an infinite fluid. Under suitable convergence assumptions of
the particle density and a strong separation assumption, we identify the order
of this hindering as well as effects of small scale inhomogeneities and
boundary effects. For certain configurations we explicitly compute the leading
order corrections.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:05:12 GMT""}]","2023-01-24"
"2301.09548","William Sulis","William Sulis","Collective Intelligence and Neurodynamics: Functional Homologies",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-sa/4.0/","  A deep understanding of the dynamics of the human nervous system requires the
simultaneous study of multiple spatiotemporal scales from the level of
neurotransmitters up to the level of human cultures. This is likely impossible
for technical and ethical reasons. Piecemeal analysis provides some
understanding of the dynamics at single levels, but this does not illuminate
the interactions between levels which are, at the very least, of great
importance clinically. It would be useful to have an accessible biological
system which could serve as a proxy for the nervous system and from which
useful insights might be obtained. Functional homologies between the nervous
system and collective intelligence systems, in particular social insect
colonies, are described. It is proposed that social insects colonies could
serve as functional proxies for nervous systems. Thus a multiscale study of
social insect colonies may provide insights into the dynamics of nervous
systems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:06:06 GMT""}]","2023-01-24"
"2301.09549","Jan R\""oder","Jan R\""oder, Alejandro Cruz-Osorio, Christian M. Fromm, Yosuke Mizuno,
  Ziri Younsi, Luciano Rezzolla","Probing spacetime and accretion model for the Galactic Center:
  Comparison of Kerr and dilaton black hole shadows",,"A&A 671, A143 (2023)","10.1051/0004-6361/202244866",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the vicinity of black holes, the influence of strong gravity, plasma
physics, and emission processes govern the behavior of the system. Since
observations such as those carried out by the EHT are not yet able to
unambiguously constrain models for astrophysical and gravitational properties,
it is imperative to explore the accretion models, particle distribution
function, and description of the spacetime geometry. Our current understanding
of these properties is often based on the assumption that the spacetime is
well-described by by the Kerr solution to general relativity, combined with
basic emission and accretion models. We explore alternative models for each
property performing general relativistic magnetohydrodynamic and radiative
transfer simulations. By choosing a Kerr solution to general relativity and a
dilaton solution to Einstein-Maxwell-dilaton-axion gravity as exemplary black
hole background spacetimes, we aim to investigate the influence of accretion
and emission models on the ability to distinguish black holes in two theories
of gravity.
  We carry out three-dimensional general relativistic magnetohydrodynamics
simulations of both black holes, matched at their innermost stable circular
orbit, in two distinct accretion scenarios. Using general-relativistic
radiative transfer calculations, we model the thermal synchrotron emission and
in the next step apply a non-thermal electron distribution function, exploring
representative parameters to compare with multiwavelength observations. We
further consider Kerr and dilaton black holes matched at their unstable
circular photon orbits, as well as their event horizons.
  From multiwavelength emission and spectral index analysis, we find that
accretion model and spacetime have only a small impact on the spectra compared
to the choice of emission model.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:06:43 GMT""}]","2023-03-22"
"2301.09550","Anupam Sengupta","Anupam Sengupta","Planktonic Active Matter","29 pages, 14 figures, to be published in ""Active Matter"" (Editors:
  Giovanni Volpe, Nuno Ara\'ujo, Giorgio Volpe and Agnese Callegari)",,,,"physics.bio-ph cond-mat.soft cond-mat.stat-mech physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Planktonic active matter represents an emergent system spanning different
scales: individual, population and community; and complexity arising from
sub-cellular and cellular to collective and ecosystem scale dynamics. This
cross-scale active matter system responds to a range of abiotic (temperature,
fluid flow and light conditions) and biotic factors (nutrients, pH, secondary
metabolites) characteristic to the relevant ecosystems they are part of. Active
modulation of cell phenotypes, including morphology, motility, and
intracellular organization enable planktonic microbes to dynamically interact
with other individuals and species; and adapt - often rapidly - to the changes
in their environment. In this chapter, I discuss both traditional and
contemporary approaches to study the dynamics of this multi-scale active matter
system from a mechanistic standpoint, with specific references to their local
settings and their ability to actively tune the behaviour and physiology, and
the emergent structures and functions they elicit under natural ecological
constraints as well as due to the shifting climatic trends.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:10:49 GMT""}]","2023-01-24"
"2301.09551","Javier Casas De La Rosa","Javier Casas-de la Rosa, \'Angel Tamariz-Mascar\'ua","On spaces with star kernel Menger",,,,,"math.GN","http://creativecommons.org/licenses/by/4.0/","  Given a topological property $\mathcal{P}$, a space $X$ is called
star-$\mathcal{P}$ if for any open cover $\mathcal{U}$ of the space $X$, there
exists a set $Y\subseteq X$ with property $\mathcal{P}$ such that
$St(Y,\mathcal{U})=X$; the set $Y$ is called a star kernel of the cover
$\mathcal{U}$. In this paper, we introduce and study spaces with star kernel
Menger, that is, star Menger spaces. Some examples are given to show the
relationship with some other related properties studied previously, and the
behaviour of the star Menger property with respect to subspaces, products,
continuous images and preimages are investigated. Additionally, some comments
on the star selection theory are given. Particularly, some questions posed by
Song within this theory are addressed. Finally, several new properties are
introduced as well as some general questions on them are posed.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:14:12 GMT""}]","2023-01-24"
"2301.09552","Mansi Dhuria","Mansi Dhuria, Abinas Pradhan","Synergy Between Hubble Tension Motivated Self-Interacting Neutrino and
  KeV-Sterile Neutrino Dark Matter","v2: 13 pages, 6 figures, 1 Table; Typos fixed and references added",,,,"hep-ph astro-ph.CO hep-th","http://creativecommons.org/licenses/by/4.0/","  The discrepancy between the value of Hubble constant measured by CMB
observations and local low-redshift based observations has proposed many
solutions which require the existence of Physics beyond Standard Model (SM).
One of the interesting solutions is based on considering the strong
self-interaction between Standard Model (SM) neutrinos through an additional
scalar/vector mediator. Interestingly, the strong self-interaction between SM
neutrinos also play an important role in obtaining KeV-sterile neutrino as a
viable Dark Matter (DM) candidate through the famous Dodelson-Widrow mechanism.
In this work, we have tried to find the synergy between the parameter space of
active-sterile neutrino mixing vs mass of sterile neutrino allowed by Hubble
tension solution and the requirement of getting KeV-sterile neutrino as DM
candidate. Interestingly, we get a large amount of parameter space that is
consistent with both the requirements and also free from X-Ray constraints.
Finally, we have embedded this scenario in a consistent supersymmetric model of
particle physics. In this framework, we have shown that the value of sterile
neutrino mass, SM neutrino mass and the required mixing angle can be naturally
obtained by considering the supersymmetry breaking scale to be around O(10)
TeV. Thus, it would give an interesting testing ground for supersymmetry as
well as signatures of Warm Dark Matter (WDM).
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:14:20 GMT""},{""version"":""v2"",""created"":""Sun, 29 Jan 2023 15:10:08 GMT""}]","2023-01-31"
"2301.09553","Sandra Korte-Kerzel","W. Luo, Z. Xie, P.-L. Sun, J. S. K.-L. Gibson, S. Korte-Kerzel","Plasticity of the Nb-rich {\mu}-Co7Nb6 phase at room temperature and 600
  {\deg}C",,"Acta Materialia, Volume 246, 2023, 118720, ISSN 1359-6454","10.1016/j.actamat.2023.118720",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The {\mu}-phase is a common precipitation phase in superalloys and it exists
in a wide composition and temperature range. As such, we study the influences
of composition and temperature on its plasticity by micropillar compression
tests and transmission electron microscopy. The micropillars of the
{\mu}-Co7Nb6 phase deform plastically by basal slip at either room temperature
or 600 oC. At room temperature, the Co-49Nb and Co-52Nb micropillars show high
yield stresses and an abrupt large strain burst at the onset of yielding
regardless of orientation, whereas the Co-54Nb micropillars oriented for basal
slip yield at much lower stresses and show intermittent small strain bursts
during plastic deformation. While the Co-49Nb micropillars deform by full
dislocation slip on the basal plane at room temperature, the Co-54Nb
micropillars deform by partial dislocation slip on the basal plane. At 600 oC,
the Co-49Nb micropillars oriented for basal slip show stable and continuous
plasticity and their critical resolved shear stress decreases dramatically. The
plastic deformation of the Co-49Nb micropillars occurs via partial dislocation
slip on the basal plane at 600 oC. Based on the geometric {\gamma}-surfaces for
all potential basal slip planes, we explore where and why the glide of full and
partial dislocations on the basal plane occurs in the {\mu}-Co7Nb6 phase.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:14:46 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 12:59:02 GMT""}]","2023-02-01"
"2301.09554","Rahul Parhi","Rahul Parhi and Robert D. Nowak","Deep Learning Meets Sparse Regularization: A Signal Processing
  Perspective",,,,,"stat.ML cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning has been wildly successful in practice and most
state-of-the-art machine learning methods are based on neural networks.
Lacking, however, is a rigorous mathematical theory that adequately explains
the amazing performance of deep neural networks. In this article, we present a
relatively new mathematical framework that provides the beginning of a deeper
understanding of deep learning. This framework precisely characterizes the
functional properties of neural networks that are trained to fit to data. The
key mathematical tools which support this framework include transform-domain
sparse regularization, the Radon transform of computed tomography, and
approximation theory, which are all techniques deeply rooted in signal
processing. This framework explains the effect of weight decay regularization
in neural network training, the use of skip connections and low-rank weight
matrices in network architectures, the role of sparsity in neural networks, and
explains why neural networks can perform well in high-dimensional problems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:16:21 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 16:56:36 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jun 2023 16:42:49 GMT""}]","2023-06-09"
"2301.09555","Stephen Dolan","S. Dolan","Uncertainties in modelling neutrino interactions for oscillation
  experiments","4 pages, 2 figures. Proceedings for a talk given at NOW2022",,,,"hep-ex hep-ph","http://creativecommons.org/licenses/by/4.0/","  Accelerator-based neutrino oscillation experiments have the potential to
revolutionise our understanding of fundamental physics, offering an opportunity
to characterise charge-parity violation in the lepton section, to determine the
neutrino mass ordering and to explore the possibility of physics beyond
three-flavour neutrino mixing. However, as more data is collected the current
and next-generation of experiments will require increasingly precise control
over the systematic uncertainties within their analyses. It is well known that
some of the most challenging uncertainties to overcome stem from our uncertain
modelling of neutrino-nucleus interactions, arising because measured event
rates depend on the neutrino interaction cross section in addition to any
oscillation probability. The sources of these uncertainties are often related
to subtle details of the pertinent nuclear physics, such as those of the target
nucleus ground state, which are extremely difficult to control with sufficient
precision. Confronting such uncertainties requires both state-of-art
theoretical modelling and precise measurements of neutrino interaction event
rates at experiment's near detectors, before oscillations are likely occur.
These proceedings will briefly review the role of neutrino interaction
systematic uncertainties in current and future measurements of neutrino
oscillations.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:16:44 GMT""}]","2023-01-24"
"2301.09556","Maeve Upton","Maeve Upton, Andrew Parnell, Andrew Kemp, Erica Ashe, Gerard McCarthy
  and Niamh Cahill","A noisy-input generalised additive model for relative sea-level change
  along the Atlantic coast of North America",,,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  We propose a Bayesian, noisy-input, spatial-temporal generalised additive
model to examine regional relative sea-level (RSL) changes over time. The model
provides probabilistic estimates of component drivers of regional RSL change
via the combination of a univariate spline capturing a common regional signal
over time, random slopes and intercepts capturing site-specific (local),
long-term linear trends and a spatial-temporal spline capturing residual,
non-linear, local variations. Proxy and instrumental records of RSL and
corresponding measurement errors inform the model and a noisy-input method
accounts for proxy temporal uncertainties. Results focus on the decomposition
of RSL over the past 3000 years along the Atlantic coast of North America.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:17:15 GMT""}]","2023-01-24"
"2301.09557","Shantanu Desai","Aaseesh Rallapalli, Shantanu Desai","Bayesian inference of $W$-boson mass","8 pages, 4 figures",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  We use a Bayesian regression technique (similar to a recent analysis by
Rinaldi et al) to obtain a central estimate for the $W$-boson mass using four
different combinations of datasets compiled by the PDG including the 2022 CDF
result. We use three different priors on the unknown intrinsic scatter and also
a non-parametric hierarchical Dirichlet Process Gaussian Mixture model to
obtain a world average for $W$-boson mass. We also evaluate the statistical
significance of the discrepancy with respect to Standard model for each of the
datasets. We find that for all the cases analyzed and prior choices, the
discrepancy with respect to the Standard Model value for the $W$-mass is less
than 3$\sigma$.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:17:26 GMT""}]","2023-01-24"
"2301.09558","Andrzej Derdzinski","Andrzej Derdzinski and Ivo Terek","Rank-one ECS manifolds of dilational type","Text rearranged and slightly expanded, some references updated",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study ECS manifolds, that is, pseudo-Riemannian manifolds with parallel
Weyl tensor which are neither conformally flat nor locally symmetric. Every ECS
manifold has rank 1 or 2, the rank being the dimension of a distinguished null
parallel distribution discovered by Olszak, and a rank-one ECS manifold may be
called translational or dilational, depending on whether the holonomy group of
a natural flat connection in the Olszak distribution is finite or infinite.
Some such manifolds are in a natural sense generic, which refers to the
algebraic structure of the Weyl tensor. Known examples of compact ECS
manifolds, in every dimension greater than 4, are all of rank 1 and
translational, some of them generic, none of them locally homogeneous. As we
show, generic compact rank-one ECS manifolds must be translational or locally
homogeneous, provided that they arise as isometric quotients of a specific
class of explicitly constructed ""model"" manifolds. This result is relevant
since the clause starting with ""provided that"" may be dropped: according to a
theorem which we prove in a forthcoming paper, the models just mentioned
include the isometry types of the pseudo-Riemannian universal coverings of all
generic compact rank-one ECS manifolds.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:17:52 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 17:28:47 GMT""}]","2023-06-09"
"2301.09559","Hamed Ayoobi","Hamed Ayoobi, Nico Potyka, Francesca Toni","SpArX: Sparse Argumentative Explanations for Neural Networks",,,,,"cs.AI cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Neural networks (NNs) have various applications in AI, but explaining their
decision process remains challenging. Existing approaches often focus on
explaining how changing individual inputs affects NNs' outputs. However, an
explanation that is consistent with the input-output behaviour of an NN is not
necessarily faithful to the actual mechanics thereof. In this paper, we exploit
relationships between multi-layer perceptrons (MLPs) and quantitative
argumentation frameworks (QAFs) to create argumentative explanations for the
mechanics of MLPs. Our SpArX method first sparsifies the MLP while maintaining
as much of the original mechanics as possible. It then translates the sparse
MLP into an equivalent QAF to shed light on the underlying decision process of
the MLP, producing global and/or local explanations. We demonstrate
experimentally that SpArX can give more faithful explanations than existing
approaches, while simultaneously providing deeper insights into the actual
reasoning process of MLPs.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:20:25 GMT""}]","2023-01-24"
"2301.09560","Lei Wu","Raffaele Esposito and Yan Guo and Rossana Marra and Lei Wu","Ghost Effect from Boltzmann Theory: Expansion with Remainder","27 pages; several misprints corrected. arXiv admin note: text overlap
  with arXiv:2301.09427",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider the limit $\varepsilon\rightarrow0$ of the steady Boltzmann problem
\begin{align}
v\cdot\nabla_x\mathfrak{F}=\varepsilon^{-1}Q[\mathfrak{F},\mathfrak{F}],\quad
\mathfrak{F}\big|_{v\cdot n<0}=M_w\displaystyle\int_{v'\cdot n>0}
  \mathfrak{F}(v')|v'\cdot n|\mathrm{d}{v'}, \end{align} where $\displaystyle
M_w(x_0,v):=\frac{1}{2\pi\big(T_w(x_0)\big)^2}
\exp\bigg(-\frac{|v|^2}{2T_w(x_0)}\bigg)$ for $x_0\in\partial\Omega$ is the
wall Maxwellian in the diffuse-reflection boundary condition. In the natural
case of $|\nabla T_w|=O(1)$, for any constant $P>0$, the Hilbert expansion
leads to \begin{align}\label{expansion}
  \mathfrak{F}\approx \mu+\varepsilon\bigg\{\mu\bigg(\rho_1+u_1\cdot
v+T_1\frac{|v|^2-3T}{2}\bigg)-\mu^{\frac{1}{2}}\left(\mathscr{A}\cdot\frac{\nabla_xT}{2T^2}\right)\bigg\}
\end{align} where $\displaystyle\mu(x,v):=\frac{\rho(x)}{\big(2\pi
T(x)\big)^{\frac{3}{2}}} \exp\bigg(-\frac{|v|^2}{2T(x)}\bigg)$, and
$(\rho,u_1,T)$ is determined by a Navier-Stokes-Fourier system with ""ghost""
effect. The goal of this paper is to construct $\mathfrak{F}$ in the form of
\begin{align}\label{aa 08}
  \mathfrak{F}(x,v)=&\mu+\mu^{\frac{1}{2}}\Big(\varepsilon
f_1+\varepsilon^2f_2\Big)+\mu_w^{\frac{1}{2}}\Big(\varepsilon
f^B_1\Big)+\varepsilon^{\alpha}\mu^{\frac{1}{2}}R, \end{align} for interior
solutions $f_1$, $f_2$ and boundary layer $f^B_1$, where $\mu_w$ is $\mu$
computed for $T=T_w$, and derive equation for the remainder $R$ with some
constant $\alpha\geq1$. To prove the validity of the expansion suitable bounds
on $R$ are needed, which are provided in the companion paper
[Esposito-Guo-Rossana-Wu2022].
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:22:09 GMT""},{""version"":""v2"",""created"":""Tue, 7 Mar 2023 22:05:24 GMT""}]","2023-03-09"
"2301.09561","Leonid Positselski","Leonid Positselski","Homological full-and-faithfulness of comodule inclusion and contramodule
  forgetful functors","LaTeX 2e with xy-pic; 33 pages, 3 commutative diagrams",,,,"math.RA math.CT","http://creativecommons.org/licenses/by/4.0/","  In this paper we consider a conilpotent coalgebra $C$ over a field $k$. Let
$\Upsilon\colon\textsf{Comod-}C\longrightarrow\textsf{Mod-}C^*$ be the natural
functor of inclusion of the category of $C$-comodules into the category of
$C^*$-modules, and let $\Theta\colon C\textsf{-Contra}\longrightarrow
C^*\textsf{-Mod}$ be the natural forgetful functor. We prove that the functor
$\Upsilon$ induces a fully faithful triangulated functor on bounded (below)
derived categories if and only if the functor $\Theta$ induces a fully faithful
triangulated functor on bounded (above) derived categories, and if and only if
the $k$-vector space $\operatorname{Ext}_C^n(k,k)$ is finite-dimensional for
all $n\ge0$. We call such coalgebras ""weakly finitely Koszul"".
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:23:04 GMT""}]","2023-01-24"
"2301.09562","Gopal Bhatta","Gopal Bhatta, Staszek Zola, M. Drozdz, Daniel Reichart, Joshua
  Haislip, Vladimir Kouprianov, Katsura Matsumoto, Eda Sonbas, D. Caton,
  Urszula Pajdosz-\'Smierciak, A. Simon, J. Provencal, Dariusz G\'ora, and
  Grzegorz Stachowski","Catching profound optical flares in blazars","11 pages, 6 figures, MNRAS accepted",,"10.1093/mnras/stad280",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Flaring episodes in blazars represent one of the most violent processes
observed in extra-galactic objects. Studies of such events shed light on the
energetics of the physical processes occurring in the innermost regions of
blazars, which cannot otherwise be resolved by any current instruments. In this
work, we present some of the largest and most rapid flares captured in the
optical band in the blazars 3C 279, OJ 49, S4 0954+658, TXS 1156+295 and PG
1553+113. The source flux was observed to increase by nearly ten times within a
timescale of a few weeks. We applied several methods of time series analysis
and symmetry analysis. Moreover, we also performed searches for periodicity in
the light curves of 3C 279, OJ 49 and PG 1553+113 using the Lomb-Scargle method
and found plausible indications of quasi-periodic oscillations (QPOs). In
particular, the 33- and 22-day periods found in 3C 279, i.e. a 3:2 ratio, are
intriguing. These violent events might originate from magnetohydrodynamical
instabilities near the base of the jets, triggered by processes modulated by
the magnetic field of the accretion disc. We present a qualitative treatment as
the possible explanation for the observed large amplitude flux changes in both
the source-intrinsic and source-extrinsic scenarios.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:23:47 GMT""}]","2023-02-08"
"2301.09563","Raul Toral","Jaume Llabres, Maxi San Miguel, Raul Toral","Partisan Voter Model: Quasi-stationary properties and noise-induced
  transitions",,,,,"cond-mat.stat-mech physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  We revisit the Partisan Voter Model (PVM) reporting analytical results for
the quasi-stationary distribution, exit probabilities and fixation times.
Similarly to the Noisy Voter Model (NVM) we introduce a Noisy version of the
PVM (NPVM). We find that the finite size noise induced transition of the NVM is
modified in the NPVM so that there exists a new intermediate phase.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:27:23 GMT""}]","2023-01-24"
"2301.09564","Enrique Jord\'a","Enrique Jord\'a","On the spectrum of isomorphisms defined on the space of smooth functions
  which are flat at 0",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we study the spectrum and the Waelbroeck spectrum of the
derivative operator composed with isomorphic multiplication oper
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:28:05 GMT""}]","2023-01-24"
"2301.09571","Carole Diederichs","Mohamed-Raouf Amara, Zakaria Said, Caixia Huo, Aur\'elie Pierret,
  Christophe Voisin, Weibo Gao, Qihua Xiong, and Carole Diederichs","Spectral fingerprint of quantum confinement in single CsPbBr$_3$
  nanocrystals",,,"10.1021/acs.nanolett.3c00793",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Lead halide perovskite nanocrystals are promising materials for classical and
quantum light emission. To understand these outstanding properties, a thorough
analysis of the band-edge exciton emission is needed which is not reachable in
ensemble and room temperature studies because of broadening effects. Here, we
report on a cryogenic-temperature study of the photoluminescence of single
CsPbBr$_3$ NCs in the intermediate quantum confinement regime. We reveal the
size-dependence of the spectral features observed: the bright-triplet exciton
energy splittings, the trion and biexciton binding energies as well as the
optical phonon replica spectrum. In addition, we show that bright triplet
energy splittings are consistent with a pure exchange model and that the
variety of polarisation properties and spectra recorded can be rationalised
simply by considering the orientation of the emitting dipoles and the
populations of the emitting states.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:29:19 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 13:54:31 GMT""}]","2023-04-07"
"2301.09573","Hongjian Wang","Hongjian Wang, Aaditya Ramdas","Huber-Robust Confidence Sequences","Accepted for publication at the 26th International Conference on
  Artificial Intelligence and Statistics (AISTATS 2023)",,,,"math.ST cs.LG stat.ME stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Confidence sequences are confidence intervals that can be sequentially
tracked, and are valid at arbitrary data-dependent stopping times. This paper
presents confidence sequences for a univariate mean of an unknown distribution
with a known upper bound on the $p$-th central moment ($p$ > 1), but allowing
for (at most) $\epsilon$ fraction of arbitrary distribution corruption, as in
Huber's contamination model. We do this by designing new robust exponential
supermartingales, and show that the resulting confidence sequences attain the
optimal width achieved in the nonsequential setting. Perhaps surprisingly, the
constant margin between our sequential result and the lower bound is smaller
than even fixed-time robust confidence intervals based on the trimmed mean, for
example. Since confidence sequences are a common tool used within A/B/n testing
and bandits, these results open the door to sequential experimentation that is
robust to outliers and adversarial corruptions.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:29:26 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 04:55:07 GMT""}]","2023-02-09"
"2301.09577","Baptiste Lafoux","Baptiste Lafoux, Jeanne Moscatelli, Ramiro Godoy-Diana, Benjamin
  Thiria","Illuminance-tuned collective motion in fish",,,,,"nlin.AO physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  We experimentally investigate the role of illumination on the collective
dynamics of a large school (ca. 50 individuals) of Hemigrammus rhodostomus. The
structure of the group, defined using two order parameters, is quantified while
progressively altering the visual range of the fish through controlled cycles
of ambient light intensity. We show that, at low light levels, the individuals
within the group are unable to form a cohesive group, while at higher
illuminance the degree of alignment of the school correlates with the light
intensity. When increasing the illuminance, the school structure is
successively characterized by a polarized state followed by a highly regular
and stable rotational configuration (milling). Our study shows that vision is
necessary to achieve cohesive collective motion for free swimming fish schools,
while the short-range lateral line sensing is insufficient in this situation.
The present experiment therefore provides new insights into the interaction
mechanisms that govern the emergence and intensity of collective motion in
biological systems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:30:55 GMT""}]","2023-01-24"
"2301.09581","Armando Pezo aP","Armando Pezo, Matheus P. Lima, Marcio Costa, Adalberto Fazzio","Electronic transport properties of MoS$_2$ nanoribbons embedded on
  butadiene solvent",,,"10.1039/C9CP01590F",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Transition metal dichalcogenides (TMDCs) are promising materials for
applications in nanoelectronics and correlated fields, where their metallic
edge states play a fundamental role in the electronic transport. In this work,
we investigate the transport properties of MoS$_2$ zigzag nanoribbons under a
butadiene (C$_4$H$_6$) atmosphere, as this compound has been used to obtain
MoS$_2$ flakes by exfoliation. We use density functional theory combined with
non-equilibrium Green's function techniques, in a methodology contemplating
disorder and different coverages. Our results indicate a strong modulation of
the TMDC electronic transport properties driven by butadiene molecules anchored
at their edges, producing the suppression of currents due to a backscattering
process. Our results indicate a high sensitivity of the TMDC edge states. Thus,
the mechanisms used to reduce the dimensionality of MoS$_2$ considerably modify
its transport properties.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:34:56 GMT""}]","2023-01-24"
"2301.09582","Svea Hernandez","Svea Hernandez, Logan Jones, Linda J. Smith, Aditya Togi, Alessandra
  Aloisi, William P. Blair, Alec S. Hirschauer, Leslie K. Hunt, Bethan L.
  James, Nimisha Kumari, Matilde Mingozzi and Lise Ramambason","Dissecting the Mid-Infrared Heart of M83 with JWST","13 pages, 3 Tables, 8 Figures, Accepted for publication in ApJ",,"10.3847/1538-4357/acc837",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a first look at the MRS observations of the nucleus of the nearby
galaxy M83, taken with MIRI onboard JWST. The observations show a rich set of
emission features from the ionized gas, warm molecular gas, and dust. To begin
dissecting the complex processes in this part of the galaxy, we divide the
observations into four different regions. We find that the strength of the
emission features varies strongly from region to region, with the south-east
region displaying the weakest features tracing the dust continuum and ISM
properties. Comparison between the cold molecular gas traced by the $^{12}$CO
(1-0) transition with ALMA and the H$_2$ S(1) transition shows a similar
spatial distribution. This is in contrast to the distribution of the much
warmer H$_2$ emission from the S(7) transition found to be concentrated around
the optical nucleus. We use the rotational emission lines and model the H$_2$
excitation to estimate a total molecular gas mass accounting for the warm H$_2$
component of M($>$50 K)$_{\rm H_{2}}$ = 67.90 ($\pm 5.43$)$\times$10$^{6}$
M$_{\odot}$. We compare this value to the total gas mass inferred by probing
the cold H$_2$ gas through the $^{12}$CO (1-0) emission, M(CO)$_{\rm H_{2}}$ =
17.15$\times$10$^{6}$ M$_{\odot}$. We estimate that $\sim$75\% of the total
molecular gas mass is contained in the warm H$_2$ component. We also identify
[\ion{O}{4}] 25.89 $\mu$m and [\ion{Fe}{2}] 25.99 $\mu$m emission. We propose
that the diffuse [\ion{Fe}{2}] 25.99 $\mu$m emission might be tracing shocks
created during the interactions between the hot wind produced by the starburst
and the much cooler ISM above the galactic plane. More detailed studies are
needed to confirm such a scenario.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:35:02 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 02:51:05 GMT""}]","2023-05-24"
"2301.09583","Benoit Vicedo","Joaquin Liniado and Benoit Vicedo","Integrable degenerate $\mathcal E$-models from 4d Chern-Simons theory",,,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general construction of integrable degenerate $\mathcal
E$-models on a 2d manifold $\Sigma$ using the formalism of Costello and
Yamazaki based on 4d Chern-Simons theory on $\Sigma \times \mathbb{C}P^1$. We
begin with a physically motivated review of the mathematical results of
[arXiv:2008.01829] where a unifying 2d action was obtained from 4d Chern-Simons
theory which depends on a pair of 2d fields $h$ and $\mathcal L$ on $\Sigma$
subject to a constraint and with $\mathcal L$ depending rationally on the
complex coordinate on $\mathbb{C}P^1$. When the meromorphic 1-form $\omega$
entering the action of 4d Chern-Simons theory is required to have a double pole
at infinity, the constraint between $h$ and $\mathcal L$ was solved in
[arXiv:2011.13809] to obtain integrable non-degenerate $\mathcal E$-models. We
extend the latter approach to the most general setting of an arbitrary 1-form
$\omega$ and obtain integrable degenerate $\mathcal E$-models. To illustrate
the procedure we reproduce two well known examples of integrable degenerate
$\mathcal E$-models: the pseudo dual of the principal chiral model and the
bi-Yang-Baxter $\sigma$-model.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:35:30 GMT""}]","2023-01-24"
"2301.09584","Benjamin Finociety","Benjamin Finociety, Jean-Fran\c{c}ois Donati, Konstantin Grankin,
  J\'er\^ome Bouvier, Silvia Alencar, Fran\c{c}ois M\'enard, Tom P. Ray,
  \'Agnes K\'osp\'al, the SLS consortium","The active weak-line T Tauri star LkCa 4 observed with SPIRou and TESS","16 pages, 18 figures, accepted for publication in MNRAS",,"10.1093/mnras/stad267",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report results of a spectropolarimetric and photometric monitoring of the
weak-line T Tauri star LkCa 4 within the SPIRou Legacy Survey large programme,
based on data collected with SPIRou at the Canada-France-Hawaii Telescope and
the TESS space probe between October 2021 and January 2022. We applied
Zeeman-Doppler Imaging to our spectropolarimetric and photometric data to
recover a surface brightness distribution compatible with TESS photometry, as
well as the large-scale magnetic topology of the star. As expected from the
difference in wavelength between near-infrared and optical data, the recovered
surface brightness distribution is less contrasted than the previously
published one based on ESPaDOnS data, but still features mid-latitude dark and
bright spots. The large-scale magnetic field is consistent in shape and
strength with the one derived previously, with a poloidal component resembling
a 2.2 kG dipole and a toroidal component reaching 1.4 kG and encircling the
star at the equator. Our new data confirm that the surface differential
rotation of LkCa 4 is about 10 times weaker than that of the Sun, and
significantly different from zero. Using our brightness reconstruction and
Gaussian Process Regression, we were able to filter the radial velocity
activity jitter down to a precision of 0.45 and 0.38 km $\rm s^{-1}$ (from an
amplitude of 6.10 km $\rm s^{-1}$), respectively, yielding again no evidence
for a close-in massive planet orbiting the star.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:38:13 GMT""}]","2023-02-01"
"2301.09585","Xin Nie","Xin Nie","On circle patterns and spherical conical metrics","9 pages, 6 figures",,,,"math.DG math.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Koebe-Andreev-Thurston circle packing theorem, as well as its
generalization to circle patterns due to Bobenko and Springborn, holds for
Euclidean and hyperbolic metrics possibly with conical singularities, but fails
for spherical metrics because of the non-uniqueness coming from M\""obius
transformations. In this paper, we show that a unique existence result for
circle pattern with spherical conical metric holds if one prescribes the
geodesic total curvature of each circle instead of the cone angles.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:38:58 GMT""}]","2023-01-24"
"2301.09586","Rishab Dutta","Armin Khamoshi and Rishab Dutta and Gustavo E. Scuseria","State preparation of AGP on a quantum computer without number projection","11 pages, 6 figures, manuscript revised",,"10.1021/acs.jpca.3c00525",,"quant-ph cond-mat.str-el physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The antisymmetrized geminal power (AGP) is equivalent to the number projected
Bardeen-Cooper-Schrieffer (PBCS) wavefunction. It is also an elementary
symmetric polynomial (ESP) state. We generalize previous research on
deterministically implementing the Dicke state to a state preparation algorithm
for an ESP state, or equivalently AGP, on a quantum computer. Our method is
deterministic and has polynomial cost, and it does not rely on number symmetry
breaking and restoration. We also show that our circuit is equivalent to a
disentangled unitary paired coupled cluster operator and a layer of unitary
Jastrow operator acting on a single Slater determinant. The method presented
herein highlights the ability of disentangled unitary coupled cluster to
capture non-trivial entanglement properties that are hardly accessible with
traditional Hartree-Fock based electronic structure methods.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:39:08 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 18:23:40 GMT""}]","2023-04-28"
"2301.09587","Necdet Batir","Necdet Batir, Sezer Sorgunand Sevda Atpinar","On some Binomial Coefficient Identities with Applications","Submitted",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We present a different proof of the following identity due to Munarini, which
generalizes a curious binomial identity of Simons. \begin{align*}
\sum_{k=0}^{n}\binom{\alpha}{n-k}\binom{\beta+k}{k}x^k
&=\sum_{k=0}^{n}(-1)^{n+k}\binom{\beta-\alpha+n}{n-k}\binom{\beta+k}{k}(x+1)^k,
\end{align*} where $n$ is a non-negative integer and $\alpha$ and $\beta$ are
complex numbers, which are not negative integers. Our approach is based on a
particularly interesting combination of the Taylor theorem and the
Wilf-Zeilberger algorithm. We also generalize a combinatorial identity due to
Alzer and Kouba, and offer a new binomial sum identity. Furthermore, as
applications, we give many harmonic number sum identities. As examples, we
prove that \begin{equation*}
H_n=\frac{1}{2}\sum_{k=1}^{n}(-1)^{n+k}\binom{n}{k}\binom{n+k}{k}H_k
\end{equation*} and \begin{align*}
\sum_{k=0}^{n}\binom{n}{k}^2H_kH_{n-k}=\binom{2n}{n}
\left((H_{2n}-2H_n)^2+H_{n}^{(2)}-H_{2n}^{(2)}\right). \end{align*}
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:40:22 GMT""}]","2023-01-24"
"2301.09589","Danilo Liarte","Danilo B. Liarte, Alberto Petri and Silvio R. Salinas","Hard-needle elastomer in one spatial dimension","6 pages, 4 figures, to appear in a special issue of the Brazilian
  Journal of Physics in honor of Prof. Silvio R. Salinas","Braz. J. Phys. 53, 73 (2023)","10.1007/s13538-023-01289-7",,"cond-mat.stat-mech cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform exact Statistical Mechanics calculations for a system of elongated
objects (hard needles) that are restricted to translate along a line and rotate
within a plane, and that interact via both excluded-volume steric repulsion and
harmonic elastic forces between neighbors. This system represents a
one-dimensional model of a liquid crystal elastomer, and has a zero-tension
critical point that we describe using the transfer-matrix method. In the
absence of elastic interactions, we build on previous results by Kantor and
Kardar, and find that the nematic order parameter $Q$ decays linearly with
tension $\sigma$. In the presence of elastic interactions, the system exhibits
a standard universal scaling form, with $Q / |\sigma|$ being a function of the
rescaled elastic energy constant $k / |\sigma|^\Delta$, where $\Delta$ is a
critical exponent equal to $2$ for this model. At zero tension, simple scaling
arguments lead to the asymptotic behavior $Q \sim k^{1/\Delta}$, which does not
depend on the equilibrium distance of the springs in this model.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:42:46 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 16:04:40 GMT""}]","2023-04-11"
"2301.09590","Gianira N. Alfarano","Gianira N. Alfarano, Martino Borello, Alessandro Neri","Outer Strong Blocking Sets",,,,,"math.CO cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Strong blocking sets, introduced first in 2011 in connection with saturating
sets, have recently gained a lot of attention due to their correspondence with
minimal codes. In this paper, we dig into the geometry of the concatenation
method, introducing the concept of outer strong blocking sets and their coding
theoretical counterpart. We investigate their structure and provide bounds on
their size. As a byproduct, we improve the best-known upper bound on the
minimum size of a strong blocking set. Finally, we present a geometric
construction of small strong blocking sets, whose computational cost is
significantly smaller than the previously known ones.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:43:40 GMT""}]","2023-01-25"
"2301.09591","Arianna Favale","Arianna Favale, Adri\`a G\'omez-Valent and Marina Migliaccio","Cosmic chronometers to calibrate the ladders and measure the curvature
  of the Universe. A model-independent study","18 pages, 10 figures, 5 tables. Version accepted for publication in
  MNRAS",,"10.1093/mnras/stad1621",,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We use the state-of-the-art data on cosmic chronometers (CCH) and the
Pantheon+ compilation of supernovae of Type Ia (SNIa) to test the constancy of
the SNIa absolute magnitude, $M$, and the robustness of the cosmological
principle (CP) at $z\lesssim 2$ with a model-agnostic approach. We do so by
reconstructing $M(z)$ and the curvature parameter $\Omega_{k}(z)$ using
Gaussian Processes. Moreover, we use CCH in combination with data on baryon
acoustic oscillations (BAO) from various galaxy surveys (6dFGS, BOSS, eBOSS,
WiggleZ, DES Y3) to measure the sound horizon at the baryon-drag epoch, $r_d$,
from each BAO data point and check their consistency. Given the precision
allowed by the CCH, we find that $M(z)$, $\Omega_k(z)$ and $r_d(z)$ are fully
compatible (at $<68\%$ C.L.) with constant values. This justifies our final
analyses, in which we put constraints on these constant parameters under the
validity of the CP, the metric description of gravity and standard physics in
the vicinity of the stellar objects, but otherwise in a model-independent way.
If we exclude the SNIa contained in the host galaxies employed by SH0ES, our
results read $M=(-19.314^{+0.086}_{-0.108})$ mag, $r_d=(142.3\pm 5.3)$ Mpc and
$\Omega_k=-0.07^{+0.12}_{-0.15}$, with $H_0=(71.5\pm 3.1)$ km/s/Mpc ($68\%$
C.L.). These values are independent from the main data sets involved in the
$H_0$ tension, namely, the cosmic microwave background and the first two rungs
of the cosmic distance ladder. If, instead, we also consider the SNIa in the
host galaxies, calibrated with Cepheids, we measure
$M=(-19.252^{+0.024}_{-0.036})$ mag, $r_d=(141.9^{+5.6}_{-4.9})$ Mpc,
$\Omega_k=-0.10^{+0.12}_{-0.15}$ and $H_0=(74.0^{+0.9}_{-1.0})$ km/s/Mpc.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:45:09 GMT""},{""version"":""v2"",""created"":""Mon, 20 Mar 2023 14:29:42 GMT""},{""version"":""v3"",""created"":""Fri, 26 May 2023 13:55:10 GMT""}]","2023-06-07"
"2301.09592","Lukas Alexander Hauger","Lukas Hauger","Decay of Entropy and Information for multidimensional Kac models","34 pages",,,,"math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We study the approach to equilibrium of systems of gas particles in terms of
relative entropy. The systems are modeled by the Kac master equation in
arbitrary dimensions. First, we study the Kac system coupled to a thermostat,
and secondly connected to a heat reservoir. The use of the Fisher-information
allows elementary proofs with weak regularity assumptions. As a result, we
obtain for both systems exponential decay rates for the entropy and information
that are essentially independent of the size of the systems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:46:36 GMT""}]","2023-01-24"
"2301.09593","Ronald Doney","Ron Doney","Local behaviour of the remainder in Renewal theory","16 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several terms in an asynptotic estimate for the renewal mass function ina
discrete random walk which has positive mean and regularly varying right-hand
tail are given. Similar results are given for the renewal density function in
the absolutely continuous case.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:48:24 GMT""}]","2023-01-24"
"2301.09594","Rawad Mezher","Rawad Mezher, Ana Filipa Carvalho, Shane Mansfield","Solving graph problems with single-photons and linear optics","6 pages + 9 pages appendix. Comments Welcome !",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important challenge for current and near-term quantum devices is finding
useful tasks that can be preformed on them. We first show how to efficiently
encode a bounded $n \times n$ matrix $A$ into a linear optical circuit with
$2n$ modes. We then apply this encoding to the case where $A$ is a matrix
containing information about a graph $G$. We show that a photonic quantum
processor consisting of single-photon sources, a linear optical circuit
encoding $A$, and single-photon detectors can solve a range of graph problems
including finding the number of perfect matchings of bipartite graphs,
computing permanental polynomials, determining whether two graphs are
isomorphic, and the $k$-densest subgraph problem. We also propose
pre-processing methods to boost the probabilities of observing the relevant
detection events and thus improve performance. Finally, we present various
numerical simulations which validate our findings.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:48:33 GMT""}]","2023-01-24"
"2301.09595","Adri\`a Recasens","Adri\`a Recasens, Jason Lin, Jo\=ao Carreira, Drew Jaegle, Luyu Wang,
  Jean-baptiste Alayrac, Pauline Luc, Antoine Miech, Lucas Smaira, Ross
  Hemsley, Andrew Zisserman","Zorro: the masked multimodal transformer",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Attention-based models are appealing for multimodal processing because inputs
from multiple modalities can be concatenated and fed to a single backbone
network - thus requiring very little fusion engineering. The resulting
representations are however fully entangled throughout the network, which may
not always be desirable: in learning, contrastive audio-visual self-supervised
learning requires independent audio and visual features to operate, otherwise
learning collapses; in inference, evaluation of audio-visual models should be
possible on benchmarks having just audio or just video. In this paper, we
introduce Zorro, a technique that uses masks to control how inputs from each
modality are routed inside Transformers, keeping some parts of the
representation modality-pure. We apply this technique to three popular
transformer-based architectures (ViT, Swin and HiP) and show that with
contrastive pre-training Zorro achieves state-of-the-art results on most
relevant benchmarks for multimodal tasks (AudioSet and VGGSound). Furthermore,
the resulting models are able to perform unimodal inference on both video and
audio benchmarks such as Kinetics-400 or ESC-50.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:51:39 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 18:58:10 GMT""}]","2023-02-23"
"2301.09596","Yvain Bruned","I. Bailleul, Y. Bruned","Random models for singular SPDEs","15 pages",,,,"math.PR math.AP","http://creativecommons.org/licenses/by/4.0/","  We give a simple and short proof of the convergence of the BHZ renormalized
model associated with the generalized (KPZ) equation.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:52:25 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 16:22:35 GMT""}]","2023-03-28"
"2301.09597","Alexander Schulz-Rosengarten","Alexander Schulz-Rosengarten, Reinhard von Hanxleden, Marten Lohstroh,
  Soroush Bateni, Edward A. Lee","Modal Reactors",,,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  Complex software systems often feature distinct modes of operation, each
designed to handle a particular scenario that may require the system to respond
in a certain way. Breaking down system behavior into mutually exclusive modes
and discrete transitions between modes is a commonly used strategy to reduce
implementation complexity and promote code readability. However, such
capabilities often come in the form of self-contained domain specific languages
or language-specific frameworks. The work in this paper aims to bring the
advantages of modal models to mainstream programming languages, by following
the polyglot coordination approach of Lingua Franca (LF), in which verbatim
target code (e.g., C, C++, Python, Typescript, or Rust) is encapsulated in
composable reactive components called reactors. Reactors can form a dataflow
network, are triggered by timed as well as sporadic events, execute
concurrently, and can be distributed across nodes on a network.
  With modal models in LF, we introduce a lean extension to the concept of
reactors that enables the coordination of reactive tasks based on modes of
operation. The implementation of modal reactors outlined in this paper
generalizes to any LF-supported language with only modest modifications to the
generic runtime system.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:55:49 GMT""}]","2023-01-24"
"2301.09598","Ross Silver","Ross Silver, N\'uria Torres-Alba, Xiurui Zhao, Stefano Marchesi,
  Andrealuna Pizzetti, Isaiah Cox, Marco Ajello","A New Mid-Infrared and X-ray Machine Learning Algorithm to Discover
  Compton-thick AGN",,,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a new method to predict the line-of-sight column density (NH)
values of active galactic nuclei (AGN) based on mid-infrared (MIR), soft, and
hard X-ray data. We developed a multiple linear regression machine learning
algorithm trained with WISE colors, Swift-BAT count rates, soft X-ray hardness
ratios, and an MIR-soft X-ray flux ratio. Our algorithm was trained off 451 AGN
from the Swift-BAT sample with known NH and has the ability to accurately
predict NH values for AGN of all levels of obscuration, as evidenced by its
Spearman correlation coefficient value of 0.86 and its 75% classification
accuracy. This is significant as few other methods can be reliably applied to
AGN with Log(NH <) 22.5. It was determined that the two soft X-ray hardness
ratios and the MIR-soft X-ray flux ratio were the largest contributors towards
accurate NH determination. This algorithm will contribute significantly to
finding Compton-thick (CT-) AGN (NH >= 10^24 cm^-2), thus enabling us to
determine the true intrinsic fraction of CT-AGN in the local universe and their
contribution to the Cosmic X-ray Background.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:56:15 GMT""}]","2023-01-24"
"2301.09599","Alessio Zaccone","Carmine Anzivino, Mathias Casiulis, Tom Zhang, Amgad Salah Moussa,
  Stefano Martiniani, and Alessio Zaccone","Estimating random close packing in polydisperse and bidisperse hard
  spheres via an equilibrium model of crowding",,"J. Chem. Phys. 158, 044901 (2023)","10.1063/5.0137111",,"cond-mat.soft cond-mat.dis-nn cond-mat.mtrl-sci cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that an analogy between crowding in fluid and jammed phases of hard
spheres captures the density dependence of the kissing number for a family of
numerically generated jammed states. We extend this analogy to jams of mixtures
of hard spheres in $d=3$ dimensions, and thus obtain an estimate of the random
close packing (RCP) volume fraction, $\phi_{\textrm{RCP}}$, as a function of
size polydispersity. We first consider mixtures of particle sizes with discrete
distributions. For binary systems, we show agreement between our predictions
and simulations, using both our own and results reported in previous works, as
well as agreement with recent experiments from the literature. We then apply
our approach to systems with continuous polydispersity, using three different
particle size distributions, namely the log-normal, Gamma, and truncated
power-law distributions. In all cases, we observe agreement between our
theoretical findings and numerical results up to rather large polydispersities
for all particle size distributions, when using as reference our own
simulations and results from the literature. In particular, we find
$\phi_{\textrm{RCP}}$ to increase monotonically with the relative standard
deviation, $s_{\sigma}$, of the distribution, and to saturate at a value that
always remains below 1. A perturbative expansion yields a closed-form
expression for $\phi_{\textrm{RCP}}$ that quantitatively captures a
distribution-independent regime for $s_{\sigma} < 0.5$. Beyond that regime, we
show that the gradual loss in agreement is tied to the growth of the skewness
of size distributions.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:58:00 GMT""}]","2023-01-24"
"2301.09600","Braden Brinkman","Braden A. W. Brinkman","Non-perturbative renormalization group analysis of nonlinear spiking
  networks","Revised preprint, some new figures and typo fixes, Appendices moved
  to Supplement file (available in previous version)",,,,"q-bio.NC cond-mat.dis-nn cond-mat.soft cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The critical brain hypothesis posits that neural circuits may operate close
to critical points of a phase transition, which has been argued to have
functional benefits for neural computation. Theoretical and computational
studies arguing for or against criticality in neural dynamics have largely
relied on establishing power laws in neural data, while a proper understanding
of critical phenomena requires a renormalization group (RG) analysis. However,
neural activity is typically non-Gaussian, nonlinear, and non-local, rendering
models that capture all of these features difficult to study using standard
statistical physics techniques. We overcome these issues by adapting the
non-perturbative renormalization group (NPRG) to work on network models of
stochastic spiking neurons. Within a ``local potential approximation,'' we are
able to calculate non-universal quantities such as the effective firing rate
nonlinearity of the network, allowing improved quantitative estimates of
network statistics. We also derive the dimensionless flow equation that admits
universal critical points in the renormalization group flow of the model, and
identify two important types of critical points: in networks with an absorbing
state there is a fixed point corresponding to a non-equilibrium phase
transition between sustained activity and extinction of activity, and in
spontaneously active networks there is a physically meaningful \emph{complex
valued} critical point, corresponding to a discontinuous transition between
high and low firing rate states. Our analysis suggests these fixed points are
related to two well-known universality classes, the non-equilibrium directed
percolation class, and the kinetic Ising model with explicitly broken symmetry,
respectively.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:00:05 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 20:15:48 GMT""}]","2023-03-21"
"2301.09601","Laura R\'io-Mart\'in","Saray Busto (1), Michael Dumbser (2), Laura R\'io-Mart\'in (2 and 3)
  ((1) Departamento de Matem\'atica Aplicada I, Universidade de Vigo, Campus As
  Lagoas Marcosende s/n, 36310 Vigo, Spain, (2) Laboratory of Applied
  Mathematics, DICAM, University of Trento, Via Mesiano 77, 38123 Trento,
  Italy, (3) Departamento de Matem\'aticas, Universidade da Coru\~na, Campus
  Elvi\~na s/n, 15071 A Coru\~na, Spain)","An Arbitrary-Lagrangian-Eulerian hybrid finite volume/finite element
  method on moving unstructured meshes for the Navier-Stokes equations",,"Applied Mathematics and Computation, 437, 127539, 2023","10.1016/j.amc.2022.127539",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a novel second-order semi-implicit hybrid finite volume / finite
element (FV/FE) scheme for the numerical solution of the incompressible and
weakly compressible Navier-Stokes equations on moving unstructured meshes using
an Arbitrary-Lagrangian-Eulerian (ALE) formulation. The scheme is based on a
suitable splitting of the governing PDE into subsystems and employs staggered
grids, where the pressure is defined on the primal simplex mesh, while the
velocity and the remaining flow quantities are defined on an edge-based
staggered dual mesh. The key idea of the scheme is to discretize the nonlinear
convective and viscous terms using an explicit FV scheme that employs the
space-time divergence form of the governing equations on moving space-time
control volumes. For the convective terms, an ALE extension of the Ducros flux
on moving meshes is introduced, which is kinetic energy preserving and stable
in the energy norm when adding suitable numerical dissipation terms. Finally,
the pressure equation of the Navier-Stokes system is solved on the new mesh
configuration using a continuous FE method, with $\mathbb{P}_1$ Lagrange
elements.
  The ALE hybrid FV/FE method is applied to several incompressible test
problems ranging from non-hydrostatic free surface flows over a rising bubble
to flows over an oscillating cylinder and an oscillating ellipse. Via the
simulation of a circular explosion problem on a moving mesh, we show that the
scheme applied to the weakly compressible Navier-Stokes equations is able to
capture weak shock waves, rarefactions and moving contact discontinuities. We
show that our method is particularly efficient for the simulation of weakly
compressible flows in the low Mach number limit, compared to a fully explicit
ALE scheme
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:01:54 GMT""}]","2023-01-24"
"2301.09602","Jo\~ao P C Bertoldo","Joao P. C. Bertoldo, Santiago Velasco-Forero, Jesus Angulo, Etienne
  Decenci\`ere","Adapting the Hypersphere Loss Function from Anomaly Detection to Anomaly
  Segmentation","Submitted to the 2023 IEEE International Conference on Image
  Processing (ICIP 2023)",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose an incremental improvement to Fully Convolutional Data Description
(FCDD), an adaptation of the one-class classification approach from anomaly
detection to image anomaly segmentation (a.k.a. anomaly localization). We
analyze its original loss function and propose a substitute that better
resembles its predecessor, the Hypersphere Classifier (HSC). Both are compared
on the MVTec Anomaly Detection Dataset (MVTec-AD) -- training images are
flawless objects/textures and the goal is to segment unseen defects -- showing
that consistent improvement is achieved by better designing the pixel-wise
supervision.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:06:35 GMT""}]","2023-01-24"
"2301.09603","Theodore Drivas D","Luigi De Rosa, Theodore D. Drivas, Marco Inversi","On the Support of Anomalous Dissipation Measures","21 pages",,,,"math.AP math-ph math.MP physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  By means of a unifying measure-theoretic approach, we establish lower bounds
on the Hausdorff dimension of the space-time set which can support anomalous
dissipation for weak solutions of fluid equations, both in the presence or
absence of a physical boundary. Boundary dissipation, which can occur at both
the time and the spatial boundary, is analyzed by suitably modifying the Duchon
& Robert interior distributional approach. One implication of our results is
that any bounded Euler solution (compressible or incompressible) arising as a
zero viscosity limit of Navier--Stokes solutions cannot have anomalous
dissipation supported on a set of dimension smaller than that of the space.
This result is sharp, as demonstrated by entropy-producing shock solutions of
compressible Euler and by recent constructions of dissipative incompressible
Euler solutions, as well as passive scalars. For $L^q_tL^r_x$ suitable
Leray--Hopf solutions of the $d-$dimensional Navier--Stokes equation we prove a
bound of the dissipation in terms of the Parabolic Hausdorff measure soon as
the solution lies in the Prodi--Serrin class. In the three-dimensional case,
this matches with the Caffarelli--Kohn--Nirenberg partial regularity.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:09:51 GMT""}]","2023-01-24"
"2301.09604","Divyansh Jhunjhunwala","Divyansh Jhunjhunwala, Shiqiang Wang, Gauri Joshi","FedExP: Speeding Up Federated Averaging via Extrapolation","Accepted to ICLR 2023. V2 fixes minor typos and cleans up proofs",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Averaging (FedAvg) remains the most popular algorithm for Federated
Learning (FL) optimization due to its simple implementation, stateless nature,
and privacy guarantees combined with secure aggregation. Recent work has sought
to generalize the vanilla averaging in FedAvg to a generalized gradient descent
step by treating client updates as pseudo-gradients and using a server step
size. While the use of a server step size has been shown to provide performance
improvement theoretically, the practical benefit of the server step size has
not been seen in most existing works. In this work, we present FedExP, a method
to adaptively determine the server step size in FL based on dynamically varying
pseudo-gradients throughout the FL process. We begin by considering the
overparameterized convex regime, where we reveal an interesting similarity
between FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then
show how FedExP can be motivated as a novel extension to the extrapolation
mechanism that is used to speed up POCS. Our theoretical analysis later also
discusses the implications of FedExP in underparameterized and non-convex
settings. Experimental results show that FedExP consistently converges faster
than FedAvg and competing baselines on a range of realistic FL datasets.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:10:22 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 15:52:24 GMT""}]","2023-03-07"
"2301.09605","Ronen Weiss","Ronen Weiss, Stefano Gandolfi","Nuclear three-body short-range correlations in coordinate space",,,,"LA-UR-22-32748","nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  We study the effects of three-nucleon short-range correlations on nuclear
coordinate-space densities. For this purpose, novel three-body densities are
calculated for ground state nuclei using the auxiliary-field diffusion Monte
Carlo method. The results are analyzed in terms of the Generalized Contact
Formalism, extended to include three-body correlations, revealing the universal
behavior of nucleon triplets at short distances. We identify the quantum
numbers of such correlated triplets and extract scaling factors of triplet
abundances that can be compared to upcoming inclusive electron scattering data.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:10:34 GMT""}]","2023-01-24"
"2301.09606","Zuzana Spitalova","Zuzana \v{S}pit\'alov\'a, Oliver Leontiev and Patrik Harma\v{n}o\v{s}","Concept of Delivery System in the Smart City Environment",,,"10.5121/ijci.2023.120110",,"cs.CY","http://creativecommons.org/publicdomain/zero/1.0/","  Regarding to the smart city infrastructures, there is a demand for big data
processing and its further usage. This data can be gained by various means.
There are many IoT devices in the city, which can communicate and share the
information about the environment which they are situated in. Moreover every
personal mobile device can also participate in this process and help to gain
data via various applications. Every app provides the useful data, enabling the
location and data sharing. This data can be further processed and used for
improving the city infrastructure, transport or other services. We designed the
system for shared delivery process, which can help to achieve the described
situation. It consists of frontend and backend part. The frontend part,
multiplatform mobile app, represents the graphical interface and the backend
part represents the database for the gained data.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:10:41 GMT""}]","2023-01-24"
"2301.09607","Clifton Robinson","Clifton Paul Robinson, Daniel Uvaydov, Salvatore D'Oro, Tommaso
  Melodia","Narrowband Interference Detection via Deep Learning","6 pages, 10 figures, 1 table. ICC 2023 - IEEE International
  Conference on Communications, Rome, Italy, May 2023",,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the increased usage of spectrum caused by the exponential growth of
wireless devices, detecting and avoiding interference has become an
increasingly relevant problem to ensure uninterrupted wireless communications.
In this paper, we focus our interest on detecting narrowband interference
caused by signals that despite occupying a small portion of the spectrum only
can cause significant harm to wireless systems, for example, in the case of
interference with pilots and other signals that are used to equalize the effect
of the channel or attain synchronization. Due to the small sizes of these
signals, detection can be difficult due to their low energy footprint, while
greatly impacting (or denying completely in some cases) network communications.
We present a novel narrowband interference detection solution that utilizes
convolutional neural networks (CNNs) to detect and locate these signals with
high accuracy. To demonstrate the effectiveness of our solution, we have built
a prototype that has been tested and validated on a real-world over-the-air
large-scale wireless testbed. Our experimental results show that our solution
is capable of detecting narrowband jamming attacks with an accuracy of up to
99%. Moreover, it is also able to detect multiple attacks affecting several
frequencies at the same time even in the case of previously unseen attack
patterns. Not only can our solution achieve a detection accuracy between 92%
and 99%, but it does so by only adding an inference latency of 0.093ms.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:10:58 GMT""}]","2023-01-24"
"2301.09608","Andrew Wilhelm","Andrew Wilhelm, Garrett Wendel, Brandon Collins, Doug Cowen, Igor
  Jovanovic","Evaluation of Light Collection from Highly Scattering Media using
  Wavelength-Shifting Fibers","25 pages, 15 figures","Nucl. Instrum. Methods Phys. Res. A. 1049 (2023)","10.1016/j.nima.2023.168085",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Opaque scintillators are designed to have a short scattering length such that
scintillation photons are probabilistically confined to a small region of space
about their origin. The benefit of this feature is that information on the
interaction event topology can be recorded with greater fidelity than in
traditional highly transparent media with sensors at large distances from the
light production region. Opaque scintillator detectors rely on
wavelength-shifting fibers to extract the scintillation light; however, the
efficiency of light collection has not yet been directly measured in
experiment. We measured the efficiency of light collection as a function of the
optical parameters of an opaque liquid and the distance from the origin of the
light to the fiber. We use the experimental data to validate a Monte Carlo
model of light transport and collection and discuss a simple diffusion model
that reproduces the results of Monte Carlo simulation with high fidelity. This
combination of validated models has the potential for use in predictions of
performance in various designs of future opaque scintillator detectors such as
LiquidO.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:11:21 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 16:47:01 GMT""}]","2023-02-10"
"2301.09609","Satish Mulleti","Satish Mulleti, Eliya Reznitskiy, Shlomi Savariego, Moshe Namer,
  Nimrod Glazer, Yonina C. Eldar","A Hardware Prototype of Wideband High-Dynamic Range ADC","11",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Key parameters of analog-to-digital converters (ADCs) are their sampling rate
and dynamic range. Power consumption and cost of an ADC are directly
proportional to the sampling rate; hence, it is desirable to keep it as low as
possible. The dynamic range of an ADC also plays an important role, and
ideally, it should be greater than the signal's; otherwise, the signal will be
clipped. To avoid clipping, modulo folding can be used before sampling,
followed by an unfolding algorithm to recover the true signal. In this paper,
we present a modulo hardware prototype that can be used before sampling to
avoid clipping. Our modulo hardware operates prior to the sampling mechanism
and can fold higher frequency signals compared to existing hardware. We present
a detailed design of the hardware and also address key issues that arise during
implementation. In terms of applications, we show the reconstruction of
finite-rate-of-innovation signals which are beyond the dynamic range of the
ADC. Our system operates at six times below the Nyquist rate of the signal and
can accommodate eight-times larger signals than the ADC's dynamic range.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:11:34 GMT""},{""version"":""v2"",""created"":""Sun, 29 Jan 2023 14:40:25 GMT""}]","2023-01-31"
"2301.09610","Yannick Azhri Din Omar","Yannick A. D. Omar, Zachary G. Lipel, Kranthi K. Mandadapu","The $(2 + \delta)$-dimensional theory of the electromechanics of lipid
  membranes: I. Electrostatics",,,,,"cond-mat.soft physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The coupling of electric fields to the mechanics of lipid membranes gives
rise to intriguing electromechanical behavior, as, for example, evidenced by
the deformation of lipid vesicles in external electric fields.
Electromechanical effects are relevant for many biological processes, such as
the propagation of action potentials in axons and the activation of
mechanically-gated ion channels. Currently, a theoretical framework describing
the electromechanical behavior of arbitrarily curved and deforming lipid
membranes does not exist. Purely mechanical models commonly treat lipid
membranes as two-dimensional surfaces, ignoring their finite thickness. While
holding analytical and numerical merit, this approach cannot describe the
coupling of lipid membranes to electric fields and is thus unsuitable for
electromechanical models. In a sequence of articles, we derive an
\textit{effective} surface theory of the electromechanics of lipid membranes,
named a $(2+\delta)$-dimensional theory, which has the advantages of surface
descriptions while accounting for finite thickness effects. The present article
proposes a new, generic dimension-reduction procedure relying on low-order
spectral expansions. This procedure is applied to the electrostatics of lipid
membranes to obtain a $(2+\delta)$-dimensional theory that captures potential
differences across and electric fields within lipid membranes. This new model
is tested on different geometries relevant for lipid membranes, showing good
agreement with the corresponding three-dimensional electrostatics theory.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:13:28 GMT""}]","2023-01-24"
"2301.09611","Abhilekha Dalal","Abhilekha Dalal, Md Kamruzzaman Sarker, Adrita Barua, and Pascal
  Hitzler","Explaining Deep Learning Hidden Neuron Activations using Concept
  Induction","Submitted to IJCAI-23",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  One of the current key challenges in Explainable AI is in correctly
interpreting activations of hidden neurons. It seems evident that accurate
interpretations thereof would provide insights into the question what a deep
learning system has internally \emph{detected} as relevant on the input, thus
lifting some of the black box character of deep learning systems.
  The state of the art on this front indicates that hidden node activations
appear to be interpretable in a way that makes sense to humans, at least in
some cases. Yet, systematic automated methods that would be able to first
hypothesize an interpretation of hidden neuron activations, and then verify it,
are mostly missing.
  In this paper, we provide such a method and demonstrate that it provides
meaningful interpretations. It is based on using large-scale background
knowledge -- a class hierarchy of approx. 2 million classes curated from the
Wikipedia Concept Hierarchy -- together with a symbolic reasoning approach
called \emph{concept induction} based on description logics that was originally
developed for applications in the Semantic Web field.
  Our results show that we can automatically attach meaningful labels from the
background knowledge to individual neurons in the dense layer of a
Convolutional Neural Network through a hypothesis and verification process.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:14:32 GMT""}]","2023-01-24"
"2301.09612","Neil Bassett","Neil Bassett, David Rapetti, Bang D. Nhan, Brent Page, Jack O. Burns,
  Marc Pulupa, Stuart D. Bale","Constraining a Model of the Radio Sky Below 6 MHz Using the Parker Solar
  Probe/FIELDS Instrument in Preparation for Upcoming Lunar-based Experiments","18 pages, 10 figures, 5 tables. Under review in the Astrophysical
  Journal",,"10.3847/1538-4357/acbc76",,"astro-ph.GA astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present a Bayesian analysis of data from the FIELDS instrument on board
the Parker Solar Probe (PSP) spacecraft with the aim of constraining low
frequency ($\lesssim$ 6 MHz) sky in preparation for several upcoming
lunar-based experiments. We utilize data recorded during PSP's ``coning roll''
maneuvers, in which the axis of the spacecraft is pointed 45$^{\circ}$ off of
the Sun. The spacecraft then rotates about a line between the Sun and the
spacecraft with a period of 24 minutes. We reduce the data into two formats:
roll-averaged, in which the spectra are averaged over the roll, and
phase-binned, in which the spectra are binned according to the phase of the
roll. We construct a forward model of the FIELDS observations that includes
numerical simulations of the antenna beam, an analytic emissivity function of
the galaxy, and estimates of the absorption due to free electrons. Fitting 5
parameters, we find that the roll-averaged data can be fit well by this model
and we obtain posterior parameter constraints that are in general agreement
with previous estimates. The model is not, however, able to fit the
phase-binned data well, likely due to limitations such as the lack of
non-smooth emission structure at both small and large scales, enforced symmetry
between the northern and southern galactic hemispheres, and large uncertainties
in the free electron density. This suggests that significant improvement in the
low frequency sky model is needed in order to fully and accurately represent
the sky at frequencies below 6 MHz.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:17:59 GMT""}]","2023-03-29"
"2301.09613","David C. Johnston","Santanu Pakhira, Asish K. Kundu, Farhan Islam, M. A. Tanatar, Tufan
  Roy, Thomas Heitmann, T. Yilmaz, E. Vescovo, Masahito Tsujikawa, Masafumi
  Shirai, R. Prozorov, David Vaknin, and D. C. Johnston","Anisotropic magnetism and electronic structure of trigonal
  EuAl$_2$Ge$_2$ single crystals","16 pages, 13 captioned figures, 53 references Updated several
  affiliations","Phys. Rev. B 107, 134439 (2023); 16 pages","10.1103/PhysRevB.107.134439",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The magnetic and electronic properties of the layered Zintl-phase compound
EuAl$_2$Ge$_2$ crystallizing in the trigonal CaAl$_2$Si$_2$-type structure are
reported. Our neutron-diffraction measurements show that EuAl$_2$Ge$_2$
undergoes A-type antiferromagnetic (AFM) ordering below $T_{\rm N} =
27.5(5)$~K, with the Eu moments (Eu$^{2+}$, $S = 7/2$) aligned
ferromagnetically in the $ab$ plane. The $H = 0$ magnetic structure consists of
trigonal AFM domains associated with $ab$-plane magnetic anisotropy and a
field-induced reorientation of the Eu spins in the domains is evident at $T =
2$~K below the critical field $H_{c1} = 2.5(1)$ kOe. Electrical resistivity and
ARPES measurements show that EuAl$_2$Ge$_2$ is metallic both above and below
$T_{\rm N}$. In the AFM phase, we directly observe folded bands in ARPES due to
the doubling of the magnetic unit cell along the $c$ axis with an enhancement
of quasiparticle weight due to the complex change in the coupling between the
magnetic moments and itinerant electrons on cooling below $T_{\rm N}$. The
observed electronic structure is well reproduced by first-principle
calculations, which also predict the presence of nontrivial electronic states
near the Fermi level in the AFM phase with $Z_2$ topological numbers 1;(000).
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:20:37 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 13:51:02 GMT""}]","2023-05-10"
"2301.09614","Haojing Yan","Haojing Yan, Lifan Wang, Zhiyuan Ma, and Lei Hu","Point-like sources among z>11 galaxy candidates: contaminants due to
  supernovae at high redshifts?","ApJ Letters accepted",,"10.3847/2041-8213/acc93f",,"astro-ph.CO astro-ph.GA hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent searches for z>11 galaxies using the James Webb Space Telescope
have resulted in an unexpectedly high number of candidate objects, which imply
at least an order of magnitude higher number density of z>11 galaxies than the
previously favored predictions. A question has risen whether there are some new
types of contaminants among these candidates. The candidate sample of Yan et
al. (2023a), totalling 87 dropouts, is the largest one, and we notice that a
number of these candidates are point-like. We hypothesize that the point-source
dropouts could be supernovae at high redshifts. Further investigation shows
that most of their spectral energy distributions indeed can be explained by
supernovae at various redshifts from z ~ 1--15, which lends support to this
hypothesis. Attributing such point-source dropouts to supernova contamination
cannot eliminate the tension, however, because they only account for ~10% of
the Yan et al.'s sample. On the other hand, the discovery of ""contaminant""
supernovae at z>3 will have a series of important implications. Ironically, the
existence of supernovae at $z>10$ would still imply that the previously favored
picture of early galaxy formation severely underestimates the global star
formation rate density such redshifts. Multiple-epoch JWST imaging will be the
simplest and yet the most efficient way to further test this hypothesis.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:22:03 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 01:48:20 GMT""}]","2023-04-19"
"2301.09615","Clifton Robinson","Clifton Paul Robinson, Leonardo Bonati, Tara Van Nieuwstadt, Teddy
  Reiss, Pedram Johari, Michele Polese, Hieu Nguyen, Curtis Watson, Tommaso
  Melodia","ESWORD: Implementation of Wireless Jamming Attacks in a Real-World
  Emulated Network","6 pages, 7 figures, 1 table. IEEE Wireless Communications and
  Networking Conference (WCNC), Glasgow, Scotland, March 2023",,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wireless jamming attacks have plagued wireless communication systems and will
continue to do so going forward with technological advances. These attacks fall
under the category of Electronic Warfare (EW), a continuously growing area in
both attack and defense of the electromagnetic spectrum, with one subcategory
being electronic attacks. Jamming attacks fall under this specific subcategory
of EW as they comprise adversarial signals that attempt to disrupt, deny,
degrade, destroy, or deceive legitimate signals in the electromagnetic
spectrum. While jamming is not going away, recent research advances have
started to get the upper hand against these attacks by leveraging new methods
and techniques, such as machine learning. However, testing such jamming
solutions on a wide and realistic scale is a daunting task due to strict
regulations on spectrum emissions. In this paper, we introduce eSWORD, the
first large-scale framework that allows users to safely conduct real-time and
controlled jamming experiments with hardware-in-the-loop. This is done by
integrating eSWORD into the Colosseum wireless network emulator that enables
large-scale experiments with up to 50 software-defined radio nodes. We compare
the performance of eSWORD with that of real-world jamming systems by using an
over-the-air wireless testbed (ensuring safe measures were taken when
conducting experiments). Our experimental results demonstrate that eSWORD
follows similar patterns in throughput, signal-to-noise ratio, and link status
to real-world jamming experiments, testifying to the high accuracy of the
emulated eSWORD setup.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:26:40 GMT""}]","2023-01-24"
"2301.09616","Arie Israel","Arie Israel and Azita Mayeli","On the Eigenvalue Distribution of Spatio-Spectral Limiting Operators in
  Higher Dimensions",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prolate spheroidal wave functions are an orthogonal family of bandlimited
functions on $\mathbb{R}$ that have the highest concentration within a specific
time interval. They are also identified as the eigenfunctions of a
time-frequency limiting operator (TFLO), and the associated eigenvalues belong
to the interval $[0, 1]$. Previous work has studied the asymptotic distribution
and clustering behavior of the TFLO eigenvalues.
  In this paper, we extend these results to multiple dimensions. We prove
estimates on the eigenvalues of a spatio-spectral limiting operator (SSLO) on
$L^2(\mathbb{R}^d)$, which is an alternating product of projection operators
associated to given spatial and frequency domains in $\mathbb{R}^d$. If one of
the domains is a hypercube, and the other domain is convex body satisfying a
symmetry condition, we derive quantitative bounds on the distribution of the
SSLO eigenvalues in the interval $[0,1]$.
  To prove our results, we design a family of wave packets in $\mathbb{R}^d$
that are highly concentrated in the spatial and frequency domains. We show that
these wave packets are ""approximate eigenfunctions"" of a spatio-spectral
limiting operator. To build the wave packets, we use a variant of the
Coifman-Meyer local sine basis for $L^2[0,1]$, and we lift the basis to higher
dimensions using a tensor product.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:28:36 GMT""}]","2023-01-24"
"2301.09617","Sophia Janine Wagner","Sophia J. Wagner, Daniel Reisenb\""uchler, Nicholas P. West, Jan Moritz
  Niehues, Gregory Patrick Veldhuizen, Philip Quirke, Heike I. Grabsch, Piet A.
  van den Brandt, Gordon G. A. Hutchins, Susan D. Richman, Tanwei Yuan, Rupert
  Langer, Josien Christina Anna Jenniskens, Kelly Offermans, Wolfram Mueller,
  Richard Gray, Stephen B. Gruber, Joel K. Greenson, Gad Rennert, Joseph D.
  Bonner, Daniel Schmolze, Jacqueline A. James, Maurice B. Loughrey, Manuel
  Salto-Tellez, Hermann Brenner, Michael Hoffmeister, Daniel Truhn, Julia A.
  Schnabel, Melanie Boxberg, Tingying Peng, Jakob Nikolas Kather","Fully transformer-based biomarker prediction from colorectal cancer
  histology: a large-scale multicentric study","Updated Figure 2 and Table A.5",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Background: Deep learning (DL) can extract predictive and prognostic
biomarkers from routine pathology slides in colorectal cancer. For example, a
DL test for the diagnosis of microsatellite instability (MSI) in CRC has been
approved in 2022. Current approaches rely on convolutional neural networks
(CNNs). Transformer networks are outperforming CNNs and are replacing them in
many applications, but have not been used for biomarker prediction in cancer at
a large scale. In addition, most DL approaches have been trained on small
patient cohorts, which limits their clinical utility. Methods: In this study,
we developed a new fully transformer-based pipeline for end-to-end biomarker
prediction from pathology slides. We combine a pre-trained transformer encoder
and a transformer network for patch aggregation, capable of yielding single and
multi-target prediction at patient level. We train our pipeline on over 9,000
patients from 10 colorectal cancer cohorts. Results: A fully transformer-based
approach massively improves the performance, generalizability, data efficiency,
and interpretability as compared with current state-of-the-art algorithms.
After training on a large multicenter cohort, we achieve a sensitivity of 0.97
with a negative predictive value of 0.99 for MSI prediction on surgical
resection specimens. We demonstrate for the first time that resection
specimen-only training reaches clinical-grade performance on endoscopic biopsy
tissue, solving a long-standing diagnostic problem. Interpretation: A fully
transformer-based end-to-end pipeline trained on thousands of pathology slides
yields clinical-grade performance for biomarker prediction on surgical
resections and biopsies. Our new methods are freely available under an open
source license.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:33:38 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 13:25:59 GMT""}]","2023-03-02"
"2301.09618","Jingzi Huang","Jingzi Huang, Henry C. Burridge, Maarten van Reeuwijk","The internal structure of forced fountains",,,"10.1017/jfm.2023.210",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the mixing processes inside a forced fountain using data from direct
numerical simulation. The outer boundary of the fountain with the ambient is a
turbulent/non-turbulent interface. Inside the fountain, two internal
boundaries, both turbulent/turbulent interfaces, are identified: 1) the
classical boundary between upflow and downflow which is composed of the loci of
points of zero mean vertical velocity; and 2) the streamline that separates the
mean flow emitted by the source from the entrained fluid from the ambient (the
separatrix). We show that entrainment due to turbulent fluxes across the
internal boundary is at least as important as that by the mean flow. However,
entrainment by the turbulence behaves substantively differently from that by
the mean flow and cannot be modelled using the same assumptions. This presents
a challenge for existing models of turbulent fountains and other environmental
flows that evolve inside turbulent environments.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:38:25 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 22:22:02 GMT""}]","2023-05-03"
"2301.09619","Aamal Hussain","Aamal Abbas Hussain and Francesco Belardinelli and Georgios Piliouras","Asymptotic Convergence and Performance of Multi-Agent Q-Learning
  Dynamics","Accepted in AAMAS 2023",,,,"cs.GT cs.AI cs.MA math.DS","http://creativecommons.org/licenses/by/4.0/","  Achieving convergence of multiple learning agents in general $N$-player games
is imperative for the development of safe and reliable machine learning (ML)
algorithms and their application to autonomous systems. Yet it is known that,
outside the bounds of simple two-player games, convergence cannot be taken for
granted.
  To make progress in resolving this problem, we study the dynamics of smooth
Q-Learning, a popular reinforcement learning algorithm which quantifies the
tendency for learning agents to explore their state space or exploit their
payoffs. We show a sufficient condition on the rate of exploration such that
the Q-Learning dynamics is guaranteed to converge to a unique equilibrium in
any game. We connect this result to games for which Q-Learning is known to
converge with arbitrary exploration rates, including weighted Potential games
and weighted zero sum polymatrix games.
  Finally, we examine the performance of the Q-Learning dynamic as measured by
the Time Averaged Social Welfare, and comparing this with the Social Welfare
achieved by the equilibrium. We provide a sufficient condition whereby the
Q-Learning dynamic will outperform the equilibrium even if the dynamics do not
converge.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:39:11 GMT""}]","2023-01-24"
"2301.09620","Ethan Brewer","Ethan Brewer, Zhonghui Lv, and Dan Runfola","Tracking the industrial growth of modern China with high-resolution
  panchromatic imagery: A sequential convolutional approach","Fixed typos",,,,"cs.CV cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  Due to insufficient or difficult to obtain data on development in
inaccessible regions, remote sensing data is an important tool for interested
stakeholders to collect information on economic growth. To date, no studies
have utilized deep learning to estimate industrial growth at the level of
individual sites. In this study, we harness high-resolution panchromatic
imagery to estimate development over time at 419 industrial sites in the
People's Republic of China using a multi-tier computer vision framework. We
present two methods for approximating development: (1) structural area coverage
estimated through a Mask R-CNN segmentation algorithm, and (2) imputing
development directly with visible & infrared radiance from the Visible Infrared
Imaging Radiometer Suite (VIIRS). Labels generated from these methods are
comparatively evaluated and tested. On a dataset of 2,078 50 cm resolution
images spanning 19 years, the results indicate that two dimensions of
industrial development can be estimated using high-resolution daytime imagery,
including (a) the total square meters of industrial development (average error
of 0.021 $\textrm{km}^2$), and (b) the radiance of lights (average error of 9.8
$\mathrm{\frac{nW}{cm^{2}sr}}$). Trend analysis of the techniques reveal
estimates from a Mask R-CNN-labeled CNN-LSTM track ground truth measurements
most closely. The Mask R-CNN estimates positive growth at every site from the
oldest image to the most recent, with an average change of 4,084
$\textrm{m}^2$.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:40:21 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 18:59:56 GMT""}]","2023-02-15"
"2301.09621","Natascha Sattler","Natascha Sattler, Francesca Pinna, Nadine Neumayer, Jesus
  Falc\'on-Barroso, Marie Martig, Dimitri A. Gadotti, Glenn van de Ven, Ivan
  Minchev","The vertical structure of the spiral galaxy NGC 3501: first stages of
  the formation of a thin metal-rich disc","15 pages, 12 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stad275",,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We trace the evolution of the edge-on spiral galaxy NGC 3501, making use of
its stellar populations extracted from deep integral-field spectroscopy MUSE
observations. We present stellar kinematic and population maps, as well as the
star formation history, of the south-western half of the galaxy. The derived
maps of the stellar line-of-sight velocity and velocity dispersion are quite
regular, show disc-like rotation, and no other structural component of the
galaxy. However, maps of the stellar populations exhibit structures in the
mass-weighted and light-weighted age, total metallicity and [Mg/Fe] abundance.
These maps indicate that NGC 3501 is a young galaxy, consisting mostly of stars
with ages between 2 to 8 Gyr. Also, they show a thicker more extended structure
that is metal-poor and $\alpha$-rich, and another inner metal-rich and
$\alpha$-poor one with smaller radial extension. While previous studies
revealed that NGC 3501 shows only one morphological disc component in its
vertical structure, we divided the galaxy into two regions: an inner metal-rich
midplane and a metal-poor thicker envelope. Comparing the star formation
history of the inner thinner metal-rich disc and the thicker metal-poor disc,
we see that the metal-rich component evolved more steadily, while the
metal-poor one experienced several bursts of star formation. We propose this
spiral galaxy is being observed in an early evolutionary phase, with a thicker
disc already in place and an inner thin disc in an early formation stage. So we
are probably witnessing the birth of a future massive thin disc, continuously
growing embedded in a preexisting thicker disc.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:42:25 GMT""}]","2023-02-08"
"2301.09622","Prithvi Akella","Prithvi Akella, Mohamadreza Ahmadi, Richard M. Murray, and Aaron D.
  Ames","Barrier-Based Test Synthesis for Safety-Critical Systems Subject to
  Timed Reach-Avoid Specifications",,,,,"cs.SY cs.RO eess.SY","http://creativecommons.org/licenses/by/4.0/","  We propose an adversarial, time-varying test-synthesis procedure for
safety-critical systems without requiring specific knowledge of the underlying
controller steering the system. From a broader test and evaluation context,
determination of difficult tests of system behavior is important as these tests
would elucidate problematic system phenomena before these mistakes can engender
problematic outcomes, e.g. loss of human life in autonomous cars, costly
failures for airplane systems, etc. Our approach builds on existing,
simulation-based work in the test and evaluation literature by offering a
controller-agnostic test-synthesis procedure that provides a series of
benchmark tests with which to determine controller reliability. To achieve
this, our approach codifies the system objective as a timed reach-avoid
specification. Then, by coupling control barrier functions with this class of
specifications, we construct an instantaneous difficulty metric whose minimizer
corresponds to the most difficult test at that system state. We use this
instantaneous difficulty metric in a game-theoretic fashion, to produce an
adversarial, time-varying test-synthesis procedure that does not require
specific knowledge of the system's controller, but can still provably identify
realizable and maximally difficult tests of system behavior. Finally, we
develop this test-synthesis procedure for both continuous and discrete-time
systems and showcase our test-synthesis procedure on simulated and hardware
examples.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:45:04 GMT""}]","2023-01-24"
"2301.09623","Antonio Hern\'an-Caballero","A. Hern\'an-Caballero, C. N. A. Willmer, J. Varela, C.
  L\'opez-Sanjuan, A. Mar\'in-Franch, H. V\'azquez Rami\'o, T. Civera, A.
  Ederoclite, D. Muniesa, J. Cenarro, S. Bonoli, R. Dupke, J. Lim, J.
  Chaves-Montero, J. Laur, C. Hern\'andez-Monteagudo, J. A.
  Fern\'andez-Ontiveros, A. Fern\'andez-Soto, L. A. D\'iaz-Garc\'ia, R. M.
  Gonz\'alez Delgado, C. Queiroz, J. M. V\'ilchez, R. Abramo, J. Alcaniz, N.
  Ben\'itez, S. Carneiro, D. Crist\'obal-Hornillos, C. Mendes de Oliveira, M.
  Moles, L. Sodr\'e Jr., K. Taylor","J-NEP: 60-band photometry and photometric redshifts for the James Webb
  Space Telescope North Ecliptic Pole Time-Domain Field","16 pages, 25 figures, accepted for publication in Astronomy and
  Astrophysics","A&A 671, A71 (2023)","10.1051/0004-6361/202244759",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The J-PAS survey will observe ~1/3 of the northern sky with a set of 56
narrow-band filters using the dedicated 2.55 m JST telescope at the Javalambre
Astrophysical Observatory. Prior to the installation of the main camera, in
order to demonstrate the scientific potential of J-PAS, two small surveys were
performed with the single-CCD Pathfinder camera: miniJPAS (~1 deg2 along the
Extended Groth Strip), and J-NEP (~0.3 deg2 around the JWST North Ecliptic Pole
Time Domain Field), including all 56 J-PAS filters as well as u, g, r, and i.
J-NEP is ~0.5-1.0 magnitudes deeper than miniJPAS, providing photometry for
24,618 r-band detected sources and photometric redshifts (photo-z) for the
6,662 sources with r<23.
  In this paper we describe the photometry and photo-z of J-NEP and demonstrate
a new method for the removal of systematic offsets in the photometry based on
the median colours of galaxies, dubbed ""galaxy locus recalibration"". This
method does not require spectroscopic observations except in a few reference
pointings and, unlike previous methods, is applicable to the whole J-PAS
survey.
  We use a spectroscopic sample of 787 galaxies to test the photo-z performance
for J-NEP and in comparison to miniJPAS. We find that the deeper J-NEP
observations result in a factor ~1.5-2 decrease in sigma_NMAD (a robust
estimate of the standard deviation of the photo-z error) and the outlier rate
relative to miniJPAS for r>21.5 sources, but no improvement in brighter ones.
We find the same relation between sigma_NMAD and odds in J-NEP and miniJPAS,
suggesting sigma_NMAD can be predicted for any set of J-PAS sources from their
odds distribution alone, with no need for additional spectroscopy to calibrate
the relation. We explore the causes for photo-z outliers and find that
colour-space degeneracy at low S/N, photometry artifacts, source blending, and
exotic spectra are the most important factors.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:45:19 GMT""}]","2023-03-15"
"2301.09624","Muhammad Dawood","Piotr Keller, Muhammad Dawood, Fayyaz ul Amir Afsar Minhas","Maximum Mean Discrepancy Kernels for Predictive and Prognostic Modeling
  of Whole Slide Images","* Joint first authorship Accepted: IEEE - ISBI 2023 International
  Symposium on Biomedical Imaging",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  How similar are two images? In computational pathology, where Whole Slide
Images (WSIs) of digitally scanned tissue samples from patients can be
multi-gigapixels in size, determination of degree of similarity between two
WSIs is a challenging task with a number of practical applications. In this
work, we explore a novel strategy based on kernelized Maximum Mean Discrepancy
(MMD) analysis for determination of pairwise similarity between WSIs. The
proposed approach works by calculating MMD between two WSIs using kernels over
deep features of image patches. This allows representation of an entire dataset
of WSIs as a kernel matrix for WSI level clustering, weakly-supervised
prediction of TP-53 mutation status in breast cancer patients from their
routine WSIs as well as survival analysis with state of the art prediction
performance. We believe that this work will open up further avenues for
application of WSI-level kernels for predictive and prognostic tasks in
computational pathology.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:47:41 GMT""}]","2023-01-24"
"2301.09625","Styliani Tsilia","Styliani Tsilia, Guido De Marchi, Nino Panagia","Photometric determination of the mass accretion rates of pre-main
  sequence stars. VII. The low-density cluster NGC 376 in the Small Magellanic
  Cloud","10 pages, 6 figures, accepted for publication in Astronomy and
  Astrophysics",,,,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aims. We study the properties of low-mass stars recently formed in the field
of the NGC 376 cluster in the Small Magellanic Cloud (SMC). Methods. Using
photometric observations acquired with the Hubble Space Telescope (HST) in the
V, I and Halpha bands, we identify 244 candidate pre-main sequence (PMS) stars
showing Halpha excess emission at the 5 sigma level and with Halpha equivalent
width of 20 \r{A} or more. We derive physical parameters for all PMS stars,
including masses, ages, and mass accretion rates. We compare the effective mass
accretion rate of stars in NGC 376 to that of objects in the NGC 346 cluster,
which features similar metallicity but higher total mass and gas density.
Results. We find a median age of 28 Myr for this population (with 25 and 75
percentiles at about 20 and 40 Myr, respectively), in excellent agreement with
previous studies of massive stars in the same field. The PMS stars are rather
uniformly distributed across the field, whereas massive stars are more
clustered. The spatial distribution of PMS objects is compatible with them
having formed in the centre of the cluster and then migrated outwards. We find
that in NGC 376 the mass accretion rate is systematically lower than in NGC 346
for stars of the same mass and age. This indicates that, besides metallicity,
there are other environmental factors affecting the rate of mass accretion onto
PMS stars. Our observations suggest that the gas density in the star-forming
region might play a role.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:55:08 GMT""}]","2023-01-24"
"2301.09626","Malte Ostendorff","Malte Ostendorff, Georg Rehm","Efficient Language Model Training through Cross-Lingual and Progressive
  Transfer Learning",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Most Transformer language models are primarily pretrained on English text,
limiting their use for other languages. As the model sizes grow, the
performance gap between English and other languages with fewer compute and data
resources increases even further. Consequently, more resource-efficient
training methods are needed to bridge the gap for languages with fewer
resources available. To address this problem, we introduce a cross-lingual and
progressive transfer learning approach, called CLP-Transfer, that transfers
models from a source language, for which pretrained models are publicly
available, like English, to a new target language. As opposed to prior work,
which focused on the cross-lingual transfer between two languages, we extend
the transfer to the model size. Given a pretrained model in a source language,
we aim for a same-sized model in a target language. Instead of training a model
from scratch, we exploit a smaller model that is in the target language but
requires much fewer resources. Both small and source models are then used to
initialize the token embeddings of the larger model based on the overlapping
vocabulary of the source and target language. All remaining weights are reused
from the model in the source language. This approach outperforms the sole
cross-lingual transfer and can save up to 80% of the training steps compared to
the random initialization.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:56:12 GMT""}]","2023-01-24"
"2301.09627","Kasper Green Larsen","Amin Karbasi, Kasper Green Larsen","The Impossibility of Parallelizing Boosting",,,,,"cs.LG cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of boosting is to convert a sequence of weak learners into a strong
learner. At their heart, these methods are fully sequential. In this paper, we
investigate the possibility of parallelizing boosting. Our main contribution is
a strong negative result, implying that significant parallelization of boosting
requires an exponential blow-up in the total computing resources needed for
training.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:57:16 GMT""},{""version"":""v2"",""created"":""Sat, 25 Mar 2023 08:13:08 GMT""}]","2023-03-28"
"2301.09628","Akash Jain","Jay Armas, Akash Jain","Approximate higher-form symmetries, topological defects, and dynamical
  phase transitions",,,,,"hep-th cond-mat.soft cond-mat.str-el cond-mat.supr-con physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Higher-form symmetries are a valuable tool for classifying topological phases
of matter. However, emergent higher-form symmetries in interacting many-body
quantum systems are not typically exact due to the presence of topological
defects. In this paper, we develop a systematic framework for building
effective theories with approximate higher-form symmetries, i.e. higher-form
symmetries that are weakly explicitly broken. We focus on a continuous U(1)
q-form symmetry and study various patterns of symmetry breaking. This includes
spontaneous or explicit breaking of higher-form symmetries, as well as
pseudo-spontaneous symmetry breaking patterns where the higher-form symmetry is
both spontaneously and explicitly broken. We uncover a web of dualities between
such phases and highlight their role in describing the presence of dynamical
higher-form vortices. In order to study the out-of-equilibrium dynamics of
these phases of matter, we formulate respective hydrodynamic theories and study
the spectra of excitations exhibiting higher-form charge relaxation and
Goldstone relaxation effects. We show that our framework is able to describe
various phase transitions due to proliferation of vortices or defects. This
includes the melting transition in smectic crystals, the plasma phase
transition from polarised gases to magnetohydrodynamics, the spin-ice
transition, the superfluid to neutral fluid transition and the Meissner effect
in superconductors, among many others.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:57:44 GMT""}]","2023-01-24"
"2301.09629","Qiuhong Anna Wei","Qiuhong Anna Wei, Sijie Ding, Jeong Joon Park, Rahul Sajnani, Adrien
  Poulenard, Srinath Sridhar, Leonidas Guibas","LEGO-Net: Learning Regular Rearrangements of Objects in Rooms","Project page: https://ivl.cs.brown.edu/projects/lego-net",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Humans universally dislike the task of cleaning up a messy room. If machines
were to help us with this task, they must understand human criteria for regular
arrangements, such as several types of symmetry, co-linearity or
co-circularity, spacing uniformity in linear or circular patterns, and further
inter-object relationships that relate to style and functionality. Previous
approaches for this task relied on human input to explicitly specify goal
state, or synthesized scenes from scratch -- but such methods do not address
the rearrangement of existing messy scenes without providing a goal state. In
this paper, we present LEGO-Net, a data-driven transformer-based iterative
method for LEarning reGular rearrangement of Objects in messy rooms. LEGO-Net
is partly inspired by diffusion models -- it starts with an initial messy state
and iteratively ''de-noises'' the position and orientation of objects to a
regular state while reducing distance traveled. Given randomly perturbed object
positions and orientations in an existing dataset of professionally-arranged
scenes, our method is trained to recover a regular re-arrangement. Results
demonstrate that our method is able to reliably rearrange room scenes and
outperform other methods. We additionally propose a metric for evaluating
regularity in room arrangements using number-theoretic machinery.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:58:02 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 22:49:15 GMT""}]","2023-03-28"
"2301.09630","Kalina Petrova","Yanitsa Pehova and Kalina Petrova","Embedding loose spanning trees in 3-uniform hypergraphs","23 pages, 3 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1995, Koml\'os, S\'ark\""ozy and Szemer\'edi showed that every large
$n$-vertex graph with minimum degree at least $(1/2 + \gamma)n$ contains all
spanning trees of bounded degree. We consider a generalization of this result
to loose spanning hypertrees in 3-graphs, that is, linear hypergraphs obtained
by successively appending edges sharing a single vertex with a previous edge.
We show that for all $\gamma$ and $\Delta$, and $n$ large, every $n$-vertex
3-uniform hypergraph of minimum vertex degree $(5/9 + \gamma)\binom{n}{2}$
contains every loose spanning tree $T$ with maximum vertex degree $\Delta$.
This bound is asymptotically tight, since some loose trees contain perfect
matchings.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:58:05 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 14:18:41 GMT""}]","2023-04-13"
"2301.09631","Bo\v{s}tjan Vouk","Bo\v{s}tjan Vouk, Matej Guid, Marko Robnik-\v{S}ikonja","Feature construction using explanations of individual predictions","54 pages, 10 figures, 22 tables","Engineering Applications of Artificial Intelligence 120 (2023)
  105823","10.1016/j.engappai.2023.105823",,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Feature construction can contribute to comprehensibility and performance of
machine learning models. Unfortunately, it usually requires exhaustive search
in the attribute space or time-consuming human involvement to generate
meaningful features. We propose a novel heuristic approach for reducing the
search space based on aggregation of instance-based explanations of predictive
models. The proposed Explainable Feature Construction (EFC) methodology
identifies groups of co-occurring attributes exposed by popular explanation
methods, such as IME and SHAP. We empirically show that reducing the search to
these groups significantly reduces the time of feature construction using
logical, relational, Cartesian, numerical, and threshold num-of-N and X-of-N
constructive operators. An analysis on 10 transparent synthetic datasets shows
that EFC effectively identifies informative groups of attributes and constructs
relevant features. Using 30 real-world classification datasets, we show
significant improvements in classification accuracy for several classifiers and
demonstrate the feasibility of the proposed feature construction even for large
datasets. Finally, EFC generated interpretable features on a real-world problem
from the financial industry, which were confirmed by a domain expert.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:01 GMT""}]","2023-01-24"
"2301.09632","Ang Cao","Ang Cao, Justin Johnson","HexPlane: A Fast Representation for Dynamic Scenes","CVPR 2023, Camera Ready Project page:
  https://caoang327.github.io/HexPlane",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Modeling and re-rendering dynamic 3D scenes is a challenging task in 3D
vision. Prior approaches build on NeRF and rely on implicit representations.
This is slow since it requires many MLP evaluations, constraining real-world
applications. We show that dynamic 3D scenes can be explicitly represented by
six planes of learned features, leading to an elegant solution we call
HexPlane. A HexPlane computes features for points in spacetime by fusing
vectors extracted from each plane, which is highly efficient. Pairing a
HexPlane with a tiny MLP to regress output colors and training via volume
rendering gives impressive results for novel view synthesis on dynamic scenes,
matching the image quality of prior work but reducing training time by more
than $100\times$. Extensive ablations confirm our HexPlane design and show that
it is robust to different feature fusion mechanisms, coordinate systems, and
decoding mechanisms. HexPlane is a simple and effective solution for
representing 4D volumes, and we hope they can broadly contribute to modeling
spacetime for dynamic 3D scenes.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:25 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 16:39:58 GMT""}]","2023-03-28"
"2301.09633","Tijana Zrnic","Anastasios N. Angelopoulos, Stephen Bates, Clara Fannjiang, Michael I.
  Jordan, Tijana Zrnic","Prediction-Powered Inference","Code is available at
  https://github.com/aangelopoulos/prediction-powered-inference",,,,"stat.ML cs.AI cs.LG q-bio.QM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce prediction-powered inference $\unicode{x2013}$ a framework for
performing valid statistical inference when an experimental data set is
supplemented with predictions from a machine-learning system. Our framework
yields provably valid conclusions without making any assumptions on the
machine-learning algorithm that supplies the predictions. Higher accuracy of
the predictions translates to smaller confidence intervals, permitting more
powerful inference. Prediction-powered inference yields simple algorithms for
computing valid confidence intervals for statistical objects such as means,
quantiles, and linear and logistic regression coefficients. We demonstrate the
benefits of prediction-powered inference with data sets from proteomics,
genomics, electronic voting, remote sensing, census analysis, and ecology.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:28 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 17:13:48 GMT""},{""version"":""v3"",""created"":""Thu, 16 Feb 2023 06:24:34 GMT""}]","2023-02-17"
"2301.09634","Kevin Wolz","Kevin Wolz, Nicoletta Krachmalnicoff, Luca Pagano","Inference of the optical depth to reionization $\tau$ from
  $\textit{Planck}$ CMB maps with convolutional neural networks","13 pages, 10 figures, 5 tables. Comments welcome",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The optical depth to reionization, $\tau$, is the least constrained parameter
of the cosmological $\Lambda$CDM model. To date, its most precise value is
inferred from large-scale polarized CMB power spectra from the
$\textit{Planck}$ High-Frequency Instrument (HFI). These maps are known to
contain significant contamination by residual non-Gaussian systematic effects,
which are hard to model analytically. Therefore, robust constraints on $\tau$
are currently obtained through an empirical cross-spectrum likelihood built
from simulations. In this paper, we present a likelihood-free inference of
$\tau$ from polarized $\textit{Planck}$ HFI maps which, for the first time, is
fully based on neural networks (NNs). NNs have the advantage of not requiring
an analytical description of the data and can be trained on state-of-the-art
simulations, combining information from multiple channels. By using Gaussian
sky simulations and $\textit{Planck}$ $\texttt{SRoll2}$ simulations, including
CMB, noise, and residual instrumental systematic effects, we train, test and
validate NN models considering different setups. We infer the value of $\tau$
directly from $Q$ and $U$ maps at $\sim 4^\circ$ pixel resolution, without
computing power spectra. On $\textit{Planck}$ data, we obtain $\tau_{\rm
NN}=0.0579\pm 0.0082$, compatible with current $EE$ cross-spectrum results but
with a $\sim30\%$ larger uncertainty, which can be assigned to the inherent
non-optimality of our estimator and to the retraining procedure applied to
avoid biases. While this paper does not improve on current cosmological
constraints on $\tau$, our analysis represents a first robust application of
NN-based inference on real data and highlights its potential as a promising
tool for complementary analysis of near-future CMB experiments, also in view of
the ongoing challenge to achieve a detection of primordial gravitational waves.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:52 GMT""}]","2023-01-24"
"2301.09635","Kadri Yakut","Kutay A. \c{C}okluk, Kadri Yakut and Bruno Giacomazzo","General Relativistic Simulations of High-Mass Binary Neutron Star
  Mergers: rapid formation of low-mass stellar black holes","13 pages, 5 figure, 4 tables, submitted for publication",,,,"astro-ph.HE astro-ph.SR gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Almost 100 compact binary mergers have been detected via gravitational waves
by the LIGO-Virgo-KAGRA collaboration in the past few years providing us with a
significant amount of new information on black holes and neutron stars. In
addition to observations, numerical simulations using newly developed modern
codes in the field of gravitational wave physics will guide us to understand
the nature of single and binary degenerate systems and highly energetic
astrophysical processes. We here present a set of new fully general
relativistic hydrodynamic simulations of high-mass binary neutron star systems
performed with the publicly available Einstein Toolkit and LORENE codes. We
considered systems with a total baryonic mass between 2.8 $M_\odot$ and 4.0
$M_\odot$ and we adopted the SLy equation of state. For all models we analyzed
the gravitational wave signal and we report potential indicators of the systems
undergoing rapid collapse into a black hole that may be observed by
future-planned detectors such as the Einstein Telescope and the Cosmic
Explorer. We also extracted the properties of the post-merger black hole, the
disk and ejecta masses and their dependence on the binary parameters. We also
compare our numerical results with recent analytical fits presented in the
literature and we also provide parameter-dependent semi-analytical relations
between the total mass and mass ratio of the systems and the resulting black
hole masses and spins, coalescence time scale, mass loss, and gravitational
wave energy.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:58 GMT""}]","2023-01-24"
"2301.09636","Maxwell Block","Maxwell Block, Bingtian Ye, Brenden Roberts, Sabrina Chern, Weijie Wu,
  Zilin Wang, Lode Pollet, Emily J. Davis, Bertrand I. Halperin, Norman Y. Yao","A Universal Theory of Spin Squeezing","6 pages, 3 figures + 12 pages, 6 figures",,,,"quant-ph cond-mat.quant-gas cond-mat.str-el physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide extensive numerical and analytic evidence for the following
conjecture: Any Hamiltonian exhibiting finite temperature, easy-plane
ferromagnetism (XY order) can be used to generate scalable spin squeezing, and
thus to perform quantum-enhanced sensing. Our conjecture is guided by a deep
connection between the quantum Fisher information of pure states and the
spontaneous breaking of a continuous symmetry. We demonstrate that
spin-squeezing exhibits a phase diagram with a sharp transition between
scalable squeezing and non-squeezing. This transition coincides with the
equilibrium phase boundary for XY order at a finite temperature. In the
scalable squeezing phase, we predict a sensitivity scaling as $N^{-7/10}$,
between the standard quantum limit, $N^{-1/2}$, and that achieved in all-to-all
coupled easy-plane spin models, $N^{-5/6}$. Our results provide fundamental
insight into the landscape of Hamiltonians that can be used to generate
metrologically useful quantum states.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:59 GMT""}]","2023-01-24"
"2301.09637","Chieh Hubert Lin","Chieh Hubert Lin, Hsin-Ying Lee, Willi Menapace, Menglei Chai,
  Aliaksandr Siarohin, Ming-Hsuan Yang and Sergey Tulyakov","InfiniCity: Infinite-Scale City Synthesis",,,,,"cs.CV cs.AI cs.GR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Toward infinite-scale 3D city synthesis, we propose a novel framework,
InfiniCity, which constructs and renders an unconstrainedly large and
3D-grounded environment from random noises. InfiniCity decomposes the seemingly
impractical task into three feasible modules, taking advantage of both 2D and
3D data. First, an infinite-pixel image synthesis module generates
arbitrary-scale 2D maps from the bird's-eye view. Next, an octree-based voxel
completion module lifts the generated 2D map to 3D octrees. Finally, a
voxel-based neural rendering module texturizes the voxels and renders 2D
images. InfiniCity can thus synthesize arbitrary-scale and traversable 3D city
environments, and allow flexible and interactive editing from users. We
quantitatively and qualitatively demonstrate the efficacy of the proposed
framework. Project page: https://hubert0527.github.io/infinicity/
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:59:59 GMT""}]","2023-01-24"
"2301.09645","Ludovic Scyboz","Keith Hamilton, Alexander Karlberg, Gavin P. Salam, Ludovic Scyboz,
  Rob Verheyen","Matching and event-shape NNDL accuracy in parton showers","42 pages, 14 figures; v2: matches published version",,"10.1007/JHEP03(2023)224",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  To explore the interplay of NLO matching and next-to-leading logarithmic
(NLL) parton showers, we consider the simplest case of $\gamma^*$ and
Higgs-boson decays to $q\bar q$ and $gg$ respectively. Not only should shower
NLL accuracy be retained across observables after matching, but for global
event-shape observables and the two-jet rate, matching can augment the shower
in such a way that it additionally achieves next-to-next-to-double-logarithmic
(NNDL) accuracy, a first step on the route towards general NNLL. As a
proof-of-concept exploration of this question, we consider direct application
of multiplicative matrix-element corrections, as well as simple implementations
of MC@NLO and POWHEG-style matching. We find that the first two
straightforwardly bring NNDL accuracy, and that this can also be achieved with
POWHEG, although particular care is needed in the handover between POWHEG and
the shower. Our study involves both analytic and numerical components and we
also touch on some phenomenological considerations.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 09:19:19 GMT""}]","2023-04-05"
"2301.09646","Matthew Clement","Matthew S. Clement, John E. Chambers, Nathan A. Kaib, Sean N. Raymond,
  Alan P. Jackson","Mercury's formation within the Early Instability Scenario","23 pages, 9 figures, 3 tables, accepted for publication in Icarus",,"10.1016/j.icarus.2023.115445",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The inner solar system's modern orbital architecture provides inferences into
the epoch of terrestrial planet formation; a ~100 Myr time period of planet
growth via collisions with planetesimals and other proto-planets. While classic
numerical simulations of this scenario adequately reproduced the correct number
of terrestrial worlds, their semi-major axes and approximate formation
timescales, they struggled to replicate the Earth-Mars and Venus-Mercury mass
ratios. In a series of past independent investigations, we demonstrated that
Mars' mass is possibly the result of Jupiter and Saturn's early orbital
evolution, while Mercury's diminutive size might be the consequence of a
primordial mass deficit in the region. Here, we combine these ideas in a single
modeled scenario designed to simultaneously reproduce the formation of all four
terrestrial planets and the modern orbits of the giant planets in broad
strokes. By evaluating our Mercury analogs' core mass fractions, masses, and
orbital offsets from Venus, we favor a scenario where Mercury forms through a
series of violent erosive collisions between a number of ~Mercury-mass embryos
in the inner part of the terrestrial disk. We also compare cases where the gas
giants begin the simulation locked in a compact 3:2 resonant configuration to a
more relaxed 2:1 orientation and find the former to be more successful. In 2:1
cases, the entire Mercury-forming region is often depleted due to strong
sweeping secular resonances that also tend to overly excite the orbits of Earth
and Venus as they grow. While our model is quite successful at replicating
Mercury's massive core and dynamically isolated orbit, the planets' low mass
remains extremely challenging to match. Finally, we discuss the merits and
drawbacks of alternative evolutionary scenarios and initial disk conditions.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:00 GMT""}]","2023-02-08"
"2301.09647","Keisuke Harigaya","Marcin Badziak, Keisuke Harigaya","Naturally astrophobic QCD axion","22 pages, 3 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present a QCD axion model where the couplings of the axion to nucleons,
electrons, and muons are naturally suppressed because of the appropriate choice
of the Peccei-Quinn charges of the Standard Model fermions. We reexamine
next-to-leading order corrections to the couplings of the axion with nucleons
and photons and show that the axion decay constant may be as small as $10^7$
GeV. It is also possible to suppress the coupling with the photon so that the
decay constant is even smaller and minimal axiogenesis works. In this scenario,
the axion has a mass above 1 eV and may be directly detected via absorption of
axion dark matter. Flavor-violating axion couplings are generically predicted
in our model, but we show that they may be naturally and sufficiently
suppressed. We discuss the implications of the hints for anomalous cooling in
several stellar environments to our model.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:00 GMT""}]","2023-01-25"
"2301.09648","Enrico Di Teodoro","Enrico M. Di Teodoro, Josh E. G. Peek and John F. Wu","Identification of galaxy shreds in large photometric catalogs using
  Convolutional Neural Networks","Accepted for publication in AJ",,"10.3847/1538-3881/acb53a",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contamination from galaxy fragments, identified as sources, is a major issue
in large photometric galaxy catalogs. In this paper, we prove that this problem
can be easily addressed with computer vision techniques. We use image cutouts
to train a convolutional neural network (CNN) to identify catalogued sources
that are in reality just star formation regions and/or shreds of larger
galaxies. The CNN reaches an accuracy ~98% on our testing datasets. We apply
this CNN to galaxy catalogs from three amongst the largest surveys available
today: the Sloan Digital Sky Survey (SDSS), the DESI Legacy Imaging Surveys and
the Panoramic Survey Telescope and Rapid Response System Survey (Pan-STARSS).
We find that, even when strict selection criteria are used, all catalogs still
show a ~5% level of contamination from galaxy shreds. Our CNN gives a simple
yet effective solution to clean galaxy catalogs from these contaminants.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:00 GMT""}]","2023-03-01"
"2301.09649","Andrew Larkoski","Zhong-Bo Kang, Andrew J. Larkoski, and Jinghong Yang","Understanding Jet Charge","5 pages + 4 pages supplemental material, 5 figures + 16 figures in
  supplemental material; v2: minor clarifications and justification added,
  version accepted to PRL; v3: fixed broken citation links","Phys. Rev. Lett. 130, 151901 (2023)","10.1103/PhysRevLett.130.151901",,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The jet charge is an old observable that has proven uniquely useful for
discrimination of jets initiated by different flavors of light quarks, for
example. In this Letter, we propose an approach to understanding the jet charge
by establishing simple, robust assumptions that hold to good approximation
non-perturbatively, such as isospin conservation and large particle
multiplicity in the jets, forgoing any attempt at a perturbative analysis. From
these assumptions, the jet charge distribution with fixed particle multiplicity
takes the form of a Gaussian by the central limit theorem and whose mean and
variance are related to fractional-power moments of single particle energy
distributions. These results make several concrete predictions for the scaling
of the jet charge with the multiplicity, explaining many of the results already
in the literature, and new results we validate in Monte Carlo simulation.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 18:41:37 GMT""},{""version"":""v3"",""created"":""Fri, 24 Mar 2023 21:39:17 GMT""}]","2023-04-27"
"2301.09650","Damiano Francesco Giuseppe Fiorillo","Damiano F. G. Fiorillo, Georg G. Raffelt","Slow and fast collective neutrino oscillations: Invariants and
  reciprocity","16 pages; typo below Eq. (5) and in Eq. (47) corrected","Phys. Rev. D 107, 043024, 2023","10.1103/PhysRevD.107.043024",,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The flavor evolution of a neutrino gas can show ''slow'' or ''fast''
collective motion. In terms of the usual Bloch vectors to describe the
mean-field density matrices of a homogeneous neutrino gas, the slow two-flavor
equations of motion (EOMs) are
$\dot{\mathbf{P}}_\omega=(\omega\mathbf{B}+\mu\mathbf{P})\times\mathbf{P}_\omega$,
where $\omega=\Delta m^2/2E$, $\mu=\sqrt{2} G_{\mathrm{F}}
(n_\nu+n_{\bar\nu})$, $\mathbf{B}$ is a unit vector in the mass direction in
flavor space, and $\mathbf{P}=\int d\omega\,\mathbf{P}_\omega$. For an
axisymmetric angle distribution, the fast EOMs are
$\dot{\mathbf{D}}_v=\mu(\mathbf{D}_0-v\mathbf{D}_1)\times\mathbf{D}_v$, where
$\mathbf{D}_v$ is the Bloch vector for lepton number, $v=\cos\theta$ is the
velocity along the symmetry axis, $\mathbf{D}_0=\int dv\,\mathbf{D}_v$, and
$\mathbf{D}_1=\int dv\,v\mathbf{D}_v$. We discuss similarities and differences
between these generic cases. Both systems can have pendulum-like instabilities
(soliton solutions), both have similar Gaudin invariants, and both are
integrable in the classical and quantum case. Describing fast oscillations in a
frame comoving with $\mathbf{D}_1$ (which itself may execute pendulum-like
motions) leads to transformed EOMs that are equivalent to an abstract slow
system. These conclusions carry over to three flavors.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 09:09:25 GMT""}]","2023-03-14"
"2301.09651","Peter Denton","Hooman Davoudiasl and Peter B. Denton","Sterile Neutrino Shape-shifting Caused by Dark Matter","9 pages, 1 figure, 2 tables, error in the predicted sum of neutrino
  masses corrected, general conclusions unchanged; new discussions added",,,,"hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Light sterile neutrinos with a mass of $\sim 1$ eV continue to be interesting
due to multiple hints from terrestrial experiments. This simple hypothesis
suffers from strong astrophysical constraints, in particular from the early
universe as well as solar neutrinos. We develop a novel cosmologically viable
proposal consistent with the terrestrial hints, as well as solar constraints,
by sourcing the sterile neutrino's mass from ordinary matter via an ultralight
scalar $\phi$ which can also be the dark matter. In this scenario, the
experimentally implied $\sim 1$ eV sterile neutrino mass is a local value and
changes throughout spacetime.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 23:23:38 GMT""}]","2023-02-13"
"2301.09652","Nina Akerman","Nina Akerman, Stephanie Tonnesen, Bianca M. Poggianti, Rory Smith,
  Antonino Marasco","How Ram Pressure Drives Radial Gas Motions in the Surviving Disk","26 pages, 17 figures, accepted to ApJ",,"10.3847/1538-4357/acbf4d",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Galaxy evolution can be dramatically affected by the environment, especially
by the dense environment of a galaxy cluster. Recent observational studies show
that massive galaxies undergoing strong ram pressure stripping (RPS) also show
an enhanced frequency of nuclear activity. Here, we investigate this topic
using a suite of wind-tunnel hydrodynamical simulations of an individual
massive $M_\text{star} = 10^{11} M_\odot$ disk galaxy with 39 pc resolution and
including star formation and stellar feedback. We find that RPS increases the
inflow of gas to the galaxy centre regardless of the wind impact angle. This
increase is driven by the mixing of interstellar and non-rotating intracluster
media at all wind angles, and by increased torque on the inner disk gas, mainly
from local pressure gradients when the ICM wind has an edge-on component. In
turn, the increase in pressure torques is driven by rising gradient of ram
pressure. We estimate the black hole (BH) accretion using Bondi-Hoyle and
torque models, and compare it with the mass flux in the central 140 pc region.
We find that the torque model estimates much less accretion onto the BH of a
RPS galaxy than the Bondi-Hoyle estimator. However, we argue that both models
are incomplete because the commonly used torque model does not account for
torques caused by the gas distribution or local pressure gradients and the
Bondi-Hoyle estimator depends on the the sound speed of the hot gas, which
includes the ICM in stripped galaxies, thus a new estimator would be required.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 08:32:15 GMT""}]","2023-05-03"
"2301.09653","Paolo Saracco","Paolo Saracco, Francesco La Barbera, Roberto De Propris, Davide
  Bevacqua, Danilo Marchesini, Gabriella De Lucia, Fabio Fontanot, Michaela
  Hirschmann, Mario Nonino, Anna Pasquali, Chiara Spiniello, Crescenzo Tortora","The star formation history and the nature of the mass-metallicity
  relation of passive galaxies at 1.0<z<1.4 from VANDELS","18 pages + Appendix, 16 figures, 5 tables. Accepted for publication
  in MNRAS",,"10.1093/mnras/stad241",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derived stellar ages and metallicities [Z/H] for $\sim$70 passive early
type galaxies (ETGs) selected from VANDELS survey over the redshift range
1.0$<$$z$$<$1.4 and stellar mass range 10$<$log(M$_*$/M$_\odot$)$<$11.6. We
find significant systematics in their estimates depending on models and
wavelength ranges considered. Using the full-spectrum fitting technique, we
find that both [Z/H] and age increase with mass as for local ETGs. Age and
metallicity sensitive spectral indices independently confirm these trends.
According to EMILES models, for 67 per cent of the galaxies we find
[Z/H]$>$0.0, a percentage which rises to $\sim$90 per cent for
log(M$_*$/M$_\odot$)$>$11 where the mean metallicity is [Z/H]=0.17$\pm$0.1. A
comparison with homogeneous measurements at similar and lower redshift does not
show any metallicity evolution over the redshift range 0.0<z<1.4. The derived
star formation (SF) histories show that the stellar mass fraction formed at
early epoch increases with the mass of the galaxy. Galaxies with
log(M$_*$/M$_\odot$)$>$11.0 host stellar populations with [Z/H]>0.05, formed
over short timescales ($\Delta{t50}$$<$1 Gyr) at early epochs (t$_{form}$$<$2
Gyr), implying high star formation rates (SFR$>$100 M$_\odot$/yr) in high mass
density regions (log($\Sigma_{1kpc}$)$>$10 M$_\odot$/kpc$^2$). This sharp
picture tends to blur at lower masses: log(M$_*$/M$_\odot$)$\sim$10.6 galaxies
can host either old stars with [Z/H]$<$0.0 or younger stars with [Z/H]$>$0.0,
depending on the duration ($\Delta{t50}$) of the SF. The relations between
galaxy mass, age and metallicities are therefore largely set up ab initio as
part of the galaxy formation process. Mass, SFR and SF time-scale all
contribute to shape up the stellar mass-metallicity relation with the mass that
modulates metals retention.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:01 GMT""}]","2023-02-01"
"2301.09654","Artem Sabourov","A. V. Glushkov, M. I. Pravdin, A. V. Sabourov","Energy Spectrum of Ultrahigh-Energy Cosmic Rays according to Data from
  Ground-Based Scintillation Detectors of the Yakutsk EAS Array","15 pages, 6 figures, 2 tables","Physics of Atomic Nuclei, V.81 p.575 (2018)","10.1134/S106377881804004X",,"astro-ph.HE hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Results obtained from an analysis of the energy spectrum of cosmic rays with
energies in the region of $E_0 \ge 10^{17}$ eV over the period of continuous
observations from 1974 to 2017 are presented. A refined expression for
estimating the primary-particle energy is used for individual events. This
expression is derived from calculations aimed at determining the responses of
the ground-based and underground scintillation detectors of the Yakutsk array
for studying extensive air showers (EAS) and performed within the QGSJET01,
QGSJET-II-04, SIBYLL-2.1, and EPOS-LHC models by employing the CORSIKA code
package. The new estimate of $E_0$ is substantially lower than its counterpart
used earlier.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:01 GMT""}]","2023-01-25"
"2301.09655","Florian List","Florian List and Oliver Hahn","Perturbation-theory informed integrators for cosmological simulations","39 + 4 pages, 10 + 3 figures. Comments are very welcome!",,,,"astro-ph.CO astro-ph.IM physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large-scale cosmological simulations are an indispensable tool for modern
cosmology. To enable model-space exploration, fast and accurate predictions are
critical. In this paper, we show that the performance of such simulations can
be further improved with time-stepping schemes that use input from cosmological
perturbation theory. Specifically, we introduce a class of time-stepping
schemes derived by matching the particle trajectories in a single
leapfrog/Verlet drift-kick-drift step to those predicted by Lagrangian
perturbation theory (LPT). As a corollary, these schemes exactly yield the
analytic Zel'dovich solution in 1D in the pre-shell-crossing regime (i.e.
before particle trajectories cross). One representative of this class is the
popular FastPM scheme by Feng et al. 2016, which we take as our baseline. We
then construct more powerful LPT-inspired integrators and show that they
outperform FastPM and standard integrators in fast simulations in two and three
dimensions with $\mathcal{O}(1 - 100)$ timesteps, requiring less steps to
accurately reproduce the power spectrum and bispectrum of the density field.
Furthermore, we demonstrate analytically and numerically that, for any
integrator, higher-order convergence cannot be achieved in the
post-shell-crossing regime, owing to the lacking regularity of the acceleration
field. Also, we study the impact of the timestep spacing and of a decaying mode
present in the initial conditions. Importantly, we find that symplecticity of
the integrator plays a minor role for fast approximate simulations with a small
number of timesteps.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:02 GMT""}]","2023-01-25"
"2301.09656","Vivian Lai","Vivian Lai, Yiming Zhang, Chacha Chen, Q. Vera Liao, Chenhao Tan","Selective Explanations: Leveraging Human Input to Align Explainable AI","21 pages, 25 figures",,,,"cs.AI cs.CL cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While a vast collection of explainable AI (XAI) algorithms have been
developed in recent years, they are often criticized for significant gaps with
how humans produce and consume explanations. As a result, current XAI
techniques are often found to be hard to use and lack effectiveness. In this
work, we attempt to close these gaps by making AI explanations selective -- a
fundamental property of human explanations -- by selectively presenting a
subset from a large set of model reasons based on what aligns with the
recipient's preferences. We propose a general framework for generating
selective explanations by leveraging human input on a small sample. This
framework opens up a rich design space that accounts for different selectivity
goals, types of input, and more. As a showcase, we use a decision-support task
to explore selective explanations based on what the decision-maker would
consider relevant to the decision task. We conducted two experimental studies
to examine three out of a broader possible set of paradigms based on our
proposed framework: in Study 1, we ask the participants to provide their own
input to generate selective explanations, with either open-ended or
critique-based input. In Study 2, we show participants selective explanations
based on input from a panel of similar users (annotators). Our experiments
demonstrate the promise of selective explanations in reducing over-reliance on
AI and improving decision outcomes and subjective perceptions of the AI, but
also paint a nuanced picture that attributes some of these positive effects to
the opportunity to provide one's own input to augment AI explanations. Overall,
our work proposes a novel XAI framework inspired by human communication
behaviors and demonstrates its potentials to encourage future work to better
align AI explanations with human production and consumption of explanations.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:02 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 18:00:37 GMT""}]","2023-05-26"
"2301.09657","Simona Mei","Kirill Grishin, Simona Mei, St\'ephane Ilic","YOLO-CL: Galaxy cluster detection in the SDSS with deep machine learning","14 pages, 12 figures. A&A, submitted",,,,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  (Abridged) Galaxy clusters are a powerful probe of cosmological models. Next
generation large-scale optical and infrared surveys will reach unprecedented
depths over large areas and require highly complete and pure cluster catalogs,
with a well defined selection function. We have developed a new cluster
detection algorithm YOLO-CL, which is a modified version of the
state-of-the-art object detection deep convolutional network YOLO, optimized
for the detection of galaxy clusters. We trained YOLO-CL on color images of the
redMaPPer cluster detections in the SDSS. We find that YOLO-CL detects
$95-98\%$ of the redMaPPer clusters, with a purity of $95-98\%$ calculated by
applying the network to SDSS blank fields. When compared to the MCXC2021 X-ray
catalog in the SDSS footprint,YOLO-CL is more complete then redMaPPer, which
means that the neural network improved the cluster detection efficiency of its
training sample. The YOLO-CL selection function is approximately constant with
redshift, with respect to the MCXC2021 cluster mean X-ray surface brightness.
YOLO-CL shows high performance when compared to traditional detection
algorithms applied to SDSS. Deep learning networks benefit from a strong
advantage over traditional galaxy cluster detection techniques because they do
not need galaxy photometric and photometric redshift catalogs. This eliminates
systematic uncertainties that can be introduced during source detection, and
photometry and photometric redshift measurements. Our results show that YOLO-CL
is an efficient alternative to traditional cluster detection methods. In
general, this work shows that it is worth exploring the performance of deep
convolution networks for future cosmological cluster surveys, such as the
Rubin/LSST, Euclid or the Roman Space Telescope surveys.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:02 GMT""}]","2023-01-25"
"2301.09658","Prathyush Prasanth Poduval","Prathyush P. Poduval, Katharina Laubscher, and Sankar Das Sarma","Apparent Kondo effect in Moir\'e TMD bilayers: Heavy fermions or
  disorder?","7 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent work by Zhao et al. [1] reports the realization of a synthetic Kondo
lattice in a gate-tunable Moir\'e TMD bilayer system. The observation of a
Kondo lattice is supported by a plateau (or dip, depending on filling) in the
temperature dependence of the resistivity $\rho(T)$ around $T^*\sim 40~$K,
which is interpreted as the Kondo temperature scale, and an apparent
enhancement of carrier mass extracted from the low-temperature resistivity
data, indicating the emergence of `heavy fermions'. The latter observation is
crucially based on the assumption that the primary resistive scattering
mechanism is Umklapp electron-electron scattering in the underlying Fermi
liquid. In this work, we analyze the experimental data under the assumption
that the primary resistive scattering mechanism is not electron-electron
scattering, but Coulomb scattering by random quenched charged impurities and
phonon scattering. We show that a combination of impurity and phonon scattering
is a plausible alternative explanation for the observed resistivity that can
describe the key features of the experimental data, even if no Kondo lattice
has formed, indicating that further theoretical and experimental work is needed
to conclusively verify the formation of a Kondo lattice in Ref. [1].
  [1] W. Zhao, B. Shen, Z. Tao, Z. Han, K. Kang, K. Watanabe, T. Taniguchi, K.
F. Mak, and J. Shan, arXiv:2211.00263 (2022).
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:02 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 16:29:03 GMT""}]","2023-02-08"
"2301.09659","Hiddo Algera","Hiddo Algera, Hanae Inami, Laura Sommovigo, Yoshinobu Fudamoto,
  Raffaella Schneider, Luca Graziani, Pratika Dayal, Rychard Bouwens, Manuel
  Aravena, Elisabete da Cunha, Andrea Ferrara, Alexander Hygate, Ivana van
  Leeuwen, Ilse De Looze, Marco Palla, Andrea Pallottini, Renske Smit, Mauro
  Stefanon, Michael Topping, Paul van der Werf","Cold Dust and Low [OIII]/[CII] Ratios: an Evolved Star-forming
  Population at Redshift 7","18 pages + appendices; 8 figures in main text; Submitted to MNRAS on
  27 Dec 2022",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new ALMA Band 8 (rest-frame $90\,\mu$m) observations of three
massive ($M_\star \approx 10^{10}\,M_\odot$) galaxies at $z\approx7$ previously
detected in [CII]$158\,\mu$m and underlying dust continuum emission in the
Reionization Era Bright Emission Line Survey (REBELS). We detect the dust
continuum emission of two of our targets in Band 8 (REBELS-25 and REBELS-38),
while REBELS-12 remains undetected. Through modified blackbody fitting we
determine cold dust temperatures ($T_\mathrm{dust} \approx 30 - 35\,$K) in both
of the dual-band detected targets, given a fiducial model of optically thin
emission with $\beta = 2.0$. Their dust temperatures are lower than most
$z\sim7$ galaxies in the literature, and consequently their dust masses are
higher ($M_\mathrm{dust} \approx 10^{8}\,M_\odot$). Nevertheless, these large
dust masses are still consistent with predictions from models of dust
production in the early Universe. In addition, we target and detect
[OIII]$88\,\mu$m emission in both REBELS-12 and REBELS-25, and find
$L_\mathrm{[OIII]} / L_\mathrm{[CII]}$ ratios of approximately unity, low
compared to the $L_\mathrm{[OIII]} / L_\mathrm{[CII]} \gtrsim 2 - 10$ observed
in the known $z\gtrsim6$ population thus far. We argue the lower line ratios
are due to a comparatively weaker ionizing radiation field resulting from the
less starbursty nature of our targets. This low burstiness supports the cold
dust temperatures and below average $\mathrm{[OIII]}\lambda\lambda4959,5007 +
\mathrm{H}\beta$ equivalent widths of REBELS-25 and REBELS-38, compared to the
known high-redshift population. Overall, this provides evidence for the
existence of a massive, dust-rich galaxy population at $z\approx7$ which has
previously experienced vigorous star formation, but is currently forming stars
in a steady, as opposed to bursty, manner.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:02 GMT""}]","2023-01-25"
"2301.09660","Romanczukiewicz Tomasz Ph.D.","N.S. Manton and T. Roma\'nczukiewicz","The Simplest Oscillon and its Sphaleron","26 pages, 18 figures",,"10.1103/PhysRevD.107.085012",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  Oscillons in a simple, 1-dimensional scalar field theory with a cubic
potential are discussed. The theory has a classical sphaleron, whose decay
generates a version of the oscillon. A good approximation to the
small-amplitude oscillon is constructed explicitly using the asymptotic
expansion of Fodor et al., but for larger amplitudes a better approximation
uses the discrete, unstable and stable deformation modes of the sphaleron.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:09 GMT""}]","2023-04-26"
"2301.09661","Harlan Campbell","Harlan Campbell, Julie E Park, Jeroen P Jansen, Shannon Cope","Estimating marginal treatment effects from single studies and indirect
  treatment comparisons: When are standardization-based methods preferable to
  inverse probability of treatment weighting?","33 pages",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  In light of newly developed standardization methods, we evaluate, via
simulation study, how inverse probability of treatment weighting (IPTW) and
standardization-based approaches compare for obtaining estimates of the
marginal odds-ratio and the marginal hazards ratio. Specifically, we consider
how the two approaches compare in two different scenarios: (1) in a single
comparative study (either randomized or non-randomized), and (2) in an anchored
indirect treatment comparison of randomized controlled trials (where we compare
the matching-adjusted indirect comparison (MAIC) and simulated treatment
comparison (STC) methods). We conclude that, in general, standardization-based
methods with correctly specified outcome models are more efficient than those
based on IPTW. While IPTW is robust to model misspecification in a single
comparative study, we find that this is not necessarily the case for MAIC in an
indirect treatment comparison.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:40 GMT""},{""version"":""v2"",""created"":""Sat, 4 Mar 2023 00:51:39 GMT""}]","2023-03-07"
"2301.09662","Hariharan Krishnan","Hariharan Krishnan (1), Adam P. Beardsley (2), Judd D. Bowman (1),
  Jayce Dowell (3), Matthew Kolopanis (1), Greg Taylor (3) and Nithyanandan
  Thyagarajan (4) ((1) School of Earth and Space Exploration, Arizona State
  University, Tempe, AZ 85287, (2) Department of Physics, Winona State
  University, Winona, MN 55987, (3) Department of Physics and Astronomy,
  University of New Mexico, 210 Yale Blvd NE, Albuquerque, NM 87106, USA, (4)
  Commonwealth Scientific and Industrial Research Organisation (CSIRO), Space &
  Astronomy, P. O. Box 1130, Bentley, WA 6102, Australia)","Optimization and Commissioning of the EPIC Commensal Radio Transient
  Imager for the Long Wavelength Array",,,"10.1093/mnras/stad263",,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Next generation aperture arrays are expected to consist of hundreds to
thousands of antenna elements with substantial digital signal processing to
handle large operating bandwidths of a few tens to hundreds of MHz.
Conventionally, FX~correlators are used as the primary signal processing unit
of the interferometer. These correlators have computational costs that scale as
$\mathcal{O}(N^2)$ for large arrays. An alternative imaging approach is
implemented in the E-field Parallel Imaging Correlator (EPIC) that was recently
deployed on the Long Wavelength Array station at the Sevilleta National
Wildlife Refuge (LWA-SV) in New Mexico. EPIC uses a novel architecture that
produces electric field or intensity images of the sky at the angular
resolution of the array with full or partial polarization and the full spectral
resolution of the channelizer. By eliminating the intermediate
cross-correlation data products, the computational costs can be significantly
lowered in comparison to a conventional FX~or XF~correlator from
$\mathcal{O}(N^2)$ to $\mathcal{O}(N \log N)$ for dense (but otherwise
arbitrary) array layouts. EPIC can also lower the output data rates by directly
yielding polarimetric image products for science analysis. We have optimized
EPIC and have now commissioned it at LWA-SV as a commensal all-sky imaging
back-end that can potentially detect and localize sources of impulsive radio
emission on millisecond timescales. In this article, we review the architecture
of EPIC, describe code optimizations that improve performance, and present
initial validations from commissioning observations. Comparisons between EPIC
measurements and simultaneous beam-formed observations of bright sources show
spectral-temporal structures in good agreement.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:53 GMT""}]","2023-02-01"
"2301.09663","Noah Vowell","Noah Vowell, Joseph E. Rodriguez, Samuel N. Quinn, George Zhou, Andrew
  Vanderburg, Andrew W. Mann, Matthew J. Hooton, Keivan G. Stassun, Saburo
  Howard, Allyson Bieryla, David W. Latham, Steve B. Howell, Tristan Guillot,
  Carl Ziegler, Karen A. Collins, Theron W. Carmichael, Jon M. Jenkins, Avi
  Shporer, Lyu ABE, Philippe Bendjoya, Jonathan L. Bush, Marco Buttu, Kevin I.
  Collins, Jason D. Eastman, Matthew J. Fields, Thomas Gasparetto, Maximilian
  N. G\""unther, Veselin B. Kostov, Adam L. Kraus, Kathryn V. Lester, Alan M.
  Levine, Colin Littlefield, Wenceslas Marie-Saint, Djamel M\'ekarnia, Hugh P.
  Osborn, David Rapetti, George R. Ricker, S. Seager, Gregor Srdoc, Olga
  Suarez, Guillermo Torres, Amaury H.M.J. Triaud, R. Vanderspek, Joshua N. Winn","HIP 33609 b: An Eccentric Brown Dwarf Transiting a V=7.3 Rapidly
  Rotating B-Star","16 pages, 5 figures, 4 tables, Submitted to AAS Journals",,,,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the discovery and characterization of HIP 33609 b, a transiting
warm brown dwarf orbiting a late B star, discovered by NASA's Transiting
Exoplanet Survey Satellite TESS as TOI-588 b. HIP 33609 b is a large (R$_{b}$ =
1.580$_{-0.070}^{+0.074}$ R$_{J}$) brown dwarf on a highly eccentric (e =
0.560$_{-0.031}^{+0.029}$) orbit with a 39-day period. The host star is a
bright (V = 7.3 mag), T$_{eff}$ = 10,400$_{-660}^{+800}$ K star with a mass of
M$_{*}$ = 2.383$_{-0.095}^{+0.10}$ M$_{\odot}$ and radius of R$_{*}$ =
1.863$_{-0.082}^{+0.087}$ R$_{\odot}$, making it the hottest transiting brown
dwarf host star discovered to date. We obtained radial velocity measurements
from the CHIRON spectrograph confirming the companion's mass of M$_{b}$ =
68.0$_{-7.1}^{+7.4}$ M$_{J}$ as well as the host star's rotation rate
($vsini_{*} = 55.6 \pm 1.8$ km/s). We also present the discovery of a new
comoving group of stars, designated as MELANGE-6, and determine that HIP 33609
is a member. We use a combination of rotation periods and isochrone models fit
to the cluster members to estimate an age of 150 $\pm$ 25 Myr. With a measured
mass, radius, and age, HIP 33609 b becomes a benchmark for substellar
evolutionary models.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:59 GMT""}]","2023-01-25"
"2301.09664","Ravi Boppana","Ravi B. Boppana (MIT)","A Useful Inequality for the Binary Entropy Function","4 pages",,,,"math.CO cs.CC cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We provide a simple proof of a curious inequality for the binary entropy
function, an inequality that has been used in two different contexts. In the
1980's, Boppana used this entropy inequality to prove lower bounds on Boolean
formulas. More recently, the inequality was used to achieve major progress on
Frankl's union-closed sets conjecture. Our proof of the entropy inequality uses
basic differential calculus.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:02:37 GMT""}]","2023-01-25"
"2301.09665","Stephen Powell","Neil Wilkins, Stephen Powell","Derivation of field theory for the classical dimer model using
  bosonization","20 pages, 4 figures, 1 table","Phys. Rev. E 107, 054126 (2023)","10.1103/PhysRevE.107.054126",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a field theory for the two-dimensional classical dimer model by
applying bosonization to Lieb's (fermionic) transfer-matrix solution. Our
constructive approach gives results that are consistent with the well-known
height theory, previously justified based on symmetry considerations, but also
fixes coefficients appearing in the effective theory and the relationship
between microscopic observables and operators in the field theory. In addition,
we show how interactions can be included in the field theory perturbatively,
treating the case of the double dimer model with interactions within and
between the two replicas. Using a renormalization-group analysis, we determine
the shape of the phase boundary near the noninteracting point, in agreement
with results of Monte Carlo simulations.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:05:55 GMT""}]","2023-06-01"
"2301.09666","Omkar Dhungel","Omkar Dhungel, Till Lenz, Muhib Omar, Joseph Shaji Rebeirro, Viktor
  Ivady, Adam Gali, Arne Wickenbrock, and Dmitry Budker","Zero-field microwave-free magnetometry with ensembles of
  nitrogen-vacancy centers in diamond","8 pages, 7 figures, 1 table",,,,"cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  We study cross-relaxation features near zero magnetic field with ensembles of
nitrogen-vacancy (NV) centers in diamond and examine their properties in
samples with a range (0.9 ppm - 16.0 ppm) of NV concentrations. The observed
NV-NV cross-relaxation features between differently oriented NV centers in
high-NV-density samples hold promise for a variety of magnetometry applications
where microwave fields (or any bias field) disturb the system under study. We
theoretically determine the values of the bias magnetic fields corresponding to
cross-relaxations between different axes and experimentally validate them. The
behavior of zero-field cross-relaxation features as a function of temperature
is also investigated. The sensitivity of magnetometry based on this method is
determined to be in the 10 nT/sqrt(Hz) range.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:09:22 GMT""}]","2023-01-25"
"2301.09667","Akram Bayat","Amir Ghasemi, Nasrin Bayat, Fatemeh Mottaghian, Akram Bayat","Improving Performance of Object Detection using the Mechanisms of Visual
  Recognition in Humans",,,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Object recognition systems are usually trained and evaluated on high
resolution images. However, in real world applications, it is common that the
images have low resolutions or have small sizes. In this study, we first track
the performance of the state-of-the-art deep object recognition network,
Faster- RCNN, as a function of image resolution. The results reveals negative
effects of low resolution images on recognition performance. They also show
that different spatial frequencies convey different information about the
objects in recognition process. It means multi-resolution recognition system
can provides better insight into optimal selection of features that results in
better recognition of objects. This is similar to the mechanisms of the human
visual systems that are able to implement multi-scale representation of a
visual scene simultaneously. Then, we propose a multi-resolution object
recognition framework rather than a single-resolution network. The proposed
framework is evaluated on the PASCAL VOC2007 database. The experimental results
show the performance of our adapted multi-resolution Faster-RCNN framework
outperforms the single-resolution Faster-RCNN on input images with various
resolutions with an increase in the mean Average Precision (mAP) of 9.14%
across all resolutions and 1.2% on the full-spectrum images. Furthermore, the
proposed model yields robustness of the performance over a wide range of
spatial frequencies.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:09:36 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 16:26:17 GMT""}]","2023-03-15"
"2301.09668","Timothy Berkelbach","Bryan T. G. Lau, Brian Busemeyer, and Timothy C. Berkelbach","Optical properties of defects in solids via quantum embedding with good
  active space orbitals","8 pages, 4 figures",,,,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of isolated defects in solids is a natural target for classical or
quantum embedding methods that treat the defect at a high level of theory and
the rest of the solid at a lower level of theory. Here, in the context of
active-space-based quantum embeddings, we study the performance of three
active-space orbital selection schemes based on canonical (energy-ordered)
orbitals, local orbitals defined in the spirit of density matrix embedding
theory, and approximate natural transition orbitals. Using equation-of-motion
coupled-cluster theory with single and double excitations (CCSD), we apply
these active space selection schemes to the calculation of the vertical singlet
excitation energy of a substitutional carbon dimer defect in hexagonal boron
nitride, an oxygen vacancy in magnesium oxide, and a carbon vacancy in diamond.
Especially when used in combination with a simple composite correction, we find
that the best performing schemes can predict the excitation energy to about
0.1-0.2 eV of its converged value using only a few hundred orbitals, even when
the full supercell has thousands of orbitals, which amounts to
many-orders-of-magnitude computational savings when using correlated electronic
structure theories. When compared to assigned experimental spectra and
accounting for vibrational corrections, we find that CCSD predicts excitation
energies that are accurate to about 0.1-0.3 eV, which is comparable to its
performance in molecules and bulk solids.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:11:12 GMT""}]","2023-01-25"
"2301.09669","Nima Lashkari","Samuel Goldman, Nima Lashkari, Robert G. Leigh, Mudassir Moosa","Exact Renormalization of Wave Functionals yields continuous MERA",,,,,"hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  The exact renormalization group (ERG) is a powerful tool for understanding
the formal properties of field theories. By adapting generalized ERG schemes to
the flow of wavefunctionals, we obtain a large class of continuous unitary
networks, a special case of which includes a class of Gaussian continuous
Multi-scale Renormalization Ansatzes (cMERAs). The novel feature of these
generalized wavefunctional ERG schemes is allowing for modifications of the
dispersion relation, which drastically changes the entanglement structure of
the ultraviolet states.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:11:25 GMT""}]","2023-01-25"
"2301.09670","Paula Izquierdo","Paula Izquierdo, Boris T. G\""ansicke, Pablo Rodr\'iguez-Gil, Detlev
  Koester, Odette Toloza, Nicola P. Gentile Fusillo, Anna F. Pala and
  Pier-Emmanuel Tremblay","Systematic uncertainties in the characterisation of helium-dominated
  metal-polluted white dwarf atmospheres","25 pages, 16 figures, submitted to MNRAS",,"10.1093/mnras/stad282",,"astro-ph.SR astro-ph.EP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  White dwarf photospheric parameters are usually obtained by means of
spectroscopic or photometric analysis. These results are not always consistent
with each other, with the published values often including just the statistical
uncertainties. The differences are more dramatic for white dwarfs with
helium-dominated photospheres, so to obtain realistic uncertainties we have
analysed a sample of 13 of these white dwarfs, applying both techniques to up
to three different spectroscopic and photometric data sets for each star. We
found mean standard deviations of < $\sigma T_{\mathrm{eff}}$ > = 524 K, <
$\sigma \log g$ > = 0.27 dex and < $\sigma \log(\mathrm{H/He})$ > = 0.31 dex
for the effective temperature, surface gravity and relative hydrogen abundance,
respectively, when modelling diverse spectroscopic data. The photometric fits
provided mean standard deviations up to < $\sigma T_{\mathrm{eff}}$ > = 1210 K
and < $\sigma \log g$ > = 0.13 dex. We suggest these values to be adopted as
realistic lower limits to the published uncertainties in parameters derived
from spectroscopic and photometric fits for white dwarfs with similar
characteristics. In addition, we investigate the effect of fitting the
observational data adopting three different photospheric chemical compositions.
In general, pure helium model spectra result in larger $T_{\mathrm{eff}}$
compared to those derived from models with traces of hydrogen. The $\log g$
shows opposite trends: smaller spectroscopic values and larger photometric ones
when compared to models with hydrogen. The addition of metals to the models
also affects the derived atmospheric parameters, but a clear trend is not
found.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:11:42 GMT""}]","2023-02-08"
"2301.09671","Rafael Stern","Gustavo Grivol, Rafael Izbicki, Alex A. Okuno and Rafael B. Stern","Flexible conditional density estimation for time series","19 pages, 7 figures",,,,"stat.ME cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  This paper introduces FlexCodeTS, a new conditional density estimator for
time series. FlexCodeTS is a flexible nonparametric conditional density
estimator, which can be based on an arbitrary regression method. It is shown
that FlexCodeTS inherits the rate of convergence of the chosen regression
method. Hence, FlexCodeTS can adapt its convergence by employing the regression
method that best fits the structure of data. From an empirical perspective,
FlexCodeTS is compared to NNKCDE and GARCH in both simulated and real data.
FlexCodeTS is shown to generally obtain the best performance among the selected
methods according to either the CDE loss or the pinball loss.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:11:43 GMT""}]","2023-01-25"
"2301.09672","Matteo Breschi","Matteo Breschi, Gregorio Carullo, Sebastiano Bernuzzi","Pre/post-merger consistency test for gravitational signals from binary
  neutron star mergers",,,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Gravitational waves from binary neutron star (BNS) mergers can constrain
nuclear matter models predicting the neutron star's equation of state (EOS).
Matter effects on the inspiral-merger signal are encoded in the multipolar
tidal polarizability parameters, whose leading order combination is sufficient
to capture to high accuracy the key features of the merger waveform (e.g.~the
merger frequency). Similar EOS-insensitive relations exist for the post-merger
signal and can be used to model the emission from the remnant. Several works
suggested that the appearance of new degrees of freedom or phase transitions in
high-density post-merger matter can be inferred by observing a violation of
these EOS-insensitive relations. Here, we demonstrate a Bayesian method to test
such an EOS-insensitive relation between the tidal polarizability parameters
(or any other equivalent parameter) and the dominant post-merger frequency,
using information either up to merger or from the post-merger signal.
Technically, the method is similar to tests of General Relativity with binary
black holes that verify the inspiral-merger-ringdown consistency. However,
differently from the latter, BNS pre/post-merger consistency tests are
conceptually less informative and they only address the consistency (or the
breaking) of the assumed EOS-insensitive relation. Specifically, we discuss how
such tests cannot conclusively discriminate between an EOS not respecting such
relation and the appearance of new degrees of freedom (or phase transitions) in
high-density matter.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:12:04 GMT""}]","2023-02-09"
"2301.09674","Christina Giannoula","Christina Giannoula, Kailong Huang, Jonathan Tang, Nectarios Koziris,
  Georgios Goumas, Zeshan Chishti, Nandita Vijaykumar","Architectural Support for Efficient Data Movement in Disaggregated
  Systems","To appear in the Proceedings of the ACM on Measurement and Analysis
  of Computing Systems (POMACS) 2023 and the ACM SIGMETRICS 2023 conference.
  arXiv admin note: text overlap with arXiv:2301.00414",,,,"cs.AR cs.DC cs.PF","http://creativecommons.org/licenses/by/4.0/","  Resource disaggregation offers a cost effective solution to resource scaling,
utilization, and failure-handling in data centers by physically separating
hardware devices in a server. Servers are architected as pools of processor,
memory, and storage devices, organized as independent failure-isolated
components interconnected by a high-bandwidth network. A critical challenge,
however, is the high performance penalty of accessing data from a remote memory
module over the network. Addressing this challenge is difficult as
disaggregated systems have high runtime variability in network
latencies/bandwidth, and page migration can significantly delay critical path
cache line accesses in other pages. This paper introduces DaeMon, the first
software-transparent and robust mechanism to significantly alleviate data
movement overheads in fully disaggregated systems. First, to enable scalability
to multiple hardware components in the system, we enhance each compute and
memory unit with specialized engines that transparently handle data migrations.
Second, to achieve high performance and provide robustness across various
network, architecture and application characteristics, we implement a
synergistic approach of bandwidth partitioning, link compression, decoupled
data movement of multiple granularities, and adaptive granularity selection in
data movements. We evaluate DaeMon in a wide variety of workloads at different
network and architecture configurations using a state-of-the-art accurate
simulator and demonstrate that DaeMon significantly improves system performance
and data access costs over the widely-adopted approach of moving data at page
granularity.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:12:41 GMT""}]","2023-01-25"
"2301.09675","Yiling Luo","Yiling Luo, Yiling Xie, Xiaoming Huo","Improved Rate of First Order Algorithms for Entropic Optimal Transport",,,,,"math.OC stat.ML","http://creativecommons.org/licenses/by/4.0/","  This paper improves the state-of-the-art rate of a first-order algorithm for
solving entropy regularized optimal transport. The resulting rate for
approximating the optimal transport (OT) has been improved from
$\widetilde{{O}}({n^{2.5}}/{\epsilon})$ to $\widetilde{{O}}({n^2}/{\epsilon})$,
where $n$ is the problem size and $\epsilon$ is the accuracy level. In
particular, we propose an accelerated primal-dual stochastic mirror descent
algorithm with variance reduction. Such special design helps us improve the
rate compared to other accelerated primal-dual algorithms. We further propose a
batch version of our stochastic algorithm, which improves the computational
performance through parallel computing. To compare, we prove that the
computational complexity of the Stochastic Sinkhorn algorithm is
$\widetilde{{O}}({n^2}/{\epsilon^2})$, which is slower than our accelerated
primal-dual stochastic mirror algorithm. Experiments are done using synthetic
and real data, and the results match our theoretical rates. Our algorithm may
inspire more research to develop accelerated primal-dual algorithms that have
rate $\widetilde{{O}}({n^2}/{\epsilon})$ for solving OT.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:13:25 GMT""}]","2023-01-25"
"2301.09676","Evgeny Kurbatov P.","E. P. Kurbatov, Ya. N. Pavlyuchenkov","The turbulent convection in protoplanetary disks and its role in the
  angular momentum transfer","Submitted to MNRAS | 12 pages, 4 figures",,,,"astro-ph.SR astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model for the transport of anisotropic turbulence in an accretion disk is
presented. This model is based on the mean field approximation and is designed
to study turbulence of various nature and its role in the redistribution of the
angular momentum of the accretion disk. The mean field approach makes it
possible to take into account various types of instabilities by adding
appropriate sources in the form of moments of fluctuations of hydrodynamic
quantities. We used the model to study the role of convective instability in a
gaseous and dusty circumstellar disk in the framework of a one-dimensional
approximation. To do this, it was combined with the calculation of radiative
transfer and with the calculation of the convective flow in the mixing length
theory approximation. Within this framework, we confirm the conclusions of
other authors that the turbulence generated by convection does not provide the
observable disk accretion rates and sufficient heat source for which convection
would be self-sustaining. The reasons for this are the strong anisotropy of
turbulence in the disk, as well as the fact that convection turns out to be too
weak source for turbulence.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:14:41 GMT""}]","2023-01-25"
"2301.09677","Es-said En-naoui","Es-said En-naoui","Study of the generalized von mangoldt function defined by L-additive
  function","14 pages",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  The main object of this paper is to study the generalized von mangoldt
function using the L-additive function, which can help us give many result
about the classical arithmetic function.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:17:17 GMT""}]","2023-01-25"
"2301.09678","Denver Strong","Denver Strong and R. J. Cava","Superconductivity in the Face Centered Cubic $\rm
  W_{n-x}Mo_{x}RhIrPt_{2}$ High Entropy Alloy","18 pages, 2 tables, 6 figures excluding supplemental information.
  Supplemental information included at end",,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report single phase superconducting face centered cubic (FCC) high entropy
alloys (HEAs) synthesized via splat cooling. The single phase materials fall at
electron counts in the HEA superconductor alloy family where structural
stability and optimal superconducting electron counts clash. The materials'
superconducting properties follow the general trends published for metallic
alloys. Many of the superconducting characteristics are summarized. Insights
are provided as to why an FCC structure may be stable.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:17:39 GMT""}]","2023-01-25"
"2301.09679","Raghav Govind Jha","Raghav G. Jha","Notes on Quantum Computation and Information","v2: 86 pages, 97 references. Refined the text, fixed several typos,
  added some text on continuous variables, and added few solved example
  problems. v1: 72 pages, 76 references. Suggestions, comments, and corrections
  are very welcome!",,,,"quant-ph hep-lat physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We discuss fundamentals of quantum computing and information - quantum gates,
circuits, algorithms, theorems, error correction, and provide collection of
QISKIT programs and exercises for the interested reader.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:18:43 GMT""},{""version"":""v2"",""created"":""Fri, 19 May 2023 04:50:50 GMT""}]","2023-05-22"
"2301.09680","Yulian Wu","Yulian Wu, Chaowen Guan, Vaneet Aggarwal and Di Wang","Quantum Heavy-tailed Bandits","Online learning; Quantum machine learning",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study multi-armed bandits (MAB) and stochastic linear
bandits (SLB) with heavy-tailed rewards and quantum reward oracle. Unlike the
previous work on quantum bandits that assumes bounded/sub-Gaussian
distributions for rewards, here we investigate the quantum bandits problem
under a weaker assumption that the distributions of rewards only have bounded
$(1+v)$-th moment for some $v\in (0,1]$. In order to achieve regret
improvements for heavy-tailed bandits, we first propose a new quantum mean
estimator for heavy-tailed distributions, which is based on the Quantum Monte
Carlo Mean Estimator and achieves a quadratic improvement of estimation error
compared to the classical one. Based on our quantum mean estimator, we focus on
quantum heavy-tailed MAB and SLB and propose quantum algorithms based on the
Upper Confidence Bound (UCB) framework for both problems with
$\Tilde{O}(T^{\frac{1-v}{1+v}})$ regrets, polynomially improving the dependence
in terms of $T$ as compared to classical (near) optimal regrets of
$\Tilde{O}(T^{\frac{1}{1+v}})$, where $T$ is the number of rounds. Finally,
experiments also support our theoretical results and show the effectiveness of
our proposed methods.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:23:10 GMT""}]","2023-01-25"
"2301.09681","Nicholas Sherman","Nicholas E. Sherman, Alexander Avdoshkin, Joel E. Moore","Universality of critical dynamics with finite entanglement",,,,,"quant-ph cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When a system is swept through a quantum critical point, the quantum
Kibble-Zurek mechanism makes universal predictions for quantities such as the
number and energy of excitations produced. This mechanism is now being used to
obtain critical exponents on emerging quantum computers and emulators, which in
some cases can be compared to Matrix Product State (MPS) numerical studies.
However, the mechanism is modified when the divergence of entanglement entropy
required for a faithful description of many quantum critical points is not
fully captured by the experiment or classical calculation. In this work, we
study how low-energy dynamics of quantum systems near criticality are modified
by finite entanglement, using conformally invariant critical points described
approximately by an MPS as an example. We derive that the effect of finite
entanglement on a Kibble-Zurek process is captured by a dimensionless scaling
function of the ratio of two length scales, one determined dynamically and one
by the entanglement restriction. Numerically we confirm first that dynamics at
finite bond dimension $\chi$ is independent of the algorithm chosen, then
obtain scaling collapses for sweeps in the transverse field Ising model and the
3-state Potts model. Our result establishes the precise role played by
entanglement in time-dependent critical phenomena and has direct implications
for quantum state preparation and classical simulation of quantum states.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:23:54 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 20:12:55 GMT""},{""version"":""v3"",""created"":""Tue, 7 Feb 2023 21:17:11 GMT""}]","2023-02-09"
"2301.09682","Rodrigo Falc\~ao","Rodrigo Falc\~ao, Raghad Matar, Bernd Rauch","Using I4.0 digital twins in agriculture",,,,,"cs.OH cs.CY cs.SE","http://creativecommons.org/licenses/by/4.0/","  Agriculture is a huge domain where an enormous landscape of systems interact
to support agricultural processes, which are becoming increasingly digital.
From the perspective of agricultural service providers, a prominent challenge
is interoperability. In the Fraunhofer lighthouse project Cognitive Agriculture
(COGNAC), we investigated how the usage of Industry 4.0 digital twins (I4.0
DTs) can help overcome this challenge. This paper contributes architecture
drivers and a solution concept using I4.0 DTs in the agricultural domain.
Furthermore, we discuss the opportunities and limitations offered by I4.0 DTs
for the agricultural domain.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:24:01 GMT""}]","2023-01-25"
"2301.09683","H. Blaine Lawson Jr.","H. Blaine Lawson","Spin$^h$ Manifolds",,"SIGMA 19 (2023), 012, 7 pages","10.3842/SIGMA.2023.012",,"math.DG math.AT","http://creativecommons.org/licenses/by-sa/4.0/","  The concept of a ${\rm Spin}^h$-manifold, which is a cousin of Spin- and
${\rm Spin}^c$-manifolds, has been at the center of much research in recent
years. This article discusses some of the highlights of this story.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:24:14 GMT""},{""version"":""v2"",""created"":""Sun, 19 Mar 2023 09:56:45 GMT""}]","2023-03-21"
"2301.09684","Luca Razzoli","Fabio Cavaliere, Luca Razzoli, Matteo Carrega, Giuliano Benenti, Maura
  Sassetti","Hybrid quantum thermal machines with dynamical couplings","Original submitted version of the manuscript: 14 pages, 5(+1) color
  figures","iScience 26, 106235 (2023)","10.1016/j.isci.2023.106235",,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Quantum thermal machines can perform useful tasks, such as delivering power,
cooling, or heating. In this work, we consider hybrid thermal machines, that
can execute more than one task simultaneously. We characterize and find optimal
working conditions for a three-terminal quantum thermal machine, where the
working medium is a quantum harmonic oscillator, coupled to three heat baths,
with two of the couplings driven periodically in time. We show that it is
possible to operate the thermal machine efficiently, in both pure and hybrid
modes, and to switch between different operational modes simply by changing the
driving frequency. Moreover, the proposed setup can also be used as a
high-performance transistor, in terms of output--to--input signal and
differential gain. Due to its versatility and tunability, our model may be of
interest for engineering thermodynamic tasks and for thermal management in
quantum technologies.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:26:09 GMT""}]","2023-03-07"
"2301.09685","Ruoyu Xie","Ruoyu Xie, Antonios Anastasopoulos","Noisy Parallel Data Alignment","EACL 2023 camera-ready version","Findings of the 17th Conference of the European Chapter of the
  Association for Computational Linguistics (EACL 2023)",,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An ongoing challenge in current natural language processing is how its major
advancements tend to disproportionately favor resource-rich languages, leaving
a significant number of under-resourced languages behind. Due to the lack of
resources required to train and evaluate models, most modern language
technologies are either nonexistent or unreliable to process endangered, local,
and non-standardized languages. Optical character recognition (OCR) is often
used to convert endangered language documents into machine-readable data.
However, such OCR output is typically noisy, and most word alignment models are
not built to work under such noisy conditions. In this work, we study the
existing word-level alignment models under noisy settings and aim to make them
more robust to noisy data. Our noise simulation and structural biasing method,
tested on multiple language pairs, manages to reduce the alignment error rate
on a state-of-the-art neural-based alignment model up to 59.6%.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:26:34 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 17:21:23 GMT""}]","2023-02-13"
"2301.09686","Matt Thomas","Matt Thomas, Michele Trenti, Riccardo Campana, Giancarlo Ghirlanda,
  Jakub Ripa, Luciano Burderi, Fabrizio Fiore, Yuri Evangelista, Lorenzo Amati,
  Simon Barraclough, Katie Auchettl, Miguel Ortiz del Castillo, Airlie Chapman,
  Marco Citossi, Andrea Colagrossi, Giuseppe Dilillo, Nicola Deiosso, Evgeny
  Demenev, Francesco Longo, Alessio Marino, Jack McRobbie, Robert Mearns,
  Andrea Melandri, Alessandro Riggio, Tiziana Di Salvo, Puccetti Simonetta,
  Martin Topinka","Localisation of gamma-ray bursts from the combined SpIRIT+HERMES-TP/SP
  nano-satellite constellation","17 pages, 10 figures, 1 table. Accepted for publication in PASA",,"10.1017/pasa.2023.4",,"astro-ph.HE astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Multi-messenger observations of the transient sky to detect cosmic explosions
and counterparts of gravitational wave mergers critically rely on orbiting
wide-FoV telescopes to cover the wide range of wavelengths where atmospheric
absorption and emission limit the use of ground facilities. Thanks to
continuing technological improvements, miniaturised space instruments operating
as distributed-aperture constellations are offering new capabilities for the
study of high energy transients to complement ageing existing satellites. In
this paper we characterise the performance of the upcoming joint SpIRIT +
HERMES-TP/SP nano-satellite constellation for the localisation of high-energy
transients through triangulation of signal arrival times. SpIRIT is an
Australian technology and science demonstrator satellite designed to operate in
a low-Earth Sun-synchronous Polar orbit that will augment the science
operations for the equatorial HERMES-TP/SP. In this work we simulate the
improvement to the localisation capabilities of the HERMES-TP/SP when SpIRIT is
included in an orbital plane nearly perpendicular (inclination = 97.6$^\circ$)
to the HERMES orbits. For the fraction of GRBs detected by three of the HERMES
satellites plus SpIRIT, the combined constellation is capable of localising 60%
of long GRBs to within ~ 30 deg$^2$ on the sky, and 60% of short GRBs within ~
1850 deg$^2$. Based purely on statistical GRB localisation capabilities (i.e.,
excluding systematic uncertainties and sky coverage), these figures for long
GRBs are comparable to those reported by the Fermi GBM. Further improvements by
a factor of 2 (or 4) can be achieved by launching an additional 4 (or 6)
SpIRIT-like satellites into a Polar orbit, which would both increase the
fraction of sky covered by multiple satellite elements, and enable $\geq$ 60%
of long GRBs to be localised within a radius of ~ 1.5$^\circ$ on the sky.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:28:41 GMT""}]","2023-03-29"
"2301.09687","Melanie Wood","Melanie Matchett Wood","Probability theory for random groups arising in number theory","ICM 2022 paper from my talk, references/status of problems have not
  been updated since November 2021",,,,"math.NT math.CO math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the probability theory, and in particular the moment problem and
universality theorems, for random groups of the sort of that arise or are
conjectured to arise in number theory, and in related situations in topology
and combinatorics. The distributions of random groups that are discussed
include those conjectured in the Cohen-Lenstra-Martinet heuristics to be the
distributions of class groups of random number fields, as well as distributions
of non-abelian generalizations, and those conjectured to be the distributions
of Selmer groups of random elliptic curves. For these sorts of distributions on
finite and profinite groups, we survey what is known about the moment problem
and universality, give a few new results including new applications, and
suggest open problems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:31:48 GMT""}]","2023-01-25"
"2301.09688","Zechen Xiong","Zechen Xiong, Zihan Guo, Li Yuan, Yufeng Su, Yitong Liu, Hod Lipson","Rapid grasping of fabric using bionic soft grippers with elastic
  instability","7 pages, 5 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robot grasping is subject to an inherent tradeoff: Grippers with a large span
typically take a longer time to close, and fast grippers usually cover a small
span. However, many practical applications of soft grippers require the ability
to close a large distance rapidly. For example, grasping cloth typically
requires pressing a wide span of fabric into a graspable cusp. Here, we
demonstrate a human-finger-inspired snapping gripper that exploits elastic
instability to achieve reversible rapid closure over a wide span. Using
prestressed semi-rigid material as the skeleton, the gripper fingers can widely
open (86 ~) and rapidly close (46 ms) following a trajectory similar to that of
a thumb-index finger pinching which is 2.7 times and 10.9 times better than the
reference gripper in terms of span and speed, respectively. We theoretically
give the design principle, simulatively verify the method, and experimentally
test this gripper on a variety of rigid, flexible, and limp objects and achieve
good adaptivity and mechanical performance. This research helps bridge the gap
between strong industry manipulators and safe human-interactive robotic hands.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:32:17 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 19:06:47 GMT""}]","2023-01-30"
"2301.09689","Elijah S. Lee","Elijah S. Lee, Lifeng Zhou, Alejandro Ribeiro, Vijay Kumar","Graph Neural Networks for Decentralized Multi-Agent Perimeter Defense","20 pages, 10 figures. Published in Frontiers in Control Engineering
  2023. arXiv admin note: substantial text overlap with arXiv:2211.01757",,"10.3389/fcteg.2023.1104745",,"cs.MA cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study the problem of decentralized multi-agent perimeter
defense that asks for computing actions for defenders with local perceptions
and communications to maximize the capture of intruders. One major challenge
for practical implementations is to make perimeter defense strategies scalable
for large-scale problem instances. To this end, we leverage graph neural
networks (GNNs) to develop an imitation learning framework that learns a
mapping from defenders' local perceptions and their communication graph to
their actions. The proposed GNN-based learning network is trained by imitating
a centralized expert algorithm such that the learned actions are close to that
generated by the expert algorithm. We demonstrate that our proposed network
performs closer to the expert algorithm and is superior to other baseline
algorithms by capturing more intruders. Our GNN-based network is trained at a
small scale and can be generalized to large-scale cases. We run perimeter
defense games in scenarios with different team sizes and configurations to
demonstrate the performance of the learned network.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:35:59 GMT""}]","2023-01-25"
"2301.09690","Adlene Maghenem","Pauline Bernard and Mohamed Maghenem","Reconstructing Indistinguishable Solutions Via Set-Valued KKL Observer",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  KKL observer design consists in finding a smooth change of coordinates
transforming the system dynamics into a linear filter of the output. The state
of the original system is then reconstructed by implementing this filter from
any initial condition and left-inverting the transformation, under a
\textit{backward-distinguishability} property. In this paper, we consider the
case where the latter assumption does not hold, namely when distinct solutions
may generate the same output, and thus be indistinguishable. The KKL
transformation is no longer injective and its ``left-inverse'' is thus allowed
to be set-valued, yielding a set-valued KKL observer. Assuming the
transformation is full-rank and its preimage has constant cardinality, we show
the existence of a globally defined set-valued left-inverse that is Lipschitz
in the Hausdorff sense. Leveraging on recent results linking this left-inverse
with the \textit{backward-indistinguishable sets}, we show that the set-valued
KKL observer converges in the Hausdorff sense to the backward-indistinguishable
set of the system solution. When, additionally, a given output is generated by
a specific number of solutions not converging to each other, we show that the
designed observer asymptotically reconstructs each of those solutions. Finally,
the different assumptions are discussed and illustrated via examples.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:41:16 GMT""}]","2023-01-25"
"2301.09691","Andrew Ronan","A. Ronan","Nilpotent G-spaces and their localizations",,,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop the theory of nilpotent $G$-spaces and their localizations, for
$G$ a compact Lie group, via reduction to the non-equivariant case using
Bousfield localization. One point of interest in the equivariant setting is
that we can choose to localize or complete at different sets of primes at
different fixed point spaces - and the theory works out just as well provided
that you invert more primes at $K \leq G$ than at $H \leq G$, whenever $K$ is
subconjugate to $H$ in $G$.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:43:10 GMT""}]","2023-01-25"
"2301.09692","Marc Salinas","Marc Salinas and J. Piekarewicz","Bayesian refinement of covariant energy density functionals","16 pages, 7 Figures, 3 Tables",,"10.1103/PhysRevC.107.045802",,"nucl-th astro-ph.SR nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The last five years have seen remarkable progress in our quest to determine
the equation of state of neutron rich matter. Recent advances across the
theoretical, experimental, and observational landscape have been incorporated
in a Bayesian framework to refine existing covariant energy density functionals
previously calibrated by the properties of finite nuclei. In particular,
constraints on the maximum neutron star mass from pulsar timing, on stellar
radii from the NICER mission, on tidal deformabilities from the LIGO-Virgo
collaboration, and on the dynamics of pure neutron matter as predicted from
chiral effective field theories, have resulted in significant refinements to
the models, particularly to those predicting a stiff symmetry energy. Still,
even after these improvements, we find challenging to reproduce simultaneously
the neutron skin thickness of both ${}^{208}$Pb and ${}^{48}$Ca recently
reported by the PREX/CREX collaboration.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:44:50 GMT""}]","2023-04-13"
"2301.09693","Minh Lam Nguyen","Minh Lam Nguyen","An abelian gauge-theoretic variant of the Seiberg-Witten equations for
  multiple-spinors","An important technical mistake in the set-up of this variant of
  generalization to Seiberg-Witten equations was pointed out to the author. In
  particular, the equations are not elliptic as claimed. As a result, any
  statement about (or uses) regularity and transversality of the moduli space
  has to be disregarded. However, the moduli space is still compact",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We consider a variant of the Seiberg-Witten equations for multiple-spinors.
The moduli space of solutions to our generalized Seiberg-Witten equations in
the setting of K\""ahler surfaces has a direct relation with ASD connections of
holomorphic vector bundle. Also in K\""ahler setting, we construct a numerical
invariant from the equations that detects a notion of $\phi-$stability of
$SU(n)-$holomorphic vector bundles where $\phi$ is some prescribed non-trivial
holomorphic section.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:50:12 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 23:26:12 GMT""}]","2023-01-30"
"2301.09694","Herbert Susmann","Herbert Susmann and Leontine Alkema","Flexible Modeling of Demographic Transition Processes with a Bayesian
  Hierarchical Penalized B-splines Model","28 pages, 17 figures (not including supplementary material.)",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Several demographic and health indicators, including the total fertility rate
(TFR) and modern contraceptive use rate (mCPR), exhibit similar patterns in
their evolution over time, characterized by a transition between stable states.
Existing statistical methods for estimation or projection are based on using
parametric functions to model the transition. We introduce a more flexible
model for transition processes based on B-splines called the B-spline
Transition Model. We customize the model to estimate mCPR in 174 countries from
1970-2030 using data from the United Nations Population Division and validate
performance with a set of out-of-sample model checks. While estimates and
projections are comparable between the two approaches, we find the the B-spline
approach improves out-of-sample predictions. Illustrative results for a model
for TFR are also presented and show larger differences in projections when
relaxing parametric assumptions.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:54:24 GMT""}]","2023-01-25"
"2301.09695","Eric Linder","Eric V. Linder","A Whole Cosmology View of the Hubble Constant","chapter for Hubble Constant Tension book",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The Hubble constant $H_0$ is the value of the cosmic expansion rate at one
time (the present), and cannot be adjusted successfully without taking into
account the entire expansion history and cosmology. We outline some conditions,
that if not quite ``no go'' are ``no thanks'', showing that changing the
expansion history, e.g. employing dynamical dark energy, cannot reconcile
disparate deductions of $H_0$ without upsetting some other cosmological
measurement.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:54:31 GMT""}]","2023-01-25"
"2301.09696","Omar Chehab","Omar Chehab and Alexandre Gramfort and Aapo Hyvarinen","Optimizing the Noise in Self-Supervised Learning: from Importance
  Sampling to Noise-Contrastive Estimation","arXiv admin note: text overlap with arXiv:2203.01110",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning is an increasingly popular approach to unsupervised
learning, achieving state-of-the-art results. A prevalent approach consists in
contrasting data points and noise points within a classification task: this
requires a good noise distribution which is notoriously hard to specify. While
a comprehensive theory is missing, it is widely assumed that the optimal noise
distribution should in practice be made equal to the data distribution, as in
Generative Adversarial Networks (GANs). We here empirically and theoretically
challenge this assumption. We turn to Noise-Contrastive Estimation (NCE) which
grounds this self-supervised task as an estimation problem of an energy-based
model of the data. This ties the optimality of the noise distribution to the
sample efficiency of the estimator, which is rigorously defined as its
asymptotic variance, or mean-squared error. In the special case where the
normalization constant only is unknown, we show that NCE recovers a family of
Importance Sampling estimators for which the optimal noise is indeed equal to
the data distribution. However, in the general case where the energy is also
unknown, we prove that the optimal noise density is the data density multiplied
by a correction term based on the Fisher score. In particular, the optimal
noise distribution is different from the data distribution, and is even from a
different family. Nevertheless, we soberly conclude that the optimal noise may
be hard to sample from, and the gain in efficiency can be modest compared to
choosing the noise distribution equal to the data's.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:57:58 GMT""}]","2023-01-25"
"2301.09697","Qianqian Su","Q. Su, J. Larson, T. N. Dalichaouch, F. Li, W. An, L. Hildebrand, Y.
  Zhao, V. Decyk, P.Alves, S. M. Wild, and W. B. Mori","Optimization of transformer ratio and beam loading in a plasma wakefield
  accelerator with a structure-exploiting algorithm",,,"10.1063/5.0142940",,"physics.plasm-ph physics.acc-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Plasma-based acceleration has emerged as a promising candidate as an
accelerator technology for a future linear collider or a next-generation light
source. For a linear collider, the energy transfer efficiency from the drive
beam to the wake and from the wake to the trailing beam must be large, while
the emittance and energy spread of the trailing bunch must be preserved. One
way to simultaneously achieve this when accelerating electrons is to use
longitudinally shaped bunches and nonlinear wakes. In the linear regime, there
is an analytical formalism to obtain the optimal shapes. In the nonlinear
regime, however, the optimal shape of the driver to maximize the energy
transfer efficiency cannot be precisely obtained because currently no theory
describes the wake structure and excitation process for all degrees of
nonlinearity. In addition, the ion channel radius is not well defined at the
front of the wake where the plasma electrons are not fully blown out by the
drive beam. We present results using a novel optimization method to effectively
determine a current profile for the drive and trailing beam in PWFA that
provides low energy spread, low emittance, and high acceleration efficiency. We
parameterize the longitudinal beam current profile as a piecewise-linear
function and define optimization objectives. For the trailing beam, the
algorithm converges quickly to a nearly inverse trapezoidal trailing beam
current profile similar to that predicted by the ultrarelativistic limit of the
nonlinear wakefield theory. For the drive beam, the beam profile found by the
optimization in the nonlinear regime that maximizes the transformer ratio also
resembles that predicted by linear theory. The current profiles found from the
optimization method provide higher transformer ratios compared with the linear
ramp predicted by the relativistic limit of the nonlinear theory.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:58:25 GMT""}]","2023-05-23"
"2301.09698","Essoham Ali","Essoham Ali and Kim-Hung Pho","A simulation-based study of Zero-inflated Bernoulli model with various
  models for the susceptible probability",,,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we are interested in the stability and robustness of the
parameter estimation in the Zero-Inflated Bernoulli (ZIBer) model, when the
susceptible probability (SP) model is modeled by numerous different binary
models: logit, probit, cloglog and generalized extreme value (GEV). To address
this problem, we propose the maximum likelihood estimation (MLE) method to
check its performance when different SP models are considered. Based on
numerical evidences through simulation studies and the analysis of a real data
set, it can be seen that the MLE approach has provided accurate and reliable
inferences. In addition, it can also be seen that for the empirical analysis,
the probit-ZIBer model is probably more suitable for the fishing data set than
the other models considered in this study. Besides, the results obtained in the
experimental analysis are also very consistent, compatible and very meaningful
in practice. It will help us to understand the importance of increasing
production while fishing.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:00:47 GMT""}]","2023-01-25"
"2301.09699","David Ulgenes","David Peter Hadrian Ulgenes","Series and Product Representations of Gamma and Pseudogamma Functions",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We derive and prove product and series representations of the gamma function
using Newton interpolation series. We then show how these equations can be used
to construct better and better approximations of the gamma function by writing
it as a product over the prime numbers. The series definition is also used to
find a new representation for the Euler-Mascheroni constant, containing only
rational terms. After that, we introduce a new pseudogamma function which we
call the $\Lambda$ function. This function interpolates the factorial at the
positive integers, the reciprocal factorial at the negative integers and
converges for the entire real axis. Finally, we conjecture a novel series
representation for the principal branch of the inverse gamma function
$\Gamma(y)=x$.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:01:17 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 22:08:31 GMT""}]","2023-04-04"
"2301.09700","Thomas Hentschel","Thomas W. Hentschel (1), Alina Kononov (2), Alexandra Olmstead (2 and
  3), Attila Cangi (4), Andrew D. Baczewski (2 and 5), Stephanie B. Hansen (6)
  ((1) School of Applied & Engineering Physics, Cornell University, Ithaca NY,
  USA, (2) Center for Computing Research, Sandia National Laboratories,
  Albuquerque NM, USA, (3) Nanoscience and Microsystems Engineering Program,
  University of New Mexico, Albuquerque NM, USA, (4) Center for Advanced
  Systems Understanding, Helmholtz-Zentrum Dresden-Rossendorf, G\""orlitz,
  Germany, (5) Center for Quantum Information and Control (CQuIC), Department
  of Physics and Astronomy, University of New Mexico, Albuquerque NM, USA, (6)
  Pulsed Power Sciences Center, Sandia National Laboratories, Albuquerque NM,
  USA)","Improving dynamic collision frequencies: impacts on dynamic structure
  factors and stopping powers in warm dense matter",,,,,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Simulations and diagnostics of high-energy-density plasmas and warm dense
matter rely on models of material response properties, both static and dynamic
(frequency-dependent). Here, we systematically investigate variations in
dynamic electron-ion collision frequencies $\nu(\omega)$ in warm dense matter
using data from a self-consistent-field average-atom model. We show that
including the full quantum density of states, strong collisions, and inelastic
collisions lead to significant changes in $\nu(\omega)$. These changes result
in red shifts and broadening of the plasmon peak in the dynamic structure
factor, an effect observable in x-ray Thomson scattering spectra, and modify
stopping powers around the Bragg peak. These changes improve the agreement of
computationally efficient average-atom models with first-principles
time-dependent density functional theory in warm dense aluminum, carbon, and
deuterium.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:03:21 GMT""}]","2023-01-25"
"2301.09701","Thiago Rodrigo Alves","Thiago R. Alves, Leonardo Brito and Daniel Carando","On sets of extreme functions for Fatou's theorem","9 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bounded holomorphic functions on the disk have radial limits in almost every
direction, as follows from Fatou's theorem. Given a zero-measure set $E$ in the
torus $\mathbb T$, we study the set of functions such that $\lim_{r \to 1^{-}}
f(r \, w)$ fails to exist for every $w\in E$ (such functions were first
constructed by Lusin). We show that the set of Lusin-type functions, for a
fixed zero-measure set $E$, contain algebras of algebraic dimension
$\mathfrak{c}$ (except for the zero function). When the set $E$ is countable,
we show also in the several-variable case that the Lusin-type functions contain
infinite dimensional Banach spaces and, moreover, contain plenty of
$\mathfrak{c}$-dimensional algebras. We also address the question for functions
on infinitely many variables.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:06:42 GMT""}]","2023-01-25"
"2301.09702","Jiaqi Guo","Jiaqi Guo and Amy R. Reibman and Edward J. Delp","Illumination Variation Correction Using Image Synthesis For Unsupervised
  Domain Adaptive Person Re-Identification","10 pages, 5 figures, 4 tables",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to
learn identity information from labeled images in source domains and apply it
to unlabeled images in a target domain. One major issue with many unsupervised
re-identification methods is that they do not perform well relative to large
domain variations such as illumination, viewpoint, and occlusions. In this
paper, we propose a Synthesis Model Bank (SMB) to deal with illumination
variation in unsupervised person re-ID. The proposed SMB consists of several
convolutional neural networks (CNN) for feature extraction and Mahalanobis
matrices for distance metrics. They are trained using synthetic data with
different illumination conditions such that their synergistic effect makes the
SMB robust against illumination variation. To better quantify the illumination
intensity and improve the quality of synthetic images, we introduce a new 3D
virtual-human dataset for GAN-based image synthesis. From our experiments, the
proposed SMB outperforms other synthesis methods on several re-ID benchmarks.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:11:24 GMT""}]","2023-01-25"
"2301.09703","Wenbo Chen","Wenbo Chen, Reem Khir and Pascal Van Hentenryck","Two-Stage Learning For the Flexible Job Shop Scheduling Problem",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Flexible Job-shop Scheduling Problem (FJSP) is an important combinatorial
optimization problem that arises in manufacturing and service settings. FJSP is
composed of two subproblems, an assignment problem that assigns tasks to
machines, and a scheduling problem that determines the starting times of tasks
on their chosen machines. Solving FJSP instances of realistic size and
composition is an ongoing challenge even under simplified, deterministic
assumptions. Motivated by the inevitable randomness and uncertainties in supply
chains, manufacturing, and service operations, this paper investigates the
potential of using a deep learning framework to generate fast and accurate
approximations for FJSP. In particular, this paper proposes a two-stage
learning framework 2SLFJSP that explicitly models the hierarchical nature of
FJSP decisions, uses a confidence-aware branching scheme to generate
appropriate instances for the scheduling stage from the assignment predictions
and leverages a novel symmetry-breaking formulation to improve learnability.
2SL-FJSP is evaluated on instances from the FJSP benchmark library. Results
show that 2SL-FJSP can generate high-quality solutions in milliseconds,
outperforming a state-of-the-art reinforcement learning approach recently
proposed in the literature, and other heuristics commonly used in practice.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:23:35 GMT""}]","2023-01-25"
"2301.09704","Shan Wang Dr.","Shan Wang and Hanxiang Peng","Improving Estimation Efficiency In Structural Equation Models By An Easy
  Empirical Likelihood Approach",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this article, we construct empirical likelihood (EL)-weighted estimators
of linear functionals of a probability measure in the presence of side
information. Motivated by nuisance parameters in semiparametric models with
possibly infinite dimensions, we consider the use of estimated constraint
functions and allow the number of constraints to grow with the sample size. We
study the asymptotic properties and efficiency gains. The results are used to
construct improved estimators of parameters in structural equation models. The
EL-weighted estimators of parameters are shown to have reduced variances in a
SEM in the presence of side information of stochastic independence of the
random error and random covariate. Some simulation results on efficiency gain
are reported.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:24:05 GMT""}]","2023-01-25"
"2301.09705","Andrew Papanicolaou","A. Papanicolaou, H. Fu, P. Krishnamurthy, B. Healy, F. Khorrami","An Optimal Control Strategy for Execution of Large Stock Orders Using
  LSTMs","This work was partially supported by NSF grant DMS-1907518 and in
  part by the New York University Abu Dhabi (NYUAD) Center for Artificial
  Intelligence and Robotics, funded by Tamkeen under the NYUAD Research
  Institute Award CG010",,,,"q-fin.CP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we simulate the execution of a large stock order with real
data and general power law in the Almgren and Chriss model. The example that we
consider is the liquidation of a large position executed over the course of a
single trading day in a limit order book. Transaction costs are incurred
because large orders walk the order book, that is, they consume order book
liquidity beyond the best bid/ask. We model the order book with a power law
that is proportional to trading volume, and thus transaction costs are
inversely proportional to a power of trading volume. We obtain a policy
approximation by training a long short term memory (LSTM) neural network to
minimize transaction costs accumulated when execution is carried out as a
sequence of smaller suborders. Using historical S&P100 price and volume data,
we evaluate our LSTM strategy relative to strategies based on time-weighted
average price (TWAP) and volume-weighted average price (VWAP). For execution of
a single stock, the input to the LSTM is the cross section of data on all 100
stocks, including prices, volumes, TWAPs and VWAPs. By using this data cross
section, the LSTM should be able to exploit inter-stock co-dependence in volume
and price movements, thereby reducing transaction costs for the day. Our tests
on S&P100 data demonstrate that in fact this is so, as our LSTM strategy
consistently outperforms TWAP and VWAP-based strategies.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:24:20 GMT""},{""version"":""v2"",""created"":""Sat, 28 Jan 2023 12:50:15 GMT""},{""version"":""v3"",""created"":""Thu, 11 May 2023 12:56:59 GMT""}]","2023-05-12"
"2301.09706","Alejandro Tolcachier","Adri\'an Andrada and Alejandro Tolcachier","Harmonic complex structures and special Hermitian metrics on products of
  Sasakian manifolds","In this version we have added Section 6 regarding computations with
  the Bismut connection and we have determined when the associated Bismut Ricci
  tensor and Bismut Ricci form vanish, obtaining new examples of Calabi-Yau
  with Torsion structures. We have fixed some inaccuracies with some signs in
  the previous sections but the results have not changed. Comments are welcome!",,,,"math.DG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  It is well known that the product of two Sasakian manifolds carries a
2-parameter family of Hermitian structures $(J_{a,b},g_{a,b})$. We show in this
article that the complex structure $J_{a,b}$ is harmonic with respect to
$g_{a,b}$, i.e. it is a critical point of the Dirichlet energy functional.
Furthermore, we also determine when these Hermitian structures are locally
conformally K\""ahler, balanced, strong K\""ahler with torsion, Gauduchon or
$k$-Gauduchon ($k\geq 2$). Finally, we study the Bismut connection associated
to $(J_{a,b}, g_{a,b})$ and we provide formulas for the Bismut-Ricci tensor
$\operatorname{Ric}^B$ and the Bismut-Ricci form $\rho^B$. We show that these
tensors vanish if and only if each Sasakian factor is $\eta$-Einstein with
appropriate constants and we also exhibit some examples fulfilling these
conditions, thus providing new examples of Calabi-Yau with torsion manifolds.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:24:47 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 16:03:50 GMT""}]","2023-03-09"
"2301.09707","Javier Rib\'on","Javier Rib\'on and Rudy Rosas","Nondegenerate germs of holomorphic foliations with prescribed holonomy","38 pages",,,,"math.DS math.CA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are interested in characterizing the holonomy maps associated to integral
curves of non-degenerate singularities of holomorphic vector fields. Such a
description is well-known in dimension 2 where is a key ingredient in the study
of reduced singularities. The most intricate case in the 2 dimensional setting
corresponds to (Siegel) saddle singularities. This work treats the analogous
problem for saddles in higher dimension.
  We show that any germ of holomorphic biholomorphism, in any dimension, can be
obtained as the holonomy map associated to an integral curve of a saddle
singularity.
  A natural question is whether we can prescribe the linear part of the saddle
germ of vector field provided the holonomy map. The answer to this question is
known to be positive in dimension 2. We see that this is not the case in higher
dimension. In spite of this, we provide a positive result under a natural
condition for the holonomy map.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:25:29 GMT""}]","2023-01-25"
"2301.09708","Lu Shi","Lu Shi, Zhichao Liu, and Konstantinos Karydis","Koopman Operators for Modeling and Control of Soft Robotics","Accepted to Current Robotics Report",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Purpose of review: We review recent advances in algorithmic development and
validation for modeling and control of soft robots leveraging the Koopman
operator theory. Recent findings: We identify the following trends in recent
research efforts in this area. (1) The design of lifting functions used in the
data-driven approximation of the Koopman operator is critical for soft robots.
(2) Robustness considerations are emphasized. Works are proposed to reduce the
effect of uncertainty and noise during the process of modeling and control. (3)
The Koopman operator has been embedded into different model-based control
structures to drive the soft robots. Summary: Because of their compliance and
nonlinearities, modeling and control of soft robots face key challenges. To
resolve these challenges, Koopman operator-based approaches have been proposed,
in an effort to express the nonlinear system in a linear manner. The Koopman
operator enables global linearization to reduce nonlinearities and/or serves as
model constraints in model-based control algorithms for soft robots. Various
implementations in soft robotic systems are illustrated and summarized in the
review.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:28:59 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 21:09:51 GMT""}]","2023-02-09"
"2301.09709","Anna Winnicki","Anna Winnicki, R. Srikant","On The Convergence Of Policy Iteration-Based Reinforcement Learning With
  Monte Carlo Policy Evaluation","27 pages",,,,"cs.LG cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A common technique in reinforcement learning is to evaluate the value
function from Monte Carlo simulations of a given policy, and use the estimated
value function to obtain a new policy which is greedy with respect to the
estimated value function. A well-known longstanding open problem in this
context is to prove the convergence of such a scheme when the value function of
a policy is estimated from data collected from a single sample path obtained
from implementing the policy (see page 99 of [Sutton and Barto, 2018], page 8
of [Tsitsiklis, 2002]). We present a solution to the open problem by showing
that a first-visit version of such a policy iteration scheme indeed converges
to the optimal policy provided that the policy improvement step uses lookahead
[Silver et al., 2016, Mnih et al., 2016, Silver et al., 2017b] rather than a
simple greedy policy improvement. We provide results both for the original open
problem in the tabular setting and also present extensions to the function
approximation setting, where we show that the policy resulting from the
algorithm performs close to the optimal policy within a function approximation
error.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:32:41 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 14:57:32 GMT""}]","2023-03-01"
"2301.09710","Zongyu Li","Zongyu Li, Yuni K. Dewaraja and Jeffrey A. Fessler","Training End-to-End Unrolled Iterative Neural Networks for SPECT Image
  Reconstruction","submitted to IEEE TRPMS","IEEE Transactions on Radiation and Plasma Medical Sciences, vol.
  7, no. 4, pp. 410-420, April 2023","10.1109/TRPMS.2023.3240934",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training end-to-end unrolled iterative neural networks for SPECT image
reconstruction requires a memory-efficient forward-backward projector for
efficient backpropagation. This paper describes an open-source, high
performance Julia implementation of a SPECT forward-backward projector that
supports memory-efficient backpropagation with an exact adjoint. Our Julia
projector uses only ~5% of the memory of an existing Matlab-based projector. We
compare unrolling a CNN-regularized expectation-maximization (EM) algorithm
with end-to-end training using our Julia projector with other training methods
such as gradient truncation (ignoring gradients involving the projector) and
sequential training, using XCAT phantoms and virtual patient (VP) phantoms
generated from SIMIND Monte Carlo (MC) simulations. Simulation results with two
different radionuclides (90Y and 177Lu) show that: 1) For 177Lu XCAT phantoms
and 90Y VP phantoms, training unrolled EM algorithm in end-to-end fashion with
our Julia projector yields the best reconstruction quality compared to other
training methods and OSEM, both qualitatively and quantitatively. For VP
phantoms with 177Lu radionuclide, the reconstructed images using end-to-end
training are in higher quality than using sequential training and OSEM, but are
comparable with using gradient truncation. We also find there exists a
trade-off between computational cost and reconstruction accuracy for different
training methods. End-to-end training has the highest accuracy because the
correct gradient is used in backpropagation; sequential training yields worse
reconstruction accuracy, but is significantly faster and uses much less memory.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:33:09 GMT""}]","2023-04-04"
"2301.09711","Siyan Daniel Li-Huerta","Siyan Daniel Li-Huerta","Local-global compatibility over function fields","54 pages. Comments welcome!",,,,"math.NT math.AG math.RT","http://creativecommons.org/licenses/by/4.0/","  We prove that V. Lafforgue's global Langlands correspondence is compatible
with Fargues-Scholze's semisimplified local Langlands correspondence. As a
consequence, we canonically lift Fargues-Scholze's construction to a
non-semisimplified local Langlands correspondence for local fields of
characteristic $p\geq5$. We also deduce that Fargues-Scholze's construction
agrees with that of Genestier-Lafforgue, answering a question of
Fargues-Scholze, Hansen, Harris, and Kaletha. The proof relies on a
uniformization morphism for moduli spaces of shtukas.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:36:24 GMT""}]","2023-01-25"
"2301.09712","Ram Brustein","Ram Brustein, A.J.M. Medved, Tom Shindelman, Tamar Simhon","Black holes as frozen stars: Regular interior geometry",,,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We have proposed a model geometry for the interior of a regular black hole
mimicker, the frozen star, whose most startling feature is that each spherical
shell in its interior is a surface of infinite redshift. The geometry is a
solution of the Einstein equations which is sourced by an exotic matter with
maximally negative radial pressure. The frozen star geometry was previously
presented in singular coordinates for which $-g_{tt}$ and $g^{rr}$ vanish in
the bulk and connect smoothly to the Schwarzschild exterior. Additionally, the
geometry was mildly singular in the center of the star. Here, we present
regular coordinates for the entirety of the frozen star. Each zero in the
metric is replaced with a small, dimensionless parameter $\varepsilon$; the
same parameter in both $-g_{tt}$ and $g^{rr}$ so as to maintain maximally
negative radial pressure. We also regularize the geometry, energy density and
pressure in the center of the star in a smooth way. Our initial analysis uses
Schwarzschild-like coordinates and applies the Killing equations to show that
an infalling, point-like object will move very slowly, effectively sticking to
the surface of the star and never coming out. If one nevertheless follows the
trajectory of the object into the interior of the star, it moves along an
almost-radial trajectory until it comes within a small distance from the star's
center. Once there, if the object has any amount of angular momentum at all, it
will be reflected outwards by a potential barrier onto a different
almost-radial trajectory. Finally, using Kruskal-like coordinates, we consider
the causal structure of the regularized frozen star and discuss its
$\varepsilon\to 0$ limit, for which the geometry degenerates and becomes
effectively two dimensional.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:37:52 GMT""}]","2023-01-25"
"2301.09713","Niranjana Shankarappa","Niranjana Shankarappa, Kristopher G. Klein, Mihailo M Martinovi\'c","Estimation of turbulent proton and electron heating rates via Landau
  damping constrained by Parker Solar Probe observations",,,"10.3847/1538-4357/acb542",,"astro-ph.SR physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The heating of ions and electrons due to turbulent dissipation plays a
crucial role in the thermodynamics of the solar wind and other plasma
environments. Using magnetic field and thermal plasma observations from the
first two perihelia of the Parker Solar Probe (PSP), we model the relative
heating rates as a function of radial distance, magnetic spectra, and plasma
conditions, enabling us to better characterize the thermodynamics of the inner
heliosphere. We employ the Howes et al. 2008 steady-state cascade model, which
considers the behavior of turbulent, low-frequency, wavevector-anisotropic,
critically balanced Alfv\'enic fluctuations that dissipate via Landau damping
to determine proton-to-electron heating rates $Q_p/Q_e$. We distinguish
ion-cyclotron frequency circularly polarized waves from low-frequency
turbulence and constrain the cascade model using spectra constructed from the
latter. We find that the model accurately describes the observed energy
spectrum from over 39.4 percent of the intervals from Encounters 1 and 2,
indicating the possibility for Landau damping to heat the young solar wind. The
ability of the model to describe the observed turbulent spectra increases with
the ratio of thermal-to-magnetic pressure, $\beta_p$, indicating that the model
contains the necessary physics at higher $\beta_p$. We estimate high magnitudes
for the Kolmogorov constant which is inversely proportional to the non-linear
energy cascade rate. We verify the expected strong dependency of $Q_p/Q_e$ on
$\beta_p$ and the consistency of the critical balance assumption.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:40:39 GMT""}]","2023-04-12"
"2301.09714","Ernesto Garc\'ia","Ernesto Garc\'ia and Pablo Lessa","Dimension drop of harmonic measure for some finite range random walks on
  Fuchsian Schottky groups",,,,,"math.GT math.PR","http://creativecommons.org/licenses/by/4.0/","  We prove that the harmonic measures of certain finite range random walks on
Fuchsian Schottky groups, have dimension strictly smaller than the Hausdorff
dimension of the corresponding limit set.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:41:36 GMT""}]","2023-01-25"
"2301.09715","Avirup Sil","Avirup Sil, Jaydeep Sen, Bhavani Iyer, Martin Franz, Kshitij Fadnis,
  Mihaela Bornea, Sara Rosenthal, Scott McCarley, Rong Zhang, Vishwajeet Kumar,
  Yulong Li, Md Arafat Sultan, Riyaz Bhat, Radu Florian, Salim Roukos","PrimeQA: The Prime Repository for State-of-the-Art Multilingual Question
  Answering Research and Development",,,,,"cs.CL cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  The field of Question Answering (QA) has made remarkable progress in recent
years, thanks to the advent of large pre-trained language models, newer
realistic benchmark datasets with leaderboards, and novel algorithms for key
components such as retrievers and readers. In this paper, we introduce PRIMEQA:
a one-stop and open-source QA repository with an aim to democratize QA
re-search and facilitate easy replication of state-of-the-art (SOTA) QA
methods. PRIMEQA supports core QA functionalities like retrieval and reading
comprehension as well as auxiliary capabilities such as question generation.It
has been designed as an end-to-end toolkit for various use cases: building
front-end applications, replicating SOTA methods on pub-lic benchmarks, and
expanding pre-existing methods. PRIMEQA is available at :
https://github.com/primeqa.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:43:26 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 15:48:03 GMT""}]","2023-01-26"
"2301.09716","Qingchao Li","Qingchao Li, Mohammed El-Hajjar, Ibrahim Hemadeh, Deepa Jagyasi, Arman
  Shojaeifard, Lajos Hanzo","Performance Analysis of Active RIS-aided Systems in the Face of
  Imperfect CSI and Phase Shift Noise",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  The linear minimal mean square error (LMMSE) estimator for active
reconfigurable intelligent surface (RIS)-aided wireless systems is formulated.
Furthermore, based on the moment-matching method, we employ the Gamma
distribution to approximate the distribution of the instantaneous received
signal-to-interference-plus-noise ratio (SINR), and then derive the closed-form
outage probability and ergodic channel capacity in the presence of realistic
channel estimation errors, the thermal noise of RIS amplifiers and the RIS
phase shift noise. Our theoretical analysis and simulation results show that
the introduction of RIS amplifiers is equivalent to increasing of the transmit
power, and also present the performance degradation resulting from the channel
estimation error and the RIS phase noise.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:45:55 GMT""}]","2023-01-25"
"2301.09717","Qingchao Li","Qingchao Li, Mohammed El-Hajjar, Ibrahim Hemadeh, Arman Shojaeifard,
  Alain A. M. Mourad, Lajos Hanzo","Reconfigurable Intelligent Surface Aided Amplitude- and Phase-Modulated
  Downlink Transmission",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  New reconfigurable intelligent surface (RIS) based amplitude and phase
modulation schemes are proposed as an evolution how the phase-only modulation
schemes available in the literature. Explicitly, both the amplitude-phase shift
keying (A-PSK) and quadrature amplitude-phase shift keying (QA-PSK) are
conceived, where the RIS is assumed to be part of a transmitter to deliver
information to the multi-antenna aided downlink receiver. In the proposed
design, the RIS is partitioned into multiple blocks, and the information bits
are conveyed by controlling both the ON-OFF state and the phase shift of the
RIS elements in each block. Since the propagation paths spanning from each RIS
block to the receiver can be coherently combined as a benefit of appropriately
configuring the phase of the RIS elements, the received signal constellations
can be designed by controlling both the ON-OFF pattern of the RIS blocks as
well as the phase shift of the RIS elements. Both the theoretical analysis and
the simulation results show that our proposed RIS-aided modulation schemes
outperform the state-of-the-art RIS-based PSK modulation both in terms of its
discrete-input-continuous-output memoryless channel (DCMC) capacity and its
symbol error probability, especially in the high signal-to-noise-ratio (SNR)
region, when considering realistic finite resolution RIS phase shifts.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:47:06 GMT""}]","2023-01-25"
"2301.09718","Andrea Macchi","A. Macchi","Comment on: ""Interacting quantum and classical waves: Resonant and
  non-resonant energy transfer to electrons immersed in an intense
  electromagnetic wave'' [Phys. Plasmas 29, 022107 (2022)]","2 pages. 2nd version reports an extended discussion and criticism",,,,"physics.plasm-ph physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  A comment on the paper by S. M. Mahajan and F. A. Asenjo ""Interacting quantum
and classical waves: Resonant and non-resonant energy transfer to electrons
immersed in an intense electromagnetic wave"" [Phys. Plasmas 29, 022107 (2022)]
where the authors use a model based on the Klein-Gordon equation to discuss
particle energization by a transverse electromagnetic wave in a plasma. It is
shown that the results of the paper are easily obtained in a classical
approach, so that no quantum effect has to be invoked. Moreover, some mistakes
and misinterpretations in the paper have been corrected. The (un)suitability of
the proposed mechanism to account for generation of extremely energetic
particles in both laboratory and astrophysical scenarios is also discussed.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:50:26 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 09:13:29 GMT""}]","2023-03-24"
"2301.09719","Miaomiao Jin","Hamdy Arkoub and Miaomiao Jin","Impact of chemical short-range order on radiation damage in Fe-Ni-Cr
  alloys","6 figures",,"10.1016/j.scriptamat.2023.115373",,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Chemical short-range order (CSRO), a form of nanoscale special atom
arrangement, has been found to significantly alter material properties such as
dislocation motion and defect dynamics in various alloys. Here, we use Fe-Ni-Cr
alloys to demonstrate how CSRO affects defect properties and radiation
behavior, based on extensive molecular dynamics simulations. Statistically
significant results are obtained regarding radiation-induced defect propensity,
defect clustering, and chemical mixing as a function of dose for three CSRO
levels. The perfect random solution as an energetically unfavorable state
(negative stacking fault energy) shows the strongest tendency to enable
diffusion, while a high CSRO degree scenario generally reduces the effective
defect diffusivity due to trapping effects, leading to distinct defect
dynamics. Notably, in the high-CSRO scenario, interstitial clusters are Cr-rich
and interstitial loops preferentially reside in/near the Cr-rich CSRO domains.
It is also identified that CSRO is dynamically evolving in a decreasing or
increasing manner upon continuous irradiation, reaching a steady-state value.
These new understandings suggest the importance of incorporating the effect of
CSRO in investigating radiation-driven microstructural evolution.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:54:37 GMT""}]","2023-05-19"
"2301.09720","Misja Steinmetz","Misja F.A. Steinmetz","Packets of Serre weights for generic locally reducible two-dimensional
  Galois representations","17 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Suppose $K/\mathbb{Q}_p$ is finite and $\overline{r}\colon G_K\to
\mathrm{GL}_2(\overline{\mathbb{F}}_p)$ is a reducible Galois representation.
In this paper we prove that we can use the results by the author in [Ste22] to
obtain a decomposition of the set of Serre weights $W(\overline{r})$ into a
disjoint union of at most $(e+1)^f$ 'packets' of weights (where $f$ is the
residue degree and $e$ the ramification degree of $K$) under the assumption
that $\overline{r}$ is weakly generic. Thereby, we improve on results of
Diamond--Savitt in [DS15] which give a similar decomposition, by rather
different methods, under the assumption that $\overline{r}$ is strongly
generic. We show that our definition of weak genericity is optimal for the
results of this paper to hold when $e=1$. However, we expect that for $e=2$ one
of the main results of this paper still holds under weaker hypotheses than the
ones used in this paper.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:07:19 GMT""}]","2023-01-25"
"2301.09721","Michael Jewell","HAYSTAC Collaboration: M. J. Jewell, A. F. Leder, K. M. Backes, Xiran
  Bai, K. van Bibber, B. M. Brubaker, S. B. Cahn, A. Droster, Maryam H. Esmat,
  Sumita Ghosh, Eleanor Graham, Gene C. Hilton, H. Jackson, Claire Laffan, S.
  K. Lamoreaux, K. W. Lehnert, S. M. Lewis, M. Malnou, R. H. Maruyama, D. A.
  Palken, N. M. Rapidis, E. P. Ruddy, M. Simanovskaia, Sukhman Singh, D. H.
  Speller, Leila R. Vale, H. Wang, and Yuqi Zhu","New Results from HAYSTAC's Phase II Operation with a Squeezed State
  Receiver","20 pages, 16 figures",,,,"hep-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  A search for dark matter axions with masses $>10 \mu eV/c^{2}$ has been
performed using the HAYSTAC experiment's squeezed state receiver to achieve
sub-quantum limited noise. This report includes details of the design and
operation of the experiment previously used to search for axions in the mass
ranges $16.96-17.12$ and $17.14-17.28 \mu eV/c^{2}$($4.100-4.140$GHz) and
$4.145-4.178$GHz) as well as upgrades to facilitate an extended search at
higher masses. These upgrades include improvements to the data acquisition
routine which have reduced the effective dead time by a factor of 5, allowing
for the new region to be scanned $\sim$1.6 times faster with comparable
sensitivity. No statistically significant evidence of an axion signal is found
in the range $18.44-18.71\mu eV/c^{2}$($4.459-4.523$GHz), leading to an
aggregate upper limit exclusion at the $90\%$ level on the axion-photon
coupling of $2.06\times g_{\gamma}^{KSVZ}$.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:11:40 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 15:42:57 GMT""}]","2023-01-27"
"2301.09722","Beatrice Foroni","Beatrice Foroni, Luca Merlo, Lea Petrella","Expectile hidden Markov regression models for analyzing cryptocurrency
  returns",,,,,"stat.AP q-fin.RM","http://creativecommons.org/licenses/by/4.0/","  In this paper we develop a linear expectile hidden Markov model for the
analysis of cryptocurrency time series in a risk management framework. The
methodology proposed allows to focus on extreme returns and describe their
temporal evolution by introducing in the model time-dependent coefficients
evolving according to a latent discrete homogeneous Markov chain. As it is
often used in the expectile literature, estimation of the model parameters is
based on the asymmetric normal distribution. Maximum likelihood estimates are
obtained via an Expectation-Maximization algorithm using efficient M-step
update formulas for all parameters. We evaluate the introduced method with both
artificial data under several experimental settings and real data investigating
the relationship between daily Bitcoin returns and major world market indices.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:20:50 GMT""}]","2023-01-25"
"2301.09723","Ernest Davis","Ernest Davis","Mathematics, word problems, common sense, and artificial intelligence",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  The paper discusses the capacities and limitations of current artificial
intelligence (AI) technology to solve word problems that combine elementary
knowledge with commonsense reasoning. No existing AI systems can solve these
reliably. We review three approaches that have been developed, using AI natural
language technology: outputting the answer directly, outputting a computer
program that solves the problem, and outputting a formalized representation
that can be input to an automated theorem verifier. We review some benchmarks
that have been developed to evaluate these systems and some experimental
studies. We discuss the limitations of the existing technology at solving these
kinds of problems. We argue that it is not clear whether these kinds of
limitations will be important in developing AI technology for pure mathematical
research, but that they will be important in applications of mathematics, and
may well be important in developing programs capable of reading and
understanding mathematical content written by humans.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:21:39 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 01:24:25 GMT""}]","2023-01-26"
"2301.09724","Jang Hyun Cho","Jang Hyun Cho, Philipp Kr\""ahenb\""uhl","Long-tail Detection with Effective Class-Margins","ECCV 2022 Oral. Code is available at
  https://github.com/janghyuncho/ECM-Loss",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large-scale object detection and instance segmentation face a severe data
imbalance. The finer-grained object classes become, the less frequent they
appear in our datasets. However, at test-time, we expect a detector that
performs well for all classes and not just the most frequent ones. In this
paper, we provide a theoretical understanding of the long-trail detection
problem. We show how the commonly used mean average precision evaluation metric
on an unknown test set is bound by a margin-based binary classification error
on a long-tailed object detection training set. We optimize margin-based binary
classification error with a novel surrogate objective called \textbf{Effective
Class-Margin Loss} (ECM). The ECM loss is simple, theoretically well-motivated,
and outperforms other heuristic counterparts on LVIS v1 benchmark over a wide
range of architecture and detectors. Code is available at
\url{https://github.com/janghyuncho/ECM-Loss}.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:25:24 GMT""}]","2023-01-25"
"2301.09725","Celal Soyarslan","Celal Soyarslan and Marc Pradas","Physics-informed machine learning in asymptotic homogenization of
  elliptic equations",,,,,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply physics-informed neural networks (PINNs) to first-order two-scale
periodic asymptotic homogenization of the property tensor in a generic elliptic
equation. The problem of lack of differentiability of property tensors at the
sharp phase interfaces is circumvented by making use of diffuse interface
formulation. Periodic boundary conditions are incorporated strictly, through
the introduction of an input-transfer layer (Fourier feature mapping), in which
the sine and cosine of the inner product of position vectors and reciprocal
lattice vectors are considered. This, together with the absence of Dirichlet
boundary conditions, results in a lossless boundary condition application. The
only loss terms are then due to the differential equation itself, which removes
the necessity of scaling the loss entries. In demonstrating the formulation's
versatility based on the reciprocal lattice vectors, crystalline arrangements
defined with Bravais lattices are used. We also show that considering integer
multiples of the reciprocal basis in the Fourier mapping leads to improved
convergence of high-frequency functions. We consider applications in one, two,
and three dimensions. Periodic composites, composed of embeddings of
monodisperse inclusions in the form of disks/spheres in the
two-/three-dimensional matrix, are considered. For demonstration purposes,
stochastic monodisperse disk arrangements are also considered.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:25:43 GMT""}]","2023-01-25"
"2301.09726","Paul Dubovan","Paul I. Dubovan, Kyle M. Gilbert, Corey A. Baron","Correction of high-order phase variation effects in dynamic field
  monitoring","34 pages, 8 figures, 3 supplementary figures, 3 videos (not included)",,,,"physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Purpose: Field monitoring measures field perturbations, which can be
accounted for during image reconstructions. In certain field monitoring
environments, significant phase deviations can arise far from isocenter due to
the finite extent of the gradient and/or main magnet. This can degrade the
accuracy of field dynamics when field probes are placed near or outside the
diameter spherical volume of the gradient coils and/or main magnet, leading to
corrupted image quality. The objective of this work was to develop a correction
algorithm that reduces errors from highly nonlinear phase variations at distant
field probes in field dynamic fits. Methods: The algorithm is split into three
components. Component one fits phase coefficients one spatial order at a time,
while the second implements a weighted least squares solution based on probe
distance. After initial fitting, component three calculates phase residuals and
removes the phase for distant probes before re-fitting. Two healthy volunteers
were scanned on a head-only 7T MRI using diffusion-weighted single-shot spiral
and EPI sequences and field monitoring was performed. Images were reconstructed
with and without phase coefficient correction and compared qualitatively.
Results: The algorithm was able to correct corrupted field dynamics, resulting
in image quality improvements. Significant artefact reduction was observed when
correcting higher order fits, especially for diffusion weighted images.
Stepwise fitting provided the most correction benefit, which was marginally
improved when adding weighted least squares and phase residual corrections.
Conclusion: The proposed algorithm can mitigate effects of phase errors in
field monitoring, providing improved reliability of field dynamic
characterization.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:28:13 GMT""}]","2023-01-25"
"2301.09727","Adam Ritchey","Adam M. Ritchey (Eureka Scientific), J. M. Brown (Univ. of Toledo), S.
  R. Federman (Univ. of Toledo), and Paule Sonnentrucker (Space Telescope
  Science Institute)","A Reexamination of Phosphorus and Chlorine Depletions in the Diffuse
  Interstellar Medium","44 pages, 21 figures, accepted for publication in ApJ","ApJ, 948:139 (32pp), 2023","10.3847/1538-4357/acc179",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present a comprehensive examination of interstellar P and Cl abundances
based on an analysis of archival spectra acquired with the Space Telescope
Imaging Spectrograph of the Hubble Space Telescope and the Far Ultraviolet
Spectroscopic Explorer. Column densities of P II, Cl I, and Cl II are
determined for a combined sample of 107 sight lines probing diffuse atomic and
molecular gas in the local Galactic interstellar medium (ISM). We reevaluate
the nearly linear relationship between the column densities of Cl I and H$_2$,
which arises from the rapid conversion of Cl$^+$ to Cl$^0$ in regions where
H$_2$ is abundant. Using the observed total gas-phase P and Cl abundances, we
derive depletion parameters for these elements, adopting the methodology of
Jenkins. We find that both P and Cl are essentially undepleted along sight
lines showing the lowest overall depletions. Increasingly severe depletions of
P are seen along molecule-rich sight lines. In contrast, gas-phase Cl
abundances show no systematic variation with molecular hydrogen fraction.
However, enhanced Cl (and P) depletion rates are found for a subset of sight
lines showing elevated levels of Cl ionization. An analysis of neutral chlorine
fractions yields estimates for the amount of atomic hydrogen associated with
the H$_2$-bearing gas in each direction. These results indicate that the
molecular fraction in the H$_2$-bearing gas is at least 10% for all sight lines
with $\log N({\rm H}_2)\gtrsim18$ and that the gas is essentially fully
molecular at $\log N({\rm H}_2)\approx21$.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:34:22 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 22:13:21 GMT""}]","2023-05-30"
"2301.09728","Arian Askari","Arian Askari, Amin Abolghasemi, Gabriella Pasi, Wessel Kraaij, Suzan
  Verberne","Injecting the BM25 Score as Text Improves BERT-Based Re-rankers","Accepted at ECIR 2023",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  In this paper we propose a novel approach for combining first-stage lexical
retrieval models and Transformer-based re-rankers: we inject the relevance
score of the lexical model as a token in the middle of the input of the
cross-encoder re-ranker. It was shown in prior work that interpolation between
the relevance score of lexical and BERT-based re-rankers may not consistently
result in higher effectiveness. Our idea is motivated by the finding that BERT
models can capture numeric information. We compare several representations of
the BM25 score and inject them as text in the input of four different
cross-encoders. We additionally analyze the effect for different query types,
and investigate the effectiveness of our method for capturing exact matching
relevance. Evaluation on the MSMARCO Passage collection and the TREC DL
collections shows that the proposed method significantly improves over all
cross-encoder re-rankers as well as the common interpolation methods. We show
that the improvement is consistent for all query types. We also find an
improvement in exact matching capabilities over both BM25 and the
cross-encoders. Our findings indicate that cross-encoder re-rankers can
efficiently be improved without additional computational burden and extra steps
in the pipeline by explicitly adding the output of the first-stage ranker to
the model input, and this effect is robust for different models and query
types.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:41:25 GMT""}]","2023-01-25"
"2301.09729","Elisa Donati","Elisa Donati, Simone Benatti, Enea Ceolini, and Giacomo Indiveri","Long-term stable Electromyography classification using Canonical
  Correlation Analysis",,,,,"cs.LG cs.HC eess.SP stat.AP","http://creativecommons.org/licenses/by/4.0/","  Discrimination of hand gestures based on the decoding of surface
electromyography (sEMG) signals is a well-establish approach for controlling
prosthetic devices and for Human-Machine Interfaces (HMI). However, despite the
promising results achieved by this approach in well-controlled experimental
conditions, its deployment in long-term real-world application scenarios is
still hindered by several challenges. One of the most critical challenges is
maintaining high EMG data classification performance across multiple days
without retraining the decoding system. The drop in performance is mostly due
to the high EMG variability caused by electrodes shift, muscle artifacts,
fatigue, user adaptation, or skin-electrode interfacing issues. Here we propose
a novel statistical method based on canonical correlation analysis (CCA) that
stabilizes EMG classification performance across multiple days for long-term
control of prosthetic devices. We show how CCA can dramatically decrease the
performance drop of standard classifiers observed across days, by maximizing
the correlation among multiple-day acquisition data sets. Our results show how
the performance of a classifier trained on EMG data acquired only of the first
day of the experiment maintains 90% relative accuracy across multiple days,
compensating for the EMG data variability that occurs over long-term periods,
using the CCA transformation on data obtained from a small number of gestures.
This approach eliminates the need for large data sets and multiple or periodic
training sessions, which currently hamper the usability of conventional pattern
recognition based approaches
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:45:00 GMT""}]","2023-01-25"
"2301.09730","Neil MacVicar","Neil MacVicar","An investigation of multiplicative invariance in the complex plane","27 pages",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  Multiplicative invariance is a well-studied notion in the unit interval. The
picture in the complex plane is less developed. This document introduces an
analogous notion of multiplicative invariance in the complex plane and
establishes similar results of Furstenberg's in this setting. Namely, that the
Hausdorff and box-counting dimensions of a multiplicatively invariant subset
are equal and, furthermore, are equal to the normalized topological entropy of
an underlying subshift. We also extend a formula for the box-counting dimension
of base-$b$ restricted digit sets where $b$ is a suitably chosen Gaussian
integer.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:46:01 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 21:15:47 GMT""}]","2023-01-31"
"2301.09731","Manuela Bischetti","Manuela Bischetti, Fabrizio Fiore, Chiara Feruglio, Valentina
  D'Odorico, Nahum Arav, Tiago Costa, Kastytis Zubovas, George Becker, Sarah E.
  I. Bosman, Guido Cupani, Rebecca Davies, Anna-Christina Eilers, Emanuele
  Paolo Farina, Andrea Ferrara, Massimo Gaspari, Chiara Mazzucchelli, Masafusa
  Onoue, Enrico Piconcelli, Maria-Vittoria Zanchettin, and Yongda Zhu","The fraction and kinematics of broad absorption line quasars across
  cosmic time","Accepted for publication in ApJ",,,,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Luminous quasars are powerful targets to investigate the role of feedback
from supermassive black-holes (BHs) in regulating the growth phases of BHs
themselves and of their host galaxies, up to the highest redshifts. Here we
investigate the cosmic evolution of the occurrence and kinematics of BH-driven
outflows, as traced by broad absorption line (BAL) features, due to the C IV
ionic transition. We exploit a sample of 1935 quasars quasars at $z=2.1-6.6$
with bolometric luminosity log($L_{\rm bol}/$erg s$^{-1})\gtrsim46.5$, drawn
from the Sloan Digital Sky Survey and from the X-shooter legacy survey of
Quasars at Reionisation (XQR-30). We consider rest-frame optical bright quasars
to minimise observational biases due to quasar selection criteria. We apply a
homogeneous BAL identification analysis, based on employing composite template
spectra to estimate the quasar intrinsic emission. We find a BAL quasar
fraction close to 20\% at $z\sim2-4$, while it increases to almost 50\% at
$z\sim6$. The velocity and width of the BAL features also increase at
$z\gtrsim4.5$. We exclude that the redshift evolution of the BAL properties is
due to differences in terms of quasar luminosity and accretion rate. These
results suggest significant BH feedback occurring in the 1 Gyr old Universe,
likely affecting the growth of BHs and, possibly, of their host galaxies, as
supported by models of early BH and galaxy evolution.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:48:13 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 18:17:32 GMT""}]","2023-04-20"
"2301.09732","G\""okberk Yar","Gokberk Yar, Cristina Nita-Rotaru, Alina Oprea","Backdoor Attacks in Peer-to-Peer Federated Learning",,,,,"cs.LG cs.CR","http://creativecommons.org/publicdomain/zero/1.0/","  We study backdoor attacks in peer-to-peer federated learning systems on
different graph topologies and datasets. We show that only 5% attacker nodes
are sufficient to perform a backdoor attack with 42% attack success without
decreasing the accuracy on clean data by more than 2%. We also demonstrate that
the attack can be amplified by the attacker crashing a small number of nodes.
We evaluate defenses proposed in the context of centralized federated learning
and show they are ineffective in peer-to-peer settings. Finally, we propose a
defense that mitigates the attacks by applying different clipping norms to the
model updates received from peers and local model trained by a node.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:49:28 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 02:58:12 GMT""}]","2023-02-08"
"2301.09733","Hamza El-Kebir","Hamza El-Kebir, Junren Ran, Yongseok Lee, Leonardo P. Chamorro, Martin
  Ostoja-Starzewski, Richard Berlin, Gabriela M. Aguiluz Cornejo, Enrico
  Benedetti, Pier C. Giulianotti, Joseph Bentsman","Minimally Invasive Live Tissue High-fidelity Thermophysical Modeling
  using Real-time Thermography","Accepted for publication in the IEEE Transactions on Biomedical
  Engineering. Research reported in this publication was supported by the
  National Institute of Biomedical Imaging and Bioengineering of the National
  Institutes of Health under award number R01EB029766",,"10.1109/TBME.2022.3230728",,"physics.med-ph cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  We present a novel thermodynamic parameter estimation framework for
energy-based surgery on live tissue, with direct applications to tissue
characterization during electrosurgery. This framework addresses the problem of
estimating tissue-specific thermodynamics in real-time, which would enable
accurate prediction of thermal damage impact to the tissue and damage-conscious
planning of electrosurgical procedures. Our approach provides basic
thermodynamic information such as thermal diffusivity, and also allows for
obtaining the thermal relaxation time and a model of the heat source, yielding
in real-time a controlled hyperbolic thermodynamics model. The latter accounts
for the finite thermal propagation time necessary for modeling of the
electrosurgical action, in which the probe motion speed often surpasses the
speed of thermal propagation in the tissue operated on. Our approach relies
solely on thermographer feedback and a knowledge of the power level and
position of the electrosurgical pencil, imposing only very minor adjustments to
normal electrosurgery to obtain a high-fidelity model of the tissue-probe
interaction. Our method is minimally invasive and can be performed in situ. We
apply our method first to simulated data based on porcine muscle tissue to
verify its accuracy and then to in vivo liver tissue, and compare the results
with those from the literature. This comparison shows that parameterizing the
Maxwell--Cattaneo model through the framework proposed yields a noticeably
higher fidelity real-time adaptable representation of the thermodynamic tissue
response to the electrosurgical impact than currently available. A discussion
on the differences between the live and the dead tissue thermodynamics is also
provided.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:54:01 GMT""}]","2023-01-25"
"2301.09734","Christopher Griffin","Christopher Griffin and Trevor Karn and Benjamin Apple","Topological Structure is Predictive of Deep Neural Network Success in
  Learning","11 pages, 6 figures",,,,"cs.LG physics.data-an","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning has become a fundamental tool in modern science, yet its
limitations are still not fully understood. Using a simple children's game, we
show that the topological structure of the underlying training data can have a
dramatic effect on the ability of a deep neural network (DNN) classifier to
learn to classify data. We then take insights obtained from this toy model and
apply them to two physical data sets (one from particle physics and one from
acoustics), which are known to be amenable to classification by DNN's. We show
that the simplicity in their topological structure explains the majority of the
DNN's ability to operate on these data sets by showing that fully interpretable
topological classifiers are able to perform nearly as well as their DNN
counterparts.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:54:25 GMT""}]","2023-01-25"
"2301.09735","Michael V. Klibanov","Michael V. Klibanov","Stability Estimates for Some Parabolic Inverse Problems With the Final
  Overdetermination via a New Carleman Estimate",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is about H\""older and Lipschitz stability estimates and uniqueness
theorems for a coefficient inverse problem and an inverse source problem for a
general linear parabolic equation of the second order. The data for the inverse
problem are given at the final moment of time {t=T}. In addition, both
Dirichlet and Neumann boundary conditions are given either on a part or on the
entire lateral boundary. The key to the proofs is a new Carleman estimate, in
which the Carleman Weight Function is independent on t. As a result, parasitic
integrals over {t=0} and {t=T} in the integral form of the Carleman estimate
cancel each other.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:56:57 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 05:46:16 GMT""}]","2023-03-09"
"2301.09736","Max Auer","Max Auer","Poisson Limit Theorems for Systems with Product Structure","37 pages, 0 figures, Comments are welcome!",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We obtain a Poisson Limit for return times to small sets for product systems.
Only one factor is required to be hyperbolic while the second factor is only
required to satisfy polynomial deviation bounds for ergodic sums. In
particular, the second fact can be either elliptic or parabolic. As an
application of our main result, several maps of the form Anosov map $\times$
another map are shown to satisfy a Poisson Limit Theorem at typical points,
some even at all points.\\ The methods can be extended to certain types of skew
products, including $T,T^{-1}$-maps of high rank.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:57:23 GMT""}]","2023-01-25"
"2301.09737","Hachi Cui","Cheng-Jun Wang, Lihan Yan, Haochuan Cui","Unpacking the Essential Tension of Knowledge Recombination: Analyzing
  the Impact of Knowledge Spanning on Citation Counts and Disruptive Innovation","32 pages, 6 figures",,,,"cs.SI cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Drawing on the theories of knowledge recombination, we aim to unpack the
essential tension between tradition and innovation in scientific research.
Using the American Physical Society data and computational methods, we analyze
the impact of knowledge spanning on both citation counts and disruptive
innovation. The findings show that knowledge spanning has a U-shaped impact on
disruptive innovation. In contrast, there is an inverted U-shaped relationship
between knowledge spanning and citation counts, and the inverted U-shaped
effect is moderated by team size. This study contributes to the theories of
knowledge recombination by suggesting that both intellectual conformism and
knowledge recombination can lead to disruptive innovation. That is, when
evaluating the quality of scientific research with disruptive innovation, the
essential tension seems to disappear.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:58:35 GMT""},{""version"":""v2"",""created"":""Sat, 28 Jan 2023 14:49:21 GMT""}]","2023-01-31"
"2301.09738","Hansika Madushan Weerasena Loku Kattadige","Hansika Weerasena and Prabhat Mishra","Security of Electrical, Optical and Wireless On-Chip Interconnects: A
  Survey","35 pages, 16 figures, 3 tables",,,,"cs.CR cs.AR cs.NI","http://creativecommons.org/licenses/by/4.0/","  The advancement of manufacturing technologies has enabled the integration of
more intellectual property (IP) cores on the same system-on-chip (SoC).
Scalable and high throughput on-chip communication architecture has become a
vital component in today's SoCs. Diverse technologies such as electrical,
wireless, optical, and hybrid are available for on-chip communication with
different architectures supporting them. Security of the on-chip communication
is crucial because exploiting any vulnerability would be a goldmine for an
attacker. In this survey, we provide a comprehensive review of threat models,
attacks, and countermeasures over diverse on-chip communication technologies as
well as sophisticated architectures.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 21:58:53 GMT""}]","2023-01-25"
"2301.09739","Hachi Cui","Haochuan Cui, Tiewei Li, Cheng-Jun Wang","Breaking the Boundaries of Knowledge Space: Analyzing the Knowledge
  Spanning on the Q&A Website through Word Embeddings","32 pages, 5 figures",,,,"cs.SI cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The challenge of raising a creative question exists in recombining different
categories of knowledge. However, the impact of recombination remains
controversial. Drawing on the theories of knowledge recombination and category
spanning, we propose that both the distance of knowledge spanning and the
hierarchy of knowledge shape the appeal of questions. Using word embedding
models and the data collected from a large online knowledge market (N =
463,545), we find that the impact of knowledge spanning on the appeal of
questions is parabolic: the appeal of questions increases up to a threshold,
after which point the positive effect reverses. However, the nonlinear
influence of knowledge spanning is contingent upon the hierarchy of knowledge.
The theoretical and practical implications of these findings for future
research on knowledge recombination are discussed. We fill the research gap by
conceptualizing question asking as knowledge spanning and highlighting the
theoretical underpinnings of the knowledge hierarchy.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:04:30 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 02:27:13 GMT""}]","2023-01-31"
"2301.09740","Onat Gungor","Onat Gungor, Tajana Rosing, Baris Aksanli","DODEM: DOuble DEfense Mechanism Against Adversarial Attacks Towards
  Secure Industrial Internet of Things Analytics",,,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Industrial Internet of Things (I-IoT) is a collaboration of devices, sensors,
and networking equipment to monitor and collect data from industrial
operations. Machine learning (ML) methods use this data to make high-level
decisions with minimal human intervention. Data-driven predictive maintenance
(PDM) is a crucial ML-based I-IoT application to find an optimal maintenance
schedule for industrial assets. The performance of these ML methods can
seriously be threatened by adversarial attacks where an adversary crafts
perturbed data and sends it to the ML model to deteriorate its prediction
performance. The models should be able to stay robust against these attacks
where robustness is measured by how much perturbation in input data affects
model performance. Hence, there is a need for effective defense mechanisms that
can protect these models against adversarial attacks. In this work, we propose
a double defense mechanism to detect and mitigate adversarial attacks in I-IoT
environments. We first detect if there is an adversarial attack on a given
sample using novelty detection algorithms. Then, based on the outcome of our
algorithm, marking an instance as attack or normal, we select adversarial
retraining or standard training to provide a secondary defense layer. If there
is an attack, adversarial retraining provides a more robust model, while we
apply standard training for regular samples. Since we may not know if an attack
will take place, our adaptive mechanism allows us to consider irregular changes
in data. The results show that our double defense strategy is highly efficient
where we can improve model robustness by up to 64.6% and 52% compared to
standard and adversarial retraining, respectively.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:10:40 GMT""}]","2023-01-25"
"2301.09741","Julianna S. Tymoczko","Rebecca Goldin and Julianna Tymoczko","Which Hessenberg varieties are GKM?","31 pages. Accepted for publication in Pure and Applied Math Quarterly",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  Hessenberg varieties $\mathcal{H}(X,H)$ form a class of subvarieties of the
flag variety $G/B$, parameterized by an operator $X$ and certain subspaces $H$
of the Lie algebra of $G$. We identify several families of Hessenberg varieties
in type $A_{n-1}$ that are $T$-stable subvarieties of $G/B$, as well as
families that are invariant under a subtorus $K$ of $T$. In particular, these
varieties are candidates for the use of equivariant methods to study their
geometry. Indeed, we are able to show that some of these varieties are unions
of Schubert varieties, while others cannot be such unions.
  Among the $T$-stable Hessenberg varieties, we identify several that are {\it
GKM spaces}, meaning $T$ acts with isolated fixed points and a finite number of
one-dimensional orbits, though we also show that not all Hessenberg varieties
with torus actions and finitely many fixed points are GKM.
  We conclude with a series of open questions about Hessenberg varieties, both
in type $A_{n-1}$ and in general Lie type.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:11:24 GMT""}]","2023-01-25"
"2301.09742","Tushar Pandey","Tushar Pandey","Topological Understanding of Neural Networks, a survey","Literature Review",,,,"cs.LG math.AT","http://creativecommons.org/licenses/by/4.0/","  We look at the internal structure of neural networks which is usually treated
as a black box. The easiest and the most comprehensible thing to do is to look
at a binary classification and try to understand the approach a neural network
takes. We review the significance of different activation functions, types of
network architectures associated to them, and some empirical data. We find some
interesting observations and a possibility to build upon the ideas to verify
the process for real datasets. We suggest some possible experiments to look
forward to in three different directions.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:11:37 GMT""}]","2023-01-25"
"2301.09743","Adam Ritchey","Adam M. Ritchey (Eureka Scientific), Edward B. Jenkins (Princeton
  Univ.), J. Michael Shull (Univ. of Colorado), Blair D. Savage (Univ. of
  Wisconsin), S. R. Federman (Univ. of Toledo), David L. Lambert (Univ. of
  Texas at Austin)","The Distribution of Metallicities in the Local Galactic Interstellar
  Medium","34 pages, 14 figures, accepted for publication in ApJ",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  In this investigation, we present an analysis of the metallicity distribution
that pertains to neutral gas in the local Galactic interstellar medium (ISM).
We derive relative ISM metallicities for a sample of 84 sight lines probing
diffuse atomic and molecular gas within 4 kpc of the Sun. Our analysis is
based, in large part, on column density measurements reported in the literature
for 22 different elements that are commonly studied in interstellar clouds. We
supplement the literature data with new column density determinations for
certain key elements and for several individual sight lines important to our
analysis. Our methodology involves comparing the relative gas-phase abundances
of many different elements for a given sight line to simultaneously determine
the strength of dust depletion in that direction and the overall metallicity
offset. We find that many sight lines probe multiple distinct gas regions with
different depletion properties, which complicates the metallicity analysis.
Nevertheless, our results provide clear evidence that the dispersion in the
metallicities of neutral interstellar clouds in the solar neighborhood is small
($\sim$0.10 dex) and only slightly larger than the typical measurement
uncertainties. We find no evidence for the existence of very low metallicity
gas (as has recently been reported by De Cia et al.) along any of the 84 sight
lines in our sample. Our results are consistent with a local Galactic ISM that
is well mixed and chemically homogeneous.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:12:14 GMT""},{""version"":""v2"",""created"":""Fri, 12 May 2023 20:29:28 GMT""}]","2023-05-16"
"2301.09744","William Erickson","William Q. Erickson and Markus Hunziker","Dimension identities, almost self-conjugate partitions, and BGG
  complexes for Hermitian symmetric pairs","33 pages, 5 figures, 4 tables",,,,"math.CO math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An almost self-conjugate (ASC) partition has a Young diagram in which each
arm along the diagonal is exactly one box longer than its corresponding leg.
Classically, the ASC partitions and their conjugates appear in two of
Littlewood's symmetric function identities. These identities can be viewed as
Euler characteristics of BGG complexes of the trivial representation, for
classical Hermitian symmetric pairs. In this paper, we consider partitions in
which the arm-leg difference is an arbitrary constant $m$. Regarding these
partitions and their conjugates as highest weights, we prove an identity
yielding an infinite family of dimension equalities between $\mathfrak{gl}_n$-
and $\mathfrak{gl}_{n+m}$-modules. We then interpret this combinatorial result
in the context of blocks in parabolic category $\mathcal{O}$: using
Enright-Shelton reduction, we find six infinite families of congruent blocks
whose corresponding posets of highest weights consist of the partitions in
question. These posets, in turn, lead to generalizations of the Littlewood
identities and their corresponding BGG complexes. Our results in this paper
shed light on the surprising combinatorics underlying the work of Enright and
Willenbring (2004).
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:13:39 GMT""}]","2023-01-25"
"2301.09745","Aitazaz Raja","A. A. Raja and S. Grammatico","A fair Peer-to-Peer Electricity Market model for Residential Prosumers",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a bilateral peer-to-peer (P2P) energy trading
scheme for residential prosumers with a simplified entry to the market. We
formulate the market as an assignment game, a special class of coalitional
games. For solving the resulting decision problem, we design a bilateral
negotiation mechanism that enables matched buyer-seller pairs to reach a
consensus on a set of ``stable"" and ``fair"" trading contracts. The proposed
negotiation process can be executed on possibly time-varying communication
networks with virtually minimal information requirements that in turn preserves
privacy among prosumers. Numerical simulations illustrate the beneficial
features of our P2P market model and negotiation protocol.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:22:47 GMT""}]","2023-01-25"
"2301.09746","Patrick Kamieneski","Patrick S. Kamieneski, Min S. Yun, Kevin C. Harrington, James D.
  Lowenthal, Q. Daniel Wang, Brenda L. Frye, Eric F. Jimenez-Andrade, Amit
  Vishwas, Olivia Cooper, Massimo Pascale, Nicholas Foo, Derek Berman, Anthony
  Englert, Carlos Garcia Diaz","PASSAGES: the wide-ranging, extreme intrinsic properties of
  Planck-selected, lensed dusty star-forming galaxies","48 pages, 12 figures, 6 tables. Submitted to ApJ",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The PASSAGES ($Planck$ All-Sky Survey to Analyze Gravitationally-lensed
Extreme Starbursts) collaboration has recently defined a sample of 30
gravitationally-lensed dusty star-forming galaxies (DSFGs). These rare,
submillimeter-selected objects enable high-resolution views of the most extreme
sites of star formation in galaxies at Cosmic Noon. Here, we present the first
major compilation of strong lensing analyses using LENSTOOL for PASSAGES,
including 15 objects spanning $z=1.1-3.3$, using complementary information from
$0.6^{\prime\prime}$-resolution 1 mm Atacama Large Millimeter/submillimeter
Array (ALMA) and $0.4^{\prime\prime}$ 5 cm Jansky Very Large Array continuum
imaging, in tandem with 1.6$\mu$m $Hubble$ and optical imaging with Gemini-S.
Magnifications range from $\mu = 2 - 28$ (median $\mu=7$), yielding intrinsic
infrared luminosities of $L_{\rm IR} = 0.2 - 5.9 \times 10^{13}~L_\odot$
(median ${1.4}\times 10^{13}~L_\odot$) and inferred star formation rates of
$170-6300~M_\odot~{\rm yr}^{-1}$ (median $1500~M_\odot~{\rm yr}^{-1}$). These
results suggest that the PASSAGES objects comprise some of the most extreme
known starbursts, rivaling the luminosities of even the brightest unlensed
objects, further amplified by lensing. The intrinsic sizes of far-infrared
continuum regions are large ($R_{\rm e} = {1.7 - 4.3}$ kpc; median $3.0$ kpc)
but consistent with $L_{\rm IR}-R_{\rm e}$ scaling relations for $z>1$ DSFGs,
suggesting a widespread spatial distribution of star formation. With
modestly-high angular resolution, we explore if these objects might be maximal
starbursts. Instead of approaching Eddington-limited surface densities, above
which radiation pressure will disrupt further star formation, they are safely
sub-Eddington -- at least on global, galaxy-integrated scales.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:24:32 GMT""}]","2023-01-25"
"2301.09747","Zohreh Hirbodvash","Zohreh Hirbodvash, and Pierre Berini","Surface Plasmon Electrochemistry","53 pages, 22 figures",,,,"physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Surface plasmon polaritons (SPPs) are optical waves that propagate along a
metal surface. They exhibit properties such as sub-wavelength localization and
field enhancement which make them attractive for surface sensing, as commonly
encountered in surface plasmon biosensors - the most widespread of all optical
biosensors. Electrochemistry also occurs on metal surfaces, and electrochemical
approaches are widely used to implement biosensors - electrochemical biosensors
are the most prevalent biosensors in use. Given that metal surfaces are
inherent to both techniques, it is natural to combine them into a single
platform. The motivation may be (i) to realise a multimodal biosensor
(electrochemical, optical), (ii) to use SPPs to probe electrochemical activity
or the electrochemical double layer, thereby revealing additional or
complementary information on the redox reactions occurring thereon, or (iii) to
use SPPs to affect (pump) electrochemical reactions with non-equilibrium
energetic (hot) electrons and holes created in working electrodes by SPP
absorption, potentially leading to novel redox reaction pathways (plasmonic
electrocatalysis). We introduce in a tutorial-like fashion basic concepts
related to SPPs on planar structures and to electrochemistry, then we review
non-exhaustively but representatively literature on the integration of these
techniques.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:30:01 GMT""}]","2023-01-25"
"2301.09748","Saeed Karimi-Bidhendi","Saeed Karimi-Bidhendi, Giovanni Geraci, Hamid Jafarkhani","Analysis of UAV Corridors in Cellular Networks","to be published in IEEE International Conference on Communications
  2023",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we introduce a new mathematical framework for the analysis
and design of UAV corridors in cellular networks, while considering a realistic
network deployment, antenna radiation pattern, and propagation channel model.
By leveraging quantization theory, we optimize the electrical tilts of existing
ground cellular base stations to maximize the coverage of both legacy ground
users and UAVs flying along specified aerial routes. Our practical case study
shows that the optimized network results in a cell partitioning that
significantly differs from the usual hexagonal pattern, and that it can
successfully guarantee coverage all over the UAV corridors without degrading
the perceived signal strength on the ground.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:30:30 GMT""}]","2023-01-25"
"2301.09749","Peixin Chang","Peixin Chang, Shuijing Liu, Tianchen Ji, Neeloy Chakraborty, D.
  Livingston McPherson, Katherine Driggs-Campbell","Learning Rewards and Skills to Follow Commands with A Data Efficient
  Visual-Audio Representation",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Based on the recent advancements in representation learning, we propose a
novel framework for command-following robots with raw sensor inputs. Previous
RL-based methods are either difficult to continuously improve after the
deployment or require a large number of new labels during the fine-tuning.
Motivated by (self-)supervised contrastive learning literature, we propose a
novel representation, named VAR++, that generates an intrinsic reward function
for command-following robot tasks by associating images with sound commands.
After the robot is deployed in a new domain, the representation can be updated
intuitively and data-efficiently by non-experts, and the robot is able to
fulfill sound commands without any hand-crafted reward functions. We
demonstrate our approach on various sound types and robotic tasks, including
navigation and manipulation with raw sensor inputs. In the simulated
experiments, we show that our system can continually self-improve in previously
unseen scenarios given fewer new labeled data, yet achieves better performance,
compared with previous methods.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:40:18 GMT""}]","2023-01-25"
"2301.09750","Yasir Abdul Qadir","Yasir Abdul Qadir, Andrei V. Berdyugin, Vilppu Piirola, Takeshi
  Sakanoi, Masato Kagitani","High-precision broadband linear polarimetry of early-type binaries III.
  AO Cassiopeiae revisited",,"A&A 670, A176 (2023)","10.1051/0004-6361/202245452",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The fact that the O-type close binary star system AO~Cassiopeiae exhibits
variable phase-locked linear polarization has been known since the mid-1970s.
In this work, we re-observe the polarization arising from this system more than
50 years later to better estimate the interstellar polarization and to
independently derive the orbital parameters, such as inclination, $i$,
orientation, $\Omega$, and the direction of the rotation for the inner orbit
from the phase-folded polarization curves of the Stokes $q$ and $u$ parameters.
The Dipol-2 polarimeter was used to obtain linear polarization measurements of
AO~Cassiopeiae in the $B$, $V$, and $R$ passbands with the T60 remotely
controlled telescope at an unprecedented accuracy level of $\sim$0.003\%. We
have obtained the first proper quantification of the interstellar polarization
in the direction heading towards AO~Cas by observing the polarization of three
neighboring field stars. We employed a Lomb-Scargle algorithm and detected a
clear periodic signal for the orbital period of AO~Cas. The standard analytical
method based on a two-harmonics Fourier fit was used to obtain the inclination
and orientation of the binary orbit. Our polarimetric data exhibited an
unambiguous periodic signal at 1.76 days, thus confirming the orbital period of
the binary system of 3.52 days. Most of the observed polarization is of
interstellar origin. The de-biased values of the orbital inclination are $i =
63^{\circ} +2^{\circ}/ -3^{\circ}$ and orientation of $\Omega = 29^{\circ}
(209^{\circ}) \pm 8^{\circ}$. The direction of the binary system rotation on
the plane of the sky is clockwise.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:42:50 GMT""}]","2023-03-01"
"2301.09751","Ezzedine Mliki","Ezzedine Mliki","On the fractional mixed fractional Brownian motion Time Changed by
  Inverse alpha Stable Subordinator","10 pages",,,,"math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A time-changed fractional mixed fractional Brownian motion by inverse alpha
stable subordinator with index alpha in (0, 1) is an iterated process L
constructed as the superposition of fractional mixed fractional Brownian motion
N(a, b) and an independent inverse {\alpha}-stable subordinator Talpha. In this
paper we prove that the process LT alpha(a, b) is of long range dependence
property under a smooth condition on the Hirsh index H1 and H2. We deduce that
the fractional mixed fractional Brownian motion has long range dependence for
every H1 < H2.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:49:58 GMT""}]","2023-01-25"
"2301.09752","Edon Kelmendi","Faraz Ghahremani, Edon Kelmendi, Jo\""el Ouaknine","Reachability in Injective Piecewise Affine Maps",,,,,"math.DS cs.FL cs.LO","http://creativecommons.org/licenses/by/4.0/","  One of the most basic, longstanding open problems in the theory of dynamical
systems is whether reachability is decidable for one-dimensional piecewise
affine maps with two intervals. In this paper we prove that for injective maps,
it is decidable. We also study various related problems, in each case either
establishing decidability, or showing that they are closely connected to
Diophantine properties of certain transcendental numbers, analogous to the
positivity problem for linear recurrence sequences. Lastly, we consider
topological properties of orbits of one-dimensional piecewise affine maps, not
necessarily with two intervals, and negatively answer a question of Bournez,
Kurganskyy, and Potapov, about the set of orbits in expanding maps.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:54:18 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 15:53:08 GMT""}]","2023-03-20"
"2301.09753","Samiyuru Menik","Samiyuru Menik, Lakshmish Ramaswamy","Towards Modular Machine Learning Solution Development: Benefits and
  Trade-offs",,,,,"cs.LG cs.SE","http://creativecommons.org/licenses/by/4.0/","  Machine learning technologies have demonstrated immense capabilities in
various domains. They play a key role in the success of modern businesses.
However, adoption of machine learning technologies has a lot of untouched
potential. Cost of developing custom machine learning solutions that solve
unique business problems is a major inhibitor to far-reaching adoption of
machine learning technologies. We recognize that the monolithic nature
prevalent in today's machine learning applications stands in the way of
efficient and cost effective customized machine learning solution development.
In this work we explore the benefits of modular machine learning solutions and
discuss how modular machine learning solutions can overcome some of the major
solution engineering limitations of monolithic machine learning solutions. We
analyze the trade-offs between modular and monolithic machine learning
solutions through three deep learning problems; one text based and the two
image based. Our experimental results show that modular machine learning
solutions have a promising potential to reap the solution engineering
advantages of modularity while gaining performance and data advantages in a way
the monolithic machine learning solutions do not permit.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:54:34 GMT""}]","2023-01-25"
"2301.09754","Lauren Liao","Lauren D. Liao, Yeyi Zhu, Amanda L. Ngo, Rana F. Chehab, Samuel D.
  Pimentel","Using Joint Variable Importance Plots to Prioritize Variables in
  Assessing the Impact of Glyburide on Adverse Birth Outcomes","18 pages, 3 figures",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  The only pharmacologic treatment for gestational diabetes (GDM) approved by
U.S. Food and Drug Administration is insulin. However, due to improved ease of
use and lower cost, oral antidiabetic medications, such as glyburide, are
prescribed more commonly than insulin. We investigate glyburide's impact on two
adverse perinatal outcomes compared to medical nutritional therapy, the
universal first-line therapy, in a large, population-based cohort. At the
design stage, we employ matching to select comparable treated subjects(received
glyburide) and controls (received medical nutritional therapy). Multiple
background variables were associated with GDM treatment modality and perinatal
outcomes; however, there is ambiguity about which of the many potential
confounding variables should be prioritized in matching. Standard selection
methods based on treatment imbalance alone neglect variables' relationships
with the outcome. Thus, we propose the joint variable importance plot
(jointVIP) to guide variable prioritization for this study. This plot adds
outcome associations on a second dimension to better contextualize standard
imbalance measures, further enhances variable comparisons using unadjusted bias
curves derived under the omitted variable bias framework, and can produce
recommended values for tuning parameters in existing methods. After forming
matched pairs, we conduct inference for adverse effects of glyburide and
perform sensitivity analyses to assess the potential role of unmeasured
confounding. Our findings of no reliable adverse effect of glyburide inform
future pharmacologic treatment strategies to manage GDM.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:56:35 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 03:35:33 GMT""}]","2023-03-09"
"2301.09755","Michael Pearce","Michael Pearce, Elena A. Erosheva","Modeling Preferences: A Bayesian Mixture of Finite Mixtures for Rankings
  and Ratings","41 pages, 16 figures",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Rankings and ratings are commonly used to express preferences but provide
distinct and complementary information. Rankings give ordinal and scale-free
comparisons but lack granularity; ratings provide cardinal and granular
assessments but may be highly subjective or inconsistent. Collecting and
analyzing rankings and ratings jointly has not been performed until recently
due to a lack of principled methods. In this work, we propose a flexible, joint
statistical model for rankings and ratings under heterogeneous preferences: the
Bradley-Terry-Luce-Binomial (BTL-Binomial). We employ a Bayesian mixture of
finite mixtures (MFM) approach to estimate heterogeneous preferences,
understand their inherent uncertainty, and make accurate decisions based on
ranking and ratings jointly. We demonstrate the efficiency and practicality of
the BTL-Binomial MFM approach on real and simulated datasets of ranking and
rating preferences in peer review and survey data contexts.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 23:03:25 GMT""}]","2023-01-25"
"2301.09756","Gunbir Singh Baveja","Gunbir Singh Baveja and Jaspreet Singh","Earthquake Magnitude and b value prediction model using Extreme Learning
  Machine","11 pages, 13 figures, 2 tables",,,,"physics.geo-ph cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Earthquake prediction has been a challenging research area for many decades,
where the future occurrence of this highly uncertain calamity is predicted. In
this paper, several parametric and non-parametric features were calculated,
where the non-parametric features were calculated using the parametric
features. $8$ seismic features were calculated using Gutenberg-Richter law, the
total recurrence, and the seismic energy release. Additionally, criterions such
as Maximum Relevance and Maximum Redundancy were applied to choose the
pertinent features. These features along with others were used as input for an
Extreme Learning Machine (ELM) Regression Model. Magnitude and time data of $5$
decades from the Assam-Guwahati region were used to create this model for
magnitude prediction. The Testing Accuracy and Testing Speed were computed
taking the Root Mean Squared Error (RMSE) as the parameter for evaluating the
mode. As confirmed by the results, ELM shows better scalability with much
faster training and testing speed (up to a thousand times faster) than
traditional Support Vector Machines. The testing RMSE came out to be around
$0.097$. To further test the model's robustness -- magnitude-time data from
California was used to calculate the seismic indicators which were then fed
into an ELM and then tested on the Assam-Guwahati region. The model proves to
be robust and can be implemented in early warning systems as it continues to be
a major part of Disaster Response and management.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 23:27:22 GMT""}]","2023-01-25"
"2301.09757","Bernardo Anibal Subercaseaux Roa","Bernardo Subercaseaux and Marijn J. H. Heule","The Packing Chromatic Number of the Infinite Square Grid is 15",,,,,"cs.DM cs.AI math.CO","http://creativecommons.org/licenses/by/4.0/","  A packing $k$-coloring is a natural variation on the standard notion of graph
$k$-coloring, where vertices are assigned numbers from $\{1, \ldots, k\}$, and
any two vertices assigned a common color $c \in \{1, \ldots, k\}$ need to be at
a distance greater than $c$ (as opposed to $1$, in standard graph colorings).
Despite a sequence of incremental work, determining the packing chromatic
number of the infinite square grid has remained an open problem since its
introduction in 2002. We culminate the search by proving this number to be 15.
We achieve this result by improving the best-known method for this problem by
roughly two orders of magnitude. The most important technique to boost
performance is a novel, surprisingly effective propositional encoding for
packing colorings. Additionally, we developed an alternative symmetry-breaking
method. Since both new techniques are more complex than existing techniques for
this problem, a verified approach is required to trust them. We include both
techniques in a proof of unsatisfiability, reducing the trusted core to the
correctness of the direct encoding.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 23:27:41 GMT""}]","2023-01-25"
"2301.09758","Asal Mehditabrizi","Asal Mehditabrizi, Mahdi Samadzad, Sina Sabzekar","A deep reinforcement learning approach to assess the low-altitude
  airspace capacity for urban air mobility","15 pages, 12 figures, 1 table",,,,"cs.RO cs.AI eess.SP","http://creativecommons.org/licenses/by/4.0/","  Urban air mobility is the new mode of transportation aiming to provide a fast
and secure way of travel by utilizing the low-altitude airspace. This goal
cannot be achieved without the implementation of new flight regulations which
can assure safe and efficient allocation of flight paths to a large number of
vertical takeoff/landing aerial vehicles. Such rules should also allow
estimating the effective capacity of the low-altitude airspace for planning
purposes. Path planning is a vital subject in urban air mobility which could
enable a large number of UAVs to fly simultaneously in the airspace without
facing the risk of collision. Since urban air mobility is a novel concept,
authorities are still working on the redaction of new flight rules applicable
to urban air mobility. In this study, an autonomous UAV path planning framework
is proposed using a deep reinforcement learning approach and a deep
deterministic policy gradient algorithm. The objective is to employ a
self-trained UAV to reach its destination in the shortest possible time in any
arbitrary environment by adjusting its acceleration. It should avoid collisions
with any dynamic or static obstacles and avoid entering prior permission zones
existing on its path. The reward function is the determinant factor in the
training process. Thus, two different reward function compositions are compared
and the chosen composition is deployed to train the UAV by coding the RL
algorithm in python. Finally, numerical simulations investigated the success
rate of UAVs in different scenarios providing an estimate of the effective
airspace capacity.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 23:38:05 GMT""}]","2023-01-25"
"2301.09759","Yamen Ajjour","Yamen Ajjour, Johannes Kiesel, Benno Stein, and Martin Potthast","Topic Ontologies for Arguments",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Many computational argumentation tasks, like stance classification, are
topic-dependent: the effectiveness of approaches to these tasks significantly
depends on whether the approaches were trained on arguments from the same
topics as those they are tested on. So, which are these topics that researchers
train approaches on? This paper contributes the first comprehensive survey of
topic coverage, assessing 45 argument corpora. For the assessment, we take the
first step towards building an argument topic ontology, consulting three
diverse authoritative sources: the World Economic Forum, the Wikipedia list of
controversial topics, and Debatepedia. Comparing the topic sets between the
authoritative sources and corpora, our analysis shows that the corpora
topics-which are mostly those frequently discussed in public online fora - are
covered well by the sources. However, other topics from the sources are less
extensively covered by the corpora of today, revealing interesting future
directions for corpus construction.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 23:43:24 GMT""}]","2023-01-25"
"2301.09760","Peter Vang Uttenthal","Peter Vang Uttenthal","Density of Selmer ranks in families of even Galois representations","43 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper concerns an even, reducible residual Galois representation in even
characteristic. By thickening the image with cohomology classes, all lifts of
the representation are ensured to be irreducible. The global reciprocity law of
Galois cohomology is applied to lift the representation to mod 8, and smooth
quotients of the local deformation rings at the primes where the representation
is ramified are found. By using the generic smoothness of the local deformation
rings at trivial primes and the Wiles-Greenberg formula, a balanced global
setting is created, in the sense that the Selmer group and the dual Selmer
group have the same rank. The Selmer group is computed explicitly and shown to
have rank three. Finally, the distribution over primes of the ranks of Selmer
groups in a family of even representations obtained by allowing ramification at
auxiliary primes is studied. The infinitude of primes for which the Selmer rank
increases by one is proved, and the density of such primes is shown to be
1/192.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:01:15 GMT""}]","2023-01-25"
"2301.09761","Jayasree Sengupta","Jayasree Sengupta and Sushmita Ruj and Sipra Das Bit","FairShare: Blockchain Enabled Fair, Accountable and Secure Data Sharing
  for Industrial IoT","15 pages, 10 figures and 9 tables","IEEE Transactions on Network and Service Management, 25 January
  2023","10.1109/TNSM.2023.3239832",,"cs.CR cs.NI","http://creativecommons.org/licenses/by/4.0/","  Industrial Internet of Things (IIoT) opens up a challenging research area
towards improving secure data sharing which currently has several limitations.
Primarily, the lack of inbuilt guarantees of honest behavior of participating,
such as end-users or cloud behaving maliciously may result in disputes. Given
such challenges, we propose a fair, accountable, and secure data sharing
scheme, $\textit{FairShare}$ for IIoT. In this scheme, data collected from IoT
devices are processed and stored in cloud servers with intermediate fog nodes
facilitating computation. Authorized clients can access this data against some
fee to make strategic decisions for improving the operational services of the
IIoT system. By enabling blockchain, $\textit{FairShare}$ prevents fraudulent
activities and thereby achieves fairness such that each party gets their
rightful outcome in terms of data or penalty/rewards while simultaneously
ensuring accountability of the services provided by the parties. Additionally,
smart contracts are designed to act as a mediator during any dispute by
enforcing payment settlement. Further, security and privacy of data are ensured
by suitably applying cryptographic techniques like proxy re-encryption. We
prove $\textit{FairShare}$ to be secure as long as at least one of the parties
is honest. We validate $\textit{FairShare}$ with a theoretical overhead
analysis. We also build a prototype in Ethereum to estimate performance and
justify comparable results with a state-of-the-art scheme both via simulation
and a realistic testbed setup. We observe an additional communication overhead
of 256 bytes and a cost of deployment of 1.01 USD in Ethereum which are
constant irrespective of file size.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:10:03 GMT""},{""version"":""v2"",""created"":""Sat, 28 Jan 2023 11:37:49 GMT""}]","2023-01-31"
"2301.09762","Tibor Dome","Tibor Dome, Anastasia Fialkov, Nina Sartorio and Philip Mocz","Cosmic Web Dissection in Fuzzy Dark Matter Cosmologies","16 pages, 7 figures, comments welcome",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  On large cosmological scales, anisotropic gravitational collapse is manifest
in the dark cosmic web. Its statistical properties are well known for the
standard $\Lambda$CDM cosmology, yet become modified for alternative dark
matter models such as fuzzy dark matter (FDM). In this work, we assess for the
first time the relative importance of cosmic nodes, filaments, walls and voids
in a cosmology with small-scale suppression of power such as FDM. By applying
the NEXUS+ Multiscale Morphology Filter technique to cosmological $N$-body
simulations of FDM-like cosmologies, we quantify the mass and volume filling
fractions of cosmic environments at redshifts $z\sim 3.4-5.6$ and find that 2D
cosmic sheets host a larger share of the matter content of the Universe ($\sim
5$% increase for the $m=7 \times 10^{-22}$ eV model compared to CDM) as the
particle mass $m$ is reduced. We find that the suppression of node-, filament-,
wall- and void-conditioned halo mass functions at the low-mass end can occur
well above the half-mode mass $M_{1/2}$. We show that log overdensity PDFs are
more peaked in FDM-like cosmologies with medians shifted to higher values, a
result of the suppression of the low overdensity tail as $m$ is reduced.
Skewness estimates $S_3$ of the unconditioned overdensity PDF $P(\delta)$ in
FDM-like cosmologies are systematically higher than in CDM, more so at high
redshift $z\sim 5.5$ where the $m=10^{-22}$ eV model differs from CDM by $\sim
2 \sigma$. Accordingly, we advocate for the usage of $P(\delta)$ as a testbed
for constraining FDM and other alternative dark matter models.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:11:36 GMT""}]","2023-01-25"
"2301.09763","Brendon Rhoades","Brendon Rhoades and Andy Wilson","The Hilbert series of the superspace coinvariant ring","32 pages, 1 figure",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\Omega_n$ be the ring of polynomial-valued holomorphic differential
forms on complex $n$-space, referred to in physics as the superspace ring of
rank $n$. The symmetric group $\mathfrak{S}_n$ acts diagonally on $\Omega_n$ by
permuting commuting and anticommuting generators simultaneously. We let $SI_n
\subseteq \Omega_n$ be the ideal generated by $\mathfrak{S}_n$-invariants with
vanishing constant term and study the quotient $SR_n = \Omega_n / SI_n$ of
superspace by this ideal. We calculate the doubly-graded Hilbert series of
$SR_n$ and prove an `operator theorem' which characterizes the harmonic space
$SH_n \subseteq \Omega_n$ attached to $SR_n$ in terms of the Vandermonde
determinant and certain differential operators. Our methods employ commutative
algebra results which were used in the study of Hessenberg varieties. Our
results prove conjectures of N. Bergeron, Li, Machacek, Sulzgruber, Swanson,
Wallach, and Zabrocki.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:24:43 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 20:15:50 GMT""}]","2023-03-24"
"2301.09764","Ciprian Manolescu","Ciprian Manolescu, Michael Willis","A Rasmussen invariant for links in $\mathbb{RP}^3$","31 pages",,,,"math.GT math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Asaeda-Przytycki-Sikora, Manturov, and Gabrov\v{s}ek extended Khovanov
homology to links in $\mathbb{RP}^3$. We construct a Lee-type deformation of
their theory, and use it to define an analogue of Rasmussen's s-invariant in
this setting. We show that the s-invariant gives constraints on the genera of
link cobordisms in the cylinder $I \times \mathbb{RP}^3$. As an application, we
give examples of freely 2-periodic knots in $S^3$ that are concordant but not
standardly equivariantly concordant.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:29:33 GMT""}]","2023-01-25"
"2301.09765","Vasilisa Shramchenko","Anwar Al Ghabra, K. Gopala Krishna, Patrick Labelle, Vasilisa
  Shramchenko","Enumeration of multi-rooted plane trees","28 pages, 3 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give closed form expressions for the numbers of multi-rooted plane trees
with specified degrees of root vertices. This results in an infinite number of
integer sequences some of which are known to have an alternative
interpretation. We also propose recursion relations for numbers of such trees
as well as for the corresponding generating functions. Explicit expressions for
the generating functions corresponding to plane trees having two and three
roots are derived. As a by-product, we obtain a new binomial identity and a
conjecture relating hypergeometric functions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:30:21 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 13:15:22 GMT""}]","2023-05-04"
"2301.09766","Abhineet Jain","Abhineet Jain, Jack Kolb and Harish Ravichandar","Constrained Reinforcement Learning for Dexterous Manipulation","Accepted in the International Workshop on Safe Reinforcement Learning
  at the 31st International Joint Conference on Artificial Intelligence (IJCAI
  2022). 6 pages, 5 figures",,,,"cs.RO cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Existing learning approaches to dexterous manipulation use demonstrations or
interactions with the environment to train black-box neural networks that
provide little control over how the robot learns the skills or how it would
perform post training. These approaches pose significant challenges when
implemented on physical platforms given that, during initial stages of
training, the robot's behavior could be erratic and potentially harmful to its
own hardware, the environment, or any humans in the vicinity. A potential way
to address these limitations is to add constraints during learning that
restrict and guide the robot's behavior during training as well as roll outs.
Inspired by the success of constrained approaches in other domains, we
investigate the effects of adding position-based constraints to a 24-DOF robot
hand learning to perform object relocation using Constrained Policy
Optimization. We find that a simple geometric constraint can ensure the robot
learns to move towards the object sooner than without constraints. Further,
training with this constraint requires a similar number of samples as its
unconstrained counterpart to master the skill. These findings shed light on how
simple constraints can help robots achieve sensible and safe behavior quickly
and ease concerns surrounding hardware deployment. We also investigate the
effects of the strictness of these constraints and report findings that provide
insights into how different degrees of strictness affect learning outcomes. Our
code is available at
https://github.com/GT-STAR-Lab/constrained-rl-dexterous-manipulation.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:31:28 GMT""}]","2023-01-25"
"2301.09767","Mariyam Amir","Mariyam Amir, Murchana Baruah, Mahsa Eslamialishah, Sina Ehsani,
  Alireza Bahramali, Sadra Naddaf-Sh, Saman Zarandioon","Truveta Mapper: A Zero-shot Ontology Alignment Framework",,,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, a new perspective is suggested for unsupervised Ontology
Matching (OM) or Ontology Alignment (OA) by treating it as a translation task.
Ontologies are represented as graphs, and the translation is performed from a
node in the source ontology graph to a path in the target ontology graph. The
proposed framework, Truveta Mapper (TM), leverages a multi-task
sequence-to-sequence transformer model to perform alignment across multiple
ontologies in a zero-shot, unified and end-to-end manner. Multi-tasking enables
the model to implicitly learn the relationship between different ontologies via
transfer-learning without requiring any explicit cross-ontology manually
labeled data. This also enables the formulated framework to outperform existing
solutions for both runtime latency and alignment quality. The model is
pre-trained and fine-tuned only on publicly available text corpus and
inner-ontologies data. The proposed solution outperforms state-of-the-art
approaches, Edit-Similarity, LogMap, AML, BERTMap, and the recently presented
new OM frameworks in Ontology Alignment Evaluation Initiative (OAEI22), offers
log-linear complexity in contrast to quadratic in the existing end-to-end
methods, and overall makes the OM task efficient and more straightforward
without much post-processing involving mapping extension or mapping repair.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:32:56 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 22:05:53 GMT""}]","2023-04-04"
"2301.09768","Tiziano Schiavone","Tiziano Schiavone, Giovanni Montani","Signature of $f\left(R\right)$ gravity via Lemaitre-Tolman-Bondi
  inhomogeneous perturbations","20 pages, 5 figures, to be submitted to Physical Review D",,,,"gr-qc astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We analyze inhomogeneous cosmological models in the local Universe, based on
the Lemaitre-Tolman-Bondi (LTB) metric and developed using linear perturbation
theory on a homogeneous and isotropic Universe background. Focusing on the
different evolution of spherical symmetric inhomogeneities, we want to compare
the $\Lambda$LTB model, in which the cosmological constant $\Lambda$ is
included in the LTB formalism, with inhomogeneous cosmological models based on
$f(R)$ modified gravity theories viewed in the Jordan frame. In particular, we
adopt the Hu-Sawicki $f(R)$ model in the Jordan frame to describe the cosmic
accelerated phase for the background Universe. The key difference between the
$\Lambda$LTB model and the $f(R)$ gravity in an inhomogeneous cosmology is
outlined by the 0-1 component of the gravitational field equations, since it
intrinsically links the metric tensor components to the non-minimally coupled
scalar field, present in the Jordan frame. We solve the system of field
equations for both cosmological models adopting the method of separation of
variables: we can integrate analytically the radial profiles of local
perturbations, while their time evolution requires a numerical approach. The
main result of the analysis concerns the different radial profiles of local
inhomogeneities in the two cosmological scenarios: the radial perturbations
follow a power-law in the $\Lambda$LTB model, while Yukawa-like contributions
appear in the $f(R)$ theory. Interestingly, this latter peculiar behavior of
radial profiles is not affected by the choice of the $f(R)$ functional form.
The numerical solution of time-dependent perturbations exhibits a non-diverging
profile. This work suggests that investigations about local inhomogeneities in
the late Universe may allow us to discriminate if the present cosmic
acceleration is caused by a cosmological constant term or a modified gravity
effect.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:38:27 GMT""}]","2023-01-25"
"2301.09769","Xiaolong Du","Xiaolong Du, David J. E. Marsh, Miguel Escudero, Andrew Benson, Diego
  Blas, Charis Kaur Pooni, Malcolm Fairbairn","Soliton Merger Rates and Enhanced Axion Dark Matter Decay","15 pages, 15 figures",,,"KCL-PH-TH-2023-03, CERN-TH-2023-009","astro-ph.CO astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solitons are observed to form in simulations of dark matter (DM) halos
consisting of bosonic fields. We use the extended Press-Schechter formalism to
compute the mass function of solitons, assuming various forms for the
relationship between halo mass and soliton mass. We further provide a new
calculation of the rate of soliton major mergers. Solitons composed of axion DM
are unstable above a critical mass, and decay to either relativistic axions or
photons, depending on the values of the coupling constants. We use the computed
soliton major merger rate to predict the enhanced DM decay rate due to soliton
instability. For certain values of currently allowed axion parameters, the
energy injection into the intergalactic medium from soliton decays to photons
is comparable to or larger than the energy injection due to core collapse
supernovae at $z>10$. A companion paper explores the phenomenology of such an
energy injection.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:55:16 GMT""}]","2023-01-25"
"2301.09770","Prasoon Goyal","Prasoon Goyal, Raymond J. Mooney, Scott Niekum","Language-guided Task Adaptation for Imitation Learning",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel setting, wherein an agent needs to learn a task from a
demonstration of a related task with the difference between the tasks
communicated in natural language. The proposed setting allows reusing
demonstrations from other tasks, by providing low effort language descriptions,
and can also be used to provide feedback to correct agent errors, which are
both important desiderata for building intelligent agents that assist humans in
daily tasks. To enable progress in this proposed setting, we create two
benchmarks -- Room Rearrangement and Room Navigation -- that cover a diverse
set of task adaptations. Further, we propose a framework that uses a
transformer-based model to reason about the entities in the tasks and their
relationships, to learn a policy for the target task
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:56:43 GMT""}]","2023-01-25"
"2301.09771","Raymond Leung","Raymond Leung, Andrew J Hill, Arman Melkumyan","Automation and AI Technology in Surface Mining With a Brief Introduction
  to Open-Pit Operations in the Pilbara","Keywords: Mining automation, robotics, intelligent systems, machine
  learning, remote sensing, geostatistics, planning, scheduling, optimization,
  modelling, geology, complex systems. Document: 12 pages, 4 figures",,,,"cs.CY cs.GL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This survey article provides a synopsis on some of the engineering problems,
technological innovations, robotic development and automation efforts
encountered in the mining industry -- particularly in the Pilbara iron-ore
region of Western Australia. The goal is to paint the technology landscape and
highlight issues relevant to an engineering audience to raise awareness of AI
and automation trends in mining. It assumes the reader has no prior knowledge
of mining and builds context gradually through focused discussion and short
summaries of common open-pit mining operations. The principal activities that
take place may be categorized in terms of resource development, mine-, rail-
and port operations. From mineral exploration to ore shipment, there are
roughly nine steps in between. These include: geological assessment, mine
planning and development, production drilling and assaying, blasting and
excavation, transportation of ore and waste, crush and screen, stockpile and
load-out, rail network distribution, and ore-car dumping. The objective is to
briefly describe what each of these processes involves and identify some of the
challenges/opportunities from the perspective of a decade-long
industry-university R&D collaboration.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 00:57:37 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 00:18:49 GMT""},{""version"":""v3"",""created"":""Sat, 18 Feb 2023 05:46:52 GMT""}]","2023-02-21"
"2301.09772","Yiming Xiao","Owen Hellum, Christopher Steele, Yiming Xiao","SONIA: an immersive customizable virtual reality system for the
  education and exploration of brain networks",,,,,"cs.HC cs.MM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  While mastery of neuroanatomy is important for the investigation of the
brain, there is an increasing interest in exploring the neural pathways to
better understand the roles of neural circuitry in brain functions. To tackle
the limitations of traditional 2D-display-based neuronavigation software in
intuitively visualizing complex 3D anatomies, several virtual reality (VR) and
augmented reality (AR) solutions have been proposed to facilitate
neuroanatomical education. However, with the increasing knowledge on brain
connectivity and the functioning of the sub-systems, there is still a lack of
similar software solutions for the education and exploration of these topics,
which demand more elaborate visualization and interaction strategies. To
address this gap, we designed the immerSive custOmizable Neuro learnIng plAform
(SONIA), a novel user-friendly VR software system with a multi-scale
interaction paradigm that allows flexible customization of learning materials.
With both quantitative and qualitative evaluations through user studies, the
proposed system is shown to have high usability, attractive visual design, and
good educational value. As the first immersive system that integrates
customizable design and detailed narratives of the brain sub-systems for the
education of neuroanatomy and brain connectivity, SONIA showcases new potential
directions and provides valuable insights regarding medical learning and
exploration in VR.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:04:15 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 20:35:47 GMT""}]","2023-04-28"
"2301.09773","Amir Atoufi","Lu Zhu, Amir Atoufi, Adrien Lefauve, John R. Taylor, Rich R. Kerswell,
  Stuart B. Dalziel, Gregory. A. Lawrence, and P. F. Linden","Stratified inclined duct: direct numerical simulations",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The stratified inclined duct (SID) experiment consists of a zero-net-volume
exchange flow in a long tilted rectangular duct, which allows the study of
realistic stratified shear flows with sustained internal forcing.
  We present the first three-dimensional direct numerical simulations (DNS) of
SID to explore the transitions between increasingly turbulent flow regimes
first described by Meyer \& Linden (\textit{J. Fluid Mech.} \textbf{753},
242-253, 2014). We develop a numerical set-up that faithfully reproduces the
experiments and sustains the flow for arbitrarily long times at minimal
computational cost.
  We recover the four qualitative flow regimes found experimentally in the same
regions of parameter space: laminar flow, waves, intermittent turbulence, and
fully-developed turbulence. We find good qualitative and quantitative agreement
between DNS and experiments and highlight the added value of DNS to complement
experimental diagnostics and increase our understanding of the transition to
turbulence, both temporally (laminar/turbulent cycles) and parametrically (as
the tilt angle of the duct and the Reynolds number are increased).
  These results demonstrate that numerical studies of SID -- and deeper
integration between simulations and experiments -- have the potential to lead
to a better understanding of stratified turbulence in environmental flows.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:05:38 GMT""}]","2023-01-25"
"2301.09774","Ming Li","Ming Li, Junfeng Wang, and Youjin Deng","Explosive Percolation Obeys Standard Finite-Size Scaling in an
  Event-based Ensemble","5 pages, 4 figures","Phys. Rev. Lett. 130 (2023) 147101","10.1103/PhysRevLett.130.147101",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explosive percolation in the Achlioptas process, which has attracted much
research attention, is known to exhibit a rich variety of critical phenomena
that are anomalous from the perspective of continuous phase transitions.
Hereby, we show that, in an event-based ensemble, the critical behaviors in
explosive percolation are rather clean and obey the standard finite-size
scaling theory, except for the large fluctuation of pseudo-critical points. In
the fluctuation window, multiple fractal structures emerge and the values can
be derived from a crossover scaling theory. Further, their mixing effects
account well for the previously observed anomalous phenomena. Making use of the
clean scaling in the event-based ensemble, we determine with a high precision
the critical points and exponents for a number of bond-insertion rules, and
clarify ambiguities about their universalities. Our findings hold true for any
spatial dimensions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:24:15 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 01:12:31 GMT""}]","2023-04-06"
"2301.09775","Bhaswati Mookerjea","Bhaswati Mookerjea (TIFR, Mumbai, India), V. S. Veena (MPIfR, Bonn)
  Rolf Guesten (MPIfR, Bonn) F. Wyrowski (MPIfR, Bonn), Akhil Lasrado
  (IISER-Kolkata, India)","Spiral Structure and Massive Star formation in the Hub-Filament-System
  G326.27-0.49","Accepted for publication in MNRAS",,"10.1093/mnras/stad215",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Hub-filament systems (HFSs) are potential sites of formation of star clusters
and high mass stars. To understand the HFSs and to provide observational
constraints on current theories that attempt to explainstar formation globally,
we report a study of the region associated with G326.27-0.49 using infrared
data of dust continuum and newly obtained observations on molecular tracers
using the APEX telescope. We use the spectroscopic observations to identify
velocity-coherent structures (filaments and clumps) and study their properties
at a resolution of 0.4 pc. The region contains two main velocity components:
first component shows four filaments between -63 and -55 km/s forming a spiral
structure converging in a hub, the second filamentary component at -72 km/s
harbors a massive young stellar object and possibly interacts with the hub. The
clumps harbouring the three main YSOs in the region are massive (187-535 Msun),
have luminosities consistent with B-type stars, have central densities of ~10^6
cm^-3 and drive large outflows. Majority of the velocity-coherent clumps in the
region show virial parameters between 2-7, which considering the detection of
protostars implies collapse to be gradual. We conclude that the region consists
of a network of filaments through which mass accretes (~10^-4 Msun/yr) onto the
hub. The hub and some of the ends of filaments appear to be undergoing collapse
to form new stars. This study identifies a target region for future high
resolution observations that could probe the link between the core and filament
evolution.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:25:34 GMT""}]","2023-02-08"
"2301.09776","Amir Said","Amir Said, Manish Kumar Singh, Reza Pourreza","Differentiable bit-rate estimation for neural-based video codec
  enhancement",,"Picture Coding Symposium (PCS), San Jose, CA, USA, 2022, pp.
  379-383","10.1109/PCS56426.2022.10018001",,"eess.IV cs.IT cs.LG cs.MM math.IT","http://creativecommons.org/licenses/by/4.0/","  Neural networks (NN) can improve standard video compression by pre- and
post-processing the encoded video. For optimal NN training, the standard codec
needs to be replaced with a codec proxy that can provide derivatives of
estimated bit-rate and distortion, which are used for gradient
back-propagation. Since entropy coding of standard codecs is designed to take
into account non-linear dependencies between transform coefficients, bit-rates
cannot be well approximated with simple per-coefficient estimators. This paper
presents a new approach for bit-rate estimation that is similar to the type
employed in training end-to-end neural codecs, and able to efficiently take
into account those statistical dependencies. It is defined from a mathematical
model that provides closed-form formulas for the estimates and their gradients,
reducing the computational complexity. Experimental results demonstrate the
method's accuracy in estimating HEVC/H.265 codec bit-rates.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:36:07 GMT""}]","2023-01-25"
"2301.09777","Darij Grinberg","Darij Grinberg","The entry sum of the inverse Cauchy matrix","7 pages. Expository note","The Mathematical Intelligencer (2023)","10.1007/s00283-023-10268-4",,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $x_{1},x_{2},\ldots,x_{n}$ be $n$ numbers, and $y_{1},y_{2},\ldots,y_{n}$
be $n$ further numbers chosen such that all $n^{2}$ pairwise sums $x_{i}+y_{j}$
are nonzero. Consider the $n\times n$-matrix \[ C:=\left(
\dfrac{1}{x_{i}+y_{j}}\right) _{1\leq i\leq n,\ 1\leq j\leq n} =
\begin{pmatrix} \dfrac{1}{x_{1}+y_{1}} & \dfrac{1}{x_{1}+y_{2}} & \cdots &
\dfrac{1}{x_{1}+y_{n}}\\ \dfrac{1}{x_{2}+y_{1}} & \dfrac{1}{x_{2}+y_{2}} &
\cdots & \dfrac{1}{x_{2}+y_{n}}\\ \vdots & \vdots & \ddots & \vdots\\
\dfrac{1}{x_{n}+y_{1}} & \dfrac{1}{x_{n}+y_{2}} & \cdots &
\dfrac{1}{x_{n}+y_{n}} \end{pmatrix}. \] This matrix $C$ is known as the
""Cauchy matrix"", and has been studied for 180 years.
  A classical result says that if $C$ is invertible, then the sum of all
entries of its inverse $C^{-1}$ is $\sum_{k=1}^{n}x_{k}+\sum_{k=1}^{n}y_{k}$.
We give a simple and short proof of this result, and briefly discuss a
""tropicalized"" variant in which the entries $\dfrac{1}{x_i+y_j}$ are replaced
by $ \min\left\{ x_{i},y_{j}\right\}$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:37:56 GMT""}]","2023-05-09"
"2301.09778","Furkan Ercan","Furkan Ercan, Kevin Galligan, David Starobinski, Muriel Medard, Ken R.
  Duffy, Rabia Tugce Yazicigil","GRAND-EDGE: A Universal, Jamming-resilient Algorithm with
  Error-and-Erasure Decoding","7 pages, 7 figures, accepted for IEEE ICC 2023 conference",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random jammers that overpower transmitted signals are a practical concern for
many wireless communication protocols. As such, wireless receivers must be able
to cope with standard channel noise and jamming (intentional or unintentional).
To address this challenge, we propose a novel method to augment the resilience
of the recent family of universal error-correcting GRAND algorithms. This
method, called Erasure Decoding by Gaussian Elimination (EDGE), impacts the
syndrome check block and is applicable to any variant of GRAND. We show that
the proposed EDGE method naturally reverts to the original syndrome check
function in the absence of erasures caused by jamming. We demonstrate this by
implementing and evaluating GRAND-EDGE and ORBGRAND-EDGE. Simulation results,
using a Random Linear Code (RLC) with a code rate of $105/128$, show that the
EDGE variants lower both the Block Error Rate (BLER) and the computational
complexity by up to five order of magnitude compared to the original GRAND and
ORBGRAND algorithms. We further compare ORBGRAND-EDGE to Ordered Statistics
Decoding (OSD), and demonstrate an improvement of up to three orders of
magnitude in the BLER.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:42:58 GMT""}]","2023-01-25"
"2301.09779","Erwin Topp","Gonzalo D\'avila, Alexander Quaas, and Erwin Topp","Large harmonic functions for fully nonlinear fractional operators",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study existence, uniqueness and boundary blow-up profile for fractional
harmonic functions on a bounded smooth domain $\Omega \subset \mathbb R^N$. We
deal with harmonic functions associated to uniformly elliptic, fully nonlinear
nonlocal operators, including the linear case $$ (-\Delta)^s u = 0 \quad
\mbox{in} \ \Omega, $$ where $(-\Delta)^s$ denotes the fractional Laplacian of
order $2s \in (0,2)$. We use the viscosity solution's theory and Perron's
method to construct harmonic functions with zero exterior condition in $\bar
\Omega^c$, and boundary blow-up profile $$ \lim_{x\to x_0, x \in
\Omega}\mathrm{dist}(x, \partial \Omega)^{1-s}u(x)=h(x_0), \quad \mbox{for all}
\quad x_0\in \partial \Omega, $$ for any given boundary data $h \in C(\partial
\Omega)$. Our method allows us to provide blow-up rate for the solution and its
gradient estimates. Results are new even in the linear case.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:48:25 GMT""}]","2023-01-25"
"2301.09780","Christina Williams","Christina C. Williams, Sandro Tacchella, Michael V. Maseda, Brant E.
  Robertson, Benjamin D. Johnson, Chris J. Willott, Daniel J. Eisenstein,
  Christopher N. A. Willmer, Zhiyuan Ji, Kevin N. Hainline, Jakob M. Helton,
  Stacey Alberts, Stefi Baum, Rachana Bhatawdekar, Kristan Boyett, Andrew J.
  Bunker, Stefano Carniani, Stephane Charlot, Jacopo Chevallard, Emma
  Curtis-Lake, Anna de Graaf, Eiichi Egami, Marijn Franx, Nimisha Kumari,
  Roberto Maiolino, Erica J. Nelson, Marcia J. Rieke, Lester Sandles, Irene
  Shivaei, Charlotte Simmonds, Renske Smit, Katherine A. Suess, Fengwu Sun,
  Hannah Ubler and Joris Witstok","JEMS: A deep medium-band imaging survey in the Hubble Ultra-Deep Field
  with JWST NIRCam & NIRISS","Submitted to AAS Journals, comments welcome. First data release
  including science-ready mosaics after peer-review",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present JEMS (JWST Extragalactic Medium-band Survey), the first public
medium-band imaging survey carried out using JWST/NIRCam and NIRISS. These
observations use $\sim2\mu$m and $\sim4\mu$m medium-band filters (NIRCam F182M,
F210M, F430M, F460M, F480M; and NIRISS F430M & F480M in parallel) over 15.6
square arcminutes in the Hubble Ultra Deep Field (UDF), thereby building on the
deepest multi-wavelength public datasets available anywhere on the sky. We
describe our science goals, survey design, NIRCam and NIRISS image reduction
methods, and describe our first data release of the science-ready mosaics. Our
chosen filters create a JWST imaging survey in the UDF that enables novel
analysis of a range of spectral features potentially across the redshift range
of $0.3<z<20$, including Paschen-$\alpha$, H$\alpha$+[NII], and [OIII]+H$\beta$
emission at high spatial resolution. We find that our JWST medium-band imaging
efficiently identifies strong line emitters (medium-band colors $>1$ magnitude)
across redshifts $1.5<z<9.3$, most prominently H$\alpha$+[NII] and
[OIII]+H$\beta$. We present our first data release including science-ready
mosaics of each medium-band image available to the community, adding to the
legacy value of past and future surveys in the UDF. We also describe future
data releases. This survey demonstrates the power of medium-band imaging with
JWST, informing future extragalactic survey strategies using JWST observations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:55:46 GMT""}]","2023-01-25"
"2301.09781","Kyungduk Kim","Kyungduk Kim, Yaniv Eliezer, Olivier Spitz, Hui Cao","Parallel random LiDAR with spatial multiplexing of a many-mode laser","12 pages, 7 figures","Opt. Express Vol. 31, No. 7, 11966-11981 (2023)","10.1364/OE.486348",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and experimentally demonstrate parallel LiDAR using random
intensity fluctuations from a highly multimode laser. We optimize a degenerate
cavity to have many spatial modes lasing simultaneously with different
frequencies. Their spatio-temporal beating creates ultrafast random intensity
fluctuations, which are spatially demultiplexed to generate hundreds of
uncorrelated time traces for parallel ranging. The bandwidth of each channel
exceeds 10 GHz, leading to a ranging resolution better than 1 cm. Our parallel
random LiDAR is robust to cross-channel interference, and will facilitate
high-speed 3D sensing and imaging.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:57:12 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 15:21:10 GMT""}]","2023-03-27"
"2301.09782","Jeremy Bailey","Jeremy Bailey, Daniel V. Cotton, Ain De Horta, Lucyna
  Kedziora-Chudczer, Om Shastri","PICSARR: high-precision polarimetry using CMOS image sensors","MNRAS, accepted",,"10.1093/mnras/stad271",,"astro-ph.IM astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have built and tested a compact, low-cost, but very-high-performance
astronomical polarimeter based on a continuously rotating half-wave plate and a
high-speed imaging detector. The polarimeter is suitable for small telescopes
up to ~1 m in aperture. The optical system provides very high transmission over
a wide wavelength range from the atmospheric UV cutoff to ~1000 nm. The
high-quantum-efficiency, low-noise and high-speed of the detectors enable
bright stars to be observed with high-precision as well as polarization imaging
of extended sources. We have measured the performance of the instrument on 20
cm and 60 cm aperture telescopes. We show some examples of the type of science
possible with this instrument. The polarimeter is particularly suited to
studies of the wavelength dependence and time variability of the polarization
of stars and planets.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:58:26 GMT""}]","2023-02-08"
"2301.09783","Zhonghua Sun","Zhonghua Sun and Cunsheng Ding","Several families of ternary negacyclic codes and their duals",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Constacyclic codes contain cyclic codes as a subclass and have nice algebraic
structures. Constacyclic codes have theoretical importance, as they are
connected to a number of areas of mathematics and outperform cyclic codes in
several aspects. Negacyclic codes are a subclass of constacyclic codes and are
distance-optimal in many cases. However, compared with the extensive study of
cyclic codes, negacyclic codes are much less studied. In this paper, several
families of ternary negacyclic codes and their duals are constructed and
analysed. These families of negacyclic codes and their duals contain
distance-optimal codes and have very good parameters in general.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:59:16 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 11:37:11 GMT""}]","2023-01-26"
"2301.09784","Bing Wang","Yu Li, Bing Wang","On K\""ahler Ricci shrinker surfaces","43 pages, 3 figures, 1 table",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we prove that any K\""ahler Ricci shrinker surface has bounded
sectional curvature. Combining this estimate with earlier work by many authors,
we provide a complete classification of all K\""ahler Ricci shrinker surfaces.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:09:41 GMT""}]","2023-01-25"
"2301.09785","Zeyu Huang","Zeyu Huang, Yikang Shen, Xiaofeng Zhang, Jie Zhou, Wenge Rong, Zhang
  Xiong","Transformer-Patcher: One Mistake worth One Neuron","accepted in ICLR 2023",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Transformer-based Pretrained Language Models (PLMs) dominate almost all
Natural Language Processing (NLP) tasks. Nevertheless, they still make mistakes
from time to time. For a model deployed in an industrial environment, fixing
these mistakes quickly and robustly is vital to improve user experiences.
Previous works formalize such problems as Model Editing (ME) and mostly focus
on fixing one mistake. However, the one-mistake-fixing scenario is not an
accurate abstraction of the real-world challenge. In the deployment of AI
services, there are ever-emerging mistakes, and the same mistake may recur if
not corrected in time. Thus a preferable solution is to rectify the mistakes as
soon as they appear nonstop. Therefore, we extend the existing ME into
Sequential Model Editing (SME) to help develop more practical editing methods.
Our study shows that most current ME methods could yield unsatisfying results
in this scenario. We then introduce Transformer-Patcher, a novel model editor
that can shift the behavior of transformer-based models by simply adding and
training a few neurons in the last Feed-Forward Network layer. Experimental
results on both classification and generation tasks show that
Transformer-Patcher can successively correct up to thousands of errors
(Reliability) and generalize to their equivalent inputs (Generality) while
retaining the model's accuracy on irrelevant inputs (Locality). Our method
outperforms previous fine-tuning and HyperNetwork-based methods and achieves
state-of-the-art performance for Sequential Model Editing (SME). The code is
available at https://github.com/ZeroYuHuang/Transformer-Patcher.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:12:42 GMT""}]","2023-01-25"
"2301.09786","Kangrae Park","Jiyun Park, Kangrae Park","Size of exceptional sets in weakly mixing systems","23 pages, 3 figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any weakly mixing system $(X, \mathscr{B}, \mu, T)$ and $A, B \in
\mathscr{B}$, there is a density zero set $J_{A,B}$ such that $\mu(A\cap
T^{-n}B)$ converges to $\mu(A)\mu(B)$ for $n \notin J$. In this paper, we study
bounds on the size of this exceptional set $J$. First, we show that, given the
rate of weak mixing, we can find an upper bound on the size of $J$. We use this
property to show the existence of an exceptional set $J$ of an interval
exchange system with either $\left|J \cap [0, n]\right| \le Cn\log^{-a}n$ or
$\left|J \cap [0, n]\right| \le Cn^{1 - \alpha}$, depending on whether or not
the transformation is of rotation class. We also explicitly construct an
exceptional set $J$ for the Chacon transformation and give upper and lower
bounds for its size. More precisely, we show that there is a constant $C>0$
such that for any increasing function $h: \mathbb{R}_+ \to \mathbb{R}_+$
diverging to infinity, there is an exceptional set $J \subseteq \mathbb{N}$
such that $\left|J \cap [0, n]\right|\le Cf(n)$ for every Lebesgue measurable
sets $A, B \subseteq [0,1]$, where $f(n) = (\log n)^{(\log \log n)^2h(n)}$. For
the lower bound, we prove that for any $t>0$, there exists Lebesgue measurable
sets $A, B\subseteq [0,1]$ and $C, N>0$ such that $\left|J_{A,B}\cap
[0,n]\right|\geq C(\log n)^t$ for every $n>N$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:16:11 GMT""}]","2023-01-25"
"2301.09787","Heayoung Yoon","Etee Kawna Roy, Kaden Powell, Chungho Lee, Gang Xiong, and Heayoung
  Yoon","Design and Fabrication of PERC-Like CdTe Solar Cells Using
  Micropatterned Al2O3 Layer","4 pages, 4 figures",,,,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Recent studies have investigated novel strategies to further improve the
limited Voc of CdTe solar cells via increased carrier lifetime and doping
density of CdTe thin films. Among various metal oxides, aluminum oxide (Al2O3)
is a promising passivation candidate, where the negatively charged Al2O3 layer
repels the minority carrier in CdTe and Al2O3 provides a chemically passivating
interface, increasing the carrier lifetime. Despite the continuing efforts, an
optimized back-contact architecture to improve the Voc while maintaining high
Jsc and FF is still under development. In this work, we report the design,
fabrication, and characterization of PERC-like CdTe solar cells, where an Al2O3
passivation layer is patterned using laser-beam lithography. Our process
enables reproducible patterning on a rough surface CdTe while maintaining the
size of the array in the design. Analysis of CdTe PERC devices (As-doped) shows
a notably different Voc trend compared to FF and Jsc, independent of the
patterned array structures used in this study. The subsurface electronic
structure of CdTe and the interplay between carrier selectivity and collection
of the patterned Al2O3 could be responsible for the observed PV
characteristics.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:35:20 GMT""}]","2023-01-25"
"2301.09788","Yuhao Zhu","Yuhao Zhu","Teaching Color Science to EECS Students Using Interactive Tutorials:
  Tools and Lessons",,,,,"physics.ed-ph","http://creativecommons.org/licenses/by/4.0/","  Teaching color science to Electrical Engineering and Computer Science (EECS)
students is critical to preparing them for advanced topics such as graphics,
visualization, imaging, Augmented/Virtual Reality. Color historically receive
little attention in EECS curriculum; students find it difficult to grasp basic
concepts. This is because today's pedagogical approaches are nonintuitive and
lack rigor for teaching color science. We develop a set of interactive
tutorials that teach color science to EECS students. Each tutorial is backed up
by a mathematically rigorous narrative, but is presented in a form that invites
students to participate in developing each concept on their own through
visualization tools. This paper describes the tutorial series we developed and
discusses the design decisions we made.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:39:32 GMT""}]","2023-01-25"
"2301.09789","Jenny Liang","Jenny T. Liang, Maryam Arab, Minhyuk Ko, Amy J. Ko, Thomas D. LaToza","A Qualitative Study on the Implementation Design Decisions of Developers",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Decision-making is a key software engineering skill. Developers constantly
make choices throughout the software development process, from requirements to
implementation. While prior work has studied developer decision-making, the
choices made while choosing what solution to write in code remain understudied.
In this mixed-methods study, we examine the phenomenon where developers select
one specific way to implement a behavior in code, given many potential
alternatives. We call these decisions implementation design decisions. Our
mixed-methods study includes 46 survey responses and 14 semi-structured
interviews with professional developers about their decision types,
considerations, processes, and expertise for implementation design decisions.
We find that implementation design decisions, rather than being a natural
outcome from higher levels of design, require constant monitoring of higher
level design choices, such as requirements and architecture. We also show that
developers have a consistent general structure to their implementation
decision-making process, but no single process is exactly the same. We discuss
the implications of our findings on research, education, and practice,
including insights on teaching developers how to make implementation design
decisions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:43:05 GMT""}]","2023-01-25"
"2301.09790","Zhuohan Xie","Zhuohan Xie, Trevor Cohn, Jey Han Lau","Can Very Large Pretrained Language Models Learn Storytelling With A Few
  Examples?",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  While pre-trained language models can generate individually fluent sentences
for automatic story generation, they struggle to generate stories that are
coherent, sensible and interesting. Current state-of-the-art (SOTA) story
generation models explore using higher-level features such as plots or
commonsense knowledge to improve the quality of generated stories. Prompt-based
learning using very large pre-trained language models (VLPLMs) such as GPT3 has
demonstrated impressive performance even across various NLP tasks. In this
paper, we present an extensive study using automatic and human evaluation to
compare the story generation capability of VLPLMs to those SOTA models in three
different datasets where stories differ in style, register and length. Our
results show that VLPLMs generate much higher quality stories than other story
generation models, and to a certain extent rival human authors, although
preliminary investigation also reveals that they tend to ``plagiarise'' real
stories in scenarios that involve world knowledge.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:44:02 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 23:47:00 GMT""}]","2023-03-17"
"2301.09791","Achyuth Madabhushi","Achyuth Madabhushi","Quantification of Damage Using Indirect Structural Health Monitoring",,,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Structural health monitoring is important to make sure bridges do not fail.
Since direct monitoring can be complicated and expensive, indirect methods have
been a focus on research. Indirect monitoring can be much cheaper and easier to
conduct, however there are challenges with getting accurate results. This work
focuses on damage quantification by using accelerometers. Tests were conducted
on a model bridge and car with four accelerometers attached to to the vehicle.
Different weights were placed on the bridge to simulate different levels of
damage, and 31 tests were run for 20 different damage levels. The acceleration
data collected was normalized and a Fast-Fourier Transform (FFT) was performed
on that data. Both the normalized acceleration data and the normalized FFT data
were inputted into a Non-Linear Principal Component Analysis (separately) and
three principal components were extracted for each data set. Support Vector
Regression (SVR) and Gaussian Process Regression (GPR) were used as the
supervised machine learning methods to develop models. Multiple models were
created so that the best one could be selected, and the models were compared by
looking at their Mean Squared Errors (MSE). This methodology should be applied
in the field to measure how effective it can be in real world applications.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:46:46 GMT""}]","2023-01-25"
"2301.09792","Amir Hossein Sadeghi","Hadi Moheb-Alizadeh, Amir Hossein Sadeghi, Amirreza Sahebi fakhrabad,
  Megan Kramer Jaunich, Eda Kemahlioglu-Ziya, Robert B Handfield","Reverse Logistics Network Design to Estimate the Economic and
  Environmental Impacts of Take-back Legislation: A Case Study for E-waste
  Management System in Washington State","42 pages, 7 figures, 11 tables",,,,"cs.CY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, recycling and disposal of end-of-life (EOL) electronic
products has attracted considerable attention in response to concerns over
resource recovery and environmental impacts of electronic waste (e-waste). In
many countries, legislation to make manufacturers responsible for taking
e-waste at the end of their useful lives either has been adopted or is being
considered. In this paper, by capturing different stages in the life-cycle of
EOL electronic products (or, e-waste) generated from private or small-entity
users, we develop two different formulations of a reverse logistics network,
i.e. system-optimum model and user-optimum model, to estimate both economic and
environmental effects of take-back legislation. In this system, e-waste is
collected through user drop-off at designated collection sites. While we study
the whole reverse logistics network associated with recycling and
remanufacturing of e-waste in the system-optimum model and obtain an optimum
solution from the policy maker's perspective, we split the logistics network
into two distinct parts in the user-optimum model in order to derive an optimum
solution from the users' standpoint. Implementing the proposed models on an
illustrative example shows how they are capable of estimating the economic and
environmental impacts of take-back legislation in various stages of e-waste's
life-cycle.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:50:09 GMT""}]","2023-01-25"
"2301.09793","Shin'ichirou Yoshida","Shin'ichirou Yoshida","Bifurcation and stability of uniformly rotating homogeneous ellipsoids
  surrounded by a massive thin ring","5 figures",,,,"physics.class-ph astro-ph.EP astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We examine the effects of a massive concentric ring around a spheroid or an
ellipsoid with uniform density and uniform rotation. Equilibrium sequences of
axisymmetric Maclaurin-like spheroid and triaxial Jacobi-like ellipsoids are
obtained. Due to the gravitational field of the ring, Maclaurin-like spheroid
does not have a spherical limit when the object's angular frequency vanishes.
At a critical value of the eccentricity of the spheroid's meridional section, a
triaxial Jacobi-like ellipsoid bifurcates. When a parameter characterizing the
gravitational field of the ring is smaller than a threshold, the bifurcation
points of Maclaurin-like and Jacobi-like ellipsoids exist and the critical
eccentricity is slightly larger than that of the classical Maclaurin-to-Jacobi
bifurcation. When the parameter exceeds the threshold, the Maclaurin-like
spheroid does not have the bifurcation point and the Jacobi-like ellipsoid
appears at the lower eccentricity than the Maclaurin-like spheroid. By
comparisons of the energy of the ellipsoids with the same angular momentum, it
is shown that the critical point of bifurcation does not correspond to the
onset of the secular instability of Maclaurin-like spheroid. It is concluded
that the gravitational field of a massive ring surrounding a uniformly rotating
spheroid stabilizes it against a bar-shaped deformation due to viscous
dissipations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:53:23 GMT""}]","2023-01-25"
"2301.09794","Taishi Kotsuka","Taishi Kotsuka, Yutaka Hori","Stability analysis for circulant structured multi-agent molecular
  communication systems",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce the system theoretic model for the multi-agent MC
systems represented by multi-input and multi-output (MIMO) systems using the
transfer functions, and then propose a method to analyze the stability for the
special case of the circulant structured multi-agent MC systems. The proposed
method decomposes the MIMO MC system into multiple single-input and
single-output (SISO) systems, which facilitates to analyze of the stability of
the large-scale multi-agent MC system. Finally, we demonstrate the proposed
method to analyze the stability of a specific MC system.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:54:34 GMT""}]","2023-01-25"
"2301.09795","Rajendra Gupta","Rajendra P. Gupta","Constraining Coupling Constants' Variation with Supernovae, Quasars, and
  GRBs","18 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:2202.12758","Symmetry 15, 259 (2023)","10.3390/sym15020259",,"astro-ph.CO astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dirac, in 1937 proposed the variation of coupling constants derived from his
large number hypothesis. Efforts have continued since then to constrain their
variation by various methods. We briefly discuss several methods used for the
purpose while focusing primarily on the use of supernovae type 1a, quasars, and
gamma-ray bursts (GRBs) as cosmological probes for determining cosmological
distances. Supernovae type Ia (SNeIa) are considered the best standard candles
since their intrinsic luminosity can be determined precisely from their light
curves. However, they have only been observed up to about redshift $z=2.3$,
mostly at $z<1.5$. Quasars are the brightest non-transient cosmic sources in
the Universe. They have been observed up to $z=7.5$. Certain types of quasars
can be calibrated well enough for their use as standard candles but with a
higher degree of uncertainty in their intrinsic luminosity than the SNeIa. GRBs
are even brighter than quasars, observed up to $z=9.4$. Their radiation lasts
from 10s of milliseconds to several minutes and, in rare cases, for a few
hours. However, they are even more challenging to calibrate as standard candles
than quasars. What if the standard candles' intrinsic luminosities are affected
when the coupling constants become dynamic? This paper uses our earlier finding
that the speed of light c, the gravitational constant G, the Planck constant h,
and the Boltzmann constant k variations are correlated as $G\thicksim
c^{3}\thicksim h^{3}\thicksim k^{3/2}$ with
$(\dot{G}/G)_{0}=3(\dot{c}/c)_{0}=(\dot{h}/h)_{0}=1.5 (\dot{k}/k)_{0}=5.4H_{0}
=3.90(\pm 0.04)\times 10^{-10} yr^{-1}$ corroborates it with SNeIa, quasars,
and GRBs observational data. Also, we show that this covarying coupling
constant model may be better than the standard {\Lambda}CDM model for using
quasars and GRBs as standard candles and predict the mass of the GRBs scales as
$((1+z)^{1/3}-1)$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:00:59 GMT""}]","2023-01-25"
"2301.09796","Sheng-Yang Kevin Ho","Sheng-Yang Kevin Ho","On the Rational Cuspidal Divisor Class Groups of Drinfeld Modular Curves
  $X_0(\mathfrak{p}^r)$","40 pages, comments welcome",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study an analogue of Ling's theorem in the function field
setting from different approach. Let $C(\mathfrak{p}^r)$ be the rational
cuspidal divisor class group of the Drinfeld modular curve
$X_0(\mathfrak{p}^r)$ for a prime power level $\mathfrak{p}^r\in
\mathbb{F}_q[T]$. We relate the rational cuspidal divisors of degree $0$ on
$X_0(\mathfrak{p}^r)$ with $\Delta$-quotients, where $\Delta$ is the Drinfeld
discriminant function. As a result, by applying the van der Put map, we are
able to determine explicitly the structure of $C(\mathfrak{p}^r)$ for arbitrary
prime $\mathfrak{p}\in \mathbb{F}_q[T]$ and $r\geq 2$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:06:36 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 17:26:47 GMT""},{""version"":""v3"",""created"":""Mon, 30 Jan 2023 03:59:14 GMT""},{""version"":""v4"",""created"":""Thu, 9 Feb 2023 17:59:41 GMT""},{""version"":""v5"",""created"":""Mon, 27 Feb 2023 18:06:09 GMT""},{""version"":""v6"",""created"":""Sat, 29 Apr 2023 13:27:23 GMT""}]","2023-05-02"
"2301.09797","Yusuke Manita","Yusuke Manita, Sirachak Panpanich and Rampei Kimura","Viable massive gravity without nonlinear screening","8 pages",,,"KUNS-2951","gr-qc astro-ph.CO hep-th","http://creativecommons.org/licenses/by/4.0/","  We study nonlinear effects of perturbations around a cosmological background
in projected massive gravity, which admits self-accelerating solutions in an
open FLRW universe. Using the zero-curvature scaling limit, we derive nonlinear
equations containing all the relevant terms on subhorizon scales. We find that
the solution for a scalar graviton vanishes completely for all scales, which
agrees with the linear perturbation analysis in the previous study. In
addition, the effects on the gravitational potential due to the next order
perturbation are strongly suppressed within the horizon. Therefore, a screening
mechanism is no longer needed for consistency with solar-system experiments in
the projected massive gravity.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:19:39 GMT""}]","2023-01-25"
"2301.09798","Jingbang Liu","Jingbang Liu, Chengxi Zhao, Duncan A. Lockerby, James E. Sprittles","Thermal capillary waves on bounded nanoscale thin films",,,"10.1103/PhysRevE.107.015105",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The effect of confining walls on the fluctuation of a nanoscale thin film's
free surface is studied using stochastic thin-film equations (STFEs). Two
canonical boundary conditions are employed to reveal the influence of the
confinement: (1) an imposed contact angle and (2) a pinned contact line. A
linear stability analysis provides the wave eigenmodes, after which
thermal-capillary-wave theory predicts the wave fluctuation amplitudes.
Molecular dynamics (MD) simulations are performed to test the predictions, and
a Langevin diffusion model is proposed to capture oscillations of the contact
lines observed in MD simulations. Good agreement between the theoretical
predictions and the MD simulation results is recovered, and it is discovered
that confinement can influence the entire film. Notably, a constraint on the
length scale of wave modes is found to affect fluctuation amplitudes from our
theoretical model, especially for 3D films. This opens up challenges and future
lines of inquiry.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:24:45 GMT""}]","2023-01-25"
"2301.09799","Xinjie Zhang","Xinjie Zhang, Jiawei Shao, Jun Zhang","LDMIC: Learning-based Distributed Multi-view Image Coding","Accepted by ICLR 2023",,,,"eess.IV cs.AI cs.CV cs.LG cs.MM","http://creativecommons.org/licenses/by/4.0/","  Multi-view image compression plays a critical role in 3D-related
applications. Existing methods adopt a predictive coding architecture, which
requires joint encoding to compress the corresponding disparity as well as
residual information. This demands collaboration among cameras and enforces the
epipolar geometric constraint between different views, which makes it
challenging to deploy these methods in distributed camera systems with randomly
overlapping fields of view. Meanwhile, distributed source coding theory
indicates that efficient data compression of correlated sources can be achieved
by independent encoding and joint decoding, which motivates us to design a
learning-based distributed multi-view image coding (LDMIC) framework. With
independent encoders, LDMIC introduces a simple yet effective joint context
transfer module based on the cross-attention mechanism at the decoder to
effectively capture the global inter-view correlations, which is insensitive to
the geometric relationships between images. Experimental results show that
LDMIC significantly outperforms both traditional and learning-based MIC methods
while enjoying fast encoding speed. Code will be released at
https://github.com/Xinjie-Q/LDMIC.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:47:37 GMT""},{""version"":""v2"",""created"":""Sat, 11 Mar 2023 08:29:51 GMT""},{""version"":""v3"",""created"":""Wed, 12 Apr 2023 14:57:13 GMT""}]","2023-04-13"
"2301.09800","Andrew Boateng","Andrew Boateng, Wenlong Zhang, Yu Zhang","Improving Responsiveness to Robots for Tacit Human-Robot Interaction via
  Implicit and Naturalistic Team Status Projection",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fluent human-human teaming is often characterized by tacit interaction
without explicit communication. This is because explicit communication, such as
language utterances and gestures, are inherently interruptive. On the other
hand, tacit interaction requires team situation awareness (TSA) to facilitate,
which often relies on explicit communication to maintain, creating a paradox.
In this paper, we consider implicit and naturalistic team status projection for
tacit human-robot interaction. Implicitness minimizes interruption while
naturalness reduces cognitive demand, and they together improve responsiveness
to robots. We introduce a novel process for such Team status Projection via
virtual Shadows, or TPS. We compare our method with two baselines that use
explicit projection for maintaining TSA. Results via human factors studies
demonstrate that TPS provides a more fluent human-robot interaction experience
by significantly improving human responsiveness to robots in tacit teaming
scenarios, which suggests better TSA. Participants acknowledged robots
implementing TPS as more acceptable as a teammate and favorable.
Simultaneously, we demonstrate that TPS is comparable to, and sometimes better
than, the best-performing baseline in maintaining accurate TSA
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:54:00 GMT""}]","2023-01-25"
"2301.09801","Jiashu Wu","Jiashu Wu, Hao Dai, Yang Wang, Kejiang Ye, Chengzhong Xu","Heterogeneous Domain Adaptation for IoT Intrusion Detection: A Geometric
  Graph Alignment Approach","Accepted by IEEE Internet of Things Journal",,,,"cs.CR cs.CY cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Data scarcity hinders the usability of data-dependent algorithms when
tackling IoT intrusion detection (IID). To address this, we utilise the data
rich network intrusion detection (NID) domain to facilitate more accurate
intrusion detection for IID domains. In this paper, a Geometric Graph Alignment
(GGA) approach is leveraged to mask the geometric heterogeneities between
domains for better intrusion knowledge transfer. Specifically, each intrusion
domain is formulated as a graph where vertices and edges represent intrusion
categories and category-wise interrelationships, respectively. The overall
shape is preserved via a confused discriminator incapable to identify adjacency
matrices between different intrusion domain graphs. A rotation avoidance
mechanism and a centre point matching mechanism is used to avoid graph
misalignment due to rotation and symmetry, respectively. Besides, category-wise
semantic knowledge is transferred to act as vertex-level alignment. To exploit
the target data, a pseudo-label election mechanism that jointly considers
network prediction, geometric property and neighbourhood information is used to
produce fine-grained pseudo-label assignment. Upon aligning the intrusion
graphs geometrically from different granularities, the transferred intrusion
knowledge can boost IID performance. Comprehensive experiments on several
intrusion datasets demonstrate state-of-the-art performance of the GGA approach
and validate the usefulness of GGA constituting components.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:55:14 GMT""}]","2023-01-25"
"2301.09802","Alexander Bagnall","Alexander Bagnall, Gordon Stewart, Anindya Banerjee","Inductive Reasoning for Coinductive Types",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  We present AlgCo (Algebraic Coinductives), a practical framework for
inductive reasoning over commonly used coinductive types such as conats,
streams, and infinitary trees with finite branching factor. The key idea is to
exploit the notion of algebraic complete partial order from domain theory to
define continuous operations over coinductive types via primitive recursion on
``dense'' collections of their elements, enabling a convenient strategy for
reasoning about algebraic coinductives by straightforward proofs by induction.
We implement the AlgCo framework in Coq and demonstrate its power by verifying
a stream variant of the sieve of Eratosthenes, a regular expression library
based on coinductive trie encodings of formal languages, and expected value
semantics for coinductive sampling processes over discrete probability
distributions in the random bit model.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 03:55:47 GMT""},{""version"":""v2"",""created"":""Fri, 7 Apr 2023 02:45:35 GMT""}]","2023-04-10"
"2301.09803","Claudia Soto Silva","Wim van Ackooij, Pedro P\'erez-Aros, Claudia Soto, Emilio Vilches","Inner Moreau envelope of nonsmooth conic chance constrained optimization
  problems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimization problems with uncertainty in the constraints occur in many
applications. Particularly, probability functions present a natural form to
deal with this situation. Nevertheless, in some cases, the resulting
probability functions are nonsmooth. This motivates us to propose a
regularization employing the Moreau envelope of a scalar representation of the
vector inequality. More precisely, we consider a probability function which
covers most of the general classes of probabilistic constraints:
$$\varphi(x)=\mathbb{P}(\Phi(x,\xi)\in -\mathcal{K}),$$ where $\mathcal{K}$ is
a convex cone of a Banach space. The conic inclusion $\Phi (x,\xi) \in -
\mathcal{K}$ represents an abstract system of inequalities, and $\xi$ is a
random vector. We propose a regularization by applying the Moreau envelope to
the scalarization of the function $\Phi$. In this paper, we demonstrate, under
mild assumptions, the smoothness of such a regularization and that it satisfies
a type of variational convergence to the original probability function.
Consequently, when considering an appropriately structured problem involving
probabilistic constraints, we can thus entail the convergence of the minimizers
of the regularized approximate problems to the minimizers of the original
problem. Finally, we illustrate our results with examples and applications in
the field of (nonsmooth) joint, semidefinite and probust chance constrained
optimization problems.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:05:23 GMT""}]","2023-01-25"
"2301.09804","Kevin Coulembier","Kevin Coulembier, Pavel Etingof and Victor Ostrik","Asymptotic properties of tensor powers in symmetric tensor categories",,,,,"math.RT math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let G be a group and V a finite dimensional representation of G over an
algebraically closed field k of characteristic p>0. Let $d_n(V)$ be the number
of indecomposable summands of $V^{\otimes n}$ of nonzero dimension mod p. It is
easy to see that there exists a limit $\delta(V):=\lim_{n\to
\infty}d_n(V)^{1/n}$, which is positive (and $\ge 1$) iff V has an
indecomposable summand of nonzero dimension mod p. We show that in this case
the number $$ c(V):=\liminf_{n\to \infty} \frac{d_n(V)}{\delta(V)^n}\in [0,1]
$$ is strictly positive and $$ \log (c(V)^{-1})=O(\delta(V)^2), $$ and moreover
this holds for any symmetric tensor category over k of moderate growth.
Furthermore, we conjecture that in fact $$ \log(c(V)^{-1})=O(\delta(V)) $$
(which would be sharp), and prove this for p=2,3; in particular, for p=2 we
show that $c(V)\ge 3^{-\frac{4}{3}\delta(V)+1}$. The proofs are based on the
characteristic p version of Deligne's theorem for symmetric tensor categories
obtained in earlier work of the authors. We also conjecture a classification of
semisimple symmetric tensor categories of moderate growth which is interesting
in its own right and implies the above conjecture for all $p$, and illustrate
this conjecture by describing the semisimplification of the modular
representation category of a cyclic p-group. Finally, we study the asymptotic
behavior of the decomposition of $V^{\otimes n}$ in characteristic zero using
Deligne's theorem and the Macdonald-Mehta-Opdam identity.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:06:32 GMT""}]","2023-01-25"
"2301.09805","Jun Yumoto","Jun Yumoto, Tatsuhiro Misumi","New conjecture on species doubling of lattice fermions","30 pages, 16 figures",,,,"hep-lat hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We propose a new conjecture on the relation between the species doubling of
lattice fermions and the topology of manifold on which the fermion action is
defined. Our conjecture claims that the maximal number of fermion species on a
finite-volume and finite-spacing lattice defined by discretizing a
$D$-dimensional manifold is equal to the summation of the Betti numbers of the
manifold. We start with reconsidering species doubling of naive fermions on the
lattices whose topologies are torus ($T^{D}$), hyperball ($B^D$) and their
direct-product space ($T^{D} \times B^{d}$). We find that the maximal number of
species is in exact agreement with the sum of Betti numbers $\sum^{D}_{r=0}
\beta_{r}$ for these manifolds. Indeed, the $4D$ lattice fermion on torus has
up to $16$ species while the sum of Betti numbers of $T^4$ is $16$. This
coincidence holds also for the $D$-dimensional hyperball and their
direct-product space $T^{D} \times B^{d}$. We study several examples of lattice
fermions defined on discretized hypersphere ($S^{D}$), and find that it has up
to $2$ species, which is the same number as the sum of Betti numbers of
$S^{D}$. From these facts, we conjecture the equivalence of the maximal number
of fermion species and the summation of Betti numbers. We discuss a program for
proof of the conjecture in terms of Hodge theory and spectral graph theory.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:08:42 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 01:21:54 GMT""}]","2023-01-31"
"2301.09806","Sayak Saha Roy","Sayak Saha Roy, Dipanjan Das, Priyanka Bose, Christopher Kruegel,
  Giovanni Vigna, Shirin Nilizadeh","Demystifying NFT Promotion and Phishing Scams",,,,,"cs.CR cs.CY","http://creativecommons.org/licenses/by/4.0/","  The popularity and hype around purchasing digital assets such as art, video,
and music in the form of Non-fungible tokens (NFTs) has rapidly made them a
lucrative investment opportunity, with NFT-based sales surpassing $25B in 2021
alone. However, the volatility and scarcity of NFTs, combined with the general
lack of familiarity with the technical aspects of this ecosystem, encourage the
spread of several scams. The success of an NFT is majorly impacted by its
online virality. There have been sparse reports about scammers emulating this
virality by either promoting their fraudulent NFT projects on social media or
imitating other popular NFT projects. This paper presents a longitudinal
analysis of 439 unique Twitter accounts that consistently promote fraudulent
NFT collections through giveaway competitions and 1,028 NFT phishing attacks.
Our findings indicate that most accounts interacting with these promotions are
bots, which can rapidly increase the popularity of the fraudulent NFT
collections by inflating their likes, followers, and retweet counts. This leads
to significant engagement from real users, who then proceed to invest in the
scams. On the other hand, we identify two novel attack vectors which are
utilized by NFT phishing scams to steal funds and digital assets from the
victim's wallet. We also identify several gaps in the prevalent anti-phishing
ecosystem by evaluating the performance of popular anti-phishing blocklists and
security tools against NFT phishing attacks. We utilize our findings to develop
a machine learning classifier that can automatically detect NFT phishing scams
at scale.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:13:44 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 14:01:25 GMT""}]","2023-06-05"
"2301.09807","Mathias Mikkelsen","Mathias Mikkelsen and Ippei Danshita","Relation between the noise correlations and the spin structure factor
  for Mott-insulating states in SU$(N)$ Hubbard models","11 pages, 3 figures","Phys. Rev. A 107, 043313 (2023)","10.1103/PhysRevA.107.043313",,"cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well established that the noise correlations measured by time-of-flight
imaging in cold-atom experiments, which correspond to the density-density
correlations in the momentum space of trapped atomic gases, can probe the spin
structure factor deep in the Mott-insulating regime of SU(2) Hubbard models. We
explicitly derive the mathematical relation between the noise correlations and
the spin structure factor in the strong-interaction limit of SU$(N)$ Hubbard
models at any integer filling $\rho$. By calculating the ground states of
one-dimensional SU$(N)$ Fermi-Hubbard models for $2\leq N\leq 6$ with use of
the density-matrix renormalization-group method, we confirm the relation
numerically in the regime of strong interactions $U \gg t$, where $U$ and $t$
denote the onsite interaction and the hopping energy. We show that the
deviation between the actual noise correlations and those obtained from the
spin structure factor scales as approximately $(t/U)^2$ for $\rho=1$ at
intermediate and large lattice sizes on the basis of numeric and semi-analytic
arguments.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:21:07 GMT""},{""version"":""v2"",""created"":""Thu, 13 Apr 2023 07:57:24 GMT""}]","2023-04-14"
"2301.09808","Rahul Vaze","Rahul Vaze","On Dynamic Regret and Constraint Violations in Constrained Online Convex
  Optimization",,"in Proc. WiOpt 2022",,,"cs.LG math.OC stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A constrained version of the online convex optimization (OCO) problem is
considered. With slotted time, for each slot, first an action is chosen.
Subsequently the loss function and the constraint violation penalty evaluated
at the chosen action point is revealed. For each slot, both the loss function
as well as the function defining the constraint set is assumed to be smooth and
strongly convex. In addition, once an action is chosen, local information about
a feasible set within a small neighborhood of the current action is also
revealed. An algorithm is allowed to compute at most one gradient at its point
of choice given the described feedback to choose the next action. The goal of
an algorithm is to simultaneously minimize the dynamic regret (loss incurred
compared to the oracle's loss) and the constraint violation penalty (penalty
accrued compared to the oracle's penalty). We propose an algorithm that follows
projected gradient descent over a suitably chosen set around the current
action. We show that both the dynamic regret and the constraint violation is
order-wise bounded by the {\it path-length}, the sum of the distances between
the consecutive optimal actions. Moreover, we show that the derived bounds are
the best possible.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:22:13 GMT""}]","2023-01-25"
"2301.09809","Subendhu Rongali","Subendhu Rongali, Mukund Sridhar, Haidar Khan, Konstantine Arkoudas,
  Wael Hamza, and Andrew McCallum","Low-Resource Compositional Semantic Parsing with Concept Pretraining","EACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Semantic parsing plays a key role in digital voice assistants such as Alexa,
Siri, and Google Assistant by mapping natural language to structured meaning
representations. When we want to improve the capabilities of a voice assistant
by adding a new domain, the underlying semantic parsing model needs to be
retrained using thousands of annotated examples from the new domain, which is
time-consuming and expensive. In this work, we present an architecture to
perform such domain adaptation automatically, with only a small amount of
metadata about the new domain and without any new training data (zero-shot) or
with very few examples (few-shot). We use a base seq2seq (sequence-to-sequence)
architecture and augment it with a concept encoder that encodes intent and slot
tags from the new domain. We also introduce a novel decoder-focused approach to
pretrain seq2seq models to be concept aware using Wikidata and use it to help
our model learn important concepts and perform well in low-resource settings.
We report few-shot and zero-shot results for compositional semantic parsing on
the TOPv2 dataset and show that our model outperforms prior approaches in
few-shot settings for the TOPv2 and SNIPS datasets.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:27:27 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 20:49:49 GMT""}]","2023-02-01"
"2301.09810","John Sylvester","Dimitrios Los, Thomas Sauerwald, John Sylvester","Balanced Allocations with Heterogeneous Bins: The Power of Memory","62 Pages, 6 Figures. Appearing at SODA 2023",,"10.1137/1.9781611977554.ch169",,"cs.DM cs.DS math.CO math.PR","http://creativecommons.org/licenses/by/4.0/","  We consider the allocation of $m$ balls (jobs) into $n$ bins (servers). In
the standard Two-Choice process, at each step $t=1,2,\ldots,m$ we first sample
two bins uniformly at random and place a ball in the least loaded bin. It is
well-known that for any $m \geq n$, this results in a gap (difference between
the maximum and average load) of $\log_2 \log n + \Theta(1)$ (with high
probability). In this work, we consider the Memory process [Mitzenmacher,
Prabhakar and Shah 2002] where instead of two choices, we only sample one bin
per step but we have access to a cache which can store the location of one bin.
Mitzenmacher, Prabhakar and Shah showed that in the lightly loaded case ($m =
n$), the Memory process achieves a gap of $\mathcal{O}(\log \log n)$.
  Extending the setting of Mitzenmacher et al. in two ways, we first allow the
number of balls $m$ to be arbitrary, which includes the challenging heavily
loaded case where $m \geq n$. Secondly, we follow the heterogeneous bins model
of Wieder [Wieder 2007], where the sampling distribution of bins can be biased
up to some arbitrary multiplicative constant. Somewhat surprisingly, we prove
that even in this setting, the Memory process still achieves an
$\mathcal{O}(\log \log n)$ gap bound. This is in stark contrast with the
Two-Choice (or any $d$-Choice with $d=\mathcal{O}(1)$) process, where it is
known that the gap diverges as $m \rightarrow \infty$ [Wieder 2007]. Further,
we show that for any sampling distribution independent of $m$ (but possibly
dependent on $n$) the Memory process has a gap that can be bounded
independently of $m$. Finally, we prove a tight gap bound of $\mathcal{O}(\log
n)$ for Memory in another relaxed setting with heterogeneous (weighted) balls
and a cache which can only be maintained for two steps.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:27:42 GMT""}]","2023-01-25"
"2301.09811","Hannes De Meulemeester","Arun Pandey, Hannes De Meulemeester, Bart De Moor and Johan A.K.
  Suykens","Multi-view Kernel PCA for Time series Forecasting",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a kernel principal component analysis model for
multi-variate time series forecasting, where the training and prediction
schemes are derived from the multi-view formulation of Restricted Kernel
Machines. The training problem is simply an eigenvalue decomposition of the
summation of two kernel matrices corresponding to the views of the input and
output data. When a linear kernel is used for the output view, it is shown that
the forecasting equation takes the form of kernel ridge regression. When that
kernel is non-linear, a pre-image problem has to be solved to forecast a point
in the input space. We evaluate the model on several standard time series
datasets, perform ablation studies, benchmark with closely related models and
discuss its results.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:29:30 GMT""}]","2023-01-25"
"2301.09812","Masao Oi","Charlotte Chan and Masao Oi","Characterization of supercuspidal representations and very regular
  elements","76 pages, some minor mistakes are fixed",,,,"math.RT math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that regular supercuspidal representations of $p$-adic groups are
uniquely determined by their character values on very regular elements -- a
special class of regular semisimple elements on which character formulae are
very simple -- provided that this locus is sufficiently large. As a
consequence, we resolve a question of Kaletha by giving a description of
Kaletha's $L$-packets of regular supercuspidal representations which mirrors
Langlands' construction for real groups following Harish-Chandra's
characterization theorem for discrete series representations. Our techniques
additionally characterize supercuspidal representations in general, giving
$p$-adic analogues of results of Lusztig on reductive groups over finite
fields. In particular, we establish an easy, non-cohomological characterization
of unipotent supercuspidal representations when the residue field of the base
field is sufficiently large.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:41:41 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 23:53:58 GMT""}]","2023-05-01"
"2301.09813","Jinho Lee","Mingi Yoo, Jaeyong Song, Hyeyoon Lee, Jounghoo Lee, Namhyung Kim,
  Youngsok Kim, Jinho Lee","Slice-and-Forge: Making Better Use of Caches for Graph Convolutional
  Network Accelerators","Published at PACT'22",,,,"cs.LG cs.AR cs.DC","http://creativecommons.org/licenses/by/4.0/","  Graph convolutional networks (GCNs) are becoming increasingly popular as they
can process a wide variety of data formats that prior deep neural networks
cannot easily support. One key challenge in designing hardware accelerators for
GCNs is the vast size and randomness in their data access patterns which
greatly reduces the effectiveness of the limited on-chip cache. Aimed at
improving the effectiveness of the cache by mitigating the irregular data
accesses, prior studies often employ the vertex tiling techniques used in
traditional graph processing applications. While being effective at enhancing
the cache efficiency, those approaches are often sensitive to the tiling
configurations where the optimal setting heavily depends on target input
datasets. Furthermore, the existing solutions require manual tuning through
trial-and-error or rely on sub-optimal analytical models.
  In this paper, we propose Slice-and-Forge (SnF), an efficient hardware
accelerator for GCNs which greatly improves the effectiveness of the limited
on-chip cache. SnF chooses a tiling strategy named feature slicing that splits
the features into vertical slices and processes them in the outermost loop of
the execution. This particular choice results in a repetition of the identical
computational patterns over irregular graph data over multiple rounds. Taking
advantage of such repetitions, SnF dynamically tunes its tile size. Our
experimental results reveal that SnF can achieve 1.73x higher performance in
geomean compared to prior work on multi-engine settings, and 1.46x higher
performance in geomean on small scale settings, without the need for off-line
analyses.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:43:12 GMT""}]","2023-01-25"
"2301.09814","Richard Zach","Paolo Mancosu, Richard Zach","Some Unpublished Letters by G\""odel and von Neumann in the Fraenkel
  Archive",,,,,"math.LO math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several letters by Kurt G\""odel and Johann (J\'anos) von Neumann from the (so
far uncatalogued) archive of Abraham (Adolf) Fraenkel at the National Library
of Israel are published and discussed. These include two fragments by G\""odel
of special interest, since they concern the relationship between G\""odel's
incompleteness theorem and work by Herbrand, Presburger, and Zermelo, as well
as a long letter from von Neumann from 1923 explaining his own approach to the
axiomatization of set theory.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:46:25 GMT""}]","2023-01-25"
"2301.09815","Robert A. Lewis","Robert A. Lewis, Asma Ghandeharioun, Szymon Fedor, Paola Pedrelli,
  Rosalind Picard, David Mischoulon","Mixed Effects Random Forests for Personalised Predictions of Clinical
  Depression Severity","9 pages",,,,"cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  This work demonstrates how mixed effects random forests enable accurate
predictions of depression severity using multimodal physiological and digital
activity data collected from an 8-week study involving 31 patients with major
depressive disorder. We show that mixed effects random forests outperform
standard random forests and personal average baselines when predicting clinical
Hamilton Depression Rating Scale scores (HDRS_17). Compared to the latter
baseline, accuracy is significantly improved for each patient by an average of
0.199-0.276 in terms of mean absolute error (p<0.05). This is noteworthy as
these simple baselines frequently outperform machine learning methods in mental
health prediction tasks. We suggest that this improved performance results from
the ability of the mixed effects random forest to personalise model parameters
to individuals in the dataset. However, we find that these improvements pertain
exclusively to scenarios where labelled patient data are available to the model
at training time. Investigating methods that improve accuracy when generalising
to new patients is left as important future work.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:50:55 GMT""}]","2023-01-25"
"2301.09816","Yanchao Sun","Yanchao Sun, Shuang Ma, Ratnesh Madaan, Rogerio Bonatti, Furong Huang,
  Ashish Kapoor","SMART: Self-supervised Multi-task pretrAining with contRol Transformers",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised pretraining has been extensively studied in language and
vision domains, where a unified model can be easily adapted to various
downstream tasks by pretraining representations without explicit labels. When
it comes to sequential decision-making tasks, however, it is difficult to
properly design such a pretraining approach that can cope with both
high-dimensional perceptual information and the complexity of sequential
control over long interaction horizons. The challenge becomes combinatorially
more complex if we want to pretrain representations amenable to a large variety
of tasks. To tackle this problem, in this work, we formulate a general
pretraining-finetuning pipeline for sequential decision making, under which we
propose a generic pretraining framework \textit{Self-supervised Multi-task
pretrAining with contRol Transformer (SMART)}. By systematically investigating
pretraining regimes, we carefully design a Control Transformer (CT) coupled
with a novel control-centric pretraining objective in a self-supervised manner.
SMART encourages the representation to capture the common essential information
relevant to short-term control and long-term control, which is transferrable
across tasks. We show by extensive experiments in DeepMind Control Suite that
SMART significantly improves the learning efficiency among seen and unseen
downstream tasks and domains under different learning scenarios including
Imitation Learning (IL) and Reinforcement Learning (RL). Benefiting from the
proposed control-centric objective, SMART is resilient to distribution shift
between pretraining and finetuning, and even works well with low-quality
pretraining datasets that are randomly collected.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:01:23 GMT""}]","2023-01-25"
"2301.09817","Aaron Meisner","A. M. Meisner, S. K. Leggett, S. E. Logsdon, A. C. Schneider, P.
  Tremblin, M. Phillips","Exploring the Extremes: Characterizing a New Population of Old and Cold
  Brown Dwarfs","submitted to AAS Journals",,,,"astro-ph.SR astro-ph.EP astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mapping out the populations of thick disk and halo brown dwarfs is important
for understanding the metallicity dependence of low-temperature atmospheres and
the substellar mass function. Recently, a new population of cold and metal-poor
brown dwarfs has been discovered, with $T_{\rm{eff}}$ $\lesssim$ 1400 K and
metallicity $\lesssim$ $-$1 dex. This population includes what may be the first
known ""extreme T-type subdwarfs"" and possibly the first Y-type subdwarf, WISEA
J153429.75$-$104303.3. We have conducted a Gemini YJHK/Ks photometric follow-up
campaign targeting potentially metal-poor T and Y dwarfs, utilizing the GNIRS
and Flamingos-2 instruments. We present 14 near-infrared photometric detections
of 8 unique targets: six T subdwarf candidates, one moderately metal poor Y
dwarf candidate, and one Y subdwarf candidate. We have obtained the first ever
ground-based detection of the highly anomalous object WISEA
J153429.75$-$104303.3. The F110W$-$$J$ color of WISEA J153429.75$-$104303.3 is
significantly bluer than that of other late-T and Y dwarfs, indicating that
WISEA J153429.75$-$104303.3 has an unusual spectrum in the 0.9-1.4 $\mu$m
wavelength range which encompasses the $J$-band peak. Our $J$-band detection of
WISEA J153429.75$-$104303.3 and corresponding model comparisons suggest a
subsolar metallicity and temperature of 400-550 K for this object. JWST
spectroscopic follow-up at near-infrared and mid-infrared wavelengths would
allow us to better understand the spectral peculiarities of WISEA
J153429.75$-$104303.3, assess its physical properties, and conclusively
determine whether or not it is the first Y-type subdwarf.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:06:11 GMT""}]","2023-01-25"
"2301.09818","Ziang Chen","Ziang Chen, Jianfeng Lu, Yulong Lu, Xiangxiong Zhang","On the convergence of Sobolev gradient flow for the Gross-Pitaevskii
  eigenvalue problem",,,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the convergences of three projected Sobolev gradient flows to the
ground state of the Gross-Pitaevskii eigenvalue problem. They are constructed
as the gradient flows of the Gross-Pitaevskii energy functional with respect to
the $H^1_0$-metric and two other equivalent metrics on $H_0^1$, including the
iterate-independent $a_0$-metric and the iterate-dependent $a_u$-metric. We
first prove the energy dissipation property and the global convergence to a
critical point of the Gross-Pitaevskii energy for the discrete-time $H^1$ and
$a_0$-gradient flow. We also prove local exponential convergence of all three
schemes to the ground state.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:07:41 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 19:37:49 GMT""}]","2023-02-13"
"2301.09819","Xiao Zhou","Xiao Zhou, Yong Lin, Renjie Pi, Weizhong Zhang, Renzhe Xu, Peng Cui,
  Tong Zhang","Model Agnostic Sample Reweighting for Out-of-Distribution Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributionally robust optimization (DRO) and invariant risk minimization
(IRM) are two popular methods proposed to improve out-of-distribution (OOD)
generalization performance of machine learning models. While effective for
small models, it has been observed that these methods can be vulnerable to
overfitting with large overparameterized models. This work proposes a
principled method, \textbf{M}odel \textbf{A}gnostic sam\textbf{PL}e
r\textbf{E}weighting (\textbf{MAPLE}), to effectively address OOD problem,
especially in overparameterized scenarios. Our key idea is to find an effective
reweighting of the training samples so that the standard empirical risk
minimization training of a large model on the weighted training data leads to
superior OOD generalization performance. The overfitting issue is addressed by
considering a bilevel formulation to search for the sample reweighting, in
which the generalization complexity depends on the search space of sample
weights instead of the model size. We present theoretical analysis in linear
case to prove the insensitivity of MAPLE to model size, and empirically verify
its superiority in surpassing state-of-the-art methods by a large margin. Code
is available at \url{https://github.com/x-zho14/MAPLE}.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:11:03 GMT""}]","2023-01-25"
"2301.09820","Zihao Fu","Zihao Fu, Anthony Man-Cho So, Nigel Collier","A Stability Analysis of Fine-Tuning a Pre-Trained Model",,,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,
etc.) has proven to be one of the most promising paradigms in recent NLP
research. However, numerous recent works indicate that fine-tuning suffers from
the instability problem, i.e., tuning the same model under the same setting
results in significantly different performance. Many recent works have proposed
different methods to solve this problem, but there is no theoretical
understanding of why and how these methods work. In this paper, we propose a
novel theoretical stability analysis of fine-tuning that focuses on two
commonly used settings, namely, full fine-tuning and head tuning. We define the
stability under each setting and prove the corresponding stability bounds. The
theoretical bounds explain why and how several existing methods can stabilize
the fine-tuning procedure. In addition to being able to explain most of the
observed empirical discoveries, our proposed theoretical analysis framework can
also help in the design of effective and provable methods. Based on our theory,
we propose three novel strategies to stabilize the fine-tuning procedure,
namely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self
Unsupervised Re-Training (SURT). We extensively evaluate our proposed
approaches on 11 widely used real-world benchmark datasets, as well as hundreds
of synthetic classification datasets. The experiment results show that our
proposed methods significantly stabilize the fine-tuning procedure and also
corroborate our theoretical analysis.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:11:17 GMT""}]","2023-01-25"
"2301.09821","Jennifer Wakulicz","Jennifer Wakulicz, Ki Myung Brian Lee, Teresa Vidal-Calleja, Robert
  Fitch","Topological Trajectory Prediction with Homotopy Classes","7 pages, 7 figures, accepted to ICRA 2023",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Trajectory prediction in a cluttered environment is key to many important
robotics tasks such as autonomous navigation. However, there are an infinite
number of possible trajectories to consider. To simplify the space of
trajectories under consideration, we utilise homotopy classes to partition the
space into countably many mathematically equivalent classes. All members within
a class demonstrate identical high-level motion with respect to the
environment, i.e., travelling above or below an obstacle. This allows
high-level prediction of a trajectory in terms of a sparse label identifying
its homotopy class. We therefore present a light-weight learning framework
based on variable-order Markov processes to learn and predict homotopy classes
and thus high-level agent motion. By informing a Gaussian Mixture Model (GMM)
with our homotopy class predictions, we see great improvements in low-level
trajectory prediction compared to a naive GMM on a real dataset.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:13:05 GMT""}]","2023-01-25"
"2301.09822","Chunli Tang","Chunli Tang, Laith Alahmed, Muntasir Mahdi, Yuzan Xiong, Jerad Inman,
  Nathan J. McLaughlin, Christoph Zollitsch, Tae Hee Kim, Chunhui Rita Du,
  Hidekazu Kurebayashi, Elton J. G. Santos, Wei Zhang, Peng Li, Wencan Jin","Ferromagnetic Resonance in Two-dimensional van der Waals Magnets: A
  Probe for Spin Dynamics","31 pages, 14 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The discovery of atomic monolayer magnetic materials has stimulated intense
research activities in the two-dimensional (2D) van der Waals (vdW) materials
community. The field is growing rapidly and there has been a large class of 2D
vdW magnetic compounds with unique properties, which provides an ideal platform
to study magnetism in the atomically thin limit. In parallel, based on
tunneling magnetoresistance and magneto-optical effect in 2D vdW magnets and
their heterostructures, emerging concepts of spintronic and optoelectronic
applications such as spin tunnel field-effect transistors and spin-filtering
devices are explored. While the magnetic ground state has been extensively
investigated, reliable characterization and control of spin dynamics play a
crucial role in designing ultrafast spintronic devices. Ferromagnetic resonance
(FMR) allows direct measurements of magnetic excitations, which provides
insight into the key parameters of magnetic properties such as exchange
interaction, magnetic anisotropy, gyromagnetic ratio, spin-orbit coupling,
damping rate, and domain structure. In this review article, we present an
overview of the essential progress in probing spin dynamics of 2D vdW magnets
using FMR techniques. Given the dynamic nature of this field, we focus mainly
on the broadband FMR, optical FMR, and spin-torque FMR, and their applications
in studying prototypical 2D vdW magnets including CrX3 (X = Cl, Br, I),
Fe5GeTe2, and Cr2Ge2Te6. We conclude with the recent advances in laboratory-
and synchrotron-based FMR techniques and their opportunities to broaden the
horizon of research pathways into atomically thin magnets.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:22:08 GMT""}]","2023-01-25"
"2301.09823","Purba Mukherjee","Narayan Banerjee, Purba Mukherjee and Diego Pav\'on","Spatial Curvature and Thermodynamics","9 pages, 7 sets of figures, Version published in MNRAS","Mon. Not. R. Astron. Soc. 521, 5473 (2023)","10.1093/mnras/stad921",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reasonable parametrizations of the current Hubble data set of the expansion
rate of our homogeneous and isotropic universe, after suitable smoothing of
these data, strongly suggests that the area of the apparent horizon increases
irrespective of whether the spatial curvature of the metric is open, flat or
closed. Put in another way, any sign of the spatial curvature appears
consistent with the second law of thermodynamics.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:22:23 GMT""},{""version"":""v2"",""created"":""Sat, 8 Apr 2023 17:54:09 GMT""}]","2023-04-11"
"2301.09824","Ryuta Iwazaki","Ryuta Iwazaki, Hiroshi Shinaoka, Shintaro Hoshino","Material-based analysis of spin-orbital Mott insulators","10 pages, 5 figures",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We present a framework for analyzing Mott insulators using a material-based
tight-binding model. We start with a realistic multiorbital Hubbard model and
derive an effective model for the localized electrons through the second-order
perturbation theory with respect to intersite hopping. This effective model,
known as the Kugel-Khomskii model, is described by SU($N$) generators, where
$N$ is the number of localized states. We solve this model by the mean-field
theory that takes local correlations into account and reveal spin-orbital
ordered states. To include spatial correlations, we apply the classical Monte
Carlo based on the path-integral approach with SU($N$) coherent states, and
also derive the equation of motion for spin-orbital degrees of freedom. Our
approach is applicable to any Mott insulator with reasonable computational
cost. The $5d$-pyrochlore oxide is used here as demonstration.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:29:54 GMT""}]","2023-01-25"
"2301.09825","Bo Peng","Shashank G Mehendale and Bo Peng and Niranjan Govind and Yuri Alexeev","Exploring Parameter Redundancy in the Unitary Coupled-Cluster Ansatze
  for Hybrid Variational Quantum Computing",,"J. Phys. Chem. A 2023","10.1021/acs.jpca.3c00550","2023, 127, 20, 4526--4537","quant-ph","http://creativecommons.org/licenses/by/4.0/","  One of the commonly used chemical-inspired approaches in variational quantum
computing is the unitary coupled-cluster (UCC) ansatze. Despite being a
systematic way of approaching the exact limit, the number of parameters in the
standard UCC ansatze exhibits unfavorable scaling with respect to the system
size, hindering its practical use on near-term quantum devices. Efforts have
been taken to propose some variants of UCC ansatze with better scaling. In this
paper we explore the parameter redundancy in the preparation of unitary
coupled-cluster singles and doubles (UCCSD) ansatze employing spin-adapted
formulation, small amplitude filtration, and entropy-based orbital selection
approaches. Numerical results of using our approach on some small molecules
have exhibited a significant cost reduction in the number of parameters to be
optimized and in the time to convergence compared with conventional UCCSD-VQE
simulations. We also discuss the potential application of some machine learning
techniques in further exploring the parameter redundancy, providing a possible
direction for future studies.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:36:37 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 09:04:28 GMT""}]","2023-06-06"
"2301.09826","Erin Connelly","Erin Connelly, Sameer Agarwal, Alperen Ergur, Rekha R. Thomas","The Geometry of Rank Drop in a Class of Face-Splitting Matrix Products",,,,,"math.AG math.AC math.CO","http://creativecommons.org/licenses/by/4.0/","  Given $k \leq 6$ points $(x_i,y_i) \in \mathbb{P}^2 \times \mathbb{P}^2$, we
characterize rank deficiency of the $k \times 9$ matrix $Z_k$ with rows
$x_i^\top \otimes y_i^\top$ in terms of the geometry of the point
configurations $\{x_i\}$ and $\{y_i\}$. While this question comes from computer
vision the answer relies on tools from classical algebraic geometry: For $k
\leq 5$, the geometry of the rank-drop locus is characterized by cross-ratios
and basic (projective) geometry of point configurations. For the case $k=6$ the
rank-drop locus is captured by the classical theory of cubic surfaces.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:38:25 GMT""}]","2023-01-25"
"2301.09827","Katsuhiko Kuribayashi","Katsuhiko Kuribayashi","On multiplicative spectral sequences for nerves and the free loop spaces","28 pages",,,,"math.AT math.KT","http://creativecommons.org/licenses/by-sa/4.0/","  We construct a multiplicative spectral sequence converging to the cohomology
algebra of the diagonal complex of a bisimplicial set with coefficients in a
field. The construction provides a spectral sequence converging to the
cohomology algebra of the classifying space of a topological category. By
applying the machinery to a Borel construction, we determine explicitly the mod
$p$ cohomology algebra of the free loop space of the real projective space for
each odd prime $p$. This is highlighted as an important computational example
of such a spectral sequence. Moreover, we try to represent generators in the
singular de Rham cohomology algebra of the diffeological free loop space of a
non-simply connected manifold $M$ with differential forms on the universal
cover of $M$ via Chen's iterated integral map.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:38:53 GMT""}]","2023-01-25"
"2301.09828","Sergio Mundo","Sergio A. Mundo and Richard Mushotzky","Investigating the variability of Swift-BAT blazars with NICER","Accepted for publication in MNRAS. 11 pages, 7 figures",,"10.1093/mnras/stad225",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results of X-ray spectral and time-domain variability analyses of
4 faint, ""quiescent"" blazars from the Swift-BAT 105-month catalog. We use
observations from a recent, 5-month long NICER campaign, as well as archival
BAT data. Variations in the 0.3-2 keV flux are detected on minute,
$\sim$weekly, and monthly timescales, but we find that the fractional
variability $F_{\rm var}$ on these timescales is $<25\%$ and decreases on
longer timescales, implying generally low-amplitude variability across all
sources and showing very low variability on monthly timescales ($F_{\rm
var}\lesssim13\%$), which is at odds with previous studies that show that
blazars are highly variable in the X-rays on a wide range of timescales.
Moreover, we find that the flux variability on very short timescales appears to
be characterized by long periods of relative quiescence accompanied by
occasional short bursts, against the relatively time-stationary nature of the
variability of most other AGN light curves. Our analysis also shows that the
broadband X-ray spectra (0.3-195 keV) of our sources can be described with
different power law models. As is the case with most blazars, we find that 2
sources (2MASS J09343014-1721215 and PKS 0312-770) are well-modeled with a
simple power law, while the remaining two (1RXS J225146.9-320614 and PKS
2126-15) exhibit curvature in the form of a log-parabolic power law. We also
find that, in addition to the continuum, PKS 2126-15 requires significant
absorption at the soft X-rays ($\lesssim$1 keV) to fully describe the observed
curvature, possibly due to absorption from the intergalactic medium.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 05:53:03 GMT""}]","2023-02-01"
"2301.09829","Saraswathi Kalyani Subramanian","Saraswathi Kalyani Subramanian, Sridharan Rengaswamy","Image Quality Specification for Solar Telescopes","15 pages, 8 figures",,"10.1007/s11207-022-02105-2",,"astro-ph.IM astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Modern large ground-based solar telescopes are invariably equipped with
adaptive optics systems to enhance the high angular resolution imaging and
spectroscopic capabilities in the presence of the Earth's atmospheric
turbulence. The quality of the images obtained from these telescopes can not be
quantified with the Strehl ratio or other metrics that are used for nighttime
astronomical telescopes directly. In this paper, we propose to use the root
mean square (rms) granulation contrast as a metric to quantify the image
quality of ground-based solar telescopes. We obtain semi-logarithmic plots
indicating the correspondence between the Strehl ratio and the rms granulation
contrast for most practical values of the telescope diameters (D) and the
atmospheric coherence diameters ($ r_0$), for various levels of adaptive optics
compensation. We estimate the efficiency of a few working solar adaptive optics
systems by comparing the results of our simulations with the Strehl ratio and
rms granulation contrast published by these systems. Our results can be used in
conjunction with a plausible 50 system efficiency to predict the lower bound on
the rms granulation contrast expected from ground-based solar telescopes.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:03:59 GMT""}]","2023-01-30"
"2301.09830","Jinho Lee","Jaeyong Song, Jinkyu Yim, Jaewon Jung, Hongsun Jang, Hyung-Jin Kim,
  Youngsok Kim, Jinho Lee","Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware
  Communication Compression","Accepted to ASPLOS'23",,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by/4.0/","  In training of modern large natural language processing (NLP) models, it has
become a common practice to split models using 3D parallelism to multiple GPUs.
Such technique, however, suffers from a high overhead of inter-node
communication. Compressing the communication is one way to mitigate the
overhead by reducing the inter-node traffic volume; however, the existing
compression techniques have critical limitations to be applied for NLP models
with 3D parallelism in that 1) only the data parallelism traffic is targeted,
and 2) the existing compression schemes already harm the model quality too
much.
  In this paper, we present Optimus-CC, a fast and scalable distributed
training framework for large NLP models with aggressive communication
compression. Optimus-CC differs from existing communication compression
frameworks in the following ways: First, we compress pipeline parallel
(inter-stage) traffic. In specific, we compress the inter-stage backpropagation
and the embedding synchronization in addition to the existing data-parallel
traffic compression methods. Second, we propose techniques to avoid the model
quality drop that comes from the compression. We further provide mathematical
and empirical analyses to show that our techniques can successfully suppress
the compression error. Lastly, we analyze the pipeline and opt to selectively
compress those traffic lying on the critical path. This further helps reduce
the compression error. We demonstrate our solution on a GPU cluster, and
achieve superior speedup from the baseline state-of-the-art solutions for
distributed training without sacrificing the model quality.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:07:55 GMT""}]","2023-01-25"
"2301.09831","Shay Hacohen-Gourgy","Asaf A. Diringer, Eliya Blumenthal, Avishay Grinberg, Liang Jiang,
  Shay Hacohen-Gourgy","Conditional not displacement: fast multi-oscillator control with a
  single qubit",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Bosonic encoding is an approach for quantum information processing, promising
lower hardware overhead by encoding in the many levels of a harmonic oscillator
mode. Scaling to multiple modes requires weak interaction for independent
control, yet strong interaction for fast control. Applying fast and efficient
universal control on multiple modes remains an open problem. We show that
universal control of multiple modes can be obtained with displacements of the
different modes conditioned only on a single qubit ancilla. We develop the
conditional not displacement control method which enables fast generation and
control of bosonic states in multi-mode systems weakly coupled to a single
ancilla qubit. Our method is fast despite the weak ancilla coupling. The weak
coupling in turn allows for excellent separability and thus independent
control. We demonstrate our control on a superconducting transmon qubit weakly
coupled to a multi-mode superconducting cavity. We create both entangled and
separable cat-states in different modes of the multi-mode cavity, showing
entangling operations while control of each mode is independent of the state of
the other mode. We show that the operation time is not limited by the inverse
of the coupling rate, which is the typical timescale, and we exceed it by
almost 2 orders of magnitude. Our scheme allows for fast and efficient
multi-mode bosonic encoding and measurement.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:13:38 GMT""},{""version"":""v2"",""created"":""Sat, 4 Mar 2023 19:38:00 GMT""}]","2023-03-07"
"2301.09832","Taro Sawada","Taro Sawada, Kazuki Sone, Yuto Ashida, Takahiro Sagawa","Role of Topology in Relaxation of One-dimensional Stochastic Processes","6+9 pages, 4+13 figures",,,,"cond-mat.stat-mech cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic processes are commonly used models to describe dynamics of a wide
variety of nonequilibrium phenomena ranging from electrical transport to
biological motion. The transition matrix describing a stochastic process can be
regarded as a non-Hermitian Hamiltonian. Unlike general non-Hermitian systems,
the conservation of probability imposes additional constraints on the
transition matrix, which can induce unique topological phenomena. Here, we
reveal the role of topology in relaxation phenomena of classical stochastic
processes. Specifically, we define a winding number that is related to topology
of stochastic processes and show that it predicts the existence of a spectral
gap that characterizes the relaxation time. Then, we numerically confirm that
the winding number corresponds to the system-size dependence of the relaxation
time and the unconventional transient behavior. One can experimentally realize
such topological phenomena in magnetotactic bacteria and cell adhesions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:13:43 GMT""}]","2023-01-25"
"2301.09833","Zhiwei Zhang","Moshe Y. Vardi and Zhiwei Zhang","Solving Quantum-Inspired Perfect Matching Problems via Tutte's
  Theorem-Based Hybrid Boolean Constraints","Accepted by IJCAI'23",,,,"cs.AI cs.LO math.CO quant-ph","http://creativecommons.org/licenses/by/4.0/","  Determining the satisfiability of Boolean constraint-satisfaction problems
with different types of constraints, that is hybrid constraints, is a
well-studied problem with important applications. We study here a new
application of hybrid Boolean constraints, which arises in quantum computing.
The problem relates to constrained perfect matching in edge-colored graphs.
While general-purpose hybrid constraint solvers can be powerful, we show that
direct encodings of the constrained-matching problem as hybrid constraints
scale poorly and special techniques are still needed. We propose a novel
encoding based on Tutte's Theorem in graph theory as well as optimization
techniques. Empirical results demonstrate that our encoding, in suitable
languages with advanced SAT solvers, scales significantly better than a number
of competing approaches on constrained-matching benchmarks. Our study
identifies the necessity of designing problem-specific encodings when applying
powerful general-purpose constraint solvers.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:14:24 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 02:46:09 GMT""}]","2023-05-19"
"2301.09834","Kevin Silva","Kevin M. Silva and Kevin J. Maki","Implementation of the Critical Wave Groups Method with Computational
  Fluid Dynamics and Neural Networks",,,,,"physics.flu-dyn cs.LG cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate and efficient prediction of extreme ship responses continues to be a
challenging problem in ship hydrodynamics. Probabilistic frameworks in
conjunction with computationally efficient numerical hydrodynamic tools have
been developed that allow researchers and designers to better understand
extremes. However, the ability of these hydrodynamic tools to represent the
physics quantitatively during extreme events is limited. Previous research
successfully implemented the critical wave groups (CWG) probabilistic method
with computational fluid dynamics (CFD). Although the CWG method allows for
less simulation time than a Monte Carlo approach, the large quantity of
simulations required is cost prohibitive. The objective of the present paper is
to reduce the computational cost of implementing CWG with CFD, through the
construction of long short-term memory (LSTM) neural networks. After training
the models with a limited quantity of simulations, the models can provide a
larger quantity of predictions to calculate the probability. The new framework
is demonstrated with a 2-D midship section of the Office of Naval Research
Tumblehome (ONRT) hull in Sea State 7 and beam seas at zero speed. The new
framework is able to produce predictions that are representative of a purely
CFD-driven CWG framework, with two orders of magnitude of computational cost
savings.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:14:58 GMT""}]","2023-01-25"
"2301.09835","Lei Shi","Haoyuan Zhang, Yingzhi Chen, Kunpeng Tang, Ziheng Lin, Xuan Li,
  Hongwei Zhang, Yifan Zhang, Takeshi Saito, Chi Ho Wong, Chi Wah Leung, Chee
  Leung Mak, Yuan Hu, Weili Cui, Kecheng Cao, Lei Shi","Microwave heating as a universal method to transform confined molecules
  into armchair graphene nanoribbons","7 pages, 7 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Armchair graphene nanoribbons (AGNRs) with sub-nanometer width are potential
materials for fabrication of novel nanodevices thanks to their moderate direct
band gaps. AGNRs are usually synthesized by polymerizing precursor molecules on
substrate surface. However, it is time-consuming and not suitable for
large-scale production. AGNRs can also be grown by transforming precursor
molecules inside single-walled carbon nanotubes via furnace annealing, but the
obtained AGNRs are normally twisted. In this work, microwave heating is applied
for transforming precursor molecules into AGNRs. The fast heating process
allows synthesizing the AGNRs in seconds. Several different molecules were
successfully transformed into AGNRs, suggesting that it is a universal method.
More importantly, as demonstrated by Raman spectroscopy, aberration-corrected
high-resolution transmission electron microscopy and theoretical calculations,
less twisted AGNRs are synthesized by the microwave heating than the furnace
annealing. Our results reveal a route for rapid production of AGNRs in large
scale, which would benefit future applications in novel AGNRs-based
semiconductor devices.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:35:59 GMT""}]","2023-01-25"
"2301.09836","Safa' Alsheyab","Safa' Alsheyab, Tahir Choulli","Optimal stopping problem under random horizon: Mathematical structures
  and linear RBSDEs","arXiv admin note: text overlap with arXiv:2107.11896",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers a pair $(\mathbb{F},\tau)$, where $\mathbb{F}$ is the
flow of information and $\tau$ is a random time which might not be an
$\mathbb{F}$-stopping time. To this pair, we associate the new filtration
$\mathbb{G}$ using the progressive enlargement of $\mathbb{F}$ with $\tau$. For
this setting governed with $\mathbb{G}$, we analyze the optimal stopping
problem in many aspects. Besides characterizing the existence of the solution
to this problem in terms of $\mathbb{F}$, we derive the mathematical structures
of the value process of this control problem, and we single out the optimal
stopping problem under $\mathbb{F}$ associated to it. These quantify deeply the
impact of $\tau$ on the optimal stopping problem. As an application, we assume
$\mathbb F$ is generated by a Brownian motion $W$, and we address the following
linear reflected-backward-stochastic differential equations (RBSDE hereafter
for short), \begin{eqnarray*} \begin{cases}
dY_t=f(t)d(t\wedge\tau)+Z_tdW_{t\wedge{\tau}}+dM_t-dK_t,\quad Y_{\tau}=\xi,
  Y\geq S\quad\mbox{on}\quad \Lbrack0,\tau\Lbrack,\quad
\displaystyle\int_0^{\tau}(Y_{s-}-S_{s-})dK_s=0\quad P\mbox{-a.s.}.\end{cases}
\end{eqnarray*} For this RBSDE, we focus on answering the following problems:
a) What are the sufficient minimal conditions on the data $(f, \xi, S, \tau)$
that guarantee the existence of the solution of the $\mathbb G$-RBSDE in $L^p$
($p>1$)? b) How can we estimate the solution in norm using the triplet-data
$(f, \xi, S)$? c) Is there an RBSDE under $\mathbb F$ that is intimately
related to the current one and how their solutions are related to each other?
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:42:53 GMT""}]","2023-01-25"
"2301.09837","Tanuman Ghosh","Tanuman Ghosh, Vikram Rana","Constraint on the accretion of NGC 6946 X-1 using broadband X-ray data","10 pages, 4 figures, accepted for publication in ApJ",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We analyze broadband X-ray data of NGC 6946 X-1 and probe plausible accretion
scenarios in this ULX. NGC 6946 X-1 is a persistent soft source with broadband
continuum spectra described by two thermal disk components. The cool accretion
disk temperature $\rm T_{cool} \sim 0.2$ keV and the presence of $\sim 0.9$ keV
emission/absorption broad feature suggests the evidence of optically thick wind
due to super-critical accretion. The hot geometrically modified accretion disk
has an inner temperature of $\rm T_{hot} \sim 2$ keV with a radial dependent
profile $\rm T(r) \propto r^{-0.5}$, expected in a slim disk scenario. Further,
the measurement based on a realistic inclination angle of the disk indicates
that the mass of the host compact object is comparable to $\rm \sim 6-10
~M_{\odot}$ non-rotating black hole or the system hosts a moderately magnetized
neutron star with $\rm B \lesssim 2 \times 10^{11}$ G magnetic field. Overall,
the detected spectral curvature, high luminosity, flux contribution from two
thermal disk components, and estimated accretion rate imprint the
super-Eddington accretion scenario.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:46:11 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 12:21:20 GMT""}]","2023-05-04"
"2301.09838","Song-Jin O","Ye-Un An, Song-Jin O, Kwang-Il Ryom, and Il-Gwang Son","Quantum spin Hall insulator on the honeycomb lattice induced by
  ferromagnetic exchange interaction","17 pages, 6 figures, 1 table","Physica B: Condensed Matter, 655, 414748 (2023)","10.1016/j.physb.2023.414748",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We study the many-body instabilities of correlated electrons on the
half-filled honeycomb lattice with enhanced exchange coupling. The system is
described by an extended Hubbard model including the next-nearest-neighbor
Coulomb repulsion ($V_2$) and the nearest-neighbor exchange interaction ($J$).
We use the truncated unity functional renormalization group approach to
determine a schematic ground-state phase diagram with higher resolution in the
parameter space of $V_2$ and $J$. In the absence of the on-site repulsion and
presence of sizable next-nearest-neighbor repulsion and enhanced
nearest-neighbor exchange interaction, we encounter the quantum spin Hall
phase, the spin-Kekul\'{e} phase, and the three-sublattice and the
incommensurate charge-density-wave phases. We propose a scheme for combining
consistently the truncated unity functional renormalization group and the
mean-field approximation, which is distinct from the conventional one that
directly uses the renormalization-group results as an input for the mean-field
calculation. This scheme is used to study in detail the quantum spin Hall
phase, presenting some characteristics like the bulk gap, the Chern number and
the helical edge states.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:48:15 GMT""}]","2023-03-21"
"2301.09839","Jiacheng Shen","Jiacheng Shen, Pengfei Zuo, Xuchuan Luo, Tianyi Yang, Yuxin Su,
  Yangfan Zhou, and Michael R. Lyu","FUSEE: A Fully Memory-Disaggregated Key-Value Store (Extended Version)",,,,,"cs.DC","http://creativecommons.org/licenses/by-sa/4.0/","  Distributed in-memory key-value (KV) stores are embracing the disaggregated
memory (DM) architecture for higher resource utilization. However, existing KV
stores on DM employ a semi-disaggregated design that stores KV pairs on DM but
manages metadata with monolithic metadata servers, hence still suffering from
low resource efficiency on metadata servers. To address this issue, this paper
proposes FUSEE, a FUlly memory-diSaggrEgated KV StorE that brings
disaggregation to metadata management. FUSEE replicates metadata, i.e., the
index and memory management information, on memory nodes, manages them directly
on the client side, and handles complex failures under the DM architecture. To
scalably replicate the index on clients, FUSEE proposes a client-centric
replication protocol that allows clients to concurrently access and modify the
replicated index. To efficiently manage disaggregated memory, FUSEE adopts a
two-level memory management scheme that splits the memory management duty among
clients and memory nodes. Finally, to handle the metadata corruption under
client failures, FUSEE leverages an embedded operation log scheme to repair
metadata with low log maintenance overhead. We evaluate FUSEE with both micro
and YCSB hybrid benchmarks. The experimental results show that FUSEE
outperforms the state-of-the-art KV stores on DM by up to 4.5 times with less
resource consumption.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:50:46 GMT""}]","2023-01-25"
"2301.09840","Benjamin Sambale","Benjamin Sambale","Character table sudokus","8 pages, typo corrected (thanks to \'Angel del R\'io)",,,,"math.RT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is a fun game to complete a partial character table of a finite group. We
show that one can reconstruct a missing row or column from a given table. The
proof relies on deep properties of fully ramified characters. Moreover, we
extend a classification of groups with a ""large"" character degree started by
Snyder and continued by Durfee and Jensen.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:58:02 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 04:52:31 GMT""}]","2023-01-30"
"2301.09841","Shodai Kubota","Shodai Kubota, Ken Shirakawa","Periodic solutions to Kobayashi--Warren--Carter systems",,,,,"math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, a system of parabolic PDEs, called the
Kobayashi--Warren--Carter system, is considered as a possible phase-field model
of planar grain boundary motion. The Main Theorem is concerned with the
existence of a time-periodic solution to the Kobayashi--Warren--Carter system,
and the principal objective is to provide a proof without the use of a
compromised assumption, which researchers have been forced to adopt in recent
studies.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:58:23 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 03:13:52 GMT""}]","2023-02-09"
"2301.09842","R. Winkler","R. Winkler and U. Z\""ulicke","Theory of electric, magnetic, and toroidal polarizations in crystalline
  solids with applications to hexagonal lonsdaleite and cubic diamond","26 pages, 5 figures, final version","Phys. Rev. B 107, 155201 (2023)","10.1103/PhysRevB.107.155201",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multipolar order in bulk crystalline solids is characterized by multipole
densities -- denoted as polarizations in this work -- that cannot be cleanly
defined using the concepts of classical electromagnetism. Here we use group
theory to overcome this difficulty and present a systematic study of electric,
magnetic and toroidal multipolar order in crystalline solids. Based on our
symmetry analysis, we identify five categories of polarized matter, each of
which is characterized by distinct features in the electronic band structure.
For example, Rashba spin splitting in electropolar bulk materials like wurtzite
represents the electric dipolarization in these materials. We also develop a
general formalism of indicators for individual multipole densities that provide
a physical interpretation and quantification of multipolar order. Our work
clarifies the relation between patterns of localized multipoles and macroscopic
multipole densities they give rise to. To illustrate the general theory, we
discuss its application to polarized variants of hexagonal lonsdaleite and
cubic diamond structures. Our work provides a general framework for classifying
and expanding current understanding of multipolar order in complex materials.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:00:30 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 02:01:05 GMT""}]","2023-04-06"
"2301.09843","Aparna Chakrabarti","Joydipto Bhattacharya, Rajeev Dutt and Aparna Chakrabarti","Ab initio Prediction of Mechanical, Electronic, Magnetic and Transport
  Properties of Bulk and Heterostructure of a Novel Fe-Cr based Full Heusler
  Chalcogenide",,,"10.1016/j.jpcs.2023.111307",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Using electronic structure calculations based on density functional theory,
we predict and study the structural, mechanical, electronic, magnetic and
transport properties of a new full Heusler chalcogenide, namely, Fe$_2$CrTe,
both in bulk and heterostructure form. The system shows a ferromagnetic and
half-metallic(HM) like behavior, with a very high (about 95%) spin polarization
at the Fermi level, in its cubic phase. Interestingly, under tetragonal
distortion, a clear minimum (with almost the same energy as the cubic phase)
has also been found, at a c/a value of 1.26, which, however, shows a
ferrimagnetic and fully metallic nature. The compound has been found to be
dynamically stable in both the phases against the lattice vibration. The
elastic properties indicate that the compound is mechanically stable in both
the phases, following the stability criteria of the cubic and tetragonal
phases. The elastic parameters unveil the mechanically anisotropic and ductile
nature of the alloy system. Due to the HM-like behavior of the cubic phase and
keeping in mind the practical aspects, we probe the effect of strain as well as
substrate on various physical properties of this alloy. Transmission profile of
the Fe$_2$CrTe/MgO/Fe$_2$CrTe heterojunction has been calculated to probe it as
a magnetic tunneling junction (MTJ) material in both the cubic and tetragonal
phases. Considerably large tunneling magnetoresistance ratio (TMR) of 1000% is
observed for the tetragonal phase, which is found to be one order of magnitude
larger than that of the cubic phase.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:02:30 GMT""}]","2023-04-05"
"2301.09844","Akihiro Mizutani","Akihiro Mizutani, Yuki Takeuchi, Kiyoshi Tamaki","Finite-key security analysis of differential-phase-shift quantum key
  distribution","17 pages, 6 figures","Phys. Rev. Research 5, 023132 (2023)","10.1103/PhysRevResearch.5.023132",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differential-phase-shift (DPS) quantum key distribution (QKD) is one of the
major QKD protocols that can be implemented with a simple setup using a laser
source and a passive detection unit. Recently, an information-theoretic
security proof of this protocol has been established in [npj Quant. Inf. 5, 87
(2019)] assuming the infinitely large number of emitted pulses. To implement
the DPS protocol in a real-life world, it is indispensable to analyze the
security with the finite number of emitted pulses. The extension of the
security proof to the finite-size regime requires the accommodation of the
statistical fluctuations to determine the amount of privacy amplification. In
doing so, Azuma's inequality is often employed, but unfortunately we show that
in the case of the DPS protocol, this results in a substantially low key rate.
This low key rate is due to a loose estimation of the sum of probabilities
regarding three-photon emission whose probability of occurrence is very small.
The main contribution of our work is to show that this obstacle can be overcome
by exploiting the recently found novel concentration inequality, Kato's
inequality. As a result, the key rate of the DPS protocol is drastically
improved. For instance, assuming typical experimental parameters, a 3 Mbit
secret key can be generated over 77 km for 8.3 hours, which shows the
feasibility of DPS QKD under a realistic setup.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:05:11 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 00:45:54 GMT""}]","2023-06-01"
"2301.09845","Manjil Saikia","Pankaj Jyoti Mahanta, Manjil P. Saikia and Abhishek Sarma","Biases in Non-Unitary Partitions","11 pages",,,,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the concept of parity bias in integer partitions has been studied
by several authors. We continue this study here, but for non-unitary partitions
(namely, partitions with parts greater than $1$). We prove analogous results
for these restricted partitions as those that have been obtained by Kim, Kim,
and Lovejoy (2020) and Kim and Kim (2021). We also look at inequalities between
two classes of partitions studied by Andrews (2019) where the parts are
separated by parity (either all odd parts are smaller than all even parts or
vice versa).
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:05:28 GMT""}]","2023-01-25"
"2301.09846","Manjil Saikia","Manjil P. Saikia","Some Missed Congruences modulo powers of $2$ for $t$-colored
  overpartitions","7 pages, published","Bolet\'in de la Sociedad Matem\'atica Mexicana, 2023, 29 (1),
  Article 15, 10 pp","10.1007/s40590-022-00487-8",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Nayaka and Naika (2022) proved several congruences modulo $16$ and
$32$ for $t$-colored overpartitions with $t=5,7,11$ and $13$. We extend their
list using an algorithmic technique.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:11:08 GMT""}]","2023-01-25"
"2301.09847","Alexandru Chirv\u{a}situ L.","Alexandru Chirvasitu","Non-degeneracy results for (multi-)pushouts of compact groups","27 pages + references; the new version contains a number of additions
  and corrections",,,,"math.GR math.CT math.GN math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that embeddings of compact groups are equalizers, and a number of
results on pushouts (and more generally, amalgamated free products) in the
category of compact groups. Call a family of compact-group embeddings $H\le
G_i$ algebraically sound if the corresponding group-theoretic pushout embeds in
its Bohr compactification. We (a) show that a family of normal embeddings is
algebraically sound in the sense that $G_i$ admit embeddings $G_i\le G$ into a
compact group which agree on $H$; (b) give equivalent characterizations of
coherently embeddable families of normal embeddings in representation-theoretic
terms, via Clifford theory; (c) characterize those compact connected Lie groups
$H$ for which all finite families of normal embeddings $H\trianglelefteq G_i$
are coherently embeddable (not having central 2-tori is a sufficient, but not
necessary condition), and (d) show that families of split embeddings of compact
groups are always algebraically sound.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:11:54 GMT""},{""version"":""v2"",""created"":""Wed, 1 Feb 2023 23:00:20 GMT""}]","2023-02-03"
"2301.09848","Tom\`as Ortega","Tomas Ortega and Hamid Jafarkhani","Gossiped and Quantized Online Multi-Kernel Learning",,"IEEE Signal Processing Letters. 30 (2023) 468-472","10.1109/LSP.2023.3268988",,"cs.LG eess.SP math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In instances of online kernel learning where little prior information is
available and centralized learning is unfeasible, past research has shown that
distributed and online multi-kernel learning provides sub-linear regret as long
as every pair of nodes in the network can communicate (i.e., the communications
network is a complete graph). In addition, to manage the communication load,
which is often a performance bottleneck, communications between nodes can be
quantized. This letter expands on these results to non-fully connected graphs,
which is often the case in wireless sensor networks. To address this challenge,
we propose a gossip algorithm and provide a proof that it achieves sub-linear
regret. Experiments with real datasets confirm our findings.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:12:40 GMT""},{""version"":""v2"",""created"":""Fri, 28 Apr 2023 18:38:06 GMT""}]","2023-05-02"
"2301.09849","Manjil Saikia","Pankaj Jyoti Mahanta and Manjil P. Saikia","Extensions of some results of Vladeta and Dhar","11 pages, submitted",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We look at extensions of formulas given by Vladeta and recently proved by
Dhar on integer partitions where the smallest part occurs at least $m$ times
and on integer partitions with fixed differences between the largest and
smallest parts where the smallest part occurs at least $k$ times. Our results
extend Dhar's results for the $m=2$ and $k=1$ cases to the general cases for
arbitrary $m$ and $k$. We also look at analogous results for overpartitions and
$\ell$-regular partitions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:14:16 GMT""}]","2023-01-25"
"2301.09850","Peijie Dong","Peijie Dong, Xin Niu, Lujun Li, Zhiliang Tian, Xiaodong Wang, Zimian
  Wei, Hengyue Pan, Dongsheng Li","RD-NAS: Enhancing One-shot Supernet Ranking Ability via Ranking
  Distillation from Zero-cost Proxies","6 pages, 2 figures, 4 tables, ICASSP 2023",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Neural architecture search (NAS) has made tremendous progress in the
automatic design of effective neural network structures but suffers from a
heavy computational burden. One-shot NAS significantly alleviates the burden
through weight sharing and improves computational efficiency. Zero-shot NAS
further reduces the cost by predicting the performance of the network from its
initial state, which conducts no training. Both methods aim to distinguish
between ""good"" and ""bad"" architectures, i.e., ranking consistency of predicted
and true performance. In this paper, we propose Ranking Distillation one-shot
NAS (RD-NAS) to enhance ranking consistency, which utilizes zero-cost proxies
as the cheap teacher and adopts the margin ranking loss to distill the ranking
knowledge. Specifically, we propose a margin subnet sampler to distill the
ranking knowledge from zero-shot NAS to one-shot NAS by introducing Group
distance as margin. Our evaluation of the NAS-Bench-201 and ResNet-based search
space demonstrates that RD-NAS achieve 10.7\% and 9.65\% improvements in
ranking ability, respectively. Our codes are available at
https://github.com/pprp/CVPR2022-NAS-competition-Track1-3th-solution
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:49:04 GMT""}]","2023-01-25"
"2301.09851","Jiajun Zhou","Shengbo Gong, Jiajun Zhou, Chenxuan Xie, Qi Xuan","Neighborhood Homophily-Guided Graph Convolutional Network",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph neural networks (GNNs) have achieved remarkable advances in
graph-oriented tasks. However, many real-world graphs contain heterophily or
low homophily, challenging the homophily assumption of classical GNNs and
resulting in low performance. Although many studies have emerged to improve the
universality of GNNs, they rarely consider the label reuse and the correlation
of their proposed metrics and models. In this paper, we first design a new
metric, named Neighborhood Homophily (\textit{NH}), to measure the label
complexity or purity in the neighborhood of nodes. Furthermore, we incorporate
this metric into the classical graph convolutional network (GCN) architecture
and propose \textbf{N}eighborhood \textbf{H}omophily-\textbf{G}uided
\textbf{G}raph \textbf{C}onvolutional \textbf{N}etwork (\textbf{NHGCN}). In
this framework, nodes are grouped by estimated \textit{NH} values to achieve
intra-group weight sharing during message propagation and aggregation. Then the
generated node predictions are used to estimate and update new \textit{NH}
values. The two processes of metric estimation and model inference are
alternately optimized to achieve better node classification. Extensive
experiments on both homophilous and heterophilous benchmarks demonstrate that
\textbf{NHGCN} achieves state-of-the-art overall performance on semi-supervised
node classification for the universality problem.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:56:44 GMT""}]","2023-01-25"
"2301.09852","David Zwicker","Swati Sen and David Zwicker","Zonal receptor distributions maximize olfactory information","6 pages, 4 figures",,,,"physics.bio-ph q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The olfactory sense measures the chemical composition of the environment
using a diverse array of olfactory receptors. In vertebrates, the olfactory
receptors reside in a mucus layer in the nasal cavity and can thus only detect
odorants that are inhaled with the airflow and dissolved in mucus. These
physical processes fundamentally affect how many odorant molecules contact the
receptors. We hypothesize that the olfactory system works efficiently by
optimizing the placement of receptors for maximal information transmission.
Using a simplified model, we capture all relevant physical processes and show
that odorant concentrations generally exhibit an exponential distribution.
Combining this result with information theory, we further show that receptors
separated into distinct spatial zones maximize the transmitted information. Our
results are consistent with experimentally observed receptors zones and might
help to improve artificial smell sensors.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:58:57 GMT""}]","2023-01-25"
"2301.09853","Martin Fern{\o}","Anthony R. Kovscek, Jan Martin Nordbotten, Martin A. Ferno","Scaling up FluidFlower results for carbon dioxide storage in geological
  media",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  The partial differential equations describing immiscible, but soluble, carbon
dioxide (CO2) displacement of brine are developed including local mass-transfer
effects. Scaling relationships for characteristic time among laboratory and
representative storage formation conditions are found upon assumption that
free-phase CO2 transport during injection is dominated by convection. The
implication is that an hour in the FluidFlower (large-scale visual model)
scales to hundreds of years of elapsed time in the storage formation. The
scaling criteria permit extrapolation of the effects of changes in parameters
and operating conditions. Interphase mass transfer allows CO2 to saturate the
brine phase and such mass transfer is a significant nonequilibrium phenomenon.
Significant mixing of CO2 dissolved into formation brine with original brine is
found experimentally and is also predicted. The magnitude of onset time for
downward migrating fingers containing CO2 is typically only a fraction of the
duration of CO2 injection and in general agreement with theoretical analysis in
the literature. Predictions for onset time of convective mixing at
representative storage formation conditions likewise teach that the onset time
for viscous fingering is significantly less than the duration of CO2 injection
in some cases. The implications of this observation include that mixing of CO2
with brine and the subsequent settling due to gravity are relatively rapid and
coincide with the period of active CO2 injection.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:02:21 GMT""}]","2023-01-25"
"2301.09854","Ruta Desai","Engin Tekin, Elaheh Barati, Nitin Kamra, Ruta Desai","Effective Baselines for Multiple Object Rearrangement Planning in
  Partially Observable Mapped Environments","AAAI 2023 Workshop on User-Centric Artificial Intelligence for
  Assistance in At-Home Tasks",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Many real-world tasks, from house-cleaning to cooking, can be formulated as
multi-object rearrangement problems -- where an agent needs to get specific
objects into appropriate goal states. For such problems, we focus on the
setting that assumes a pre-specified goal state, availability of perfect
manipulation and object recognition capabilities, and a static map of the
environment but unknown initial location of objects to be rearranged. Our goal
is to enable home-assistive intelligent agents to efficiently plan for
rearrangement under such partial observability. This requires efficient
trade-offs between exploration of the environment and planning for
rearrangement, which is challenging because of long-horizon nature of the
problem. To make progress on this problem, we first analyze the effects of
various factors such as number of objects and receptacles, agent carrying
capacity, environment layouts etc. on exploration and planning for
rearrangement using classical methods. We then investigate both monolithic and
modular deep reinforcement learning (DRL) methods for planning in our setting.
We find that monolithic DRL methods do not succeed at long-horizon planning
needed for multi-object rearrangement. Instead, modular greedy approaches
surprisingly perform reasonably well and emerge as competitive baselines for
planning with partial observability in multi-object rearrangement problems. We
also show that our greedy modular agents are empirically optimal when the
objects that need to be rearranged are uniformly distributed in the environment
-- thereby contributing baselines with strong performance for future work on
multi-object rearrangement planning in partially observable settings.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:03:34 GMT""}]","2023-01-25"
"2301.09855","Tetsuya Ito","Tetsuya Ito","Special alternating knots with sufficiently many twist regions have no
  chirally cosmetic surgeries","23 pages",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that a special alternating knot with sufficiently large number (more
than $63$) of twist regions has no chirally cosmetic surgeries, a pair of Dehn
surgeries producing orientation-reversingly homeomorphic $3$-manifolds. In the
course of proof, we provide the optimal upper bounds of the primitive finite
type invariants of degree 2 and 3 that solve Willerton's conjecture.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:06:44 GMT""}]","2023-01-25"
"2301.09856","Konstantinos P. Panousis","Anastasios Petropoulos, Vassilis Siakoulis, Konstantinos P. Panousis,
  Loukas Papadoulas, Sotirios Chatzis","Macroeconomic forecasting and sovereign risk assessment using deep
  learning techniques","arXiv admin note: substantial text overlap with arXiv:2009.11075",,,,"q-fin.CP stat.AP","http://creativecommons.org/licenses/by/4.0/","  In this study, we propose a novel approach of nowcasting and forecasting the
macroeconomic status of a country using deep learning techniques. We focus
particularly on the US economy but the methodology can be applied also to other
economies. Specifically US economy has suffered a severe recession from 2008 to
2010 which practically breaks out conventional econometrics model attempts.
Deep learning has the advantage that it models all macro variables
simultaneously taking into account all interdependencies among them and
detecting non-linear patterns which cannot be easily addressed under a
univariate modelling framework. Our empirical results indicate that the deep
learning methods have a superior out-of-sample performance when compared to
traditional econometric techniques such as Bayesian Model Averaging (BMA).
Therefore our results provide a concise view of a more robust method for
assessing sovereign risk which is a crucial component in investment and
monetary decisions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:09:51 GMT""}]","2023-01-25"
"2301.09857","Gi-Chan Bae","Gi-Chan Bae, Gyounghun Ko, Donghyun Lee and Seok-Bae Yun","Large amplitude problem of BGK model: Relaxation to quadratic
  nonlinearity","34 pages, 1 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  Bhatnagar-Gross-Krook (BGK) equation is a relaxation model of the Boltzmann
equation which is widely used in place of the Boltzmann equation for the
simulation of various kinetic flow problems. In this work, we study the
asymptotic stability of the BGK model when the initial data is not necessarily
close to the global equilibrium pointwisely. Due to the highly nonlinear
structure of the relaxation operator, the argument developed to derive the
bootstrap estimate for the Boltzmann equation leads to a weaker estimate in the
case of the BGK model, which does not exclude the possible blow-up of the
perturbation. To overcome this issue, we carry out a refined analysis of the
macroscopic fields to guarantee that the system transits from a highly
nonlinear regime into a quadratic nonlinear regime after a long but finite
time, in which the highly nonlinear perturbative term relaxes to essentially
quadratic nonlinearity.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:18:38 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 14:25:16 GMT""}]","2023-01-26"
"2301.09858","Edouard Yvinec","Edouard Yvinec, Arnaud Dapogny, Matthieu Cord, Kevin Bailly","PowerQuant: Automorphism Search for Non-Uniform Quantization",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) are nowadays ubiquitous in many domains such as
computer vision. However, due to their high latency, the deployment of DNNs
hinges on the development of compression techniques such as quantization which
consists in lowering the number of bits used to encode the weights and
activations. Growing concerns for privacy and security have motivated the
development of data-free techniques, at the expanse of accuracy. In this paper,
we identity the uniformity of the quantization operator as a limitation of
existing approaches, and propose a data-free non-uniform method. More
specifically, we argue that to be readily usable without dedicated hardware and
implementation, non-uniform quantization shall not change the nature of the
mathematical operations performed by the DNN. This leads to search among the
continuous automorphisms of $(\mathbb{R}_+^*,\times)$, which boils down to the
power functions defined by their exponent. To find this parameter, we propose
to optimize the reconstruction error of each layer: in particular, we show that
this procedure is locally convex and admits a unique solution. At inference
time, we show that our approach, dubbed PowerQuant, only require simple
modifications in the quantized DNN activation functions. As such, with only
negligible overhead, it significantly outperforms existing methods in a variety
of configurations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:30:14 GMT""}]","2023-01-25"
"2301.09859","Tabea Heckenthaler","Tabea Heckenthaler, Tobias Holder, Ariel Amir, Ofer Feinerman, Ehud
  Fonio","Connecting cooperative transport by ants with the physics of active
  swimmers","5 pages + 10 pages supplementary information. 4+12 figures",,,,"physics.bio-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some ant species are known as efficient transporters that can cooperatively
carry food items which would be too large for a single ant. Previous studies of
cooperative transport focused on the role of individual ants and their
behavioral rules that allow for efficient coordination. However, the resulting
detailed microscopic description requires a numerical treatment in order to
extract macroscopic features of the object's trajectory. Here, we instead treat
the carried object as a single active swimmer whose movement is characterized
by two variables: velocity amplitude and direction. We experimentally observe
Paratrechina longicornis ants cooperatively transporting loads of varying
sizes. By analyzing the statistical features of the load's movement, we show
how the salient properties of the cooperative transport are encoded in its
deterministic and random accelerations. We find that while the autocorrelation
time of the velocity direction increases with group size, the autocorrelation
time of the speed has a maximum at an intermediate group size, corresponding to
the critical slow down close to the previously identified phase transition. Our
statistical model for cooperative ant transport demonstrates that an active
swimmer model can be employed to describe a system of interacting individuals.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:35:26 GMT""}]","2023-01-25"
"2301.09860","Adrian Corrochano","Adri\'an Corrochano, Rodolfo S.M. Freitas, Alessandro Parente, Soledad
  Le Clainche","A predictive physics-aware hybrid reduced order model for reacting flows",,,,,"cs.LG physics.data-an","http://creativecommons.org/licenses/by/4.0/","  In this work, a new hybrid predictive Reduced Order Model (ROM) is proposed
to solve reacting flow problems. This algorithm is based on a dimensionality
reduction using Proper Orthogonal Decomposition (POD) combined with deep
learning architectures. The number of degrees of freedom is reduced from
thousands of temporal points to a few POD modes with their corresponding
temporal coefficients. Two different deep learning architectures have been
tested to predict the temporal coefficients, based on recursive (RNN) and
convolutional (CNN) neural networks. From each architecture, different models
have been created to understand the behavior of each parameter of the neural
network. Results show that these architectures are able to predict the temporal
coefficients of the POD modes, as well as the whole snapshots. The RNN shows
lower prediction error for all the variables analyzed. The model was also found
capable of predicting more complex simulations showing transfer learning
capabilities.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:39:20 GMT""}]","2023-01-25"
"2301.09861","Vasileios E. Papageorgiou","Vasileios E. Papageorgiou, Pantelis Dogoulis, Dimitrios-Panagiotis
  Papageorgiou","A convolutional neural network of low complexity for tumor anomaly
  detection","This article has been accepted for publication in the 8th
  International Congress on Information and Communication Technology (ICICT
  2023, Springer)",,,,"eess.IV stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automated detection of cancerous tumors has attracted interest mainly
during the last decade, due to the necessity of early and efficient diagnosis
that will lead to the most effective possible treatment of the impending risk.
Several machine learning and artificial intelligence methodologies has been
employed aiming to provide trustworthy helping tools that will contribute
efficiently to this attempt. In this article, we present a low-complexity
convolutional neural network architecture for tumor classification enhanced by
a robust image augmentation methodology. The effectiveness of the presented
deep learning model has been investigated based on 3 datasets containing brain,
kidney and lung images, showing remarkable diagnostic efficiency with
classification accuracies of 99.33%, 100% and 99.7% for the 3 datasets
respectively. The impact of the augmentation preprocessing step has also been
extensively examined using 4 evaluation measures. The proposed low-complexity
scheme, in contrast to other models in the literature, renders our model quite
robust to cases of overfitting that typically accompany small datasets
frequently encountered in medical classification challenges. Finally, the model
can be easily re-trained in case additional volume images are included, as its
simplistic architecture does not impose a significant computational burden.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:44:19 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 11:10:21 GMT""},{""version"":""v3"",""created"":""Mon, 6 Feb 2023 11:13:53 GMT""},{""version"":""v4"",""created"":""Tue, 7 Feb 2023 12:58:13 GMT""}]","2023-02-08"
"2301.09862","Fabrizio Sebastiani","Silvia Corbara and Alejandro Moreo and Fabrizio Sebastiani","Same or Different? Diff-Vectors for Authorship Analysis",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  We investigate the effects on authorship identification tasks of a
fundamental shift in how to conceive the vectorial representations of documents
that are given as input to a supervised learner. In ``classic'' authorship
analysis a feature vector represents a document, the value of a feature
represents (an increasing function of) the relative frequency of the feature in
the document, and the class label represents the author of the document. We
instead investigate the situation in which a feature vector represents an
unordered pair of documents, the value of a feature represents the absolute
difference in the relative frequencies (or increasing functions thereof) of the
feature in the two documents, and the class label indicates whether the two
documents are from the same author or not. This latter (learner-independent)
type of representation has been occasionally used before, but has never been
studied systematically. We argue that it is advantageous, and that in some
cases (e.g., authorship verification) it provides a much larger quantity of
information to the training process than the standard representation. The
experiments that we carry out on several publicly available datasets (among
which one that we here make available for the first time) show that feature
vectors representing pairs of documents (that we here call Diff-Vectors) bring
about systematic improvements in the effectiveness of authorship identification
tasks, and especially so when training data are scarce (as it is often the case
in real-life authorship identification scenarios). Our experiments tackle
same-author verification, authorship verification, and closed-set authorship
attribution; while DVs are naturally geared for solving the 1st, we also
provide two novel methods for solving the 2nd and 3rd that use a solver for the
1st as a building block.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:48:12 GMT""}]","2023-01-25"
"2301.09863","Enrico Mingo Hoffman","Enrico Mingo Hoffman, Arturo Laurenzi, Francesco Ruscelli, Luca
  Rossini, Lorenzo Baccelliere, Davide Antonucci, Alessio Margan, Paolo Guria,
  Marco Migliorini, Stefano Cordasco, Gennaro Raiola, Luca Muratore, Joaqu\'in
  Estremera Rodrigo, Andrea Rusconi, Guido Sangiovanni, Nikos G. Tsagarakis","Design and Validation of a Multi-Arm Relocatable Manipulator for Space
  Applications","7 pages (last page references), 15 figures, accepted to the IEEE
  International Conference on Robotics and Automation (ICRA) 2023",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This work presents the computational design and validation of the Multi-Arm
Relocatable Manipulator (MARM), a three-limb robot for space applications, with
particular reference to the MIRROR (i.e., the Multi-arm Installation Robot for
Readying ORUs and Reflectors) use-case scenario as proposed by the European
Space Agency. A holistic computational design and validation pipeline is
proposed, with the aim of comparing different limb designs, as well as ensuring
that valid limb candidates enable MARM to perform the complex loco-manipulation
tasks required. Motivated by the task complexity in terms of kinematic
reachability, (self)-collision avoidance, contact wrench limits, and motor
torque limits affecting Earth experiments, this work leverages on multiple
state-of-art planning and control approaches to aid the robot design and
validation. These include sampling-based planning on manifolds, non-linear
trajectory optimization, and quadratic programs for inverse dynamics
computations with constraints. Finally, we present the attained MARM design and
conduct preliminary tests for hardware validation through a set of lab
experiments.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:50:26 GMT""}]","2023-01-25"
"2301.09864","Manoj Kumar Panda","M. K. Panda, Shubham Kumar Rajput","Effects of both diffuse and collimated incident radiation on phototactic
  bioconvection",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The linear stability of a finite-depth algal suspension is investigated
numerically with particular emphasis on the effects of angle of incidence. The
suspension of phototactic algae is uniformly illuminated by both diffuse and
oblique collimated irradiation. The bioconvective solutions show a transition
of the most unstable mode of disturbance from the stationary (overstable) to
overstable (stationary) state at the variation in angle of incidence for fixed
parameter ranges. Furthermore, a transition from mode 2 to mode 1 instability
is noticed for some parameter values as the angle of incidence varies.
Oscillatory modes of disturbance are also predicted at the increment in angle
of incidence (or cell swimming speed)
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 08:57:13 GMT""}]","2023-01-25"
"2301.09865","Priyashkumar Mistry","Priyashkumar Mistry, Kamlesh Pathak, Aniket Prasad, Georgios Lekkas,
  Surendra Bhattarai, Sarvesh Gharat, Mousam Maity, Dhruv Kumar, Karen A.
  Collins, Richard P. Schwarz, Christopher R. Mann, Elise Furlan, Steve B.
  Howell, David Ciardi, Allyson Bieryla, Elisabeth C. Matthews, Erica Gonzales,
  Carl Ziegler, Ian Crossfield, Steven Giacalone, Thiam-Guan Tan, Phil Evans,
  Krzysztof G. Helminiak, Kevin I. Collins, Norio Narita, Akihiko Fukui,
  Francisco J. Pozuelos, Courtney Dressing, Abderahmane Soubkiou, Zouhair
  Benkhaldoun, Joshua E. Schlieder, Olga Suarez, Khalid Barkaoui, Enric Palle,
  Felipe Murgas, Gregor Srdoc, Maria V. Goliguzova, Ivan A. Strakhov, Crystal
  Gnilka, Kathryn Lester, Colin Littlefield, Nic Scott, Rachel Matson, Michael
  Gillon, Emmanuel Jehin, Mathilde Timmermans, Mourad Ghachoui, Lyu Abe,
  Philippe Bendjoya, Tristan Guillot and Amaury H.M.J. Triaud","VaTEST II: Statistical Validation of 11 TESS-Detected Exoplanets
  Orbiting K-type Stars","Accepted for Publication in Astronomical Journal, 28 Pages, 7 Figures",,,,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  NASA's Transiting Exoplanet Survey Satellite (TESS) is an all-sky survey
mission designed to find transiting exoplanets orbiting nearby bright stars. It
has identified more than 329 transiting exoplanets, and almost 6,000 candidates
remain unvalidated. In this manuscript, we discuss the findings from the
ongoing VaTEST (Validation of Transiting Exoplanets using Statistical Tools)
project, which aims to validate new exoplanets for further characterization. We
validated 11 new exoplanets by examining the light curves of 24 candidates
using the LATTE and TESS-Plot tools and computing the False Positive
Probabilities using the statistical validation tool TRICERATOPS. These include
planets suitable for atmospheric characterization using transmission
spectroscopy (TOI-2194b), emission spectroscopy (TOI-3082b and TOI-5704b) and
for both transmission and emission spectroscopy (TOI-672b, TOI- 1694b, and
TOI-2443b); One super-Earth (TOI-2194b) orbiting a bright (V = 8.42 mag),
metal-poor ([Fe/H] = -0.3720 $\pm$ 0.1) star; one short-period Neptune-like
planet (TOI-5704) in the Hot Neptune Desert. In total, we validated 1
super-Earth, 7 sub-Neptunes, 1 Neptune-like, and 2 sub-Saturn or
super-Neptune-like exoplanets. Additionally, we identify five likely planet
candidates (TOI-323, TOI- 1180, TOI-2200, TOI-2408 and TOI-3913) which can be
further studied to establish their planetary nature.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:00:57 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 16:43:45 GMT""},{""version"":""v3"",""created"":""Wed, 3 May 2023 10:25:47 GMT""},{""version"":""v4"",""created"":""Sat, 13 May 2023 16:55:03 GMT""}]","2023-05-16"
"2301.09866","Micha{\l} Marczenko","Micha{\l} Marczenko, Krzysztof Redlich, Chihiro Sasaki","Fluctuations near the liquid-gas and chiral phase transitions in
  hadronic matter","Version accepted for publication in Phys. Rev. D. arXiv admin note:
  substantial text overlap with arXiv:2012.15535","Phys. Rev. D 107, 054046 (2023)","10.1103/PhysRevD.107.054046",,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the fluctuations of the net-baryon number density in dense
hadronic matter. Chiral dynamics is modeled via the parity doublet Lagrangian,
and the mean-field approximation is employed to account for chiral criticality.
We focus on the qualitative properties and systematics of the second-order
susceptibility of the net-baryon number density for individual positive- and
negative-parity nucleons whose masses become degenerate at the chiral
restoration. It is shown that the second-order susceptibility of the
positive-parity state can become negative when the chiral symmetry is restored,
as a natural consequence of the unique relationship of the mass to the order
parameter. Moreover, we find that such negative fluctuations are indicative of
approaching the critical point on the chiral phase boundary. Our results may
have consequences for the interpretation of the experimental data on net-proton
fluctuations in heavy-ion collisions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:03:00 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 08:58:45 GMT""}]","2023-04-05"
"2301.09867","L\'aszl\'o Papp F.","L\'aszl\'o F. Papp","Restricted optimal pebbling is NP-hard",,,,,"math.CO cs.CC","http://creativecommons.org/licenses/by/4.0/","  Consider a distribution of pebbles on a graph. A pebbling move removes two
pebbles from a vertex and place one at an adjacent vertex. A vertex is
reachable under a pebble distribution if it has a pebble after the application
of a sequence of pebbling moves. A pebble distribution is solvable if each
vertex is reachable under it. The size of a pebble distribution is the total
number of pebbles. The optimal pebbling number $\pi^*(G)$ is the size of the
smallest solvable distribution. A $t$-restricted pebble distribution places at
most $t$ pebbles at each vertex. The $t$-restricted optimal pebbling number
$\pi_t^*(G)$ is the size of the smallest solvable $t$-restricted pebble
distribution. We show that deciding whether $\pi^*_2(G)\leq k$ is NP-complete.
We prove that $\pi_t^*(G)=\pi^*(G)$ if $\delta(G)\geq \frac{2|V(G)|}{3}-1$ and
we show infinitely many graphs which satisfies $\delta(H)\approx
\frac{1}{2}|V(H)|$ but $\pi_t^*(H)\neq\pi^*(H)$, where $\delta$ denotes the
minimum degree.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:04:04 GMT""}]","2023-01-25"
"2301.09868","Damianos Iosifidis","Damianos Iosifidis","Metric-Affine Cosmologies: Kinematics of Perfect (Ideal) Cosmological
  Hyperfluids and First Integrals","19 pages, no figures",,,,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a generic Metric-Affine Cosmological setup and classify some
particularly interesting specific cases of Perfect Hyperfluids. In particular,
we present the form of conservation laws for the cases of pure spin, pure
dilation and pure shear fluids. We also develop the concept of an
incompressible hyperfluid and pay special attention to the case of a
hypermomentum preserving hyperfluid. We also give a specific example on the
emergence of the spin, dilation and shear currents through matter-connection
couplings. In addition, starting from the generalized acceleration equation for
the scale factor including torsion and non-metricity we provide a first
integral of motion relating the latter with the rest of the hyperfluid
variables. These results then formalize the analysis of the non-Riemannian
effects in Cosmology.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:04:34 GMT""}]","2023-01-25"
"2301.09869","Jinpeng Shi","Jinpeng Shi, Hui Li, Tianle Liu, Yulong Liu, Mingjian Zhang, Jinchen
  Zhu, Ling Zheng, Shizhuang Weng","Image Super-Resolution using Efficient Striped Window Transformer","SOTA lightweight super-resolution transformer. 8 pages, 9 figures and
  6 tables. The Code is available at
  https://github.com/Fried-Rice-Lab/FriedRiceLab",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have achieved remarkable results in single-image
super-resolution (SR). However, the challenge of balancing model performance
and complexity has hindered their application in lightweight SR (LSR). To
tackle this challenge, we propose an efficient striped window transformer
(ESWT). We revisit the normalization layer in the transformer and design a
concise and efficient transformer structure to build the ESWT. Furthermore, we
introduce a striped window mechanism to model long-term dependencies more
efficiently. To fully exploit the potential of the ESWT, we propose a novel
flexible window training strategy that can improve the performance of the ESWT
without additional cost. Extensive experiments show that ESWT outperforms
state-of-the-art LSR transformers, and achieves a better trade-off between
model performance and complexity. The ESWT requires fewer parameters, incurs
faster inference, smaller FLOPs, and less memory consumption, making it a
promising solution for LSR.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:09:35 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 07:03:54 GMT""}]","2023-03-15"
"2301.09870","Carlos Puerto-Santana","Carlos Puerto-Santana, Concha Bielza, Pedro Larra\~naga, Gustav Eje
  Henter","Context-specific kernel-based hidden Markov model for time series
  analysis","Keywords: Hidden Markov models, Kernel density estimation, Bayesian
  networks, Adaptive models, Time series",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Traditional hidden Markov models have been a useful tool to understand and
model stochastic dynamic data; in the case of non-Gaussian data, models such as
mixture of Gaussian hidden Markov models can be used. However, these suffer
from the computation of precision matrices and have a lot of unnecessary
parameters. As a consequence, such models often perform better when it is
assumed that all variables are independent, a hypothesis that may be
unrealistic. Hidden Markov models based on kernel density estimation are also
capable of modeling non-Gaussian data, but they assume independence between
variables. In this article, we introduce a new hidden Markov model based on
kernel density estimation, which is capable of capturing kernel dependencies
using context-specific Bayesian networks. The proposed model is described,
together with a learning algorithm based on the expectation-maximization
algorithm. Additionally, the model is compared to related HMMs on synthetic and
real data. From the results, the benefits in likelihood and classification
accuracy from the proposed model are quantified and analyzed.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:10:38 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 13:00:31 GMT""}]","2023-05-16"
"2301.09871","Mamoru Endo PhD","Mamoru Endo, Ruofan He, Tatsuki Sonoyama, Kazuma Takahashi, Takahiro
  Kashiwazaki, Takeshi Umeki, Sachiko Takasu, Kaori Hattori, Daiji Fukuda,
  Kosuke Fukui, Kan Takase, Warit Asavanant, Petr Marek, Radim Filip, Akira
  Furusawa","Non-Gaussian quantum state generation by multi-photon subtraction at the
  telecommunication wavelength","14 pages, 5 figures","Optics Express 31, 12865-12879 (2023)","10.1364/OE.486270",,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the field of continuous-variable quantum information processing,
non-Gaussian states with negative values of the Wigner function are crucial for
the development of a fault-tolerant universal quantum computer. While several
non-Gaussian states have been generated experimentally, none have been created
using ultrashort optical wave packets, which are necessary for high-speed
quantum computation, in the telecommunication wavelength band where mature
optical communication technology is available. In this paper, we present the
generation of non-Gaussian states on wave packets with a short 8-ps duration in
the 1545.32 nm telecommunication wavelength band using photon subtraction up to
three photons. We used a low-loss, quasi-single spatial mode waveguide optical
parametric amplifier, a superconducting transition edge sensor, and a
phase-locked pulsed homodyne measurement system to observe negative values of
the Wigner function without loss correction up to three-photon subtraction.
These results can be extended to the generation of more complicated
non-Gaussian states and are a key technology in the pursuit of high-speed
optical quantum computation.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:13:36 GMT""}]","2023-04-05"
"2301.09872","Jun Su","Jun Su and Long Zhu","Temperature of the hot $\alpha$-source: a guidance to probe the
  Bose-Einstein condensation of $\alpha$ clusters in the heavy-ion collision",,,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experimental efforts were made to explore the Bose-Einstein
condensation in multi-$\alpha$ system using the heavy-ion collisions. This
Letter provides a explanation why no signatures were observed and a guidance
for future experiments. More precisely, a harmonic oscillator model is
developed to study the multi-$\alpha$ source at or near zero temperature. The
temperature and particle population of the multi-$\alpha$ sources observed in
the current experiments are extracted. It is found that almost no $\alpha$
particles occupy the ground state in those multi-$\alpha$ sources. The critical
temperature for the multi-$\alpha$-condensed states are predicted, which
provides a guidance for the future experiments to probe the Bose-Einstein
condensation of $\alpha$ clusters in the heavy-ion collisions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:15:44 GMT""}]","2023-01-25"
"2301.09873","Yoshiyuki Kageyama","Yoshiyuki Kageyama, Makiko Matsuura, and Daisuke Yazaki","Modulation in the motion of an autonomous molecular-machine assembly
  caused by the hysteresis in response to the directionality of the applied
  light",,,,,"physics.bio-ph cond-mat.soft nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Living organisms show self-sustained motion, make behavioural decisions in
response to their environment, and replicate themselves in a genetic manner.
Recently, nanometre-sized molecular machines have been assembled to realise
macroscopic systems that exhibit self-sustaining dynamics. However, it is
unclear how such systems can acquire the ability to make decisions in response
to their environment. We have previously reported that the behaviour of a
light-driven self-oscillating crystal becomes complicated when the driving
light is polarised. Here, we reveal by incorporating a theoretical analysis
that the apparent complexity is due to the orientation of the crystal relative
to the incident light. An additional reason for this complexity is that the
components remember the polarity of the preceding light input. Our results
provide a new concept, i.e., collaboration between a motor molecule to achieve
self-sustaining motion and a responsive machine for storing information to
realise self-governed dynamics in a multimolecular architecture.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:16:09 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 12:22:05 GMT""},{""version"":""v3"",""created"":""Thu, 9 Mar 2023 08:13:01 GMT""}]","2023-03-10"
"2301.09874","Giovanni Luca Cascio Rizzo","Giovanni Luca Cascio Rizzo, Jonah Berger, and Francisco Villarroel","What Drives Virtual Influencer's Impact?",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the midst of the influencer marketing boom, more and more companies are
shifting resources from real to virtual (or computer-generated) influencers.
But while virtual influencers have the potential to engage consumers and drive
action, some posts resonate and boost sales, while others do not. What makes
some virtual influencer posts more impactful? This work examines how including
someone else in photos shapes consumer responses to virtual influencers' posts.
A multimethod investigation, combining automated image and text analysis of
thousands of social media posts with controlled experiments, demonstrates that
companion presence boosts impact. These effects are driven by trust. Companion
presence makes virtual influencers seem more human, which makes them seem more
trustworthy, and thus increases the impact of their posts. Taken together, the
findings shed light on how others' presence shapes responses to virtual
influencer content, reveal a psychological mechanism through which companions
affect consumer perceptions, and provide actionable insights for designing more
impactful social media content.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:22:41 GMT""}]","2023-01-25"
"2301.09875","Georgios M. Koutentakis","Georgios M. Koutentakis, Areg Ghazaryan, and Mikhail Lemeshko","Rotor Lattice Model of Ferroelectric Large Polarons","Includes Supplemental Materials, 12 pages, 8 figures",,,,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.other quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a minimal model of charge transport in hybrid perovskites, which
provides an intuitive explanation for the recently proposed formation of
ferroelectric large polarons. We demonstrate that short-ranged charge--rotor
interactions lead to long-range ferroelectic ordering of rotors, which strongly
affects the carrier mobility. In the nonperturbative regime, where our theory
cannot be reduced to any of the earlier models, we predict polaron properties
in good agreement with experiment. This shows the potential of simple models to
reveal electronic properties of molecular materials.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:23:33 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 19:59:03 GMT""}]","2023-03-08"
"2301.09876","Tome Eftimov","Ana Kostovska, Diederick Vermetten, Sa\v{s}o D\v{z}eroski, Pan\v{c}e
  Panov, Tome Eftimov, Carola Doerr","Using Knowledge Graphs for Performance Prediction of Modular
  Optimization Algorithms","To appear at EvoApps 2023",,,,"cs.NE cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Empirical data plays an important role in evolutionary computation research.
To make better use of the available data, ontologies have been proposed in the
literature to organize their storage in a structured way. However, the full
potential of these formal methods to capture our domain knowledge has yet to be
demonstrated. In this work, we evaluate a performance prediction model built on
top of the extension of the recently proposed OPTION ontology. More
specifically, we first extend the OPTION ontology with the vocabulary needed to
represent modular black-box optimization algorithms. Then, we use the extended
OPTION ontology, to create knowledge graphs with fixed-budget performance data
for two modular algorithm frameworks, modCMA, and modDE, for the 24 noiseless
BBOB benchmark functions. We build the performance prediction model using a
knowledge graph embedding-based methodology. Using a number of different
evaluation scenarios, we show that a triple classification approach, a fairly
standard predictive modeling task in the context of knowledge graphs, can
correctly predict whether a given algorithm instance will be able to achieve a
certain target precision for a given problem instance. This approach requires
feature representation of algorithms and problems. While the latter is already
well developed, we hope that our work will motivate the community to
collaborate on appropriate algorithm representations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:28:57 GMT""}]","2023-01-25"
"2301.09877","Lauritz Van Luijk","Lauritz van Luijk, Reinhard F. Werner, Henrik Wilming","Covariant catalysis requires correlations and good quantum reference
  frames degrade little","9+1 pages; Comments welcome; v2: Added reference to previous work
  related to our second main result",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Catalysts are quantum systems that open up dynamical pathways between quantum
states which are otherwise inaccessible under a given set of operational
restrictions while, at the same time, they do not change their quantum state.
We here consider the restrictions imposed by symmetries and conservation laws,
where any quantum channel has to be covariant with respect to the unitary
representation of a symmetry group, and present two results. First, for an
exact catalyst to be useful, it has to build up correlations to either the
system of interest or the degrees of freedom dilating the given process to
covariant unitary dynamics. This explains why catalysts in pure states are
useless. Second, if a quantum system (""reference frame"") is used to simulate to
high precision unitary dynamics (which possibly violates the conservation law)
on another system via a global, covariant quantum channel, then this channel
can be chosen so that the reference frame is approximately catalytic. In other
words, a reference frame that simulates unitary dynamics to high precision
degrades only very little.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:31:55 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 15:21:55 GMT""}]","2023-02-07"
"2301.09878","Mathias Zinnen","Mathias Zinnen, Prathmesh Madhu, Ronak Kosti, Peter Bell, Andreas
  Maier, Vincent Christlein","ODOR: The ICPR2022 ODeuropa Challenge on Olfactory Object Recognition","6 pages, 6 figures","2022 26th International Conference on Pattern Recognition (ICPR),
  Montreal, QC, Canada, 2022, pp. 4989-4994","10.1109/ICPR56361.2022.9956542",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The Odeuropa Challenge on Olfactory Object Recognition aims to foster the
development of object detection in the visual arts and to promote an olfactory
perspective on digital heritage. Object detection in historical artworks is
particularly challenging due to varying styles and artistic periods. Moreover,
the task is complicated due to the particularity and historical variance of
predefined target objects, which exhibit a large intra-class variance, and the
long tail distribution of the dataset labels, with some objects having only
very few training examples. These challenges should encourage participants to
create innovative approaches using domain adaptation or few-shot learning. We
provide a dataset of 2647 artworks annotated with 20 120 tightly fit bounding
boxes that are split into a training and validation set (public). A test set
containing 1140 artworks and 15 480 annotations is kept private for the
challenge evaluation.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:35:43 GMT""}]","2023-01-25"
"2301.09879","Lin Li","Lin Li, Michael Spratling","Data Augmentation Alone Can Improve Adversarial Training","published at conference ICLR2023",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Adversarial training suffers from the issue of robust overfitting, which
seriously impairs its generalization performance. Data augmentation, which is
effective at preventing overfitting in standard training, has been observed by
many previous works to be ineffective in mitigating overfitting in adversarial
training. This work proves that, contrary to previous findings, data
augmentation alone can significantly boost accuracy and robustness in
adversarial training. We find that the hardness and the diversity of data
augmentation are important factors in combating robust overfitting. In general,
diversity can improve both accuracy and robustness, while hardness can boost
robustness at the cost of accuracy within a certain limit and degrade them both
over that limit. To mitigate robust overfitting, we first propose a new crop
transformation, Cropshift, which has improved diversity compared to the
conventional one (Padcrop). We then propose a new data augmentation scheme,
based on Cropshift, with much improved diversity and well-balanced hardness.
Empirically, our augmentation method achieves the state-of-the-art accuracy and
robustness for data augmentations in adversarial training. Furthermore, when
combined with weight averaging it matches, or even exceeds, the performance of
the best contemporary regularization methods for alleviating robust
overfitting. Code is available at:
https://github.com/TreeLLi/DA-Alone-Improves-AT.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:36:39 GMT""}]","2023-01-25"
"2301.09880","Xiao Zhou","Xiao Zhou, Renjie Pi, Weizhong Zhang, Yong Lin, Tong Zhang","Probabilistic Bilevel Coreset Selection",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of coreset selection in supervised learning is to produce a weighted
subset of data, so that training only on the subset achieves similar
performance as training on the entire dataset. Existing methods achieved
promising results in resource-constrained scenarios such as continual learning
and streaming. However, most of the existing algorithms are limited to
traditional machine learning models. A few algorithms that can handle large
models adopt greedy search approaches due to the difficulty in solving the
discrete subset selection problem, which is computationally costly when coreset
becomes larger and often produces suboptimal results. In this work, for the
first time we propose a continuous probabilistic bilevel formulation of coreset
selection by learning a probablistic weight for each training sample. The
overall objective is posed as a bilevel optimization problem, where 1) the
inner loop samples coresets and train the model to convergence and 2) the outer
loop updates the sample probability progressively according to the model's
performance. Importantly, we develop an efficient solver to the bilevel
optimization problem via unbiased policy gradient without trouble of implicit
differentiation. We provide the convergence property of our training procedure
and demonstrate the superiority of our algorithm against various coreset
selection methods in various tasks, especially in more challenging label-noise
and class-imbalance scenarios.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:37:00 GMT""}]","2023-01-25"
"2301.09881","Andrew Lewis-Pye","Andrew Lewis-Pye, Ittai Abraham","Fever: Optimal Responsive View Synchronisation",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  View synchronisation is an important component of many modern Byzantine Fault
Tolerant State Machine Replication (SMR) systems in the partial synchrony
model. Roughly, the efficiency of view synchronisation is measured as the word
complexity and latency required for moving from being synchronised in a view of
one correct leader to being synchronised in the view of the next correct
leader.
  The efficiency of view synchronisation has emerged as a major bottleneck in
the efficiency of SMR systems as a whole. A key question remained open: Do
there exist view synchronisation protocols with asymptotically optimal
quadratic worst-case word complexity that also obtain linear message complexity
and responsiveness when moving between consecutive correct leaders?
  We answer this question affirmatively with a new view synchronisation
protocol for partial synchrony assuming minimal clock synchronisation, called
\emph{Fever}. If $n$ is the number of processors and $t$ is the largest integer
$<n/3$, then Fever has resilience $t$, and in all executions with at most
$0\leq f\leq t$ Byzantine parties and network delays of at most $\delta \leq
\Delta$ after $GST$ (where $f$ and $\delta$ are unknown), Fever has worst-case
word complexity $O(fn+n)$ and worst-case latency $O(\Delta f + \delta)$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:37:13 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 09:56:53 GMT""}]","2023-05-11"
"2301.09882","Konstantin Maslov","Konstantin Maslov, David Blaschke","Effect of mesonic off-shell correlations in the PNJL equation of state","13 pages, 8 figures",,"10.1103/PhysRevD.107.094010",,"hep-ph nucl-th","http://creativecommons.org/licenses/by/4.0/","  We study the meson contribution to the equation of state of the 2-flavor PNJL
model, including the full momentum dependence of the meson polarization loops.
Within the Beth-Uhlenbeck approach, we demonstrate that the contribution from
the quark-antiquark continuum excitations in the spacelike region $\omega^2 -
q^2 < 0$, i.e. the Landau damping, leads to an increase of the pressure for
temperatures $\gtrsim 0.8\,T_c^\chi$ and a significant meson momentum cut-off
dependence in the mesonic pressure and the QCD trace anomaly. We investigate
the dependence of the results on the choice of the Polyakov-loop potential
parameter $T_0$. From the dependence of the mesonic pressure on the current
quark mass, by means of the Feynman-Hellmann theorem, we evaluate the
contribution of the pion quasiparticle gas and Landau damping to the chiral
condensate.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:40:29 GMT""}]","2023-05-17"
"2301.09883","Harry Schmidt","Gal Binyamini, Gareth O. Jones, Harry Schmidt, Margaret E.M. Thomas","An effective Pila-Wilkie theorem for sets definable using Pfaffian
  functions, with some diophantine applications","Comments welcome!",,,,"math.NT math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove an effective version of the Pila-Wilkie Theorem for sets definable
using Pfaffian functions, providing effective estimates for the number of
algebraic points of bounded height and degree lying on such sets. We also prove
effective versions of extensions of this result due to Pila and Habegger-Pila .
In order to prove these counting results, we obtain an effective version of
Yomdin-Gromov parameterization for sets defined using restricted Pfaffian
functions. Furthermore, for sets defined in the restricted setting, as well as
for unrestricted sub-Pfaffian sets, our effective estimates depend polynomially
on the degree (one measure of complexity) of the given set. The level of
uniformity present in all the estimates allows us to obtain several diophantine
applications. These include an effective and uniform version of the
Manin-Mumford conjecture for products of elliptic curves with complex
multiplication, and an effective, uniform version of a result due to Habegger
which characterizes the set of special points lying on an algebraic variety
contained in a fibre power of an elliptic surface. We also show that if
Andr\'e-Oort for $Y(2)^g$ can be made effective, then Andr\'e-Oort for a family
of elliptic curves over $Y(2)^g$ can be made effective.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:40:48 GMT""}]","2023-01-25"
"2301.09884","Shruti Aggarwal","Shruti Aggarwal, Anu Kumari, Satyabrata Adhikari","Physical realization of realignment criteria using structural physical
  approximation","10 pages, 5 figures, 1 table, Appendix",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entanglement detection is an important problem in quantum information theory
because quantum entanglement is a key resource in quantum information
processing. Realignment criteria is a powerful tool for detection of entangled
states in bipartite and multipartite quantum system. It is an important
criteria for entanglement detection because it works well; not only for
negative partial transpose entangled states (NPTES) but also for positive
partial transpose entangled states (PPTES). Since the matrix corresponding to
realignment map is indefinite so the experimental implementation of the map is
an obscure task. In this work, firstly, we have approximated the realignment
map to a positive map using the method of structural physical approximation
(SPA) and then we have shown that the structural physical approximation of
realignment map (SPA-R) is completely positive. Positivity of the constructed
map is characterized using moments which can be physically measured. Next, we
develop a separability criterion based on our SPA-R map in the form of an
inequality and have shown that the developed criterion not only detect NPTES
but also PPTES. We have provided some examples to support the results obtained.
Moreover, we have analysed the error that may occur because of approximating
the realignment map.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:41:33 GMT""}]","2023-01-25"
"2301.09885","Rachael Martina Marshal","Rachael M. Marshal, Ottaviano Ruesch, Christian Woehler, Kay
  Wohlfarth, Sergey Velichko","Photometry of LROC NAC resolved rock-rich regions on the Moon",,"Icarus (April 2023) Volume:394","10.1016/j.icarus.2022.115419",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The study of meter and sub-meter scale geological features, especially
boulders and boulder fields, on the surface of airless bodies can provide
insight into the evolution of the regolith and the contribution of various
processes to its formation. Prior studies have examined the photometric
properties of the lunar regolith surrounding young craters using image ratios.
We extend this methodology to extracting surface properties, in particular the
roughness characteristics, exclusive to boulder fields and the boulders that
constitute them around impact craters. In this study, rock-rich regions on the
Moon are investigated using photometric roughness by employing a normalised
logarithmic phase ratio difference metric to measure and compare the slope of
the phase curve (reflectance versus phase angle) of a rock-rich field to a
rock-free field. We compare the photometric roughness of rock-rich fields on
simulated images with the photometric roughness of rock-rich fields on LROC NAC
images (0.5m/pixel). Using this technique, we determine that rock-rich surfaces
are not necessarily photometrically rougher than rock-free areas. Additionally,
we find the roughness of resolved rock fields to indicate the presence of
diverse sub-mm scale rock roughness (microtopography) and, possibly, variable
rock single scattering albedo. These latter properties are likely controlled by
rock petrology and material response to weathering and erosion. Spatial
clustering of photometrically smooth and rough boulder fields in the downrange
and uprange of two craters is observed, reflecting ejecta asymmetry and
possibly indicating asymmetric modification of ejecta rock surfaces during the
impact excavation process.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:44:17 GMT""}]","2023-01-25"
"2301.09886","Pedro Fortuny Ayuso","L. Bay\'on, P. Fortuny Ayuso, J.M. Grau, M.M Ruiz","Entry and leaving arcs of turnpikes: their exact computation in the
  calculus of variations","15 pages, 8 figures",,,,"math.OC math.DS","http://creativecommons.org/licenses/by/4.0/","  We settle the question of how to compute the entry and leaving arcs for
turnpikes in autonomous variational problems, in the one-dimensional case using
the phase space of the vector field associated to the Euler equation, and the
initial/final and/or the transversality condition. The results hinge on the
realization that extremals are the contours of a well-known function and that
that the transversality condition is (generically) a curve. An approximation
algorithm is presented and an example included for completeness.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:44:39 GMT""}]","2023-01-25"
"2301.09887","Pouya Karimian","Azadeh Fakhrzadeh, Pouya Karimian, Mahsa Meyari, Cris L. Luengo
  Hendriks, Lena Holm, Christian Sonne, Rune Dietz, Ellinor Sp\""orndly-Nees","Deep learning-based method for segmenting epithelial layer of tubules in
  histopathological images of testicular tissue","submitted to Journal of Medical Imaging, 16 pages, 5 figures","J. Med. Imag. 10(3) 037501 (3 May 2023)","10.1117/1.JMI.10.3.037501",,"eess.IV cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is growing concern that male reproduction is affected by environmental
chemicals. One way to determine the adverse effect of environmental pollutants
is to use wild animals as monitors and evaluate testicular toxicity using
histopathology. Automated methods are necessary tools in the quantitative
assessment of histopathology to overcome the subjectivity of manual evaluation
and accelerate the process. We propose an automated method to process histology
images of testicular tissue. Segmenting the epithelial layer of the
seminiferous tubule is a prerequisite for developing automated methods to
detect abnormalities in tissue. We suggest an encoder-decoder fully connected
convolutional neural network (F-CNN) model to segment the epithelial layer of
the seminiferous tubules in histological images. Using ResNet-34 modules in the
encoder adds a shortcut mechanism to avoid the gradient vanishing and
accelerate the network convergence. The squeeze & excitation (SE) attention
block is integrated into the encoding module improving the segmentation and
localization of epithelium. We applied the proposed method for the 2-class
problem where the epithelial layer of the tubule is the target class. The
f-score and IoU of the proposed method are 0.85 and 0.92. Although the proposed
method is trained on a limited training set, it performs well on an independent
dataset and outperforms other state-of-the-art methods. The pretrained
ResNet-34 in the encoder and attention block suggested in the decoder result in
better segmentation and generalization. The proposed method can be applied to
testicular tissue images from any mammalian species and can be used as the
first part of a fully automated testicular tissue processing pipeline. The
dataset and codes are publicly available on GitHub.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:46:47 GMT""}]","2023-05-17"
"2301.09888","Rurie Mizuno","Rurie Mizuno, Megumi Niikura, Tokihiro Ikeda, Teiichiro Matsuzaki,
  Shintaro Go, Takeshi Y. Saito, Shin'ichiro Michimasa, and Hiroyoshi Sakurai","Response of germanium detectors for high-energy $\gamma$-rays by
  $^{27}$Al(p, $\gamma$)$^{28}$Si at Ep=992 keV",,,,,"physics.ins-det nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The performance of germanium detectors for high-energy $\gamma$-rays was
evaluated using a 992-keV resonance in the $^{27}$Al(p, $\gamma$)$^{27}$Si
reaction. The measurement was conducted at the RIKEN tandem accelerator. The
energy of the excited state from the resonance was evaluated as 12540.7(2) keV.
Using newly evaluated excitation energy, an energy calibration function and the
photo-peak efficiency of Ge detectors up to 10.8-MeV photon were deduced. The
energy accuracy is achieved at 0.3 keV for the overall energy region. This
reaction provides reliable energy and efficiency standards for high-energy
$\gamma$ rays.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:50:12 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 01:47:20 GMT""}]","2023-04-26"
"2301.09889","Luca Guastoni","L. Guastoni, J. Rabault, P. Schlatter, H. Azizpour, R. Vinuesa","Deep reinforcement learning for turbulent drag reduction in channel
  flows","19 pages, 4 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a reinforcement learning (RL) environment to design and
benchmark control strategies aimed at reducing drag in turbulent fluid flows
enclosed in a channel. The environment provides a framework for
computationally-efficient, parallelized, high-fidelity fluid simulations, ready
to interface with established RL agent programming interfaces. This allows for
both testing existing deep reinforcement learning (DRL) algorithms against a
challenging task, and advancing our knowledge of a complex, turbulent physical
system that has been a major topic of research for over two centuries, and
remains, even today, the subject of many unanswered questions. The control is
applied in the form of blowing and suction at the wall, while the observable
state is configurable, allowing to choose different variables such as velocity
and pressure, in different locations of the domain. Given the complex nonlinear
nature of turbulent flows, the control strategies proposed so far in the
literature are physically grounded, but too simple. DRL, by contrast, enables
leveraging the high-dimensional data that can be sampled from flow simulations
to design advanced control strategies. In an effort to establish a benchmark
for testing data-driven control strategies, we compare opposition control, a
state-of-the-art turbulence-control strategy from the literature, and a
commonly-used DRL algorithm, deep deterministic policy gradient. Our results
show that DRL leads to 43% and 46% drag reduction in a minimal and a larger
channel (at a friction Reynolds number of 180), respectively, outperforming the
classical opposition control by around 20 percentage points.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:54:44 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 11:43:15 GMT""},{""version"":""v3"",""created"":""Wed, 8 Feb 2023 13:01:35 GMT""}]","2023-02-09"
"2301.09890","Mark van de Wiel","Mark A. van de Wiel, Gwena\""el G.R. Leday, Jeroen Hoogland, Martijn W.
  Heymans, Erik W. van Zwet, Ailko H. Zwinderman","Think before you shrink: Alternatives to default shrinkage methods can
  improve prediction accuracy, calibration and coverage","35 pages including Supplementary Information",,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by/4.0/","  While shrinkage is essential in high-dimensional settings, its use for
low-dimensional regression-based prediction has been debated. It reduces
variance, often leading to improved prediction accuracy. However, it also
inevitably introduces bias, which may harm two other measures of predictive
performance: calibration and coverage of confidence intervals. Much of the
criticism stems from the usage of standard shrinkage methods, such as lasso and
ridge with a single, cross-validated penalty. Our aim is to show that readily
available alternatives can strongly improve predictive performance, in terms of
accuracy, calibration or coverage. For linear regression, we use small sample
splits of a large, fairly typical epidemiological data set to illustrate this.
We show that usage of differential ridge penalties for covariate groups may
enhance prediction accuracy, while calibration and coverage benefit from
additional shrinkage of the penalties. In the logistic setting, we apply an
external simulation to demonstrate that local shrinkage improves calibration
with respect to global shrinkage, while providing better prediction accuracy
than other solutions, like Firth's correction. The benefits of the alternative
shrinkage methods are easily accessible via example implementations using
\texttt{mgcv} and \texttt{r-stan}, including the estimation of multiple
penalties. A synthetic copy of the large data set is shared for
reproducibility.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:54:52 GMT""}]","2023-01-25"
"2301.09891","Tiangang Cui","Yiran Zhao and Tiangang Cui","Tensor-train methods for sequential state and parameter learning in
  state-space models",,,,,"math.NA cs.NA math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider sequential state and parameter learning in state-space models
with intractable state transition and observation processes. By exploiting
low-rank tensor-train (TT) decompositions, we propose new sequential learning
methods for joint parameter and state estimation under the Bayesian framework.
Our key innovation is the introduction of scalable function approximation tools
such as TT for recursively learning the sequentially updated posterior
distributions. The function approximation perspective of our methods offers
tractable error analysis and potentially alleviates the particle degeneracy
faced by many particle-based methods. In addition to the new insights into
algorithmic design, our methods complement conventional particle-based methods.
Our TT-based approximations naturally define conditional Knothe--Rosenblatt
(KR) rearrangements that lead to filtering, smoothing and path estimation
accompanying our sequential learning algorithms, which open the door to
removing potential approximation bias. We also explore several preconditioning
techniques based on either linear or nonlinear KR rearrangements to enhance the
approximation power of TT for practical problems. We demonstrate the efficacy
and efficiency of our proposed methods on several state-space models, in which
our methods achieve state-of-the-art estimation accuracy and computational
performance.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:55:13 GMT""},{""version"":""v2"",""created"":""Fri, 28 Apr 2023 05:04:03 GMT""}]","2023-05-01"
"2301.09892","Praveen Paruchuri","Vignesh Viswanathan, Megha Bose and Praveen Paruchuri","Learning Effective Strategies for Moving Target Defense with Switching
  Costs",,,,,"cs.GT cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Moving Target Defense (MTD) has emerged as a key technique in various
security applications as it takes away the attacker's ability to perform
reconnaissance for exploiting a system's vulnerabilities. However, most of the
existing research in the field assumes unrealistic access to information about
the attacker's motivations and/or actions when developing MTD strategies. Many
of the existing approaches also assume complete knowledge regarding the
vulnerabilities of a system and how each of these vulnerabilities can be
exploited by an attacker. In this work, we aim to create algorithms that
generate effective Moving Target Defense strategies that do not rely on prior
knowledge about the attackers. Our work assumes that the only way the defender
receives information about its own reward is via interaction with the attacker
in a repeated game setting. Depending on the amount of information that can be
obtained from the interactions, we devise two different algorithms using
multi-armed bandit formulation to identify efficient strategies. We then
evaluate our algorithms using data mined from the National Vulnerability
Database to showcase that they match the performance of the state-of-the-art
techniques, despite using a lot less amount of information.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 09:57:24 GMT""}]","2023-01-25"
"2301.09893","Xun Qian","Xun Qian, Hanze Dong, Tong Zhang, Peter Richt\'arik","Catalyst Acceleration of Error Compensated Methods Leads to Better
  Communication Complexity","42 pages, 21 figures",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Communication overhead is well known to be a key bottleneck in large scale
distributed learning, and a particularly successful class of methods which help
to overcome this bottleneck is based on the idea of communication compression.
Some of the most practically effective gradient compressors, such as TopK, are
biased, which causes convergence issues unless one employs a well designed {\em
error compensation/feedback} mechanism. Error compensation is therefore a
fundamental technique in the distributed learning literature. In a recent
development, Qian et al (NeurIPS 2021) showed that the error-compensation
mechanism can be combined with acceleration/momentum, which is another key and
highly successful optimization technique. In particular, they developed the
error-compensated loop-less Katyusha (ECLK) method, and proved an accelerated
linear rate in the strongly convex case. However, the dependence of their rate
on the compressor parameter does not match the best dependence obtainable in
the non-accelerated error-compensated methods. Our work addresses this problem.
We propose several new accelerated error-compensated methods using the {\em
catalyst acceleration} technique, and obtain results that match the best
dependence on the compressor parameter in non-accelerated error-compensated
methods up to logarithmic terms.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:01:53 GMT""}]","2023-01-25"
"2301.09894","Alea Schr\""oder","Alea Schr\""oder, Maik R\""oper, Dirk W\""ubben, Bho Matthiesen, Petar
  Popovski, Armin Dekorsy","A Comparison between RSMA, SDMA, and OMA in Multibeam LEO Satellite
  Systems","This article is presented in part at the 2023 International ITG 26th
  Workshop on Smart Antennas and 13th Conference on Systems, Communications,
  and Coding",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low Earth orbit (LEO) satellite systems enable close to global coverage and
are therefore expected to become important pillars of future communication
standards. However, a particular challenge faced by LEO satellites is the high
orbital velocities due to which a precise channel estimation is difficult. We
model this influence as an erroneous angle of departure (AoD), which
corresponds to imperfect channel state information (CSI) at the transmitter
(CSIT). Poor CSIT and non-orthogonal user channels degrade the performance of
space-division multiple access (SDMA) precoding by increasing inter-user
interference (IUI). In contrast to SDMA, there is no IUI in orthogonal multiple
access (OMA), but it requires orthogonal time or frequency resources for each
user. Rate-splitting multiple access (RSMA), unifying SDMA, OMA, and
non-orthogonal multiple access (NOMA), has recently been proven to be a
flexible approach for robust interference management considering imperfect
CSIT. In this paper, we investigate RSMA as a promising strategy to manage IUI
in LEO satellite downlink systems caused by non-orthogonal user channels as
well as imperfect CSIT. We evaluate the optimal configuration of RSMA depending
on the geometrical constellation between the satellite and users.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:03:42 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 13:12:22 GMT""}]","2023-01-30"
"2301.09895","Brahim Lemkalli","Brahim Lemkalli, Muamer Kadic, Youssef El Badri, S\'ebastien Guenneau,
  Abdellah Mir, Younes Achaoui","The emergence of low-frequency dual Fano resonances in chiral twisting
  metamaterials","7 pages, 5 figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In the current work, through a finite element analysis, we demonstrate that a
configuration of chiral cells having syndiotactic symmetry provides dual Fano
resonances at low frequency. From the phononic dispersion and transmission
response, we compare the signature provided by a composite made of chiral cells
to the ones of homogeneous medium, isotactic nonchiral, and isotactic chiral
beams. The study results in an innovative design of a mechanical metamaterial
that induces the Fano resonance at low frequency with a relatively high quality
factor. This might be a significant step forward for mechanical wave filtering
and detection. Performances have been evaluated using a sensor that will be
implemented as a thermometer.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:11:47 GMT""}]","2023-01-25"
"2301.09896","Ai Matsushita","Lord Christian Carl H. Regacho, Ai Matsushita, Angie M. Ceniza-Canillo","Automated Identification of Disaster News For Crisis Management Using
  Machine Learning",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A lot of news sources picked up on Typhoon Rai (also known locally as Typhoon
Odette), along with fake news outlets. The study honed in on the issue, to
create a model that can identify between legitimate and illegitimate news
articles. With this in mind, we chose the following machine learning algorithms
in our development: Logistic Regression, Random Forest and Multinomial Naive
Bayes. Bag of Words, TF-IDF and Lemmatization were implemented in the Model.
Gathering 160 datasets from legitimate and illegitimate sources, the machine
learning was trained and tested. By combining all the machine learning
techniques, the Combined BOW model was able to reach an accuracy of 91.07%,
precision of 88.33%, recall of 94.64%, and F1 score of 91.38% and Combined
TF-IDF model was able to reach an accuracy of 91.18%, precision of 86.89%,
recall of 94.64%, and F1 score of 90.60%.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:13:00 GMT""}]","2023-01-25"
"2301.09897","Wei Wang","Tianyi Pan, Wei Wang, Jianliang Zhai, Tusheng Zhang","Stochastic heat equations on moving domains",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we establish the well-posedness of stochastic heat equations
on moving domains, which amounts to a study of infinite dimensional interacting
systems. The main difficulty is to deal with the problems caused by the
time-varying state spaces and the interaction of the particle systems. The
interaction still occurs even in the case of additive noise. This is in
contrast to stochastic heat equations in a fixed domain.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:14:23 GMT""}]","2023-01-25"
"2301.09898","Kohei Hayashi","Patr\'icia Gon\c{c}alves, Kohei Hayashi","Derivation of anomalous behavior from interacting oscillators in the
  high-temperature regime","43 pages",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A microscopic model of interacting oscillators, which admits two conserved
quantities, volume, and energy, is investigated. We begin with a system driven
by a general nonlinear potential under high-temperature regime by taking the
inverse temperature of the system asymptotically small. As a consequence, one
can extract a principal part (by a simple Taylor expansion argument), which is
driven by the harmonic potential, and we show that previous results for the
harmonic chain are covered with generality. We consider two fluctuation fields,
which are defined as a linear combination of the two conserved quantities,
volume, and energy, and we show that the fluctuations of one field converge to
a solution of an additive stochastic heat equation, which corresponds to the
Ornstein-Uhlenbeck process, in a weak asymmetric regime, or to a solution of
the stochastic Burgers equation, in a stronger asymmetric regime. On the other
hand, the fluctuations of the other field cross from an additive stochastic
heat equation to a fractional diffusion equation given by a skewed L\'{e}vy
process.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:14:51 GMT""}]","2023-01-25"
"2301.09899","Karla Stepanova","Petr Vanc, Jan Kristof Behrens, Karla Stepanova","Context-aware robot control using gesture episodes","7 pages, 8 figures, accepted for ICRA 2023",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Collaborative robots became a popular tool for increasing productivity in
partly automated manufacturing plants. Intuitive robot teaching methods are
required to quickly and flexibly adapt the robot programs to new tasks.
Gestures have an essential role in human communication. However, in
human-robot-interaction scenarios, gesture-based user interfaces are so far
used rarely, and if they employ a one-to-one mapping of gestures to robot
control variables. In this paper, we propose a method that infers the user's
intent based on gesture episodes, the context of the situation, and common
sense. The approach is evaluated in a simulated table-top manipulation setting.
We conduct deterministic experiments with simulated users and show that the
system can even handle personal preferences of each user.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:15:23 GMT""}]","2023-01-25"
"2301.09900","Kannabiran Seshasayanan","Kannabiran Seshasayanan","Spatial extreme values of vorticity and velocity gradients in
  two-dimensional turbulent flows",,,,,"physics.flu-dyn cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the distribution of spatial extrema of vorticity and the determinant
of the strain rate tensor for a two-dimensional turbulent flow forced by a
Kolmogorov forcing. The distribution of these quantities follow non-Gaussian
behaviour and they do not fall into the Generalised Extreme value
distributions. It is found that for the truncated Euler equations the spatial
extrema of vorticity and strain rate tensor are well described by the Gumbel
distribution. The spatial extrema for the vorticity is found to be at the core
of the vortices while the velocity gradients are found near the edges of the
vortices or at the shear layers in the regions between the vortices. Temporal
correlations of the velocity gradients shed light on the extreme value
distributions obtained for turbulence and the truncated Euler equations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:17:51 GMT""}]","2023-01-25"
"2301.09901","Kohki Uno","Kohki Uno, Keiichi Maeda, Takashi Nagao, Tatsuya Nakaoka, Kentaro
  Motohara, Akito Tajitsu, Masahito Konishi, Shuhei Koyama, Hidenori Takahashi,
  Masaomi Tanaka, Hanindyo Kuncarayakti, Miho Kawabata, Masayuki Yamanaka,
  Kentaro Aoki, Keisuke Isogai, Kenta Taguchi, Mao Ogawa, Koji S. Kawabata,
  Yuzuru Yoshii, Takashi Miyata, and Ryo Imazawa","SN 2020uem: A Possible Thermonuclear Explosion within A Dense
  Circumstellar Medium (I) The Nature of Type IIn/Ia-CSM SNe from Photometry
  and Spectroscopy","22 pages, 15 figures, 3 tables. Accepted for publication in ApJ",,"10.3847/1538-4357/acb5ec",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have performed intensive follow-up observations of a Type IIn/Ia-CSM SN
(SN IIn/Ia-CSM), 2020uem, with photometry, spectroscopy, and polarimetry. In
this paper, we report on the results of our observations focusing on
optical/near-infrared (NIR) photometry and spectroscopy. The maximum V-band
magnitude of SN 2020uem is over $-19.5$ mag. The light curves decline slowly
with a rate of $\sim 0.75 {\rm ~mag}/100 {\rm ~days}$. In the late phase
($\gtrsim 300$ days), the light curves show accelerated decay ($\sim 1.2 {\rm
~mag}/100 {\rm ~days}$). The optical spectra show prominent hydrogen emission
lines and broad features possibly associated with Fe-peak elements. In
addition, the $\rm H\alpha$ profile exhibits a narrow P-Cygni profile with the
absorption minimum of $\sim 100 {\rm ~km~s^{-1}}$. SN 2020uem shows a higher
$\rm H\alpha/H\beta$ ratio ($\sim 7$) than those of SNe IIn, which suggests a
denser CSM. The NIR spectrum shows the Paschen and Brackett series with
continuum excess in the H and Ks bands. We conclude that the NIR excess
emission originates from newly-formed carbon dust. The dust mass ($M_{\rm d}$)
and temperature ($T_{\rm d}$) are derived to be $(M_{\rm d}, T_{\rm d}) \sim
(4-7 \times 10^{-5} {\rm ~M_{\odot}}, 1500-1600 {\rm ~K})$. We discuss the
differences and similarities between the observational properties of SNe
IIn/Ia-CSM and those of other SNe Ia and interacting SNe. In particular,
spectral features around $\sim 4650$ {\text \AA} and $\sim 5900$ {\text \AA} of
SNe IIn/Ia-CSM are more suppressed than those of SNe Ia; these lines are
possibly contributed, at least partly, by \ion{Mg}{1}] and \ion{Na}{1}, and may
be suppressed by high ionization behind the reverse shock caused by the massive
CSM.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:18:48 GMT""}]","2023-03-08"
"2301.09902","Luke Haliburton","Luke Haliburton and Sinksar Ghebremedhin and Robin Welsch and Albrecht
  Schmidt and Sven Mayer","Investigating Labeler Bias in Face Annotation for Machine Learning","Pre-print currently under review",,,,"cs.LG cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In a world increasingly reliant on artificial intelligence, it is more
important than ever to consider the ethical implications of artificial
intelligence on humanity. One key under-explored challenge is labeler bias,
which can create inherently biased datasets for training and subsequently lead
to inaccurate or unfair decisions in healthcare, employment, education, and law
enforcement. Hence, we conducted a study to investigate and measure the
existence of labeler bias using images of people from different ethnicities and
sexes in a labeling task. Our results show that participants possess
stereotypes that influence their decision-making process and that labeler
demographics impact assigned labels. We also discuss how labeler bias
influences datasets and, subsequently, the models trained on them. Overall, a
high degree of transparency must be maintained throughout the entire artificial
intelligence training process to identify and correct biases in the data as
early as possible.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:19:24 GMT""}]","2023-01-25"
"2301.09903","Ken-Ichi Uchida","Weinan Zhou, Asuka Miura, Takamasa Hirai, Yuya Sakuraba, Ken-ichi
  Uchida","Seebeck-driven transverse thermoelectric generation in magnetic hybrid
  bulk materials","12 pages, 4 figures, 1 table","Applied Physics Letters 122, 062402 (2023)","10.1063/5.0126870",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Seebeck-driven transverse thermoelectric generation in
magnetic/thermoelectric hybrid materials (STTG) has been investigated in
all-bulk hybrid materials. The transverse thermopower in a ferromagnetic
Co$_2$MnGa/thermoelectric $n$-type Si hybrid bulk material with the adjusted
dimensions reaches 16.0 $\mu$V/K at room temperature with the aid of the STTG
contribution, which is much larger than the anomalous Nernst coefficient of the
Co$_2$MnGa slab (6.8 $\mu$V/K). Although this transverse thermopower is smaller
than the value for previously reported thin-film-based hybrid materials, the
hybrid bulk materials exhibit much larger electrical power owing to their small
internal resistance. This demonstration confirms the validity of STTG in bulk
materials and clarifies its potential as a thermal energy harvester.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:21:55 GMT""}]","2023-02-09"
"2301.09904","Yo\`av Montacute","David Fern\'andez-Duque and Yo\`av Montacute","Dynamic Tangled Derivative Logic of Metric Spaces","arXiv admin note: text overlap with arXiv:2107.10349",,,,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamical systems are abstract models of interaction between space and time.
They are often used in fields such as physics and engineering to understand
complex processes, but due to their general nature, they have found
applications for studying computational processes, interaction in multi-agent
systems, machine learning algorithms and other computer science related
phenomena. In the vast majority of applications, a dynamical system consists of
the action of a continuous 'transition function' on a metric space. In this
work, we consider decidable formal systems for reasoning about such structures.
Spatial logics can be traced back to the 1940's, but our work follows a more
dynamic turn that these logics have taken due to two recent developments: the
study of the topological mu-calculus, and the the integration of linear
temporal logic with logics based on the Cantor derivative. In this paper, we
combine dynamic topological logics based on the Cantor derivative and the 'next
point in time' operators with an expressively complete fixed point operator to
produce a combination of the topological mu-calculus with linear temporal
logic. We show that the resulting logics are decidable and have a natural
axiomatisation. Moreover, we prove that these logics are complete for
interpretations on the Cantor space, the rational numbers, and subspaces
thereof.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:24:36 GMT""}]","2023-06-01"
"2301.09905","Paolo Crivelli","P. Crivelli","Status and prospects of the NA64 experiment at the CERN SPS","5 pages, 4 figures, prepared for the proceedings of the FIPs 2022
  workshop, v2 some typos fixed",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  NA64 is a fixed target experiment at the CERN SPS designed as a hermetic
general purpose detector to search for Dark Sector physics in missing energy
events from electron/positron, hadrons, and muon scattering off nuclei. In this
contribution to the FIPs 2022 workshop, we review the current status and
prospects of NA64.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:25:05 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 16:16:47 GMT""}]","2023-01-26"
"2301.09906","Mathias Zinnen","Mathias Zinnen, Prathmesh Madhu, Peter Bell, Andreas Maier, and
  Vincent Christlein","Transfer Learning for Olfactory Object Detection","6 pages, 4 figures","2022 Digital Humanities Conference, Tokyo, Japan, 2022, pp.409-413",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We investigate the effect of style and category similarity in multiple
datasets used for object detection pretraining. We find that including an
additional stage of object-detection pretraining can increase the detection
performance considerably. While our experiments suggest that style similarities
between pre-training and target datasets are less important than matching
categories, further experiments are needed to verify this hypothesis.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:31:43 GMT""}]","2023-01-25"
"2301.09907","Vladimir Matveev","T. Ma, K. J. Flood, V. S. Matveev, V. \v{Z}\'adn\'ik","Canonical curves and Kropina metrics in Lagrangian contact geometry","24 pages, no figures",,,,"math.DG math.AP math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a Fefferman-type construction from Lagrangian contact to conformal
structures and examine several related topics. In particular, we concentrate on
describing the canonical curves and their correspondence. We show that chains
and null-chains of an integrable Lagrangian contact structure are the
projections of null-geodesics of the Fefferman space. Employing the Fermat
principle, we realize chains as geodesics of Kropina (pseudo-Finsler) metrics.
Using recent rigidity results, we show that ``sufficiently many'' chains
determine the Lagrangian contact structure. Separately, we comment on
Lagrangian contact structures induced by projective structures and the special
case of dimension three.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:34:04 GMT""}]","2023-01-25"
"2301.09908","Mareike Hartmann","Siting Liang and Mareike Hartmann and Daniel Sonntag","Cross-lingual German Biomedical Information Extraction: from Zero-shot
  to Human-in-the-Loop",,,,,"cs.HC cs.CL","http://creativecommons.org/licenses/by/4.0/","  This paper presents our project proposal for extracting biomedical
information from German clinical narratives with limited amounts of
annotations. We first describe the applied strategies in transfer learning and
active learning for solving our problem. After that, we discuss the design of
the user interface for both supplying model inspection and obtaining user
annotations in the interactive environment.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:35:28 GMT""}]","2023-01-25"
"2301.09909","Kecheng Zhang","Kecheng Zhang, Weijie Yuan, Shuangyang Li, Fan Liu, Feifei Gao,
  Pingzhi Fan, Yunlong Cai","Radar Sensing via OTFS Signaling: A Delay Doppler Signal Processing
  Perspective","ICC-2023 Accepted",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  The recently proposed orthogonal time frequency space (OTFS) modulation
multiplexes data symbols in the delay-Doppler (DD) domain. Since the range and
velocity, which can be derived from the delay and Doppler shifts, are the
parameters of interest for radar sensing, it is natural to consider
implementing DD signal processing for radar sensing. In this paper, we
investigate the potential connections between the OTFS and DD domain radar
signal processing. Our analysis shows that the range-Doppler matrix computing
process in radar sensing is exactly the demodulation of OTFS with a rectangular
pulse shaping filter. Furthermore, we propose a two-dimensional (2D)
correlation-based algorithm to estimate the fractional delay and Doppler
parameters for radar sensing. Simulation results show that the proposed
algorithm can efficiently obtain the delay and Doppler shifts associated with
multiple targets.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:40:09 GMT""}]","2023-01-25"
"2301.09910","Lyuben Lichev","Lyuben Lichev","Color-avoiding percolation of random graphs: between the subcritical and
  the intermediate regime","8 pages. arXiv admin note: text overlap with arXiv:2211.16086",,,,"math.PR math.CO","http://creativecommons.org/licenses/by/4.0/","  Fix a graph $G$ in which every edge is colored in some of $k\ge 2$ colors.
Two vertices $u$ and $v$ are CA-connected if $u$ and $v$ may be connected using
any subset of $k - 1$ colors. CA-connectivity is an equivalence relation
dividing the vertex set into classes called CA-components.
  In two recent papers, R\'ath, Varga, Fekete, and Molontay, and Lichev and
Schapira studied the size of the largest CA-component in a randomly colored
random graph. The second of these works distinguished and studied three regimes
(supercritical, intermediate, and subcritical) in which the largest
CA-component has respectively linear, logarithmic, and bounded size. In this
short note, we describe the phase transition between the intermediate and the
subcritical regime.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:44:57 GMT""}]","2023-01-25"
"2301.09911","Milad Alshomary","Milad Alshomary and Henning Wachsmuth","Conclusion-based Counter-Argument Generation","8 pages, 1 figure, conference paper, eacl-23",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In real-world debates, the most common way to counter an argument is to
reason against its main point, that is, its conclusion. Existing work on the
automatic generation of natural language counter-arguments does not address the
relation to the conclusion, possibly because many arguments leave their
conclusion implicit. In this paper, we hypothesize that the key to effective
counter-argument generation is to explicitly model the argument's conclusion
and to ensure that the stance of the generated counter is opposite to that
conclusion. In particular, we propose a multitask approach that jointly learns
to generate both the conclusion and the counter of an input argument. The
approach employs a stance-based ranking component that selects the counter from
a diverse set of generated candidates whose stance best opposes the generated
conclusion. In both automatic and manual evaluation, we provide evidence that
our approach generates more relevant and stance-adhering counters than strong
baselines.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:49:01 GMT""}]","2023-01-25"
"2301.09912","Diptesh Kanojia","Diptesh Kanojia, Aditya Joshi","Applications and Challenges of Sentiment Analysis in Real-life Scenarios","Book Chapter (3rd Chapter in ""Computational Intelligence Applications
  for Text and Sentiment Data Analysis"" published by Elsevier)",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Sentiment analysis has benefited from the availability of lexicons and
benchmark datasets created over decades of research. However, its applications
to the real world are a driving force for research in SA. This chapter
describes some of these applications and related challenges in real-life
scenarios. In this chapter, we focus on five applications of SA: health, social
policy, e-commerce, digital humanities and other areas of NLP. This chapter is
intended to equip an NLP researcher with the `what', `why' and `how' of
applications of SA: what is the application about, why it is important and
challenging and how current research in SA deals with the application. We note
that, while the use of deep learning techniques is a popular paradigm that
spans these applications, challenges around privacy and selection bias of
datasets is a recurring theme across several applications.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:49:21 GMT""}]","2023-01-25"
"2301.09913","Yifan Jiang","Kai Du, Yifan Jiang, Xiaochen Li","Sequential propagation of chaos","25 pages, 6 figures",,,,"math.PR cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new class of particle systems with sequential interaction is proposed to
approximate the McKean-Vlasov process that originally arises as the limit of
the mean-field interacting particle system. The weighted empirical measure of
this particle system is proved to converge to the law of the McKean-Vlasov
process as the system grows. Based on the Wasserstein metric, quantitative
propagation of chaos results are obtained for two cases: the finite time
estimates under the monotonicity condition and the uniform in time estimates
under the dissipation and the non-degenerate conditions. Numerical experiments
are implemented to demonstrate the theoretical results.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:49:25 GMT""}]","2023-01-25"
"2301.09914","Zdravko Marinov","Verena Jasmin Hallitschke, Tobias Schlumberger, Philipp Kataliakos,
  Zdravko Marinov, Moon Kim, Lars Heiliger, Constantin Seibold, Jens Kleesiek,
  Rainer Stiefelhagen","Multimodal Interactive Lung Lesion Segmentation: A Framework for
  Annotating PET/CT Images based on Physiological and Anatomical Cues","Accepted at ISBI 2023; 5 pages, 5 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Recently, deep learning enabled the accurate segmentation of various diseases
in medical imaging. These performances, however, typically demand large amounts
of manual voxel annotations. This tedious process for volumetric data becomes
more complex when not all required information is available in a single imaging
domain as is the case for PET/CT data. We propose a multimodal interactive
segmentation framework that mitigates these issues by combining anatomical and
physiological cues from PET/CT data. Our framework utilizes the geodesic
distance transform to represent the user annotations and we implement a novel
ellipsoid-based user simulation scheme during training. We further propose two
annotation interfaces and conduct a user study to estimate their usability. We
evaluated our model on the in-domain validation dataset and an unseen PET/CT
dataset. We make our code publicly available:
https://github.com/verena-hallitschke/pet-ct-annotate.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:50:45 GMT""}]","2023-01-25"
"2301.09915","Giuseppe Sottile","G. Sottile (1), P. Sangiorgi (1), C. Gargano (1), F. Lo Gerfo (1), M.
  Corpora (1), O. Catalano (1), D. Impiombato (1), D. Mollica (1), M. Capalbi
  (1), T. Mineo (1), G. Contino (1), B. Biondo (1), F. Russo (1), M. C.
  Maccarone (1), G. La Rosa (1), S. Giarrusso (1), G. Leto (2), A. Grillo (2),
  G. Bonanno (2), G. Romeo (2), S. Garozzo (2), D. Marano (2), V. Conforti (3),
  F. Gianotti (3), S. Scuderi (4), G. Pareschi (5), G. Tosti (6), A. Abba (7),
  A. Cusimano (7), F. Caponio (7), C. Tintori (8), M. Lippi (8), F. Vivaldi
  (8), G. Marchiori (9), M. Spinola (9), A. Colovini (9), F. Perez (10), S.
  Ahmad (10), J. B. Cizel (10), J. Fluery (10) (for the ASTRI project, (1) INAF
  IASF Palermo, Italy, (2) INAF OACT Catania, Italy, (3) INAF OAS Bologna,
  Italy, (4) INAF IASF Milano, Italy, (5) INAF OA Brera Milano, Italy, (6)
  Universit\`a degli Studi di Perugia, Italy, (7) Nuclear Instruments -
  Lambrugo, Italy, (8) CAEN, Viareggio, Italy, (9) EIE Group s.r.l., Venezia,
  Italy, (10) Weeroc, Villebone sur Yvette, France)","The ASTRI Cherenkov Camera: from the prototype to the industrial version
  for the Mini-Array","10 pages, 7 figures, 2022 IEEE Nuclear Science Symposium (NSS),
  Medical Imaging Conference (MIC) and Room Temperature Semiconductor Detector
  (RTSD) Conference in press by IEEE Xplore",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The observation of energetic astronomical sources emitting very high-energy
gamma-rays in the TeV spectral range (as e.g. supernova remnants or blazars) is
mainly based on detecting the Cherenkov light induced by relativistic particles
in the showers produced by the photon interaction with the Earth atmosphere.
The ASTRI Mini-Array is an INAF-led project aimed observing such celestial
objects in the 1 - 100 TeV energy range. It consists of an array of nine
innovative imaging atmospheric Cherenkov telescopes that are an evolution of
the dual-mirror aplanatic ASTRI-Horn telescope operating at the INAF ""M.C.
Fracastoro"" observing station (Serra La Nave, Mount Etna, Italy). The ASTRI
Mini-Array is currently under construction at the Observatorio del Teide
(Tenerife, Spain). In this paper, we present the compact (diameter 660mm,
height 520mm, weight 73kg) ASTRI-Horn prototype Cherenkov Camera based on a
modular multipixel Silicon Photon Multiplier (SiPM) detector, has been
acquiring data since 2016 and allowing us to obtain both scientific data and
essential lessons. In this contribution, we report the main features of the
camera and its evolution toward the new Cherenkov camera, which will be
installed on each ASTRI Mini-Array telescope to cover an unprecedented field of
view of 10.5{\deg}.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:53:23 GMT""}]","2023-01-25"
"2301.09916","Andrzej \.Zak","Andrzej M. \.Zak, Anna Wieczorek, Agnieszka Chowaniec, Lukasz Sadowski","Segmentation of pores in cementitious materials based on backscattered
  electron measurements: a new proposal of regression-based approach for
  threshold estimation","13 pages, 6 figures","Construction and Building Materials 368 (2023) 130419","10.1016/j.conbuildmat.2023.130419",,"physics.app-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the following work, we described the problems of porosity analysis of
cement materials using backscattered electron images. We noticed that despite
its great utility, the overflow porosity segmentation method allows for the
introduction of an additional error by the effect of the subjective researcher.
For this purpose, two developed variants of this method - regression I and II -
were completely algorithmized and compared with the literature methods of
overflow, triangle, and method preserving to choose the fastest and most
consistent measurement method. Based on the comparison of the two data sets, it
was judged that the improved overflow-based methods are the best candidates for
the automated porosity assessment, with particular emphasis on regression II.
All the algorithms used are summarized as Python source code in Supplementary
Material.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:56:04 GMT""}]","2023-01-25"
"2301.09917","Alessio Traficante","A. Traficante, B. M. Jones, A. Avison, G. A. Fuller, M. Benedettini,
  D. Elia, S. Molinari, N. Peretto, S. Pezzuto, T. Pillai, K. L. J. Rygl, E.
  Schisano and R. J. Smith","The SQUALO project (Star formation in QUiescent And Luminous Objects) I:
  clump-fed accretion mechanism in high-mass star-forming objects","25 pages, 15 Figures, 9 Tables. Accepted for publication in MNRAS",,"10.1093/mnras/stad272",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation mechanism of the most massive stars is far from completely
understood. It is still unclear if the formation is core-fed or clump-fed, i.e.
if the process is an extension of what happens in low-mass stars, or if the
process is more dynamical such as a continuous, multi-scale accretion from the
gas at parsec (or even larger) scales. In this context we introduce the SQUALO
project, an ALMA 1.3 mm and 3 mm survey designed to investigate the properties
of 13 massive clumps selected at various evolutionary stages, with the common
feature that they all show evidence for accretion at the clump scale. In this
work we present the results obtained from the 1.3 mm continuum data. Our
observations identify 55 objects with masses in the range 0.4 <~ M <~ 309
M_sun, with evidence that the youngest clumps already present some degree of
fragmentation. The data show that physical properties such as mass and surface
density of the fragments and their parent clumps are tightly correlated. The
minimum distance between fragments decreases with evolution, suggesting a
dynamical scenario in which massive clumps first fragment under the influence
of non-thermal motions driven by the competition between turbulence and
gravity. With time gravitational collapse takes over and the fragments organize
themselves into more thermally supported objects while continuing to accrete
from their parent clump. Finally, one source does not fragment, suggesting that
the support of other mechanisms (such as magnetic fields) is crucial only in
specific star-forming regions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:56:51 GMT""}]","2023-02-01"
"2301.09918","David Rold\'an-\'Alvarez","David Rold\'an-\'Alvarez","Smart tutor to provide feedback in programming courses","Preliminary work",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Artificial Intelligence (AI) is becoming more and more popular as time
passes, allowing to perform tasks that were difficult to do in the past. From
predictions to customization, AI is being used in many areas, not being
educational environments outside this situation. AI is being used in
educational settings to customize contents or to provide personalized feedback
to the students, among others. In this scenario, AI in programming teaching is
something that still has to be explored, since in this area we usually find
assessment tools that allow grading the students work, but we can not find many
tools aimed towards providing feedback to the students in the process of
creating their program. In this work we present an AI based intelligent tutor
that answers students programming questions. The tool has been tested by
university students at the URJC along a whole course. Even if the tool is still
in its preliminary phase, it helped the students with their questions,
providing accurate answers and examples. The students were able to use the
intelligent tutor easily and they thought that it could be a useful tool to use
in other courses.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:00:06 GMT""}]","2023-01-25"
"2301.09919","Nico Daheim","Jakub Macina, Nico Daheim, Lingzhi Wang, Tanmay Sinha, Manu Kapur,
  Iryna Gurevych, Mrinmaya Sachan","Opportunities and Challenges in Neural Dialog Tutoring","EACL 2023 (main conference, camera-ready)",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Designing dialog tutors has been challenging as it involves modeling the
diverse and complex pedagogical strategies employed by human tutors. Although
there have been significant recent advances in neural conversational systems
using large language models (LLMs) and growth in available dialog corpora,
dialog tutoring has largely remained unaffected by these advances. In this
paper, we rigorously analyze various generative language models on two dialog
tutoring datasets for language learning using automatic and human evaluations
to understand the new opportunities brought by these advances as well as the
challenges we must overcome to build models that would be usable in real
educational settings. We find that although current approaches can model
tutoring in constrained learning scenarios when the number of concepts to be
taught and possible teacher strategies are small, they perform poorly in less
constrained scenarios. Our human quality evaluation shows that both models and
ground-truth annotations exhibit low performance in terms of equitable
tutoring, which measures learning opportunities for students and how engaging
the dialog is. To understand the behavior of our models in a real tutoring
setting, we conduct a user study using expert annotators and find a
significantly large number of model reasoning errors in 45% of conversations.
Finally, we connect our findings to outline future work.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:00:17 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 19:13:35 GMT""}]","2023-03-29"
"2301.09920","Simone Manti","Kristian Piscicchia, Sandro Donadi, Simone Manti, Angelo Bassi,
  Maaneli Derakhshani and Catalina Curceanu","Surprising results of a refined dynamical collapse spontaneous radiation
  study: CSL and gravity related collapse have distinctive features at atomic
  orbits wavelength scale",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The experimental search of spontaneous radiation signal in the $\gamma$-Rays
range produced strong bounds on the models of dynamical wave function collapse,
in particular on the Continuous Spontaneous Localization and on the
Di\'{o}si-Penrose. Ongoing and future experiments are moving the investigation
to the X-Rays domain, also motivated by the introduction of non-Markovian
modifications of the original theories, which require a scan of the spontaneous
emission phenomenon for decreasing energies. In this work the spontaneous
radiation rate, for an atomic system, is generalized to contemplate photons'
wavelengths of the order of the atomic orbits size, i.e. photons' energies in
the X-Rays range. The simple high-energy limit of the rate undergoes a strong
correction, due to a complex interplay among the photon wavelength, the
distances among the emitting particles, and the characteristic correlation
lengths of the models. Moreover the spontaneous radiation rate energy
distribution is found to depend on the specific collapse mechanism, thus
opening a new experimental perspective to discriminate among the theories.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:06:10 GMT""}]","2023-01-25"
"2301.09921","Ignacio Roldan","Ignacio Roldan, Francesco Fioranelli, Alexander Yarovoy","Self-Supervised Learning for Enhancing Angular Resolution in Automotive
  MIMO Radars","Published at IEEE Transactions on Vehicular Technology. For citation,
  please use the IEEE DOI",,"10.1109/TVT.2023.3269199",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel framework to enhance the angular resolution of automotive radars is
proposed. An approach to enlarge the antenna aperture using artificial neural
networks is developed using a self-supervised learning scheme. Data from a high
angular resolution radar, i.e., a radar with a large antenna aperture, is used
to train a deep neural network to extrapolate the antenna element's response.
Afterward, the trained network is used to enhance the angular resolution of
compact, low-cost radars. One million scenarios are simulated in a Monte-Carlo
fashion, varying the number of targets, their Radar Cross Section (RCS), and
location to evaluate the method's performance. Finally, the method is tested in
real automotive data collected outdoors with a commercial radar system. A
significant increase in the ability to resolve targets is demonstrated, which
can translate to more accurate and faster responses from the planning and
decision making system of the vehicle.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:06:16 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 10:07:45 GMT""}]","2023-04-26"
"2301.09922","Kohki Uno","Kohki Uno, Takashi Nagao, Keiichi Maeda, Hanindyo Kuncarayakti,
  Masaomi Tanaka, Koji S. Kawabata, Tatsuya Nakaoka, Miho Kawabata, Masayuki
  Yamanaka, Kentaro Aoki, Keisuke Isogai, Mao Ogawa, Akito Tajitsu, and Ryo
  Imazawa","SN 2020uem: A Possible Thermonuclear Explosion within A Dense
  Circumstellar Medium (II) The Properties of The CSM from Polarimetry and
  Light Curve Modeling","16pages, 9 figures, 1 table. Accepted for publication in ApJ",,"10.3847/1538-4357/acb5eb",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Type IIn/Ia-CSM supernovae (SNe IIn/Ia-CSM) are classified by their
characteristic spectra, which exhibit narrow hydrogen emission lines
originating from a strong interaction with a circumstellar medium (CSM)
together with broad lines of intermediate-mass elements. We performed intensive
follow-up observations of SN IIn/Ia-CSM 2020uem, including photometry,
spectroscopy, and polarimetry. In this paper, we focus on the results of
polarimetry. We performed imaging polarimetry at $66$ days and
spectropolarimetry at $103$ days after the discovery. SN 2020uem shows a high
continuum polarization of $1.0-1.5\%$ without wavelength dependence. Besides,
the polarization degree and position angle keep roughly constant. These results
suggest that SN 2020uem is powered by a strong interaction with a confined and
aspherical CSM. We performed a simple polarization modeling, based on which we
suggest that SN 2020uem has an equatorial-disk/torus CSM. Besides, we performed
semi-analytic light-curve modeling and estimated the CSM mass. We revealed that
the mass-loss rate in the final few hundred years immediately before the
explosion of SN 2020uem is in the range of $0.01 - 0.05 {\rm
~M_{\odot}~yr^{-1}}$, and that the total CSM mass is $0.5-4 {\rm ~M_{\odot}}$.
The CSM mass can be accommodated by not only a red supergiant (RSG) but a red
giant (RG) or an asymptotic-giant-branch (AGB) star. As a possible progenitor
scenario of SN 2020uem, we propose a white-dwarf binary system including an RG,
RSG or AGB star, especially a merger scenario via common envelope evolution,
i.e., the core-degenerate scenario or its variant.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:09:55 GMT""}]","2023-03-08"
"2301.09923","Pascal Marc Vecsei","Pascal M. Vecsei, Christian Flindt, and Jose L. Lado","Lee-Yang theory of quantum phase transitions with neural network quantum
  states","9 pages, 5 figures, 1 table",,,,"cond-mat.str-el cond-mat.dis-nn quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predicting the phase diagram of interacting quantum many-body systems is a
central problem in condensed matter physics and related fields. A variety of
quantum many-body systems, ranging from unconventional superconductors to spin
liquids, exhibit complex competing phases whose theoretical description has
been the focus of intense efforts. Here, we show that neural network quantum
states can be combined with a Lee-Yang theory of quantum phase transitions to
predict the critical points of strongly-correlated spin lattices. Specifically,
we implement our approach for quantum phase transitions in the transverse-field
Ising model on different lattice geometries in one, two, and three dimensions.
We show that the Lee-Yang theory combined with neural network quantum states
yields predictions of the critical field, which are consistent with large-scale
quantum many-body methods. As such, our results provide a starting point for
determining the phase diagram of more complex quantum many-body systems,
including frustrated Heisenberg and Hubbard models.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:10:37 GMT""}]","2023-01-25"
"2301.09924","Effie Papageorgiou","Effie Papageorgiou","Asymptotics for the infinite Brownian loop on noncompact symmetric
  spaces","15 pages, 2 figures",,,,"math.AP math.PR","http://creativecommons.org/licenses/by/4.0/","  The infinite Brownian loop on a Riemannian manifold is the limit in
distribution of the Brownian bridge of length $T$ around a fixed origin when $T
\rightarrow +\infty$. The aim of this note is to study its long-time
asymptotics on Riemannian symmetric spaces $G/K$ of noncompact type and of
general rank. This amounts to the behavior of solutions to the heat equation
subject to the Doob transform induced by the ground spherical function. Unlike
the standard Brownian motion, we observe in this case phenomena which are
similar to the Euclidean setting, namely $L^1$ asymptotic convergence without
requiring bi-$K$-invariance for initial data, and strong $L^{\infty}$
convergence.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:12:49 GMT""}]","2023-01-25"
"2301.09925","Ramil Akzyanov","R. S. Akzyanov","Born approximation study of the strong disorder in magnetized surface
  states of topological insulator","9 pages, 7 figures",,"10.1103/PhysRevB.107.205416",,"cond-mat.mes-hall cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  In this study we investigate the effect of random point disorder on the
surface states of a topological insulator with out-of-plane magnetization. We
consider the disorder within a high order Born approximation. The Born series
converges to the one branch of the self-consistent Born approximation (SCBA)
solution at low disorder. As the disorder strength increases, the Born series
converges to another SCBA solution with the finite density of states within the
magnetization induced gap. Further increase of the disorder strength leads to a
divergence of the Born series, showing the limits of the applicability of the
Born approximation. We find that the convergence properties of this Born series
are closely related to the properties of the logistic map, which is known as a
prototypical model of chaos. We also calculate the longitudinal and Hall
conductivities within the Kubo formulas at zero temperature with the vertex
corrections for the velocity operator. Vertex corrections are important for
describing transport properties in the strong disorder regime. In the case of
strong disorder, the longitudinal conductivity is weakly dependent on the
disorder strength, while the Hall conductivity decreases with increasing
disorder.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:15:45 GMT""}]","2023-06-07"
"2301.09926","Giovanni Stabile","Isabella Carla Gonnella, Martin W. Hess, Giovanni Stabile, Gianluigi
  Rozza","A two stages Deep Learning Architecture for Model Reduction of
  Parametric Time-Dependent Problems",,,,,"math.NA cs.LG cs.NA","http://creativecommons.org/licenses/by/4.0/","  Parametric time-dependent systems are of a crucial importance in modeling
real phenomena, often characterized by non-linear behaviors too. Those
solutions are typically difficult to generalize in a sufficiently wide
parameter space while counting on limited computational resources available. As
such, we present a general two-stages deep learning framework able to perform
that generalization with low computational effort in time. It consists in a
separated training of two pipe-lined predictive models. At first, a certain
number of independent neural networks are trained with data-sets taken from
different subsets of the parameter space. Successively, a second predictive
model is specialized to properly combine the first-stage guesses and compute
the right predictions. Promising results are obtained applying the framework to
incompressible Navier-Stokes equations in a cavity (Rayleigh-Bernard cavity),
obtaining a 97% reduction in the computational time comparing with its
numerical resolution for a new value of the Grashof number.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:24:18 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 07:36:14 GMT""}]","2023-01-26"
"2301.09927","Vaibhav Prabhudesai","Akshay Kumar, Suvasis Swain, Jankee Upadhyay, Yogesh Upalekar, Rajesh
  Arya, and Vaibhav S. Prabhudesai","Predissociation dynamics of negative ion resonances of H$_2$ near 12 eV
  and 14.5 eV using velocity slice imaging technique","13 pages, 5 figures",,,,"physics.chem-ph physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  Dissociative electron attachment (DEA) is an important tool for investigating
negative ion resonances. We have studied the negative ion resonances of H2 at
10 eV and 14 eV using the improved velocity slice imaging technique. We
obtained modulations in the kinetic energy spectrum of H$^-$ ions obtained at
12 eV and 14.5 eV electron energy, consistent with the earlier reported
vibrational state contributions from the higher lying bound resonances. We show
that structures obtained at 12 eV are due to predissociation of the
$C^2{\Sigma}_g^+$ resonance consistent with the current understanding. However,
based on our angular distribution measurements, we propose that the structures
obtained at 14.4 eV are due to predissociation of bound resonance of
$^2{\Sigma}_g^+$ symmetry as against ${\delta}_g$ that was proposed earlier. We
also report that the bound $^2{\Sigma}_g^+$ resonance contributes to the
observed inversion symmetry breaking near 14 eV.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:24:41 GMT""}]","2023-01-25"
"2301.09928","Shahbozbek Abdunabiev","Shahbozbek Abdunabiev, Andrea Merlone, Chiara Musacchio, Miryam
  Paredes, Eros Pasero, Daniela Tordella","Validation and traceability of multi-parameter miniaturized radiosondes
  for environmental observations","Cloud, Lagrangian tracking, Radiosonde, Dispersion, Diffusion, Sensor
  fusion, Stereo vision",,,,"eess.SY cs.SY physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of the work is to design and develop light (less then 20 gr),
expendable radioprobes to study complex micro-physical and chemical processes
inside warm clouds. This includes the tracking of turbulent, both saturated and
unsaturated, air parcels. With this new kind of radiosonde, we thus aim to
obtain Lagrangian statistics of the intense turbulence inside warm clouds and
of the lower intensity turbulence typical of the air surrounding them. The
radiosonde is made of the radioprobe (the electronic board) attached to a
biodegradable balloon filled with a mixture of helium and air. The system is
able to float inside/into clouds for a time span of the order of a few hours
and measure fluctuations of air temperature, pressure, humidity position,
velocity and acceleration along with its own trajectory which...
  Preliminary in-field experiments were carried out with a single and multiple
radiosondes in different environments. Sensor readings are validated by
comparison with reference values provided by INRIM traceable instrumentation
and/or ARPA (Piemonte) and OAvdA nearby meteorological stations. The last two
experiments, INRIM, September 29, 2021 and OAVdA, February 10, 2022, addressed
the possibility to implement a distance neighbor graph algorithm (Richardson LF
- 1926) conceived for turbulent dispersion analysis in the atmosphere and
which, actually, has not been yet realized in the context of in-field
atmospheric observations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:24:48 GMT""}]","2023-01-25"
"2301.09929","Raymond Cheng","Raymond Cheng","$q$-bic forms","Comments very welcome!",,,,"math.AG math.NT","http://creativecommons.org/licenses/by/4.0/","  A $q$-bic form is a pairing $V \times V \to \mathbf{k}$ that is linear in the
second variable and $q$-power Frobenius linear in the first; here, $V$ is a
vector space over a field $\mathbf{k}$ containing the finite field on $q^2$
elements. This article develops a geometric theory of $q$-bic forms in the
spirit of that of bilinear forms. I find two filtrations intrinsically attached
to a $q$-bic form, with which I define a series of numerical invariants. These
are used to classify, study automorphism group schemes of, and describe
specialization relations in the parameter space of $q$-bic forms.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:25:50 GMT""}]","2023-01-25"
"2301.09930","Pavan Vynatheya","Pavan Vynatheya, Rosemary A. Mardling, Adrian S. Hamers","Quadruple-star systems are not always nested triples: a machine learning
  approach to dynamical stability","10 pages, 7 figures; Submitted to MNRAS",,,,"cs.LG astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamical stability of quadruple-star systems has traditionally been
treated as a problem involving two `nested' triples which constitute a
quadruple. In this novel study, we employed a machine learning algorithm, the
multi-layer perceptron (MLP), to directly classify 2+2 and 3+1 quadruples based
on their stability (or long-term boundedness). The training data sets for the
classification, comprised of $5\times10^5$ quadruples each, were integrated
using the highly accurate direct $N$-body code MSTAR. We also carried out a
limited parameter space study of zero-inclination systems to directly compare
quadruples to triples. We found that both our quadruple MLP models perform
better than a `nested' triple MLP approach, which is especially significant for
3+1 quadruples. The classification accuracies for the 2+2 MLP and 3+1 MLP
models are 94% and 93% respectively, while the scores for the `nested' triple
approach are 88% and 66% respectively. This is a crucial implication for
quadruple population synthesis studies. Our MLP models, which are very simple
and almost instantaneous to implement, are available on GitHub, along with
Python3 scripts to access them.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:27:17 GMT""}]","2023-01-25"
"2301.09931","Lars Leon Schaaf","Lars Schaaf, Edvin Fako, Sandip De, Ansgar Sch\""afer, G\'abor Cs\'anyi","Accurate Reaction Barriers for Catalytic Pathways: An Automatic Training
  Protocol for Machine Learning Force Fields",,,,,"physics.chem-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we introduce an automatic training protocol for developing
machine learning force fields (MLFFs) that can accurately determine reaction
barriers for a given catalytic reaction pathway. The protocol is demonstrated
through its application to the eleven-step hydrogenation of carbon dioxide to
methanol over an indium oxide catalyst. The training set is iteratively
expanded with active learning, using the model's uncertainty estimates to
sample novel configurations that are chemically relevant. Our final force field
obtains reaction barriers that are within 0.05 eV of those obtained through
Density Functional Theory (DFT) calculations. Additionally, we examine two
extrapolation tasks. Firstly, we demonstrate that with only a few extra
single-point DFT calculations, we can accurately capture the adsorption energy
for all eleven reaction intermediates on platinum-doped surfaces. Secondly, we
show that MLFFs can be used to identify a wide range of low-energy adsorption
configurations that are thermodynamically relevant. This abundance of adsorbate
geometries highlights the need for fast and accurate alternatives to direct
ab-initio simulations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:27:49 GMT""}]","2023-01-25"
"2301.09932","P. A. Miles-P\'aez","Paulo A. Miles-P\'aez, Stanimir A. Metchev and Benjamin George","The photometric periods of rapidly rotating field ultra-cool dwarfs","Accepted for publication in MNRAS",,"10.1093/mnras/stad273",,"astro-ph.SR astro-ph.EP physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  We use 1-m class telescopes and the Transiting Exoplanet Survey Satellite
(TESS) to explore the photometric variability of all known rapidly rotating
($v\sin{i}\gtrsim30$ km\,s$^{-1}$) ultra-cool ($\geq$M7) dwarfs brighter than
$I\approx17.5$ mag. For a sample of 13 M7--L1.5 dwarfs without prior
photometric periods, we obtained $I$-band light curves with the SMARTS 1.3m and
WIYN 0.9m telescopes and detected rotation-modulated photometric variability in
three of them. Seven of our targets were also observed by TESS and six of them
show significant periodicities compatible with the estimated rotation periods
of the targets. We investigate the potential of TESS to search for
rotation-modulated photometric variability in ultra-cool dwarfs and find that
its long stare enables $<$80~h periodic variations to be retrieved with
$\leq$1\% amplitudes for ultra-cool dwarfs up to a TESS magnitude of 16.5. We
combine these results with the periods of all other known
photometrically-periodic ultra-cool dwarfs from the literature, and find that
the periods of ultra-cool dwarfs range between 1 and 24 h, although the upper
limit is likely an observational bias. We also observe that the minimum
rotation periods follow a lower envelope that runs from $\approx$2 h at
spectral type $\approx$M8 to $\approx$1 h at spectral type T.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:28:05 GMT""}]","2023-02-01"
"2301.09933","Ronen Wdowinski","Ronen Wdowinski","On an $f$-coloring generalization of linear arboricity of multigraphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a multigraph $G$ and function $f : V(G) \rightarrow \mathbb{Z}_{\ge 2}$
on its vertices, a degree-$f$ subgraph of $G$ is a spanning subgraph in which
every vertex $v$ has degree at most $f(v)$. The degree-$f$ arboricity $a_f(G)$
of $G$ is the minimum number of colors required to edge-color $G$ into
degree-$f$ forests. At least for constant $f$, Truszczy\'nski conjectured that
$a_f(G) \le \max \{\Delta_f(G) + 1, a(G)\}$ for every multigraph $G$, where
$\Delta_f(G) = \max_{v \in V(G)} \lceil d(v)/f(v) \rceil$ and $a(G)$ is the
usual arboricity of $G$. This is a strong generalization of the Linear
Arboricity Conjecture due to Akiyama, Exoo, and Harary. In this paper, we
disprove Truszczy\'nski's conjecture in a strong sense for general multigraphs.
On the other hand, extending known results for linear arboricity, we prove that
the conjecture holds for simple graphs with sufficiently large girth, and that
it holds for all simple graphs asymptotically. More strongly, we prove these
partial results in the setting of directed graphs, where the color classes are
required to be analogously defined degree-$f$ branchings.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:29:48 GMT""}]","2023-01-25"
"2301.09934","Ettore Del Monte","Ettore Del Monte, Sergio Fabiani and Mark Pearce","Compton Polarimetry","This invited Chapter will appear in the Section ""Detectors for X-ray
  Astrophysics"" (Section Editors: Jan-Willen den Herder, Marco Feroci and
  Norbert Meidinger) of the ""Handbook of X-ray and Gamma-ray Astrophysics""
  (Editors in chief: Cosimo Bambi and Andrea Santangelo) published by Springer.
  45 pages, 10 figures",,,,"physics.ins-det astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Photons preferentially Compton scatter perpendicular to the plane of
polarisation. This property can be exploited to design instruments to measure
the linear polarisation of hard X-rays ($\sim$10 - 100 keV). Photons may
undergo two interactions in the sensitive volume of the instrument, i.e. a
scattering followed by an absorption. Depending on the materials used to detect
these two interactions, the Compton polarimeter can be classified as
single-phase (same material for scattering and absorption detectors) or
dual-phase (different materials). Different designs have been studied and
adopted, and current instruments are predominantly with sensors based on
scintillation- or solid-state detectors. X-ray polarimetry requires much higher
statistics than e.g. spectrometry or timing, thus systematic effects must be
accurately measured and accounted for. In this chapter we introduce the basic
formalism of the Compton effect; we describe the design schemes developed so
far for scattering polarimeters, including both the single-phase and dual-phase
approaches; we overview the calibration methods to reduce the systematic
effects; and we describe sources of background which affect the measurements.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:36:50 GMT""}]","2023-01-25"
"2301.09935","Yongling Zhao","Haiwei Li, Yongling Zhao, Ronita Bardhan, Aytac Kubilay, Dominique
  Derome, Jan Carmeliet","Time-evolving Impact of Trees on Street Canyon Microclimate","4 figures, 8 pages",,,,"physics.flu-dyn physics.soc-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Nowadays, cities are frequently exposed to heatwaves, worsening the outdoor
thermal comfort and increasing cooling energy demand in summer. Urban forestry
is seen as one of the viable and preferable solutions to combating extreme heat
events and urban heat island (UHI) in times of climate change. While many
cities have initiated tree-planting programmes in recent years, the evolving
impact of trees on street microclimate, in a time span of up to several
decades, remains unclear. We investigate the cooling effects of linden trees in
five groups, i.e., 10-20, 20-30, 30-40, 40-60, and 60-100 years old. The leaf
area index (LAI) and leaf area density (LAD) vary nonlinearly as the trees
grow, peaking at different ages. Computational fluid dynamics (CFD) simulations
solving microclimate are performed for an idealized street canyon with trees of
varied age groups. Turbulent airflow, heat and moisture transport, shortwave
and longwave radiation, shading and transpiration are fully coupled and solved
in OpenFOAM. The meteorological data, including air temperature, wind speed,
moisture, and shortwave radiation of the heatwave in Zurich (June 2019), are
applied as boundary conditions. The results show that young trees in the age
group of 10-20 years old provide little heat mitigation at the pedestrian level
in an extreme heat event. Optimal heat mitigation by trees is observed for the
group of 30-60 years old trees. Finally, the potential impact of growing trees
as a heat mitigation measure on air ventilation is evaluated.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:38:44 GMT""}]","2023-01-25"
"2301.09936","Van Quoc Phuong Huynh","Van Quoc Phuong Huynh, Johannes F\""urnkranz, Florian Beck","Efficient learning of large sets of locally optimal classification rules","article, 40 pages, Machine Learning journal (2023)","Mach Learn (2023)","10.1007/s10994-022-06290-w",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Conventional rule learning algorithms aim at finding a set of simple rules,
where each rule covers as many examples as possible. In this paper, we argue
that the rules found in this way may not be the optimal explanations for each
of the examples they cover. Instead, we propose an efficient algorithm that
aims at finding the best rule covering each training example in a greedy
optimization consisting of one specialization and one generalization loop.
These locally optimal rules are collected and then filtered for a final rule
set, which is much larger than the sets learned by conventional rule learning
algorithms. A new example is classified by selecting the best among the rules
that cover this example. In our experiments on small to very large datasets,
the approach's average classification accuracy is higher than that of
state-of-the-art rule learning algorithms. Moreover, the algorithm is highly
efficient and can inherently be processed in parallel without affecting the
learned rule set and so the classification accuracy. We thus believe that it
closes an important gap for large-scale classification rule induction.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:40:28 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 07:54:14 GMT""}]","2023-01-27"
"2301.09937","George Vouros","George A. Vouros","Explainable Deep Reinforcement Learning: State of the Art and Challenges",,"ACM Comput. Surv. 55, 5, Article 92 (May 2023), 39 pages","10.1145/3527448",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Interpretability, explainability and transparency are key issues to
introducing Artificial Intelligence methods in many critical domains: This is
important due to ethical concerns and trust issues strongly connected to
reliability, robustness, auditability and fairness, and has important
consequences towards keeping the human in the loop in high levels of
automation, especially in critical cases for decision making, where both (human
and the machine) play important roles. While the research community has given
much attention to explainability of closed (or black) prediction boxes, there
are tremendous needs for explainability of closed-box methods that support
agents to act autonomously in the real world. Reinforcement learning methods,
and especially their deep versions, are such closed-box methods. In this
article we aim to provide a review of state of the art methods for explainable
deep reinforcement learning methods, taking also into account the needs of
human operators - i.e., of those that take the actual and critical decisions in
solving real-world problems. We provide a formal specification of the deep
reinforcement learning explainability problems, and we identify the necessary
components of a general explainable reinforcement learning framework. Based on
these, we provide a comprehensive review of state of the art methods,
categorizing them in classes according to the paradigm they follow, the
interpretable models they use, and the surface representation of explanations
provided. The article concludes identifying open questions and important
challenges.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:41:25 GMT""}]","2023-01-25"
"2301.09938","The ATLAS Collaboration","ATLAS Collaboration","Search for exclusive Higgs and $Z$ boson decays to $\omega\gamma$ and
  Higgs boson decays to $K^{*}\gamma$ with the ATLAS detector","18 pages in total, 4 figures, 3 tables, submitted to Physics Letters
  B. All figures including auxiliary figures are available at
  https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/HDBS-2019-33",,,"CERN-EP-2022-288","hep-ex","http://creativecommons.org/licenses/by/4.0/","  Searches for the exclusive decays of the Higgs boson to an $\omega$ meson and
a photon or a $K^{*}$ meson and a photon can probe flavour-conserving and
flavour-violating Higgs boson couplings to light quarks, respectively. Searches
for these decays, along with the analogous $Z$ boson decay to an $\omega$ meson
and a photon, are performed with a $pp$ collision data sample corresponding to
integrated luminosities of up to 134 fb$^{-1}$ collected at $\sqrt{s}=13$ TeV
with the ATLAS detector at the CERN Large Hadron Collider. The obtained 95%
confidence-level upper limits on the respective branching fractions are ${\cal
B}(H\rightarrow\omega\gamma)< 1.5\times 10^{-4}$, ${\cal B}(H\rightarrow
K^{*}\gamma)< 8.9\times10^{-5}$ and ${\cal B}(Z\rightarrow
\omega\gamma)<3.8\times 10^{-7}$. The limits for $H\rightarrow \omega\gamma$
and $Z\rightarrow \omega\gamma$ are 100 times and 17 times the Standard Model
expected values, respectively. The result for $Z\rightarrow \omega\gamma$
corresponds to a three-orders-of-magnitude improvement over a previously set
limit.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:43:13 GMT""}]","2023-01-25"
"2301.09939","Toby Phillips","T. R. F. Phillips, C. E. Heaney, C. Boyang, A. G. Buchan, C. C. Pain","Solving the Discretised Neutron Diffusion Equations using Neural
  Networks",,,,,"cs.CE cs.AI cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  This paper presents a new approach which uses the tools within Artificial
Intelligence (AI) software libraries as an alternative way of solving partial
differential equations (PDEs) that have been discretised using standard
numerical methods. In particular, we describe how to represent numerical
discretisations arising from the finite volume and finite element methods by
pre-determining the weights of convolutional layers within a neural network. As
the weights are defined by the discretisation scheme, no training of the
network is required and the solutions obtained are identical (accounting for
solver tolerances) to those obtained with standard codes often written in
Fortran or C++. We also explain how to implement the Jacobi method and a
multigrid solver using the functions available in AI libraries. For the latter,
we use a U-Net architecture which is able to represent a sawtooth multigrid
method. A benefit of using AI libraries in this way is that one can exploit
their power and their built-in technologies. For example, their executions are
already optimised for different computer architectures, whether it be CPUs,
GPUs or new-generation AI processors. In this article, we apply the proposed
approach to eigenvalue problems in reactor physics where neutron transport is
described by diffusion theory. For a fuel assembly benchmark, we demonstrate
that the solution obtained from our new approach is the same (accounting for
solver tolerances) as that obtained from the same discretisation coded in a
standard way using Fortran. We then proceed to solve a reactor core benchmark
using the new approach.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:46:09 GMT""}]","2023-01-25"
"2301.09940","Stefan Vatev","Nikolay Bazhenov, Ekaterina Fokina, Dino Rossegger, Alexandra A.
  Soskova, Stefan V. Vatev","A Lopez-Escobar Theorem for Continuous Domains","17 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove an effective version of the Lopez-Escobar theorem for continuous
domains. Let $Mod(\tau$ be the set of countable structures with universe
$\omega$ in vocabulary $\tau$ topologized by the Scott topology. We show that
an invariant set $X \subseteq Mod(\tau)$ is $\Pi^0_\alpha$ in the effective
Borel hierarchy of this topology if and only if it is definable by a
$\Pi^p_\alpha$ - formula, a positive $\Pi^0_\alpha$ formula in the infinitary
logic $L_{\omega_1,\omega}$. As a corollary of this result we obtain a new
pullback theorem for computable embeddings: Let $K$ be computably embeddable in
$K'$ by $\Phi$, then for every $\Pi^p_\alpha$ formula $\xi$ in the vocabulary
of $K'$ there is a $\Pi^p_\alpha$ formula $\xi^\star$ in the vocabulary of $K$
such that for all $A \in K$, $A \models \xi^\star$ if and only if $\Phi(A)
\models \xi$. We use this to obtain new results on the possibility of
computable embeddings into the class of linear orderings.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:51:29 GMT""}]","2023-01-25"
"2301.09941","Yotam Amitai","Yotam Amitai, Guy Avni and Ofra Amir","ASQ-IT: Interactive Explanations for Reinforcement-Learning Agents",,,,,"cs.AI cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  As reinforcement learning methods increasingly amass accomplishments, the
need for comprehending their solutions becomes more crucial. Most explainable
reinforcement learning (XRL) methods generate a static explanation depicting
their developers' intuition of what should be explained and how. In contrast,
literature from the social sciences proposes that meaningful explanations are
structured as a dialog between the explainer and the explainee, suggesting a
more active role for the user and her communication with the agent. In this
paper, we present ASQ-IT -- an interactive tool that presents video clips of
the agent acting in its environment based on queries given by the user that
describe temporal properties of behaviors of interest. Our approach is based on
formal methods: queries in ASQ-IT's user interface map to a fragment of Linear
Temporal Logic over finite traces (LTLf), which we developed, and our algorithm
for query processing is based on automata theory. User studies show that
end-users can understand and formulate queries in ASQ-IT, and that using ASQ-IT
assists users in identifying faulty agent behaviors.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 11:57:37 GMT""}]","2023-01-25"
"2301.09942","Ian Morris","Ian D. Morris","An irreducible linear switching system whose unique Barabanov norm is
  not strictly convex",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a marginally stable linear switching system in continuous time,
in four dimensions and with three switching states, which is exponentially
stable with respect to constant switching laws and which has a unique Barabanov
norm, but such that the Barabanov norm fails to be strictly convex. This
resolves a question of Y. Chitour, M. Gaye and P. Mason.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:01:41 GMT""}]","2023-01-25"
"2301.09943","Max Benedikt Paulus","Max B. Paulus, Andreas Krause","Learning To Dive In Branch And Bound",,,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Primal heuristics are important for solving mixed integer linear programs,
because they find feasible solutions that facilitate branch and bound search. A
prominent group of primal heuristics are diving heuristics. They iteratively
modify and resolve linear programs to conduct a depth-first search from any
node in the search tree. Existing divers rely on generic decision rules that
fail to exploit structural commonality between similar problem instances that
often arise in practice. Therefore, we propose L2Dive to learn specific diving
heuristics with graph neural networks: We train generative models to predict
variable assignments and leverage the duality of linear programs to make diving
decisions based on the model's predictions. L2Dive is fully integrated into the
open-source solver SCIP. We find that L2Dive outperforms standard divers to
find better feasible solutions on a range of combinatorial optimization
problems. For real-world applications from server load balancing and neural
network verification, L2Dive improves the primal-dual integral by up to 7%
(35%) on average over a tuned (default) solver baseline and reduces average
solving time by 20% (29%).
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:01:45 GMT""}]","2023-01-25"
"2301.09944","Marzia Mazzotta","Marzia Mazzotta, Vicent P\'erez-Calabuig, Paola Stefanelli","Set-theoretical solutions of the pentagon equation on Clifford
  semigroups",,,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  Given a set-theoretical solution of the pentagon equation $s:S\times S\to
S\times S$ on a set $S$ and writing $s(a, b)=(a\cdot b,\, \theta_a(b))$, with
$\cdot$ a binary operation on $S$ and $\theta_a$ a map from $S$ into itself,
for every $a\in S$, one naturally obtains that $\left(S,\,\cdot\right)$ is a
semigroup. In this paper, we focus on solutions on Clifford semigroups
$\left(S,\,\cdot\right)$ satisfying special properties on the set of the
idempotents $E(S)$. Into the specific, we provide a complete description of
idempotent-invariant solutions, namely, those solutions for which $\theta_a$
remains invariant in $E(S)$, for every $a\in S$. Moreover, considering
$(S,\,\cdot)$ as a disjoint union of groups, we construct a family of
idempotent-fixed solutions, i.e., those solutions for which $\theta_a$ fixes
every element in $E(S)$, for every $a\in S$, starting from a solution on each
group.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:04:17 GMT""}]","2023-01-25"
"2301.09945","Luis Felipe Prieto-Mart\'inez","Luis Felipe Prieto-Mart\'inez","The concept of center as an equivariant map and a proof of an analogue
  of the center conjecture for equifacetal simplices",,,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Several authors have remarked the convenience of understanding the different
notions of center appearing in Geometry (centroid of a set of points, incenter
of a triangle, center of a conic and many others) as functions. The most
general way to do so is to define centers as equivariant maps between
$G$-spaces. In this paper, we prove that, under certain hypothesis, for any two
$G$-spaces $\mathcal A,\mathcal X$, for every $V\in \mathcal A$ and for every
point $P\in\mathcal X$ fixed by the symmetry group of $V$, there exists some
equivariant map $\mathfrak Z:\mathcal A\to \mathcal X$ such that $\mathfrak
Z(V)=P$. As a consequence of this fact, we prove an analogue (for
non-neccessarily continuous centers) of the \emph{center conjecture for
equifacetal simplices}, proposed by A. L. Edmonds.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:06:37 GMT""},{""version"":""v2"",""created"":""Sun, 5 Feb 2023 19:07:27 GMT""}]","2023-02-07"
"2301.09946","Berk Cirisci","Berk Cirisci, Constantin Enea, Suha Orhun Mutluergil","Quorum Tree Abstractions of Consensus Protocols",,,,,"cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Distributed algorithms solving agreement problems like consensus or state
machine replication are essential components of modern fault-tolerant
distributed services. They are also notoriously hard to understand and reason
about. Their complexity stems from the different assumptions on the environment
they operate with, i.e., process or network link failures, Byzantine failures
etc. In this paper, we propose a novel abstract representation of the dynamics
of such protocols which focuses on quorums of responses (votes) to a request
(proposal) that form during a run of the protocol. We show that focusing on
such quorums, a run of a protocol can be viewed as working over a tree
structure where different branches represent different possible outcomes of the
protocol, the goal being to stabilize on the choice of a fixed branch. This
abstraction resembles the description of recent protocols used in Blockchain
infrastructures, e.g., the protocol supporting Bitcoin or HotStuff. We show
that this abstraction supports reasoning about the safety of various
algorithms, e.g., Paxos, PBFT, Raft, and HotStuff, in a uniform way. In
general, it provides a novel induction based argument for proving that such
protocols are safe.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:10:14 GMT""}]","2023-01-25"
"2301.09947","Krisztina Perger","Krisztina Perger, Yingkang Zhang, S\'andor Frey, Tao An, Krisztina
  \'E. Gab\'anyi, Leonid I. Gurvits, Chorng-Yuan Hwang, Ekaterina Koptelova,
  Zsolt Paragi, Ailing Wang","High-resolution Imaging of Two Radio Quasars at the End of the
  Reionization Epoch","5 pages, 2 figures; to appear in the proceedings of the 15th European
  VLBI Network Symposium and Users' Meeting (EVN2022), 11-15 July 2022,
  University College Cork, Ireland","Proceedings of Science, Vol. 428, id. PoS(EVN2022)024 (2023)","10.22323/1.428.0024",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  There are approximately 250 quasars discovered at redshift $z\geq6$, of which
only a handful were detected in radio bands, and even fewer were imaged with
the highest resolution very long baseline interferometry (VLBI) technique. Here
we report the results of our dual-frequency observations with the Very Long
Baseline Array (VLBA) of two such recently discovered quasars, VIKING
J231818.35$-$311346.3 at $z=6.44$ and FIRST J233153.20$+$112952.11 at $z=6.57$.
Both extremely distant sources were imaged with VLBI for the first time. The
radio properties of the former are consistent with those of quasars with young
radio jets. The latter has an UV/optical spectrum characteristic of BL Lac
objects, of which no others have been found beyond redshift 4 so far. Our VLBA
observations revealed a flat-spectrum compact radio source.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:12:54 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 12:38:31 GMT""}]","2023-03-20"
"2301.09948","Samuel Stockman","Samuel Stockman, Daniel J. Lawson, Maxmilian J. Werner","Forecasting the 2016-2017 Central Apennines Earthquake Sequence with a
  Neural Point Process",,,,,"physics.geo-ph stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Point processes have been dominant in modeling the evolution of seismicity
for decades, with the Epidemic Type Aftershock Sequence (ETAS) model being most
popular. Recent advances in machine learning have constructed highly flexible
point process models using neural networks to improve upon existing parametric
models. We investigate whether these flexible point process models can be
applied to short-term seismicity forecasting by extending an existing temporal
neural model to the magnitude domain and we show how this model can forecast
earthquakes above a target magnitude threshold. We first demonstrate that the
neural model can fit synthetic ETAS data, however, requiring less computational
time because it is not dependent on the full history of the sequence. By
artificially emulating short-term aftershock incompleteness in the synthetic
dataset, we find that the neural model outperforms ETAS. Using a new enhanced
catalog from the 2016-2017 Central Apennines earthquake sequence, we
investigate the predictive skill of ETAS and the neural model with respect to
the lowest input magnitude. Constructing multiple forecasting experiments using
the Visso, Norcia and Campotosto earthquakes to partition training and testing
data, we target M3+ events. We find both models perform similarly at previously
explored thresholds (e.g., above M3), but lowering the threshold to M1.2
reduces the performance of ETAS unlike the neural model. We argue that some of
these gains are due to the neural model's ability to handle incomplete data.
The robustness to missing data and speed to train the neural model present it
as an encouraging competitor in earthquake forecasting.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:15:12 GMT""},{""version"":""v2"",""created"":""Thu, 11 May 2023 09:45:32 GMT""}]","2023-05-12"
"2301.09949","Mathew Zuparic Dr","Ryan Ahern, Mathew Zuparic, Keeley Hoek and Alexander Kalloniatis","Unifying warfighting functions in mathematical modelling: combat,
  manoeuvre, and C2","30 pages, 16 figures, preprint accepted by the Journal of the
  Operational Research Society","Journal of the Operational Research Society, 73 (9), 2009-2027",,,"math.DS math.OC nlin.AO physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The outcomes of warfare have rarely only been characterised by the quantity
and quality of individual combatant force elements. The ability to manoeuvre
and adapt across force elements through effective Command and Control (C2) can
allow smaller or weaker forces to overcome an adversary with greater resource
and fire-power. In this paper, we combine the classic Lanchester combat model
with the Kuramoto-Sakaguchi model for phase oscillators on a network to create
a flexible Networked-Lanchester-C2 representation of force-on-force military
engagement. The mathematical model thus unifies three of the military
warfighting `functions': fires, manoeuvre and C2. We consider three
illustrative use-cases, and show that an analytical treatment of a reduced
model characterises global effects in the full system. For inhomogeneous forces
we observe that with appropriate balance between internal organisational
coupling, resource manoeuvrability and even weaker lethality the force can be
adaptive to overcome an initially stronger adversary.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:15:42 GMT""}]","2023-01-25"
"2301.09950","Kaan Ak\c{s}it","Koray Kavakl{\i}, Liang Shi, Hakan \""Urey, Wojciech Matusik, Kaan
  Ak\c{s}it","HoloHDR: Multi-color Holograms Improve Dynamic Range","10 pages, 11 figures",,,,"cs.GR cs.AR cs.HC physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Holographic displays generate Three-Dimensional (3D) images by displaying
single-color holograms time-sequentially, each lit by a single-color light
source. However, representing each color one by one limits peak brightness and
dynamic range in holographic displays. This paper introduces a new driving
scheme, HoloHDR, for realizing higher dynamic range images in holographic
displays. Unlike the conventional driving scheme, in HoloHDR, three light
sources illuminate each displayed hologram simultaneously at various brightness
levels. In this way, HoloHDR reconstructs a multiplanar three-dimensional
target scene using consecutive multi-color holograms and persistence of vision.
We co-optimize multi-color holograms and required brightness levels from each
light source using a gradient descent-based optimizer with a combination of
application-specific loss terms. We experimentally demonstrate that HoloHDR can
increase the brightness levels in holographic displays up to three times with
support for a broader dynamic range, unlocking new potentials for perceptual
realism in holographic displays.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:16:30 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 14:17:53 GMT""}]","2023-01-27"
"2301.09951","Eric Yanchenko","Eric Yanchenko, Howard D. Bondell and Brian J. Reich","R2D2 goes to space! A principled approach to setting prior distributions
  on spatial parameters",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spatially dependent data arises in many biometric applications, and Gaussian
processes are a popular modelling choice for these scenarios. While Bayesian
analyses of these problems have proven to be successful, selecting prior
distributions for these complex models remains a difficult task. In this work,
we propose a principled approach for setting prior distributions for spatial
covariance parameters by placing a prior distribution on a measure of model
fit. In particular, we derive the distribution of the prior coefficient of
determination. Placing a beta prior distribution on this measure induces a
generalized beta prime prior distribution on the global variance of the linear
predictor in the model. This method can also be thought of as shrinking the fit
towards the intercept-only (null) model. We derive an efficient Gibbs sampler
for the majority of the parameters and use Metropolis-Hasting updates for the
others. Finally, the method is applied to a marine protection area data set. We
estimate the effect of marine policies on biodiversity and conclude that
no-take restrictions lead to a slight increase in biodiversity and that the
majority of the variance in the linear predictor comes from the spatial effect.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:26:11 GMT""}]","2023-01-25"
"2301.09952","Yevheniya Nosyk","Maciej Korczy\'nski and Yevheniya Nosyk","Source Address Validation","arXiv admin note: substantial text overlap with arXiv:2006.05277,
  arXiv:2002.00441","Encyclopedia of Cryptography, Security and Privacy (2021)","10.1007/978-3-642-27739-9_1626-1",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Source address validation (SAV) is a standard formalized in RFC 2827 aimed at
discarding packets with spoofed source IP addresses. The absence of SAV has
been known as a root cause of reflection distributed denial-of-service (DDoS)
attacks. Outbound SAV (oSAV): filtering applied at the network edge to traffic
coming from inside the customer network to the outside. Inbound SAV (iSAV):
filtering applied at the network edge to traffic coming from the outside to the
customer network.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:26:11 GMT""}]","2023-01-25"
"2301.09953","Danfeng Xiang","Danfeng Xiang, Xiaofeng Wang, Xinghan Zhang, Hanna Sai, Jujia Zhang,
  Thomas G. Brink, Alexei V. Filippenko, Jun Mo, Tianmeng Zhang, Zhihao Chen,
  Luc Dessart, Zhitong Li, Shengyu Yan, Sergei I. Blinnikov, Liming Rui, E.
  Baron, J. M. DerKacy","SN 2018hna: Adding a Piece to the Puzzles of the Explosion of Blue
  Supergiants","18 pages; accepted for publication in MNRAS",,"10.1093/mnras/stad340",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present extensive optical/ultraviolet observations and modelling analysis
for the nearby SN 1987A-like peculiar Type II supernova (SN) 2018hna. Both
photometry and spectroscopy covered phases extending to $>$500 days after the
explosion, making it one of the best-observed SN II of this subtype. SN 2018hna
is obviously bluer than SN 1987A during the photospheric phase, suggesting
higher photospheric temperature, which may account for weaker BaII
$\mathrm{\lambda}$6142 lines in its spectra. Analysis of early-time temperature
evolution suggests a radius of $\sim$45 $\mathrm{R_{\odot}}$ for the progenitor
of SN 2018hna, consistent with a blue supergiant (BSG). By fitting the
bolometric light curve with hydrodynamical models, we find that SN 2018hna has
an ejecta mass of $\sim$(13.7--17.7) $\mathrm{M_{\odot}}$, a kinetic energy of
$\sim$ (1.0--1.2) $\times 10^{51}$ erg, and a $^{56}$Ni mass of about 0.05
$\mathrm{M_{\odot}}$. Moreover, based on standard stellar evolution and the
oxygen mass (0.44--0.73 $\mathrm{M_{\odot}}$) deduced from nebular [OI] lines,
the progenitor of SN 2018hna is expected to have an initial main-sequence mass
$<$16 $\mathrm{M_{\odot}}$. In principle, such a relatively low-mass star
cannot end as a BSG just before core-collapse, except some unique mechanisms
are involved, such as rapid rotation, restricted semiconvection, etc. On the
other hand, binary scenario may be more favourable, like in the case of SN
1987A. While the much lower oxygen mass inferred for SN~2018hna may imply that
its progenitor system also had much lower initial masses than that of SN 1987A.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:26:48 GMT""}]","2023-02-08"
"2301.09954","Lukas M\""olschl","Lukas M\""olschl, Jakob J. Hollenstein, Justus Piater","Differentiable Forward Kinematics for TensorFlow 2",,,,,"cs.RO cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robotic systems are often complex and depend on the integration of a large
number of software components. One important component in robotic systems
provides the calculation of forward kinematics, which is required by both
motion-planning and perception related components. End-to-end learning systems
based on deep learning require passing gradients across component
boundaries.Typical software implementations of forward kinematics are not
differentiable, and thus prevent the construction of gradient-based, end-to-end
learning systems. In this paper we present a library compatible with ROS-URDF
that computes forward kinematics while simultaneously giving access to the
gradients w.r.t. joint configurations and model parameters, allowing
gradient-based learning and model identification. Our Python library is based
on Tensorflow~2 and is auto-differentiable. It supports calculating a large
number of kinematic configurations on the GPU in parallel, yielding a
considerable performance improvement compared to sequential CPU-based
calculation. https://github.com/lumoe/dlkinematics.git
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:31:05 GMT""},{""version"":""v2"",""created"":""Fri, 10 Mar 2023 13:51:16 GMT""}]","2023-03-13"
"2301.09955","Yong-Hui Xia","Weijie Lu, Y-H. Xia","Linearization and H\""{o}lder continuity of generalized ODEs with
  application to measure differential equations",,,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  The generalized ordinary differential equations (for short, GODEs) in Banach
space were defined via its solution, which include measure differential
equations, impulsive differential equations, functional differential equations
and the classical ordinary differential equations as special cases. It should
be mentioned that even the symbol $\frac{dx}{d\tau}$ does not indicate that the
solution has a derivative. In this paper, we study the linearization and its
H\""{o}lder continuity of a class of GODEs. Firstly, we construct the formulas
for bounded solutions of the nonlinear GODEs in the Kurzweil integral sense
under the linear GODEs have an exponential dichotomy. Afterwards, we establish
a topological conjugacy between the linear and nonlinear GODEs. Further, we
show that the conjugacies are both H\""{o}lder continuous by using the
Gronwall-type inequality (in the Perron-Stieltjes integral sense) and other
nontrivial estimate techniques. Finally, applications to the measure
differential equations and impulsive differential equations, our results are
very effective.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:33:34 GMT""}]","2023-01-25"
"2301.09956","Hailong Hu","Hailong Hu, Jun Pang","Membership Inference of Diffusion Models",,,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recent years have witnessed the tremendous success of diffusion models in
data synthesis. However, when diffusion models are applied to sensitive data,
they also give rise to severe privacy concerns. In this paper, we
systematically present the first study about membership inference attacks
against diffusion models, which aims to infer whether a sample was used to
train the model. Two attack methods are proposed, namely loss-based and
likelihood-based attacks. Our attack methods are evaluated on several
state-of-the-art diffusion models, over different datasets in relation to
privacy-sensitive data. Extensive experimental evaluations show that our
attacks can achieve remarkable performance. Furthermore, we exhaustively
investigate various factors which can affect attack performance. Finally, we
also evaluate the performance of our attack methods on diffusion models trained
with differential privacy.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:34:27 GMT""}]","2023-01-25"
"2301.09957","Alessandro Traspadini","Alessandro Traspadini, Marco Giordani, Giovanni Giambene and Michele
  Zorzi","Real-Time HAP-Assisted Vehicular Edge Computing for Rural Areas","6 pages, 2 figures. This paper has been accepted for publication at
  IEEE Wireless Communications Letters (WCL). Copyright IEEE 2023. Please cite
  it as: A. Traspadini, M. Giordani, G. Giambene and M. Zorzi, ""Real-Time
  HAP-Assistes Vehicular Edge Computing for Rural Areas,"" in IEEE Wireless
  Communications Letters, doi: 10.1109/LWC.2023.3238851",,"10.1109/LWC.2023.3238851",,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-Terrestrial Networks (NTNs) are expected to be a key component of 6th
generation (6G) networks to support broadband seamless Internet connectivity
and expand the coverage even in rural and remote areas. In this context, High
Altitude Platforms (HAPs) can act as edge servers to process computational
tasks offloaded by energy-constrained terrestrial devices such as Internet of
Things (IoT) sensors and ground vehicles (GVs). In this paper, we analyze the
opportunity to support Vehicular Edge Computing (VEC) via HAP in a rural
scenario where GVs can decide whether to process data onboard or offload them
to a HAP. We characterize the system as a set of queues in which computational
tasks arrive according to a Poisson arrival process. Then, we assess the
optimal VEC offloading factor to maximize the probability of real-time service,
given latency and computational capacity constraints.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:39:25 GMT""}]","2023-01-25"
"2301.09958","Yining Hu","Yining Hu","Algebraic automatic continued fractions in characteristic $2$ II",,,,,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  We present two families of automatic sequences that define algebraic
continued
  fractions in characteristic $2$. The period-doubling sequence belongs
  to the first first family $\mathcal{P}$; and its sum, the Thue-Morse
  sequence, belongs to the second family $\mathcal{G}$. The family
  $\mathcal{G}$ contains all the iterated sums of
  sequences from the $\mathcal{P}$ and more.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:39:49 GMT""}]","2023-01-25"
"2301.09959","Leonardo Chimirri","Leonardo Chimirri","A Quenched Exploration of Heavy Quark Moments and their Perturbative
  Expansion","9 pages, 6 figures",,,"HU-EP-23/04","hep-lat","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The parametric error on the QCD-coupling can be a dominant source of
uncertainty in several important observables. One way to extract the coupling
is to compare high order perturbative computations with lattice evaluated
moments of heavy quark two-point functions. The truncation of the perturbative
series is a sizable systematic uncertainty that needs to be under control. In
this contribution we give an update on our study arXiv:hep-lat/2203.07936v1 on
this issue. We measure pseudo-scalar two-point functions in volumes of $L=2$ fm
with twisted-mass Wilson fermions in the quenched approximation. We use full
twist, the non-perturbative clover term and lattice spacings down to $a=0.010$
fm to tame the large discretization effects. Our results show that both the
continuum extrapolations and the extrapolation of the $\Lambda$-parameter to
the asymptotic perturbative region are very challenging.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:39:52 GMT""}]","2023-01-25"
"2301.09960","Tomonori Kouya","Taiga Utsugiri, Tomonori Kouya","Acceleration of Multiple Precision Matrix Multiplication using Ozaki
  scheme",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Optimized multiple precision basic linear computation, especially matrix
multiplication, is crucial for solving ill-conditioned problems. The recently
proposed Ozaki scheme, which implements accurate matrix multiplication using
existing optimized low precision matrix multiplication, is known to be useful
for multiple precision as well. In this paper, we implement fixed precision
multi-component-way matrix multiplication using Ozaki scheme and show that in
some cases it is faster than existing optimized matrix multiplications. We also
show that arbitrary precision matrix multiplication using Ozaki scheme is also
faster than Strassen matrix multiplication up to a certain precision.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:42:35 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 01:54:21 GMT""}]","2023-01-26"
"2301.09961","Salvatore Tringali","Laura Cossu and Salvatore Tringali","On the finiteness of certain factorization invariants","13 pages, no figures. Changed the title. Improved the presentation.
  Added Corollary 3.3 and a couple of open questions in Sect. 5",,,,"math.RA math.AC math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $H$ be a monoid, $\mathscr F(X)$ be the free monoid on a set $X$, and
$\pi_H$ be the unique extension of the identity map on $H$ to a monoid
homomorphism $\mathscr F(H) \to H$. Given $A \subseteq H$, an $A$-word
$\mathfrak z$ (i.e., an element of $\mathscr F(A)$) is minimal if
$\pi_H(\mathfrak z) \ne \pi_H(\mathfrak z')$ for every permutation $\mathfrak
z'$ of a proper subword of $\mathfrak z$. The minimal $A$-elasticity of $H$ is
then the supremum of all rational numbers $m/n$ with $m, n \in \mathbb N^+$
such that there exist minimal $A$-words $\mathfrak a$ and $\mathfrak b$ of
length $m$ and $n$, resp., with $\pi_H(\mathfrak a) = \pi_H(\mathfrak b)$.
  Most notably, we show that if $H$ is commutative and $A$ is finite, then the
minimal $A$-elasticity of $H$ is finite. This yields a non-trivial
generalization of the finiteness part of a classical theorem of Anderson et al.
(namely, Theorem 7 in [Proc. Amer. Math. Soc. 117 (1993), 37-43]) from the case
where $H$ is cancellative, commutative, and finitely generated (f.g.) modulo
units and $A$ is the set $\mathscr A(H)$ of its atoms. We also check that
commutativity is somewhat essential here, by proving the existence of an
atomic, cancellative, f.g. monoid with trivial group of units whose minimal
$\mathscr A(H)$-elasticity is infinite.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:48:04 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 16:40:21 GMT""}]","2023-03-01"
"2301.09962","Mattias Nilsson","Mattias Nilsson, Ton Juny Pina, Lyes Khacef, Foteini Liwicki,
  Elisabetta Chicca, and Fredrik Sandin","A Comparison of Temporal Encoders for Neuromorphic Keyword Spotting with
  Few Neurons","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.NE eess.AS","http://creativecommons.org/licenses/by/4.0/","  With the expansion of AI-powered virtual assistants, there is a need for
low-power keyword spotting systems providing a ""wake-up"" mechanism for
subsequent computationally expensive speech recognition. One promising approach
is the use of neuromorphic sensors and spiking neural networks (SNNs)
implemented in neuromorphic processors for sparse event-driven sensing.
However, this requires resource-efficient SNN mechanisms for temporal encoding,
which need to consider that these systems process information in a streaming
manner, with physical time being an intrinsic property of their operation. In
this work, two candidate neurocomputational elements for temporal encoding and
feature extraction in SNNs described in recent literature - the spiking
time-difference encoder (TDE) and disynaptic excitatory-inhibitory (E-I)
elements - are comparatively investigated in a keyword-spotting task on
formants computed from spoken digits in the TIDIGITS dataset. While both
encoders improve performance over direct classification of the formant features
in the training data, enabling a complete binary classification with a logistic
regression model, they show no clear improvements on the test set.
Resource-efficient keyword spotting applications may benefit from the use of
these encoders, but further work on methods for learning the time constants and
weights is required to investigate their full potential.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:50:54 GMT""}]","2023-01-25"
"2301.09963","Robert Drost","Robert Drost, Shawulienu Kezilebieke, Jose Lado, Peter Liljeroth","Real-space imaging of dispersive triplon excitations in engineered
  quantum magnets",,,,,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum magnets provide a powerful platform to explore complex quantum
many-body phenomena. One example is triplon excitations, exotic many-body modes
emerging from deconfined singlet-triplet transitions with no single particle
analog. Triplons are challenging to observe in conventional materials, as the
energy scales of singlet-triplet transitions are associated with Hund's energy
and are dramatically larger than the typical bandwidth of spin fluctuations. We
engineer a minimal quantum magnet from organic molecules and demonstrate the
emergence of dispersive triplon modes in one- and two-dimensional assemblies
probed with scanning tunneling microscopy and spectroscopy. We show the
variable bandwidth of triplon excitations in these two different geometries.
Our results provide the first demonstration of dispersive triplon excitations
from a real-space measurement, suggesting their potential engineering to
realize exotic many-body phenomena in quantum magnets without breaking
time-reversal symmetry.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:52:35 GMT""}]","2023-01-25"
"2301.09964","Yawen Cui","Yawen Cui, Wanxia Deng, Haoyu Chen, and Li Liu","Uncertainty-Aware Distillation for Semi-Supervised Few-Shot
  Class-Incremental Learning","Submitted to IEEE Transactions on Neural Networks and Learning
  Systems",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a model well-trained with a large-scale base dataset, Few-Shot
Class-Incremental Learning (FSCIL) aims at incrementally learning novel classes
from a few labeled samples by avoiding overfitting, without catastrophically
forgetting all encountered classes previously. Currently, semi-supervised
learning technique that harnesses freely-available unlabeled data to compensate
for limited labeled data can boost the performance in numerous vision tasks,
which heuristically can be applied to tackle issues in FSCIL, i.e., the
Semi-supervised FSCIL (Semi-FSCIL). So far, very limited work focuses on the
Semi-FSCIL task, leaving the adaptability issue of semi-supervised learning to
the FSCIL task unresolved. In this paper, we focus on this adaptability issue
and present a simple yet efficient Semi-FSCIL framework named Uncertainty-aware
Distillation with Class-Equilibrium (UaD-CE), encompassing two modules UaD and
CE. Specifically, when incorporating unlabeled data into each incremental
session, we introduce the CE module that employs a class-balanced self-training
to avoid the gradual dominance of easy-to-classified classes on pseudo-label
generation. To distill reliable knowledge from the reference model, we further
implement the UaD module that combines uncertainty-guided knowledge refinement
with adaptive distillation. Comprehensive experiments on three benchmark
datasets demonstrate that our method can boost the adaptability of unlabeled
data with the semi-supervised learning technique in FSCIL tasks.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:53:06 GMT""}]","2023-01-25"
"2301.09965","Fr\'ed\'eric Naud","Fr\'ed\'eric Naud","Determinants of Laplacians on random hyperbolic surfaces","20 pages, slightly improved the moments result",,,,"math.SP math.DG","http://creativecommons.org/licenses/by/4.0/","  We investigate the behaviour of the regularized determinant of the
Laplace-Beltrami operator on compact hyperbolic surfaces when the genus goes to
infinity. We show that for all popular models of random surfaces, with high
probability as the genus goes to infinity, the determinant has an exponential
growth with a universal exponent. Limit results for some moments of the
logarithm of the determinant are then derived.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 12:59:02 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 09:06:31 GMT""},{""version"":""v3"",""created"":""Fri, 10 Feb 2023 09:21:10 GMT""}]","2023-02-13"
"2301.09966","G. Senizergues","G. S\'enizergues","Word-Mappings of level $3$","43 pages. 1 figure",,,,"cs.FL cs.CC","http://creativecommons.org/licenses/by/4.0/","  Sequences of numbers (either natural integers, or integers or rational) of
level $k \in \mathbb{N}$ have been defined in \cite{Fra05,Fra-Sen06} as the
sequences which can be computed by deterministic pushdown automata of level
$k$. This definition has been extended to sequences of {\em words} indexed by
{\em words} in \cite{Sen07,Fer-Mar-Sen14}. We characterise here the sequences
of level 3 as the compositions of two HDT0L-systems. Two applications are
derived:
  - the sequences of rational numbers of level 3 are characterised by
polynomial recurrences
  - the equality problem for sequences of rational numbers of level 3 is
decidable.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:02:42 GMT""}]","2023-01-25"
"2301.09967","Maxim Malyshev","Lipatov A.V., Lykasov G.I., Malyshev M.A","Test of the TMD gluon density in a proton with the longitudinal
  structure function $F_L(x,Q^2)$","9 pages, 4 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We investigate the dependence of the deep inelastic proton structure function
$F_L(x, Q^2)$ on different forms of the transverse momentum dependent (TMD, or
unintegrated) gluon distribution. We present a comparison of theoretical
results with the latest experimental data taken by the H1 and ZEUS
Collaborations at HERA. We demonstrate that these data, despite of having quite
large uncertainties, can test different kinds of the gluon TMD in a proton.
Moreover, different phenomenological models at low $x$ could be tested by
future experiments on deep inelastic scattering.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:03:50 GMT""}]","2023-01-25"
"2301.09968","Marc Barthelemy","Jean Cyrus de Gourcuff, David Makowski, Philippe Ciais, Marc
  Barthelemy","Impact of the Ukrainian crisis on the global food security","Main paper and supplementary material",,,,"physics.soc-ph econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using global wheat trade data and a network model for shock propagation, we
study the impact of the Ukrainian crisis on food security. Depending on the
level of reduction in Ukrainian wheat exports, the number of additional
individuals falling under the minimum dietary energy requirement varies from 1
to 9 millions, and reaches about 4.8 millions for a $50\%$ reduction in
exports. In the most affected countries, supply reductions are mainly related
to indirect trade restrictions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:05:38 GMT""}]","2023-01-25"
"2301.09969","Kiumars Sharifmoghaddam","Kiumars Sharifmoghaddam, Rupert Maleczek, Georg Nawratil","Generalizing rigid-foldable tubular structures of T-hedral type","27 pages, 24 figures",,,,"math.DG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We introduce an alternative way of constructing continuous flexible tubes and
tubular structures based on a discrete, semi-discrete and smooth construction
of surfaces known as T-hedra in the discrete case and profile-affine surfaces
in the smooth setting, respectively. The geometric understanding of this method
enables us to generalize discrete tubes with a rigid-foldability and to extend
the construction to smooth and semi-discrete tubes with an isometric
deformation. This achievement implies a unified treatment of continuous
flexible structures, like surfaces and metamaterials, composed of tubes and it
is the base for a deeper study of zipper tubes, and their generalization.
Moreover, we discuss a potential application of the presented structures for
the design of foldable bridges.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:09:02 GMT""}]","2023-01-25"
"2301.09970","Dario Spirito","Dario Spirito","Boundness in almost Dedekind domains",,,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study different form of boundness for ideals of almost Dedekind domains,
generalizing the notions of critical ideals, radical factorization, and
SP-domains. We show that every almost Dedekind domain has at least one
noncritical maximal ideals and, indeed, the set of noncritical maximal ideals
is dense in the maximal space, with respect to the constructible topology; as a
consequence, we show that every almost Dedekind domain is SP-scattered, and in
particular that the group $\mathrm{Inv}(D)$ of invertible ideals of an almost
Dedekind domain $D$ is always free. If $D$ is an almost Dedekind domain with
nonzero Jacobson radical, we also show that there is at least one element whose
ideal function is bounded.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:11:35 GMT""}]","2023-01-25"
"2301.09971","B{\l}azej Jaworowski","B{\l}a\.zej Jaworowski, Michael Iversen, Anne E. B. Nielsen","Approximate Hofstadter- and Kapit-Mueller-like parent Hamiltonians for
  Laughlin states on fractals","12 pages, 10 figures. See the Ancillary Files for the Supplementary
  Material",,,,"cond-mat.str-el cond-mat.dis-nn cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, it was shown that fractional quantum Hall states can be defined on
fractal lattices. Proposed exact parent Hamiltonians for these states are
nonlocal and contain three-site terms. In this work, we look for simpler,
approximate parent Hamiltonians for bosonic Laughlin states at half filling,
which contain only onsite potentials and two-site hopping with the interaction
generated implicitly by hardcore constraints (as in the Hofstadter and
Kapit-Mueller models on periodic lattices). We use an ``inverse method'' to
determine such Hamiltonians on finite-generation Sierpi\'{n}ski carpet and
triangle lattices. The ground states of some of the resulting models display
relatively high overlap with the model states if up to third neighbor hopping
terms are considered, and by increasing the maximum hopping distance one can
achieve nearly perfect overlaps. When the number of particles is reduced and
additional potentials are introduced to trap quasiholes, the overlap with a
model quasihole wavefunction is also high in some cases, especially for the
nonlocal Hamiltonians. We also study how the small system size affects the
braiding properties for the model quasihole wavefunctions and perform analogous
computations for Hamiltonian models.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:16:14 GMT""}]","2023-01-25"
"2301.09976","Luke Thorburn","Aviv Ovadya, Luke Thorburn","Bridging Systems: Open Problems for Countering Destructive Divisiveness
  across Ranking, Recommenders, and Governance","40 pages, 11 figures. See https://bridging.systems for more about
  this work",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Divisiveness appears to be increasing in much of the world, leading to
concern about political violence and a decreasing capacity to collaboratively
address large-scale societal challenges. In this working paper we aim to
articulate an interdisciplinary research and practice area focused on what we
call bridging systems: systems which increase mutual understanding and trust
across divides, creating space for productive conflict, deliberation, or
cooperation. We give examples of bridging systems across three domains:
recommender systems on social media, collective response systems, and
human-facilitated group deliberation. We argue that these examples can be more
meaningfully understood as processes for attention-allocation (as opposed to
""content distribution"" or ""amplification"") and develop a corresponding
framework to explore similarities - and opportunities for bridging - across
these seemingly disparate domains. We focus particularly on the potential of
bridging-based ranking to bring the benefits of offline bridging into spaces
which are already governed by algorithms. Throughout, we suggest research
directions that could improve our capacity to incorporate bridging into a world
increasingly mediated by algorithms and artificial intelligence.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:26:42 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 14:03:19 GMT""}]","2023-04-21"
"2301.09978","Sara Bertocco","Giuliano Taffoni, Sara Bertocco, Dave Morris, Manu Parra-Roy\'on,
  Klaas Kliffen, Marco Molinaro, John Swinbank, Susana Sanchez Exposito","Feasibility of access EGI resources through the ESCAPE developed ESFRI
  Science Analysis Platform","Will be published in ADASS XXXII Proceedings - Astronomical Society
  of the Pacific Conference Series",,,,"astro-ph.IM cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The EU ESCAPE project is developing ESAP, ESFRI 1 Scientific Analysis
Platform, as an API gateway that enables the seamless integration of
independent services accessing distributed data and computing resources. In
ESCAPE we are exploring the possibility of exploiting EGI's OpenStack cloud
computing services through ESAP. In our contribution we briefly describe ESCAPE
and ESAP, the the use cases, the work done to automate a virtual machine
creation in EGI's OpenStack cloud computing, drawbacks and possible solutions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:53:20 GMT""}]","2023-01-25"
"2301.09979","Zolt\'an L. Bl\'azsik","J\'anos Bar\'at, Zolt\'an L. Bl\'azsik","General sharp upper bounds on the total coalition number","This updated version contains a complete answer for Problem 4.7 of
  the first version",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $G(V,E)$ be a finite, simple, isolate-free graph. Two disjoint sets
$A,B\subset V$ form a total coalition in $G$, if none of them is a total
dominating set, but their union $A\cup B$ is a total dominating set. A vertex
partition $\Psi=\{C_1,C_2,\dots,C_k\}$ is a total coalition partition, if none
of the partition classes is a total dominating set, meanwhile for every
$i\in\{1,2,\dots,k\}$ there exists a distinct $j\in\{1,2,\dots,k\}$ such that
$C_i$ and $C_j$ form a total coalition. The maximum cardinality of a total
coalition partition of $G$ is the total coalition number of $G$ and denoted by
$TC(G)$. We give a general sharp upper bound on the total coalition number as a
function of the maximum degree. We further investigate this optimal case and
study the total coalition graph. We show that every graph can be realised as a
total coalition graph.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:28:13 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 22:06:56 GMT""},{""version"":""v3"",""created"":""Tue, 7 Feb 2023 09:04:13 GMT""}]","2023-02-08"
"2301.09981","Zhen Zhang","Zhen Zhang, Shaofu Yang, and Wenying Xu","Decentralized ADMM with Compressed and Event-Triggered Communication",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the decentralized optimization problem, where agents in
a network cooperate to minimize the sum of their local objective functions by
information exchange and local computation. Based on the alternating direction
method of multipliers (ADMM), we propose CC-DQM, a communication-efficient
decentralized second-order optimization algorithm that combines compressed
communication with event-triggered communication. Specifically, agents are
allowed to transmit the compressed message only when the current primal
variables have changed greatly compared to its last estimate. Moreover, to
relieve the computation cost, the update of Hessian is scheduled by the trigger
condition. To maintain exact linear convergence under compression, we compress
the difference between the information to be transmitted and its estimate by a
general contractive compressor. Theoretical analysis shows that CC-DQM can
still achieve an exact linear convergence, despite the existence of compression
error and intermittent communication, if the objective functions are strongly
convex and smooth. Finally, we validate the performance of CC-DQM by numerical
experiments.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:29:52 GMT""}]","2023-01-25"
"2301.09982","Stephanie Von Hinke","Gerard J. van den Berg, Stephanie von Hinke, R. Adele H. Wang","Prenatal Sugar Consumption and Late-Life Human Capital and Health:
  Analyses Based on Postwar Rationing and Polygenic Scores",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Maternal sugar consumption in utero may have a variety of effects on
offspring. We exploit the abolishment of the rationing of sweet confectionery
in the UK on April 24, 1949, and its subsequent reintroduction some months
later, in an era of otherwise uninterrupted rationing of confectionery
(1942-1953), sugar (1940-1953) and many other foods, and we consider effects on
late-life cardiovascular disease, BMI, height, type-2 diabetes and the intake
of sugar, fat and carbohydrates, as well as cognitive outcomes and birth
weight. We use individual-level data from the UK Biobank for cohorts born
between April 1947-May 1952. We also explore whether one's genetic
""predisposition"" to the outcome can moderate the effects of prenatal sugar
exposure. We find that prenatal exposure to derationing increases education and
reduces BMI and sugar consumption at higher ages, in line with the
""developmental origins"" explanatory framework, and that the sugar effects are
stronger for those who are genetically ""predisposed"" to sugar consumption.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:30:40 GMT""}]","2023-01-25"
"2301.09983","Liora Rueff","Habib Ammari, Jinghao Cao, Erik Orvehed Hiltunen, Liora Rueff","Transmission properties of time-dependent one-dimensional metamaterials","23 pages, 11 figures",,,,"math.AP math-ph math.MP physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We solve the wave equation with periodically time-modulated material
parameters in a one-dimensional high-contrast resonator structure in the
subwavelength regime exactly, for which we compute the subwavelength
quasifrequencies numerically using Muller's method. We prove a formula in the
form of an ODE using a capacitance matrix approximation. Comparison of the
exact results with the approximations reveals that the method of capacitance
matrix approximation is accurate and significantly more efficient. We prove
various transmission properties in the aforementioned structure and illustrate
them with numerical simulations. In particular, we investigate the effect of
time-modulated material parameters on the formation of degenerate points, band
gaps and k-gaps.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:30:54 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 09:02:18 GMT""}]","2023-06-01"
"2301.09987","Su Hyeong Lee","Su Hyeong Lee","Chemical Integration of ODEs using Idealized Abstract Solutions",,,,,"q-bio.MN math.DS","http://creativecommons.org/licenses/by/4.0/","  In this work, we propose a general inversion framework to non-uniquely invert
a very large class of ordinary differential equations (ODEs) into chemical
reaction networks. A thorough treatment of the relevant chemical reaction
network theory from the literature is given. Various simulation results are
provided to augment the selection procedure for the inverse framework, where a
previously known kineticization strategy is shown to be deterministically
excellent but undesirable in chemical simulations. The utility of the framework
is verified by simulating reaction network forms of meaningful ODE systems, and
their time series are analyzed. In particular, we provide simulations of
deterministic chaotic attractors whose newly discovered reaction networks are
non-equivalent with any existing chemical interpretations within the
literature, as well as presenting exemplary figures which may form a roadmap to
the successful biochemical implementation of the integration of ODE systems.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 17:14:00 GMT""}]","2023-01-25"
"2301.09991","Toby Phillips","T. R. F. Phillips, C. E. Heaney, C. Boyang, A. G. Buchan, C. C. Pain","Solving the Discretised Boltzmann Transport Equations using Neural
  Networks: Applications in Neutron Transport",,,,,"cs.CE cs.LG physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we solve the Boltzmann transport equation using AI libraries.
The reason why this is attractive is because it enables one to use the highly
optimised software within AI libraries, enabling one to run on different
computer architectures and enables one to tap into the vast quantity of
community based software that has been developed for AI and ML applications
e.g. mixed arithmetic precision or model parallelism. Here we take the first
steps towards developing this approach for the Boltzmann transport equation and
develop the necessary methods in order to do that effectively. This includes:
1) A space-angle multigrid solution method that can extract the level of
parallelism necessary to run efficiently on GPUs or new AI computers. 2) A new
Convolutional Finite Element Method (ConvFEM) that greatly simplifies the
implementation of high order finite elements (quadratic to quintic, say). 3) A
new non-linear Petrov-Galerkin method that introduces dissipation
anisotropically.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:37:50 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 10:59:21 GMT""}]","2023-01-26"
"2301.09992","Tariq Alhindi","Tariq Alhindi, Tuhin Chakrabarty, Elena Musi and Smaranda Muresan","Multitask Instruction-based Prompting for Fallacy Recognition","In Proceedings of the 2022 Conference on Empirical Methods in Natural
  Language Processing, pages 8172 - 8187","Proceedings of the 2022 Conference on Empirical Methods in Natural
  Language Processing, pages 8172 - 8187",,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Fallacies are used as seemingly valid arguments to support a position and
persuade the audience about its validity. Recognizing fallacies is an
intrinsically difficult task both for humans and machines. Moreover, a big
challenge for computational models lies in the fact that fallacies are
formulated differently across the datasets with differences in the input format
(e.g., question-answer pair, sentence with fallacy fragment), genre (e.g.,
social media, dialogue, news), as well as types and number of fallacies (from 5
to 18 types per dataset). To move towards solving the fallacy recognition task,
we approach these differences across datasets as multiple tasks and show how
instruction-based prompting in a multitask setup based on the T5 model improves
the results against approaches built for a specific dataset such as T5, BERT or
GPT-3. We show the ability of this multitask prompting approach to recognize 28
unique fallacies across domains and genres and study the effect of model size
and prompt choice by analyzing the per-class (i.e., fallacy type) results.
Finally, we analyze the effect of annotation quality on model performance, and
the feasibility of complementing this approach with external knowledge.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:39:23 GMT""}]","2023-01-25"
"2301.09993","Stefan Zetzsche","Stefan Zetzsche","Isomorphism Classes of Vertex-Transitive Tournaments","Bachelor thesis",,,,"math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tournaments are graphs obtained by assigning a direction for every edge in an
undirected complete graph. We give a formula for the number of isomorphism
classes of vertex-transitive tournaments with prime order. For that, we
introduce Cayley tournaments, which are special Cayley digraphs, and show that
there is a one to one identification between the isomorphism classes of
vertex-transitive tournaments with prime order and the isomorphism classes of
Cayley tournaments with prime order.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:44:19 GMT""}]","2023-01-25"
"2301.09994","Elizabeth Robertson","Mingwei Yang, Elizabeth Robertson, Luisa Esguerra, Kurt Busch and
  Janik Wolters","Optical convolutional neural network with atomic nonlinearity",,,"10.1364/OE.490070",,"physics.optics cs.ET","http://creativecommons.org/licenses/by/4.0/","  Due to their high degree of parallelism, fast processing speeds and low power
consumption, analog optical functional elements offer interesting routes for
realizing neuro-morphic computer hardware. For instance, convolutional neural
networks lend themselves to analog optical implementations by exploiting the
Fourier-transform characteristics of suitable designed optical setups. However,
the efficient implementation of optical nonlinearities for such neural networks
still represents challenges. In this work, we report on the realization and
characterization of a three-layer optical convolutional neural network where
the linear part is based on a 4f-imaging system and the optical nonlinearity is
realized via the absorption profile of a cesium atomic vapor cell. This system
classifies the handwritten digital dataset MNIST with 83.96% accuracy, which
agrees well with corresponding simulations. Our results thus demonstrate the
viability of utilizing atomic nonlinearities in neural network architectures
with low power consumption.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:44:27 GMT""}]","2023-05-17"
"2301.09995","Mikael Chala","Mikael Chala","Constraints on anomalous dimensions from the positivity of the S-matrix","17 pages, 3 figures",,,,"hep-ph hep-th","http://creativecommons.org/licenses/by-sa/4.0/","  We show that the analyticity and crossing symmetry of the S-matrix, together
with the optical theorem, impose restrictions on the renormalisation group
evolution of dimension-eight operators in the Standard Model Effective Field
Theory. Moreover, in the appropriate basis of operators, the latter manifest as
zeros in the anomalous dimension matrix that, to the best of our knowledge,
have not been anticipated anywhere else in the literature. Our results can be
trivially extended to other effective field theories.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:44:42 GMT""}]","2023-01-25"
"2301.09996","Richard Martin","Richard J. Martin","Black-Scholes without stochastics or PDEs","Added S1.7 on derivation of the delta",,,,"q-fin.PR math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We show how to derive the Black-Scholes model and its generalisation to the
`exchange-option' (to exchange one asset for another) via the continuum limit
of the Binomial tree. No knowledge of stochastic calculus or partial
differential equations is assumed, as we do not use them.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:47:47 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 15:36:06 GMT""}]","2023-04-04"
"2301.09997","Satoshi Kura","Satoshi Kura","Higher-Order Weakest Precondition Transformers via a CPS Transformation",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weakest precondition transformers are essential notions for program
verification, and various extensions have been studied. However, only a few
consider both higher-order languages and syntactic calculation of weakest
precondition transformers. In this paper, we consider weakest precondition
transformers for a higher-order functional language with computational effects
and recursion and show that we can calculate them via a CPS transformation. We
prove this in a general framework of categorical semantics. Because of this
generality, two existing methods for program verification can be understood as
instances of our result. Specifically, we show how to instantiate our result to
(1) verification of trace properties by Kobayashi et al. and (2) expected cost
analysis by Avanzini et al.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:49:48 GMT""}]","2023-01-25"
"2301.09998","Andrei Nefiodov","Anastassia M. Makarieva, Andrei V. Nefiodov, Anja Rammig, Antonio
  Donato Nobre","Re-appraisal of the global climatic role of natural forests for improved
  climate projections and policies","17 pages, 5 figures, 1 table",,,,"physics.ao-ph physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  Along with the accumulation of atmospheric carbon dioxide, the loss of
primary forests and other natural ecosystems is a major disruption of the Earth
system causing global concern. Quantifying planetary warming from carbon
emissions, global climate models highlight natural forests' high carbon storage
potential supporting conservation policies. However, some model outcomes
effectively deprioritize conservation of boreal and temperate forests
suggesting that increased albedo upon deforestation could cool the planet.
Potential conflict of global cooling versus regional forest conservation could
harm environmental policies. Here we present theoretical and observational
evidence to demonstrate that, compared to the carbon-related warming, the model
skills for assessing climatic impacts of deforestation is low. We argue that
deforestation-induced global cooling results from the models' limited capacity
to account for the global effect of cooling from evapotranspiration of intact
forests. Transpiration of trees can change the greenhouse effect via small
modifications of the vertical temperature profile. Due to their convective
parameterization (which postulates a certain critical temperature profile),
global climate models do not properly capture this effect. This
parameterization may lead to underestimation of warming from the loss of
evapotranspiration in both high and low latitidues, and therefore, conclusions
about deforestation-induced global cooling are not robust. To avoid deepening
the environmental crisis, these conclusions should not inform policies of
vegetation cover management. Studies are mounting quantifying the stabilizing
impact of natural ecosystems evolved to maintain environmental homeostasis.
Given the critical state and our limited understanding of both climate and
ecosystems, an optimal policy would be a global moratorium on the exploitation
of all natural forests.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:50:45 GMT""}]","2023-01-25"
"2301.09999","Angela Malizia","A. Malizia (INAF-OAS Bologna, Italy), L. Bassani (INAF-OAS Bologna,
  Italy), R. Landi (INAF-OAS Bologna, Italy), M. Molina (INAF-IASF Milano,
  Italy), N. Masetti (INAF-OAS Bologna, Italy, Instituto de Astrofisica,
  Facultad de Ciencias Exactas, Universidad Andres Bello Santiago, Chile), E.
  Palazzi (INAF-OAS Bologna, Italy), G. Bruni (INAF-IAPS Roma, Italy), A.
  Bazzano (INAF-IAPS Roma, Italy), P. Ubertini (INAF-IAPS Roma, Italy), A. J.
  Bird (University of Southampton, UK)","Update of the INTEGRAL/IBIS AGN catalogue: deeper on the Galactic plane
  and wider beyond","18 pages, 13 figures. Accepted for publication in Astronomy &
  Astrophysics",,"10.1051/0004-6361/202245495",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  In this work we have updated the list of AGN detected by INTEGRAL taking into
account the new objects listed in the last published INTEGRAL/IBIS survey. We
have collected 83 new AGN increasing the number of INTEGRAL detected active
galaxies (436) by 19%. Half of these new additions are located behind the
Galactic plane; for most of them we have full X-ray coverage obtained through
archival data from Swift/XRT, XMM-Newton and NuSTAR. This allowed us to
associate each high-energy emitter with a single or multiple X-ray
counterpart/s and characterise the spectral shape of these new AGN by
estimating the photon index, the intrinsic absorption and the 2-10 keV flux. A
few cases where two soft X-ray counterparts fall within the INTEGRAL error
circle and at least one is classified as an AGN have been found and discussed
in detail. Thirty-four sources originally listed as AGN candidates or
unidentified objects have been recognised as AGN by employing three diagnostic
tests: WISE colours, radio emission and morphology. For 12 sources, among the
34 AGN candidates, we reduced optical spectra and confirmed their AGN nature,
providing also their optical class and redshift. This paper is part of an
on-going effort to keep the INTEGRAL AGN catalogue updated in order to provide
the scientific community with a hard X-ray selected sample of active galaxies
well classified and spectrally characterised.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:51:01 GMT""}]","2023-03-29"
"2301.10000","Sayantan Choudhury","Sayantan Choudhury, Mayukh R. Gangopadhyay, M. Sami","No-go for the formation of heavy mass Primordial Black Holes in Single
  Field Inflation","29 pages, 4 figures, Updated version, Reference added and typos
  corrected, Latex Style and format updated, Comments are welcome",,,,"astro-ph.CO gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the possibility of Primordial Black Holes (PBHs) formation in
single-field models of inflation. We show that a one-loop correction to the
renormalized primordial power spectrum rules out the possibility of having
large mass PBHs. We consider a framework in which PBHs are produced during the
transition from Slow Roll (SR) to Ultra Slow Roll (USR) followed by the end of
inflation. We demonstrate that the Dynamical Renormalization Group (DRG)
resummed power spectrum severely restricts the possible mass range of produced
PBHs in the said transition, namely, $M_{\rm PBH}\sim 10^{2}{\rm gm}$
$\widehat{a}$ la a no-go theorem. In particular, we find that the produced PBHs
are short-lived ($t^{\rm evap}_{\rm PBH}\sim 10^{-17}{\rm sec}$) and the
corresponding number of e-folds in the USR region is restricted to $\Delta
N_{\rm USR}\approx 2$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:51:30 GMT""},{""version"":""v2"",""created"":""Fri, 27 Jan 2023 12:29:32 GMT""},{""version"":""v3"",""created"":""Mon, 20 Mar 2023 13:33:09 GMT""}]","2023-03-21"
"2301.10002","Ilias Rentzeperis","Ilias Rentzeperis, Luca Calatroni, Laurent Perrinet, Dario Prandi","Beyond $\ell_1$ sparse coding in V1",,,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Growing evidence indicates that only a sparse subset from a pool of sensory
neurons is active for the encoding of visual stimuli at any instant in time.
Traditionally, to replicate such biological sparsity, generative models have
been using the $\ell_1$ norm as a penalty due to its convexity, which makes it
amenable to fast and simple algorithmic solvers. In this work, we use
biological vision as a test-bed and show that the soft thresholding operation
associated to the use of the $\ell_1$ norm is highly suboptimal compared to
other functions suited to approximating $\ell_q$ with $0 \leq q < 1 $
(including recently proposed Continuous Exact relaxations), both in terms of
performance and in the production of features that are akin to signatures of
the primary visual cortex. We show that $\ell_1$ sparsity produces a denser
code or employs a pool with more neurons, i.e. has a higher degree of
overcompleteness, in order to maintain the same reconstruction error as the
other methods considered. For all the penalty functions tested, a subset of the
neurons develop orientation selectivity similarly to V1 neurons. When their
code is sparse enough, the methods also develop receptive fields with varying
functionalities, another signature of V1. Compared to other methods, soft
thresholding achieves this level of sparsity at the expense of much degraded
reconstruction performance, that more likely than not is not acceptable in
biological vision. Our results indicate that V1 uses a sparsity inducing
regularization that is closer to the $\ell_0$ pseudo-norm rather than to the
$\ell_1$ norm.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:53:07 GMT""},{""version"":""v2"",""created"":""Wed, 25 Jan 2023 13:04:38 GMT""}]","2023-01-26"
"2301.10004","Ivo Mihov","Ivo S. Mihov and Nikolay V. Vitanov","Pulse shape effects in qubit dynamics demonstrated on an IBM quantum
  computer","9 pages including appendix and references, 5 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a study of the coherent interaction of a qubit with a pulse-shaped
external field of a constant carrier frequency. We explore, theoretically and
experimentally, the transition line profile -- the dependence of the transition
probability on the detuning -- for five different pulse shapes: rectangular,
Gaussian, hyperbolic-secant, squared hyperbolic-secant and exponential. The
theoretical description for all cases but sech$^2$ is based on the analytical
solutions to the Schr\""odinger equation or accurate approximations available in
the literature. For the sech$^2$ pulse we derive an analytical expression for
the transition probability using the Rosen-Zener conjecture, which proves very
accurate. The experimental results are obtained with one of IBM's quantum
processors. An excellent agreement between theory and experiment is observed,
demonstrating some pulse-shape-dependent fine features of the transition
probability profile. The divergence index -- a measure of the accuracy of the
fit -- features an improvement by a factor of 4 to 7 for the analytic models
compared to the commonly used (sinc$^2$ and Lorentzian) baseline fits.
Moreover, we observe a reduction by about a factor of about 4 of the error bars
of the resonance frequency of the qubit for the analytic models compared to the
baseline fits. These results demonstrate both the accuracy of the analytic
modelling of quantum dynamics and the excellent coherent properties of IBM's
qubit.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:54:22 GMT""}]","2023-01-25"
"2301.10008","Xiao He","Xiao He, Mingrui Zhu, Nannan Wang, Xinbo Gao and Heng Yang","Few-shot Font Generation by Learning Style Difference and Similarity","11 pages",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot font generation (FFG) aims to preserve the underlying global
structure of the original character while generating target fonts by referring
to a few samples. It has been applied to font library creation, a personalized
signature, and other scenarios. Existing FFG methods explicitly disentangle
content and style of reference glyphs universally or component-wisely. However,
they ignore the difference between glyphs in different styles and the
similarity of glyphs in the same style, which results in artifacts such as
local distortions and style inconsistency. To address this issue, we propose a
novel font generation approach by learning the Difference between different
styles and the Similarity of the same style (DS-Font). We introduce contrastive
learning to consider the positive and negative relationship between styles.
Specifically, we propose a multi-layer style projector for style encoding and
realize a distinctive style representation via our proposed Cluster-level
Contrastive Style (CCS) loss. In addition, we design a multi-task patch
discriminator, which comprehensively considers different areas of the image and
ensures that each style can be distinguished independently. We conduct
qualitative and quantitative evaluations comprehensively to demonstrate that
our approach achieves significantly better results than state-of-the-art
methods.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:57:25 GMT""}]","2023-01-25"
"2301.10011","Egbert Rijke","\'El\'eonore Mangel, Egbert Rijke","Delooping the sign homomorphism in univalent mathematics",,,,,"math.GR math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In univalent mathematics there are at least two equivalent ways to present
the category of groups. Groups presented in their usual algebraic form are
called abstract groups, and groups presented as pointed connected $1$-types are
called concrete groups. Since these two descriptions of the category of groups
are equivalent, we find that every algebraic group corresponds uniquely to a
concrete group -- its delooping -- and that each abstract group homomorphisms
corresponds uniquely to a pointed map between concrete groups.
  The $n$-th abstract symmetric group $S_n$ of all bijections $[n]\simeq [n]$,
for instance, corresponds to the concrete group of all $n$-element types. The
sign homomorphism from $S_n$ to $S_2$ should therefore correspond to a pointed
map from the type $BS_n$ of all $n$-element types to the type $BS_2$ of all
$2$-element types. Making use of the univalence axiom, we characterize
precisely when a pointed map $BS_n\to_\ast BS_2$ is a delooping of the sign
homomorphism. Then we proceed to give several constructions of the delooping of
the sign homomorphism. Notably, the construction following a method of Cartier
can be given without reference to the sign homomorphism. Our results are
formalized in the agda-unimath library.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:58:21 GMT""}]","2023-01-25"
"2301.10017","Sascha Heu{\ss}en","Sascha Heu{\ss}en, Lukas Postler, Manuel Rispler, Ivan Pogorelov,
  Christian D. Marciniak, Thomas Monz, Philipp Schindler and Markus M\""uller","Strategies for practical advantage of fault-tolerant circuit design in
  noisy trapped-ion quantum computers","36 pages, 26 figures",,"10.1103/PhysRevA.107.042422",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fault-tolerant quantum error correction provides a strategy to protect
information processed by a quantum computer against noise which would otherwise
corrupt the data. A fault-tolerant universal quantum computer must implement a
universal gate set on the logical level in order to perform arbitrary
calculations to in principle unlimited precision. We characterize the recent
demonstration of a fault-tolerant universal gate set in a trapped-ion quantum
computer [Postler et al. Nature 605.7911 (2022)] and identify aspects to
improve the design of experimental setups to reach an advantage of logical over
physical qubit operation. We show that various criteria to assess the
break-even point for fault-tolerant quantum operations are within reach for the
ion trap quantum computing architecture under consideration. We analyze the
influence of crosstalk in entangling gates for logical state preparation
circuits. These circuits can be designed to respect fault tolerance for
specific microscopic noise models. We find that an experimentally-informed
depolarizing noise model captures the essential noise dynamics of the
fault-tolerant experiment, and crosstalk is negligible in the currently
accessible regime of physical error rates. For deterministic Pauli state
preparation, we provide a fault-tolerant unitary logical qubit initialization
circuit, which can be realized without in-sequence measurement and feed-forward
of classical information. We show that non-deterministic state preparation
schemes for logical Pauli and magic states perform with higher logical fidelity
over their deterministic counterparts for the current and anticipated future
regime of physical error rates. Our results offer guidance on improvements of
physical qubit operations and validate the experimentally-informed noise model
as a tool to predict logical failure rates in quantum computing architectures
based on trapped ions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:01:48 GMT""}]","2023-04-26"
"2301.10019","Tristan Bruel","T. Bruel, M-A. Bizouard, M. Obergaulinger, P. Maturana-Russel, A.
  Torres-Forn\'e, P. Cerd\'a-Dur\'an, N. Christensen, J. A. Font, R. Meyer","Inference of proto-neutron star properties in core-collapse supernovae
  from a gravitational-wave detector network",,,"10.1103/PhysRevD.107.083029",,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The next Galactic core-collapse supernova (CCSN) will be a unique opportunity
to study within a fully multi-messenger approach the explosion mechanism
responsible for the formation of neutron stars and stellar-mass black holes.
State-of-the-art numerical simulations of those events reveal the complexity of
the gravitational-wave emission which is highly stochastic. This challenges the
possibility to infer the properties of the compact remnant and of its
progenitor using the information encoded in the waveforms. In this paper we
take further steps in a program we recently initiated to overcome those
difficulties. In particular we show how oscillation modes of the proto-neutron
star, highly visible in the gravitational-wave signal, can be used to
reconstruct the time evolution of their physical properties. Extending our
previous work where only the information from a single detector was used we
here describe a new data-analysis pipeline that coherently combines
gravitational-wave detectors' data and infers the time evolution of a
combination of the mass and radius of the compact remnant. The performance of
the method is estimated employing waveforms from 2D and 3D CCSN simulations
covering a progenitor mass range between 11$\mathrm{M_{\odot}}$\, and
40$\mathrm{M_{\odot}}$\, and different equations of state for both a network of
up to five second-generation detectors and the proposed third-generation
detectors Einstein Telescope and Cosmic Explorer. Our study shows that it will
be possible to infer PNS properties for CCSN events occurring in the vicinity
of the Milky Way, up to the Large Magellanic Cloud, with the current generation
of gravitational-wave detectors.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:05:58 GMT""}]","2023-05-03"
"2301.10020","Jaydeb Sarkar","Deepak K. D. and Jaydeb Sarkar","Commutant lifting, interpolation, and perturbations on the polydisc","56 pages. Thoroughly revised, new results, sections, and examples",,,,"math.FA math.CV math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fundamental theorem on commutant lifting due to Sarason does not carry
over to the setting of the polydisc. This paper presents two classifications of
commutant lifting in several variables. The first classification links the
lifting problem to the contractivity of certain linear functionals. The second
one transforms it into nonnegative real numbers. We also solve the
Nevanlinna-Pick interpolation problem for bounded analytic functions on the
polydisc. Along the way, we solve a perturbation problem for bounded analytic
functions. Commutant lifting and interpolation on the polydisc solve two
well-known problems in Hilbert function space theory.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:06:04 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 07:24:57 GMT""}]","2023-04-19"
"2301.10021","Jerome Rech","B. Bertin-Johannet, L. Raymond, J. Rech, T. Jonckheere, B. Gr\'emaud,
  D. C. Glattli, T. Martin","Photo-assisted current in the fractional quantum Hall effect as a probe
  of the quasiparticle operator scaling dimension","18 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We study photo-assisted transport for the edge states of a two dimensional
electron gas in the fractional quantum Hall regime, pinched by a single quantum
point contact. We provide a general expression of the photo-assisted current
using a Keldysh-Floquet approach, when the AC drive is applied either directly
to the edge states, or when it modulates the tunneling amplitude at the quantum
point contact. Strikingly, for a simple cosine modulation of the tunneling
amplitude, the phase shift of the second harmonic of the photoassisted current
is directly related to the scaling dimension of the quasiparticle operators
describing the fractional excitations. As the scaling dimension is intimately
related to the statistics, our proposal of a gate modulation of the
backscattered current provides a diagnosis of the statistics of Laughlin
quasiparticles using a simple quantum point contact geometry.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:09:33 GMT""}]","2023-01-25"
"2301.10022","Yang Tian","Wei Xiong, Xiaomeng Huang, Ziyang Zhang, Ruixuan Deng, Pei Sun, Yang
  Tian","Koopman neural operator as a mesh-free solver of non-linear partial
  differential equations",,,,,"cs.LG cs.NA math.NA physics.comp-ph physics.data-an physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The lacking of analytic solutions of diverse partial differential equations
(PDEs) gives birth to series of computational techniques for numerical
solutions. In machine learning, numerous latest advances of solver designs are
accomplished in developing neural operators, a kind of mesh-free approximators
of the infinite-dimensional operators that map between different
parameterization spaces of equation solutions. Although neural operators
exhibit generalization capacities for learning an entire PDE family
simultaneously, they become less accurate and explainable while learning
long-term behaviours of non-linear PDE families. In this paper, we propose
Koopman neural operator (KNO), a new neural operator, to overcome these
challenges. With the same objective of learning an infinite-dimensional mapping
between Banach spaces that serves as the solution operator of target PDE
family, our approach differs from existing models by formulating a non-linear
dynamic system of equation solution. By approximating the Koopman operator, an
infinite-dimensional linear operator governing all possible observations of the
dynamic system, to act on the flow mapping of dynamic system, we can
equivalently learn the solution of an entire non-linear PDE family by solving
simple linear prediction problems. In zero-shot prediction and long-term
prediction experiments on representative PDEs (e.g., the Navier-Stokes
equation), KNO exhibits notable advantages in breaking the tradeoff between
accuracy and efficiency (e.g., model size) while previous state-of-the-art
models are limited. These results suggest that more efficient PDE solvers can
be developed by the joint efforts from physics and machine learning.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:10:15 GMT""}]","2023-01-25"
"2301.10024","Yogesh Shelke","Yogesh Shelke (1), Fabrizio Camerin (2), Susana Mar\'in-Aguilar (2),
  Ruben W. Verweij (1), Marjolein Dijkstra (2) and Daniela J. Kraft (1) ((1)
  Soft Matter Physics, Huygens-Kamerlingh Onnes Laboratory, Leiden University,
  The Netherlands, (2) Soft Condensed Matter, Debye Institute for Nanomaterials
  Science, Utrecht University, The Netherlands)","Flexible Colloidal Molecules with Directional Bonds and Controlled
  Flexibility",,,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Colloidal molecules are ideal model systems for mimicking real molecules and
can serve as versatile building blocks for the bottom-up self-assembly of
flexible and smart materials. While most colloidal molecules are rigid objects,
the development of colloidal joints has made it possible to also include
conformational flexibility into colloidal molecules. However, their
unrestricted range of motion does not capture the restricted motion range and
bond directionality that is typical of real molecules.
  In this work, we create flexible colloidal molecules with an in situ
controllable motion range and bond directionality by assembling spherical
particles onto cubes functionalized with complementary surface-mobile DNA. We
assemble colloidal molecules with different coordination number of spheres by
varying the size ratio and find that they feature a constrained range of motion
above a critical size ratio. Using theory and simulations, we show that the
particle shape together with the multivalent bonds create an effective
free-energy landscape for the motion of the sphere on the surface of the cube.
We quantify the confinement of the spheres on the surface of the cube and the
probability to change facet. We find that temperature can be used as an extra
control parameter to switch in situ between full and constrained flexibility of
these colloidal molecules. These flexible colloidal molecules with temperature
switching motion range can be used to investigate the effect of directional,
yet flexible bonds in determining their self-assembly and phase behavior, and
may be employed as constructional units in microrobotics and novel smart
materials
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 16:43:56 GMT""}]","2023-01-25"
"2301.10027","Isaac Harris","Rafael Ceja Ayala and Isaac Harris","Reconstruction of small and extended scatterers with a conductive
  boundary using far-field data","There is an updated version with a new focus and new coauthor",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we consider the inverse shape problem of recovering small and
extended isotropic scatterers with a conductive boundary condition. Here, we
assume that the measured far-field data is known at a fixed wave number. We
will provide qualitative reconstruction methods for recovering either small or
extended scatterers. For the case of small scatterers, we model this by a
region(possibly with multiple components) with small volume. We derive an
asymptotic expansion for the far-field pattern which will allow us to study the
MUSIC algorithm for solving the problem. In the case of an extended scatterer,
we derive a new factorization of the far-field operator. This is then used to
provide the resolution analysis for a direct sampling method. The theoretical
results are verified with some numerical experiments in 2--dimensions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:12:41 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 16:22:26 GMT""}]","2023-05-25"
"2301.10029","Mojtaba Bakherad","Mojtaba Bakherad","A generalization of the norm inequalities for sums of operators",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Let ${\mathbb B}(\mathscr H)$ denote the set of all bounded linear operators
on a complex Hilbert space ${\mathscr H}$. In this paper, we present some norm
inequalities for sums of operators which are a generalization of some recent
results. Among other inequalities, it is shown that if $S, T\in {\mathbb
B}({\mathscr H})$ are normal operators, then \begin{eqnarray*} \left\Vert
S+T\right\Vert \leq \frac{1}{2}(\left\Vert S\right\Vert+\left\Vert
T\right\Vert)+\frac{1}{2}\min_{t>0}\sqrt{ (\left\Vert S \right\Vert-\left\Vert
T\right\Vert)^2+ \left\Vert \frac{1}{t} f_1(\vert S \vert)g_1(\vert
T\vert)+tf_2(\vert S \vert)g_2(\vert T\vert) \right\Vert^2}, \end{eqnarray*}
where $f_1,f_2,g_1,g_2$ are non-negative continuous functions on $[0,\infty )$,
in which $f_1(x)f_2(x)=x$ and $g_1(x)g_2(x)=x\,\,(x\geq 0)$. Moreover, it is
shown several inequalities for the numerical radius.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:15:26 GMT""}]","2023-01-25"
"2301.10030","Yu Zheng","Yu Zheng, Alessandro Ferraro, Anton Frisk Kockum, and Giulia Ferrini","Gaussian conversion protocol for heralded generation of qunaught states","10 pages",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the field of fault-tolerant quantum computing, continuous-variable systems
can be utilized to protect quantum information from noise through the use of
bosonic codes. These codes map qubit-type quantum information onto the larger
bosonic Hilbert space, and can be divided into two main categories:
translational-symmetric codes, such as Gottesman-Kitaev-Preskill (GKP) codes,
and rotational-symmetric codes, including cat and binomial codes. The
relationship between these families of codes has not yet been fully understood.
We present an iterative protocol for converting between two instances of these
codes GKP qunaught states and four-foldsymmetric binomial states corresponding
to a zero-logical encoded qubit - using only Gaussian operations. This
conversion demonstrates the potential for universality of binomial states for
all-Gaussian quantum computation and provides a new method for the heraladed
preparation of GKP states. Through numerical simulation, we obtain GKP qunaught
states with a fidelity of over 98% and a probability of approximately 3.14%,
after only two steps of our iterative protocol, though higher fidelities can be
achieved with additional iterations at the cost of lower success probabilities.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:17:07 GMT""}]","2023-01-25"
"2301.10031","Paloma Thome De Lima","Hans L. Bodlaender, \'Edouard Bonnet, Lars Jaffke, Du\v{s}an Knop,
  Paloma T. Lima, Martin Milani\v{c}, Sebastian Ordyniak, Sukanya Pandey and
  Ond\v{r}ej Such\'y","Treewidth is NP-Complete on Cubic Graphs (and related results)",,,,,"cs.CC cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we give a very simple proof that Treewidth is NP-complete;
this proof also shows NP-completeness on the class of co-bipartite graphs. We
then improve the result by Bodlaender and Thilikos from 1997 that Treewidth is
NP-complete on graphs with maximum degree at most 9, by showing that Treewidth
is NP-complete on cubic graphs.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:17:58 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 09:49:25 GMT""}]","2023-03-03"
"2301.10032","Rayna Dimitrova","Philippe Heim and Rayna Dimitrova","Taming Large Bounds in Synthesis from Bounded-Liveness Specifications
  (Full Version)","Full version of paper accepted at TACAS 2023",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Automatic synthesis from temporal logic specifications is an attractive
alternative to manual system design, due to its ability to generate
correct-by-construction implementations from high-level specifications. Due to
the high complexity of the synthesis problem, significant research efforts have
been directed at developing practically efficient approaches for restricted
specification language fragments. In this paper, we focus on the Safety LTL
fragment of Linear Temporal Logic (LTL) syntactically extended with bounded
temporal operators. We propose a new synthesis approach with the primary
motivation to solve efficiently the synthesis problem for specifications with
bounded temporal operators, in particular those with large bounds. The
experimental evaluation of our method shows that for this type of
specifications, it outperforms state-of-art synthesis tools, demonstrating that
it is a promising approach to efficiently treating quantitative timing
constraints in safety specifications.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:18:40 GMT""}]","2023-01-25"
"2301.10033","Jerome Rech","A. Popoff, A. V. Lebedev, L. Raymond, T. Jonckheere, J. Rech, T.
  Martin","Renormalization flow of a weak extended backscattering Hamiltonian in a
  non-chiral Tomonaga-Luttinger liquid","27 pages, 8 figures","J. Phys.: Condens. Matter, 33, 115602 (2021)","10.1088/1361-648X/abd525",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a non-chiral Luttinger liquid in the presence of a backscattering
Hamiltonian which has an extended range. Right/left moving fermions at a given
location can thus be converted as left/right moving fermions at a different
location, within a specific range. We perform a momentum shell renormalization
group treatment which gives the evolution of the relative degrees of freedom of
this Hamiltonian contribution under the renormalization flow, and we study a
few realistic examples of this extended backscattering Hamiltonian. We find
that, for repulsive Coulomb interaction in the Luttinger liquid, any such
Hamiltonian contribution evolves into a delta-like scalar potential upon
renormalization to a zero temperature cutoff. On the opposite, for attractive
couplings, the amplitude of this kinetic Hamiltonian is suppressed, rendering
the junction fully transparent. As the renormalization procedure may have to be
stopped because of experimental constraints such as finite temperature, we
predict the actual spatial shape of the kinetic Hamiltonian at different stages
of the renormalization procedure, as a function of the position and the
Luttinger interaction parameter, and show that it undergoes structural changes.
This renormalized kinetic Hamiltonian has thus to be used as an input for the
perturbative calculation of the current, for which we provide analytic
expressions in imaginary time. We discuss the experimental relevance of this
work by looking at one-dimensional systems consisting of carbon nanotubes or
semiconductor nanowires.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:19:09 GMT""}]","2023-01-25"
"2301.10035","Oded Nov","Oded Nov and Nina Singh and Devin Mann","Putting ChatGPT's Medical Advice to the (Turing) Test",,,,,"cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  Objective: Assess the feasibility of using ChatGPT or a similar AI-based
chatbot for patient-provider communication. Participants: A US representative
sample of 430 study participants aged 18 and above. 53.2% of respondents
analyzed were women; their average age was 47.1. Exposure: Ten representative
non-administrative patient-provider interactions were extracted from the EHR.
Patients' questions were placed in ChatGPT with a request for the chatbot to
respond using approximately the same word count as the human provider's
response. In the survey, each patient's question was followed by a provider- or
ChatGPT-generated response. Participants were informed that five responses were
provider-generated and five were chatbot-generated. Participants were asked,
and incentivized financially, to correctly identify the response source.
Participants were also asked about their trust in chatbots' functions in
patient-provider communication, using a Likert scale of 1-5. Results: The
correct classification of responses ranged between 49.0% to 85.7% for different
questions. On average, chatbot responses were correctly identified 65.5% of the
time, and provider responses were correctly distinguished 65.1% of the time. On
average, responses toward patients' trust in chatbots' functions were weakly
positive (mean Likert score: 3.4), with lower trust as the health-related
complexity of the task in questions increased. Conclusions: ChatGPT responses
to patient questions were weakly distinguishable from provider responses.
Laypeople appear to trust the use of chatbots to answer lower risk health
questions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:24:44 GMT""}]","2023-01-25"
"2301.10036","Daniel Brito de Freitas","C. V. da Silva, M. M. F. Nepomuceno and D. B. de Freitas","Multiscale structure of the gravitational wave signal from GW150914
  based on the nonextensivity $q$-triplet","7 pages, 6 figures",,"10.1209/0295-5075/acbc94",,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the first gravitational wave, GW150914, detected by advanced LIGO
and constructed from the data of measurement of strain relative deformation of
the fabric of spacetime. We show that the time series from the gravitational
wave obeys Tsallis's $q$-Gaussian distribution as a probability density and its
dynamics evolve of the three associated Tsallis' indices named $q$-triplet.
This fact strongly suggests that these black hole merger systems behave in a
non-extensive manner. Furthermore, our results point out that the entropic
indexes obtained as a function of frequency are useful statistical parameters
to determine the dominant frequency when black hole coalescence is achieved.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:25:38 GMT""}]","2023-03-15"
"2301.10037","Thibault Dardinier","Thibault Dardinier, Peter M\""uller","Hyper Hoare Logic: (Dis-)Proving Program Hyperproperties (extended
  version)",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hoare logics are proof systems that allow one to formally establish
properties of computer programs. Traditional Hoare logics prove properties of
individual program executions (so-called trace properties, such as functional
correctness). On the one hand, Hoare logic has been generalized to prove
properties of multiple executions of a program (so-called hyperproperties, such
as determinism or non-interference). These program logics prove the absence of
(bad combinations of) executions. On the other hand, program logics similar to
Hoare logic have been proposed to disprove program properties (e.g.,
Incorrectness Logic), by proving the existence of (bad combinations of)
executions. All of these logics have in common that they specify program
properties using assertions over a fixed number of states, for instance, a
single pre- and post-state for functional properties or pairs of pre- and
post-states for non-interference. In this paper, we present Hyper Hoare Logic,
a generalization of Hoare logic that lifts assertions to properties of
arbitrary sets of states. The resulting logic is simple yet expressive: its
judgments can express arbitrary trace- and hyperproperties over the terminating
executions of a program. By allowing assertions to reason about sets of states,
Hyper Hoare Logic can reason about both the absence and the existence of
(combinations of) executions, and, thereby, supports both proving and
disproving program (hyper-)properties within the same logic. In fact, we prove
that Hyper Hoare Logic subsumes the properties handled by numerous existing
correctness and incorrectness logics, and can express hyperproperties that no
existing Hoare logic can. We also prove that Hyper Hoare Logic is sound and
complete. All our technical results have been proved in Isabelle/HOL.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:26:02 GMT""}]","2023-01-25"
"2301.10038","Peijie Dong","Peijie Dong, Xin Niu, Zhiliang Tian, Lujun Li, Xiaodong Wang, Zimian
  Wei, Hengyue Pan, Dongsheng Li","Progressive Meta-Pooling Learning for Lightweight Image Classification
  Model","5 pages, 2 figures, ICASSP23",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Practical networks for edge devices adopt shallow depth and small
convolutional kernels to save memory and computational cost, which leads to a
restricted receptive field. Conventional efficient learning methods focus on
lightweight convolution designs, ignoring the role of the receptive field in
neural network design. In this paper, we propose the Meta-Pooling framework to
make the receptive field learnable for a lightweight network, which consists of
parameterized pooling-based operations. Specifically, we introduce a
parameterized spatial enhancer, which is composed of pooling operations to
provide versatile receptive fields for each layer of a lightweight model. Then,
we present a Progressive Meta-Pooling Learning (PMPL) strategy for the
parameterized spatial enhancer to acquire a suitable receptive field size. The
results on the ImageNet dataset demonstrate that MobileNetV2 using Meta-Pooling
achieves top1 accuracy of 74.6\%, which outperforms MobileNetV2 by 2.3\%.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:28:05 GMT""}]","2023-01-25"
"2301.10039","Stefan Zetzsche","Stefan Zetzsche","Generalised Duality Theory for Monoidal Categories and Applications","Master thesis",,,,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss generalised duality theory for monoidal categories and its
applications to the categories of exact endofunctors, graded vector spaces, and
topological vector spaces.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:30:34 GMT""}]","2023-01-25"
"2301.10040","Paulo Andr\'e D. Gon\c{c}alves","P. A. D. Gon\c{c}alves and F. Javier Garc\'ia de Abajo","Interrogating Quantum Nonlocal Effects in Nanoplasmonics through
  Electron-Beam Spectroscopy","8 pages, 4 figures","Nano Letters (2023)","10.1021/acs.nanolett.3c00298",,"cond-mat.mes-hall cond-mat.mtrl-sci physics.optics","http://creativecommons.org/licenses/by/4.0/","  A rigorous account of quantum nonlocal effects is paramount for understanding
the optical response of metal nanostructures and for designing plasmonic
devices at the nanoscale. Here, we present a scheme for retrieving the quantum
surface response of metals, encapsulated in the Feibelman $d$-parameters, from
electron energy-loss spectroscopy (EELS) and cathodoluminescence (CL)
measurements. We theoretically demonstrate that quantum nonlocal effects have a
dramatic impact on EELS and CL spectra, in the guise of spectral shifts and
nonlocal damping, when either the system size or the inverse wave vector in
extended structures approach the nanometer scale. Our concept capitalizes on
the unparalleled ability of free-electrons to supply deeply subwavelength
near-fields and, thus, probe the optical response of metals at length scales in
which quantum-mechanical effects are apparent. These results pave the way for a
widespread use of the $d$-parameter formalism, thereby facilitating a rigorous
yet practical inclusion of nonclassical effects in nanoplasmonics.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:31:18 GMT""},{""version"":""v2"",""created"":""Sat, 13 May 2023 19:23:45 GMT""}]","2023-05-16"
"2301.10041","Fabio Credali","Daniele Boffi, Fabio Credali, Lucia Gastaldi, Simone Scacchi","A parallel solver for FSI problems with fictitious domain approach","Contribution to the 5th African Conference on Computational Mechanics",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We present and analyze a parallel solver for the solution of fluid structure
interaction problems described by a fictitious domain approach. In particular,
the fluid is modeled by the non-stationary incompressible Navier-Stokes
equations, while the solid evolution is represented by the elasticity
equations. The parallel implementation is based on the PETSc library and the
solver has been tested in terms of robustness with respect to mesh refinement
and weak scalability by running simulations on a Linux cluster.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:32:35 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 07:23:03 GMT""}]","2023-04-11"
"2301.10042","Dmitrii Pavlov","Dmitrii Pavlov","Logarithmically Sparse Symmetric Matrices","15 pages",,,,"math.AG cs.SC","http://creativecommons.org/licenses/by/4.0/","  A positive definite matrix is called logarithmically sparse if its matrix
logarithm has many zero entries. Such matrices play a significant role in
high-dimensional statistics and semidefinite optimization. In this paper,
logarithmically sparse matrices are studied from the point of view of
computational algebraic geometry: we present a formula for the dimension of the
Zariski closure of a set of matrices with a given logarithmic sparsity pattern,
give a degree bound for this variety and develop implicitization algorithms
that allow to find its defining equations. We illustrate our approach with
numerous examples.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:34:21 GMT""}]","2023-01-25"
"2301.10043","Jose Daniel Lara","Jose Daniel Lara and Rodrigo Henriquez-Auba and Deepak Ramasubramanian
  and Sairaj Dhople and Duncan S. Callaway and Seth Sanders","Revisiting Power Systems Time-domain Simulation Methods and Models",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The changing nature of power systems dynamics is challenging present
practices related to modeling and study of system-level dynamic behavior. While
developing new techniques and models to handle the new modeling requirements,
it is also critical to review some of the terminology used to describe existing
simulation approaches and the embedded assumptions. This paper provides a
first-principles review of the simplifications and transformation commonly used
in the formulation of time-domain simulation models. It introduces a taxonomy
and classification of time-domain simulation models depending on their
frequency bandwidth, network representation, and software availability.
Furthermore, it focuses on the fundamental aspects of averaging techniques, and
model reduction approaches that result in modeling choices, and discusses the
associated challenges and opportunities of applying these methods in systems
with large shares of Inverter Based Resources (IBRs). The paper concludes with
an illustrative simulation that compares the trajectories of an IBR-dominated
system.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:36:29 GMT""}]","2023-01-25"
"2301.10044","Tomohisa Yamakami","Kenichiro Shiraya, Tomohisa Yamakami","Constructing Copulas Using Corrected Hermite Polynomial Expansion for
  Estimating Cross Foreign Exchange Volatility","36 pages, 48 figures",,,,"q-fin.MF q-fin.ST","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Copulas are used to construct joint distributions in many areas. In some
problems, it is necessary to deal with correlation structures that are more
complicated than the commonly known copulas. A finite order multivariate
Hermite polynomial expansion, as an approximation of a joint density function,
can handle complex correlation structures. However, it does not construct
copulas because the density function can take negative values. In this study,
we propose a method to construct a copula based on the finite sum of
multivariate Hermite polynomial expansions by applying corrections to the joint
density function. Furthermore, we apply this copula to estimate the volatility
smile of cross currency pairs in the foreign exchange option market. This
method can easily reproduce the volatility smile of cross currency pairs by
appropriately adjusting the parameters and following the daily volatility
fluctuations even if the higher-order parameters are fixed. In the numerical
experiments, we compare the estimation results of the volatility smile of
EUR-JPY with those of USD-JPY and EUR-USD for the proposed and other copulas,
and show the validity of the proposed copula.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:37:57 GMT""}]","2023-01-25"
"2301.10045","Theodoros Papanikolaou","Theodoros Papanikolaou, Konstantinos N. Gourgouliatos","Primordial magnetic field generation via primordial black hole disks","1)To appear in Physical Review D. 2)Major revisions regarding the
  derivation of the magnetic field power spectrum",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large scale primordial magnetic fields (PMFs) threading the intergalactic
medium are observed ubiquitously in the Universe playing a key role in the
cosmic evolution. Their origin is still debated constituting a very active
field of research. In the present article, we propose a novel natural ab initio
mechanism for the origin of such PMFs through the portal of supermassive
primordial black holes (PBHs) forming between the Big Bang Nucleosynthesis and
the recombination era. In particular, by considering PBHs furnished with a
locally isothermal disk we study the generation of a Biermann battery induced
seed magnetic field (MF) due to the vortexlike motion of the primordial plasma
around the black hole. Finally, by considering monochromatic PBH mass
distributions and deriving the relevant MF power spectrum we make a
conservative estimate for the seed PMF in intergalactic scales and at redshift
$z=30$, when typical galaxies are considered to form, which reads as $B\simeq
10^{-30}\mathrm{G}\left(\frac{\ell_\mathrm{R}}{10^6}\right)^2\left(\frac{M_\mathrm{PBH}}{10^{14}M_\odot}\right)^{5/2}$,
where $M_\mathrm{PBH}$ is the PBH mass and $\ell_\mathrm{R}\equiv
R_\mathrm{d}/R_\mathrm{ISCO}$, is the ratio of the radius of the disk,
$R_\mathrm{d}$ over the radius of the innermost stable circular orbit,
$R_\mathrm{ISCO}$. Interestingly enough, by requiring to seed a PMF of the
order of $10^{-30}\mathrm{G}$ necessary to give rise to a present day
$10^{-18}\mathrm{G}$ in intergalactic scales, we find a lower bound on the PBH
mass within the range $[10^{10}- 10^{16}]M_\odot$ depending on the radius of
the PBH disk.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:39:12 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 14:31:44 GMT""}]","2023-05-17"
"2301.10046","Eric Sawyer","Michel Alexis, Jose Luis Luna-Garcia, Eric T. Sawyer and Ignacio
  Uriarte-Tuero","The T1 theorem for the Hilbert transform fails when p is not 2","4 pages",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  Given p between 1 and infinity, but not 2, we show that the T1 theorem for
the Hilbert transform fails for L^{p}, despite holding for p equal to 2
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:41:47 GMT""}]","2023-01-25"
"2301.10047","Zhang Fan","Fan Zhang, Naye Ji, Fuxing Gao, Yongping Li","DiffMotion: Speech-Driven Gesture Synthesis Using Denoising Diffusion
  Model","13 pages, 3 figures",,,,"cs.GR cs.CV cs.HC cs.SD eess.AS eess.IV","http://creativecommons.org/licenses/by/4.0/","  Speech-driven gesture synthesis is a field of growing interest in virtual
human creation. However, a critical challenge is the inherent intricate
one-to-many mapping between speech and gestures. Previous studies have explored
and achieved significant progress with generative models. Notwithstanding, most
synthetic gestures are still vastly less natural. This paper presents
DiffMotion, a novel speech-driven gesture synthesis architecture based on
diffusion models. The model comprises an autoregressive temporal encoder and a
denoising diffusion probability Module. The encoder extracts the temporal
context of the speech input and historical gestures. The diffusion module
learns a parameterized Markov chain to gradually convert a simple distribution
into a complex distribution and generates the gestures according to the
accompanied speech. Compared with baselines, objective and subjective
evaluations confirm that our approach can produce natural and diverse
gesticulation and demonstrate the benefits of diffusion-based models on
speech-driven gesture synthesis.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:44:03 GMT""},{""version"":""v2"",""created"":""Thu, 2 Feb 2023 12:56:21 GMT""}]","2023-02-03"
"2301.10048","Kaidong Zhang","Kaidong Zhang, Jialun Peng, Jingjing Fu, Dong Liu","Exploiting Optical Flow Guidance for Transformer-Based Video Inpainting","This manuscript is a journal extension of our ECCV 2022 paper
  (arXiv:2208.06768)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have been widely used for video processing owing to the
multi-head self attention (MHSA) mechanism. However, the MHSA mechanism
encounters an intrinsic difficulty for video inpainting, since the features
associated with the corrupted regions are degraded and incur inaccurate self
attention. This problem, termed query degradation, may be mitigated by first
completing optical flows and then using the flows to guide the self attention,
which was verified in our previous work - flow-guided transformer (FGT). We
further exploit the flow guidance and propose FGT++ to pursue more effective
and efficient video inpainting. First, we design a lightweight flow completion
network by using local aggregation and edge loss. Second, to address the query
degradation, we propose a flow guidance feature integration module, which uses
the motion discrepancy to enhance the features, together with a flow-guided
feature propagation module that warps the features according to the flows.
Third, we decouple the transformer along the temporal and spatial dimensions,
where flows are used to select the tokens through a temporally deformable MHSA
mechanism, and global tokens are combined with the inner-window local tokens
through a dual perspective MHSA mechanism. FGT++ is experimentally evaluated to
be outperforming the existing video inpainting networks qualitatively and
quantitatively.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:44:44 GMT""}]","2023-01-25"
"2301.10049","Jacopo Ulivelli","Jonas Knoerr and Jacopo Ulivelli","From valuations on convex bodies to convex functions","A new section was added after the Preliminaries, adding information
  on the methods and connections with the literature. Abstract, Introduction,
  and Preliminaries have been restructured",,,,"math.MG math.FA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A geometric framework relating valuations on convex bodies to valuations on
convex functions is introduced. It is shown that a classical result by McMullen
can be used to obtain a characterization of continuous, epi-translation
invariant, and n-epi-homogeneous valuations on convex functions, which was
previously established by Colesanti, Ludwig, and Mussnig. Following an approach
by Goodey and Weil, a new characterization of 1-epi-homogeneous valuations is
obtained.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:46:27 GMT""},{""version"":""v2"",""created"":""Fri, 14 Apr 2023 14:15:18 GMT""}]","2023-04-17"
"2301.10050","Thomas Schuster","Dimitri Rothermel and Thomas Schuster","Development of a photothermal measurement model to determine layer
  thickness of multi-layered coating systems with unknown thermal properties","16 pages, 8 figures",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this article, a general model for 1D thermal wave interference is derived
for multi-layered coating systems on a thermally thick substrate using the same
principles as for the well established one-layered and two-layered coating
cases. Using the lock-in thermography principle, an illumination source
modulates the surface of those systems periodically by a planar, sinusoidal
wave form with a fixed frequency. The coating systems absorb the optical energy
on its surface and convert it into thermal energy, resulting in the propagation
of a spatially and temporally periodic thermal wave with the same frequency.
These thermal waves, originating at the surface, are reflected and transmitted
at each interface leading to infinitely many wave trains that need to be
tracked in order to formulate the final surface temperature as a superposition
of all these waves. The heat transfer inside the object depends on the layer
thickness of each coating, but also on the thermal properties of each layer
material. The goal is to have a mathematical and physical model which describes
the phase angle data measured by an infrared camera. Having these data, the
main objective of this paper is to determine the thickness of each coating
layer. In practice, the thermal properties of the layers usually are unknown,
which makes the process even more difficult. For that reason, this article
presents a concept to determine the thermal properties in advance.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:47:19 GMT""}]","2023-01-25"
"2301.10051","Zanjia Tong","Zanjia Tong, Yuhang Chen, Zewei Xu, Rong Yu","Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The loss function for bounding box regression (BBR) is essential to object
detection. Its good definition will bring significant performance improvement
to the model. Most existing works assume that the examples in the training data
are high-quality and focus on strengthening the fitting ability of BBR loss. If
we blindly strengthen BBR on low-quality examples, it will jeopardize
localization performance. Focal-EIoU v1 was proposed to solve this problem, but
due to its static focusing mechanism (FM), the potential of non-monotonic FM
was not fully exploited. Based on this idea, we propose an IoU-based loss with
a dynamic non-monotonic FM named Wise-IoU (WIoU). The dynamic non-monotonic FM
uses the outlier degree instead of IoU to evaluate the quality of anchor boxes
and provides a wise gradient gain allocation strategy. This strategy reduces
the competitiveness of high-quality anchor boxes while also reducing the
harmful gradient generated by low-quality examples. This allows WIoU to focus
on ordinary-quality anchor boxes and improve the detector's overall
performance. When WIoU is applied to the state-of-the-art real-time detector
YOLOv7, the AP-75 on the MS-COCO dataset is improved from 53.03% to 54.50%.
Code is available at https://github.com/Instinct323/wiou.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:50:40 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 14:05:02 GMT""},{""version"":""v3"",""created"":""Sat, 8 Apr 2023 13:58:40 GMT""}]","2023-04-11"
"2301.10052","Aditya Sangram Singh Rana","Aditya Sangram Singh Rana","Event Detection in Football using Graph Convolutional Networks",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The massive growth of data collection in sports has opened numerous avenues
for professional teams and media houses to gain insights from this data. The
data collected includes per frame player and ball trajectories, and event
annotations such as passes, fouls, cards, goals, etc. Graph Convolutional
Networks (GCNs) have recently been employed to process this highly unstructured
tracking data which can be otherwise difficult to model because of lack of
clarity on how to order players in a sequence and how to handle missing objects
of interest. In this thesis, we focus on the goal of automatic event detection
from football videos. We show how to model the players and the ball in each
frame of the video sequence as a graph, and present the results for graph
convolutional layers and pooling methods that can be used to model the temporal
context present around each action.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:52:54 GMT""}]","2023-01-25"
"2301.10053","Meenatchi Sundaram Muthu Selva Annamalai","Meenatchi Sundaram Muthu Selva Annamalai, Andrea Gadotti and Luc
  Rocher","A Linear Reconstruction Approach for Attribute Inference Attacks against
  Synthetic Data",,,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Personal data collected at scale from surveys or digital devices offers
important insights for statistical analysis and scientific research. Safely
sharing such data while protecting privacy is however challenging.
Anonymization allows data to be shared while minimizing privacy risks, but
traditional anonymization techniques have been repeatedly shown to provide
limited protection against re-identification attacks in practice. Among modern
anonymization techniques, synthetic data generation (SDG) has emerged as a
potential solution to find a good tradeoff between privacy and statistical
utility. Synthetic data is typically generated using algorithms that learn the
statistical distribution of the original records, to then generate ""artificial""
records that are structurally and statistically similar to the original ones.
Yet, the fact that synthetic records are ""artificial"" does not, per se,
guarantee that privacy is protected. In this work, we systematically evaluate
the tradeoffs between protecting privacy and preserving statistical utility for
a wide range of synthetic data generation algorithms. Modeling privacy as
protection against attribute inference attacks (AIAs), we extend and adapt
linear reconstruction attacks, which have not been previously studied in the
context of synthetic data. While prior work suggests that AIAs may be effective
only on few outlier records, we show they can be very effective even on
randomly selected records. We evaluate attacks on synthetic datasets ranging
from 10^3 to 10^6 records, showing that even for the same generative model, the
attack effectiveness can drastically increase when a larger number of synthetic
records is generated. Overall, our findings prove that synthetic data is
subject to privacy-utility tradeoffs just like other anonymization techniques:
when good utility is preserved, attribute inference can be a risk for many data
subjects.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:56:36 GMT""}]","2023-01-25"
"2301.10054","Jinbang Yang","Jinbang Yang and Kang Zuo","Constructing algebraic solutions of Painleve VI equation from $p$-adic
  Hodge theory and Langlands Correspondence","12 pages",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We construct infinitely many non-isotrivial families of abelian varieties
over given four punctured projective lines. These families lead to algebraic
solutions of Painleve VI equation. Finally, based on a recent paper by
Lin-Sheng-Wang, we prove a complete characterization for the locus of motivic
Higgs bundles in the moduli space as fixed points of an ``additive'' self-map.
This is a note based on the lecture given by the second named author on 04 Nov.
2022 at Tsinghua University.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:59:15 GMT""}]","2023-01-25"
"2301.10055","Simon Gazagnes","Simon Gazagnes, Nasser Kalantar-Nayestanaki, Johan G. Messchendorp,
  Jenny Regina, Tobias Stockmanns, and Michael H.F. Wilkinson (on behalf of the
  PANDA collaboration)","Reconstructing charged-particle trajectories in the PANDA Straw Tube
  Tracker using the LOcal Track Finder (LOTF) algorithm","Accepted to EPJ A - 20 pages, 18 figures, 1 table",,"10.1140/epja/s10050-023-01005-8",,"hep-ex physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the LOcal Track Finder (LOTF) algorithm, a method that performs
charged-particle trajectory reconstruction using the Straw Tube Tracker, one of
the central trackers of the antiProton ANnihilation at DArmstadt (PANDA)
detector. The algorithm builds upon the neighboring relations of the tubes to
connect individual hits and form track candidates. In addition, it uses a local
fitting procedure to handle regions where several tracks overlap and utilizes a
system of virtual nodes to reconstruct the z-information of the particle
trajectories. We generated 30,000 events to assess the performance of our
approach and compared our results to two other track reconstruction methods.
LOTF has (1) an average of 85\% of found tracks, (2) the largest number of
Fully Pure tracks, (3) the lowest amount of incorrect reconstructions, and (4)
is significantly faster than the other two approaches. Further, we compared the
z-reconstruction performance with one of the two alternative methods and show
that LOTF improves the median z-error by a factor of 8.7. Finally, we tested
our method using 3,750 data sets composed of 4 events each, showing that our
approach handles cases in which events are mixed. The raw (without
parallelization) average reconstruction rate is about 68,000 hits/s, which
makes the present algorithm promising for online data selection and processing.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 14:59:21 GMT""},{""version"":""v2"",""created"":""Thu, 13 Apr 2023 17:40:24 GMT""}]","2023-05-24"
"2301.10056","Yan Long","Yan Long, Pirouz Naghavi, Blas Kojusner, Kevin Butler, Sara Rampazzi,
  Kevin Fu","Side Eye: Characterizing the Limits of POV Acoustic Eavesdropping from
  Smartphone Cameras with Rolling Shutters and Movable Lenses",,"2023 IEEE Symposium on Security and Privacy (SP)","10.1109/SP46215.2023.00059",,"cs.CR cs.CV cs.MM cs.SD eess.AS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Our research discovers how the rolling shutter and movable lens structures
widely found in smartphone cameras modulate structure-borne sounds onto camera
images, creating a point-of-view (POV) optical-acoustic side channel for
acoustic eavesdropping. The movement of smartphone camera hardware leaks
acoustic information because images unwittingly modulate ambient sound as
imperceptible distortions. Our experiments find that the side channel is
further amplified by intrinsic behaviors of Complementary
metal-oxide-semiconductor (CMOS) rolling shutters and movable lenses such as in
Optical Image Stabilization (OIS) and Auto Focus (AF). Our paper characterizes
the limits of acoustic information leakage caused by structure-borne sound that
perturbs the POV of smartphone cameras. In contrast with traditional
optical-acoustic eavesdropping on vibrating objects, this side channel requires
no line of sight and no object within the camera's field of view (images of a
ceiling suffice). Our experiments test the limits of this side channel with a
novel signal processing pipeline that extracts and recognizes the leaked
acoustic information. Our evaluation with 10 smartphones on a spoken digit
dataset reports 80.66%, 91.28%, and 99.67% accuracies on recognizing 10 spoken
digits, 20 speakers, and 2 genders respectively. We further systematically
discuss the possible defense strategies and implementations. By modeling,
measuring, and demonstrating the limits of acoustic eavesdropping from
smartphone camera image streams, our contributions explain the physics-based
causality and possible ways to reduce the threat on current and future devices.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:00:47 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 20:11:27 GMT""}]","2023-01-30"
"2301.10057","Jon\'a\v{s} \v{S}er\'ych","Jonas Serych, Jiri Matas","Planar Object Tracking via Weighted Optical Flow","WACV 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose WOFT -- a novel method for planar object tracking that estimates a
full 8 degrees-of-freedom pose, i.e. the homography w.r.t. a reference view.
The method uses a novel module that leverages dense optical flow and assigns a
weight to each optical flow correspondence, estimating a homography by weighted
least squares in a fully differentiable manner. The trained module assigns zero
weights to incorrect correspondences (outliers) in most cases, making the
method robust and eliminating the need of the typically used non-differentiable
robust estimators like RANSAC. The proposed weighted optical flow tracker
(WOFT) achieves state-of-the-art performance on two benchmarks, POT-210 and
POIC, tracking consistently well across a wide range of scenarios.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:02:44 GMT""}]","2023-01-25"
"2301.10059","Alexandra Erdmann","Alexandra Erdmann, Jan Beyersmann, and Kaspar Rufibach","Oncology clinical trial design planning based on a multistate model that
  jointly models progression-free and overall survival endpoints","27 pages, 3 tables, 12 figures",,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  When planning an oncology clinical trial, the usual approach is to assume an
exponential distribution for the time-to-event endpoints. Often, besides the
gold-standard endpoint overall survival, progression-free survival is
considered as a second confirmatory endpoint. We use a survival multistate
model to jointly model these two endpoints and find that neither exponential
distribution nor proportional hazards will typically hold for both endpoints
simultaneously. The multistate model approach allows us to consider the joint
distribution of the two endpoints and to derive quantities of interest as the
correlation between overall survival and progression-free survival. In this
paper, we use the multistate model framework to simulate clinical trials with
endpoints OS and PFS and show how design planning questions can be answered
using this approach. In addition to the major advantage that we can model
non-proportional hazards quite naturally with this approach, the correlation
between the two endpoints can be exploited to determine sample size and
type-I-error. We consider an oncology trial on non-small-cell lung cancer as a
motivating example from which we derive relevant trial design questions. We
then illustrate how clinical trial design can be based on simulations from a
multistate model. Key applications are co-primary endpoints and
group-sequential designs. Simulations for these applications show that the
standard simplifying approach often leads to underpowered or overpowered
clinical trials. Our approach is quite general and can be extended to more
complex trial designs, further endpoints, and other therapeutic areas.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:03:37 GMT""}]","2023-01-25"
"2301.10060","Pawan Goyal","Pawan Goyal and Igor Pontes Duff and Peter Benner","Inference of Continuous Linear Systems from Data with Guaranteed
  Stability",,,,,"cs.LG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine-learning technologies for learning dynamical systems from data play
an important role in engineering design. This research focuses on learning
continuous linear models from data. Stability, a key feature of dynamic
systems, is especially important in design tasks such as prediction and
control. Thus, there is a need to develop methodologies that provide stability
guarantees. To that end, we leverage the parameterization of stable matrices
proposed in [Gillis/Sharma, Automatica, 2017] to realize the desired models.
Furthermore, to avoid the estimation of derivative information to learn
continuous systems, we formulate the inference problem in an integral form. We
also discuss a few extensions, including those related to control systems.
Numerical experiments show that the combination of a stable matrix
parameterization and an integral form of differential equations allows us to
learn stable systems without requiring derivative information, which can be
challenging to obtain in situations with noisy or limited data.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:04:19 GMT""}]","2023-01-25"
"2301.10061","Simon Oddershede Gregersen","Simon Oddershede Gregersen, Alejandro Aguirre, Philipp Haselwarter,
  Joseph Tassarotti, Lars Birkedal","Asynchronous Probabilistic Couplings in Higher-Order Separation Logic",,,,,"cs.LO cs.PL","http://creativecommons.org/licenses/by/4.0/","  Probabilistic couplings are the foundation for many probabilistic relational
program logics and arise when relating random sampling statements across two
programs. In relational program logics, this manifests as dedicated coupling
rules that, e.g., say we may reason as if two sampling statements return the
same value. However, this approach fundamentally requires aligning or
""synchronizing"" the sampling statements of the two programs which is not always
possible.
  In this paper, we develop Clutch, a higher-order probabilistic relational
separation logic that addresses this issue by supporting asynchronous
probabilistic couplings. We use Clutch to develop a logical step-indexed
logical relational to reason about contextual refinement and equivalence of
higher-order programs written in a rich language with higher-order local state
and impredicative polymorphism. Finally, we demonstrate the usefulness of our
approach on a number of case studies.
  All the results that appear in the paper have been formalized in the Coq
proof assistant using the Coquelicot library and the Iris separation logic
framework.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:04:50 GMT""}]","2023-01-25"
"2301.10063","Ole S\""onnerborn","Niklas H\""ornedal, Ole S\""onnerborn","The Margolus-Levitin quantum speed limit for an arbitrary fidelity","16 pages, 7 figures, comments are welcome",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The Mandelstam-Tamm and Margolus-Levitin quantum speed limits are two
well-known evolution time estimates for isolated quantum systems. These bounds
are usually formulated for fully distinguishable initial and final states, but
both have tight extensions to systems that evolve between states with arbitrary
fidelity. However, the foundations for these extensions differ in some
essential respects. The extended Mandelstam-Tamm quantum speed limit has been
proven analytically and has a clear geometric interpretation. Furthermore, the
systems that saturate the limit have been completely classified. The derivation
of the extended Margolus-Levitin quantum speed limit, on the other hand, is
based on numerical estimates. Moreover, the limit lacks a geometric
interpretation, and there is no complete characterization of the systems
reaching it. In this paper, we derive the extended Margolus-Levitin quantum
speed limit analytically and describe in detail the systems that saturate the
limit. We also provide the limit with a symplectic-geometric interpretation,
indicating that it is of a different character than most existing quantum speed
limits. At the end of the paper, we analyze the maximum of the extended
Mandelstam-Tamm and Margolus-Levitin quantum speed limits, and we derive a dual
version of the extended Margolus-Levitin quantum speed limit. The maximum limit
is tight regardless of the fidelity of the initial and final states. However,
the conditions under which the maximum limit is saturated differ depending on
whether or not the initial and final states are fully distinguishable. The dual
limit is also tight and follows from a time reversal argument. We describe all
systems that saturate the dual quantum speed limit.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:10:02 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 18:26:16 GMT""}]","2023-04-06"
"2301.10064","Zhigang Li","Meilin Jiang, Seonjoo Lee, James O'Malley, Yaakov Stern, Zhigang Li","A Novel Causal Mediation Analysis Approach for Zero-Inflated Mediators","Corresponding: zhigang.li@ufl.edu",,,,"stat.AP math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Mediation analyses play important roles in making causal inference in
biomedical research to examine causal pathways that may be mediated by one or
more intermediate variables (i.e., mediators). Although mediation frameworks
have been well established such as counterfactual-outcomes (i.e.,
potential-outcomes) models and traditional linear mediation models, little
effort has been devoted to dealing with mediators with zero-inflated structures
due to challenges associated with excessive zeros. We develop a novel mediation
modeling approach to address zero-inflated mediators containing true zeros and
false zeros. The new approach can decompose the total mediation effect into two
components induced by zero-inflated structures: the first component is
attributable to the change in the mediator on its numerical scale which is a
sum of two causal pathways and the second component is attributable only to its
binary change from zero to a non-zero status. An extensive simulation study is
conducted to assess the performance and it shows that the proposed approach
outperforms existing standard causal mediation analysis approaches. We also
showcase the application of the proposed approach to a real study in comparison
with a standard causal mediation analysis approach.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:11:27 GMT""}]","2023-01-25"
"2301.10066","Alexander Erreygers","Alexander Erreygers","Sublinear expectations for countable-state uncertain processes","14 pages, accepted for publication in the proceedings of ISIPTA 2023",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sublinear expectations for uncertain processes have received a lot of
attention recently, particularly methods to extend a downward-continuous
sublinear expectation on the bounded finitary functions to one on the
non-finitary functions. In most of the approaches the domain of the extension
is not very rich because it is limited to bounded measurable functions on the
set of all paths. This contribution alleviates this problem in the
countable-state case by extending, under a mild condition, to the extended real
measurable functions on the set of c\`adl\`ag paths, and investigates when a
sublinear Markov semigroup induces a sublinear expectation that satisfies this
mild condition.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:11:55 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 14:04:04 GMT""}]","2023-05-05"
"2301.10067","Artem Latyshev","Artem Latyshev, Aleksandr I. Panov","Intrinsic Motivation in Model-based Reinforcement Learning: A Brief
  Review","13 pages, 7 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The reinforcement learning research area contains a wide range of methods for
solving the problems of intelligent agent control. Despite the progress that
has been made, the task of creating a highly autonomous agent is still a
significant challenge. One potential solution to this problem is intrinsic
motivation, a concept derived from developmental psychology. This review
considers the existing methods for determining intrinsic motivation based on
the world model obtained by the agent. We propose a systematic approach to
current research in this field, which consists of three categories of methods,
distinguished by the way they utilize a world model in the agent's components:
complementary intrinsic reward, exploration policy, and intrinsically motivated
goals. The proposed unified framework describes the architecture of agents
using a world model and intrinsic motivation to improve learning. The potential
for developing new techniques in this area of research is also examined.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:13:02 GMT""}]","2023-01-25"
"2301.10068","Guillaume Thekkadath","G.S. Thekkadath, D. England, F. Bouchard, Y. Zhang, M.S. Kim, B.
  Sussman","Intensity interferometry for holography with quantum and classical light","10 pages, 9 figures; includes Supplemental Material",,,,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As first demonstrated by Hanbury Brown and Twiss, it is possible to observe
interference between independent light sources by measuring correlations in
their intensities rather than their amplitudes. In this work, we apply this
concept of intensity interferometry to holography. We combine a signal beam
with a reference and measure their intensity cross-correlations using a
time-tagging single-photon camera. These correlations reveal an interference
pattern from which we reconstruct the signal wavefront in both intensity and
phase. We demonstrate the principle with classical and quantum light, including
a single photon. Since the signal and reference do not need to be phase-stable,
this technique can be used to generate holograms of self-luminous or remote
objects using a local reference, thus opening the door to new holography
applications.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:13:03 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 20:39:25 GMT""}]","2023-05-29"
"2301.10070","Salih G\""oktu\u{g} K\""ose","Salih G\""oktu\u{g} K\""ose and Fatma Ba\c{s}ak Aydemir","A Framework To Improve User Story Sets Through Collaboration",,,,,"cs.SE","http://creativecommons.org/publicdomain/zero/1.0/","  Agile methodologies have become increasingly popular in recent years. Due to
its inherent nature, agile methodologies involve stakeholders with a wide range
of expertise and require interaction between them, relying on collaboration and
customer involvement. Hence, agile methodologies encourage collaboration
between all team members so that more efficient and effective processes are
maintained. Generating requirements can be challenging, as it requires the
participation of multiple stakeholders who describe various aspects of the
project and possess a shared understanding of essential concepts. One simple
method for capturing requirements using natural language is through user
stories, which document the agreed-upon properties of a project. Stakeholders
try to strive for completeness while generating user stories, but the final
user story set may still be flawed. To address this issue, we propose SCOUT:
Supporting Completeness of User Story Sets, which employs a natural language
processing pipeline to extract key concepts from user stories and construct a
knowledge graph by connecting related terms. The knowledge graph and different
heuristics are then utilized to enhance the quality and completeness of the
user story sets by generating suggestions for the stakeholders. We perform a
user study to evaluate SCOUT and demonstrate its performance in constructing
user stories. The quantitative and qualitative results indicate that SCOUT
significantly enhance the quality and completeness of the user story sets. Our
contribution is threefold. First, we develop heuristics to suggest new concepts
to include in user stories by considering both the individuals' and other team
members' contributions. Second, we implement an open-source collaborative tool
to support writing user stories and ensuring their quality. Third, we share the
experimental setup and materials.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:18:09 GMT""}]","2023-01-25"
"2301.10071","Lorenzo Monacelli","Lorenzo Monacelli and Nicola Marzari","First-principles thermodynamics of CsSnI3","Accepted on Chemistry of Materials",,"10.1021/acs.chemmater.2c03475",,"cond-mat.mtrl-sci cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  CsSnI3 is a promising eco-friendly solution for energy harvesting
technologies. It exists at room temperature in either a black perovskite
polymorph or a yellow 1D double-chain, which irreversibly deteriorates in the
air. In this work, we unveil the relative thermodynamic stability between the
two structures with a first-principles sampling of the CsSnI3
finite-temperature phase diagram, discovering how it is driven by anomalously
large quantum and anharmonic ionic fluctuations. Thanks to a comprehensive
treatment of anharmonicity, the simulations deliver a remarkable agreement with
known experimental data for the transition temperatures of the orthorhombic,
rhombohedral, and cubic perovskite structures and the thermal expansion
coefficient. We disclose how the perovskite polymorphs are the ground state
above \SI{270}{\kelvin} and discover an abnormal decrease in heat capacity upon
heating in the cubic black perovskite. Our results also significantly downplay
the Cs+ rattling modes' contribution to mechanical instability. The remarkable
agreement with experiments validates our methodology, which can be
systematically applied to all metal halides.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:19:32 GMT""}]","2023-02-10"
"2301.10073","Ruy Exel","Ruy Exel","Regular ideals under the ideal intersection property","8 pages, no figures",,,,"math.OA","http://creativecommons.org/licenses/by/4.0/","  The goal of this short note is to prove that when $A$ is a closed
*-subalgebra of a C*-algebra $B$ satisfying the ideal intersection property
plus a mild axiom (INV), then the map $J\mapsto J\cap A$ establishes an
isomorphism from the boolean algebra of all regular ideals of $B$ to the
boolean algebra of all regular, invariant ideals of $A$.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:25:12 GMT""}]","2023-01-25"
"2301.10074","Alexandre Forel","Alexandre Forel, Axel Parmentier, Thibaut Vidal","Explainable Data-Driven Optimization: From Context to Decision and Back
  Again",,,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-driven optimization uses contextual information and machine learning
algorithms to find solutions to decision problems with uncertain parameters.
While a vast body of work is dedicated to interpreting machine learning models
in the classification setting, explaining decision pipelines involving learning
algorithms remains unaddressed. This lack of interpretability can block the
adoption of data-driven solutions as practitioners may not understand or trust
the recommended decisions. We bridge this gap by introducing a counterfactual
explanation methodology tailored to explain solutions to data-driven problems.
We introduce two classes of explanations and develop methods to find nearest
explanations of random forest and nearest-neighbor predictors. We demonstrate
our approach by explaining key problems in operations management such as
inventory management and routing.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:25:16 GMT""}]","2023-01-25"
"2301.10075","Andrea Piergentili","Andrea Piergentili, Dennis Fucci, Beatrice Savoldi, Luisa Bentivogli,
  Matteo Negri","Gender Neutralization for an Inclusive Machine Translation: from
  Theoretical Foundations to Open Challenges",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Gender inclusivity in language technologies has become a prominent research
topic. In this study, we explore gender-neutral translation (GNT) as a form of
gender inclusivity and a goal to be achieved by machine translation (MT)
models, which have been found to perpetuate gender bias and discrimination.
Specifically, we focus on translation from English into Italian, a language
pair representative of salient gender-related linguistic transfer problems. To
define GNT, we review a selection of relevant institutional guidelines for
gender-inclusive language, discuss its scenarios of use, and examine the
technical challenges of performing GNT in MT, concluding with a discussion of
potential solutions to encourage advancements toward greater inclusivity in MT.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:26:36 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 08:27:18 GMT""}]","2023-05-29"
"2301.10076","Jiyao Wang","Jiyao Wang, Chunxi Huang, Ran Tu, Dengbo He","Influential Factors of Users' Trust in the Range Estimation Systems of
  Battery Electric Vehicles -- A Survey Study in China","Accepted and reported at Transportation Research Board Annual Meeting
  2022",,,"TRBAM-23-01746","cs.CY","http://creativecommons.org/licenses/by/4.0/","  Although the rapid development of battery technology has greatly increased
the range of battery electric vehicle (BEV), the range anxiety is still a major
concern of BEV users or potential users. Previous work has proposed a framework
explaining the influential factors of range anxiety and users' trust toward the
range estimation system (RES) of BEV has been identified as a leading factor of
range anxiety. The trust in RES may further influence BEV users' charging
decisions. However, the formation of trust in RES of BEVs has not yet explored.
In this work, a questionnaire has been designed to investigate BEV users' trust
in RES and further explore the influential factors of BEV users' charging
decision. In total, 152 samples collected from the BEV users in mainland China
have been analyzed. The BEV users' gender, driving area, knowledge of BEV or
RES, system usability and trust in battery system of smartphones have been
identified as influential factors of RES in BEVs, supporting the three-layer
framework in automation-related trust (i.e., dispositional trust, situational
trust and learned trust). A connection between smartphone charging behaviors
and BEV charging behaviors has also been observed. The results from this study
can provide insights on the design of RES in BEVs in order to alleviate range
anxiety among users. The results can also inform the design of strategies
(e.g., advertising, training and in-vehicle HMI design) that can facilitate
more rational charging decisions among BEV users.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:28:23 GMT""}]","2023-02-06"
"2301.10077","Vitaly Vanchurin","Nikola Andrejic and Vitaly Vanchurin","Autonomous particles","15 pages, 3 figures",,,,"cs.LG hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a reinforcement learning problem where an agent has access to a very
large amount of information about the environment, but it can only take very
few actions to accomplish its task and to maximize its reward. Evidently, the
main problem for the agent is to learn a map from a very high-dimensional space
(which represents its environment) to a very low-dimensional space (which
represents its actions). The high-to-low dimensional map implies that most of
the information about the environment is irrelevant for the actions to be
taken, and only a small fraction of information is relevant. In this paper we
argue that the relevant information need not be learned by brute force (which
is the standard approach), but can be identified from the intrinsic symmetries
of the system. We analyze in details a reinforcement learning problem of
autonomous driving, where the corresponding symmetry is the Galilean symmetry,
and argue that the learning task can be accomplished with very few relevant
parameters, or, more precisely, invariants. For a numerical demonstration, we
show that the autonomous vehicles (which we call autonomous particles since
they describe very primitive vehicles) need only four relevant invariants to
learn how to drive very well without colliding with other particles. The simple
model can be easily generalized to include different types of particles (e.g.
for cars, for pedestrians, for buildings, for road signs, etc.) with different
types of relevant invariants describing interactions between them. We also
argue that there must exist a field theory description of the learning system
where autonomous particles would be described by fermionic degrees of freedom
and interactions mediated by the relevant invariants would be described by
bosonic degrees of freedom.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:31:22 GMT""}]","2023-01-26"
"2301.10078","Andrea Munari","Andrea Munari, Francisco Lazaro, Giuseppe Durisi, Gianluigi Liva","The Dynamic Behavior of Frameless ALOHA: Stability, Throughput, and Age
  of Information","arXiv admin note: substantial text overlap with arXiv:2112.00491",,,,"cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the dynamic behavior of frameless ALOHA, both in terms of throughput
and age of information (AoI). In particular, differently from previous studies,
our analysis accounts for the fact that the number of terminals contending the
channel may vary over time, as a function of the duration of the previous
contention period. The stability of the protocol is analyzed via a drift
analysis, which allows us to determine the presence of stable and unstable
equilibrium points. We also provide an exact characterization of the AoI
performance, through which we determine the impact of some key protocol
parameters, such as the maximum length of the contention period, on the average
AoI. Specifically, we show that configurations of parameters that maximize the
throughput may result in a degradation of the AoI performance.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:32:09 GMT""}]","2023-01-25"
"2301.10079","Mauro Vallati","Diaeddin Alarnaouti and George Baryannis and Mauro Vallati","Reformulation Techniques for Automated Planning: A Systematic Review","Accepted and to appear in The Knowledge Engineering Review (KER),
  2023",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Automated planning is a prominent area of Artificial Intelligence, and an
important component for intelligent autonomous agents. A cornerstone of
domain-independent planning is the separation between planning logic, i.e. the
automated reasoning side, and the knowledge model, that encodes a formal
representation of domain knowledge needed to reason upon a given problem to
synthesise a solution plan. Such a separation enables the use of reformulation
techniques, which transform how a model is represented in order to improve the
efficiency of plan generation. Over the past decades, significant research
effort has been devoted to the design of reformulation techniques. In this
paper, we present a systematic review of the large body of work on
reformulation techniques for classical planning, aiming to provide a holistic
view of the field and to foster future research in the area. As a tangible
outcome, we provide a qualitative comparison of the existing classes of
techniques, that can help researchers gain an overview of their strengths and
weaknesses.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:33:37 GMT""},{""version"":""v2"",""created"":""Mon, 30 Jan 2023 10:04:02 GMT""}]","2023-01-31"
"2301.10080","Mohsen Bayat","Mohsen Bayat, Sanoopkumar P. S., and Arman Farhang","Practical Synchronization for OTFS",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In the existing literature on joint timing and frequency synchronization of
orthogonal time frequency space modulation (OTFS), practically infeasible
impulse pilot with large peak-to-average power ratio (PAPR) is deployed. Hence,
in this paper, we propose a timing offset (TO) and carrier frequency offset
(CFO) estimation for OTFS over a linear time-varying (LTV) channel, using a low
PAPR pilot structure. The proposed technique utilizes the recently proposed
practically feasible pilot structure with a cyclic prefix (PCP). We exploit the
periodic properties of PCP in both delay and time domains to find the starting
point of each OTFS block. Furthermore, we propose a two-stage CFO estimation
technique with over an order of magnitude higher estimation accuracy than the
existing estimator using the impulse pilot. In the first stage, a coarse CFO
estimate is obtained which is refined in the second stage, through our proposed
maximum likelihood (ML) based approach. The proposed ML-based approach deploys
the generalized complex exponential basis expansion model (GCE-BEM) to capture
the time variations of the channel, absorb them into the pilot and provide an
accurate CFO estimate. Since our proposed synchronization technique utilizes
the same pilot deployed for channel estimation, it does not require any
additional overhead. Finally, we evaluate the performance of our proposed
synchronization technique through simulations. We also compare and show the
superior performance of our proposed technique to the only other existing joint
TO and CFO estimation method in OTFS literature.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:33:54 GMT""}]","2023-01-25"
"2301.10081","Rhys Steele","Martin Hairer, Rhys Steele","The BPHZ Theorem for Regularity Structures via the Spectral Gap
  Inequality","updated to match submitted version",,,,"math.PR math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a relatively compact proof of the BPHZ theorem for regularity
structures of decorated trees in the case where the driving noise satisfies a
suitable spectral gap property, as in the Gaussian case. This is inspired by
the recent work [LOTT21] in the multi-index setting, but our proof relies
crucially on a novel version of the reconstruction theorem for a space of
""pointed Besov modelled distributions"". As a consequence, the analytical core
of the proof is quite short and self-contained, which should make it easier to
adapt the proof to different contexts (such as the setting of discrete models).
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:35:18 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 16:08:15 GMT""}]","2023-02-10"
"2301.10082","Thomas Degueule","Corentin Latappy, Quentin Perez (Euromov DHM), Thomas Degueule,
  Jean-R\'emy Falleri (IUF), Christelle Urtado (Euromov DHM), Sylvain Vauttier
  (Euromov DHM), Xavier Blanc, C\'edric Teyton","MLinter: Learning Coding Practices from Examples-Dream or Reality?",,"30th IEEE International Conference on Software Analysis, Evolution
  and Reengineering (SANER), Mar 2023, Macao SAR, Macau SAR China",,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coding practices are increasingly used by software companies. Their use
promotes consistency, readability, and maintainability, which contribute to
software quality. Coding practices were initially enforced by general-purpose
linters, but companies now tend to design and adopt their own company-specific
practices. However, these company-specific practices are often not automated,
making it challenging to ensure they are shared and used by developers.
Converting these practices into linter rules is a complex task that requires
extensive static analysis and language engineering expertise. In this paper, we
seek to answer the following question: can coding practices be learned
automatically from examples manually tagged by developers? We conduct a
feasibility study using CodeBERT, a state-of-the-art machine learning approach,
to learn linter rules. Our results show that, although the resulting
classifiers reach high precision and recall scores when evaluated on balanced
synthetic datasets, their application on real-world, unbalanced codebases,
while maintaining excellent recall, suffers from a severe drop in precision
that hinders their usability.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:40:24 GMT""}]","2023-01-25"
"2301.10083","Alex Ho","Alex Ho, Margrethe Wold, Mohammad Poursina, John T. Conway","The accuracy of mutual potential approximations in simulations of binary
  asteroids","15 pages, 16 figures. Accepted for publication in A&A. The abstract
  has been abridged for arXiv submission","A&A 671, A38 (2023)","10.1051/0004-6361/202245552",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulations of asteroid binaries commonly use mutual gravitational potentials
approximated by series expansions, leading to truncation errors, and also
preventing correct computations of the forces and torques when the bodies are
close. We make of a recently developed method where the mutual potential is
calculated with the use of surface integrals and is exact for bodies of
ellipsoidal shapes. The solutions produced by the surface integration method
are compared with an approach that expands the mutual potential, truncated at
second and fourth order. The approximate solutions are generated with the
``General Use Binary Asteroid Simulator'' (gubas). We find that the differences
in the forces and torques are the largest when the bodies are nearly touching.
These differences can exceed 1000% if the shape of the primary is highly
elongated. Long term simulations show more than 100% difference in the dynamics
if the bodies are initially close, while the differences are negligible if the
bodies are initially far apart. For simulations with two triaxial ellipsoids,
the computational efficiency of the surface integral method is comparable to
fourth order approximations with gubas, and superior to potentials truncated to
order eight or higher.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:42:38 GMT""}]","2023-03-08"
"2301.10084","Andrew Dickerson","Jelle J. Schoppink and Keerthana Mohan and Miguel A. Quetzeri-Santiago
  and Gareth McKinley and David Fernandez Rivas and Andrew K. Dickerson","Cavitation-induced microjets tuned by channels with alternating
  wettability patterns",,,"10.1063/5.0143223",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  A laser pulse focused near the closed end of a glass capillary partially
filled with water creates a vapor bubble and an associated pressure wave. The
pressure wave travels through the liquid toward the meniscus where it is
reflected, creating a fast, focused microjet. In this study, we selectively
coat the hydrophilic glass capillaries with hydrophobic strips along the
capillary. The result after filling the capillary is a static meniscus which
has a curvature markedly different than an unmodified capillary. This tilting
asymmetry in the static meniscus alters the trajectory of the ensuing jets. The
hydrophobic strips also influence the advancing contact line and receding
contact line as the vapor bubble expands and collapses. We present thirteen
different permutations of this system which includes three geometries and four
coating schemes. The combination of geometry and coatings influences the jet
breakup, the resulting drop size distribution, the trajectory of the jet tip,
and the consistency of jet characteristics across trials. The inclusion of
hydrophobic strips promotes jetting in line with the channel axis, with the
most effective arrangement dependent on channel size.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:46:16 GMT""}]","2023-04-05"
"2301.10085","Tao Li","Tao Li and Chunze Zhang and Peiyi Peng and Ji Hou and Qin Zhou and
  Qian Ma","A numerical simulation method of fish adaption behavior based on deep
  reinforcement learning and fluid-structure coupling-realization of some
  lateral line functions",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Improving the numerical method of fish autonomous swimming behavior in
complex environments is of great significance to the optimization of bionic
controller,the design of fish passing facilities and the study of fish
behavior.This work has built a fish autonomous swimming simulation
platform,which adapts the high-precision IB-LBM to simulate the dynamic process
of the interaction between the fish and the flow field in real time,and
realizes the fish brain motion control through the SAC deep reinforcement
learning algorithm.More importantly,in view of the poor generalization of the
existing simulation platform,a method to simulate the fish's lateral line
function is proposed.By adding the Lateral-line machine and designing the
Macro-action system,the intelligent fish has the ability to
recognize,classify,memorize and transplant the corresponding swimming strategy
in the unsteady field.Using this method,the training and simulation of
point-to-point predation swimming and Kamangait test under different inlet
velocities are carried out.In the example of point-to-point predation
swimming,the fish in random position can adjust the swimming posture and speed
autonomously to catch the fast moving food,and has a certain prediction ability
on the movement trajectory of the food.In the Kaman-gait test,the trained fish
are placed in three different Kamangait flow fields,to study its ability to
recognize the flow field and select swimming strategies through experience.The
results of numerical experiments show that,comparing with the other value
function networks,the SAC algorithm based on maximum entropy has more
advantages in convergence speed and training efficiency when simulating fish
brain decision-making.The use of the Lateral line Machine and Macro-action
system can avoid the waste of experience and improve the adaptability of
intelligent fish in the new complex flow field environment.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:47:49 GMT""}]","2023-01-25"
"2301.10086","Sebastian Schulthei{\ss}","Sebastian Schulthei{\ss}","How search engine marketing influences user knowledge gain: Development
  and empirical testing of an information search behavior model",,,"10.1145/3576840.3578297",,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  People use search engines to find answers to questions related to their
health, finances, or other socially relevant issues. However, most users are
unaware that search results are considerably influenced by search engine
marketing (SEM). SEM measures are driven by commercial, political, or other
motives. Due to these motivations, two questions arise: What information
quality is mediated through SEM? And how is collecting documents of different
quality affecting user knowledge gain? Both questions are not considered by
existing models of information behavior. Hence, the doctoral research project
described in this paper aims to develop and empirically test an information
search behavior model on the influences of SEM on user knowledge gain and
thereby contribute to the search as learning body of research.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:48:18 GMT""}]","2023-01-25"
"2301.10087","Elizabeth Bradley","Elizabeth Bradley, Chandra Krintz, and Melanie Moses","Building Resilience to Climate Driven Extreme Events with Computing
  Innovations: A Convergence Accelerator Report",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  In 2022, the National Science Foundation (NSF) funded the Computing Research
Association (CRA) to conduct a workshop to frame and scope a potential
Convergence Accelerator research track on the topic of ""Building Resilience to
Climate-Driven Extreme Events with Computing Innovations"". The CRA's research
visioning committee, the Computing Community Consortium (CCC), took on this
task, organizing a two-part community workshop series, beginning with a small,
in-person brainstorming meeting in Denver, CO on 27-28 October 2022, followed
by a virtual event on 10 November 2022. The overall objective was to develop
ideas to facilitate convergence research on this critical topic and encourage
collaboration among researchers across disciplines. Based on the CCC community
white paper entitled Computing Research for the Climate Crisis, we initially
focused on five impact areas (i.e. application domains that are both important
to society and critically affected by climate change): Energy, Agriculture,
Environmental Justice, Transportation, and Physical Infrastructure.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:49:22 GMT""}]","2023-01-25"
"2301.10088","Yo\`av Montacute","Samson Abramsky and Yo\`av Montacute and Nihil Shah","Linear Arboreal Categories",,,,,"cs.LO math.CT math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Arboreal categories, introduced by Abramsky and Reggio, axiomatise categories
with tree-shaped objects. These categories provide a categorical language for
formalising behavioural notions such as simulation, bisimulation, and
resource-indexing. Comonadic adjunctions between an arboreal category and any
extensional category of objects, called arboreal covers, allow for application
of the behavioural notions to the static objects of the extensional category.
  In this paper, we demonstrate that every arboreal category has an associated
linear arboreal subcategory which admits a categorical version of trace
equivalence and complete trace equivalence. This generalises the connection
between the pebble-relation comonad, of Montacute and Shah, and the pebbling
comonad, of Abramsky, Dawar, and Wang. Specialising to the pebble-relation
comonad, we obtain categorical semantics for equivalence in a restricted
conjunction fragment of infinitary finite variable logic. As another example,
we construct a linear modal comonad recovering trace inclusion, trace
equivalence, and complete trace equivalence between transition systems as
instances of their categorical definitions. We conclude with a new Rossman
preservation theorem relating trace inclusion with trace equivalence, and a van
Benthem characterisation theorem relating complete trace equivalence with a
linear fragment of modal logic.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:52:54 GMT""}]","2023-01-25"
"2301.10089","Vesa Julin","Vesa Julin","Flat flow solution to the mean curvature flow with volume constraint",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper I will revisit the construction of a global weak solution to
the volume preserving mean curvature flow via discrete minimizing movement
scheme by Mugnai-Seis-Spadaro (2016). This method is based on the gradient flow
approach due to Almgren-Taylor-Wang (1993) and Luckhaus-Strurzenhecker (1995)
and my aim is to replace the volume penalization by implementing the volume
constraint directly in the discrete scheme, which from practical point of view
is perhaps more natural. A technical novelty is the proof of the density
estimate which is based on the second variation condition of the energy.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:54:15 GMT""}]","2023-01-25"
"2301.10090","Joseph de Vilmarest","Joseph de Vilmarest, Jethro Browell, Matteo Fasiolo, Yannig Goude (EDF
  R\&D), Olivier Wintenberger (SU)","Adaptive Probabilistic Forecasting of Electricity (Net-)Load",,,,,"stat.AP stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electricity load forecasting is a necessary capability for power system
operators and electricity market participants. The proliferation of local
generation, demand response, and electrification of heat and transport are
changing the fundamental drivers of electricity load and increasing the
complexity of load modelling and forecasting. We address this challenge in two
ways. First, our setting is adaptive; our models take into account the most
recent observations available, yielding a forecasting strategy able to
automatically respond to changes in the underlying process. Second, we consider
probabilistic rather than point forecasting; indeed, uncertainty quantification
is required to operate electricity systems efficiently and reliably. Our
methodology relies on the Kalman filter, previously used successfully for
adaptive point load forecasting. The probabilistic forecasts are obtained by
quantile regressions on the residuals of the point forecasting model. We
achieve adaptive quantile regressions using the online gradient descent; we
avoid the choice of the gradient step size considering multiple learning rates
and aggregation of experts. We apply the method to two data sets: the regional
net-load in Great Britain and the demand of seven large cities in the United
States. Adaptive procedures improve forecast performance substantially in both
use cases for both point and probabilistic forecasting.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:56:14 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 12:33:30 GMT""}]","2023-04-25"
"2301.10091","Karl-Mikael Perfekt","Alexandru Aleman, Karl-Mikael Perfekt, Stefan Richter, Carl Sundberg,
  James Sunkes","Cyclicity and iterated logarithms in the Drury-Arveson space","17 pages",,,,"math.FA math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $H^2_d$ be the Drury-Arveson space, and let $f\in H^2_d$ have bounded
argument and no zeros in $\mathbb{B}_d$. We show that $f$ is cyclic in $H^2_d$
if and only if $\log f$ belongs to the Pick-Smirnov class $N^+(H^2_d)$.
Furthermore, for non-vanishing functions $f\in H^2_d$ with bounded argument and
$H^\infty$-norm less than 1, cyclicity can also be tested via iterated
logarithms. For example, we show that $f$ is cyclic if and only if $\log(1+\log
(1/f))\in N^+(H^2_d)$. Thus, a sufficient condition for cyclicity is that
$\log(1+\log (1/f))\in H^2_d$. More generally, our results hold for all
radially weighted Besov spaces that also are complete Pick spaces.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:56:24 GMT""}]","2023-01-25"
"2301.10092","Charles Dansereau","Charles Dansereau, Milo Sobral, Maninder Bhogal and Mehdi Zalai","Model soups to increase inference without increasing compute time",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we compare Model Soups performances on three different models
(ResNet, ViT and EfficientNet) using three Soup Recipes (Greedy Soup Sorted,
Greedy Soup Random and Uniform soup) from arXiv:2203.05482, and reproduce the
results of the authors. We then introduce a new Soup Recipe called Pruned Soup.
Results from the soups were better than the best individual model for the
pre-trained vision transformer, but were much worst for the ResNet and the
EfficientNet. Our pruned soup performed better than the uniform and greedy
soups presented in the original paper. We also discuss the limitations of
weight-averaging that were found during the experiments. The code for our model
soup library and the experiments with different models can be found here:
https://github.com/milo-sobral/ModelSoup
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:59:07 GMT""}]","2023-01-25"
"2301.10093","Lisa Ackermann","Lisa Ackermann, Clemens Roider, Kristian Cvecek, Nicolas Barr\'e,
  Christian Aigner, Michael Schmidt","Polarization-Controlled Nonlinear Computer-Generated Holography",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Dynamic phase-only beam shaping with a liquid crystal spatial light modulator
is a powerful technique for tailoring the beam's intensity profile or wave
front. While shaping and controlling the light field is a highly researched
topic, dynamic nonlinear beam shaping has hardly been explored so far. One
potential reason is that generating the second harmonic is a degenerate process
as it mixes two fields at the same frequency. To overcome this problem, we
propose the use of type II phase matching as a control mechanism to distinguish
the two involved fields. We experimentally demonstrate that arbitrary intensity
distributions can be shaped in the frequency-converted field at the same
quality as for linear beam shaping and with conversion efficiencies similar to
the case without beam shaping. We envision this technique as a milestone
towards beam shaping beyond the physical limits of liquid crystal displays,
i.e. facilitating dynamic phase-only beam shaping in the ultraviolet spectral
range.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:59:19 GMT""}]","2023-01-25"
"2301.10094","Arttu Arjas","Arttu Arjas, Mikko J. Sillanp\""a\""a and Andreas Hauptmann","Sequential model correction for nonlinear inverse problems","25 pages, 9 figures",,,,"math.NA cs.NA math.FA","http://creativecommons.org/licenses/by/4.0/","  Inverse problems are in many cases solved with optimization techniques. When
the underlying model is linear, first-order gradient methods are usually
sufficient. With nonlinear models, due to nonconvexity, one must often resort
to second-order methods that are computationally more expensive. In this work
we aim to approximate a nonlinear model with a linear one and correct the
resulting approximation error. We develop a sequential method that iteratively
solves a linear inverse problem and updates the approximation error by
evaluating it at the new solution. This treatment convexifies the problem and
allows us to benefit from established convex optimization methods. We
separately consider cases where the approximation is fixed over iterations and
where the approximation is adaptive. In the fixed case we show theoretically
under what assumptions the sequence converges. In the adaptive case,
particularly considering the special case of approximation by first-order
Taylor expansion, we show that with certain assumptions the sequence converges
to a critical point of the original nonconvex functional. Furthermore, we show
that with quadratic objective functions the sequence corresponds to the
Gauss-Newton method. Finally, we showcase numerical results superior to the
conventional model correction method. We also show, that a fixed approximation
can provide competitive results with considerable computational speed-up.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:59:25 GMT""},{""version"":""v2"",""created"":""Fri, 12 May 2023 10:37:55 GMT""}]","2023-05-15"
"2301.10245","Minh Lam Nguyen","Minh Lam Nguyen","The Seiberg-Witten equations for multiple-spinors on $4-$manifolds with
  definite intersection forms","The proof of the theorem in the notes relies on the results stated in
  our other posting arXiv:2301.09693. Specifically, one of the ingredients
  needed is transversality. It is pointed out to us that due to a technicality
  in our set-up, the system of equations that we consider is not elliptic.
  Hence, we should not expect transversality in this set-up",,,,"math.GT math.DG","http://creativecommons.org/licenses/by/4.0/","  In this note, we present a proof of Donaldson's Diagonalization Theorem via
an abelian gauge-theoretic variant of the Seiberg-Witten equations for multiple
spinors. Like the other proof of Donaldson's theorem using the standard
Seiberg-Witten theory, Elkies' theorem also plays a key role in our argument.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 20:01:01 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 23:34:12 GMT""}]","2023-01-30"
"2301.10416","Jiawei Liu","Yongqiang Ma, Jiawei Liu, Fan Yi, Qikai Cheng, Yong Huang, Wei Lu,
  Xiaozhong Liu","AI vs. Human -- Differentiation Analysis of Scientific Content
  Generation",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent neural language models have taken a significant step forward in
producing remarkably controllable, fluent, and grammatical text. Although
studies have found that AI-generated text is not distinguishable from
human-written text for crowd-sourcing workers, there still exist errors in
AI-generated text which are even subtler and harder to spot. We primarily focus
on the scenario in which scientific AI writing assistant is deeply involved.
First, we construct a feature description framework to distinguish between
AI-generated text and human-written text from syntax, semantics, and pragmatics
based on the human evaluation. Then we utilize the features, i.e., writing
style, coherence, consistency, and argument logistics, from the proposed
framework to analyze two types of content. Finally, we adopt several publicly
available methods to investigate the gap of between AI-generated scientific
text and human-written scientific text by AI-generated scientific text
detection models. The results suggest that while AI has the potential to
generate scientific content that is as accurate as human-written content, there
is still a gap in terms of depth and overall quality. The AI-generated
scientific content is more likely to contain errors in factual issues. We find
that there exists a ""writing style"" gap between AI-generated scientific text
and human-written scientific text. Based on the analysis result, we summarize a
series of model-agnostic and distribution-agnostic features for detection tasks
in other domains. Findings in this paper contribute to guiding the optimization
of AI models to produce high-quality content and addressing related ethical and
security concerns.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 04:23:20 GMT""},{""version"":""v2"",""created"":""Sun, 12 Feb 2023 11:58:22 GMT""}]","2023-02-14"
"2301.10557","Shibdas Roy","Shibdas Roy","PSPACE $\subseteq$ BQP","4 pages, 1 figure",,,,"cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The complexity class $PSPACE$ includes all computational problems that can be
solved by a classical computer with polynomial memory. All $PSPACE$ problems
are known to be solvable by a quantum computer too with polynomial memory and
are, therefore, known to be in $BQPSPACE$. Here, we present a polynomial time
quantum algorithm for a $PSPACE$-complete problem, implying that $PSPACE$ is a
subset of the class $BQP$ of all problems solvable by a quantum computer in
polynomial time. In particular, we outline a $BQP$ algorithm for the
$PSPACE$-complete problem of evaluating a full binary $NAND$ tree. An existing
best of quadratic speedup is achieved using quantum walks for this problem,
which is still exponential in the problem size. By contrast, we achieve an
exponential speedup for the problem, allowing for solving it in polynomial
time. There are many real-world applications of our result, such as strategy
games like chess or Go. As an example, in quantum sensing, the problem of
quantum illumination, that is treated as that of channel discrimination, is
$PSPACE$-complete. Our work implies that quantum channel discrimination, and
therefore, quantum illumination, can be performed by a quantum computer in
polynomial time.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:52:36 GMT""}]","2023-01-26"
"2301.10566","Dr. Sumanjit Chakraborty","Sumanjit Chakraborty and D. Chakrabarty","Global asymmetry in $\Delta$X variations during the 06 April 2000
  geomagnetic storm: Relative roles of IMF Bz and By","Accepted for publication in JGR Space Physics on 04 January 2023","Journal of Geophysical Research: Space Physics (2023)","10.1029/2022JA031047",,"physics.space-ph astro-ph.EP astro-ph.SR physics.geo-ph physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  This investigation is directed to understand the asymmetry in $\Delta$X
variations caused due to the relative roles played by IMF Bz and IMF By in a
particular interval (22:22 - 22:55 UT), during the main phase of a strong
geomagnetic storm event of April 06, 2000 (Ap = 236). Two pairs of antipodal
stations, being part of the SuperMAG network, are considered here. Ionospheric
convection maps from SuperDARN network are used to understand spatio-temporal
evolution of the DP2 ionospheric convection patterns over high-latitudes. The
two-dimensional maps of equivalent currents are used to show signatures of
global DP2 currents associated with the interplay effect between the two IMF
components. Observations show increases in the difference in $\Delta$X
variations between nearly antipodal stations from the Japanese-European/African
sector with respect to the same between the nearly antipodal stations from the
Pacific/American-Indian sector. This asymmetry is observed during the period
when the absolute magnitude of IMF By is larger than that of IMF Bz resulting
in a significant and conspicuous enhancement in IMF |By/Bz|. It is suggested
that the distortions in DP2 cells and associated rotation of electrodynamic
day-night divider, bring one pair of stations under the same DP2 cell and one
station of the other pair under a different DP2 cell and throat flow region
leading to the asymmetry in $\Delta$X variations between the antipodal
stations. Therefore, the work highlights the importance of the interplay
between IMF Bz and IMF By in determining the ionospheric impact over low
latitudes during strong geomagnetic conditions.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 10:53:04 GMT""}]","2023-01-26"
"2301.11106","Peter Denton","Peter B. Denton","Klein-Gordon Equation with Self-Interaction $\lambda\phi^4$ and
  Arbitrary Spherical Source Terms","6 pages, 2 figures, comments welcome",,,,"physics.comp-ph hep-ph physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  The Klein-Gordon equation for a scalar field sourced by a spherically
symmetric background is an interesting second-order differential equation with
applications in particle physics, astrophysics, and elsewhere. Here we present
solutions for generic source density profiles in the case where the scalar
field has no interactions or a mass term. For a $\lambda\phi^4$
self-interaction term, we provide the necessary expressions for a numerical
computation, an algorithm to numerically match the initial conditions from
infinity to the origin, and an accurate guess of that initial condition. We
also provide code to perform the numerical calculations that can be adapted for
arbitrary density profiles.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 19:00:02 GMT""}]","2023-01-27"
"2301.11278","S. Stoynev","S. Stoynev (1), M. Baldini (1), S. Feher (1) ((1) Fermilab)","Commissioning, Performance, and Effect of the Quench Current-boosting
  Device on a Dedicated Superconducting Magnet",,,"10.1109/TASC.2023.3261264","FERMILAB-PUB-22-764-TD","physics.ins-det physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Superconducting magnet training is one of the accelerator related issues
attracting attention due to significant operational costs and time budget
associated to it. It is especially worrisome that magnets based on the
next-generation Nb3Sn technology are affected by long training. While various
efforts are underway to better understand and resolve the problem a parallel
path could also be investigated, a path bypassing the issue. Following the
concept of fast induced over-current during magnet powering, FNAL has developed
an upgradable capacitor-based device to discharge through a superconducting
magnet at quench detection or operator chosen time. The 0.4 F/1 kV device has
been tested on a 1-m-long dipole-coil in a mirror magnet configuration and
conclusive results on magnet training elimination have been observed. In this
paper we discuss the main characteristics of the device, compare simulated
response and actual performance, elaborate on test drivers and outcomes. Next
steps and perspectives for future use are debated.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:00:01 GMT""}]","2023-05-03"
"2301.11726","Hadi Mansourifar","Hadi Mansourifar and Steven J. Simske","GAN-Based Object Removal in High-Resolution Satellite Images",,,,,"cs.CV eess.IV","http://creativecommons.org/publicdomain/zero/1.0/","  Satellite images often contain a significant level of sensitive data compared
to ground-view images. That is why satellite images are more likely to be
intentionally manipulated to hide specific objects and structures. GAN-based
approaches have been employed to create forged images with two major problems:
(i) adding a new object to the scene to hide a specific object or region may
create unrealistic merging with surrounding areas; and (ii) using masks on
color feature images has proven to be unsuccessful in GAN-based object removal.
In this paper, we tackle the problem of object removal in high-resolution
satellite images given a limited number of training data. Furthermore, we take
advantage of conditional GANs (CGANs) to collect perhaps the first GAN-based
forged satellite image data set. All forged instances were manipulated via
CGANs trained by Canny Feature Images for object removal. As part of our
experiments, we demonstrate that distinguishing the collected forged images
from authentic (original) images is highly challenging for fake image detector
models.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:23:29 GMT""}]","2023-01-30"
"2301.11925","Yuri Nesterenko R.","Yuri Nesterenko","Octupoles for octahedral symmetry",,,,,"math.NA cs.GR cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spherical harmonics of degree 4 are widely used in volumetric frame fields
design due to their ability to reproduce octahedral symmetry. In this paper we
show how to use harmonics of degree 3 (octupoles) for the same purpose, thereby
reducing number of parameters and computational complexity. The key ingredients
of the presented approach are
  \quad \textbullet \ implicit equations for the manifold of octupoles
possessing octahedral symmetry up to multiplication by $-1$,
  \quad \textbullet \ corresponding rotationally invariant measure of
octupole's deviation from the specified symmetry,
  \quad \textbullet \ smoothing penalty term compensating the lack of
octupoles' symmetries during a field optimization.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 18:28:48 GMT""}]","2023-01-31"
"2302.00635","Sergejs Kozlovi\v{c}s","Sergejs Kozlovi\v{c}s","Shared SAT Solvers and SAT Memory in Distributed Business Applications","This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this contribution is
  published in CCIS vol. 1598, ""Digital Business and Intelligent Systems: 15th
  International Baltic Conference, Baltic DB&IS 2022, Riga, Latvia, July 4-6,
  2022, Proceedings"", pp.201-216, and is available online at
  https://doi.org/10.1007/978-3-031-09850-5_14","CCIS vol. 1598, ""Digital Business and Intelligent Systems: 15th
  International Baltic Conference"" (proceedings), pp.201-216, Riga, Latvia,
  July 4-6, 2022","10.1007/978-3-031-09850-5_14",,"cs.DC cs.LO","http://creativecommons.org/licenses/by/4.0/","  We propose a software architecture where SAT solvers act as a shared network
resource for distributed business applications. There can be multiple parallel
SAT solvers running either on dedicated hardware (a multi-processor system or a
system with a specific GPU) or in the cloud. In order to avoid complex message
passing between network nodes, we introduce a novel concept of the shared SAT
memory, which can be accessed (in the read/write mode) from multiple different
SAT solvers and modules implementing the business logic. As a result, our
architecture allows for the easy generation, diversification, and solving of
SAT instances from existing high-level programming languages without the need
to think about the network. We demonstrate our architecture on the use case of
transforming the integer factorization problem to SAT.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:06:53 GMT""}]","2023-02-02"
"2302.01912","Francesco Mainardi","F. Mainardi, E. Masina, J-L. Gonzales-Santander","A note on the Lambert W function: Bernstein and Stieltjes properties","9 pages, 4 figures",,,,"math.GM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this note is to validate with MATHEMATICA the Bernstein and
Stietltjes properties of the Lambert W function. We show plots that validate
the results known in the literature, but also an extension of the
Perron-Stieltjes formula on a discontinuous function. We assume the branch
W0(t) of the Lambert function that, because it is a Bernstein function, may
find further applications including creep laws in linear viscoelasticity and
distributions in probability
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:28:54 GMT""}]","2023-02-06"
"2302.02824","Ashot Chilingarian Agassi","A. Chilingarian, G. Hovsepyan","Proving new physics by measuring cosmic ray fluxes",,,,,"physics.data-an","http://creativecommons.org/licenses/by/4.0/","  The paper aims to demonstrate how the measurements of different species of
cosmic ray flux can lead to a meaningful physical inference. We want to show
when and how it is possible to path the way from measurement to physical
inference and how we can prove that measurements are not artifacts or equipment
failures but manifestations of a new physical phenomenon.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 06:06:48 GMT""}]","2023-02-07"
"2302.04662","Adish Singla","Tung Phung, Jos\'e Cambronero, Sumit Gulwani, Tobias Kohn, Rupak
  Majumdar, Adish Singla, Gustavo Soares","Generating High-Precision Feedback for Programming Syntax Errors using
  Large Language Models","Published in International Conference on Educational Data Mining
  (EDM) 2023",,,,"cs.PL cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LLMs), such as Codex, hold great promise in enhancing
programming education by automatically generating feedback for students. We
investigate using LLMs to generate feedback for fixing syntax errors in Python
programs, a key scenario in introductory programming. More concretely, given a
student's buggy program, our goal is to generate feedback comprising a fixed
program along with a natural language explanation describing the errors/fixes,
inspired by how a human tutor would give feedback. While using LLMs is
promising, the critical challenge is to ensure high precision in the generated
feedback, which is imperative before deploying such technology in classrooms.
The main research question we study is: Can we develop LLMs-based feedback
generation techniques with a tunable precision parameter, giving educators
quality control over the feedback that students receive? To this end, we
introduce PyFiXV, our technique to generate high-precision feedback powered by
Codex. The key idea behind PyFiXV is to use a novel run-time validation
mechanism to decide whether the generated feedback is suitable for sharing with
the student; notably, this validation mechanism also provides a precision knob
to educators. We perform an extensive evaluation using two real-world datasets
of Python programs with syntax errors and show the efficacy of PyFiXV in
generating high-precision feedback.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:00:25 GMT""},{""version"":""v2"",""created"":""Fri, 28 Apr 2023 11:33:44 GMT""}]","2023-05-01"
"2302.08319","Mikrajuddin Abdullah","Ardi Khalifah, Riri Murniati, Mikrajuddin Abdullah","Magnetic Lens Made of a Single Solenoid for Controlling Bending of
  Two-Dimensional Ion Beam","15 pages, 6 figures",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The magnetic field inside an ideal solenoid cavity with an arbitrary
cross-section is always constant, while it is always zero outside the solenoid.
We can make a solenoid lens that can focus a parallel beam to a point behind it
by adjusting the curvature of the solenoid circumference. In this paper, we
discuss the design of magnetic lenses ranging from simple geometries to the
general ones. We discovered that there are an infinite number of curvatures
that can be used to focus the parallel beam to a specific focal point. Using
this property, we also present the concept of a simple mass spectrometer by
measuring the intensity of the ion captured by a detector placed at the focal
point. This result is expected to enrich learning material in undergraduate
courses, especially for the topic of electricity and magnetism.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 01:07:45 GMT""}]","2023-02-17"
"2302.10240","Herbert J Bernstein","Lawrence C. Andrews and Herbert J. Bernstein","Measuring Lattices","45 pages, 24 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Unit cells are used to represent crystallographic lattices. Calculations
measuring the differences between unit cells are used to provide metrics for
measuring meaningful distances between three-dimensional crystallographic
lattices. This is a surprisingly complex and computationally demanding problem.
We present a review of the current best practice using Delaunay-reduced unit
cells in the six-dimensional real space of Selling scalar cells S6 and the
equivalent three-dimensional complex space C3. The process is a simplified
version of the process needed when working with the more complex
six-dimensional real space of Niggli-reduced unit cells G6. Obtaining a
distance begins with identification of the fundamental region in the space,
continues with conversion to primitive cells and reduction, analysis of
distances to the boundaries of the fundamental unit, and is completed by a
comparison of direct paths to boundary-interrupted paths, looking for a path of
minimal length.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:54:33 GMT""}]","2023-02-22"
"2302.10303","Romain Xu","Romain Xu-Darme (LSL, MRIM ), Julien Girard-Satabin (LSL), Darryl
  Hond, Gabriele Incorvaia, Zakaria Chihani (LSL)","Interpretable Out-Of-Distribution Detection Using Pattern Identification",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Out-of-distribution (OoD) detection for data-based programs is a goal of
paramount importance. Common approaches in the literature tend to train
detectors requiring inside-of-distribution (in-distribution, or IoD) and OoD
validation samples, and/or implement confidence metrics that are often abstract
and therefore difficult to interpret. In this work, we propose to use existing
work from the field of explainable AI, namely the PARTICUL pattern
identification algorithm, in order to build more interpretable and robust OoD
detectors for visual classifiers. Crucially, this approach does not require to
retrain the classifier and is tuned directly to the IoD dataset, making it
applicable to domains where OoD does not have a clear definition. Moreover,
pattern identification allows us to provide images from the IoD dataset as
reference points to better explain the confidence scores. We demonstrates that
the detection capabilities of this approach are on par with existing methods
through an extensive benchmark across four datasets and two definitions of OoD.
In particular, we introduce a new benchmark based on perturbations of the IoD
dataset which provides a known and quantifiable evaluation of the discrepancy
between the IoD and OoD datasets that serves as a reference value for the
comparison between various OoD detection methods. Our experiments show that the
robustness of all metrics under test does not solely depend on the nature of
the IoD dataset or the OoD definition, but also on the architecture of the
classifier, which stresses the need for thorough experimentations for future
work on OoD detection.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 15:35:54 GMT""}]","2023-02-22"
"2302.13829","Erin Tonita Ms.","Erin M. Tonita, Christopher E. Valdivia, Annie C. J. Russell, Michael
  Martinez-Szewczyk, Mariana I. Bertoni, and Karin Hinzer","A general illumination method to predict bifacial photovoltaic system
  performance","PDF file includes the supplementary information","Joule 7(1), P5-12, January 18, 2023","10.1016/j.joule.2022.12.005",,"physics.ins-det physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bifacial photovoltaic technologies are estimated to supply >16% of global
energy demand by 2050 to achieve net-zero greenhouse gas emissions. However,
the current IEC bifacial measurement standard (IEC 60904-1-2) does not provide
a pathway to account for the critical effects of spectral or broadband albedo
on the rear-side irradiance, with in-lab characterization of bifacial devices
limited by overestimation of rear incident irradiance, neglecting spectral
albedo effects on the rear, or both. As a result, prior reports have limited
applicability to the diverse landscapes of bifacial photovoltaic deployments.
In this paper, we identify a general bifacial illumination method which
accounts for spectral albedo while representing realistic system operating
conditions, referred to as the scaled rear irradiance (SRI) method. We describe
how the SRI method extends the IEC standard, facilitating indoor testing of
cell or module performance under varied albedo with standard solar simulator
set-ups. This enables improved comparisons of bifacial technologies,
application-specific optimization, and the standardization of bifacial module
power ratings.
","[{""version"":""v1"",""created"":""Mon, 23 Jan 2023 22:37:26 GMT""}]","2023-02-28"
"2302.13876","Mostafa Hussien","Mostafa Hussien, Islam A.T.F. Taj-Eddin, Mohammed F. A. Ahmed, Ali
  Ranjha, Kim Khoa Nguyen, and Mohamed Cheriet","Evolution of MAC Protocols in the Machine Learning Decade: A
  Comprehensive Survey",,,,,"cs.NI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The last decade, (2012 - 2022), saw an unprecedented advance in machine
learning (ML) techniques, particularly deep learning (DL). As a result of the
proven capabilities of DL, a large amount of work has been presented and
studied in almost every field. Since 2012, when the convolution neural networks
have been reintroduced in the context of \textit{ImagNet} competition, DL
continued to achieve superior performance in many challenging tasks and
problems. Wireless communications, in general, and medium access control (MAC)
techniques, in particular, were among the fields that were heavily affected by
this improvement. MAC protocols play a critical role in defining the
performance of wireless communication systems. At the same time, the community
lacks a comprehensive survey that collects, analyses, and categorizes the
recent work in ML-inspired MAC techniques. In this work, we fill this gap by
surveying a long line of work in this era. We solidify the impact of machine
learning on wireless MAC protocols. We provide a comprehensive background to
the widely adopted MAC techniques, their design issues, and their taxonomy, in
connection with the famous application domains. Furthermore, we provide an
overview of the ML techniques that have been considered in this context.
Finally, we augment our work by proposing some promising future research
directions and open research questions that are worth further investigation.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 02:27:14 GMT""}]","2023-02-28"
"2302.14706","Farimehr Zohari","Farimehr Zohari, S. M. Mahdi Shahabi, and Mehrdad Ardebilipour","A Novel Deep Reinforcement Learning-based Approach for Enhancing
  Spectral Efficiency of IRS-assisted Wireless Systems","4 pages, 4 figures",,,,"eess.SP cs.AI cs.IT cs.NI math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This letter investigates an intelligent reflecting surfaces (IRS)-enhanced
network from spectral efficiency enhancement point of view for downlink
multi-user (MU) multi-input-single-output systems (MISO). In contrast to
previous works which mainly focused on alternative optimization methods, we
investigate the non-convex joint optimization problem of the active transmit
beamforming matrix at the base station together with the passive phase shift
matrix at the IRS by utilizing two deep reinforcement learning frameworks, i.
e., deep deterministic policy gradient (DDPG) and twin delayed DDPG (TD3).
Simulation results reveal that the neural networks in the latter scheme perform
generally more satisfactorily in various situations.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 13:20:03 GMT""}]","2023-03-01"
"2303.02105","Joyanta Jyoti Mondal","Jannatun Noor, Rizwanul Haque Ratul, Mir Rownak Ali Uday, Joyanta
  Jyoti Mondal, Md. Sadiqul Islam Sakif, A. B. M. Alim Al Islam","Sherlock in OSS: A Novel Approach of Content-Based Searching in Object
  Storage System","13 Pages, 9 Figures, Submitted to IEEE Transactions on Parallel and
  Distributed Systems for possible publication. arXiv admin note: substantial
  text overlap with arXiv:1306.3075 by other authors; substantial text overlap
  with arXiv:1910.05786 by other authors without attribution",,,,"cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Object Storage Systems (OSS) inside a cloud promise scalability, durability,
availability, and concurrency. However, open-source OSS does not have a
specific approach to letting users and administrators search based on the data,
which is contained inside the object storage, without involving the entire
cloud infrastructure. Therefore, in this paper, we propose Sherlock, a novel
Content-Based Searching (CoBS) architecture to extract additional information
from images and documents. Here, we store the additional information in an
Elasticsearch-enabled database, which helps us to search for our desired data
based on its contents. This approach works in two sequential stages. First, the
data will be uploaded to a classifier that will determine the data type and
send it to the specific model for the data. Here, the images that are being
uploaded are sent to our trained model for object detection, and the documents
are sent for keyword extraction. Next, the extracted information is sent to
Elasticsearch, which enables searching based on the contents. Because the
precision of the models is so fundamental to the search's correctness, we train
our models with comprehensive datasets (Microsoft COCO Dataset for multimedia
data and SemEval2017 Dataset for document data). Furthermore, we put our
designed architecture to the test with a real-world implementation of an
open-source OSS called OpenStack Swift. We upload images into the dataset of
our implementation in various segments to find out the efficacy of our proposed
model in real-life Swift object storage.
","[{""version"":""v1"",""created"":""Tue, 24 Jan 2023 07:11:14 GMT""},{""version"":""v2"",""created"":""Sat, 6 May 2023 14:44:33 GMT""}]","2023-05-09"
