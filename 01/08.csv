"2301.02658","Shiekh Zia Uddin","Shiekh Zia Uddin","Measuring Power with a Saturated Photodiode","Technical Note",,,,"physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  Accurate measurement of optical power is pivotal in many applications and
scientific research. However, traditional power meters are unable to measure
power levels beyond a certain saturation point, limiting their usefulness in
high-power applications. In this technical note, I discuss how optical power
can be measured using a saturated photodiode. I demonstrate that by monitoring
both the dc photocurrent and ac noise, it is possible to accurately measure
power levels beyond its saturation point.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:04:18 GMT""}]","2023-01-10"
"2301.02852","Shuomin Zhong","Shuomin Zhong, Xuchen Wang, and Sergei A. Tretyakov","Coherent control of wave beams via unidirectional evanescent modes
  excitation","12 pages, 6 figures",,,,"physics.app-ph physics.optics","http://creativecommons.org/publicdomain/zero/1.0/","  Conventional coherent absorption occurs only when two incident beams exhibit
mirror symmetry with respect to the absorbing surface, i.e., the two beams have
the same incident angles, phases, and amplitudes. In this work, we propose a
more general metasurface paradigm for coherent perfect absorption, with
impinging waves from arbitrary asymmetric directions. By exploiting excitation
of unidirectional evanescent waves, the output can be fixed at one reflection
direction for any amplitude and phase of the control wave. We show
theoretically and confirm experimentally that the relative amplitude of the
reflected wave can be tuned continuously from zero to unity by changing the
phase difference between the two beams, i.e. switching from coherent perfect
absorption to full reflection. We hope that this work will open up promising
possibilities for wave manipulation via evanescent waves engineering with
applications in optical switches, one-side sensing, and radar cross section
control.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:57:25 GMT""}]","2023-01-10"
"2301.02880","Ali Altingun","Ali M. Altingun, Emrah Kalemci, Efe Oztaban","A Simulation Study for the Expected Performance of Sharjah-Sat-1 payload
  improved X-Ray Detector (iXRD) in the Orbital Background Radiation","This preprint has not undergone peer review or any post-submission
  improvements or corrections. The Version of Record of this article is
  published in Experimental Astronomy, and is available online at
  https://doi.org/10.1007/s10686-022-09885-2",,"10.1007/s10686-022-09885-2",,"physics.ins-det astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Sharjah-Sat-1 is a 3U cubesat with a CdZnTe based hard X-ray detector, called
iXRD (improved X-ray Detector) as a scientific payload with the primary
objective of monitoring bright X-ray sources in the galaxy. We investigated the
effects of the in-orbit background radiation on the iXRD based on Geant4
simulations. Several background components were included in the simulations
such as the cosmic diffuse gamma-rays, galactic cosmic rays (protons and alpha
particles), trapped protons and electrons, and albedo radiation arising from
the upper layer of the atmosphere. The most dominant component is the albedo
photon radiation which contributes at low and high energies alike in the
instrument energy range of 20 keV - 200 keV. On the other hand, the cosmic
diffuse gamma-ray contribution is the strongest between 20 keV and 60 keV in
which most of the astrophysics source flux is expected. The third effective
component is the galactic cosmic protons. The radiation due to the trapped
particles, the albedo neutrons, and the cosmic alpha particles are negligible
when the polar regions and the South Atlantic Anomaly region are excluded in
the analysis. The total background count rates are ~0.36 and ~0.85 counts/s for
the energy bands of 20 - 60 keV and 20 - 200 keV, respectively. We performed
charge transportation simulations to determine the spectral response of the
iXRD and used it in sensitivity calculations as well. The simulation framework
was validated with experimental studies. The estimated sensitivity of 180 mCrab
between the energy band of 20 keV - 100 keV indicates that the iXRD could
achieve its scientific goals.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:01:49 GMT""}]","2023-01-10"
"2301.02881","Juan M. Z\'arate Pretel","Juan M. Z. Pretel","Moment of inertia of slowly rotating anisotropic neutron stars in
  $f(R,T)$ gravity","9 pages, 5 figures","Mod. Phys. Lett. A 37 (2022) 2250188","10.1142/S0217732322501887",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the framework of $f(R,T)$ theories of gravity, we investigate the
hydrostatic equilibrium of anisotropic neutron stars with a physically relevant
equation of state (EoS) for the radial pressure. In particular, we focus on the
$f(R,T) = R+ 2\beta T$ model, where $\beta$ is a minimal coupling constant. In
the slowly rotating approximation, we derive the modified TOV equations and the
expression for the relativistic moment of inertia. The main properties of
neutron stars, such as radius, mass and moment of inertia, are studied in
detail. Our results revel that the main consequence of the $2\beta T$ term is a
substantial increase in the surface radius for low enough central densities.
Nevertheless, such a term slightly modifies the total gravitational mass and
moment of inertia of the slowly rotating stars. Furthermore, the changes are
noticeable when anisotropy is incorporated into the stellar fluid, and it is
possible to obtain higher masses that are consistent with the current
observational data.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:02:39 GMT""}]","2023-01-10"
"2301.02882","Michael Giles","Michael B Giles","MLMC techniques for discontinuous functions","15 pages, 6 figures, submitted to proceedings of MCQMC22 conference",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  The Multilevel Monte Carlo (MLMC) approach usually works well when estimating
the expected value of a quantity which is a Lipschitz function of intermediate
quantities, but if it is a discontinuous function it can lead to a much slower
decay in the variance of the MLMC correction. This article reviews the
literature on techniques which can be used to overcome this challenge in a
variety of different contexts, and discusses recent developments using either a
branching diffusion or adaptive sampling.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:07:43 GMT""}]","2023-01-10"
"2301.02883","Michael Eides","Michael I. Eides","One-loop electron mass and QED trace anomaly","11 pages, 4 figures",,"10.1140/epjc/s10052-023-11535-6",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Electron mass is considered as a matrix element of the energy-momentum trace
in the rest frame. The one-loop diagrams for this matrix element are different
from the textbook diagrams for the electron mass renormalization. We clarify
connection between the two sets of diagrams and explain analytically and
diagrammatically why the results of both calculations coincide.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:11:22 GMT""},{""version"":""v2"",""created"":""Thu, 4 May 2023 01:44:13 GMT""}]","2023-05-24"
"2301.02884","Shangda Wu","Shangda Wu, Maosong Sun","TunesFormer: Forming Tunes with Control Codes","9 pages, 11 figures",,,,"cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  In recent years, deep learning techniques have been applied to music
generation systems with promising results. However, one of the main challenges
in this field has been the lack of annotated datasets, making it difficult for
models to learn musical forms in compositions. To address this issue, we
present TunesFormer, a Transformer-based melody generation system that is
trained on a large dataset of 285,449 ABC tunes. By utilizing specific symbols
commonly found in ABC notation to indicate section boundaries, TunesFormer can
understand and generate melodies with given musical forms based on control
codes. Our objective evaluations demonstrate the effectiveness of the control
codes in achieving controlled musical forms, and subjective experiments show
that the generated melodies are of comparable quality to human compositions.
Our results also provide insights into the optimal placement of control codes
and their impact on the generated melodies. TunesFormer presents a promising
approach for generating melodies with desired musical forms through the use of
deep learning techniques.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:11:55 GMT""}]","2023-01-10"
"2301.02885","Yanhui Zhu","Yanhui Zhu, Fang Hu, Lei Hsin Kuo, Jia liu","SCOREH+: A High-Order Node Proximity Spectral Clustering on
  Ratios-of-Eigenvectors Algorithm for Community Detection",,,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  Complex network analysis has brought significant advances in uncovering
network mesoscopic properties. Community detection is one of the significant
features of understanding real-world complex systems. In this paper, we propose
a High-order node proximity Spectral Clustering on Ratios-of-Eigenvectors
(SCOREH+) algorithm for finding communities in complex networks. This algorithm
preserves high-order transitivity information of the network affinity matrix.
First, we construct the high-order proximity matrix from the original affinity
matrix using the Radial Basis Functions (RBFs) and Katz index. Furthermore, we
obtain the normalized Laplacian matrix and the normalized leading eigenvectors.
The ratios of the leading eigenvectors aid in mitigating the effect of degree
heterogeneity. Moreover, we implement a procedure that joins an additional
eigenvector (the $(K+1)^{th}$ leading eigenvector) to the spectrum domain for
clustering if the network is considered to be a ``weak signal"" graph. Finally,
we apply the K-means algorithm to the spectrum domain for acquiring the node
labels. We compare our SCOREH+ algorithm with spectral clustering (SC),
Spectral Clustering on Ratios-of-Eigenvectors (SCORE), and SCORE+. To
demonstrate the high effectiveness of our algorithm, we conducted comparison
experiments on $11$ real-world networks and several synthetic networks with
noise. The experimental results demonstrate that our SCOREH+ outperforms SC,
SCORE, and SCORE+ on most of these networks. In addition, we find that by
tuning the RBFs and their shaping parameters, we can obtain state-of-the-art
community structures on all real-world networks and even on noisy synthetic
networks.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:12:17 GMT""}]","2023-01-10"
"2301.02886","Han Han","Han Han, Vincent Lostanlen, Mathieu Lagrange","Perceptual-Neural-Physical Sound Matching",,,,,"cs.SD cs.LG eess.AS","http://creativecommons.org/licenses/by/4.0/","  Sound matching algorithms seek to approximate a target waveform by parametric
audio synthesis. Deep neural networks have achieved promising results in
matching sustained harmonic tones. However, the task is more challenging when
targets are nonstationary and inharmonic, e.g., percussion. We attribute this
problem to the inadequacy of loss function. On one hand, mean square error in
the parametric domain, known as ""P-loss"", is simple and fast but fails to
accommodate the differing perceptual significance of each parameter. On the
other hand, mean square error in the spectrotemporal domain, known as ""spectral
loss"", is perceptually motivated and serves in differentiable digital signal
processing (DDSP). Yet, spectral loss is a poor predictor of pitch intervals
and its gradient may be computationally expensive; hence a slow convergence.
Against this conundrum, we present Perceptual-Neural-Physical loss (PNP). PNP
is the optimal quadratic approximation of spectral loss while being as fast as
P-loss during training. We instantiate PNP with physical modeling synthesis as
decoder and joint time-frequency scattering transform (JTFS) as spectral
representation. We demonstrate its potential on matching synthetic drum sounds
in comparison with other loss functions.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:17:48 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 17:16:37 GMT""}]","2023-03-14"
"2301.02887","Christian Lange","Christian Lange","Orbifolds and manifold quotients with upper curvature bounds","5 pages",,,,"math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize Riemannian orbifolds with an upper curvature bound in the
Alexandrov sense as reflectofolds, i.e. Riemannian orbifolds all of whose local
groups are generated by reflections, with the same upper bound on the sectional
curvature. Combined with a result by Lytchak--Thorbergsson this implies that a
quotient of a Riemannian manifold by a closed group of isometries has locally
bounded curvature (from above) in the Alexandrov sense if and only if it is a
reflectofold.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:21:15 GMT""}]","2023-01-10"
"2301.02888","Kirill Lazebnik","Christopher J. Bishop, Kirill Lazebnik","A Geometric Approach to Polynomial and Rational Approximation",,,,,"math.CV math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We strengthen the classical approximation theorems of Weierstrass, Runge and
Mergelyan by showing the polynomial and rational approximants can be taken to
have a simple geometric structure. In particular, when approximating a function
$f$ on a compact set $K$, the critical points of our approximants may be taken
to lie in any given domain containing $K$, and all the critical values in any
given neighborhood of the polynomially convex hull of $f(K)$.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:26:49 GMT""},{""version"":""v2"",""created"":""Sat, 11 Feb 2023 05:50:45 GMT""}]","2023-02-14"
"2301.02889","Zirou Qiu","Zirou Qiu, Chen Chen, Madhav V. Marathe, S. S. Ravi, Daniel J.
  Rosenkrantz, Richard E. Stearns, Anil Vullikanti","Networked Anti-Coordination Games Meet Graphical Dynamical Systems:
  Equilibria and Convergence","AAAI-23",,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  Evolutionary anti-coordination games on networks capture real-world strategic
situations such as traffic routing and market competition. In such games,
agents maximize their utility by choosing actions that differ from their
neighbors' actions. Two important problems concerning evolutionary games are
the existence of a pure Nash equilibrium (NE) and the convergence time of the
dynamics. In this work, we study these two problems for anti-coordination games
under sequential and synchronous update schemes. For each update scheme, we
examine two decision modes based on whether an agent considers its own previous
action (self essential ) or not (self non-essential ) in choosing its next
action. Using a relationship between games and dynamical systems, we show that
for both update schemes, finding an NE can be done efficiently under the self
non-essential mode but is computationally intractable under the self essential
mode. To cope with this hardness, we identify special cases for which an NE can
be obtained efficiently. For convergence time, we show that the best-response
dynamics converges in a polynomial number of steps in the synchronous scheme
for both modes; for the sequential scheme, the convergence time is polynomial
only under the self non-essential mode. Through experiments, we empirically
examine the convergence time and the equilibria for both synthetic and
real-world networks.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:32:22 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 18:25:09 GMT""}]","2023-03-06"
"2301.02890","Iskandar Sattarov Abu-Aliyevich","I.A. Sattarov, E.T. Aliev","Ergodicity and periodic orbits of $p$-adic $(1,2)$-rational dynamical
  systems with two fixed points",,,,,"math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We consider $(1,2)$-rational functions given on the field of $p$-adic numbers
$\mathbb Q_p$. In general, such a function has four parameters. We study the
case when such a function has two fixed points and show that when there are two
fixed points then $(1,2)$-rational function is conjugate to a two-parametric
$(1,2)$-rational function. Depending on these two parameters we determine the
type of the fixed points, find Siegel disks and the basin of attraction of the
fixed points. Moreover, we classify invariant sets and study the ergodicity
properties of the function on each invariant set. We describe 2- and 3-periodic
orbits of the $p$-adic dynamical systems generated by the two-parametric
$(1,2)$-rational functions.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:33:07 GMT""}]","2023-01-10"
"2301.02891","Clebson Cruz","Clebson Cruz, Maron F. Anka, Hamid-Reza Rastegar-Sedehi and Cleidson
  Castro","Geometric quantum discord and coherence in a dipolar interacting
  magnetic system",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The study of low-dimensional metal complexes has revealed fascinating
characteristics regarding the ground-state crossover shown by spin-gaped
systems. In this context, this work explores the effect of the quantum-level
crossing, induced by the magnetic anisotropies of dipolar interacting systems,
on the quantum discord and coherence of the system. The analytical expressions
for the quantum discord, based on Schatten 1-norm, and the $l_1$ trace-norm
quantum coherence for dinuclear spin-1/2 systems, are provided in terms of the
magnetic anisotropies. The results show that, while the quantum discord has a
clear signature of the quantum level-crossing, the basis dependence of the
quantum coherence hides the crossover regarding the measured basis. In
addition, the global quantum coherence is wholly stored within the correlations
of the system, regardless of its reference basis.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:45:17 GMT""}]","2023-01-10"
"2301.02892","Victor Velasco Roland Da Silva","Victor Velasco and Marcello B. Silva Neto","Disorder-induced finite center-of-mass momentum Cooper pairing and its
  consequences to the critical temperature and superconducting gap of overdoped
  cuprates","11 pages, 6 figures",,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most studied classes of unconventional high-temperature
superconductors is the hole-doped cuprates, where special attention is given to
those doped with extra interstitial oxygens. In this context, the formation of
spatially inhomogeneous agglomerates of dopant oxygen atoms in the form of
nanosized puddles is not only relevant, but also subject of intense recent
experimental and theoretical surveys. Following these efforts, in this work we
show the consequences of the presence of networks of oxygen puddles in the
superconducting state of overdoped cuprates. Starting from the inhomogeneous
disordered background brought by the network of puddles, we show that an
effective interaction between electrons can be mediated by the local
vibrational degrees of freedom of each puddle, but the pairs arising from this
interaction have a finite center-of-mass momentum $\mathbf{p}$, thus breaking
up the Cooper channel. Furthermore, we derive an analytical expression for the
amplitude of the superconducting gap $\Delta_\mathbf{k}$ in terms of disorder
and finite center-of-mass momentum and show that amplitude fluctuations are
induced in the superconducting state by the presence of the puddles, where both
the gap and the critical temperature are affect and reduced by disorder and
finite momentum pairs. Finally, we discuss our findings in the context of
networks of superconducting oxygen nano-puddles in cuprates.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:57:35 GMT""}]","2023-01-10"
"2301.02893","Billy Javier","Billy S. Javier, Leo P. Paliuanan, James Karl A. Agpalza, Jesty S.
  Agoto","MangngalApp -- An integrated package of technology for COVID-19 response
  and rural development: Acceptability and usability using TAM","University-approved project","Journal of Biodiversity and Environmental Science, November 2022,
  V21, No4, pp109-117",,,"cs.CY cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The COVID19 pandemic has challenged universities and organizations to devise
mechanisms to uplift the well-being and welfare of people and communities. In
response, the design and development of an integrated package of technologies,
MangngalApp -- A web-based portal and mobile responsive application for rural
development served as an opportunity. It showcases different packets of
technologies that were outputs of R&D in the field of fisheries and
aqua-culture, innovations that were IP-protected, and technologies that harness
locally available resources for post-harvest development and aiding in
sustaining growth and development in the communities. This paper focused on the
usability and acceptability of the MangngalApp implementing a descriptive
research design using the Technology Acceptance Model or TAM and ISO 25010
software quality standards. Constrained by government health restrictions due
to COVID-19, a Google form-based questionnaire was forwarded to consented
participants via an email with the attached consent and evaluation form.
Results revealed that the MangngalApp was found to be very acceptable and
usable, and compliant to ISO 25010 software quality characteristics to the
higher extent. From the results, it is concluded that the developed MangngalApp
will be a usable and responsive technology that aids to rural development
especially among target users: fishers, gatherers, processors, traders, and
farmers. Considering compatibility and usefulness, the MangngalApp is expected
to provide greater social development in the community.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:58:42 GMT""}]","2023-01-10"
"2301.02894","Randy Kuang","Randy Kuang and Adrian Chan","Quantum Encryption in Phase Space using Displacement Operator for QPSK
  Data Modulation","6 pages, 5 figures, for conference submission",,,,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2020, Kuang and Bettenburg proposed Quantum Public Key Distribution (QPKE)
which utilized the randomized phase shift gate. Since then, it has been
implemented both theoretically through simulations and experimentally over
existing fiber optical networks. QPKE can be compared to an RSA-type scheme but
in the optical analogue domain. Later on, it was renamed Quantum Encryption in
Phase Space (QEPS) to emphasize the encryption of coherent states in phase
space. However, the phase shift gate used in QEPS is limited to data modulation
schemes with phase shift keying such as quadrature phase shift keying (QPSK) as
it may leak data information in amplitude if applied to quadrature amplitude
modulation (QAM) schemes. Recently, Kuang and Chan proposed a new version of
QEPS known as Quantum Encryption in Phase Space with the displacement gate or
QEPS-d, which overcomes the limitation of QEPS with the phase shift gate. This
was achieved by introducing a reduced displacement operator that ignores the
global phase factor, making the reduced displacement operators commutable, thus
aiding the implementation at both transmission and reception. Furthermore, any
arbitrary displacement operator can be decoupled into a standard QAM modulation
with a phase shift modulation, making encryption and decryption easier. This
paper demonstrates the simulation of QEPS-d encryption for QPSK data modulation
to illustrate how QEPS-d functions.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:58:48 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 21:45:19 GMT""}]","2023-03-03"
"2301.02895","Paul Bressloff","Paul C. Bressloff","Renewal equations for single-particle diffusion in multi-layered media","26 pages, 5 figures",,,,"cond-mat.stat-mech math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we develop a probabilistic model of single-particle diffusion
in 1D multi-layered media by constructing a multi-layered version of so-called
snapping out Brownian motion (BM). The latter sews together successive rounds
of reflected BM, each of which is restricted to a single layer. Each round of
reflected BM is killed when the local time at one end of the layer exceeds an
independent, exponentially distributed random variable. (The local time
specifies the amount of time a reflected Brownian particle spends in a
neighborhood of a boundary.) The particle then immediately resumes reflected BM
in the same layer or the layer on the other side of the boundary with equal
probability, and the process is iterated We proceed by constructing a last
renewal equation for multi-layered snapping out BM that relates the full
probability density to the probability densities of partially reflected BM in
each layer. We then show how transfer matrices can be used to solve the Laplace
transformed renewal equation, and prove that the renewal equation and
corresponding multi-layer diffusion equation are equivalent. We illustrate the
theory by analyzing the first passage time (FPT) problem for escape at the
exterior boundaries of the domain. Finally, we use the renewal approach to
incorporate a generalization of snapping out BM based on the encounter-based
method for surface absorption; each round of reflected BM is now killed
according to a non-exponential distribution for each local time threshold. This
is achieved by considering a corresponding first renewal equation that relates
the full probability density to the FPT densities for killing each round of
reflected BM. We show that for certain configurations, non-exponential killing
leads to an effective time-dependent permeability that is normalizable but
heavy-tailed.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:59:54 GMT""}]","2023-01-10"
"2301.02896","Devvrat Joshi","Devvrat Joshi, Janvi Thakkar","k-Means SubClustering: A Differentially Private Algorithm with Improved
  Clustering Quality","Accepted at PAS Workshop at CIKM 2022",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In today's data-driven world, the sensitivity of information has been a
significant concern. With this data and additional information on the person's
background, one can easily infer an individual's private data. Many
differentially private iterative algorithms have been proposed in interactive
settings to protect an individual's privacy from these inference attacks. The
existing approaches adapt the method to compute differentially private(DP)
centroids by iterative Llyod's algorithm and perturbing the centroid with
various DP mechanisms. These DP mechanisms do not guarantee convergence of
differentially private iterative algorithms and degrade the quality of the
cluster. Thus, in this work, we further extend the previous work on
'Differentially Private k-Means Clustering With Convergence Guarantee' by
taking it as our baseline. The novelty of our approach is to sub-cluster the
clusters and then select the centroid which has a higher probability of moving
in the direction of the future centroid. At every Lloyd's step, the centroids
are injected with the noise using the exponential DP mechanism. The results of
the experiments indicate that our approach outperforms the current
state-of-the-art method, i.e., the baseline algorithm, in terms of clustering
quality while maintaining the same differential privacy requirements. The
clustering quality significantly improved by 4.13 and 2.83 times than baseline
for the Wine and Breast_Cancer dataset, respectively.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:07:12 GMT""}]","2023-01-10"
"2301.02897","Thakur Yadav","S.K. Verma, M.A. Shaz, T.P.Yadav","Catalytic action of two-dimensional layered materials (WS2, and MoS2) on
  hydrogen sorption properties of MgH2","24 pages 12 Figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The present study reports the catalytic action of two-dimensional (2D)
layered materials (MoS2 and WS2) for improving the de/re-hydrogenation kinetics
of MgH2. The MgH2 start desorbing at 277 C with a hydrogen storage capacity of
5.95 wt% in the presence of WS2 catalyst whereas onset desorption temperature
of MgH2 catalyzed by MoS2 is 330 C. The MgH2-WS2 absorbed hydrogen ~ 3.72 wt%
within 1.3 minutes at 300 C under 13 atm hydrogen pressure and it desorbed
~5.57 wt% within 20 minutes at 300 C under 1 atm hydrogen pressure. We have
performed 25 cycles of dehydrogenation (under 1 atm hydrogen pressure at 300 C)
and re-hydrogenation (under 13 atm hydrogen pressure at 300 {\deg}C) to ensure
cyclic stability of catalyzed version of MgH2 where MgH2-WS2 shows better
cyclic stability than MgH2-MoS2. MgH2-WS2 also shows the lower reaction
activation energy ~117 kJ/mol as compare to other catalyzed and uncatalyzed
samples. On the other hand, these catalysts (WS2 and MoS2) do not have any
impact on the thermodynamical parameters that is change in enthalpy.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:09:52 GMT""}]","2023-01-10"
"2301.02898","Pierre Schapira","Pierre Schapira","A truncated manuscript","Already published by Inference-Review","Inference-Review.com Vol 7, issue 3, Dec 2022","10.37282/991819.22.61",,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A critical essay of the book ``R\'ecoltes et Semailles'' by Alexander
Grothendieck, recently published by Gallimard editions.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:10:03 GMT""}]","2023-01-10"
"2301.02899","Antoine Chambert-Loir","Antoine Chambert-Loir, Maxim Kontsevich, Yuri Tschinkel","Burnside rings and volume forms with logarithmic poles","28 pages. Correction of lapsus in {\S}7",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a theory of Burnside rings in the context of birational
equivalences of algebraic varieties equipped with logarithmic volume forms. We
introduce a residue homomorphism and construct an additive invariant of
birational morphisms. We also define a specialization homomorphism.
  --
  Nous proposons une th\'eorie d'anneaux de Burnside dans le contexte de la
g\'eom\'etrie birationnelle des vari\'et\'es alg\'ebriques munies d'une forme
volume \`a p\^oles logarithmiques. Nous introduisons un homomorphisme
{\guillemotleft} r\'esidu {\guillemotright}, construisons un invariant additif
des morphismes birationnels. Nous d\'efinissons aussi un homomorphisme de
sp\'ecialisation.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:12:34 GMT""},{""version"":""v2"",""created"":""Fri, 13 Jan 2023 16:40:36 GMT""}]","2023-01-16"
"2301.02900","David Ssevviiri Professor","Philly Ivan Kimuli and David Ssevviiri","Characterizations of regular modules","19 pages","International Electronic Journal of Algebra, 2022","10.24330/ieja.1224782",,"math.AC math.RA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Different and distinct notions of regularity for modules exist in the
literature. When these notions are restricted to commutative rings, they all
coincide with the well-known von-Neumann regularity for rings. We give new
characterizations of these distinct notions for modules in terms of both
(weakly-)morphic modules and reduced modules. Furthermore, module theoretic
settings are established where these in general distinct notions turn out to be
indistinguishable.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:16:09 GMT""}]","2023-01-10"
"2301.02901","Joe Jackson","Joe Jackson and Daniel Lacker","Approximately optimal distributed stochastic controls beyond the mean
  field setting",,,,,"math.PR math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study high-dimensional stochastic optimal control problems in which many
agents cooperate to minimize a convex cost functional. We consider both the
full-information problem, in which each agent observes the states of all other
agents, and the distributed problem, in which each agent observes only its own
state. Our main results are sharp non-asymptotic bounds on the gap between
these two problems, measured both in terms of their value functions and optimal
states. Along the way, we develop theory for distributed optimal stochastic
control in parallel with the classical setting, by characterizing optimizers in
terms of an associated stochastic maximum principle and a Hamilton-Jacobi-type
equation. By specializing these results to the setting of mean field control,
in which costs are (symmetric) functions of the empirical distribution of
states, we derive the optimal rate for the convergence problem in the
displacement convex regime.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:23:35 GMT""}]","2023-01-10"
"2301.02902","Narender Khatri","Narender Khatri and Raymond Kapral","Inertial effects on rectification and diffusion of active Brownian
  particles in an asymmetric channel","7 pages, 7 figures","J. Chem. Phys. 158, 124903 (2023)","10.1063/5.0141696",,"cond-mat.soft physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Micro- and nano-swimmers moving in a fluid solvent confined by structures
that produce entropic barriers are often described by overdamped active
Brownian particle dynamics, where viscous effects are large and inertia plays
no role. However, inertial effects should be considered for confined swimmers
moving in media where viscous effects are no longer dominant. Here, we study
how inertia affects the rectification and diffusion of self-propelled particles
in a two-dimensional asymmetric channel. We show that most of the particles
accumulate at the channel walls as the masses of the particles increase.
Furthermore, the average particle velocity has a maximum as a function of the
mass, indicating that particles with an optimal mass $M^{*}_{\rm op}$ can be
sorted from a mixture with particles of other masses. In particular, we find
that the effective diffusion coefficient exhibits an enhanced diffusion peak as
a function of the mass, which is a signature of the accumulation of most of the
particles at the channel walls. The dependence of $M^{*}_{\rm op}$ on the
rotational diffusion rate, self-propulsion force, aspect ratio of the channel,
and active torque is also determined. The results of this study could stimulate
the development of strategies for controlling the diffusion of self-propelled
particles in entropic ratchet systems.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:23:58 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 21:05:40 GMT""}]","2023-03-28"
"2301.02903","Byoungjip Kim","Byoungjip Kim, Sungik Choi, Dasol Hwang, Moontae Lee, Honglak Lee","Transferring Pre-trained Multimodal Representations with Cross-modal
  Similarity Matching","20 pages, 10 figures, NeurIPS 2022",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Despite surprising performance on zero-shot transfer, pre-training a
large-scale multimodal model is often prohibitive as it requires a huge amount
of data and computing resources. In this paper, we propose a method (BeamCLIP)
that can effectively transfer the representations of a large pre-trained
multimodal model (CLIP-ViT) into a small target model (e.g., ResNet-18). For
unsupervised transfer, we introduce cross-modal similarity matching (CSM) that
enables a student model to learn the representations of a teacher model by
matching the relative similarity distribution across text prompt embeddings. To
better encode the text prompts, we design context-based prompt augmentation
(CPA) that can alleviate the lexical ambiguity of input text prompts. Our
experiments show that unsupervised representation transfer of a pre-trained
vision-language model enables a small ResNet-18 to achieve a better ImageNet-1K
top-1 linear probe accuracy (66.2%) than vision-only self-supervised learning
(SSL) methods (e.g., SimCLR: 51.8%, SwAV: 63.7%), while closing the gap with
supervised learning (69.8%).
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:24:11 GMT""}]","2023-01-10"
"2301.02904","Ngoc Q. Duong","Ngoc Q. Duong and Amy J. Pitts and Soohyun Kim and Caleb H. Miles","Sensitivity analysis for transportability in multi-study, multi-outcome
  settings",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Existing work in data fusion has covered identification of causal estimands
when integrating data from heterogeneous sources. These results typically
require additional assumptions to make valid estimation and inference. However,
there is little literature on transporting and generalizing causal effects in
multiple-outcome setting, where the primary outcome is systematically missing
on the study level but for which other outcome variables may serve as proxies.
We review an identification result developed in ongoing work that utilizes
information from these proxies to obtain more efficient estimators and the
corresponding key identification assumption. We then introduce methods for
assessing the sensitivity of this approach to the identification assumption.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:33:31 GMT""}]","2023-01-10"
"2301.02905","Jinyuan Jia","Wenjie Qu and Jinyuan Jia and Neil Zhenqiang Gong","REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust
  Encoder as a Service","To appear in Network and Distributed System Security (NDSS)
  Symposium, 2023",,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Encoder as a service is an emerging cloud service. Specifically, a service
provider first pre-trains an encoder (i.e., a general-purpose feature
extractor) via either supervised learning or self-supervised learning and then
deploys it as a cloud service API. A client queries the cloud service API to
obtain feature vectors for its training/testing inputs when training/testing
its classifier (called downstream classifier). A downstream classifier is
vulnerable to adversarial examples, which are testing inputs with carefully
crafted perturbation that the downstream classifier misclassifies. Therefore,
in safety and security critical applications, a client aims to build a robust
downstream classifier and certify its robustness guarantees against adversarial
examples.
  What APIs should the cloud service provide, such that a client can use any
certification method to certify the robustness of its downstream classifier
against adversarial examples while minimizing the number of queries to the
APIs? How can a service provider pre-train an encoder such that clients can
build more certifiably robust downstream classifiers? We aim to answer the two
questions in this work. For the first question, we show that the cloud service
only needs to provide two APIs, which we carefully design, to enable a client
to certify the robustness of its downstream classifier with a minimal number of
queries to the APIs. For the second question, we show that an encoder
pre-trained using a spectral-norm regularization term enables clients to build
more robust downstream classifiers.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:40:11 GMT""}]","2023-01-10"
"2301.02906","Luffina Huang","Luffina C. Huang","A Greedy-optimized Framework for Heart Rate Variability Monitoring
  during Daily Activities using Wearable Photoplethysmography",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous monitoring of inter-beat-interval (IBI) and heart rate variability
(HRV) provides insights in cardiovascular, neurological, and mental health.
Photoplethysmography (PPG) from wearables assures convenient measurement of
IBI. However, PPG is susceptible to motion artifacts, considerably
deteriorating the accuracy of IBIs estimation. Although a multi-channel model
in previous study improves accuracy, prevailing compact commercial wearables
would favor single-channel sensors, causing benefits of multi-channel
applications to have restrictions. In this paper, a greedy-optimized framework
is proposed for measurement of IBI and HRV featuring single-channel and
multi-channel PPG signals collected during daily activities. Utilizing the fact
of continuity in heartbeats, the IBI estimation problem is converted into the
shortest path problem in a directed acyclic graph, where candidate heartbeats
from the noisy PPG are regarded as vertices. The framework exploits a convex
penalty function to optimize weight assignment in the shortest path calculation
and a greedy-optimized fusion method to mitigate overly fluctuating patterns in
estimated IBIs. The results achieve correlation of 0.96 with percentage error
of 3.2% for IBI estimation using single-channel PPG signals from the 2015 IEEE
Signal Processing Cup dataset, where percentage error is reduced by 58.4% and
correlation is improved by 11.6% in comparison to those without
greedy-optimized fusion. In the multi-channel model, it achieves correlation of
0.98 with percentage error of 2.2%. Estimated and true HRV parameters are also
highly correlated with low percentage errors. This paper further validates
these techniques on the PPG-DaLiA dataset, indicating the robustness of the
proposed framework.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:49:28 GMT""}]","2023-01-10"
"2301.02907","Angela Bonaccorso Dr.","C. V. Sukumar, A. Bonaccorso","David Maurice Brink, 20 July 1930 - 8 March 2021","A slightly shortened version of this article was published in the
  Biographical Memoirs of Fellows of the Royal Society,Volume 73","Biographical Memoirs of Fellows of the Royal Society, Volume 73,
  2022, pag.65 - 83","10.1098/rsbm.2022.0020open_in_new",,"physics.hist-ph nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  David Brink was one of the leading theoretical nuclear physicists of his
generation. He made major contributions to the study of all aspects of nuclear
physics embracing nuclear structure, nuclear scattering, and nuclear
instability. His wide ranging interests and interactions with theorists and
experimentalists alike helped him in providing both theoretical analysis and
interpretations and suggesting experiments. He had the gift of visualising
complex problems in simple terms and provided clear analysis of the underlying
processes. He was an expert on the use of semi-classical methods which provided
an intuitively clear picture of complex phenomena. His research work and books
are characterised by scientific clarity, transparency, and depth. David
possessed outstanding skills in mathematical computation, and he was an expert
on special functions, group theory, and the Feynman path integral method. David
had many research students and collaborated with a large number of scientists
from across the world, for whom he was a source of scientific and human
inspiration and admiration. His most fundamental belief was that research was a
means of trying to discover and understand the beauties of Nature and explain
them in simple terms to others. His absolute belief in the value of truth and
his unselfish and generous attitude in sharing knowledge makes him an
outstanding figure in contemporary Nuclear Physics.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:55:13 GMT""}]","2023-01-10"
"2301.02908","Stefan Ivkovic","Stefan Ivkovic, Serap Oztop, Seyyed Mohammad Tabatabaie","Dynamical properties and some classes of non-porous subsets",,,,,"math.FA","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we introduce several classes of non-{\sigma}-porous subsets of
a general Lebesgue space. Also, we study some linear dynamics of operators and
show that the set of all non-hypercyclic vectors of a sequence of weighted
translation operators on Lp-spaces is not {\sigma}-porous.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:56:42 GMT""}]","2023-01-10"
"2301.02909","Lorenzo Perini","Lorenzo Perini, Daniele Giannuzzi, Jesse Davis","How to Allocate your Label Budget? Choosing between Active Learning and
  Learning to Reject in Anomaly Detection","Paper presented at the 1st AAAI Workshop on Uncertainty Reasoning and
  Quantification in Decision Making",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Anomaly detection attempts at finding examples that deviate from the expected
behaviour. Usually, anomaly detection is tackled from an unsupervised
perspective because anomalous labels are rare and difficult to acquire.
However, the lack of labels makes the anomaly detector have high uncertainty in
some regions, which usually results in poor predictive performance or low user
trust in the predictions. One can reduce such uncertainty by collecting
specific labels using Active Learning (AL), which targets examples close to the
detector's decision boundary. Alternatively, one can increase the user trust by
allowing the detector to abstain from making highly uncertain predictions,
which is called Learning to Reject (LR). One way to do this is by thresholding
the detector's uncertainty based on where its performance is low, which
requires labels to be evaluated. Although both AL and LR need labels, they work
with different types of labels: AL seeks strategic labels, which are evidently
biased, while LR requires i.i.d. labels to evaluate the detector's performance
and set the rejection threshold. Because one usually has a unique label budget,
deciding how to optimally allocate it is challenging. In this paper, we propose
a mixed strategy that, given a budget of labels, decides in multiple rounds
whether to use the budget to collect AL labels or LR labels. The strategy is
based on a reward function that measures the expected gain when allocating the
budget to either side. We evaluate our strategy on 18 benchmark datasets and
compare it to some baselines.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:02:43 GMT""}]","2023-01-10"
"2301.02910","NgocLoan Phan Ms","Doan-An Trieu, Ngoc-Loan Phan, Quan-Hao Truong, Hien T. Nguyen, Cam-Tu
  Le, DinhDuy Vu and Van-Hoang Le","Universality in odd-even harmonic generation and application in
  terahertz waveform sampling",,,,,"quant-ph physics.comp-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Odd-even harmonics emitted from a laser-target system imprint rich, subtle
information characterizing the system's dynamical asymmetry, which is desirable
to decipher. In this Letter, we discover a simple universal relation between
the odd-even harmonics and the asymmetry of the THz-assisted laser-atomic
system -- atoms in a fundamental mid-IR laser pulse combined with a THz laser.
First, we demonstrate numerically and then analytically formulize the harmonic
even-to-odd ratio as a function of the THz electric field, the source of the
system's asymmetry. Notably, we suggest a scaling that makes the obtained rule
universal, independent of the parameters of both the fundamental pulse and
atomic target. This universality facilitates us to propose a general pump-probe
scheme for THz waveform sampling from the even-to-odd ratio, measurable within
a conventional compact setup.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:06:58 GMT""},{""version"":""v2"",""created"":""Mon, 16 Jan 2023 13:23:04 GMT""}]","2023-01-18"
"2301.02911","Bruno Tafur","Bruno Tafur, Marwa Mahmoud and Staci Weiss","Towards early prediction of neurodevelopmental disorders: Computational
  model for Face Touch and Self-adaptors in Infants",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Infants' neurological development is heavily influenced by their motor
skills. Evaluating a baby's movements is key to understanding possible risks of
developmental disorders in their growth. Previous research in psychology has
shown that measuring specific movements or gestures such as face touches in
babies is essential to analyse how babies understand themselves and their
context. This research proposes the first automatic approach that detects face
touches from video recordings by tracking infants' movements and gestures. The
study uses a multimodal feature fusion approach mixing spatial and temporal
features and exploits skeleton tracking information to generate more than 170
aggregated features of hand, face and body. This research proposes data-driven
machine learning models for the detection and classification of face touch in
infants. We used cross dataset testing to evaluate our proposed models. The
models achieved 87.0% accuracy in detecting face touches and 71.4%
macro-average accuracy in detecting specific face touch locations with
significant improvements over Zero Rule and uniform random chance baselines.
Moreover, we show that when we run our model to extract face touch frequencies
of a larger dataset, we can predict the development of fine motor skills during
the first 5 months after birth.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:08:43 GMT""},{""version"":""v2"",""created"":""Sun, 15 Jan 2023 21:00:08 GMT""}]","2023-01-18"
"2301.02912","Assaf Libman","Jarek K\k{e}dra, Assaf Libman, Victoria Steblovskaya","Hedging of European type contingent claims in discrete time binomial
  market models",,,,,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a discrete-time binomial model of a market consisting of $m\geq
1$ risky securities and one bond. For a European type contingent claim we give
an explicit formula for the minimum-cost maximal hedging strategy.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:24:04 GMT""}]","2023-01-10"
"2301.02913","Remudin Reshid Mekuria Dr.","Remudin Reshid Mekuria, Amare Abebe","Observational constraints of diffusive dark-fluid cosmology","There are 20 pages and 20 Figures in this article, comments are
  welcome",,,,"astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this work, we consider an interacting dark-fluid cosmological model in
which energy exchange between dark matter and dark energy occurs through
diffusion. After solving the background expansion history for a late-time
universe, we attempt to constrain the cosmological parameters by comparing
simulated values of the model against Supernovae Type 1A data. We consider four
different cases and compare them against the LCDM model as the ""true model"".
Our results show that the diffusive model in which dark energy flows to dark
matter is the most likely alternative to LCDM model. This model is not only in
line with Planck 2018 observational results but can also give a potential
explanation to the so-called Hubble tension.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:26:26 GMT""}]","2023-01-10"
"2301.02914","Mikhail Zubkov Dr","M. Selch, J. Miller, M.A.Zubkov","Gravastar-like black hole solutions in $q$-theory","Latex, 14 figures, 28 pages",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a stationary spherically symmetric solution of the Einstein
equations, with a source generated by a scalar field of $q$-theory. In this
theory Riemannian gravity, as described by the Einstein - Hilbert action, is
coupled to a three - form field that describes the dynamical vacuum. Formally
it behaves like a matter field with its own stress - energy tensor, equivalent
to a scalar field minimally coupled to gravity. The asymptotically flat
solutions obtained to the field equations represent black holes. For a
sufficiently large horizon radius the energy density is localized within a thin
spherical shell situated just outside of the horizon, analogous to a gravastar.
The resulting solutions to the field equations, which admit this class of
configurations, satisfy existence conditions that stem from the Black Hole no -
hair theorem, thanks to the presence of a region in space in which the energy
density is negative.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:32:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 17:38:15 GMT""}]","2023-05-31"
"2301.02915","Robert Schilling","Robert Schilling, Pascal Nasahl, Martin Unterguggenberger, Stefan
  Mangard","SFP: Providing System Call Flow Protection against Software and Fault
  Attacks","Published at HASP22",,,,"cs.CR cs.OS","http://creativecommons.org/licenses/by/4.0/","  With the improvements in computing technologies, edge devices in the
Internet-of-Things have become more complex. The enabler technology for these
complex systems are powerful application core processors with operating system
support, such as Linux. While the isolation of applications through the
operating system increases the security, the interface to the kernel poses a
new threat. Different attack vectors, including fault attacks and memory
vulnerabilities, exploit the kernel interface to escalate privileges and take
over the system.
  In this work, we present SFP, a mechanism to protect the execution of system
calls against software and fault attacks providing integrity to user-kernel
transitions. SFP provides system call flow integrity by a two-step linking
approach, which links the system call and its origin to the state of
control-flow integrity. A second linking step within the kernel ensures that
the right system call is executed in the kernel. Combining both linking steps
ensures that only the correct system call is executed at the right location in
the program and cannot be skipped. Furthermore, SFP provides dynamic CFI
instrumentation and a new CFI checking policy at the edge of the kernel to
verify the control-flow state of user programs before entering the kernel. We
integrated SFP into FIPAC, a CFI protection scheme exploiting ARM pointer
authentication. Our prototype is based on a custom LLVM-based toolchain with an
instrumented runtime library combined with a custom Linux kernel to protect
system calls. The evaluation of micro- and macrobenchmarks based on SPEC 2017
show an average runtime overhead of 1.9 % and 20.6 %, which is only an increase
of 1.8 % over plain control-flow protection. This small impact on the
performance shows the efficiency of SFP for protecting all system calls and
providing integrity for the user-kernel transitions.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:35:08 GMT""},{""version"":""v2"",""created"":""Thu, 12 Jan 2023 12:10:34 GMT""}]","2023-01-13"
"2301.02916","Rodrigo Bonazzola","Rodrigo Bonazzola, Enzo Ferrante, Nishant Ravikumar, Yan Xia, Bernard
  Keavney, Sven Plein, Tanveer Syeda-Mahmood, and Alejandro F Frangi","Unsupervised ensemble-based phenotyping helps enhance the
  discoverability of genes related to heart morphology","14 pages of main text, 22 pages of supplemental information",,,,"q-bio.GN cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent genome-wide association studies (GWAS) have been successful in
identifying associations between genetic variants and simple cardiac parameters
derived from cardiac magnetic resonance (CMR) images. However, the emergence of
big databases including genetic data linked to CMR, facilitates investigation
of more nuanced patterns of shape variability. Here, we propose a new framework
for gene discovery entitled Unsupervised Phenotype Ensembles (UPE). UPE builds
a redundant yet highly expressive representation by pooling a set of phenotypes
learned in an unsupervised manner, using deep learning models trained with
different hyperparameters. These phenotypes are then analyzed via (GWAS),
retaining only highly confident and stable associations across the ensemble. We
apply our approach to the UK Biobank database to extract left-ventricular (LV)
geometric features from image-derived three-dimensional meshes. We demonstrate
that our approach greatly improves the discoverability of genes influencing LV
shape, identifying 11 loci with study-wide significance and 8 with suggestive
significance. We argue that our approach would enable more extensive discovery
of gene associations with image-derived phenotypes for other organs or image
modalities.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:36:44 GMT""}]","2023-01-10"
"2301.02917","Dora Musielak Ph.D.","Dora Musielak","Dido's Problem. When a myth of ancient literature became a problem of
  variational calculus","12 pages, 2 figures",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When introducing the calculus of variations, we may invoke Dido's problem to
illustrate the most fundamental variational problem: to find the curve of given
perimeter which bounds the greatest area. This type of problem led
mathematicians to invent solution methods of maxima and minima, and the genesis
of variational calculus as a distinct branch of analysis. Dido's problem was
inspired by the mythical tale of the foundation of Carthage (ancient city in
North Africa) by a Phoenician princess as told independently by Roman poet
Virgil, and by Latin historian Justinus in the first two centuries BC.
Historians have debated the facts surrounding Carthage's birth; however,
contemporary mathematicians have accepted the vague events described by Virgil
in his Aeneid, adding details to Dido's story to extrapolate a few verses and
use as a basis for the isoperimetric theorem. Was Leonhard Euler or Lord Kelvin
who first interpreted Virgil's poem as Dido's problem of variational calculus?
In this article I attempt to resolve a question of historical attribution to
identify who first defined Dido's problem.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:37:12 GMT""}]","2023-01-10"
"2301.02918","Hyeongseon Jeon","Hyeongseon Jeon, Juan Xie, Yeseul Jeon, Kyeong Joo Jung, Arkobrato
  Gupta, Won Chang, Dongjun Chung","Statistical Power Analysis for Designing Bulk, Single-Cell, and Spatial
  Transcriptomics Experiments: Review, Tutorial, and Perspectives",,,,,"q-bio.GN","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gene expression profiling technologies have been used in various applications
such as cancer biology. The development of gene expression profiling has
expanded the scope of target discovery in transcriptomic studies, and each
technology produces data with distinct characteristics. In order to guarantee
biologically meaningful findings using transcriptomic experiments, it is
important to consider various experimental factors in a systematic way through
statistical power analysis. In this paper, we review and discuss the power
analysis for three types of gene expression profiling technologies from a
practical standpoint, including bulk RNA-seq, single-cell RNA-seq, and
high-throughput spatial transcriptomics. Specifically, we describe the existing
power analysis tools for each research objective for each of the bulk RNA-seq
and scRNA-seq experiments, along with recommendations. On the other hand, since
there are no power analysis tools for high-throughput spatial transcriptomics
at this point, we instead investigate the factors that can influence power
analysis.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:42:28 GMT""}]","2023-01-10"
"2301.02919","Thomas Misa","Thomas J. Misa","Charles Babbage, Ada Lovelace, and the Bernoulli Numbers","20 pages, 4 figures","In Robin Hammerman and Andrew L. Russell, eds., Ada's Legacy:
  Cultures of Computing from the Victorian to the Digital Age. Association for
  Computing Machinery and Morgan & Claypool, 2015","10.1145/2809523.2809527",,"math.HO cs.CY cs.GL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This chapter makes needed corrections to an unduly negative scholarly view of
Ada Lovelace. Credit between Lovelace and Babbage is not a zero-sum game, where
any credit added to Lovelace somehow detracts from Babbage. Ample evidence
indicates Babbage and Lovelace each had important contributions to the famous
1843 Sketch of Babbage's Analytical Engine and the accompanying Notes. Further,
Lovelace's correspondence with two highly accomplished figures in 19th century
mathematics, Charles Babbage and Augustus De Morgan, establish her mathematical
background and sophistication. Babbage and Lovelace's treatment of the
Bernoulli numbers in Note 'G' spotlights this aspect of their collaboration.
Finally, while acknowledging significant definitional problems in calling
Lovelace the world's ""first computer programmer,"" I affirm that Lovelace
created an elemental sequence of instructions -- that is, an algorithm -- for
computing the series of Bernoulli numbers.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:55:04 GMT""}]","2023-01-10"
"2301.02920","Elena Di Domenico","Elena Di Domenico, \c{S}\""ukran G\""ul, Anitha Thillaisundaram","Beauville structures for quotients of generalised GGS-groups","19 pages",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A finite group with a Beauville structure gives rise to a certain compact
complex surface called a Beauville surface. G\""{u}l and Uria-Albizuri showed
that quotients of the periodic Grigorchuk-Gupta-Sidki (GGS-)groups that act on
the $p$-adic tree, for $p$ an odd prime, admit Beauville structures. We extend
their result by showing that quotients of infinite periodic GGS-groups acting
on $p^n$-adic trees, for $p$ any prime and $n\ge 2$, also admit Beauville
structures.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 18:59:56 GMT""}]","2023-01-10"
"2301.02921","Xavier Claeys","Xavier Claeys","Non-local optimized Schwarz method with physical boundaries",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We extend the theoretical framework of non-local optimized Schwarz methods as
introduced in [Claeys,2021], considering an Helmholtz equation posed in a
bounded cavity supplemented with a variety of conditions modeling material
boundaries. The problem is reformulated equivalently as an equation posed on
the skeleton of a non-overlapping partition of the computational domain,
involving an operator of the form ""identity + contraction"". The analysis covers
the possibility of resonance phenomena where the Helmholtz problem is not
uniquely solvable. In case of unique solvability, the skeleton formulation is
proved coercive, and an explicit bound for the coercivity constant is provided
in terms of the inf-sup constant of the primary Helmholtz boundary value
problem.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:04:34 GMT""}]","2023-01-10"
"2301.02922","Vojt\v{e}ch Miller","Vojtech Miller, Karel Zidek","High-precision FoM measurement setup for Ti:Sapphire crystals",,,"10.1364/AO.479254",,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The figure of merit (FoM) of Ti:Sapphire (Ti:Sa) crystals is a generally used
means to evaluate the quality of the crystals. Despite the importance of Ti:Sa,
the question of FoM measurement precision stayed out of focus, while the
commercially available spectrometers provide unsatisfactory 3-sigma precision
reaching 60 %. In this paper, we present a setup for a single-pass
high-precision transmission measurement for three different wavelengths (532
nm, 780 nm, and 1560 nm) based on Nd:YAG and Er:YAG lasers. A synchronous
detection via a double integrated sphere enabled us to achieve the transmission
uncertainty of 0,01-0,03%. With the presented setup, we show that it is
possible to determine the FoM values with 3-sigma precision of 7,5 %. Owing to
the high FoM precision, we were able to trace spatial inhomogeneities of an
unannealed Ti:Sa crystal produced by a commercial manufacturer Crytur. Our
measurements demonstrate that the FoM values can be significantly affected by
the crystal inhomogeneities and angular mismatch between the c-axis of the
Ti:Sa and polarization orientation.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:11:28 GMT""}]","2023-02-22"
"2301.02923","James Scott","James M. Scott, Qiang Du","Nonlocal boundary-value problems with local boundary conditions",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe and analyze nonlocal integro-differential equations with
classical local boundary conditions. The interaction kernel of the nonlocal
operator has horizon parameter dependent on position in the domain, and
vanishes as the boundary of the domain is approached. This heterogeneous
localization allows for boundary values to be captured in the trace sense. We
state and prove a nonlocal Green's identity for these nonlocal operators that
involve local boundary terms. We use this identity to state and establish the
well-posedness of variational formulations of the nonlocal problems with
several types of classical boundary conditions.
  We show the consistency of these nonlocal boundary-value problems with their
classical local counterparts in the vanishing horizon limit via the convergence
of solutions. The Poisson data for the local boundary-value problem is
permitted to be quite irregular, belonging to the dual of the classical Sobolev
space. Heterogeneously mollifying this Poisson data for the local problem on
the same length scale as the horizon and using the regularity of the
interaction kernel, we show that the solutions to the nonlocal boundary-value
problem with the mollified Poisson data actually belong to the classical
Sobolev space, and converge weakly to the unique variational solution of the
classical Poisson problem with original Poisson data.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:13:54 GMT""}]","2023-01-10"
"2301.02924","Yeskendir Koishekenov","Yeskendir Koishekenov","Reducing Over-smoothing in Graph Neural Networks Using Relational
  Embeddings","To be published in The Ninth International Workshop on Deep Learning
  on Graphs: Method and Applications (DLG-AAAI'23)",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Neural Networks (GNNs) have achieved a lot of success with
graph-structured data. However, it is observed that the performance of GNNs
does not improve (or even worsen) as the number of layers increases. This
effect has known as over-smoothing, which means that the representations of the
graph nodes of different classes would become indistinguishable when stacking
multiple layers. In this work, we propose a new simple, and efficient method to
alleviate the effect of the over-smoothing problem in GNNs by explicitly using
relations between node embeddings. Experiments on real-world datasets
demonstrate that utilizing node embedding relations makes GNN models such as
Graph Attention Network more robust to over-smoothing and achieves better
performance with deeper GNNs. Our method can be used in combination with other
methods to give the best performance. GNN applications are endless and depend
on the user's objective and the type of data that they possess. Solving
over-smoothing issues can potentially improve the performance of models on all
these tasks.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:26:04 GMT""}]","2023-01-10"
"2301.02925","Hosein Barzekar","Hosein Barzekar, Hai Ngu, Han Hui Lin, Mohsen Hejrati, Steven Ray
  Valdespino, Sarah Chu, Baris Bingol, Somaye Hashemifar, Soumitra Ghosh","Multiclass Semantic Segmentation to Identify Anatomical Sub-Regions of
  Brain and Measure Neuronal Health in Parkinson's Disease",,,"10.1016/j.neuri.2023.100131",,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Automated segmentation of anatomical sub-regions with high precision has
become a necessity to enable the quantification and characterization of cells/
tissues in histology images. Currently, a machine learning model to analyze
sub-anatomical regions of the brain to analyze 2D histological images is not
available. The scientists rely on manually segmenting anatomical sub-regions of
the brain which is extremely time-consuming and prone to labeler-dependent
bias. One of the major challenges in accomplishing such a task is the lack of
high-quality annotated images that can be used to train a generic artificial
intelligence model. In this study, we employed a UNet-based architecture,
compared model performance with various combinations of encoders, image sizes,
and sample selection techniques. Additionally, to increase the sample set we
resorted to data augmentation which provided data diversity and robust
learning. In this study, we trained our best fit model on approximately one
thousand annotated 2D brain images stained with Nissl/ Haematoxylin and
Tyrosine Hydroxylase enzyme (TH, indicator of dopaminergic neuron viability).
The dataset comprises of different animal studies enabling the model to be
trained on different datasets. The model effectively is able to detect two
sub-regions compacta (SNCD) and reticulata (SNr) in all the images. In spite of
limited training data, our best model achieves a mean intersection over union
(IOU) of 79% and a mean dice coefficient of 87%. In conclusion, the UNet-based
model with EffiecientNet as an encoder outperforms all other encoders,
resulting in a first of its kind robust model for multiclass segmentation of
sub-brain regions in 2D images.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:35:28 GMT""}]","2023-06-05"
"2301.02926","Debangshu Banerjee","Debangshu Banerjee","Markov Chain Concentration with an Application in Reinforcement Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Given $X_1,\cdot ,X_N$ random variables whose joint distribution is given as
$\mu$ we will use the Martingale Method to show any Lipshitz Function $f$ over
these random variables is subgaussian. The Variance parameter however can have
a simple expression under certain conditions. For example under the assumption
that the random variables follow a Markov Chain and that the function is
Lipschitz under a Weighted Hamming Metric. We shall conclude with certain well
known techniques from concentration of suprema of random processes with
applications in Reinforcement Learning
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:36:13 GMT""}]","2023-01-10"
"2301.02927","William Black","William K. Black, Rebecca L. Matz, Mark Mills, and A. E. Evrard","Practice Makes Better: Quantifying Grade Benefits of Study","Accepted for publication in Physical Review Physics Education
  Research; 13 pages, 8 figures",,,,"physics.ed-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Problem Roulette (PR), an online study service at the University of Michigan,
offers points-free formative practice to students preparing for examinations in
introductory STEM courses. Using four years of PR data involving millions of
problem attempts by thousands of students, we quantify benefits of increased
practice study volume in introductory physics. After conditioning mean final
grade on standardized (ACT/SAT) math test score, we analyze deviations based on
student study volume. We find a strong effect; mean course grade rises
quadratically with the logarithm of the total number of PR questions
encountered over the term ($N_{\rm Q,tot}$), with an overall gain of $0.77 \pm
0.12$ grade points between $1 < N_{\rm Q,tot} < 1000$. The gains are persistent
across the range of math test score represented in our sample. While $N_{\rm
Q,tot}$ surely correlates with other study habits, the benefits of increased
study in general still hold. A model for final grade using test score and study
volume largely accounts for demographic stratification, including by sex,
parental education level, number of parents at home, nationality /
underrepresented minority status, and regional income level, with two
significant exceptions: students whose parents did not earn a college degree,
who earn $-0.27 \pm 0.04$ grade points ($6.1\sigma$) below expectations and
underrepresented minority students at $-0.14 \pm 0.04$ points ($3.6\sigma$).
Residual scatter in final grade remains comparable to the maximal study gains,
implying that the model is far from deterministic: individual variation trumps
mean trends. Our findings can help motivate students to study more and help
teachers to identify which types of students may especially need such
encouragement.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:38:29 GMT""},{""version"":""v2"",""created"":""Sat, 29 Apr 2023 14:29:13 GMT""}]","2023-05-02"
"2301.02928","Philip Appleton","P. N. Appleton, P. Guillard, B. Emonts, F. Boulanger, A. Togi, W. T.
  Reach, K. Alatalo, M. Cluver, T. Diaz Santos, P-A. Duc, S. Gallagher, P.
  Ogle, E. O'Sullivan, K. Voggel and C. K. Xu","Multi-phase gas interactions on subarcsec scales in the shocked IGM of
  Stephan's Quintet with JWST and ALMA","Accepted for Publications to ApJ April 10 2023",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We combine JWST and HST imaging with ALMA~CO(2-1) spectroscopy to study the
highly turbulent multi-phase intergalactic medium (IGM) in Stephan's Quintet on
25-150 pc scales. Previous Spitzer observations revealed luminous H$_2$ line
cooling across a 45 kpc-long filament, created by a giant shock-wave, following
the collision with an intruder galaxy NGC~7318b. We demonstrate that the
MIRI/F1000W/F770W filters are dominated by 0-0~S(3)~H$_2$ and a combination of
PAH and 0-0~S(5)~H$_2$ emission. They reveal the dissipation of kinetic energy
as massive clouds experience collisions, interactions and likely
destruction/re-cycling within different phases of the IGM. In one kpc-scaled
structure, warm H$_2$ formed a triangular-shaped head and tail of compressed
and stripped gas behind a narrow shell of cold H$_2$. In another region, two
cold molecular clumps with very different velocities are connected by an
arrow-shaped stream of warm, probably shocked, H$_2$ suggesting a cloud-cloud
collision is occurring. In both regions, a high warm-to-cold molecular gas
fraction indicates that the cold clouds are being disrupted and converted into
warm gas. We also map gas associated with an apparently forming dwarf galaxy.
We suggest that the primary mechanism for exciting strong mid-IR H$_2$ lines
throughout Stephan's Quintet is through a fog of warm gas created by the
shattering of denser cold molecular clouds and mixing/recycling in the
post-shocked gas. A full picture of the diverse kinematics and excitation of
the warm H$_2$ will require future JWST mid-IR spectroscopy. The current
observations reveal the rich variety of ways that different gas phases can
interact with one another.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 19:56:54 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 00:40:26 GMT""}]","2023-04-12"
"2301.02929","S. A. Kuzmichev","Ya.G. Ponomarev, S.A. Kuzmichev, M.G. Mikheev, M.V. Sudakova, S.N.
  Tchesnokov, N.Z. Timergaleev, A.V. Yarigin, M.A. Hein, G. Mueller, H. Piel,
  B.M. Bulychev, K.P. Burdina, V.K. Gentchel, L.G. Sevastyanova, S.I.
  Krasnosvobodtsev, A.V. Varlashkin","Leggett's plasma resonances and two-gap structures in the CVCs of
  MgB$_2$ break junctions $-$ a direct evidence for a two-gap superconductivity
  in MgB$_2$","20 pages (8 pages - preface, 7 pages - electron copy of the ""V.
  Tarasov's Readings"" International conference proceedings published in
  December 2002, 4 pages - electron layout of references and figures), 6
  figures. On the occasion of 20th anniversary of the first experimental
  observation of the Leggett collective plasma oscillation in MgB2","Bulletin of the V. Tarasov Center of Chemotronics of Glass No.2,
  139 (2002), ISBN 5-7237-0388-9, Mendeleev University of Chemical Technology
  of Russia, Moscow",,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present investigation (2002) the current-voltage characteristics
(CVCs) of break junctions in polycrystalline $MgB_2$ samples have been studied
in the temperature range $4.2 K < T < T_c$. An inelastic Cooper pair tunneling
accompanied by the emission of Leggett plasmons has been found for the first
time in $MgB_2$ Josephson contacts. A fine structure in the CVCs of $MgB_2$
Andreev point contacts caused by a resonant emission of Leggett plasmons has
been observed for the first time. An energy of the Leggett plasmon has been
estimated: $E_0$ ~ 4 meV. Distinct two-gap structures have been found in the
CVCs of $MgB_2$ tunneling contacts and $MgB_2$ Andreev point contacts with 7.5
meV $< \Delta_L <$ 11 meV and 1.5 meV $< \Delta_S <$ 2.5 meV. An intrinsic
tunneling effect (ITE) and intrinsic multiple Andreev reflections effect
(IMARE) have been observed due to the layered structure of $MgB_2$. The
obtained experimental results give a direct evidence for a two-gap
superconductivity in $MgB_2$. (""V. Tarasov's Readings"", November 2002, Russia,
Moscow, conference proceedings.)
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:12:35 GMT""},{""version"":""v2"",""created"":""Mon, 23 Jan 2023 23:19:03 GMT""}]","2023-01-25"
"2301.02930","Dongxue Qu","Muxin Han, Hongguang Liu, Dongxue Qu","Complex critical points in Lorentzian spinfoam quantum gravity:
  4-simplex amplitude and effective dynamics on double-$\Delta_3$ complex","29 pages, 15 figures",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The complex critical points are analyzed in the 4-dimensional Lorentzian
Engle-Pereira-Rovelli-Livine (EPRL) spinfoam model in the large-$j$ regime. For
the 4-simplex amplitude, taking into account the complex critical point
generalizes the large-$j$ asymptotics to the situation with non-Regge boundary
data and relates to the twisted geometry. For generic simplicial complexes, we
present a general procedure to derive the effective theory of Regge geometries
from the spinfoam amplitude in the large-$j$ regime by using the complex
critical points. The effective theory is analyzed in detail for the spinfoam
amplitude on the double-$\Delta_3$ simplicial complex. We numerically compute
the effective action and the solution of the effective equation of motion on
the double-$\Delta_3$ complex. The effective theory reproduces the classical
Regge gravity when the Barbero-Immirzi parameter $\gamma$ is small.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:16:37 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 17:11:53 GMT""}]","2023-02-10"
"2301.02931","Can Chen","Can Chen, Yingxue Zhang, Xue Liu, Mark Coates","Bidirectional Learning for Offline Model-based Biological Sequence
  Design","Accepted by ICML2023, AI for Science, 13 pages,3 figures",,,,"cs.CE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Offline model-based optimization aims to maximize a black-box objective
function with a static dataset of designs and their scores. In this paper, we
focus on biological sequence design to maximize some sequence score. A recent
approach employs bidirectional learning, combining a forward mapping for
exploitation and a backward mapping for constraint, and it relies on the neural
tangent kernel (NTK) of an infinitely wide network to build a proxy model.
Though effective, the NTK cannot learn features because of its parametrization,
and its use prevents the incorporation of powerful pre-trained Language Models
(LMs) that can capture the rich biophysical information in millions of
biological sequences. We adopt an alternative proxy model, adding a linear head
to a pre-trained LM, and propose a linearization scheme. This yields a
closed-form loss and also takes into account the biophysical information in the
pre-trained LM. In addition, the forward mapping and the backward mapping play
different roles and thus deserve different weights during sequence
optimization. To achieve this, we train an auxiliary model and leverage its
weak supervision signal via a bi-level optimization framework to effectively
learn how to balance the two mappings. Further, by extending the framework, we
develop the first learning rate adaptation module \textit{Adaptive}-$\eta$,
which is compatible with all gradient-based algorithms for offline model-based
optimization. Experimental results on DNA/protein sequence design tasks verify
the effectiveness of our algorithm. Our code is
available~\href{https://anonymous.4open.science/r/BIB-ICLR2023-Submission/README.md}{here.}
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:27:34 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 01:18:11 GMT""},{""version"":""v3"",""created"":""Mon, 24 Apr 2023 22:18:50 GMT""}]","2023-04-26"
"2301.02932","Shuli Chen","Shuli Chen","Index of minimal hypersurfaces in real projective spaces","14 pages",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  We prove that for an embedded unstable one-sided minimal hypersurface of the
$(n+1)$-dimensional real projective space, the Morse index is at least $n+2$,
and this bound can be attained by the cubic isoparametric hypersurfaces. We
also show that there exist embedded two-sided minimal surfaces in the
3-dimensional real projective space of each odd index by computing the index of
the Lawson surfaces.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:30:02 GMT""}]","2023-01-10"
"2301.02933","Pushpak Pati","Pushpak Pati, Guillaume Jaume, Zeineb Ayadi, Kevin Thandiackal, Behzad
  Bozorgtabar, Maria Gabrani, Orcun Goksel","Weakly Supervised Joint Whole-Slide Segmentation and Classification in
  Prostate Cancer",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The segmentation and automatic identification of histological regions of
diagnostic interest offer a valuable aid to pathologists. However, segmentation
methods are hampered by the difficulty of obtaining pixel-level annotations,
which are tedious and expensive to obtain for Whole-Slide images (WSI). To
remedy this, weakly supervised methods have been developed to exploit the
annotations directly available at the image level. However, to our knowledge,
none of these techniques is adapted to deal with WSIs. In this paper, we
propose WholeSIGHT, a weakly-supervised method, to simultaneously segment and
classify WSIs of arbitrary shapes and sizes. Formally, WholeSIGHT first
constructs a tissue-graph representation of the WSI, where the nodes and edges
depict tissue regions and their interactions, respectively. During training, a
graph classification head classifies the WSI and produces node-level pseudo
labels via post-hoc feature attribution. These pseudo labels are then used to
train a node classification head for WSI segmentation. During testing, both
heads simultaneously render class prediction and segmentation for an input WSI.
We evaluated WholeSIGHT on three public prostate cancer WSI datasets. Our
method achieved state-of-the-art weakly-supervised segmentation performance on
all datasets while resulting in better or comparable classification with
respect to state-of-the-art weakly-supervised WSI classification methods.
Additionally, we quantify the generalization capability of our method in terms
of segmentation and classification performance, uncertainty estimation, and
model calibration.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:38:36 GMT""}]","2023-02-02"
"2301.02934","Kevin Ho Man Cheng","Kevin H. M. Cheng, Xu Cheng, and Guoying Zhao","Advancing 3D finger knuckle recognition via deep feature learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contactless 3D finger knuckle patterns have emerged as an effective biometric
identifier due to its discriminativeness, visibility from a distance, and
convenience. Recent research has developed a deep feature collaboration network
which simultaneously incorporates intermediate features from deep neural
networks with multiple scales. However, this approach results in a large
feature dimension, and the trained classification layer is required for
comparing probe samples, which limits the introduction of new classes. This
paper advances this approach by investigating the possibility of learning a
discriminative feature vector with the least possible dimension for
representing 3D finger knuckle images. Experimental results are presented using
a publicly available 3D finger knuckle images database with comparisons to
popular deep learning architectures and the state-of-the-art 3D finger knuckle
recognition methods. The proposed approach offers outperforming results in
classification and identification tasks under the more practical feature
comparison scenario, i.e., using the extracted deep feature instead of the
trained classification layer for comparing probe samples. More importantly,
this approach can offer 99% reduction in the size of feature templates, which
is highly attractive for deploying biometric systems in the real world.
Experiments are also performed using other two public biometric databases with
similar patterns to ascertain the effectiveness and generalizability of our
proposed approach.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:55:16 GMT""}]","2023-01-10"
"2301.02935","Floyd Stecker","Floyd W. Stecker (NASA Goddard Space Flight Center and University of
  California, Los Angeles)","Neutrino Physics and Astrophysics Overview","9 pages, 1 figure, To be published in ""Neutrino Physics and
  Astrophysics"", edited by F. W. Stecker, in Encyclopedia of Cosmology II,
  edited by G. G. Fazio, World Scientific Publishing Company, Singapore, 2023",,,,"hep-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This book chapter presents an overview of the historical experimental and
theoretical developments in neutrino physics and astrophysics and also the
physical properties of neutrinos, as well as the physical processes involving
neutrinos. It also discusses the role of neutrinos in astrophysics and
cosmology. Correction to tex file made.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:12:34 GMT""},{""version"":""v2"",""created"":""Tue, 10 Jan 2023 13:56:03 GMT""}]","2023-01-11"
"2301.02936","Andrzej Dudek","Andrzej Dudek, Jaros{\l}aw Grytczuk and Andrzej Ruci\'nski","Erd\H{o}s-Szekeres type Theorems for ordered uniform matchings",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  For $r,n\ge2$, an ordered $r$-uniform matching $M^{(r)}_n$ of size $n$ is an
$r$-uniform hypergraph on a linearly ordered vertex set $V$, with $|V|=rn$,
consisting of $n$ pairwise disjoint edges. There are $\tfrac12\binom{2r}r$
different $M_2^{(r)}$'s, that is, different ways two edges may intertwine,
called here patterns. Among them we identify $3^{r-1}$ collectable patterns
$P$, which have the potential of appearing in arbitrarily large quantities
called $P$-cliques.
  We prove an Erd\H{o}s-Szekeres type result guaranteeing in every $M^{(r)}_n$
the presence of a $P$-clique of a prescribed size, for some collectable pattern
$P$. In particular, in the diagonal case, one of the $P$-cliques must be of
size $\Omega\left( n^{3^{1-r}}\right)$. In addition, for each collectable
pattern $P$ we show that the largest size of a $P$-clique in a \emph{random}
$M^{(r)}_n$ is, with high probability, $\Theta\left(n^{1/r}\right)$.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:12:59 GMT""}]","2023-01-10"
"2301.02937","Weifeng Jin","Weifeng Jin","Quantile Autoregression-based Non-causality Testing",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  Non-causal processes have been drawing attention recently in Macroeconomics
and Finance for their ability to display nonlinear behaviors such as asymmetric
dynamics, clustering volatility, and local explosiveness. In this paper, we
investigate the statistical properties of empirical conditional quantiles of
non-causal processes. Specifically, we show that the quantile autoregression
(QAR) estimates for non-causal processes do not remain constant across
different quantiles in contrast to their causal counterparts. Furthermore, we
demonstrate that non-causal autoregressive processes admit nonlinear
representations for conditional quantiles given past observations. Exploiting
these properties, we propose three novel testing strategies of non-causality
for non-Gaussian processes within the QAR framework. The tests are constructed
either by verifying the constancy of the slope coefficients or by applying a
misspecification test of the linear QAR model over different quantiles of the
process. Some numerical experiments are included to examine the finite sample
performance of the testing strategies, where we compare different specification
tests for dynamic quantiles with the Kolmogorov-Smirnov constancy test. The new
methodology is applied to some time series from financial markets to
investigate the presence of speculative bubbles. The extension of the approach
based on the specification tests to AR processes driven by innovations with
heteroskedasticity is studied through simulations. The performance of QAR
estimates of non-causal processes at extreme quantiles is also explored.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:15:17 GMT""}]","2023-01-10"
"2301.02938","Leimin Tian","Leimin Tian, Kerry He, Shiyu Xu, Akansel Cosgun, Dana Kuli\'c","Crafting with a Robot Assistant: Use Social Cues to Inform Adaptive
  Handovers in Human-Robot Collaboration","accepted at HRI 2023",,,,"cs.RO cs.HC","http://creativecommons.org/licenses/by/4.0/","  We study human-robot handovers in a naturalistic collaboration scenario,
where a mobile manipulator robot assists a person during a crafting session by
providing and retrieving objects used for wooden piece assembly (functional
activities) and painting (creative activities). We collect quantitative and
qualitative data from 20 participants in a Wizard-of-Oz study, generating the
Functional And Creative Tasks Human-Robot Collaboration dataset (the FACT HRC
dataset), available to the research community. This work illustrates how social
cues and task context inform the temporal-spatial coordination in human-robot
handovers, and how human-robot collaboration is shaped by and in turn
influences people's functional and creative activities.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:19:31 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 02:56:46 GMT""}]","2023-04-06"
"2301.02939","Davide Vodola","Michael P. Kaicher, Davide Vodola, Simon B. J\""ager","Study of the long-range transverse field Ising model with fermionic
  Gaussian states","11 pages, 9 figures, 1 table",,"10.1103/PhysRevB.107.165144",,"quant-ph cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We numerically study the one-dimensional long-range Transverse Field Ising
Model (TFIM) in the antiferromagnetic (AFM) regime at zero temperature using
Generalized Hartree-Fock (GHF) theory. The spin-spin interaction extends to all
spins in the lattice and decays as $1/r^\alpha$, where $r$ denotes the distance
between two spins and $\alpha$ is a tunable exponent. We map the spin operators
to Majorana operators and approximate the ground state of the Hamiltonian with
a Fermionic Gaussian State (FGS). Using this approximation, we calculate the
ground state energy and the entanglement entropy which allows us to map the
phase diagram for different values of $\alpha$. In addition, we compute the
scaling behavior of the entanglement entropy with the system size to determine
the central charge at criticality for the case of $\alpha>1$. For $\alpha<1$ we
find a logarithmic divergence of the entanglement entropy even far away from
the critical point, a feature of systems with long-range interactions. We
provide a detailed comparison of our results to outcomes of Density Matrix
Renormalization Group (DMRG) and the Linked Cluster Expansion (LCE) methods. In
particular, we find excellent agreement of GHF with DMRG and LCE in the weak
long-range regime $\alpha\geq 1$, and qualitative agreement with DMRG in the
strong-long range regime $\alpha \leq 1$. Our results highlight the power of
the computationally efficient GHF method in simulating interacting quantum
systems.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:23:53 GMT""}]","2023-05-10"
"2301.02940","Taufik Abrao PhD","Bruno Felipe Costa, Taufik Abr\~ao","GA-Aided Directivity in Volumetric and Planar Massive-Antenna Array
  Design","25pages","COSTA, BRUNO FELIPE ; Abr\~ao, Taufik . GA-aided directivity in
  volumetric and planar massive-antenna array design. SIGNAL PROCESSING, v.
  205, p. 108857, 2023","10.1016/j.sigpro.2022.108857",,"eess.SY cs.AI cs.SY eess.SP","http://creativecommons.org/licenses/by/4.0/","  The problem of directivity enhancement, leading to the increase in the
directivity gain over a certain desired angle of arrival/departure (AoA/AoD),
is considered in this work. A new formulation of the volumetric array
directivity problem is proposed using the rectangular coordinates to describe
each antenna element and the desired azimuth and elevation angles with a
general element pattern. Such a directivity problem is formulated to find the
optimal minimum distance between the antenna elements $d_\text{min}$ aiming to
achieve as high directivity gains as possible. {An expedited implementation
method is developed to place the antenna elements in a distinctive plane
dependent on ($\theta_0$; $\phi_0$). A novel concept on optimizing directivity
for the uniform planar array (OUPA) is introduced to find a quasi-optimal
solution for the non-convex optimization problem with low complexity. This
solution is reached by deploying the proposed successive evaluation and
validation (SEV) method. {Moreover, the genetic} algorithm (GA) method was
deployed to find the directivity optimization solution expeditiously. For a
small number of antenna elements {, typically $N\in [4,\dots, 9]$,} the
achievable directivity by GA optimization demonstrates gains of $\sim 3$ dBi
compared with the traditional beamforming technique, using steering vector for
uniform linear arrays (ULA) and uniform circular arrays (UCA), while gains of
$\sim1.5$ dBi are attained when compared with an improved UCA directivity
method. For a larger number of antenna elements {, two improved GA procedures,
namely GA-{\it marginal} and GA-{\it stall}, were} proposed and compared with
the OUPA method. OUPA also indicates promising directivity gains surpassing
$30$ dBi for massive MIMO scenarios.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:52:19 GMT""}]","2023-01-10"
"2301.02941","Anton Fonarev","Anton Fonarev","Dual exceptional collections on Lagrangian Grassmannians","v2: minor improvements, to appear in Sbornik: Mathematics",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct graded left dual exceptional collections to the exceptional
collections generating the blocks of Kuznetsov and Polishchuk on Lagrangian
Grassmannians. As an application, we find explicit resolutions for some natural
irreducible equivariant vector bundles.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 21:58:49 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 20:31:09 GMT""}]","2023-04-28"
"2301.02942","Xiangxiong Zhang","Xinyu Liu and Jie Shen and Xiaongxiong Zhang","An efficient and robust SAV based algorithm for discrete gradient
  systems arising from optimizations",,,,,"math.NA cs.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose in this paper a new minimization algorithm based on a slightly
modified version of the scalar auxiliary variable (SAV) approach coupled with a
relaxation step and an adaptive strategy. It enjoys several distinct advantages
over popular gradient based methods: (i) it is unconditionally energy
diminishing with a modified energy which is intrinsically related to the
original energy, thus no parameter tuning is needed for stability; (ii) it
allows the use of large step-sizes which can effectively accelerate the
convergence rate. We also present a convergence analysis for some SAV based
algorithms, which include our new algorithm without the relaxation step as a
special case.
  We apply our new algorithm to several illustrative and benchmark problems,
and compare its performance with several popular gradient based methods. The
numerical results indicate that the new algorithm is very robust, and its
adaptive version usually converges significantly faster than those popular
gradient descent based methods.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 22:26:37 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 16:49:20 GMT""}]","2023-05-11"
"2301.02943","Baicheng Mei","Baicheng Mei, Tsai-Wei Lin, Grant S. Sheridan, Christopher M. Evans,
  Charles E. Sing, and Kenneth S. Schweizer","How Segmental Dynamics and Mesh Confinement Determine the Selective
  Diffusivity of Molecules in Crosslinked Dense Polymer Networks","including a main text and a supporting information. For the main
  text, 28 pages and 5 figures; For the supporting information, 23 pages and 14
  figures. Totally, 51 pages and 19 figures","ACS Cent. Sci. 9 (2023) 508-518","10.1021/acscentsci.2c01373",,"cond-mat.soft cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  The diffusion of molecules (penetrants) of variable size, shape, and
chemistry through dense crosslinked polymer networks is a fundamental
scientific problem that is broadly relevant in materials, polymer, physical and
biological chemistry. Relevant applications include molecular separations in
membranes, barrier materials for coatings, drug delivery, and nanofiltration. A
major open question is the relationship between molecular transport,
thermodynamic state, and chemical structure of the penetrant and polymeric
media. Here we address this question by combining experiment, simulation, and
theory to unravel the competing effects of penetrant chemistry on its transport
in rubbery and supercooled polymer permanent networks over a wide range of
crosslink densities, size ratios, and temperatures. The crucial importance of
the coupling of local penetrant hopping to the polymer structural relaxation
process, and the secondary importance of geometric mesh confinement effects,
are established. Network crosslinks induce a large slowing down of nm-scale
polymer relaxation which greatly retards the rate of penetrant activated
relaxation. The demonstrated good agreement between experiment, simulation, and
theory provides strong support for the size ratio variable (effective penetrant
diameter to the polymer Kuhn length) as a key variable, and the usefulness of
coarse-grained simulation and theoretical models that average over Angstrom
scale chemical details. The developed microscopic theory provides a fundamental
understanding of the physical processes underlying the behaviors observed in
experiment and simulation. Penetrant transport is theoretically predicted to
become even more size sensitive in a more deeply supercooled regime not probed
in our present experiments or simulations, which suggests new strategies for
enhancing selective polymer membrane design.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 22:27:44 GMT""}]","2023-06-09"
"2301.02944","Marcus Edwards","Marcus Edwards","Quantum Honest Byzantine Agreement as a Distributed Quantum Algorithm","arXiv admin note: text overlap with arXiv:1912.09280",,,,"quant-ph cs.DS","http://creativecommons.org/licenses/by/4.0/","  We suggest that the Quantum Honest Byzantine Agreement (QHBA) protocol [1]
essentially reduces consensus to coincidence. The volume of coincidence is the
parameter that drives a receiver to echo its input. A lack of coincidence
results in no output from a receiver. This is a similar mechanism therefore to
the learning mechanism in cognitive modular neural architectures like
Haikonen's architecture [2]. We introduce a simple feedback mechanism and
quantum neuron to realize a hybrid quantum / classical machine learning network
of simple nodes.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 23:04:31 GMT""},{""version"":""v2"",""created"":""Sun, 15 Jan 2023 06:39:00 GMT""}]","2023-01-18"
"2301.02945","Robi Kormokar","Robi Kormokar, Md Hosne Mobarok Shamim, and Martin Rochette","Energy conversion efficiency from a high order soliton to fundamental
  solitons in presence of Raman scattering","To be published in JOSAB",,"10.1364/JOSAB.478975",,"physics.optics","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We formulate the energy conversion efficiency from a high-order soliton to
fundamental solitons by including the influence of interpulse Raman scattering
in the fission process. The proposed analytical formula agrees closely with
numerical results of the generalized nonlinear Schrodinger equation as well as
to experimental results, while the resulting formulation significantly alters
the energy conversion efficiency predicted by the Raman-independent inverse
scattering method. We also calculate the energy conversion efficiency in
materials of different Raman gain profiles such as silica, ZBLAN and
chalcogenide glasses (As2S3 and As2Se3). It is predicted that ZBLAN glass leads
to the largest energy conversion efficiency of all four materials. The energy
conversion efficiency is a notion of utmost practical interest for the design
of wavelength converters and supercontinuum generation systems based on the
dynamics of soliton self-frequency shift.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 23:06:55 GMT""}]","2023-02-15"
"2301.02946","Klaus Mueller","Darius Coelho, Nikita Gupta, Eric Papenhausen, Klaus Mueller","Patterns of Social Vulnerability -- An Interactive Dashboard to Explore
  Risks to Public Health on the US County Level",,,,,"cs.HC cs.SI physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Social vulnerability is the susceptibility of a community to be adversely
impacted by natural hazards and public health emergencies, such as drought,
earthquakes, flooding, virus outbreaks, and the like. Climate change is at the
root of many recent natural hazards while the COVID-19 pandemic is still an
active threat. Social vulnerability also refers to resilience, or the ability
to recover from such adverse events. To gauge the many aspects of social
vulnerability the US Center of Disease Control (CDC) has subdivided social
vulnerabilities into distinct themes, such as socioeconomic status, household
composition, and others. Knowing a community's social vulnerabilities can help
policymakers and responders to recognize risks to community health, prepare for
possible hazards, or recover from disasters. In this paper we study social
vulnerabilities on the US county level and present research that suggests that
there are certain combinations, or patterns, of social vulnerability indicators
into which US counties can be grouped. We then present an interactive dashboard
that allows analysts to explore these patterns in various ways. We demonstrate
our methodology using COVID-19 death rate as the hazard and show that the
patterns we identified have high predictive capabilities of the pandemic's
local impact.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 23:25:02 GMT""}]","2023-01-10"
"2301.02947","Alexander V. Savin","Alexander V. Savin and Yuri S. Kivshar","Chiral organic molecular structures supported by multilayer surfaces","12 pages, 13 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We study numerically the dynamics of acetanilide (ACN) molecules placed on a
flat surface of a multilayer hexagonal boron nitride structure. We demonstrate
that the ACN molecules, being achiral in three dimensions, become chiral after
being placed on the substrate. Homochirality of the ACN molecules leads to
stable secondary structures stabilized by hydrogen bonds between peptide groups
of the molecules. Numerical simulations of systems of such molecules reveal
that the structure of the resulting hydrogen-bond chains depends on the
isomeric composition of the molecules. If all molecules are homochiral (i.e.
only one isomer is present), they form secondary structures (chains of hydrogen
bonds in the shapes of arcs, circles, and spirals). If the molecules at the
substrate form a racemic mixture, then no regular secondary structures appear,
and only curvilinear chains of hydrogen bonds of random shapes can emerge. A
hydrogen-bond chain can form a straight zigzag only if it has an alternation of
isomers. Such chains can create two-dimensional (2D) regular lattices, or 2D
crystals. The melting scenarios of such 2D crystals depend on density of its
coverage of the substrate. At 25% coverage, melting occurs continuously in a
certain temperature interval. For a complete coverage, melting occurs at
415-470 K due to a shift of 11% of all molecules into the second layer of the
substrate.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 23:49:46 GMT""}]","2023-01-10"
"2301.02948","Yuan Shen","Yuan Shen, Wai-Keong Mok, Changsuk Noh, Ai Qun Liu, Leong-Chuan Kwek,
  Weijun Fan, and Andy Chia","Quantum synchronization effects induced by strong nonlinearities","6 pages, 3 figures",,"10.1103/PhysRevA.107.053713",,"quant-ph nlin.AO nlin.CD","http://creativecommons.org/licenses/by/4.0/","  A paradigm for quantum synchronization is the quantum analog of the
Stuart--Landau oscillator, which corresponds to a van der Pol oscillator in the
limit of weak (i.e. vanishingly small) nonlinearity. Due to this limitation,
the quantum Stuart--Landau oscillator fails to capture interesting
nonlinearity-induced phenomena such as relaxation oscillations. To overcome
this deficiency we propose an alternative model which approximates the van der
Pol oscillator to finitely large nonlinearities while remaining numerically
tractable. This allows us to uncover interesting phenomena in the deep-quantum
strongly-nonlinear regime with no classical analog, such as the persistence of
amplitude death on resonance. We also report nonlinearity-induced position
correlations in reactively coupled quantum oscillators. Such coupled
oscillations become more and more correlated with increasing nonlinearity
before reaching some maximum. Again, this behavior is absent classically. We
also show how strong nonlinearity can enlarge the synchronization bandwidth in
both single and coupled oscillators. This effect can be harnessed to induce
mutual synchronization between two oscillators initially in amplitude death.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 00:05:24 GMT""}]","2023-06-07"
"2301.02949","Honglin Zhu","Hyuk Jun Kweon, Honglin Zhu","Maximum overlap area of a convex polyhedron and a convex polygon under
  translation","20 pages, 7 figures",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $P$ be a convex polyhedron and $Q$ be a convex polygon with $n$ vertices
in total in three-dimensional space. We present a deterministic algorithm that
finds a translation vector $v \in \mathbb{R}^3$ maximizing the overlap area $|P
\cap (Q + v)|$ in $O(n \log^2 n)$ time. We then apply our algorithm to solve
two related problems. We give an $O(n \log^3 n)$ time algorithm that finds the
maximum overlap area of three convex polygons with $n$ vertices in total. We
also give an $O(n \log^2 n)$ time algorithm that minimizes the symmetric
difference of two convex polygons under scaling and translation.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 00:11:13 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 01:56:11 GMT""}]","2023-02-28"
"2301.02950","Dylan Laplace Mermoud","Dylan Laplace Mermoud","Geometry of set functions in cooperative game theory",,,,,"cs.GT econ.TH math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  They are many unexplored links between cooperative transferable utility games
and convex, discrete or combinatorial geometry. In this paper, we investigate
some of these links, such as the ones between cores of convex games and
generalized permutohedra, also named polymatroids or base polyhedra. Another
link that we investigate is the one between the resonance hyperplane
arrangement and the set of sets of preimputations which are effective for a
given coalition. These bridges can give interpretation and intuition to
cooperative game theory, as well as bring new results and tools from other
fields into the study of cooperative games.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 00:19:51 GMT""}]","2023-01-10"
"2301.02951","Jorge Garcia Dr.","Jorge Garcia","Class Number of the Imaginary Quadratic Field and Quadratic Residues
  Identities",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  A formula for the sum of quadratic residues modulus a prime $p=4n-1$ is
studied. We relate some terms on this formula with roots of quadratics and
provide an exhaustive analysis of new concepts based on these roots. A number
of formulas for the sum of the quadratic residues are obtained. We finalize the
paper by obtaining several identities involving $h(-p)$ the class number of the
imaginary quadratic field $\mathbb Q(\sqrt{-p}).$
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 00:29:40 GMT""}]","2023-01-10"
"2301.02952","Phillip Christoffersen","Phillip J.K. Christoffersen, Andrew C. Li, Rodrigo Toro Icarte, Sheila
  A. McIlraith","Learning Symbolic Representations for Reinforcement Learning of
  Non-Markovian Behavior","7 pages, 2 figures, presented at KR2ML workshop at NeurIPS 2020",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Many real-world reinforcement learning (RL) problems necessitate learning
complex, temporally extended behavior that may only receive reward signal when
the behavior is completed. If the reward-worthy behavior is known, it can be
specified in terms of a non-Markovian reward function - a function that depends
on aspects of the state-action history, rather than just the current state and
action. Such reward functions yield sparse rewards, necessitating an inordinate
number of experiences to find a policy that captures the reward-worthy pattern
of behavior. Recent work has leveraged Knowledge Representation (KR) to provide
a symbolic abstraction of aspects of the state that summarize reward-relevant
properties of the state-action history and support learning a Markovian
decomposition of the problem in terms of an automaton over the KR. Providing
such a decomposition has been shown to vastly improve learning rates,
especially when coupled with algorithms that exploit automaton structure.
Nevertheless, such techniques rely on a priori knowledge of the KR. In this
work, we explore how to automatically discover useful state abstractions that
support learning automata over the state-action history. The result is an
end-to-end algorithm that can learn optimal policies with significantly fewer
environment samples than state-of-the-art RL on simple non-Markovian domains.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 00:47:19 GMT""}]","2023-01-10"
"2301.02953","Foster Thompson","Foster Thompson and Alex Kamenev","Field Theory of Many-Body Lindbladian Dynamics",,,,,"cond-mat.mes-hall cond-mat.quant-gas cond-mat.stat-mech quant-ph","http://creativecommons.org/licenses/by/4.0/","  We review and further develop the Keldysh functional integral technique for
the study of Lindbladian evolution of many-body driven-dissipative quantum
systems. A systematic and pedagogical account of the dynamics of generic
bosonic and fermionic Lindbladians is presented. Our particular emphasis is on
unique properties of the stationary distribution function, determined by the
Lyapunov equation. This framework is applied to study examples of Lindbladian
dynamics in the context of band theory, disorder, collisionless collective
modes, and mean-field theory.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:02:31 GMT""}]","2023-01-10"
"2301.02954","Naoki Ishikawa","Yuma Katsuki, Giuseppe Thadeu Freitas de Abreu, Koji Ishibashi, Naoki
  Ishikawa","A New Noncoherent Gaussian Signaling Scheme for Low Probability of
  Detection Communications","5 pages, 3 figures","IEEE Wireless Communications Letters, 2023","10.1109/LWC.2022.3233619",,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We propose a novel, Gaussian signaling mechanism for low probability of
detection (LPD) communication systems with either single or multiple antennas.
The new scheme is designed to allow the noncoherent detection of
Gaussian-distributed signals, enabling LPD communications using signals that
follow the complex Gaussian distribution in the time and frequency domains. It
is demonstrated via simulations that the proposed scheme achieves better
performance than a comparable conventional scheme over the entire SNR region,
with the advantage becoming more significant in scenarios with lower overhead.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:19:49 GMT""}]","2023-01-10"
"2301.02955","Rodrigo Rivas Barbosa","Xhorxhina Shaulli, Rodrigo Rivas-Barbosa, Maxime Jolisse Bergman, Chi
  Zhang, Nicoletta Gnan, Frank Scheffold, Emanuela Zaccarelli","Probing temperature-responsivity of microgels and its interplay with a
  solid surface by superresolution microscopy and numerical simulations","47 pages, 24 figures",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Superresolution microscopy has become a powerful tool to investigate the
internal structure of complex colloidal and polymeric systems, such as
microgels, at the nanometer scale. The ability to monitor microgels response to
temperature changes in situ opens new and exciting opportunities to design and
precisely control their behaviour for various applications. When performing
advanced microscopy experiments, interactions between the particle and the
environment can be important. Often microgels are deposited on a substrate
since they have to remain still for several minutes during the experiment. This
study uses dSTORM microscopy and advanced coarse-grained molecular dynamics
simulations to investigate, for the first time, how individual microgels
anchored on hydrophilic and hydrophobic surfaces undergo their volume phase
transition in temperature. We find that, in the presence of a hydrophilic
substrate, the structure of the microgel is unperturbed and the resulting
density profiles quantitatively agree with simulations performed in bulk
conditions. Instead, when a hydrophobic surface is used, the microgel spreads
at the interface and an interesting competition between the two hydrophobic
strengths -- monomer-monomer vs monomer-surface -- comes into play at high
temperatures. The remarkable agreement between experiments and simulations
makes the present study a fundamental step to establish this high-resolution
monitoring technique as a platform for investigating more complex systems,
being these either macromolecules with peculiar internal structure or
nanocomplexes where molecules of interest can be encapsulated in the microgel
network and controllably released with temperature.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:24:25 GMT""}]","2023-01-10"
"2301.02956","Naoya Iwahara","Naoya Iwahara and Shouta Shikano","Vibronic excitations in resonant inelastic x-ray scattering spectra of
  K$_2$RuCl$_6$","11 pages, 5 figures, 1 table","Phys. Rev. Research 5, 023051 (2023)","10.1103/PhysRevResearch.5.023051",,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We present the fingerprints of dynamic Jahn-Teller effect in resonant
inelastic x-ray scattering (RIXS) spectra of K$_2$RuCl$_6$. We determined the
dynamic Jahn-Teller model Hamiltonian of an embedded Ru$^{4+}$ ion using post
Hartree-Fock methods, and derived the vibronic states by numerically
diagonalizing the Hamiltonian. With the obtained vibronic states, we reproduced
the RIXS spectra. The shape and the temperature dependence of the RIXS spectrum
agree well with the experimental data. We found that some peaks emerge due to
the dynamic Jahn-Teller effect rather than the crystal field splitting. Our
study indicates the significance of the Jahn-Teller coupling to adequately
interpret RIXS spectra.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:27:26 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 04:17:17 GMT""}]","2023-04-26"
"2301.02957","Chang Liu","Chang Liu, Antwan D. Clark","Semi-Analytical Solutions of Shallow Water Waves with Idealised Bottom
  Topographies","21 pages, 3 figures","Geophysical & Astrophysical Fluid Dynamics, 2023, Volume 117,
  Issue 1, Pages 35-58","10.1080/03091929.2023.2169283",,"physics.flu-dyn math-ph math.MP nlin.SI","http://creativecommons.org/licenses/by/4.0/","  Analysing two-dimensional shallow water equations with idealised bottom
topographies have many applications in the atmospheric and oceanic sciences;
however, restrictive flow pattern assumptions have been made to achieve
explicit solutions. This work employs the Adomian decomposition method (ADM) to
develop semi-analytical formulations of these problems that preserve the direct
correlation of the physical parameters while capturing the nonlinear
phenomenon. Furthermore, we exploit these techniques as reverse engineering
mechanisms to develop key connections between some prevalent ansatz
formulations in the open literature as well as derive new families of exact
solutions describing geostrophic inertial oscillations and anticyclonic
vortices with finite escape times. Our semi-analytical evaluations show the
promise of this approach in terms of providing robust approximations against
several oceanic variations and bottom topographies while also preserving the
direct correlation between the physical parameters such as the Froude number,
the bottom topography, the Coriolis parameter, as well as the flow and free
surface behaviours. Our numerical validations provide additional confirmations
of this approach while also illustrating that ADM can also be used to provide
insight and deduce novel solutions that have not been explored, which can be
used to characterize various types of geophysical flows.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:28:46 GMT""},{""version"":""v2"",""created"":""Thu, 12 Jan 2023 16:32:11 GMT""},{""version"":""v3"",""created"":""Sat, 28 Jan 2023 22:37:28 GMT""}]","2023-05-01"
"2301.02958","Lei Chang","Zanbin Xing, Minghui Ding, Kh\'epani Raya and Lei Chang","A fresh look at the generalized parton distributions of light
  pseudoscalar mesons","5 pages, 2 figures, references added",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a symmetry-preserving scheme to derive the pion and kaon
generalized parton distributions (GPDs) in Euclidean space. The key to
maintaining crucial symmetries under this approach is the treatment of the
scattering amplitude, such that it contains both the traditional leading-order
contributions and the scalar/vector pole contribution automatically, the latter
being necessary to ensure the soft-pion theorem. The GPD is extracted
analytically via the uniqueness and definition of the Mellin moments and we
find that it naturally matches the double distribution; consequently, the
polynomiality condition and sum rules are satisfied. The present scheme thus
paves the way for the extraction of the GPD in Euclidean space using the
Dyson-Schwinger equation framework or similar continuum approaches.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:30:43 GMT""},{""version"":""v2"",""created"":""Thu, 26 Jan 2023 01:30:36 GMT""}]","2023-01-27"
"2301.02959","Geet Sethi","Geet Sethi, Pallab Bhattacharya, Dhruv Choudhary, Carole-Jean Wu,
  Christos Kozyrakis","FlexShard: Flexible Sharding for Industry-Scale Sequence Recommendation
  Models",,,,,"cs.LG cs.DC cs.IR cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequence-based deep learning recommendation models (DLRMs) are an emerging
class of DLRMs showing great improvements over their prior sum-pooling based
counterparts at capturing users' long term interests. These improvements come
at immense system cost however, with sequence-based DLRMs requiring substantial
amounts of data to be dynamically materialized and communicated by each
accelerator during a single iteration. To address this rapidly growing
bottleneck, we present FlexShard, a new tiered sequence embedding table
sharding algorithm which operates at a per-row granularity by exploiting the
insight that not every row is equal. Through precise replication of embedding
rows based on their underlying probability distribution, along with the
introduction of a new sharding strategy adapted to the heterogeneous, skewed
performance of real-world cluster network topologies, FlexShard is able to
significantly reduce communication demand while using no additional memory
compared to the prior state-of-the-art. When evaluated on production-scale
sequence DLRMs, FlexShard was able to reduce overall global all-to-all
communication traffic by over 85%, resulting in end-to-end training
communication latency improvements of almost 6x over the prior state-of-the-art
approach.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 01:46:26 GMT""}]","2023-01-10"
"2301.02960","Shanshan Cao","Ze-Fang Jiang, Xiang-Yu Wu, Shanshan Cao, Ben-Wei Zhang","Directed flow and global polarization in Au+Au collisions across
  energies covered by the beam energy scan at RHIC","13 pages, 7 figures","Phys. Rev. C 107 (2023) 3, 034904","10.1103/PhysRevC.107.034904",,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the directed flow of identified particles in Au+Au collisions at
$\sqrt{s_\text{NN}}=7.7$ to 62.4 GeV. The Glauber model is extended to include
both a tilted deformation of the QGP fireball with respect to the longitudinal
direction and a non-zero longitudinal flow velocity gradient in the initial
state. By combining this improved initial condition with a (3+1)-dimensional
viscous hydrodynamic model calculation, we obtain a satisfactory description of
the transverse momentum spectra and the rapidity dependent directed flow
coefficient of different hadron species. Our calculation indicates the
sensitivity of the hadron directed flow, especially its splitting between
protons and antiprotons, to both the initial geometry and the initial
longitudinal flow velocity. Therefore, the combination of directed flow of
different hadrons can provide a tight constraint on the initial condition of
nuclear matter created in heavy-ion collisions. The initial condition extracted
from the directed flow is further tested with the global polarization of
$\Lambda$ and $\bar{\Lambda}$ within the same theoretical framework, where we
obtain a reasonable description of these hyperon polarization observed at
different collision energies at RHIC.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 02:16:51 GMT""},{""version"":""v2"",""created"":""Thu, 9 Mar 2023 06:27:25 GMT""}]","2023-03-10"
"2301.02961","Noah Tuchow","Noah W. Tuchow and Jason T. Wright","The Abundance of Belatedly Habitable Planets and Ambiguities in
  Definitions of the Continuously Habitable Zone","Accepted for publication in The Astrophysical Journal",,"10.3847/1538-4357/acb054",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A planet's history dictates its current potential to host habitable
conditions and life. The concept of the Continuously Habitable Zone (CHZ) has
been used to define the region around a star most likely to host planets with
long-term habitability. However, definitions of the CHZ vary in the literature
and often conflict with each other. Calculating the fraction of habitable zone
planets in the CHZ as a function of stellar properties, we find that the
quality of a star as a host for planets with long-term habitability and
biosignatures depends strongly on the formulation of the CHZ used. For
instance, older M stars are either excellent or sub-optimal hosts for CHZ
planets, depending on whether one's definition of habitability prioritizes the
total time spent in the habitable zone or the continuity of habitable
conditions from the delivery of volatiles to its current age. In this study, we
focus on Belatedly Habitable Zone (BHZ) planets, i.e. planets which enter the
habitable zone after formation due to the evolution of their host star. We find
that between ~29-74% of planets in the habitable zone belong to this class of
BHZ planets depending on the timescale for the delivery of volatiles. Whether
these planets can retain their volatiles and support habitable conditions is
unclear. Since BHZ planets comprise a large portion of the planets we expect to
survey for biosignatures with future missions, the open question of their
habitability is an important factor for mission design, survey strategies, and
the interpretation of results.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 02:25:47 GMT""}]","2023-02-22"
"2301.02962","Neil G. Marchant","Neil G. Marchant, Benjamin I. P. Rubinstein and Rebecca C. Steorts","Bayesian Graphical Entity Resolution Using Exchangeable Random Partition
  Priors","27 pages, 4 figures, 3 tables. Includes 37 pages of appendices. This
  is an accepted manuscript to be published in the Journal of Survey Statistics
  and Methodology",,"10.1093/jssam/smac030",,"stat.ME cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entity resolution (record linkage or deduplication) is the process of
identifying and linking duplicate records in databases. In this paper, we
propose a Bayesian graphical approach for entity resolution that links records
to latent entities, where the prior representation on the linkage structure is
exchangeable. First, we adopt a flexible and tractable set of priors for the
linkage structure, which corresponds to a special class of random partition
models. Second, we propose a more realistic distortion model for
categorical/discrete record attributes, which corrects a logical inconsistency
with the standard hit-miss model. Third, we incorporate hyperpriors to improve
flexibility. Fourth, we employ a partially collapsed Gibbs sampler for
inferential speedups. Using a selection of private and nonprivate data sets, we
investigate the impact of our modeling contributions and compare our model with
two alternative Bayesian models. In addition, we conduct a simulation study for
household survey data, where we vary distortion, duplication rates and data set
size. We find that our model performs more consistently than the alternatives
across a variety of scenarios and typically achieves the highest entity
resolution accuracy (F1 score). Open source software is available for our
proposed methodology, and we provide a discussion regarding our work and future
directions.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 02:33:24 GMT""}]","2023-01-10"
"2301.02963","Gaole Dai","Gaole Dai, Fubao Yang, Jun Wang, Liujun Xu, and Jiping Huang","Diffusive Pseudo-Conformal Mapping: Anisotropy-Free Transformation
  Thermal Media with Perfect Interface Matching",,,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Transformation media provide a fundamental paradigm for field regulation, but
their tricky anisotropy challenges fabrication. Though optical conformal
mapping has been utilized to eliminate anisotropy, two key factors still hinder
its development in thermotics, i.e., the distinct diffusion nature and
inevitable interface mismatching. Here, we put forth the concept of diffusive
pseudo-conformal mapping, overcoming the inherent difference between diffusion
and waves and achieving perfect interface matching. The proposed mapping
directly leads to heat guiding and expanding functions with anisotropy-free
transformation thermal media, whose feasibility is confirmed by experiments or
simulations. Besides diverse applications, we provide a unified perspective for
two distinct types of prevailing bilayer cloaks by uncovering their profound
ties with pseudo-conformal mapping. These results greatly simplify the
preparation of transformation thermotics and have implications for regulating
other diffusion and wave phenomena.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 02:34:38 GMT""}]","2023-01-10"
"2301.02964","Per Kraus","Seolhwa Kim, Per Kraus, Richard M. Myers","Systematics of Boundary Actions in Gauge Theory and Gravity","67 pages. v2: references added, typos corrected",,"10.1007/JHEP04(2023)121",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We undertake a general study of the boundary (or edge) modes that arise in
gauge and gravitational theories defined on a space with boundary, either
asymptotic or at finite distance, focusing on efficient techniques for
computing the corresponding boundary action. Such actions capture all the
dynamics of the system that are implied by its asymptotic symmetry group, such
as correlation functions of the corresponding conserved currents. Working in
the covariant phase space formalism, we develop a collection of approaches for
isolating the boundary modes and their dynamics, and illustrate with various
examples, notably AdS$_3$ gravity (with and without a gravitational
Chern-Simons terms) subject to assorted boundary conditions.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:05:10 GMT""},{""version"":""v2"",""created"":""Mon, 23 Jan 2023 02:13:30 GMT""}]","2023-05-17"
"2301.02965","Amit Agarwal","Sunit Das, Kamal Das, and Amit Agarwal","Chiral anomalies in 3D spin-orbit coupled metals: electrical, thermal,
  and gravitational anomaly","14 pages, and 4 figures. Seeking feedback, criticism or comments on
  this paper",,,,"cond-mat.mes-hall cond-mat.mtrl-sci hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discovery of a chiral anomaly in Weyl semimetals, the non-conservation of
chiral charge and energy across two opposite chirality Weyl nodes, has sparked
immense interest in understanding its impact on various physical phenomena.
Here, we demonstrate the existence of electrical, thermal, and gravitational
quantum chiral anomalies in 3D spin-orbit coupled systems. Notably, these
anomalies involve chiral charge transfer across two Fermi surfaces linked to a
single Weyl-like point, rather than across opposite chirality Weyl nodes as in
Weyl semimetals. Our findings reveal that the Berry curvature flux piercing the
Fermi surface plays a critical role in distinguishing the `chirality' of the
carriers and the corresponding chiral charge and energy transfer. Importantly,
we demonstrate that these quantum chiral anomalies lead to interesting thermal
spin transport such as the spin Nernst effect. Our results suggest that 3D
spin-orbit coupled metals offer a promising platform for investigating the
interplay between quantum chiral anomalies and charge and spin transport in
non-relativistic systems.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:09:37 GMT""}]","2023-01-10"
"2301.02966","Heli Qi","Heli Qi, Sashi Novitasari, Andros Tjandra, Sakriani Sakti, Satoshi
  Nakamura","SpeeChain: A Speech Toolkit for Large-Scale Machine Speech Chain","Submitted to ICASSP 2023",,,,"cs.CL cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces SpeeChain, an open-source Pytorch-based toolkit
designed to develop the machine speech chain for large-scale use. This first
release focuses on the TTS-to-ASR chain, a core component of the machine speech
chain, that refers to the TTS data augmentation by unspoken text for ASR. To
build an efficient pipeline for the large-scale TTS-to-ASR chain, we implement
easy-to-use multi-GPU batch-level model inference, multi-dataloader batch
generation, and on-the-fly data selection techniques. In this paper, we first
explain the overall procedure of the TTS-to-ASR chain and the difficulties of
each step. Then, we present a detailed ablation study on different types of
unlabeled data, data filtering thresholds, batch composition, and
real-synthetic data ratios. Our experimental results on train_clean_460 of
LibriSpeech demonstrate that our TTS-to-ASR chain can significantly improve WER
in a semi-supervised setting.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:16:56 GMT""}]","2023-01-10"
"2301.02967","Tian-Yu Zhao","Zhixiang Ren, Tianyu Zhao, Zhoujian Cao, Zong-Kuan Guo, Wen-Biao Han,
  Hong-Bo Jin, Yue-Liang Wu","Taiji Data Challenge for Exploring Gravitational Wave Universe","13 pages, 2 figures",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  The direct observation of gravitational waves (GWs) opens a new window for
exploring new physics from quanta to cosmos and provides a new tool for probing
the evolution of universe. GWs detection in space covers a broad spectrum
ranging over more than four orders of magnitude and enables us to study rich
physical and astronomical phenomena. Taiji is a proposed space-based
gravitational wave (GW) detection mission that will be launched in the 2030s.
Taiji will be exposed to numerous overlapping and persistent GW signals buried
in the foreground and background, posing various data analysis challenges. In
order to empower potential scientific discoveries, the Mock Laser
Interferometer Space Antenna (LISA) Data Challenge and the LISA Data Challenge
(LDC) were developed. While LDC provides a baseline framework, the first LDC
needs to be updated with more realistic simulations and adjusted detector
responses for Taiji's constellation. In this paper, we review the scientific
objectives and the roadmap for Taiji, as well as the technical difficulties in
data analysis and the data generation strategy, and present the associated data
challenges. In contrast to LDC, we utilize second-order Keplerian orbit and
second-generation time delay interferometry techniques. Additionally, we employ
a new model for the extreme-mass-ratio inspiral waveform and stochastic GW
background spectrum, which enables us to test general relativity and measure
the non-Gaussianity of curvature perturbations. As the first data challenge for
Taiji, we aim to build an open ground for data analysis related to Taiji
sources and sciences. More details can be found on the official website
http://taiji-tdc.ictp-ap.org.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:22:41 GMT""}]","2023-01-10"
"2301.02968","Nicol\`o Cartiglia","N. Cartiglia, F. Moscatelli, R. Arcidiacono, P. Asenov, M. Costa, T.
  Croci, M. Ferrero, A. Fondacci, L. Lanteri, L. Menzio, A. Morozzi, R.
  Mulargia, D.Passeri, F. Siviero, V. Sola, M. Tornago","Resistive Read-out in Thin Silicon Sensors with Internal Gain","8 pages, 7 figures",,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  Two design innovations, low-gain avalanche (Low-Gain Avalance Diode, LGAD)
and resistive read-out (Resistive Silicon Detector, RSD), have brought strong
performance improvements to silicon sensors. Large signals, due to the added
gain mechanism, lead to improved temporal precision, while charge sharing,
introduced by resistive read-out, allows for achieving excellent spatial
resolution even with large pixels. LGAD- and RSD- based silicon sensors are now
adopted, or considered, in several future experiments and are the basis for
almost every next 4D-trackers. New results obtained with sensors belonging to
the second FBK production of RSD (RSD2) demonstrate how a combined resolution
of 30 ps and 30 \microns can be obtained with pixels as large as $1 \times 1 $
mm$^2$.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:37:05 GMT""}]","2023-01-10"
"2301.02969","Fengping Wang","Fengping Wang, Jie Li, Chun Qi, Lin Wang, Pan Wang","Multi-scale multi-modal micro-expression recognition algorithm based on
  transformer",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A micro-expression is a spontaneous unconscious facial muscle movement that
can reveal the true emotions people attempt to hide. Although manual methods
have made good progress and deep learning is gaining prominence. Due to the
short duration of micro-expression and different scales of expressed in facial
regions, existing algorithms cannot extract multi-modal multi-scale facial
region features while taking into account contextual information to learn
underlying features. Therefore, in order to solve the above problems, a
multi-modal multi-scale algorithm based on transformer network is proposed in
this paper, aiming to fully learn local multi-grained features of
micro-expressions through two modal features of micro-expressions - motion
features and texture features. To obtain local area features of the face at
different scales, we learned patch features at different scales for both
modalities, and then fused multi-layer multi-headed attention weights to obtain
effective features by weighting the patch features, and combined cross-modal
contrastive learning for model optimization. We conducted comprehensive
experiments on three spontaneous datasets, and the results show the accuracy of
the proposed algorithm in single measurement SMIC database is up to 78.73% and
the F1 value on CASMEII of the combined database is up to 0.9071, which is at
the leading level.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:45:23 GMT""},{""version"":""v2"",""created"":""Wed, 11 Jan 2023 03:04:42 GMT""}]","2023-01-12"
"2301.02970","Cheng-Zong Ruan","Cheng-Zong Ruan, Carolina Cuesta-Lazaro, Alexander Eggemeier, Baojiu
  Li, Carlton M. Baugh, Christian Arnold, Sownak Bose, C\'esar
  Hern\'andez-Aguayo, Pauline Zarrouk and Christopher T. Davies","An emulator-based halo model in modified gravity -- I. The halo
  concentration-mass relation and density profile","18 pages, 15 figures",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In this series of papers we present an emulator-based halo model for the
non-linear clustering of galaxies in modified gravity cosmologies. In the first
paper, we present emulators for the following halo properties: the halo mass
function, concentration-mass relation and halo-matter cross-correlation
function. The emulators are trained on data extracted from the \textsc{FORGE}
and \textsc{BRIDGE} suites of $N$-body simulations, respectively for two
modified gravity (MG) theories: $f(R)$ gravity and the DGP model, varying three
standard cosmological parameters $\Omega_{\mathrm{m0}}, H_0, \sigma_8$, and one
MG parameter, either $\bar{f}_{R0}$ or $r_{\mathrm{c}}$. Our halo property
emulators achieve an accuracy of $\lesssim 1\%$ on independent test data sets.
We demonstrate that the emulators can be combined with a galaxy-halo connection
prescription to accurately predict the galaxy-galaxy and galaxy-matter
correlation functions using the halo model framework.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:51:35 GMT""}]","2023-01-10"
"2301.02971","Md. Ahsan Habib Nayan","Md. Ahsan Habib, M. A. H. Akhand and Md. Abdus Samad Kamal","Emotion Recognition from Microblog Managing Emoticon with Text and
  Classifying using 1D CNN","9 pages, 3 figures, 5 tables, journal paper","Journal of Computer Science, 18(12), 1170-1178 (2022)","10.3844/jcssp.2022.1170.1178",,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Microblog, an online-based broadcast medium, is a widely used forum for
people to share their thoughts and opinions. Recently, Emotion Recognition (ER)
from microblogs is an inspiring research topic in diverse areas. In the machine
learning domain, automatic emotion recognition from microblogs is a challenging
task, especially, for better outcomes considering diverse content. Emoticon
becomes very common in the text of microblogs as it reinforces the meaning of
content. This study proposes an emotion recognition scheme considering both the
texts and emoticons from microblog data. Emoticons are considered unique
expressions of the users' emotions and can be changed by the proper emotional
words. The succession of emoticons appearing in the microblog data is preserved
and a 1D Convolutional Neural Network (CNN) is employed for emotion
classification. The experimental result shows that the proposed emotion
recognition scheme outperforms the other existing methods while tested on
Twitter data.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:04:44 GMT""}]","2023-01-10"
"2301.02972","Shu Sun Dr.","Shu Sun and Meixia Tao","Characteristics of Channel Eigenvalues and Mutual Coupling Effects for
  Holographic Reconfigurable Intelligent Surfaces",,"Sensors, vol. 22, no. 14, pp. 5297, Jul. 2022","10.3390/s22145297",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a prospective key technology for the next-generation wireless
communications, reconfigurable intelligent surfaces (RISs) have gained
tremendous research interest in both the academia and industry in recent years.
Only limited knowledge, however, has been obtained about the channel eigenvalue
characteristics and spatial degrees of freedom (DoF) of systems containing
RISs, especially when mutual coupling (MC) is present between the array
elements. In this paper, we focus on the small-scale spatial correlation and
eigenvalue properties excluding and including MC effects, for RISs with a
quasi-continuous aperture (i.e., holographic RISs). Specifically, asymptotic
behaviors of far-field and near-field eigenvalues of the spatial correlation
matrix of holographic RISs without MC are first investigated, where the
counter-intuitive observation of a lower DoF with more elements is explained by
leveraging the power spectrum of the spatial correlation function. Second, a
novel metric is proposed to quantify the inter-element correlation or coupling
strength in RISs and ordinary antenna arrays. Furthermore, in-depth analysis is
performed regarding the MC effects on array gain, effective spatial
correlation, and eigenvalue architectures for a variety of element intervals
when a holographic RIS works in the radiation and reception mode, respectively.
The analysis and numerical results demonstrate that a considerable amount of
the eigenvalues of the spatial correlation matrix correspond to evanescent
waves that are promising for near-field communication and sensing. More
importantly, holographic RISs can potentially reach an array gain conspicuously
larger than conventional arrays by exploiting MC, and MC has discrepant impacts
on the effective spatial correlation and eigenvalue structures at the
transmitter and receiver.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:10:40 GMT""}]","2023-01-10"
"2301.02973","Sean English","Sean English, J\""urgen Kritschgau, Mina Nahvi, Elizabeth Sprangel","Saturation Numbers for Berge Cliques","16 pages, 1 figure",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $F$ be a graph and $\mathcal{H}$ be a hypergraph, both embedded on the
same vertex set. We say $\mathcal{H}$ is a Berge-$F$ if there exists a
bijection $\phi:E(F)\to E(\mathcal{H})$ such that $e\subseteq \phi(e)$ for all
$e\in E(F)$. We say $\mathcal{H}$ is Berge-$F$-saturated if $\mathcal{H}$ does
not contain any Berge-$F$, but adding any missing edge to $\mathcal{H}$ creates
a copy of a Berge-$F$.
  The saturation number $\mathrm{sat}_k(n,\text{Berge-}F)$ is the least number
of edges in a Berge-$F$-saturated $k$-uniform hypergraph on $n$ vertices.
  We show
  \[
  \mathrm{sat}_k(n,\text{Berge-}K_\ell)\sim \frac{\ell-2}{k-1}n,
  \]
  for all $k,\ell\geq 3$. Furthermore, we provide some sufficient conditions to
imply that $\mathrm{sat}_k(n,\text{Berge-}F)=O(n)$ for general graphs $F$.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:18:50 GMT""}]","2023-01-10"
"2301.02974","Xiaozhe Wang","Xiaozhe Wang, Suyang Sun, Jiang-Jing Wang, Shuang Li, Jian Zhou, Oktay
  Aktas, Ming Xu, Volker L. Deringer, Riccardo Mazzarello, En Ma, Wei Zhang","Spin glass behavior in amorphous Cr2Ge2Te6 phase-change alloy",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The layered crystal structure of Cr2Ge2Te6 shows ferromagnetic ordering at
the two-dimensional limit, which holds promise for spintronic applications.
However, external voltage pulses can trigger amorphization of the material in
nanoscale electronic devices, and it is unclear whether the loss of structural
ordering leads to a change in magnetic properties. Here, we demonstrate that
Cr2Ge2Te6 preserves the spin-polarized nature in the amorphous phase, but
undergoes a magnetic transition to a spin glass state below 20 K.
Quantum-mechanical computations reveal the microscopic origin of this
transition in spin configuration: it is due to strong distortions of the
Cr-Te-Cr bonds, connecting chromium-centered octahedra, and to the overall
increase in disorder upon amorphization. The tunable magnetic properties of
Cr2Ge2Te6 could be exploited for multifunctional, magnetic phase-change devices
that switch between crystalline and amorphous states.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:31:46 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 10:18:08 GMT""}]","2023-06-05"
"2301.02975","Bruce W. Lee","Bruce W. Lee, Jason Hyung-Jong Lee","Traditional Readability Formulas Compared for English","Submitted to EMNLP 2022",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Traditional English readability formulas, or equations, were largely
developed in the 20th century. Nonetheless, many researchers still rely on them
for various NLP applications. This phenomenon is presumably due to the
convenience and straightforwardness of readability formulas. In this work, we
contribute to the NLP community by 1. introducing New English Readability
Formula (NERF), 2. recalibrating the coefficients of old readability formulas
(Flesch-Kincaid Grade Level, Fog Index, SMOG Index, Coleman-Liau Index, and
Automated Readability Index), 3. evaluating the readability formulas, for use
in text simplification studies and medical texts, and 4. developing a
Python-based program for the wide application to various NLP projects.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:33:43 GMT""},{""version"":""v2"",""created"":""Tue, 10 Jan 2023 05:54:50 GMT""}]","2023-01-11"
"2301.02976","Jiawen Zhang","Jiawen Zhang","Well-Posedness for 2D Combustion Model in Bounded Domains and
  Serrin-Type Blowup Criterion","54 pages, 41 conference",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We investigate the 2D combustion model with Dirichlet boundary conditions and
slip boundary conditions in bounded domains. The global existence of weak and
strong solutions and the uniqueness of strong solutions are obtained provided
the initial density is small in some precise sense. Using the energy method and
the estimates of boundary integrals, we obtain the a priori bounds if the
density and velocity field. In addition, we prove the local existence of the
strong solutions via iterative method and the contraction mapping theorem.
Finally, we extend the well known Serrion's blowup criterion to the 2D
combustion model. Under the suitable boundary conditions, the Serrin's
condition on the velocity can be removed in this criteria.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:51:31 GMT""}]","2023-01-10"
"2301.02977","Ashoke De","Bharat Bhatia, Tom Johny, and Ashoke De","Understanding the liquid jet break-up in various regimes at elevated
  pressure using a compressible VOF-LPT coupled framework",,"International Journal of Multiphase Flow 2023","10.1016/j.ijmultiphaseflow.2022.10430",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present work develops a compressible VOF-LPT coupled solver in OpenFOAM
and utilizes it to simulate a LJICF numerically. This methodology helps
accurately predict a complex primary breakup in the Eulerian framework and the
secondary atomization of spherical droplets using a computationally efficient
LPT method. The coupled solver with AMR is rigorously validated for a liquid
jet in crossflow at varying operating conditions. We have further carried out a
thorough investigation to study the effect of momentum flux ratio and weber
number on the various flow features and liquid jet break-up phenomenon in a
crossflow while identifying the stream-wise location of the liquid jet breakup
region. At low momentum flux ratios in the bag breakup regime, the predictions
reveal that the liquid jet breakup occurs due to the growth of similar
instability as usually observed in the high-speed liquid sheet atomization. The
short wavelength assumption of the inviscid dispersion relation resembles the
Kelvin-Helmholtz type instability observed in this case, as opposed to
Rayleigh-Taylor instability at high momentum flux ratio in the surface breakup
regime. It is also proposed that the shear breakup along the transverse edges
of the liquid column occurs due to the shear layer instability of the air
passing around the liquid column. The simulation wavelength closely matches the
Williamson correlation for shear layer instability around cylinders: a shape
similar to the cross-section of the bottom of the liquid column. The results
show a distinct streamer or bifurcation phenomenon at low momentum flux ratios
and moderate weber numbers. Further investigation suggests that the internal
liquid boundary layer and the three-dimensional flow field behind the liquid
jet are responsible for streamer formation.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:53:41 GMT""}]","2023-01-10"
"2301.02978","Haibo Wang","Yanbaihui Liu and Haibo Wang and Dongming Jia","Human Following Based on Visual Perception in the Context of Warehouse
  Logistics","Under review in 2023 5th international Conference on Materials
  Science, Machine and Energy Engineering (MSMEE 2023)",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Under the background of 5G, Internet, artificial intelligence technol,ogy and
robot technology, warehousing, and logistics robot technology has developed
rapidly, and products have been widely used. A practical application is to help
warehouse personnel pick up or deliver heavy goods at dispersed locations based
on dynamic routes. However, programs that can only accept instructions or
pre-set by the system do not have more flexibility, but existing human
auto-following techniques either cannot accurately identify specific targets or
require a combination of lasers and cameras that are cumbersome and do not
accomplish obstacle avoidance well. This paper proposed an algorithm that
combines DeepSort and a width-based tracking module to track targets and use
artificial potential field local path planning to avoid obstacles. The
evaluation is performed in a self-designed flat bounded test field and
simulated in ROS. Our method achieves the SOTA results on following and
successfully reaching the end-point without hitting obstacles.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:03:01 GMT""}]","2023-01-10"
"2301.02979","Cheng-Yen Yang","Cheng-Yen Yang, Jiajia Luo, Lu Xia, Yuyin Sun, Nan Qiao, Ke Zhang,
  Zhongyu Jiang, Jenq-Neng Hwang","CameraPose: Weakly-Supervised Monocular 3D Human Pose Estimation by
  Leveraging In-the-wild 2D Annotations",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To improve the generalization of 3D human pose estimators, many existing deep
learning based models focus on adding different augmentations to training
poses. However, data augmentation techniques are limited to the ""seen"" pose
combinations and hard to infer poses with rare ""unseen"" joint positions. To
address this problem, we present CameraPose, a weakly-supervised framework for
3D human pose estimation from a single image, which can not only be applied on
2D-3D pose pairs but also on 2D alone annotations. By adding a camera parameter
branch, any in-the-wild 2D annotations can be fed into our pipeline to boost
the training diversity and the 3D poses can be implicitly learned by
reprojecting back to 2D. Moreover, CameraPose introduces a refinement network
module with confidence-guided loss to further improve the quality of noisy 2D
keypoints extracted by 2D pose estimators. Experimental results demonstrate
that the CameraPose brings in clear improvements on cross-scenario datasets.
Notably, it outperforms the baseline method by 3mm on the most challenging
dataset 3DPW. In addition, by combining our proposed refinement network module
with existing 3D pose estimators, their performance can be improved in
cross-scenario evaluation.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:07:41 GMT""}]","2023-01-10"
"2301.02980","Hong Tang","Hong Tang, Jason M. Breslin, Li Yin, and Adrienn Ruzsinszky","Bending effects and optical properties of WSe2 nanoribbons of
  topological phase","15pages",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  A WSe2 monolayer of 1T' phase is a large band gap quantum spin Hall
insulator, supporting dissipationless charge and spin transports through the
topologically protected edge states. In this work, we explore the nanoribbon
forms of 1T' phase WSe2 by first-principles density functional calculations and
the many-body perturbation GW and Bethe-Salpeter equation method. We found that
the 1T' WSe2 nanoribbon can show topological edge states with a ribbon width of
~4-6 nm. Those edge bands show crossing through the Fermi level an odd number
of times, with one kind of spin-polarization connecting the valence band
continuum and conduction band continuum. The topological features of the edge
bands hold even under small and medium bending in the nanoribbon, while large
bending induces large band splitting, resulting in a topological switch-off in
the edge bands. The semiconducting 1T' WSe2 nanoribbon shows a large tunability
with bending in optical absorption spectra and exciton states. The
lowest-energy exciton is changed from optically dark in the flat nanoribbon to
bright in the bent nanoribbons. These properties in the 1T' WSe2 nanoribbons
suggest potential applications in controllable quantum electronics and
exciton-based quantum information processes.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:19:53 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 06:17:55 GMT""}]","2023-02-28"
"2301.02981","Kinkar Chandra Das","Xueyi Huang, Kinkar Chandra Das and Shunlai Zhu","Toughness and normalized Laplacian eigenvalues of graphs",,,,,"math.CO math.SP","http://creativecommons.org/licenses/by/4.0/","  Given a connected graph $G$, the toughness $\tau_G$ is defined as the minimum
value of the ratio $|S|/\omega_{G-S}$, where $S$ ranges over all vertex cut
sets of $G$, and $\omega_{G-S}$ is the number of connected components in the
subgraph $G-S$ obtained by deleting all vertices of $S$ from $G$. In this
paper, we provide a lower bound for the toughness $\tau_G$ in terms of the
maximum degree, minimum degree and normalized Laplacian eigenvalues of $G$.
This can be viewed as a slight generalization of Brouwer's toughness
conjecture, which was confirmed by Gu (2021). Furthermore, we give a
characterization of those graphs attaining the two lower bounds regarding
toughness and Laplacian eigenvalues provided by Gu and Haemers (2022).
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:19:53 GMT""}]","2023-01-10"
"2301.02982","Yanmeng Wang","Yanmeng Wang, Qingjiang Shi, Tsung-Hui Chang","Why Batch Normalization Damage Federated Learning on Non-IID Data?",,,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a promising distributed learning paradigm, federated learning (FL)
involves training deep neural network (DNN) models at the network edge while
protecting the privacy of the edge clients. To train a large-scale DNN model,
batch normalization (BN) has been regarded as a simple and effective means to
accelerate the training and improve the generalization capability. However,
recent findings indicate that BN can significantly impair the performance of FL
in the presence of non-i.i.d. data. While several FL algorithms have been
proposed to address this issue, their performance still falls significantly
when compared to the centralized scheme. Furthermore, none of them have
provided a theoretical explanation of how the BN damages the FL convergence. In
this paper, we present the first convergence analysis to show that under the
non-i.i.d. data, the mismatch between the local and global statistical
parameters in BN causes the gradient deviation between the local and global
models, which, as a result, slows down and biases the FL convergence. In view
of this, we develop a new FL algorithm that is tailored to BN, called FedTAN,
which is capable of achieving robust FL performance under a variety of data
distributions via iterative layer-wise parameter aggregation. Comprehensive
experimental results demonstrate the superiority of the proposed FedTAN over
existing baselines for training BN-based DNN models.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:24:12 GMT""}]","2023-01-10"
"2301.02983","Fangzhi Xu","Fangzhi Xu, Jun Liu, Qika Lin, Tianzhe Zhao, Jian Zhang, Lingling
  Zhang","Mind Reasoning Manners: Enhancing Type Perception for Generalized
  Zero-shot Logical Reasoning over Text","12 pages, 7 figures",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Logical reasoning task involves diverse types of complex reasoning over text,
based on the form of multiple-choice question answering. Given the context,
question and a set of options as the input, previous methods achieve superior
performances on the full-data setting. However, the current benchmark dataset
has the ideal assumption that the reasoning type distribution on the train
split is close to the test split, which is inconsistent with many real
application scenarios. To address it, there remain two problems to be studied:
(1) How is the zero-shot capability of the models (train on seen types and test
on unseen types)? (2) How to enhance the perception of reasoning types for the
models? For problem 1, we propose a new benchmark for generalized zero-shot
logical reasoning, named ZsLR. It includes six splits based on the three type
sampling strategies. For problem 2, a type-aware model TaCo is proposed. It
utilizes both the heuristic input reconstruction and the contrastive learning
to improve the type perception in the global representation. Extensive
experiments on both the zero-shot and full-data settings prove the superiority
of TaCo over the state-of-the-art methods. Also, we experiment and verify the
generalization capability of TaCo on other logical reasoning dataset.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:24:34 GMT""}]","2023-01-10"
"2301.02984","Bo Jiang","Yumin Ma, Xingju Cai, Bo Jiang, Deren Han","Understanding the convergence of the preconditioned PDHG method: a view
  of indefinite proximal ADMM","accepted for publication in Journal of Scientific Computing",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The primal-dual hybrid gradient (PDHG) algorithm is popular in solving
min-max problems which are being widely used in a variety of areas. To improve
the applicability and efficiency of PDHG for different application scenarios,
we focus on the preconditioned PDHG (PrePDHG) algorithm, which is a framework
covering PDHG, alternating direction method of multipliers (ADMM), and other
methods. We give the optimal convergence condition of PrePDHG in the sense that
the key parameters in the condition can not be further improved, which fills
the theoretical gap in the-state-of-art convergence results of PrePDHG, and
obtain the ergodic and non-ergodic sublinear convergence rates of PrePDHG. The
theoretical analysis is achieved by establishing the equivalence between
PrePDHG and indefinite proximal ADMM. Besides, we discuss various choices of
the proximal matrices in PrePDHG and derive some interesting results. For
example, the convergence condition of diagonal PrePDHG is improved to be tight,
the dual stepsize of the balanced augmented Lagrangian method can be enlarged
to $4/3$ from $1$, and a balanced augmented Lagrangian method with symmetric
Gauss-Seidel iterations is also explored. Numerical results on the matrix game,
projection onto the Birkhoff polytope, earth mover's distance, and CT
reconstruction verify the effectiveness and superiority of PrePDHG.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:38:25 GMT""}]","2023-01-10"
"2301.02985","Liang Liu","Liang Liu, Weikang Liu, Bin Cheng, Bin Cui, and Jifan Hu","Switchable Giant Bulk Photocurrents and Photo-spin-currents in Monolayer
  PT-symmetric Anti-ferromagnet MnPSe3","21 pages, 5 figures",,"10.1021/acs.jpclett.2c03383",,"cond-mat.mtrl-sci physics.comp-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Converting light into steady currents and spin-currents in two-dimensional
(2D) platform is essential for future energy harvesting and spintronics. We
show that the giant and modulable bulk photovoltaic effects (BPVEs) can be
achieved in air-stable 2D antiferromagnet (AFM) monolayer MnPSe3, with
nonlinear photoconductance > 4000 nm$\cdot\mu$A/V2 and photo-spin-conductance >
2000 (nm$\cdot\mu$A/V2 $\hbar$/2e) in the visible spectrum. The propagation and
the spin-polarizations of photocurrents can be switched via simply rotating the
N$\'e$el vector. We unveil that the PT-symmetry, mirror symmetries, and
spin-orbital-couplings are the keys for the observed sizable and controllable
2D BPVEs. All the results provide insights into the BPVEs of 2D AFM, and
suggest that the layered MnPSe3 is an outstanding 2D platform for energy device
and photo-spintronics.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:42:31 GMT""}]","2023-01-10"
"2301.02986","Zekang Zhang","Zekang Zhang, Huanyuan Shan, Nan Li, Chengliang Wei, Ji Yao and Ran Li","Forklens: Accurate weak lensing shear measurement on extremely noisy
  images with deep learning","11 pages, 11 figures; Comments are welcome!",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weak gravitational lensing is one of the most important probes of the nature
of dark matter and dark energy. In order to extract cosmological information
from next-generation weak lensing surveys (e.g., Euclid, Roman, LSST, and CSST)
as much as possible, accurate measurements of weak lensing shear are required.
In this work, we present a fully deep-learning-based approach to measuring weak
lensing shear accurately. Our approach comprises two modules. The first one
contains a CNN with two branches for taking galaxy images and PSF
simultaneously, and the output of this module includes the galaxy's magnitude,
size, and shape. The second module includes a multiple-layer Neural Network to
calibrate weak lensing shear measurements. We name the program Forklens and
make it publicly available online. Applying Forklens to CSST-like mock images,
we achieve consistent accuracy with traditional approaches (such as
moment-based measurement and forward model fitting) on the sources with high
signal-to-noise ratios (S/N). For the sources with meagre S/N, Forklens
exhibits powerful latent denoising ability and offers accurate predictions on
galaxy shapes. The final shear measurements with Forklens deliver a
multiplicative bias $m=-0.4\pm3.0\times10^{-3}$ and an additive bias
$c=-0.5\pm1.9\times10^{-4}$. Our tests with CSST-like simulation show that
Forklens is competitive with other shear measurement algorithms such as
Metacalibration, while Forklens can potentially lower the S/N limit. Moreover,
the whole procedure of Forklens is automated and costs about 0.6 milliseconds
per galaxy, which is appropriate to adequately take advantage of the sky
coverage and depth of the upcoming weak lensing surveys.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:49:55 GMT""}]","2023-01-10"
"2301.02987","Plamen Dimitrov","Plamen Dimitrov","Neural network models","112 pages, 26 figures, master thesis in Mathematics, supervised by
  Debora Amadori and Leonardo Guidoni, submitted on November 30, 2016",,,,"cs.NE math.DS","http://creativecommons.org/licenses/by-sa/4.0/","  This work presents the current collection of mathematical models related to
neural networks and proposes a new family of such with extended structure and
dynamics in order to attain a selection of cognitive capabilities. It starts by
providing a basic background to the morphology and physiology of the biological
and the foundations and advances of the artificial neural networks. The first
part then continues with a survey of all current mathematical models and some
of their derived properties. In the second part, a new family of models is
formulated, compared with the rest, and developed analytically and numerically.
Finally, important additional aspects and any limitations to deal with in the
future are discussed.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:52:13 GMT""}]","2023-01-10"
"2301.02988","Kabgyun Jeong","Kabgyun Jeong","Sample-size-reduction of quantum states for the noisy linear problem","11 pages, 2 figures, 1 table; Close to published version","Annals of Physics 449, 169215 (2023)","10.1016/j.aop.2022.169215",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum supremacy poses that a realistic quantum computer can perform a
calculation that classical computers cannot in any reasonable amount of time.
It has become a topic of significant research interest since the birth of the
field, and it is intrinsically based on the efficient construction of quantum
algorithms. It has been shown that there exists an expeditious way to solve the
noisy linear (or learning with errors) problems in quantum machine learning
theory via a well-posed quantum sampling over pure quantum states. In this
paper, we propose an advanced method to reduce the sample size in the noisy
linear structure, through a technique of randomizing quantum states, namely,
$\varepsilon$-random technique. Particularly, we show that it is possible to
reduce a quantum sample size in a quantum random access memory (QRAM) to the
linearithmic order, in terms of the dimensions of the input-data. Thus, we
achieve a shorter run-time for the noisy linear problem.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 05:53:17 GMT""}]","2023-01-10"
"2301.02989","Hao-Wei Chung","Ching-Hao Chiu, Hao-Wei Chung, Yu-Jen Chen, Yiyu Shi, Tsung-Yi Ho","Fair Multi-Exit Framework for Facial Attribute Classification",,,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fairness has become increasingly pivotal in facial recognition. Without bias
mitigation, deploying unfair AI would harm the interest of the underprivileged
population. In this paper, we observe that though the higher accuracy that
features from the deeper layer of a neural networks generally offer, fairness
conditions deteriorate as we extract features from deeper layers. This
phenomenon motivates us to extend the concept of multi-exit framework. Unlike
existing works mainly focusing on accuracy, our multi-exit framework is
fairness-oriented, where the internal classifiers are trained to be more
accurate and fairer. During inference, any instance with high confidence from
an internal classifier is allowed to exit early. Moreover, our framework can be
applied to most existing fairness-aware frameworks. Experiment results show
that the proposed framework can largely improve the fairness condition over the
state-of-the-art in CelebA and UTK Face datasets.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 06:18:51 GMT""}]","2023-01-10"
"2301.02990","Jason Ryan Picardo","Jason R. Picardo and Emmanuel L. C. VI M. Plan and Dario Vincenzi","Polymers in turbulence: stretching statistics and the role of extreme
  strain-rate fluctuations","21 pages, 7 figures",,,,"physics.flu-dyn cond-mat.soft cond-mat.stat-mech nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polymers in a turbulent flow are stretched out by the fluctuating velocity
gradient; the stationary probability distribution function (p.d.f.) of
extensions $R$ has a power-law tail with an exponent that increases with the
Weissenberg number $Wi$, a nondimensional measure of polymer elasticity. This
study addresses the following questions: (i) What is the role of the
non-Gaussian statistics of the turbulent velocity gradient on polymer
stretching? (ii) How does the p.d.f. of $R$ evolve to its asymptotic stationary
form? Our analysis is based on simulations of the dynamics of
finitely-extensible bead-spring dumbbells and chains, in the extremely dilute
limit, that are transported in a homogeneous and isotropic turbulent flow, as
well as in a Gaussian random flow. First, we recall the large deviations theory
of polymer stretching, and illustrate its application. Then, we compare polymer
stretching in turbulent and Gaussian random flows and show that while
extreme-valued strain rates aid in stretching small-$Wi$ stiff polymers, they
are unimportant for high-$Wi$ polymers, which instead are stretched by the
cumulative action of moderate strain-rates. This result is supported by an
analysis of the persistence time of polymers in stretched states. Next,
beginning from a distribution of coiled polymers, we find that the p.d.f. of
$R$ has the form of an evolving power-law, for low to moderate $Wi$, though
this is not the case at high $Wi$. In either case, the p.d.f. relaxes to its
stationary form exponentially. The corresponding time scales of equilibration,
measured as a function of $Wi$, point to a critical slowing down at the
coil-stretch transition. Importantly, these results show no qualitative change
when chains in a turbulent flow are replaced by dumbbells in a Gaussian flow,
thereby supporting the use of the latter for reduced-order modelling.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 06:30:00 GMT""}]","2023-01-10"
"2301.02991","Juan Jose Fernandez-Duran","Fern\'andez-Dur\'an, J.J. and Gregorio-Dom\'inguez, M.M","Test of Bivariate Independence Based on Angular Probability Integral
  Transform with Emphasis on Circular-Circular and Circular-Linear Data","30 pages, 3 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The probability integral transform (PIT) of a random variable X with
distribution function F_X is a uniformly distributed random variable U =
F_X(X). We define the angular probability integral transform (APIT) as
{\theta}_U = 2{\pi}U = 2{\pi}F_X(X), which corresponds to a uniformly
distributed angle on the unit circle. For circular (angular) random variables,
the sum of absolutely continuous independent circular uniform random variables
is a circular uniform random variable, that is, the circular uniform
distribution is closed under summation, and it is a stable continuous
distribution on the unit circle. If we consider the sum (difference) of the
angular probability integral transforms of two random variables, X_1 and X_2,
and test for the circular uniformity of their sum (difference), this is
equivalent to test of independence of the original variables. In this study, we
used a flexible family of nonnegative trigonometric sums (NNTS) circular
distributions, which include the uniform circular distribution as a member of
the family, to evaluate the power of the proposed independence test by
generating samples from NNTS alternative distributions that could be at a
closer proximity with respect to the circular uniform null distribution.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 06:59:52 GMT""}]","2023-01-10"
"2301.02992","Chushan Wang","Weizhu Bao, Chushan Wang","Error estimates of the time-splitting methods for the nonlinear
  Schr\""odinger equation with semi-smooth nonlinearity","30 pages, 6 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish error bounds of the Lie-Trotter time-splitting sine
pseudospectral method for the nonlinear Schr\""odinger equation (NLSE) with
semi-smooth nonlinearity $ f(\rho) = \rho^\sigma$, where $\rho=|\psi|^2$ is the
density with $\psi$ the wave function and $\sigma>0$ is the exponent of the
semi-smooth nonlinearity. Under the assumption of $ H^2 $-solution of the NLSE,
we prove error bounds at $ O(\tau^{\frac{1}{2}+\sigma} + h^{1+2\sigma}) $ and $
O(\tau + h^{2}) $ in $ L^2 $-norm for $0<\sigma\leq\frac{1}{2}$ and
$\sigma\geq\frac{1}{2}$, respectively, and an error bound at $
O(\tau^\frac{1}{2} + h) $ in $ H^1 $-norm for $\sigma\geq \frac{1}{2}$, where
$h$ and $\tau$ are the mesh size and time step size, respectively. In addition,
when $\frac{1}{2}<\sigma<1$ and under the assumption of $ H^3 $-solution of the
NLSE, we show an error bound at $ O(\tau^{\sigma} + h^{2\sigma}) $ in $ H^1
$-norm. Two key ingredients are adopted in our proof: one is to adopt an
unconditional $ L^2 $-stability of the numerical flow in order to avoid an a
priori estimate of the numerical solution for the case of $ 0 < \sigma \leq
\frac{1}{2}$, and to establish an $ l^\infty $-conditional $ H^1 $-stability to
obtain the $ l^\infty $-bound of the numerical solution by using the
mathematical induction and the error estimates for the case of $ \sigma \ge
\frac{1}{2}$; and the other one is to introduce a regularization technique to
avoid the singularity of the semi-smooth nonlinearity in obtaining improved
local truncation errors. Finally, numerical results are reported to demonstrate
our error bounds.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 07:11:57 GMT""}]","2023-01-10"
"2301.02993","Dai Kun","Tao Xie, Kun Dai, Ke Wang, Ruifeng Li, Lijun Zhao","DeepMatcher: A Deep Transformer-based Network for Robust and Accurate
  Local Feature Matching",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Local feature matching between images remains a challenging task, especially
in the presence of significant appearance variations, e.g., extreme viewpoint
changes. In this work, we propose DeepMatcher, a deep Transformer-based network
built upon our investigation of local feature matching in detector-free
methods. The key insight is that local feature matcher with deep layers can
capture more human-intuitive and simpler-to-match features. Based on this, we
propose a Slimming Transformer (SlimFormer) dedicated for DeepMatcher, which
leverages vector-based attention to model relevance among all keypoints and
achieves long-range context aggregation in an efficient and effective manner. A
relative position encoding is applied to each SlimFormer so as to explicitly
disclose relative distance information, further improving the representation of
keypoints. A layer-scale strategy is also employed in each SlimFormer to enable
the network to assimilate message exchange from the residual block adaptively,
thus allowing it to simulate the human behaviour that humans can acquire
different matching cues each time they scan an image pair. To facilitate a
better adaption of the SlimFormer, we introduce a Feature Transition Module
(FTM) to ensure a smooth transition in feature scopes with different receptive
fields. By interleaving the self- and cross-SlimFormer multiple times,
DeepMatcher can easily establish pixel-wise dense matches at coarse level.
Finally, we perceive the match refinement as a combination of classification
and regression problems and design Fine Matches Module to predict confidence
and offset concurrently, thereby generating robust and accurate matches.
Experimentally, we show that DeepMatcher significantly outperforms the
state-of-the-art methods on several benchmarks, demonstrating the superior
matching capability of DeepMatcher.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 07:15:09 GMT""}]","2023-01-10"
"2301.02994","Aashish Gupta","Aashish Gupta, Anna Miotello, Carlo F. Manara, Jonathan P. Williams,
  Stefano Facchini, Giacomo Beccari, Til Birnstiel, Christian Ginski, Alvaro
  Hacar, Michael K\""uffmeier, Leonardo Testi, Lukasz Tychoniec and Hsi-Wei Yen","Reflections on nebulae around young stars: A systematic search for
  late-stage infall of material onto Class II disks","Accepted for publication in Astronomy & Astrophysics","A&A 670, L8 (2023)","10.1051/0004-6361/202245254",,"astro-ph.SR astro-ph.EP astro-ph.GA","http://creativecommons.org/licenses/by-sa/4.0/","  Context. While it is generally assumed that Class II sources evolve largely
in isolation from their environment, many still lie close to molecular clouds
and may continue to interact with them. This may result in late accretion of
material onto the disk that can significantly influence disk processes and
planet formation.
  Aims. In order to systematically study late infall of gas onto disks, we
identify candidate Class II sources in close vicinity to a reflection nebula
(RN) that may be undergoing this process.
  Methods. First we targeted Class II sources with known kilo-au scale gas
structures - possibly due to late infall of material - and we searched for RNe
in their vicinity in optical and near-infrared images. Second, we compiled a
catalogue of Class II sources associated with RNe and looked for the
large-scale CO structures in archival ALMA data. Using the catalogues of
protostars and RNe, we also estimated the probability of Class II sources
interacting with surrounding material.
  Results. All of the sources with large-scale gas structures also exhibit some
reflection nebulosity in their vicinity. Similarly, at least five Class II
objects associated with a prominent RNe, and for which adequate ALMA
observations are available, were found to have spirals or stream-like
structures which may be due to late infall. We report the first detection of
these structures around S CrA.
  Conclusions. Our results suggest that a non-negligible fraction of Class II
disks in nearby star-forming regions may be associated with RNe and could
therefore be undergoing late accretion of gas. Surveys of RNe and kilo-au scale
gas structures around Class II sources will allow us to better understand the
frequency and impact of late-infall phenomena.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 07:15:42 GMT""}]","2023-02-01"
"2301.02995","Ao Liu","Ao Liu, Qishen Han, Lirong Xia, Nengkun Yu","Accelerating Voting by Quantum Computation","8 pages main text + 2 pages reference + 6 pages appendix",,,,"cs.CY quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studying the computational complexity of determining winners under voting
rules and designing fast algorithms are classical and fundamental questions in
computational social choice. In this paper, we accelerate voting by leveraging
quantum computing. We propose a quantum-accelerated voting algorithm that can
be applied to any anonymous voting rule. We further show that our algorithm can
be quadratically faster than any classical algorithm (based on sampling with
replacement) under a wide range of common voting rules, including positional
scoring rules, Copeland, and single transferable voting (STV). Precisely, our
quantum-accelerated voting algorithm output the correct winner with runtime
$\Theta\left(\frac{n}{\text{MOV}}\right)$, where $n$ is the number of votes and
$\text{MOV}$ is margin of victory, the smallest number of voters to change the
winner. On the other hand, any classical voting algorithm based on sampling
with replacement requires runtime $\Omega\left(\frac{n^2}{\text{MOV}^2}\right)$
under a large subset of voting rules. Our theoretical results are supported by
experiments under plurality, Borda, Copeland, and STV.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 07:29:38 GMT""},{""version"":""v2"",""created"":""Sat, 18 Feb 2023 17:48:14 GMT""},{""version"":""v3"",""created"":""Thu, 11 May 2023 01:03:38 GMT""}]","2023-05-12"
"2301.02996","Gentian Zavalani","Gentian Zavalani and Elima Shehu","A note on the rate of convergence of integration schemes for closed
  surfaces","14 pages, 6 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we issue an error analysis for integration over discrete
surfaces using the surface parametrization presented in [PS22] as well as prove
why even-degree polynomials exhibit a higher convergence rate than odd-degree
polynomials. Additionally, we provide some numerical examples that illustrate
our findings and propose a potential approach that overcomes the problems
associated with the original one.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 07:52:53 GMT""}]","2023-01-10"
"2301.02997","Liu Tonghua","Liu Tonghua, Cao Shuo, Ma Shuai, Liu Yuting, Zheng Chenfa and Wang
  Jieci","What are recent observations telling us in light of improved tests of
  distance duality relation?","21 pages, 5 figures, accepted for publication in PLB",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  As an exact result required by the Etherington reciprocity theorem, the
cosmic distance duality relation (CDDR), $\eta(z)=D_L(z)(1+z)^{-2}/D_A(z)=1$
plays an essential part in modern cosmology. In this paper, we present a new
method ($\eta(z_i)/\eta(z_j)$) to use the measurements of ultra-compact
structure in radio quasars (QSO) and the latest observations of type Ia
supernova (SN Ia) to test CDDR. By taking the observations directly from SN Ia
and QSOs, one can completely eliminate the uncertainty caused by the
calibration of the absolute magnitudes of standard candles ($M_B$) and the
linear sizes of standard rulers ($l_m$). Benefit from the absence of nuisance
parameters involved in other currently available methods, our analysis
demonstrates no evidence for the deviation and redshift evolution of CDDR up to
$z=2.3$. The combination of our methodology and the machine learning Artificial
Neural Network (ANN) would produce $10^{-3}$ level constraints on the violation
parameter at high redshifts. Our results indicate perfect agreement between
observations and predictions, supporting the persisting claims that the
Etherington reciprocity theorem could still be the best description of our
universe.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 07:55:08 GMT""}]","2023-01-10"
"2301.02998","Leonid Boytsov","Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayani
  Kundu, Ramya Ramanathan, Eric Nyberg","InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers",,,,,"cs.IR cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We carried out a reproducibility study of InPars recipe for unsupervised
training of neural rankers. As a by-product of this study, we developed a
simple-yet-effective modification of InPars, which we called InPars-light.
Unlike InPars, InPars-light uses only a freely available language model BLOOM
and 7x-100x smaller ranking models. On all five English retrieval collections
(used in the original InPars study) we obtained substantial (7-30%) and
statistically significant improvements over BM25 in nDCG or MRR using only a
30M parameter six-layer MiniLM ranker. In contrast, in the InPars study only a
100x larger MonoT5-3B model consistently outperformed BM25, whereas their
smaller MonoT5-220M model (which is still 7x larger than our MiniLM ranker),
outperformed BM25 only on MS MARCO and TREC DL 2020. In a purely unsupervised
setting, our 435M parameter DeBERTA v3 ranker was roughly at par with the 7x
larger MonoT5-3B: In fact, on three out of five datasets, it slightly
outperformed MonoT5-3B. Finally, these good results were achieved by re-ranking
only 100 candidate documents compared to 1000 used in InPars. We believe that
InPars-light is the first truly cost-effective prompt-based unsupervised recipe
to train and deploy neural ranking models that outperform BM25.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 08:03:46 GMT""}]","2023-01-10"
"2301.02999","Qiang Zou","Qiang Zou, Hsi-Yung Feng, Shuming Gao","Variational Direct Modeling: A framework towards integration of
  parametric modeling and direct modeling in CAD","19pages",,"10.1016/j.cad.2022.103465",,"cs.GR cs.CG","http://creativecommons.org/licenses/by/4.0/","  Feature-based parametric modeling is the de facto standard in CAD. Boundary
representation-based direct modeling is another CAD paradigm developed
recently. They have complementary advantages and limitations, thereby offering
huge potential for improvement towards an integrated CAD modeling scheme. Most
existing integration methods are developed by industry and typically treat
direct edits as pseudo-features, where little can be said about seamless
integration. This paper presents an alternative method for seamless
parametric/direct integration, which allows parametric and direct edits to work
in a unified way. The fundamental issues and challenges of parametric/direct
integration are first explained. A framework is then proposed to handle those
information inconsistencies, based on a detection-then-resolution strategy.
Algorithms that can systematically detect and resolve all possible types of
information inconsistencies are also given to implement the framework. With
them, model validity can be maintained during the whole model editing process,
and then the discrepancy between direct edits and parametric edits can be
resolved. The effectiveness of the proposed approach has been shown with a
series of case studies and comparisons, based on a preliminary prototype.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 08:16:28 GMT""}]","2023-01-10"
"2301.03000","Jeong Min Jeon","Jeong Min Jeon and Ingrid Van Keilegom","Density estimation and regression analysis on S^d in the presence of
  measurement error",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  This paper studies density estimation and regression analysis with
contaminated data observed on the unit hypersphere S^d. Our methodology and
theory are based on harmonic analysis on general S^d. We establish novel
nonparametric density and regression estimators, and study their asymptotic
properties including the rates of convergence and asymptotic distributions. We
also provide asymptotic confidence intervals based on the asymptotic
distributions of the estimators and on the empirical likelihood technique. We
present practical details on implementation as well as the results of numerical
studies.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 08:59:06 GMT""}]","2023-01-10"
"2301.03001","Yongling Zhao","Yongling Zhao, Lup Wai Chew, Yifan Fan, Christof Gromke, Jian Hang,
  Yichen Yu, Alessio Ricci, Yan Zhang, Yunpeng Xue, Sofia Fellini, Parham A.
  Mirzaei, Naiping Gao, Matteo Carpentieri, Pietro Salizzoni, Jianlei Niu, Jan
  Carmeliet","Fluid Tunnel Research for Challenges of Urban Climate","36 pages,9 figures, 1 table",,,,"physics.flu-dyn physics.ao-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Experimental investigations using wind and water tunnels have long been a
staple of fluid mechanics research for a large number of applications. These
experiments often single out a specific physical process to be investigated,
while studies involving multiscale and multi-physics processes are rare due to
the difficulty and complexity in the experimental setup. In the era of climate
change, there is an increasing interest in innovative experimental studies in
which fluid (wind and water) tunnels are employed for modelling multiscale,
multi-physics phenomena of the urban climate. High-quality fluid tunnel
measurements of urban-physics related phenomena are also much needed to
facilitate the development and validation of advanced multi-physics numerical
models. As a repository of knowledge in modelling these urban processes, we
cover fundamentals, recommendations and guidelines for experimental design,
recent advances and outlook on eight selected research areas, including (i)
thermal buoyancy effects of urban airflows, (ii) aerodynamic and thermal
effects of vegetation, (iii) radiative and convective heat fluxes over urban
materials, (iv) influence of thermal stratification on land-atmosphere
interactions, (v) pollutant dispersion, (vi) indoor and outdoor natural
ventilation, (vii) wind thermal comfort, and (viii) urban winds over complex
urban sites. Further, three main challenges, i.e., modelling of multi-physics,
modelling of anthropogenic processes, and combined use of fluid tunnels, scaled
outdoor and field measurements for urban climate studies, are discussed.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 08:59:09 GMT""}]","2023-01-10"
"2301.03002","Di Wu","Di Wu, Shuang-Qing Wu","Topological classes of thermodynamics of rotating AdS black holes","13 pages, 20 figures, 2 tables, revtex4-1.cls, match with the
  published version in PRD","Phys. Rev. D 107, 084002 (2023)","10.1103/PhysRevD.107.084002",,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  In this paper, we extend our previous work [Phys. Rev. D 107, 024024 (2023)]
to the more general cases with a negative cosmological constant, and
investigate the topological numbers for the singly rotating Kerr-AdS black
holes in all dimensions and the four-dimensional Kerr-Newman-AdS black hole as
well as the three-dimensional Ba\~nados-Teitelboim-Zanelli black hole. We find
that the topological numbers of black holes are remarkably influenced by the
cosmological constant. In addition, we also demonstrate that the dimension of
spacetimes has an important effect on the topological number for rotating AdS
black holes. Furthermore, it is interesting to observe that the difference
between the topological number of the AdS black hole and that of its
corresponding asymptotically flat black hole is always unity. This new
observation leads us to conjure that it might be valid also for other black
holes. Of course, this novel conjecture needs to be further verified by
examining the topological numbers of many other black holes and their AdS
counterparts in the future work.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:02:43 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 05:57:42 GMT""},{""version"":""v3"",""created"":""Sun, 19 Mar 2023 03:12:08 GMT""},{""version"":""v4"",""created"":""Mon, 3 Apr 2023 14:45:52 GMT""}]","2023-04-04"
"2301.03003","Kai Mo","Kai Mo, Chongkun Xia, Xueqian Wang, Yuhong Deng, Xuehai Gao, Bin Liang","Foldsformer: Learning Sequential Multi-Step Cloth Manipulation With
  Space-Time Attention","8 pages, 6 figures, published to IEEE Robotics & Automation Letters
  (RA-L)","IEEE Robotics and Automation Letters, vol. 8, no. 2, pp. 760-767,
  Feb. 2023","10.1109/LRA.2022.3229573",,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential multi-step cloth manipulation is a challenging problem in robotic
manipulation, requiring a robot to perceive the cloth state and plan a sequence
of chained actions leading to the desired state. Most previous works address
this problem in a goal-conditioned way, and goal observation must be given for
each specific task and cloth configuration, which is not practical and
efficient. Thus, we present a novel multi-step cloth manipulation planning
framework named Foldformer. Foldformer can complete similar tasks with only a
general demonstration and utilize a space-time attention mechanism to capture
the instruction information behind this demonstration. We experimentally
evaluate Foldsformer on four representative sequential multi-step manipulation
tasks and show that Foldsformer significantly outperforms state-of-the-art
approaches in simulation. Foldformer can complete multi-step cloth manipulation
tasks even when configurations of the cloth (e.g., size and pose) vary from
configurations in the general demonstrations. Furthermore, our approach can be
transferred from simulation to the real world without additional training or
domain randomization. Despite training on rectangular clothes, we also show
that our approach can generalize to unseen cloth shapes (T-shirts and shorts).
Videos and source code are available at:
https://sites.google.com/view/foldsformer.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:15:45 GMT""}]","2023-01-10"
"2301.03004","Yan-Gang Miao","Yang Guo, Hao Xie, Yan-Gang Miao","Joule-Thomson effect of AdS black holes in conformal gravity","v1: 10 pages, 4 figures",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the Joule-Thomson (JT) effect of AdS black holes in conformal
gravity. We derive the JT coefficient in terms of the relevant thermodynamic
quantities and then make a similar derivation via a direct way. We analyze the
JT coefficient and find that the JT coefficients obtained from two different
approaches are equivalent. Moreover, we present a novel isenthalpic process in
which the inversion temperature is minimal and it separates the corresponding
heating-cooling phase. We analyze the inversion temperature and its
corresponding inversion curve that separates the regions for the JT effect to
be allowable or forbidden, where such an effect can only be observed in the
allowable region. We also discuss the effects of two important parameters on
the inversion curves.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:17:51 GMT""}]","2023-01-10"
"2301.03005","Zhengxiao Li","Jiakun Jiang, Zhengxiao Li, Liang Yang","Dynamic online prediction model and its application to automobile claim
  frequency data","29 pages, 6 figures",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  Prediction modelling of claim frequency is an important task for pricing and
risk management in non-life insurance and needed to be updated frequently with
the changes in the insured population, regulatory legislation and technology.
Existing methods are either done in an ad hoc fashion, such as parametric model
calibration, or less so for the purpose of prediction. In this paper, we
develop a Dynamic Poisson state space (DPSS) model which can continuously
update the parameters whenever new claim information becomes available. DPSS
model allows for both time-varying and time-invariant coefficients. To account
for smoothness trends of time-varying coefficients over time, smoothing splines
are used to model time-varying coefficients. The smoothing parameters are
objectively chosen by maximum likelihood. The model is updated using batch data
accumulated at pre-specified time intervals, which allows for a better
approximation of the underlying Poisson density function. The proposed method
can be also extended to the distributional assumption of zero-inflated Poisson
and negative binomial. In the simulation, we show that the new model has
significantly higher prediction accuracy compared to existing methods. We apply
this methodology to a real-world automobile insurance claim data set in China
over a period of six years and demonstrate its superiority by comparing it with
the results of competing models from the literature.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:18:53 GMT""}]","2023-01-10"
"2301.03006","Chunping Gao","Chunping Gao, Zheng Tang, Fei Zhu, Yunbo Zhang, Han Pu, and Li Chen","Non-thermal dynamics in a spin-1/2 lattice Schwinger model",,,"10.1103/PhysRevB.107.104302",,"cond-mat.quant-gas cond-mat.dis-nn cond-mat.stat-mech hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Local gauge symmetry is intriguing for the study of quantum thermalization
breaking. For example, in the high-spin lattice Schwinger model (LSM), the
local U(1) gauge symmetry underlies the disorder-free many-body localization
(MBL) dynamics of matter fields. This mechanism, however, would not work in a
spin-1/2 LSM due to the absence of electric energy in the Hamiltonian. In this
paper, we show that the spin-1/2 LSM can also exhibit disorder-free MBL
dynamics, as well as entropy prethermalization, by introducing a four-fermion
interaction into the system. The interplay between the fermion interaction and
U(1) gauge symmetry endows the gauge fields with an effectively disordered
potential which is responsible for the thermalization breaking. It induces
anomalous (i.e., non-thermal) behaviors in the long-time evolution of such
quantities as local observables, entanglement entropy, and correlation
functions. Our work offers a new platform to explore emergent non-thermal
dynamics in state-of-the-art quantum simulators with gauge symmetries.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:23:34 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 01:26:22 GMT""}]","2023-03-29"
"2301.03007","Martin Werner Licht","Martin W. Licht","Averaging-based local projections in finite element exterior calculus","27 pages. Submitted. Comments welcome",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop projection operators onto finite element differential forms over
simplicial meshes. Our projection is locally bounded in Lebesgue and
Sobolev-Slobodeckij norms, uniformly with respect to mesh parameters. Moreover,
it incorporates homogeneous boundary conditions and satisfies a local broken
Bramble-Hilbert estimate. The construction principle includes the Ern-Guermond
projection and a modified Cl\'ement-type interpolant with the projection
property. The latter seems to be a new result even for Lagrange elements. This
projection operator immediately enables an equivalence result on local- and
global-best approximations. We combine techniques for the Scott-Zhang and
Ern-Guermond projections and adopt the framework of finite element exterior
calculus. We instantiate the abstract projection for Brezzi-Douglas-Marini,
N\'ed\'elec, and Raviart-Thomas elements.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:33:25 GMT""}]","2023-01-10"
"2301.03008","Samuel Kamau","Abdijabar Yussuf Mohamed and Samuel Kang'ara Kamau","A Continent-Wide Assessment of Cyber Vulnerability Across Africa","10 pages, 5 figures, submitted to the initiative Digital Technologies
  in Emerging Countries: Impacts and Responses by The Program on Democracy and
  the Internet (PDI) at Stanford University Cyber Policy Center",,,,"cs.CR cs.NI","http://creativecommons.org/licenses/by-sa/4.0/","  As the internet penetration rate in Africa increases, so does the
proliferation of the Internet of Things (IoT) devices. Along with this growth
in internet access is the risk of cyberattacks to vulnerable IoT devices
mushrooming in the African cyberspace. One way to determine IoT vulnerabilities
is to find open ports within Africa s cyberspace. Our research leverages Shodan
search engine, a powerful tool for discovering IoT devices facing the public
internet, to find open ports across Africa. We conduct an analysis of our
findings, ranking countries from most to least vulnerable to cyberattack. We
find that South Africa,Tunisia, Morocco, Egypt, and Nigeria are the five
countries most susceptible to cyberattack on the continent. Further, 69.8% of
devices having one of the five most commonly open internet ports have had past
documented vulnerabilities. Following our analysis, we conclude with policy
recommendations for both the public and private sector.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:00:11 GMT""}]","2023-01-10"
"2301.03009","Elijah Pelofske","Elijah Pelofske","Comparing Three Generations of D-Wave Quantum Annealers for Minor
  Embedded Combinatorial Optimization Problems",,,,"LA-UR-23-20101","quant-ph cs.ET math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum annealing is a novel type of analog computation that aims to use
quantum mechanical fluctuations to search for optimal solutions of Ising
problems. Quantum annealing in the Transverse Ising model, implemented on
D-Wave QPUs, are available as cloud computing resources. In this article we
report concise benchmarks across three generations of D-Wave quantum annealers,
consisting of four different devices, for the NP-Hard combinatorial
optimization problems unweighted maximum clique and unweighted maximum cut on
random graphs. The Ising, or equivalently QUBO, formulation of these problems
do not require auxiliary variables for order reduction, and their overall
structure and weights are not highly complex, which makes these problems simple
test cases to understand the sampling capability of current D-Wave quantum
annealers. All-to-all minor embeddings of size $52$, with relatively uniform
chain lengths, are used for a direct comparison across the Chimera, Pegasus,
and Zephyr device topologies. A grid search over annealing times and the minor
embedding chain strengths is performed in order to determine the level of
reasonable performance for each device and problem type. Experiment metrics
that are reported are approximation ratios for non-broken chain samples and
chain break proportions. How fairly the quantum annealers sample optimal
maximum cliques, for instances which contain multiple maximum cliques, is also
quantified using entropy of the measured ground state distributions. The newest
generation of quantum annealing hardware, which has a Zephyr hardware
connectivity, performed the best overall with respect to approximation ratios
and chain break frequencies.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:02:56 GMT""},{""version"":""v2"",""created"":""Fri, 20 Jan 2023 21:36:48 GMT""},{""version"":""v3"",""created"":""Thu, 20 Apr 2023 03:12:16 GMT""}]","2023-04-21"
"2301.03010","Xuyang Ning","Xuyang Ning, Abdusalam Abdukerim, Zihao Bo, Wei Chen, Xun Chen, Yunhua
  Chen, Chen Cheng, Zhaokan Cheng, Xiangyi Cui, Yingjie Fan, Deqing Fang,
  Changbo Fu, Mengting Fu, Lisheng Geng, Karl Giboni, Linhui Gu, Xuyuan Guo,
  Chencheng Han, Ke Han, Changda He, Jinrong He, Di Huang, Yanlin Huang, Zhou
  Huang, Ruquan Hou, Xiangdong Ji, Yonglin Ju, Chenxiang Li, Jiafu Li,
  Mingchuan Li, Shu Li, Shuaijie Li, Qing Lin, Jianglai Liu, Xiaoying Lu,
  Lingyin Luo, Yunyang Luo, Wenbo Ma, Yugang Ma, Yajun Mao, Yue Meng, Ningchun
  Qi, Zhicheng Qian, Xiangxiang Ren, Nasir Shaheed, Changsong Shang, Xiaofeng
  Shang, Guofang Shen, Lin Si, Wenliang Sun, Andi Tan, Yi Tao, Anqing Wang,
  Meng Wang, Qiuhong Wang, Shaobo Wang, Siguang Wang, Wei Wang, Xiuli Wang,
  Zhou Wang, Yuehuan Wei, Mengmeng Wu, Weihao Wu, Jingkai Xia, Mengjiao Xiao,
  Xiang Xiao, Pengwei Xie, Binbin Yan, Xiyu Yan, Jijun Yang, Yong Yang, Yukun
  Yao, Chunxu Yu, Jumin Yuan, Ying Yuan, Zhe Yuan, Xinning Zeng, Dan Zhang,
  Minzhen Zhang, Peng Zhang, Shibo Zhang, Shu Zhang, Tao Zhang, Yang Zhang,
  Yingxin Zhang, Yuanyuan Zhang, Li Zhao, Qibin Zheng, Jifang Zhou, Ning Zhou,
  Xiaopeng Zhou, Yong Zhou, and Yubo Zhou (for the PandaX Collaboration)
  Liangliang Su and Lei Wu","Search for light dark matter from atmosphere in PandaX-4T",,,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a sensitive search for light dark matter originating from cosmic
ray inelastic collision with the atmosphere using the PandaX-4T detector. A
full and dedicated simulation including both elastic and quasi-elastic
processes of the Earth attenuation effect on the dark matter flux arriving at
the PandaX-4T detector is performed. In the commissioning data of 0.63
tonne$\cdot$year exposure, no significant excess over background is observed.
The first constraints on the interaction between light dark matters from
atmosphere and nucleus with a light scalar mediator are obtained.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:03:18 GMT""}]","2023-01-10"
"2301.03011","Alejandro David de la Concha Duarte","Alejandro de la Concha and Argyris Kalogeratos and Nicolas Vayatis","Online Centralized Non-parametric Change-point Detection via Graph-based
  Likelihood-ratio Estimation",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider each node of a graph to be generating a data stream that is
synchronized and observed at near real-time. At a change-point $\tau$, a change
occurs at a subset of nodes $C$, which affects the probability distribution of
their associated node streams. In this paper, we propose a novel kernel-based
method to both detect $\tau$ and localize $C$, based on the direct estimation
of the likelihood-ratio between the post-change and the pre-change
distributions of the node streams. Our main working hypothesis is the
smoothness of the likelihood-ratio estimates over the graph, i.e connected
nodes are expected to have similar likelihood-ratios. The quality of the
proposed method is demonstrated on extensive experiments on synthetic
scenarios.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:15:24 GMT""},{""version"":""v2"",""created"":""Thu, 12 Jan 2023 08:51:25 GMT""}]","2023-01-13"
"2301.03012","Badr M. Abdullah","Badr M. Abdullah, Dietrich Klakow","Analyzing the Representational Geometry of Acoustic Word Embeddings","In BlackboxNLP workshop, EMNLP 2022 [ oral presentation ]",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Acoustic word embeddings (AWEs) are vector representations such that
different acoustic exemplars of the same word are projected nearby in the
embedding space. In addition to their use in speech technology applications
such as spoken term discovery and keyword spotting, AWE models have been
adopted as models of spoken-word processing in several cognitively motivated
studies and have been shown to exhibit human-like performance in some auditory
processing tasks. Nevertheless, the representational geometry of AWEs remains
an under-explored topic that has not been studied in the literature. In this
paper, we take a closer analytical look at AWEs learned from English speech and
study how the choice of the learning objective and the architecture shapes
their representational profile. To this end, we employ a set of analytic
techniques from machine learning and neuroscience in three different analyses:
embedding space uniformity, word discriminability, and representational
consistency. Our main findings highlight the prominent role of the learning
objective on shaping the representation profile compared to the model
architecture.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:22:50 GMT""}]","2023-01-10"
"2301.03013","Ritesh Chandra","Ritesh Chandra, Sadhana Tiwari, Sonali Agarwal, Navjot Singh","Semantic rule Web-based Diagnosis and Treatment of Vector-Borne Diseases
  using SWRL rules",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Vector-borne diseases (VBDs) are a kind of infection caused through the
transmission of vectors generated by the bites of infected parasites, bacteria,
and viruses, such as ticks, mosquitoes, triatomine bugs, blackflies, and
sandflies. If these diseases are not properly treated within a reasonable time
frame, the mortality rate may rise. In this work, we propose a set of
ontologies that will help in the diagnosis and treatment of vector-borne
diseases. For developing VBD's ontology, electronic health records taken from
the Indian Health Records website, text data generated from Indian government
medical mobile applications, and doctors' prescribed handwritten notes of
patients are used as input. This data is then converted into correct text using
Optical Character Recognition (OCR) and a spelling checker after
pre-processing. Natural Language Processing (NLP) is applied for entity
extraction from text data for making Resource Description Framework (RDF)
medical data with the help of the Patient Clinical Data (PCD) ontology.
Afterwards, Basic Formal Ontology (BFO), National Vector Borne Disease Control
Program (NVBDCP) guidelines, and RDF medical data are used to develop
ontologies for VBDs, and Semantic Web Rule Language (SWRL) rules are applied
for diagnosis and treatment. The developed ontology helps in the construction
of decision support systems (DSS) for the NVBDCP to control these diseases.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:32:38 GMT""},{""version"":""v2"",""created"":""Tue, 31 Jan 2023 16:36:36 GMT""}]","2023-02-01"
"2301.03014","Da Eun Kang","Da Eun Kang, Ralf S. Klessen, Victor F. Ksoll, Lynton Ardizzone,
  Ullrich Koethe and Simon C. O. Glover","Noise-Net: Determining physical properties of HII regions reflecting
  observational uncertainties","22 pages, 14 figures, Accepted for publication by MNRAS on 04.
  January",,"10.1093/mnras/stad072",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar feedback, the energetic interaction between young stars and their
birthplace, plays an important role in the star formation history of the
universe and the evolution of the interstellar medium (ISM). Correctly
interpreting the observations of star-forming regions is essential to
understand stellar feedback, but it is a non-trivial task due to the complexity
of the feedback processes and degeneracy in observations. In our recent paper,
we introduced a conditional invertible neural network (cINN) that predicts
seven physical properties of star-forming regions from the luminosity of 12
optical emission lines as a novel method to analyze degenerate observations. We
demonstrated that our network, trained on synthetic star-forming region models
produced by the WARPFIELD-Emission predictor (WARPFIELD-EMP), could predict
physical properties accurately and precisely. In this paper, we present a new
updated version of the cINN that takes into account the observational
uncertainties during network training. Our new network named Noise-Net reflects
the influence of the uncertainty on the parameter prediction by using both
emission-line luminosity and corresponding uncertainties as the necessary input
information of the network. We examine the performance of the Noise-Net as a
function of the uncertainty and compare it with the previous version of the
cINN, which does not learn uncertainties during the training. We confirm that
the Noise-Net outperforms the previous network for the typical observational
uncertainty range and maintains high accuracy even when subject to large
uncertainties.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:40:15 GMT""}]","2023-01-24"
"2301.03015","Takaki Hayashi","Takeaki Kariya, Hiroshi Kurata, Takaki Hayashi","A Modelling Framework for Regression with Collinearity",,,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study addresses a fundamental, yet overlooked, gap between standard
theory and empirical modelling practices in the OLS regression model
$\boldsymbol{y}=\boldsymbol{X\beta}+\boldsymbol{u}$ with collinearity. In fact,
while an estimated model in practice is desired to have stability and
efficiency in its ""individual OLS estimates"", $\boldsymbol{y}$ itself has no
capacity to identify and control the collinearity in $\boldsymbol{X}$ and hence
no theory including model selection process (MSP) would fill this gap unless
$\boldsymbol{X}$ is controlled in view of sampling theory. In this paper, first
introducing a new concept of ""empirically effective modelling"" (EEM), we
propose our EEM methodology (EEM-M) as an integrated process of two MSPs with
data $(\boldsymbol{y^o,X})$ given. The first MSP uses $\boldsymbol{X}$ only,
called the XMSP, and pre-selects a class $\scr{D}$ of models with individually
inefficiency-controlled and collinearity-controlled OLS estimates, where the
corresponding two controlling variables are chosen from predictive standard
error of each estimate. Next, defining an inefficiency-collinearity risk index
for each model, a partial ordering is introduced onto the set of models to
compare without using $\boldsymbol{y^o}$, where the better-ness and
admissibility of models are discussed. The second MSP is a commonly used MSP
that uses $(\boldsymbol{y^o,X})$, and evaluates total model performance as a
whole by such AIC, BIC, etc. to select an optimal model from $\scr{D}$. Third,
to materialize the XMSP, two algorithms are proposed.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:52:45 GMT""}]","2023-01-10"
"2301.03016","Philippe Grangier","Maxime Federico and Philippe Grangier","A contextually objective approach to the extended Wigner's friend
  thought experiment","8 pages, 3 figures",,,,"quant-ph physics.hist-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a discussion of the extended Wigner's friend thought experiment
proposed by Frauchiger and Renner in [1]. We show by using various arguments,
including textbook quantum mechanics and the ontological approach of Contexts,
Systems, Modalities (CSM), that no contradiction arises if one admits that
agents must agree on what is considered as a system and what is not. In such a
contextually objective approach of quantum mechanics, the apparent
contradiction is automatically removed. We also discuss why this mutual
agreement between agents is already implicit in the standard formulations of
quantum mechanics, and why removing it leads to inconsistencies.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:58:02 GMT""}]","2023-01-10"
"2301.03017","Haidong Yu","Haidong Yu, Xiaobo Quan, Haipeng Wei, Matev\v{z} Dular, Song Fu","Development of a novel nonlinear dynamic cavitation model and its
  numerical validations",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aiming at modeling the cavitation bubble cluster, we propose a novel
nonlinear dynamic cavitation model (NDCM) considering the second derivative
term in Rayleigh-Plesset equation through strict mathematical derivation. There
are two improvements of the new model: i) the empirical coefficients are
eliminated by introduction of the nonuniform potential functions of {\psi}_v
and {\psi}_c for growth and collapse processes respectively, and ii) only two
model parameters are required, which both base on physical quantities - the
Blake critical radius R_b and the average maximum growth radius R_m. The
corresponding cavitation solver was developed by using OpenFOAM in which we
implemented the modified momentum interpolation (MMI) method to ensure that the
calculated results are independent of time step size. Three validation cases,
namely numerical bubble cluster collapse, ultrasonic horn experiment, and
hydrodynamic cavitation around slender body are employed. The results indicate
that {\psi}_v and {\psi}_c can reveal the nonlinear characteristics for cavity
accurately, and R_b and R_m can reflect the relevance between cavitation model
and actual physical quantities. Moreover, it is discussed the potentiality of
NDCM that is generally applied on the cavitating flow possessing with dispersed
bubbly cloud.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:58:26 GMT""}]","2023-01-10"
"2301.03018","Waqas Aman","M. Hashim Shahab, Hasan Mujtaba Buttar, Ahsan Mehmood, Waqas Aman, M.
  Mahboob Ur Rahman, M. Wasim Nawaz, Qammer H. Abbasi","Transfer learning for non-intrusive load monitoring and appliance
  identification in a smart home",,,,,"eess.SP cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-intrusive load monitoring (NILM) or energy disaggregation is an inverse
problem whereby the goal is to extract the load profiles of individual
appliances, given an aggregate load profile of the mains of a home. NILM could
help identify the power usage patterns of individual appliances in a home, and
thus, could help realize novel energy conservation schemes for smart homes. In
this backdrop, this work proposes a novel deep-learning approach to solve the
NILM problem and a few related problems as follows. 1) We build upon the
reputed seq2-point convolutional neural network (CNN) model to come up with the
proposed seq2-[3]-point CNN model to solve the (home) NILM problem and
site-NILM problem (basically, NILM at a smaller scale). 2) We solve the related
problem of appliance identification by building upon the state-of-the-art
(pre-trained) 2D-CNN models, i.e., AlexNet, ResNet-18, and DenseNet-121, which
are trained upon two custom datasets that consist of Wavelets and short-time
Fourier transform (STFT)-based 2D electrical signatures of the appliances. 3)
Finally, we do some basic qualitative inference about an individual appliance's
health by comparing the power consumption of the same appliance across multiple
homes. Low-frequency REDD dataset is used to train and test the proposed deep
learning models for all problems, except site-NILM where REFIT dataset has been
used. As for the results, we achieve a maximum accuracy of 94.6\% for
home-NILM, 81\% for site-NILM, and 88.9\% for appliance identification (with
Resnet-based model).
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 10:59:44 GMT""}]","2023-01-10"
"2301.03019","Patrick Kr\""uger","Patrick Kr\""uger, Hanno Gottschalk","Equivariant and Steerable Neural Networks: A review with special
  emphasis on the symmetric group",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Convolutional neural networks revolutionized computer vision and natrual
language processing. Their efficiency, as compared to fully connected neural
networks, has its origin in the architecture, where convolutions reflect the
translation invariance in space and time in pattern or speech recognition
tasks. Recently, Cohen and Welling have put this in the broader perspective of
invariance under symmetry groups, which leads to the concept of group
equivaiant neural networks and more generally steerable neural networks. In
this article, we review the architecture of such networks including equivariant
layers and filter banks, activation with capsules and group pooling. We apply
this formalism to the symmetric group, for which we work out a number of
details on representations and capsules that are not found in the literature.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:05:31 GMT""}]","2023-01-10"
"2301.03020","Jinyu Guo","Jinyu Guo, Chao Xia","Stable anisotropic capillary hypersurfaces in the half-space","20 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study stability problem of anisotropic capillary
hypersurfaces in an Euclidean half-space. We prove that any compact immersed
anisotropic capillary constant anisotropic mean curvature hypersurface in the
half-space is weakly stable if and only if it is a truncated Wulff shape. On
the other hand, we prove a Bernstein-type theorem for stable anisotropic
capillary minimal surfaces in the three dimensional half-space under Euclidean
area growth assumption.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:18:50 GMT""}]","2023-01-10"
"2301.03021","Paul Sutcliffe","Paul Sutcliffe","A Skyrme model with novel chiral symmetry breaking","10 pages, 2 figures",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  An extension of the Skyrme model is presented in which derivative terms are
added that break chiral symmetry to isospin symmetry. The theory contains just
one new parameter and it reduces to the standard Skyrme model when this
symmetry breaking parameter vanishes. The same Faddeev-Bogomolny energy bound
applies for all parameter values, but the parameter can be tuned so that the
energy of the single Skyrmion is much closer to the bound than in the standard
Skyrme model. Applying the rational map approximation to multi-Skyrmions
suggests that, for a suitable value of the symmetry breaking parameter, binding
energies in this theory may be significantly more realistic than in the
standard Skyrme model.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:50:37 GMT""}]","2023-01-10"
"2301.03022","Muhammad Kashif","Muhammad Kashif, Saif Al-Kuwari","Physical Realization of Measurement Based Quantum Computation",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Harnessing quantum mechanics properties, quantum computers have the potential
to outperform classical computers in many applications and are envisioned to
affect various aspects of our society. Different approaches are being explored
for building such computers. One of such potential approaches is Measurement
based quantum computation (MBQC), introduced by Raussendorf and Briegel in
2001. In MBQC a large number of qubits are prepared in a highly entangled
clusters, called cluster states. The required quantum computation is then
performed by a sequence of measurements. Cluster states are being physically
realized using continuous variables (CV) and discrete variables (DV)
approaches. CV-based approaches can be further categorized as Frequency domain
multiplexing (FDM), Time domain multiplexing (TDM), Spatial domain multiplexing
(SDM) and hybrid. We discuss and compare these approaches in detail. We also
discuss cluster states generation in DV and report some recent results where
photons and superconducting qubits are used.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:52:38 GMT""}]","2023-01-10"
"2301.03023","Louis Soares","Louis Soares","Improved fractal Weyl bounds for convex cocompact hyperbolic surfaces
  and large resonance-free regions","32 pages, 1 figure",,,,"math.SP math.AP","http://creativecommons.org/licenses/by/4.0/","  Let $X$ be a convex cocompact hyperbolic surface and let $\delta$ be the
dimension of its limit set. Let $N_X(\sigma,T)$ be the number of resonances for
$X$ inside the box $[\sigma,\delta]+i[0,T]$. We prove that for all $\sigma >
\delta/2$ we have $$ N_X(\sigma,T) \ll_\epsilon T^{1 + \delta - \frac{3\delta
+2}{2\delta + 2} (2\sigma - \delta) + \epsilon}. $$ This improves upon previous
""improved"" fractal Weyl bounds of Naud \cite{Naud14} and Dyatlov \cite{Dya19}.
Moreover, this bound implies that there are resonance-free rectangular boxes of
arbitrary height in the strip $$ \left\{ \delta - \frac{\delta^2}{6\delta+4} <
\mathrm{Re}(s) < \delta \right\}. $$ We combine the approach of Naud
\cite{Naud14} with the refined transfer operator machinery introduced by
Dyatlov--Zworski \cite{DyZw18}, and we use a new bound for certain oscillatory
integrals that arise naturally in our analysis.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:54:51 GMT""}]","2023-01-10"
"2301.03024","Francisco Albergaria","Francisco Albergaria, Lu\'is Lavoura","Oblique corrections from leptoquarks","17 pages, 2 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present general formulas for the oblique-correction parameters $S$, $T$,
$U$, $V$, $W$, and $X$ in a model of New Physics having arbitrary numbers of
scalar leptoquarks of the five permissible types. We allow for a general mixing
among the scalars of the various electric charges, $\textit{viz.}$ $-4/3$,
$-1/3$, $2/3$, and $5/3$.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:55:47 GMT""},{""version"":""v2"",""created"":""Wed, 18 Jan 2023 14:25:57 GMT""}]","2023-01-19"
"2301.03025","Evgeny Frolov","Yuliya Tukmacheva, Ivan Oseledets, Evgeny Frolov","Mitigating Human and Computer Opinion Fraud via Contrastive Learning","15 pages, 3 figures, 1 table",,,,"cs.AI cs.HC","http://creativecommons.org/licenses/by/4.0/","  We introduce the novel approach towards fake text reviews detection in
collaborative filtering recommender systems. The existing algorithms
concentrate on detecting the fake reviews, generated by language models and
ignore the texts, written by dishonest users, mostly for monetary gains. We
propose the contrastive learning-based architecture, which utilizes the user
demographic characteristics, along with the text reviews, as the additional
evidence against fakes. This way, we are able to account for two different
types of fake reviews spamming and make the recommendation system more robust
to biased reviews.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:02:28 GMT""}]","2023-01-10"
"2301.03026","Ting Kei Pong","Xiaozhou Wang and Ting Kei Pong","Convergence rate analysis of a Dykstra-type projection algorithm",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given closed convex sets $C_i$, $i=1,\ldots,\ell$, and some nonzero linear
maps $A_i$, $i = 1,\ldots,\ell$, of suitable dimensions, the multi-set split
feasibility problem aims at finding a point in $\bigcap_{i=1}^\ell A_i^{-1}C_i$
based on computing projections onto $C_i$ and multiplications by $A_i$ and
$A_i^T$. In this paper, we consider the associated best approximation problem,
i.e., the problem of computing projections onto $\bigcap_{i=1}^\ell
A_i^{-1}C_i$; we refer to this problem as the best approximation problem in
multi-set split feasibility settings (BA-MSF). We adapt the Dykstra's
projection algorithm, which is classical for solving the BA-MSF in the special
case when all $A_i = I$, to solve the general BA-MSF. Our Dykstra-type
projection algorithm is derived by applying (proximal) coordinate gradient
descent to the Lagrange dual problem, and it only requires computing
projections onto $C_i$ and multiplications by $A_i$ and $A_i^T$ in each
iteration. Under a standard relative interior condition and a genericity
assumption on the point we need to project, we show that the dual objective
satisfies the Kurdyka-Lojasiewicz property with an explicitly computable
exponent on a neighborhood of the (typically unbounded) dual solution set when
each $C_i$ is $C^{1,\alpha}$-cone reducible for some $\alpha\in (0,1]$: this
class of sets covers the class of $C^2$-cone reducible sets, which include all
polyhedrons, second-order cone, and the cone of positive semidefinite matrices
as special cases. Using this, explicit convergence rate (linear or sublinear)
of the sequence generated by the Dykstra-type projection algorithm is derived.
Concrete examples are constructed to illustrate the necessity of some of our
assumptions.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:09:39 GMT""}]","2023-01-10"
"2301.03027","Jong Chul Ye","Gyutaek Oh, Jeong Eun Lee, and Jong Chul Ye","Annealed Score-Based Diffusion Model for MR Motion Artifact Reduction",,,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Motion artifact reduction is one of the important research topics in MR
imaging, as the motion artifact degrades image quality and makes diagnosis
difficult. Recently, many deep learning approaches have been studied for motion
artifact reduction. Unfortunately, most existing models are trained in a
supervised manner, requiring paired motion-corrupted and motion-free images, or
are based on a strict motion-corruption model, which limits their use for
real-world situations. To address this issue, here we present an annealed
score-based diffusion model for MRI motion artifact reduction. Specifically, we
train a score-based model using only motion-free images, and then motion
artifacts are removed by applying forward and reverse diffusion processes
repeatedly to gradually impose a low-frequency data consistency. Experimental
results verify that the proposed method successfully reduces both simulated and
in vivo motion artifacts, outperforming the state-of-the-art deep learning
methods.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:16:08 GMT""}]","2023-01-10"
"2301.03028","Xinjiang Lu","Yan Li, Xinjiang Lu, Yaqing Wang, Dejing Dou","Generative Time Series Forecasting with Diffusion, Denoise, and
  Disentanglement",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Time series forecasting has been a widely explored task of great importance
in many applications. However, it is common that real-world time series data
are recorded in a short time period, which results in a big gap between the
deep model and the limited and noisy time series. In this work, we propose to
address the time series forecasting problem with generative modeling and
propose a bidirectional variational auto-encoder (BVAE) equipped with
diffusion, denoise, and disentanglement, namely D3VAE. Specifically, a coupled
diffusion probabilistic model is proposed to augment the time series data
without increasing the aleatoric uncertainty and implement a more tractable
inference process with BVAE. To ensure the generated series move toward the
true target, we further propose to adapt and integrate the multiscale denoising
score matching into the diffusion process for time series forecasting. In
addition, to enhance the interpretability and stability of the prediction, we
treat the latent variable in a multivariate manner and disentangle them on top
of minimizing total correlation. Extensive experiments on synthetic and
real-world data show that D3VAE outperforms competitive algorithms with
remarkable margins. Our implementation is available at
https://github.com/PaddlePaddle/PaddleSpatial/tree/main/research/D3VAE.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:20:46 GMT""}]","2023-01-10"
"2301.03029","Lifeng Han","Bernadeta Grici\=ut\.e and Lifeng Han and Goran Nenadic","Topic Modelling of Swedish Newspaper Articles about Coronavirus: a Case
  Study using Latent Dirichlet Allocation Method","Accepted to International HealthNLP WS @ IEEE-ICHI2023
  https://ieeeichi.github.io/ICHI2023/",,,,"cs.CL cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Topic Modelling (TM) is from the research branches of natural language
understanding (NLU) and natural language processing (NLP) that is to facilitate
insightful analysis from large documents and datasets, such as a summarisation
of main topics and the topic changes. This kind of discovery is getting more
popular in real-life applications due to its impact on big data analytics. In
this study, from the social-media and healthcare domain, we apply popular
Latent Dirichlet Allocation (LDA) methods to model the topic changes in Swedish
newspaper articles about Coronavirus. We describe the corpus we created
including 6515 articles, methods applied, and statistics on topic changes over
approximately 1 year and two months period of time from 17th January 2020 to
13th March 2021. We hope this work can be an asset for grounding applications
of topic modelling and can be inspiring for similar case studies in an era with
pandemics, to support socio-economic impact research as well as clinical and
healthcare analytics. Our data and source code are openly available at
https://github. com/poethan/Swed_Covid_TM Keywords: Latent Dirichlet Allocation
(LDA); Topic Modelling; Coronavirus; Pandemics; Natural Language Understanding;
BERT-topic
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:33:58 GMT""},{""version"":""v2"",""created"":""Tue, 17 Jan 2023 22:00:52 GMT""},{""version"":""v3"",""created"":""Sat, 4 Feb 2023 22:45:20 GMT""},{""version"":""v4"",""created"":""Fri, 17 Feb 2023 16:47:27 GMT""},{""version"":""v5"",""created"":""Fri, 10 Mar 2023 11:38:05 GMT""},{""version"":""v6"",""created"":""Tue, 18 Apr 2023 16:43:11 GMT""}]","2023-04-19"
"2301.03030","Shenghong Ju","Xiang Huang, Shengluo Ma, C. Y. Zhao, Hong Wang, and Shenghong Ju","Exploring high thermal conductivity polymers via interpretable machine
  learning with physical descriptors",,,,,"cond-mat.mtrl-sci cond-mat.soft physics.app-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The efficient and economical exploitation of polymers with high thermal
conductivity is essential to solve the issue of heat dissipation in organic
devices. Currently, the experimental preparation of functional thermal
conductivity polymers remains a trial and error process due to the
multi-degrees of freedom during the synthesis and characterization process. In
this work, we have proposed a high-throughput screening framework for polymer
chains with high thermal conductivity via interpretable machine learning and
physical-feature engineering. The polymer thermal conductivity datasets for
training were first collected by molecular dynamics simulation. Inspired by the
drug-like small molecule representation and molecular force field, 320 polymer
monomer descriptors were calculated and the 20 optimized descriptors with
physical meaning were extracted by hierarchical down-selection. All the machine
learning models achieve a prediction accuracy R2 greater than 0.80, which is
superior to that of represented by traditional graph descriptors. Further, the
cross-sectional area and dihedral stiffness descriptors were identified for
positive/negative contribution to thermal conductivity, and 107 promising
polymer structures with thermal conductivity greater than 20.00 W/mK were
obtained. Mathematical formulas for predicting the polymer thermal conductivity
were also constructed by using symbolic regression. The high thermal
conductivity polymer structures are mostly {\pi}-conjugated, whose overlapping
p-orbitals enable easily to maintain strong chain stiffness and large group
velocities. The proposed data-driven framework should facilitate the
theoretical and experimental design of polymers with desirable properties.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:37:43 GMT""}]","2023-01-10"
"2301.03031","Yuta Sekino","Yuta Sekino, Hiroyuki Tajima, Shun Uchino","Spin conductivity spectrum and spin superfluidity in a binary Bose
  mixture","13 pages, 4 figures","Phys. Rev. Research 5, 023058 (2023)","10.1103/PhysRevResearch.5.023058","RIKEN-iTHEMS-Report-23","cond-mat.quant-gas cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.stat-mech cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the spectrum of spin conductivity for a miscible two-component
Bose-Einstein condensate (BEC) that exhibits spin superfluidity. By using the
Bogoliubov theory, the regular part being the spin conductivity at finite ac
frequency and the spin Drude weight characterizing the delta-function peak at
zero frequency are analytically computed. We demonstrate that the spectrum
exhibits a power-law behavior at low frequency, reflecting gapless density and
spin modes specific to the binary BEC. At the phase transition points into
immiscible and quantum-droplet states, the change in quasiparticle dispersion
relations modifies the power law. In addition, the spin Drude weight becomes
finite, indicating zero spin resistivity due to spin superfluidity. Our results
also suggest that the Andreev-Bashkin drag density is accessible by measuring
the spin conductivity spectrum.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:45:15 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 05:44:55 GMT""}]","2023-04-28"
"2301.03032","Zhen Su","Zhen Su, J\""urgen Kurths, Henning Meyerhenke","Network Sparsification via Degree- and Subgraph-based Edge Sampling","8 pages, 10 figures, to be published in IEEE/ACM International
  Conference on Advances in Social Networks Analysis and Mining, 2022 (ASONAM
  2022)",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  Network (or graph) sparsification compresses a graph by removing inessential
edges. By reducing the data volume, it accelerates or even facilitates many
downstream analyses. Still, the accuracy of many sparsification methods, with
filtering-based edge sampling being the most typical one, heavily relies on an
appropriate definition of edge importance. Instead, we propose a different
perspective with a generalized local-property-based sampling method, which
preserves (scaled) local \emph{node} characteristics. Apart from degrees, these
local node characteristics we use are the expected (scaled) number of wedges
and triangles a node belongs to. Through such a preservation, main complex
structural properties are preserved implicitly. We adapt a game-theoretic
framework from uncertain graph sampling by including a threshold for faster
convergence (at least $4$ times faster empirically) to approximate solutions.
Extensive experimental studies on functional climate networks show the
effectiveness of this method in preserving macroscopic to mesoscopic and
microscopic network structural properties.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:56:17 GMT""},{""version"":""v2"",""created"":""Tue, 10 Jan 2023 08:35:37 GMT""}]","2023-01-11"
"2301.03033","Zhengyi Liu","Zhengyi Liu, Wei Wu, Yacheng Tan, Guanghui Zhang","RGB-T Multi-Modal Crowd Counting Based on Transformer",,"BMVC2022",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crowd counting aims to estimate the number of persons in a scene. Most
state-of-the-art crowd counting methods based on color images can't work well
in poor illumination conditions due to invisible objects. With the widespread
use of infrared cameras, crowd counting based on color and thermal images is
studied. Existing methods only achieve multi-modal fusion without count
objective constraint. To better excavate multi-modal information, we use
count-guided multi-modal fusion and modal-guided count enhancement to achieve
the impressive performance. The proposed count-guided multi-modal fusion module
utilizes a multi-scale token transformer to interact two-modal information
under the guidance of count information and perceive different scales from the
token perspective. The proposed modal-guided count enhancement module employs
multi-scale deformable transformer decoder structure to enhance one modality
feature and count information by the other modality. Experiment in public
RGBT-CC dataset shows that our method refreshes the state-of-the-art results.
https://github.com/liuzywen/RGBTCC
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:59:52 GMT""}]","2023-01-10"
"2301.03034","Matt Fleming","Matt Fleming, Piotr Ko{\l}aczkowski, Ishita Kumar, Shaunak Das, Sean
  McCarthy, Pushkala Pattabhiraman, Henrik Ingo","Hunter: Using Change Point Detection to Hunt for Performance Regressions",,,,,"cs.DB cs.SE","http://creativecommons.org/licenses/by/4.0/","  Change point detection has recently gained popularity as a method of
detecting performance changes in software due to its ability to cope with noisy
data. In this paper we present Hunter, an open source tool that automatically
detects performance regressions and improvements in time-series data. Hunter
uses a modified E-divisive means algorithm to identify statistically
significant changes in normally-distributed performance metrics. We describe
the changes we made to the E-divisive means algorithm along with their
motivation. The main change we adopted was to replace the significance test
using randomized permutations with a Student's t-test, as we discovered that
the randomized approach did not produce deterministic results, at least not
with a reasonable number of iterations. In addition we've made tweaks that
allow us to find change points the original algorithm would not, such as two
nearby changes. For evaluation, we developed a method to generate real
timeseries, but with artificially injected changes in latency. We used these
data sets to compare Hunter against two other well known algorithms, PELT and
DYNP. Finally, we conclude with lessons we've learned supporting Hunter across
teams with individual responsibility for the performance of their project.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:02:29 GMT""}]","2023-01-10"
"2301.03035","Yuhang Chen","Chong Han, Yuhang Chen, Longfei Yan, Zhi Chen, Linglong Dai","Cross Far- and Near-field Wireless Communications in Terahertz
  Ultra-large Antenna Array Systems",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terahertz (THz) band owning the abundant multi-ten-GHz bandwidth is capable
to support Terabit-per-second wireless communications, which is a pillar
technology for 6G and beyond systems. With sub-millimeter-long antennas,
ultra-massive (UM) MIMO and intelligent surface (IS) systems with thousands of
array elements are exploited to effectively combat the distance limitation and
blockage problems, which compose a promising THz ultra-large antenna array
(ULAA) system. As a combined effect of wavelength and array aperture, the
resulting coverage of THz systems ranges from near-field to far-field, leading
to a new paradigm of cross-field communications. Although channel models,
communications theories, and networking strategies have been studied for
far-field and near-field separately, the unified design of cross-field
communications that achieve high spectral efficiency and low complexity is
still missing. In this article, the challenges and features of THz ULAA
cross-field communications are investigated. Furthermore, cross-field solutions
in three perspectives are presented, including a hybrid spherical- and
planar-wave channel model, cross-field channel estimation, and widely-spaced
multi-subarray hybrid beamforming, where a subarray as a basic unit in THz ULAA
systems is exploited. The approximation error of channel modeling accuracy,
spectral efficiency, and estimation error of these designs are numerically
evaluated. Finally, as a roadmap of THz ULAA cross-field communications,
multiple open problems and potential research directions are elaborated.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:05:25 GMT""}]","2023-01-10"
"2301.03036","Zhengyi Liu","Bin Tang, Zhengyi Liu, Yacheng Tan, and Qian He","HRTransNet: HRFormer-Driven Two-Modality Salient Object Detection",,"TCSVT2022","10.1109/TCSVT.2022.3202563",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The High-Resolution Transformer (HRFormer) can maintain high-resolution
representation and share global receptive fields. It is friendly towards
salient object detection (SOD) in which the input and output have the same
resolution. However, two critical problems need to be solved for two-modality
SOD. One problem is two-modality fusion. The other problem is the HRFormer
output's fusion. To address the first problem, a supplementary modality is
injected into the primary modality by using global optimization and an
attention mechanism to select and purify the modality at the input level. To
solve the second problem, a dual-direction short connection fusion module is
used to optimize the output features of HRFormer, thereby enhancing the
detailed representation of objects at the output level. The proposed model,
named HRTransNet, first introduces an auxiliary stream for feature extraction
of supplementary modality. Then, features are injected into the primary
modality at the beginning of each multi-resolution branch. Next, HRFormer is
applied to achieve forwarding propagation. Finally, all the output features
with different resolutions are aggregated by intra-feature and inter-feature
interactive transformers. Application of the proposed model results in
impressive improvement for driving two-modality SOD tasks, e.g., RGB-D, RGB-T,
and light field SOD.https://github.com/liuzywen/HRTransNet
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:09:01 GMT""}]","2023-01-25"
"2301.03037","Botao Fu","Hongbo Wu, Da-Shuai Ma, and Botao Fu","Hybrid Nodal-chain Semimetal State in MgCaN2","9 pages, 6 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The distinct over-tilting of band crossings in topological semimetal
generates the type-I and typeII classification of Dirac/Weyl and nodal-line
fermions, accompanied by the exotic electronic and magnetic transport
properties. In this work, we propose a concept of hybrid nodal-chain semimetal,
which is identified by the linked type-I and type-II nodal rings in the
Brillouin zone. Based on first-principles calculations and swarm-intelligence
structure search technique, a new ternary nitride MgCaN2 crystal is proposed as
the first candidate to realize a novel 3D hybrid nodal-chain state. Remarkably,
a flat band is emergent as a characteristic signature of such a hybrid
nodal-chain along certain direction in the momentum space, thereby serving a
platform to explore the interplay between topological semimetal state and flat
band. Moreover, the underlying protection mechanism of the hybrid nodal-chain
is revealed by calculating the mirror Z2 invariant and developing a k.p
effective Hamiltonian. Additionally, considerable drumhead-like surface states
with unique connection patterns are illustrated to identify the non-trivial
band topology, which may be measured by future experiments.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:12:43 GMT""}]","2023-01-10"
"2301.03038","Daniele Durante","Daniele Durante, Francesco Pozza, Botond Szabo","Skewed Bernstein-von Mises theorem and skew-modal approximations",,,,,"math.ST stat.CO stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deterministic Gaussian approximations of intractable posterior distributions
are common in Bayesian inference. From an asymptotic perspective, a theoretical
justification in regular parametric settings is provided by the Bernstein-von
Mises theorem. However, such a limiting behavior may require a large sample
size before becoming visible in practice. In fact, in situations with
small-to-moderate sample size, even simple parametric models often yield
posterior distributions which are far from resembling a Gaussian shape, mainly
due to skewness. In this article, we provide rigorous theoretical arguments for
such a behavior by deriving a novel limiting law that coincides with a
closed-form and tractable skewed generalization of Gaussian densities, and
yields a total variation distance from the exact posterior whose convergence
rate crucially improves by a $\sqrt{n}$ factor the one obtained under the
classical Bernstein-von Mises theorem based on limiting Gaussians. In contrast
to higher-order approximations (which require finite truncations for inference,
possibly leading to even negative densities), our theory characterizes the
limiting behavior of Bayesian posteriors with respect to a sequence of valid
and tractable densities. This further motivates a practical plug-in version
which replaces the unknown model parameters with the corresponding MAP estimate
to obtain a novel skew-modal approximation achieving the same improved rate of
convergence of its population counterpart. Extensive quantitative studies
confirm that our new theory closely matches the empirical behavior observed in
practice even in finite, possibly small, sample regimes. The proposed
skew-modal approximation further exhibits improved accuracy not only relative
to classical Laplace approximation, but also with respect to state-of-the-art
approximations from mean-field variational Bayes and expectation-propagation.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:13:48 GMT""}]","2023-01-10"
"2301.03039","Hsin-Yi Chen","Cheng-Yen Hsu, Hsin-Yi Chen and Jen-Hui Chuang","Equivalence of Two Expressions of Principal Line","5 pages, 3 figures, 47 equations",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geometry-based camera calibration using principal line is more precise and
robust than calibration using optimization approaches; therefore, several
researches try to re-derive the principal line from different views of 2D
projective geometry to increase alternatives of the calibration process. In
this report, algebraical equivalence of two expressions of principal line, one
derived w.r.t homography and the other using for two sets of orthogonal
vanishing points, is proved. Moreover, the extension of the second expression
to incorporate infinite vanishing point is carried out with simple mathematics.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:17:49 GMT""}]","2023-01-10"
"2301.03040","Ashwin Agrawal","Ashwin Agrawal, Robert Thiel, Pooja Jain, Vishal Singh, Martin Fischer","Digital Twin: Where do humans fit in?","Accepted for publication in Automation in Construction",,,,"cs.HC cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Digital Twin (DT) technology is far from being comprehensive and mature,
resulting in their piecemeal implementation in practice where some functions
are automated by DTs, and others are still performed by humans. This piecemeal
implementation of DTs often leaves practitioners wondering what roles (or
functions) to allocate to DTs in a work system, and how might it impact humans.
A lack of knowledge about the roles that humans and DTs play in a work system
can result in significant costs, misallocation of resources, unrealistic
expectations from DTs, and strategic misalignments. To alleviate this
challenge, this paper answers the research question: When humans work with DTs,
what types of roles can a DT play, and to what extent can those roles be
automated? Specifically, we propose a two-dimensional conceptual framework,
Levels of Digital Twin (LoDT). The framework is an integration of the types of
roles a DT can play, broadly categorized under (1) Observer, (2) Analyst, (3)
Decision Maker, and (4) Action Executor, and the extent of automation for each
of these roles, divided into five different levels ranging from completely
manual to fully automated. A particular DT can play any number of roles at
varying levels. The framework can help practitioners systematically plan DT
deployments, clearly communicate goals and deliverables, and lay out a
strategic vision. A case study illustrates the usefulness of the framework.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:25:30 GMT""}]","2023-01-10"
"2301.03041","Jie Gui","Jidong Ge, Yuxiang Liu, Jie Gui, Lanting Fang, Ming Lin, James Tin-Yau
  Kwok, LiGuo Huang, Bin Luo","Learning the Relation between Similarity Loss and Clustering Loss in
  Self-Supervised Learning","This paper is accepted by IEEE Transactions on Image Processing",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning enables networks to learn discriminative features
from massive data itself. Most state-of-the-art methods maximize the similarity
between two augmentations of one image based on contrastive learning. By
utilizing the consistency of two augmentations, the burden of manual
annotations can be freed. Contrastive learning exploits instance-level
information to learn robust features. However, the learned information is
probably confined to different views of the same instance. In this paper, we
attempt to leverage the similarity between two distinct images to boost
representation in self-supervised learning. In contrast to instance-level
information, the similarity between two distinct images may provide more useful
information. Besides, we analyze the relation between similarity loss and
feature-level cross-entropy loss. These two losses are essential for most deep
learning methods. However, the relation between these two losses is not clear.
Similarity loss helps obtain instance-level representation, while feature-level
cross-entropy loss helps mine the similarity between two distinct images. We
provide theoretical analyses and experiments to show that a suitable
combination of these two losses can get state-of-the-art results. Code is
available at https://github.com/guijiejie/ICCL.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:30:39 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 11:58:22 GMT""}]","2023-06-06"
"2301.03042","Peng-Bi Cui","Peng-Bi Cui","Exploring the foundation of social diversity and coherence with a novel
  attraction-repulsion model framework","21 pages, 19 figures",,"10.1016/j.physa.2023.128714",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One widely-existed state --``harmony with diversity"" in which individuals
freely express various viewpoints to sustain integration of social diversity,
but at the same time shared values ensure social coherence, can be considered
as the foundation of social diversity and coherence, however, which has never
attracted research attention. Its formation mechanism still remains unclear. To
address this issue, this study proposes an attraction-repulsion model based on
the general simple assumption that individuals tend to either reach an
agreement with shared opinions or to amplify difference from others with
distant opinions. It allows us to take account into the three core parameters:
interaction strength, individuals' susceptibility and tolerance to others'
opinions. We are concerned with the effect of not only time-varying topology
but also fixed interactions imposed by static social network, where the tasks
of heterogeneous individuals' attributes are also performed. Remarkably, the
simple model rules successfully generate the three above phases except for
fragmentation, along with three different transitions and the triple points. We
find that sufficient susceptibility, intermediate interaction strength and high
tolerance can benefit a balance between repulsive and attractive forces, and
thus the emergence of ""harmony with diversity"". However, fixed interactions can
introduce cluster-level self-reinforced mechanism which can unexpectedly
promote polarization. Heterogeneous susceptibility or tolerance turns out to be
an inhibiting factor, which should be avoided. A method to identify the phase
boundaries through computing the maximum susceptibility of entropy and stand
deviation of opinions, confirmed by numerical simulations, allows us to build
phase diagrams and to locate where the triple points are.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:34:31 GMT""},{""version"":""v2"",""created"":""Wed, 11 Jan 2023 04:24:19 GMT""},{""version"":""v3"",""created"":""Thu, 12 Jan 2023 06:57:31 GMT""},{""version"":""v4"",""created"":""Mon, 27 Mar 2023 02:28:58 GMT""}]","2023-04-26"
"2301.03043","Andreas Kontogiannis","Andreas Kontogiannis and George Vouros","XDQN: Inherently Interpretable DQN through Mimicking",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Although deep reinforcement learning (DRL) methods have been successfully
applied in challenging tasks, their application in real-world operational
settings is challenged by methods' limited ability to provide explanations.
Among the paradigms for explainability in DRL is the interpretable box design
paradigm, where interpretable models substitute inner constituent models of the
DRL method, thus making the DRL method ""inherently"" interpretable. In this
paper we explore this paradigm and we propose XDQN, an explainable variation of
DQN, which uses an interpretable policy model trained through mimicking. XDQN
is challenged in a complex, real-world operational multi-agent problem, where
agents are independent learners solving congestion problems. Specifically, XDQN
is evaluated in three MARL scenarios, pertaining to the demand-capacity
balancing problem of air traffic management. XDQN achieves performance similar
to that of DQN, while its abilities to provide global models' interpretations
and interpretations of local decisions are demonstrated.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 13:39:58 GMT""}]","2023-01-10"
"2301.03044","Wenzhe Li","Wenzhe Li, Hao Luo, Zichuan Lin, Chongjie Zhang, Zongqing Lu, Deheng
  Ye","A Survey on Transformers in Reinforcement Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer has been considered the dominating neural architecture in NLP and
CV, mostly under a supervised setting. Recently, a similar surge of using
Transformers has appeared in the domain of reinforcement learning (RL), but it
is faced with unique design choices and challenges brought by the nature of RL.
However, the evolution of Transformers in RL has not yet been well unraveled.
Hence, in this paper, we seek to systematically review motivations and progress
on using Transformers in RL, provide a taxonomy on existing works, discuss each
sub-field, and summarize future prospects.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:04:26 GMT""}]","2023-01-10"
"2301.03045","Jo\~ao Ribeiro Pinto","Jo\~ao Ribeiro Pinto","Seamless Multimodal Biometrics for Continuous Personalised Wellbeing
  Monitoring","Doctoral thesis presented and approved on the 21st of December 2022
  to the University of Porto",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificially intelligent perception is increasingly present in the lives of
every one of us. Vehicles are no exception, (...) In the near future, pattern
recognition will have an even stronger role in vehicles, as self-driving cars
will require automated ways to understand what is happening around (and within)
them and act accordingly. (...) This doctoral work focused on advancing
in-vehicle sensing through the research of novel computer vision and pattern
recognition methodologies for both biometrics and wellbeing monitoring. The
main focus has been on electrocardiogram (ECG) biometrics, a trait well-known
for its potential for seamless driver monitoring. Major efforts were devoted to
achieving improved performance in identification and identity verification in
off-the-person scenarios, well-known for increased noise and variability. Here,
end-to-end deep learning ECG biometric solutions were proposed and important
topics were addressed such as cross-database and long-term performance,
waveform relevance through explainability, and interlead conversion. Face
biometrics, a natural complement to the ECG in seamless unconstrained
scenarios, was also studied in this work. The open challenges of masked face
recognition and interpretability in biometrics were tackled in an effort to
evolve towards algorithms that are more transparent, trustworthy, and robust to
significant occlusions. Within the topic of wellbeing monitoring, improved
solutions to multimodal emotion recognition in groups of people and
activity/violence recognition in in-vehicle scenarios were proposed. At last,
we also proposed a novel way to learn template security within end-to-end
models, dismissing additional separate encryption processes, and a
self-supervised learning approach tailored to sequential data, in order to
ensure data security and optimal performance. (...)
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:07:01 GMT""},{""version"":""v2"",""created"":""Thu, 19 Jan 2023 22:29:35 GMT""}]","2023-01-23"
"2301.03046","Ming Li","Ming Li, Xiangyu Xu, Hehe Fan, Pan Zhou, Jun Liu, Jia-Wei Liu, Jiahe
  Li, Jussi Keppo, Mike Zheng Shou and Shuicheng Yan","STPrivacy: Spatio-Temporal Privacy-Preserving Action Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing methods of privacy-preserving action recognition (PPAR) mainly focus
on frame-level (spatial) privacy removal through 2D CNNs. Unfortunately, they
have two major drawbacks. First, they may compromise temporal dynamics in input
videos, which are critical for accurate action recognition. Second, they are
vulnerable to practical attacking scenarios where attackers probe for privacy
from an entire video rather than individual frames. To address these issues, we
propose a novel framework STPrivacy to perform video-level PPAR. For the first
time, we introduce vision Transformers into PPAR by treating a video as a
tubelet sequence, and accordingly design two complementary mechanisms, i.e.,
sparsification and anonymization, to remove privacy from a spatio-temporal
perspective. In specific, our privacy sparsification mechanism applies adaptive
token selection to abandon action-irrelevant tubelets. Then, our anonymization
mechanism implicitly manipulates the remaining action-tubelets to erase privacy
in the embedding space through adversarial learning. These mechanisms provide
significant advantages in terms of privacy preservation for human eyes and
action-privacy trade-off adjustment during deployment. We additionally
contribute the first two large-scale PPAR benchmarks, VP-HMDB51 and VP-UCF101,
to the community. Extensive evaluations on them, as well as two other tasks,
validate the effectiveness and generalization capability of our framework.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:07:54 GMT""},{""version"":""v2"",""created"":""Sun, 12 Mar 2023 00:12:23 GMT""}]","2023-03-14"
"2301.03047","Liheng Bian","Daoyu Li, Hanwen Xu, Miao Cao, Xin Yuan, David J. Brady, and Liheng
  Bian","Large-scale Global Low-rank Optimization for Computational Compressed
  Imaging",,,,,"eess.IV cs.CV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational reconstruction plays a vital role in computer vision and
computational photography. Most of the conventional optimization and deep
learning techniques explore local information for reconstruction. Recently,
nonlocal low-rank (NLR) reconstruction has achieved remarkable success in
improving accuracy and generalization. However, the computational cost has
inhibited NLR from seeking global structural similarity, which consequentially
keeps it trapped in the tradeoff between accuracy and efficiency and prevents
it from high-dimensional large-scale tasks. To address this challenge, we
report here the global low-rank (GLR) optimization technique, realizing
highly-efficient large-scale reconstruction with global self-similarity.
Inspired by the self-attention mechanism in deep learning, GLR extracts
exemplar image patches by feature detection instead of conventional uniform
selection. This directly produces key patches using structural features to
avoid burdensome computational redundancy. Further, it performs patch matching
across the entire image via neural-based convolution, which produces the global
similarity heat map in parallel, rather than conventional sequential block-wise
matching. As such, GLR improves patch grouping efficiency by more than one
order of magnitude. We experimentally demonstrate GLR's effectiveness on
temporal, frequency, and spectral dimensions, including different computational
imaging modalities of compressive temporal imaging, magnetic resonance imaging,
and multispectral filter array demosaicing. This work presents the superiority
of inherent fusion of deep learning strategies and iterative optimization, and
breaks the persistent dilemma of the tradeoff between accuracy and efficiency
for various large-scale reconstruction tasks.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:12:51 GMT""}]","2023-01-10"
"2301.03048","Gerhard Tutz","Gerhard Tutz","Invariance of Comparisons: Separation of Item and Person Parameters
  beyond Rasch Models",,,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Rasch model is the most prominent member of the class of latent trait
models that are in common use. The main reason is that it can be considered as
a measurement model that allows to separate person and item parameters, a
feature that is referred to as invariance of comparisons or specific
objectivity. It is shown that the property is not an exclusive trait of Rasch
type models but is also found in alternative latent trait models. It is
distinguished between separability in the theoretical measurement model and
empirical separability with empirical separability meaning that parameters can
be estimated without reference to the other group of parameters. A new type of
pairwise estimator with this property is proposed that can be used also in
alternative models. Separability is considered in binary models as well as in
polytomous models.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:30:14 GMT""}]","2023-01-10"
"2301.03049","Zhennan Zhu","Guanghui Zhu, Zhennan Zhu, Wenjie Wang, Zhuoer Xu, Chunfeng Yuan,
  Yihua Huang","AutoAC: Towards Automated Attribute Completion for Heterogeneous Graph
  Neural Network",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many real-world data can be modeled as heterogeneous graphs that contain
multiple types of nodes and edges. Meanwhile, due to excellent performance,
heterogeneous graph neural networks (GNNs) have received more and more
attention. However, the existing work mainly focuses on the design of novel GNN
models, while ignoring another important issue that also has a large impact on
the model performance, namely the missing attributes of some node types. The
handcrafted attribute completion requires huge expert experience and domain
knowledge. Also, considering the differences in semantic characteristics
between nodes, the attribute completion should be fine-grained, i.e., the
attribute completion operation should be node-specific. Moreover, to improve
the performance of the downstream graph learning task, attribute completion and
the training of the heterogeneous GNN should be jointly optimized rather than
viewed as two separate processes. To address the above challenges, we propose a
differentiable attribute completion framework called AutoAC for automated
completion operation search in heterogeneous GNNs. We first propose an
expressive completion operation search space, including topology-dependent and
topology-independent completion operations. Then, we propose a continuous
relaxation schema and further propose a differentiable completion algorithm
where the completion operation search is formulated as a bi-level joint
optimization problem. To improve the search efficiency, we leverage two
optimization techniques: discrete constraints and auxiliary unsupervised graph
node clustering. Extensive experimental results on real-world datasets reveal
that AutoAC outperforms the SOTA handcrafted heterogeneous GNNs and the
existing attribute completion method
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:38:32 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 12:31:18 GMT""}]","2023-02-21"
"2301.03050","Benne de Weger","Benne de Weger","A lot of fudge around A + B = C",,,,,"math.NT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper reports on experiments searching for elliptic curves over Q with
large Tamagawa products. The main idea is to look among curves related to good
abc-triples.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:47:11 GMT""}]","2023-01-10"
"2301.03051","Ana Agore","A.L. Agore","Functors between representation categories. Universal modules","Continues arXiv:2006.00711",,,,"math.RA math.CT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathfrak{g}$ and $\mathfrak{h}$ be two Lie algebras with $\mathfrak{h}$
finite dimensional and consider ${\mathcal A} = {\mathcal A} (\mathfrak{h}, \,
\mathfrak{g})$ to be the corresponding universal algebra as introduced in
\cite{am20}. Given an ${\mathcal A}$-module $U$ and a Lie $\mathfrak{h}$-module
$V$ we show that $U \otimes V$ can be naturally endowed with a Lie
$\mathfrak{g}$-module structure. This gives rise to a functor between the
category of Lie $\mathfrak{h}$-modules and the category of Lie
$\mathfrak{g}$-modules and, respectively, to a functor between the category of
${\mathcal A}$-modules and the category of Lie $\mathfrak{g}$-modules. Under
some finite dimensionality assumptions, we prove that the two functors admit
left adjoints which leads to the construction of universal ${\mathcal
A}$-modules and universal Lie $\mathfrak{h}$-modules as the representation
theoretic counterparts of Manin-Tambara's universal coacting objects
\cite{Manin, Tambara}.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 14:52:09 GMT""},{""version"":""v2"",""created"":""Fri, 20 Jan 2023 08:40:41 GMT""}]","2023-01-23"
"2301.03052","Pin-Yu Chen","Pin-Yu Chen and Payel Das","AI Maintenance: A Robustness Perspective","Accepted to IEEE Computer Magazine. To be published in 2023",,,,"cs.LG cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the advancements in machine learning (ML) methods and compute resources,
artificial intelligence (AI) empowered systems are becoming a prevailing
technology. However, current AI technology such as deep learning is not
flawless. The significantly increased model complexity and data scale incur
intensified challenges when lacking trustworthiness and transparency, which
could create new risks and negative impacts. In this paper, we carve out AI
maintenance from the robustness perspective. We start by introducing some
highlighted robustness challenges in the AI lifecycle and motivating AI
maintenance by making analogies to car maintenance. We then propose an AI model
inspection framework to detect and mitigate robustness risks. We also draw
inspiration from vehicle autonomy to define the levels of AI robustness
automation. Our proposal for AI maintenance facilitates robustness assessment,
status tracking, risk scanning, model hardening, and regulation throughout the
AI lifecycle, which is an essential milestone toward building sustainable and
trustworthy AI ecosystems.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:02:38 GMT""}]","2023-01-10"
"2301.03053","Xingchen Ji","Xingchen Ji, Yoshitomo Okawachi, Andres Gil-Molina, Mateus
  Corato-Zanarella, Samantha Roberts, Alexander L. Gaeta and Michal Lipson","Ultra-Low-Loss Silicon Nitride Photonics Based on Deposited Films
  Compatible with Foundries",,"Laser & Photonics Reviews (2022)","10.1002/lpor.202200544",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The fabrication processes of silicon nitride photonic devices used in
foundries require low temperature deposition, which typically leads to high
propagation losses. Here, we show that propagation loss as low as 0.42 dB/cm
can be achieved using foundry compatible processes by solely reducing waveguide
surface roughness. By post-processing the fabricated devices using rapid
thermal anneal (RTA) and furnace anneal, we achieve propagation losses down to
0.28 dB/cm and 0.06 dB/cm, respectively. These low losses are comparable to the
conventional devices using high temperature, high-stress low-pressure chemical
vapor deposition (LPCVD) films. We also tune the dispersion of the devices, and
proved that these devices can be used for linear and nonlinear applications.
Low threshold parametric oscillation, broadband frequency combs and
narrow-linewidth laser are demonstrated. Our work demonstrates the feasibility
of scalable photonic systems based on foundries.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:07:34 GMT""}]","2023-01-10"
"2301.03054","Zi Cai","Mingxi Yue and Zi Cai","Prethermal time-crystalline spin ice and monopole confinement in a
  driven magnet","6 pages",,,,"cond-mat.str-el cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Studies on systems far from equilibrium open up new avenues for investigating
exotic phases of matter. A driven-dissipative frustrated spin system is
examined in this study, and we suggest an out-of-equilibrium non-magnetic phase
where the spins do not order but adhere to the ice rule in space and establish
a long-range crystalline order in time. In contrast to the conventional spin
ice, the dynamics of monopoles is confined due to the nonequilibrium feature of
our model. Possible experimental realizations of our model has been discussed.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:11:19 GMT""},{""version"":""v2"",""created"":""Wed, 19 Apr 2023 08:51:38 GMT""}]","2023-04-20"
"2301.03055","Mario B. Schulz","Alessandro Carlotto, Mario B. Schulz, David Wiygul","Spectral estimates for free boundary minimal surfaces via Montiel-Ros
  partitioning methods","55 pages, 6 figures",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We adapt and extend the Montiel-Ros methodology to compact manifolds with
boundary, allowing for mixed (including oblique) boundary conditions and also
accounting for the action of a finite group $G$ together with an additional
twisting homomorphism $\sigma\colon G\to\operatorname O(1)$. We then apply this
machinery in order to obtain quantitative lower and upper bounds on the growth
rate of the Morse index of free boundary minimal surfaces with respect to the
topological data (i. e. the genus and the number of boundary components) of the
surfaces in question. In particular, we compute the exact values of the
equivariant Morse index and nullity for two infinite families of examples, with
respect to their maximal symmetry groups, and thereby derive explicit two-sided
linear bounds when the equivariance constraint is lifted.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:11:32 GMT""}]","2023-01-10"
"2301.03056","Anubrata Das","Anubrata Das, Houjiang Liu, Venelin Kovatchev, Matthew Lease","The State of Human-centered NLP Technology for Fact-checking","Published in Machine and Human Factors in Misinformation Management
  -- a special issue of Information Processing and Management","Information Processing & Management, 60(2), 103219 (2023)","10.1016/j.ipm.2022.103219",,"cs.CL cs.AI cs.CY cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Misinformation threatens modern society by promoting distrust in science,
changing narratives in public health, heightening social polarization, and
disrupting democratic elections and financial markets, among a myriad of other
societal harms. To address this, a growing cadre of professional fact-checkers
and journalists provide high-quality investigations into purported facts.
However, these largely manual efforts have struggled to match the enormous
scale of the problem. In response, a growing body of Natural Language
Processing (NLP) technologies have been proposed for more scalable
fact-checking. Despite tremendous growth in such research, however, practical
adoption of NLP technologies for fact-checking still remains in its infancy
today.
  In this work, we review the capabilities and limitations of the current NLP
technologies for fact-checking. Our particular focus is to further chart the
design space for how these technologies can be harnessed and refined in order
to better meet the needs of human fact-checkers. To do so, we review key
aspects of NLP-based fact-checking: task formulation, dataset construction,
modeling, and human-centered strategies, such as explainable models and
human-in-the-loop approaches. Next, we review the efficacy of applying
NLP-based fact-checking tools to assist human fact-checkers. We recommend that
future research include collaboration with fact-checker stakeholders early on
in NLP research, as well as incorporation of human-centered design practices in
model development, in order to further guide technology development for human
use and practical adoption. Finally, we advocate for more research on benchmark
development supporting extrinsic evaluation of human-centered fact-checking
technologies.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:13:13 GMT""}]","2023-01-10"
"2301.03057","Harrison Reeder","Harrison T. Reeder, Kyu Ha Lee, and Sebastien Haneuse","Characterizing quantile-varying covariate effects under the accelerated
  failure time model","This is the pre-peer reviewed, ""submitted"" version of the manuscript
  published in final form in Biostatistics by Oxford University Press at the
  below citation/doi. This upload will be updated with the final peer-reviewed
  ""accepted"" version of the manuscript following a 24 month embargo period","Biostatistics (Oxford, England), kxac052 (2023)","10.1093/biostatistics/kxac052",,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  An important task in survival analysis is choosing a structure for the
relationship between covariates of interest and the time-to-event outcome. For
example, the accelerated failure time (AFT) model structures each covariate
effect as a constant multiplicative shift in the outcome distribution across
all survival quantiles. Though parsimonious, this structure cannot detect or
capture effects that differ across quantiles of the distribution, a limitation
that is analogous to only permitting proportional hazards in the Cox model. To
address this, we propose a general framework for quantile-varying
multiplicative effects under the AFT model. Specifically, we embed flexible
regression structures within the AFT model, and derive a novel formula for
interpretable effects on the quantile scale. A regression standardization
scheme based on the g-formula is proposed to enable estimation of both
covariate-conditional and marginal effects for an exposure of interest. We
implement a user-friendly Bayesian approach for estimation and quantification
of uncertainty, while accounting for left truncation and complex censoring. We
emphasize the intuitive interpretation of this model through numerical and
graphical tools, and illustrate its performance by application to a study of
Alzheimer's disease and dementia.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:14:19 GMT""}]","2023-01-10"
"2301.03058","Shulim Kaliman","Shulim Kaliman and Mikhail Zaidenberg","Gromov Ellipticity and subellipticity","7 pages",,,,"math.AG math.CV","http://creativecommons.org/licenses/by/4.0/","  We establish the equivalence of Gromov ellipticity and subellipticity in the
algebraic category.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:15:18 GMT""}]","2023-01-10"
"2301.03059","Alessandro Siciliano","Giusy Monzillo, Tim Penttila, Alessandro Siciliano","Eggs in finite projective spaces and unitals in translation planes",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Inspired by the connection between ovoids and unitals arising from the
Buekenhout construction in the Andr\'e/Bruck-Bose representation of translation
planes of dimension at most two over their kernel, and since eggs of
PG(4m-1,q), m>=1, are a generalization of ovoids, we explore the relation
between eggs and unitals in translation planes of higher dimension over their
kernel. By investigating such a relationship, we construct a unital in the
Dickson semifield plane of order 3^{10}, which is represented in PG(20,3) by a
cone whose base is a set of points constructed from the dual of the
Penttila-Williams egg in PG(19,3). This unital is not polar; so, up to the
knowledge of the authors, it seems to be a new unital in such a plane.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:15:59 GMT""}]","2023-01-10"
"2301.03060","Yoshihiko Hasegawa","Yoshihiko Hasegawa","Thermodynamic correlation inequality","6 pages, 1 figure; 8 pages of supplemental material with 1 figure",,,,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncertainty relations place fundamental limits on the operations that
physical systems can perform. This Letter presents uncertainty relations that
bound the correlation function, which measures the relationship between a
system's current and future states, in classical Markov processes. The obtained
bounds, referred to as thermodynamic correlation inequalities, state that the
change in the correlation function has an upper bound comprising the dynamical
activity, a measure of the activity of a Markov process. Moreover, by applying
the obtained relation to a linear response function, it is demonstrated that
the effect of perturbation has a bound comprising the dynamical activity.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:22:56 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 09:05:46 GMT""}]","2023-04-25"
"2301.03061","Hector M. Castro-Beltran","H. M. Castro-Beltr\'an, O. de los Santos-S\'anchez, L. Guti\'errez,
  and A. D. Alcantar-Vidal","Quantum interference in the resonance fluorescence of a $J=1/2 - J'=1/2$
  atomic system: Quantum beats, nonclassicality, and non-Gaussianity","17 pages, 14 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We study the resonance fluorescence of a system with angular momentum $J=1/2
- J'=1/2$ level structure driven by a single, linearly polarized, monochromatic
laser field. Quantum interference among the two, antiparallel, $\pi$
transitions leads to rich results. We develop the article around two broad
overlapping themes: (i) the observation of quantum beats in the intensity and
the dipole-dipole, intensity-intensity, and quadrature-intensity correlations,
when the atom is subject to a strong laser and large Zeeman splittings. The
mean and modulation frequencies of the beats are given by the average and
difference, respectively, among two close generalized Rabi frequencies related
to a Mollow-like spectrum with two pairs of sidebands. (ii) The nonclassical
and non-Gaussian properties of phase-dependent fluorescence for the cases of
weak to moderate excitation and in the regime of beats. The fluorescence in the
beats regime is nonclassical, mainly from the third-order dipole fluctuations,
which reveal them to be also strongly non-Gaussian. For weak to moderate
driving laser and small detunings and Zeeman splittings the nonclassicality is
an interplay of second- (squeezing) and third-order dipole noise.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:25:36 GMT""}]","2023-01-10"
"2301.03062","Peichun Li","Peichun Li, Guoliang Cheng, Xumin Huang, Jiawen Kang, Rong Yu, Yuan
  Wu, Miao Pan","AnycostFL: Efficient On-Demand Federated Learning over Heterogeneous
  Edge Devices","Accepted to IEEE INFOCOM 2023",,,,"cs.LG cs.DC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  In this work, we investigate the challenging problem of on-demand federated
learning (FL) over heterogeneous edge devices with diverse resource
constraints. We propose a cost-adjustable FL framework, named AnycostFL, that
enables diverse edge devices to efficiently perform local updates under a wide
range of efficiency constraints. To this end, we design the model shrinking to
support local model training with elastic computation cost, and the gradient
compression to allow parameter transmission with dynamic communication
overhead. An enhanced parameter aggregation is conducted in an element-wise
manner to improve the model performance. Focusing on AnycostFL, we further
propose an optimization design to minimize the global training loss with
personalized latency and energy constraints. By revealing the theoretical
insights of the convergence analysis, personalized training strategies are
deduced for different devices to match their locally available resources.
Experiment results indicate that, when compared to the state-of-the-art
efficient FL algorithms, our learning framework can reduce up to 1.9 times of
the training latency and energy consumption for realizing a reasonable global
testing accuracy. Moreover, the results also demonstrate that, our approach
significantly improves the converged global accuracy.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:25:55 GMT""}]","2023-01-10"
"2301.03063","Gennady Shkliarevsky","Gennady Shkliarevsky","Inflation and Value Creation: An Economic and Philosophic Investigation","52 pages",,"10.13140/RG.2.2.30512.23046",,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  The subject of this study is inflation, a problem that has plagued America
and the world over the last several decades. Despite a rich trove of scholarly
studies and a wide range of tools developed to deal with inflation, we are
nowhere near a solution of this problem. We are now in the middle of the
inflation that threatens to become a stagflation or even a full recession; and
we have no idea what to prevent this outcome. This investigation explores the
real source of inflation. Tracing the problem of inflation to production, it
finds that inflation is not a phenomenon intrinsic to economy; rather, it is a
result of inefficiencies and waste in our economy. The investigation leads to a
conclusion that the solution of the problem of inflation is in achieving full
efficiency in production. Our economic production is a result of the evolution
that is propelled by the process of creation. In order to end economic
inefficiencies, we should model our economic practice on the process that
preceded production and has led to its emergence. In addition, the study will
outline ways in which our economic theory and practice must be changed to
achieve full efficiency of our production. Finally, the study provides a
critical overview of the current theories of inflation and remedies that are
proposed to deal with it.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:30:59 GMT""}]","2023-01-10"
"2301.03064","Yisroel Mirsky Dr.","Lior Yasur, Guy Frankovits, Fred M. Grabovski, Yisroel Mirsky","Deepfake CAPTCHA: A Method for Preventing Fake Calls",,,,,"cs.CR cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning technology has made it possible to generate realistic content
of specific individuals. These `deepfakes' can now be generated in real-time
which enables attackers to impersonate people over audio and video calls.
Moreover, some methods only need a few images or seconds of audio to steal an
identity. Existing defenses perform passive analysis to detect fake content.
However, with the rapid progress of deepfake quality, this may be a losing
game.
  In this paper, we propose D-CAPTCHA: an active defense against real-time
deepfakes. The approach is to force the adversary into the spotlight by
challenging the deepfake model to generate content which exceeds its
capabilities. By doing so, passive detection becomes easier since the content
will be distorted. In contrast to existing CAPTCHAs, we challenge the AI's
ability to create content as opposed to its ability to classify content. In
this work we focus on real-time audio deepfakes and present preliminary results
on video.
  In our evaluation we found that D-CAPTCHA outperforms state-of-the-art audio
deepfake detectors with an accuracy of 91-100% depending on the challenge
(compared to 71% without challenges). We also performed a study on 41
volunteers to understand how threatening current real-time deepfake attacks
are. We found that the majority of the volunteers could not tell the difference
between real and fake audio.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:34:19 GMT""}]","2023-01-10"
"2301.03065","Rahul Kothari","Shamik Ghosh, Pankaj Jain, Rahul Kothari, Mohit Panwar, Gurmeet Singh,
  Prabhakar Tiwari","Probing Cosmology beyond $\Lambda$CDM using the SKA","To be published in JoAA as a special issue on ""Indian participation
  in the SKA"" (10 Pages, 2 Figures). Matches with the published version","J. Astrophys. Astr. (2023) 44:22","10.1007/s12036-023-09918-y",,"astro-ph.CO gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  The cosmological principle states that the Universe is statistically
homogeneous and isotropic at large distance scales. There currently exist many
observations which indicate a departure from this principle. It has been shown
that many of these observations can be explained by invoking superhorizon
cosmological perturbations and may be consistent with the Big Bang paradigm.
Remarkably, these modes simultaneously explain the observed Hubble tension,
i.e., the discrepancy between the direct and indirect measurements of the
Hubble parameter. We propose several tests of the cosmological principle using
SKA. In particular, we can reliably extract the signal of dipole anisotropy in
the distribution of radio galaxies. The superhorizon perturbations also predict
a significant redshift dependence of the dipole signal which can be nicely
tested by the study of signals of reionization and the dark ages using SKA. We
also propose to study the alignment of radio galaxy axes as well as their
integrated polarization vectors over distance scales ranging from a few Mpc to
Gpc. We discuss data analysis techniques that can reliably extract these
signals from data.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:35:36 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 03:13:33 GMT""}]","2023-03-31"
"2301.03066","Yingxun Zhang","Yangyang Liu, Yingxun Zhang, Junping Yang, Yongjia Wang, Qingfeng Li,
  Zhuxia Li","Impacts of momentum dependent interaction, symmetry energy and
  near-threshold $NN\to N\Delta$ cross sections on isospin sensitive flow and
  pion observables","9 pages, 7 figures. arXiv admin note: text overlap with
  arXiv:2301.00212",,,,"nucl-th nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the ultra-relativistic quantum molecular dynamics (UrQMD) model, the
impacts of momentum dependent interaction, symmetry energy and near-threshold
$NN\to N\Delta$ cross sections on isospin sensitive collective flow and pion
observables are investigated. Our results confirm that the elliptic flow of
neutrons and charged particles, i.e. $v_2^n$ and $v_2^{ch}$, are sensitive to
the strength of momentum dependence interaction and the elliptic flow ratio,
i.e., $v_2^n/v_2^{ch}$, is sensitive to the stiffness of symmetry energy. For
describing the pion multiplicity near the threshold energy, accurate $NN\to
N\Delta$ cross sections are crucial. With the updated momentum dependent
interaction and $NN\to N\Delta$ cross sections in UrQMD model, seven
observables, such as directed flow and elliptic flow of neutrons and charged
particles, the elliptic flow ratio of neutrons to charged particles, charged
pion multiplicity and its ratio $\pi^-/\pi^+$, can be well described by the
parameter sets with the slope of symmetry energy from 5 MeV to 70 MeV. To
describe the constraints of symmetry energy at the densities probed by the
collective flow and pion observables, the named characteristic density is
investigated and used. Our analysis found that the flow characteristic density
is around 1.2$\rho_0$ and pion characteristic density is around 1.5$\rho_0$,
and we got the constrains of symmetry energy at characteristic densities are
$S(1.2\rho_0)=34\pm 4$ MeV and $S(1.5\rho_0)=36\pm 8$ MeV. These results are
consistent with previous analysis by using pion and flow observable with
different transport models, and demonstrate a reasonable description of
symmetry energy constraint should be presented at the characteristic density of
isospin sensitive observables.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:45:45 GMT""}]","2023-01-10"
"2301.03067","Cl\'esio Evangelista Mota","Cl\'esio E. Mota, Luis C. N. Santos, Franciele M. da Silva, Cesar V.
  Flores, Iarley P. Lobo and Valdir B. Bezerra","Neutron stars in the context of $f$($\mathbb{T}$,$\mathcal{T}$) gravity",,,,,"astro-ph.HE gr-qc nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we investigate the existence of neutron stars (NS) in the
framework of $f$($\mathbb{T}$,$\mathcal{T}$) gravity, where $\mathbb{T}$ is the
torsion tensor and $\mathcal{T}$ is the trace of the energy-momentum tensor.
The hydrostatic equilibrium equations are obtained, however, with $p$ and
$\rho$ quantities passed on by effective quantities $\bar{p}$ and $\bar{\rho}$,
whose mass-radius diagrams are obtained using modern equations of state (EoS)
of nuclear matter derived from relativistic mean field models and compared with
the ones computed by the Tolman-Oppenheimer-Volkoff (TOV) equations.
Substantial changes in the mass-radius profiles of NS are obtained even for
small changes in the free parameter of this modified theory. The results
indicate that the use of $f$($\mathbb{T}$,$\mathcal{T}$) gravity in the study
of NS provides good results for the masses and radii of some important
astrophysical objects, as for example, the low-mass X-ray binary (LMXB) NGC
6397 and the pulsar of millisecond PSR J0740+6620. In addition, radii results
inferred from the Lead Radius EXperiment (PREX-2) can also be described for
certain parameter values.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:50:53 GMT""},{""version"":""v2"",""created"":""Tue, 10 Jan 2023 13:34:20 GMT""}]","2023-01-11"
"2301.03068","Lei Lei","Lei Lei (USTC&PMO), Qing-Feng Zhu (USTC), Xu Kong (USTC), Ting-Gui
  Wang (USTC), Xian-Zhong Zheng (USTC&PMO), Dong-Dong Shi (PMO), Lu-Lu Fan
  (USTC) and Wei Liu (PMO)","Limiting Magnitudes of the Wide Field Survey Telescope (WFST)","Figure 5 (a,b,c) has been updated in this latest version. 12 pages, 5
  figures, accepted by RAA (Research in Astronomy and Astrophysics)","Research in Astronomy and Astrophysics, 23:035013 (8pp), 2023
  March","10.1088/1674-4527/acb877",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Expected to be of the highest survey power telescope in the northern
hemisphere, the Wide Field Survey Telescope (WFST) will begin its routine
observations of the northern sky since 2023. WFST will produce a lot of
scientific data to support the researches of time-domain astronomy, asteroids
and the solar system, galaxy formation and cosmology and so on. We estimated
that the 5 $\sigma$ limiting magnitudes of WFST with 30 second exposure are
$u=22.31$ mag, $g=23.42$ mag, $r=22.95$ mag, $i=22.43$ mag, $z=21.50$ mag,
$w=23.61$ mag. The above values are calculated for the conditions of
$airmass=1.2$, seeing = 0.75 arcsec, precipitable water vapour (PWV) = 2.5 mm
and Moon-object separation = $45^{\circ}$ at the darkest New Moon night of the
Lenghu site (V=22.30 mag, Moon phase $\theta=0^{\circ}$). The limiting
magnitudes in different Moon phase conditions are also calculated. The
calculations are based on the empirical transmittance data of WFST optics, the
vendor provided CCD quantum efficiency, the atmospherical model transmittance
and spectrum of the site. In the absence of measurement data such as sky
transmittance and spectrum, we use model data.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 15:56:19 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 03:26:49 GMT""}]","2023-05-04"
"2301.04011","Chong Wang","Chong Wang, Yuyuan Liu, Yuanhong Chen, Fengbei Liu, Yu Tian, Davis J.
  McCarthy, Helen Frazer, Gustavo Carneiro","Learning Support and Trivial Prototypes for Interpretable Image
  Classification",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Prototypical part network (ProtoPNet) methods have been designed to achieve
interpretable classification by associating predictions with a set of training
prototypes, which we refer to as trivial prototypes because they are trained to
lie far from the classification boundary in the feature space. Note that it is
possible to make an analogy between ProtoPNet and support vector machine (SVM)
given that the classification from both methods relies on computing similarity
with a set of training points (i.e., trivial prototypes in ProtoPNet, and
support vectors in SVM). However, while trivial prototypes are located far from
the classification boundary, support vectors are located close to this
boundary, and we argue that this discrepancy with the well-established SVM
theory can result in ProtoPNet models with inferior classification accuracy. In
this paper, we aim to improve the classification of ProtoPNet with a new method
to learn support prototypes that lie near the classification boundary in the
feature space, as suggested by the SVM theory. In addition, we target the
improvement of classification results with a new model, named ST-ProtoPNet,
which exploits our support prototypes and the trivial prototypes to provide
more effective classification. Experimental results on CUB-200-2011, Stanford
Cars, and Stanford Dogs datasets demonstrate that ST-ProtoPNet achieves
state-of-the-art classification accuracy and interpretability results. We also
show that the proposed support prototypes tend to be better localised in the
object of interest rather than in the background region.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 09:27:41 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 06:37:31 GMT""}]","2023-03-14"
"2301.04016","Shuyuan Xu","Shuyuan Xu, Jianchao Ji, Yunqi Li, Yingqiang Ge, Juntao Tan, Yongfeng
  Zhang","Causal Inference for Recommendation: Foundations, Methods and
  Applications",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems are important and powerful tools for various personalized
services. Traditionally, these systems use data mining and machine learning
techniques to make recommendations based on correlations found in the data.
However, relying solely on correlation without considering the underlying
causal mechanism may lead to various practical issues such as fairness,
explainability, robustness, bias, echo chamber and controllability problems.
Therefore, researchers in related area have begun incorporating causality into
recommendation systems to address these issues. In this survey, we review the
existing literature on causal inference in recommender systems. We discuss the
fundamental concepts of both recommender systems and causal inference as well
as their relationship, and review the existing work on causal methods for
different problems in recommender systems. Finally, we discuss open problems
and future directions in the field of causal inference for recommendations.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:57:15 GMT""}]","2023-01-11"
"2301.04019","Ying Wei","Shuailei Ma, Yuefeng Wang, Shanze Wang and Ying Wei","FGAHOI: Fine-Grained Anchors for Human-Object Interaction Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human-Object Interaction (HOI), as an important problem in computer vision,
requires locating the human-object pair and identifying the interactive
relationships between them. The HOI instance has a greater span in spatial,
scale, and task than the individual object instance, making its detection more
susceptible to noisy backgrounds. To alleviate the disturbance of noisy
backgrounds on HOI detection, it is necessary to consider the input image
information to generate fine-grained anchors which are then leveraged to guide
the detection of HOI instances. However, it is challenging for the following
reasons. i) how to extract pivotal features from the images with complex
background information is still an open question. ii) how to semantically align
the extracted features and query embeddings is also a difficult issue. In this
paper, a novel end-to-end transformer-based framework (FGAHOI) is proposed to
alleviate the above problems. FGAHOI comprises three dedicated components
namely, multi-scale sampling (MSS), hierarchical spatial-aware merging (HSAM)
and task-aware merging mechanism (TAM). MSS extracts features of humans,
objects and interaction areas from noisy backgrounds for HOI instances of
various scales. HSAM and TAM semantically align and merge the extracted
features and query embeddings in the hierarchical spatial and task perspectives
in turn. In the meanwhile, a novel training strategy Stage-wise Training
Strategy is designed to reduce the training pressure caused by overly complex
tasks done by FGAHOI. In addition, we propose two ways to measure the
difficulty of HOI detection and a novel dataset, i.e., HOI-SDC for the two
challenges (Uneven Distributed Area in Human-Object Pairs and Long Distance
Visual Modeling of Human-Object Pairs) of HOI instances detection.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 03:53:50 GMT""}]","2023-01-11"
"2301.04464","Vlad-Titus Sp\u{a}taru","Vlad-Titus Sp\u{a}taru","Runs of Consecutive Integers Having the Same Number of Divisors",,"The PUMP Journal of Undergraduate Research, Vol. 6 (2023), 96-101",,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Our objective is to provide an upper bound for the length $\ell_N$ of the
longest run of consecutive integers smaller than $N$ which have the same number
of divisors. We prove in an elementary way that $\log\ell_N\ll(\log N\log\log
N)^\lambda$, where $\lambda=1/2$. Using estimates for the Jacobsthal function,
we then improve the result to $\lambda=1/3$.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 12:39:38 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 22:11:13 GMT""}]","2023-02-07"
"2301.04468","Eghbal Hosseini","Eghbal Hosseini","Tabu Search and Simulated Annealing metaheuristic algorithms applied to
  the RoRo vessel stowage problem",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  The search heuristics Tabu search and Simulated annealing are commonly used
meta-heuristics. The two heuristics have different ways of ensuring
diversification. The heuristics can be implemented for solving the stowage
planning problem. The stowage planning problem occurs every time a vessel is
loaded. The idea is to stow the cargo in an optimal manner satisfying a set of
constraints and specifically the stability constraints. An optimal plan can be
to assign the cargo to spots on the vessel so that the vessel trim and draft
are optimized ensuring a low fuel consumption. Here the problem considered is
the stowage planning of trailers on a Roll-on/Roll-off vessel. Roll-on/Roll-off
vessels carries vehicles or trailers on the different levels of the vessel.
When making a stowage plan of a vessel ballast tanks can be adjusted to improve
stability and to change draft. This leads to stability constraints which can be
very complex to model and solve using a mixed integer model and solver.
Complicating constraints occur in many different applications and different
forms and are the cause of the popularity of search algorithms, such as tabu
search and simulated annealing, for solving real-life applications. Results of
the two meta-heuristics are shown for real-life stowage planning cases for
Roll-on/Roll-off vessels.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:44:28 GMT""}]","2023-01-12"
"2301.05639","Shuai Wang","Shuai Wang (1), ChiYung Yam (2,3), Shuguang Chen (1,2), Lihong Hu (4),
  Liping Li (2), Faan-Fung Hung (1,2), Jiaqi Fan (2), Chi-Ming Che (1,2), and
  GuanHua Chen (1,2) ((1) Department of Chemistry, The University of Hong Kong,
  Pokfulam, Hong Kong SAR, China (2) Hong Kong Quantum AI Lab Limited, Pak Shek
  Kok, Hong Kong SAR, China (3) Shenzhen Institute for Advanced Study,
  University of Electronic Science and Technology of China, Shenzhen, 518000,
  China (4) School of Information Science and Technology, Northeast Normal
  University, Changchun, 130117, China)","Predictions of photophysical properties of phosphorescent platinum(II)
  complexes based on ensemble machine learning approach",,,,,"cs.LG physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phosphorescent metal complexes have been under intense investigations as
emissive dopants for energy efficient organic light emitting diodes (OLEDs).
Among them, cyclometalated Pt(II) complexes are widespread triplet emitters
with color-tunable emissions. To render their practical applications as OLED
emitters, it is in great need to develop Pt(II) complexes with high radiative
decay rate constant ($k_r$) and photoluminescence (PL) quantum yield. Thus, an
efficient and accurate prediction tool is highly desirable. Here, we develop a
general protocol for accurate predictions of emission wavelength, radiative
decay rate constant, and PL quantum yield for phosphorescent Pt(II) emitters
based on the combination of first-principles quantum mechanical method, machine
learning (ML) and experimental calibration. A new dataset concerning
phosphorescent Pt(II) emitters is constructed, with more than two hundred
samples collected from the literature. Features containing pertinent electronic
properties of the complexes are chosen. Our results demonstrate that ensemble
learning models combined with stacking-based approaches exhibit the best
performance, where the values of squared correlation coefficients ($R^2$), mean
absolute error (MAE), and root mean square error (RMSE) are 0.96, 7.21 nm and
13.00 nm for emission wavelength prediction, and 0.81, 0.11 and 0.15 for PL
quantum yield prediction. For radiative decay rate constant ($k_r$), the
obtained value of $R^2$ is 0.67 while MAE and RMSE are 0.21 and 0.25 (both in
log scale), respectively. The accuracy of the protocol is further confirmed
using 24 recently reported Pt(II) complexes, which demonstrates its reliability
for a broad palette of Pt(II) emitters.We expect this protocol will become a
valuable tool, accelerating the rational design of novel OLED materials with
desired properties.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 04:54:33 GMT""}]","2023-01-16"
"2302.02797","Kristopher Kuhlman","Forest T. Good, Kristopher L. Kuhlman, Tara C. LaForce, Matthew J.
  Paul and Jason E. Heath","Analytical Solution and Parameter Estimation for Heat of Wetting and
  Vapor Adsorption During Spontaneous Imbibition in Tuff","4 figures, 1 table",,"10.1016/j.ijheatmasstransfer.2022.123814",,"physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An analytical expression is derived for the thermal response observed during
spontaneous imbibition of water into a dry core of zeolitic tuff. Sample
tortuosity, thermal conductivity, and thermal source strength are estimated
from fitting an analytical solution to temperature observations during a single
laboratory test. The closed-form analytical solution is derived using Green's
functions for heat conduction in the limit of ""slow"" water movement; that is,
when advection of thermal energy with the wetting front is negligible. The
solution has four free fitting parameters and is efficient for parameter
estimation. Laboratory imbibition data used to constrain the model include a
time series of the mass of water imbibed, visual location of the wetting front
through time, and temperature time series at six locations. The thermal front
reached the end of the core hours before the visible wetting front. Thus, the
predominant form of heating during imbibition in this zeolitic tuff is due to
vapor adsorption in dry zeolitic rock ahead of the wetting front. The
separation of the wetting front and thermal front in this zeolitic tuff is
significant, compared to wetting front behavior of most materials reported in
the literature. This work is the first interpretation of a thermal imbibition
response to estimate transport (tortuosity) and thermal properties (including
thermal conductivity) from a single laboratory test.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 17:43:21 GMT""}]","2023-02-07"
"2302.05294","Farzan Farnia","Jingwei Zhang, Farzan Farnia","MoreauGrad: Sparse and Robust Interpretation of Neural Networks via
  Moreau Envelope",,,,,"cs.CV cs.AI cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Explaining the predictions of deep neural nets has been a topic of great
interest in the computer vision literature. While several gradient-based
interpretation schemes have been proposed to reveal the influential variables
in a neural net's prediction, standard gradient-based interpretation frameworks
have been commonly observed to lack robustness to input perturbations and
flexibility for incorporating prior knowledge of sparsity and group-sparsity
structures. In this work, we propose MoreauGrad as an interpretation scheme
based on the classifier neural net's Moreau envelope. We demonstrate that
MoreauGrad results in a smooth and robust interpretation of a multi-layer
neural network and can be efficiently computed through first-order optimization
methods. Furthermore, we show that MoreauGrad can be naturally combined with
$L_1$-norm regularization techniques to output a sparse or group-sparse
explanation which are prior conditions applicable to a wide range of deep
learning applications. We empirically evaluate the proposed MoreauGrad scheme
on standard computer vision datasets, showing the qualitative and quantitative
success of the MoreauGrad approach in comparison to standard gradient-based
interpretation methods.
","[{""version"":""v1"",""created"":""Sun, 8 Jan 2023 11:28:28 GMT""}]","2023-02-13"
"2302.10234","Davor Palle","Davor Palle","W boson mass anomaly and noncontractibility of the physical space","v2: few sentences and one reference added",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The CDF II detector at the Tevatron collider reported significant tension
between the measurement of the W boson mass and the Standard Model prediction,
assuming that 125 GeV scalar discovered at the LHC is the Higgs boson. We
calculate one loop corrections to the W boson mass within the theory of
noncontractible space without the Higgs boson. It turns out that our theory
provides better agreement with the CDF II detector result than the Standard
Model.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 20:47:59 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 11:23:33 GMT""}]","2023-03-28"
"2302.12889","Shlomo Kashani","Shlomo Kashani, David Zaret","Using the Julia framework to teach quantum entanglement",,,,,"physics.ed-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Entanglement, a phenomenon that has puzzled scientists since its discovery,
has been extensively studied by many researchers through both theoretical and
experimental aspect of both quantum information processing (QIP) and quantum
mechanics (QM). But how can entanglement be most effectively taught to computer
science students compared to applied physics students?. in this educational
pursuit, we propose using Yao.jl, a quantum computing framework written in
Julia for teaching entanglement to graduate computer science students attending
a quantum computing class at Johns Hopkins University.
  David Mermin's just enough QM for them to understand and develop algorithms
in quantum computation [Mer98, Mer03] idea aligns with the purpose of this
work. Additionally, the authors of the study Improving students understanding
of QM via the Stern-Gerlach experiment (SGE) argue that this experiment should
be a key part of any QM education. Here, we explore the concept of entanglement
and it's quantification in various quantum information processing experiments,
including one inequality-free form of Bell's theorem: (1) Superposition via the
Hadamard, (2) Bell-state generation and (3) GHZ state generation. The
utilisation of circuit diagrams and code fragmentsis a central theme in this
work's philosophy.
","[{""version"":""v1"",""created"":""Sat, 7 Jan 2023 16:39:31 GMT""}]","2023-02-28"
