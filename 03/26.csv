"2303.14196","Kai Wang","Kai Wang, Michael Z. Q. Chen, Fei Liu","Series-Parallel Mechanical Circuit Synthesis of a Positive-Real
  Third-Order Admittance Using at Most Six Passive Elements for Inerter-Based
  Control","This report includes the original manuscript (pp. 2-47) and the
  supplementary material (pp. 48-67)",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the circuit synthesis problem for a certain
positive-real bicubic (third-order) admittance with a simple pole at the origin
(s = 0) to be realizable as a one-port series-parallel damper-spring-inerter
circuit consisting of at most six elements, where the results can be directly
applied to the design and physical realization of inerter-based control
systems. Necessary and sufficient conditions for such a specific bicubic
admittance to be realizable by a one-port passive series-parallel mechanical
circuit containing at most six elements are derived, and a group of mechanical
circuit configurations covering the whole set of realizability conditions are
presented together with element value expressions. The conditions and element
value expressions are related to the admittance coefficients and the roots of
certain algebraic equations. The circuit synthesis results of this paper are
illustrated by several numerical examples including the control system design
of a train suspension system. Any realization circuit in this paper contains
much fewer passive elements than the ten-element realization circuit by the
well-known Bott-Duffin circuit synthesis approach. The investigations of this
paper can contribute to the theory of circuit synthesis and many other related
fields.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:44:37 GMT""}]","2023-03-28"
"2303.14506","Jiacheng Li","Jiacheng Li, Chang Chen, Zhen Cheng, Zhiwei Xiong","Toward DNN of LUTs: Learning Efficient Image Restoration with Multiple
  Look-Up Tables","Project Page: https://mulut.pages.dev/",,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The widespread usage of high-definition screens on edge devices stimulates a
strong demand for efficient image restoration algorithms. The way of caching
deep learning models in a look-up table (LUT) is recently introduced to respond
to this demand. However, the size of a single LUT grows exponentially with the
increase of its indexing capacity, which restricts its receptive field and thus
the performance. To overcome this intrinsic limitation of the single-LUT
solution, we propose a universal method to construct multiple LUTs like a
neural network, termed MuLUT. Firstly, we devise novel complementary indexing
patterns, as well as a general implementation for arbitrary patterns, to
construct multiple LUTs in parallel. Secondly, we propose a re-indexing
mechanism to enable hierarchical indexing between cascaded LUTs. Finally, we
introduce channel indexing to allow cross-channel interaction, enabling LUTs to
process color channels jointly. In these principled ways, the total size of
MuLUT is linear to its indexing capacity, yielding a practical solution to
obtain superior performance with the enlarged receptive field. We examine the
advantage of MuLUT on various image restoration tasks, including
super-resolution, demosaicing, denoising, and deblocking. MuLUT achieves a
significant improvement over the single-LUT solution, e.g., up to 1.1dB PSNR
for super-resolution and up to 2.8dB PSNR for grayscale denoising, while
preserving its efficiency, which is 100$\times$ less in energy cost compared
with lightweight deep neural networks. Our code and trained models are publicly
available at https://github.com/ddlee-cn/MuLUT.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:00:33 GMT""}]","2023-03-28"
"2303.14507","Stefan F\""urd\""os","Paulo D. Cordaro and Stefan F\""urd\""os","The Metivier inequality and ultradifferentiable hypoellipticity",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 1980 M{\'e}tivier characterized the analytic (and Gevrey) hypoellipticity
of $L^2$-solvable partial linear differential operators by a-priori estimates.
In this note we extend this characterization to ultradifferentiable
hypoellipticity with respect to Denjoy-Carleman classes given by suitable
weight sequences. We also discuss the case when the solutions can be taken as
hyperfunctions and present some applications.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:04:38 GMT""}]","2023-03-28"
"2303.14508","Qianyong Wu","Qianyong Wu and Jiang Hu","A spectral based goodness-of-fit test for stochastic block models",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Community detection in complex networks has attracted considerable attention,
however, most existing methods need the number of communities to be specified
beforehand. In this paper, a goodness-of-fit test based on the linear spectral
statistic of the centered and rescaled adjacency matrix for the stochastic
block model is proposed. We prove that the proposed test statistic converges in
distribution to the standard Gaussian distribution under the null hypothesis.
The proof uses some recent advances in generalized Wigner matrices. Simulations
and real data examples show that our proposed test statistic performs well.
This paper extends the work of Dong et al. [Information Science 512 (2020)
1360-1371].
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:05:34 GMT""}]","2023-03-28"
"2303.14509","Christopher Davis","Christopher William Davis","Whitney tower concordance and knots in homology spheres","16 pages, 10 Figures",,,,"math.GT","http://creativecommons.org/licenses/by/4.0/","  In a groundbreaking work A. Levine proved the surprising result that there
exist knots in homology spheres which are not smoothly concordant to any knot
in $S^3$, even if one allows for concordances in homology cobordisms. Since
then subsequent works due to Hom-Levine-Lidman and Zhou have strengthened this
result showing that there are many knots in homology spheres which are not
smoothly concordant to knots in $S^3$. In this paper we present evidence that
the opposite is true topologically. We study the Whitney tower filtration of
concordance due to Cochran-Orr-Teichner and prove that modulo any term in this
filtration every knot (or link) in a homology sphere is equivalent to a knot
(or link) in $S^3$. As an application we recover the main result of
[Davis2019], namely that the solvable filtration similarly fails to distinguish
links in homology spheres from links in $S^3$.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:15:02 GMT""}]","2023-03-28"
"2303.14510","Wensheng Gan","Shan Huang, Wensheng Gan, Jinbao Miao, Xuming Han, Philippe
  Fournier-Viger","Targeted Mining of Top-k High Utility Itemsets","Preprint. 5 figures, 5 tables",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding high-importance patterns in data is an emerging data mining task
known as High-utility itemset mining (HUIM). Given a minimum utility threshold,
a HUIM algorithm extracts all the high-utility itemsets (HUIs) whose utility
values are not less than the threshold. This can reveal a wealth of useful
information, but the precise needs of users are not well taken into account. In
particular, users often want to focus on patterns that have some specific items
rather than find all patterns. To overcome that difficulty, targeted mining has
emerged, focusing on user preferences, but only preliminary work has been
conducted. For example, the targeted high-utility itemset querying algorithm
(TargetUM) was proposed, which uses a lexicographic tree to query itemsets
containing a target pattern. However, selecting the minimum utility threshold
is difficult when the user is not familiar with the processed database. As a
solution, this paper formulates the task of targeted mining of the top-k
high-utility itemsets and proposes an efficient algorithm called TMKU based on
the TargetUM algorithm to discover the top-k target high-utility itemsets
(top-k THUIs). At the same time, several pruning strategies are used to reduce
memory consumption and execution time. Extensive experiments show that the
proposed TMKU algorithm has good performance on real and synthetic datasets.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:19:39 GMT""}]","2023-03-28"
"2303.14511","Annika Stein","Annika Stein","Improving robustness of jet tagging algorithms with adversarial
  training: exploring the loss surface","5 pages, 2 figures; submitted to ACAT 2022 proceedings",,,,"hep-ex cs.AI cs.LG hep-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  In the field of high-energy physics, deep learning algorithms continue to
gain in relevance and provide performance improvements over traditional
methods, for example when identifying rare signals or finding complex patterns.
From an analyst's perspective, obtaining highest possible performance is
desirable, but recently, some attention has been shifted towards studying
robustness of models to investigate how well these perform under slight
distortions of input features. Especially for tasks that involve many
(low-level) inputs, the application of deep neural networks brings new
challenges. In the context of jet flavor tagging, adversarial attacks are used
to probe a typical classifier's vulnerability and can be understood as a model
for systematic uncertainties. A corresponding defense strategy, adversarial
training, improves robustness, while maintaining high performance.
Investigating the loss surface corresponding to the inputs and models in
question reveals geometric interpretations of robustness, taking correlations
into account.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:23:27 GMT""}]","2023-03-28"
"2303.14512","Ayvaz Davletkhanov","Ayvaz I. Davletkhanov, Aram A. Mkrtchyan, Dmitry A. Chermoshentsev,
  Mikhail V. Shashkov, Daniil A. Ilatovskii, Dmitry V. Krasnikov, Albert G.
  Nasibulin, Yuriy G. Gladush","Inverted loss engineering in functional material covered waveguides","7 pages, 3 figures",,,,"physics.optics cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical waveguides, covered with thin films, which transmittance can be
controlled by external action, are widely used in various applications from
optical modulators to saturable absorbers. It is natural to suggest that the
waveguide losses will be proportional to the covering material absorption. We
demonstrate that under certain conditions this simple assumption fails.
Instead, we observe the reduction of the film material absorption can lead to
an increase in the waveguide propagation losses. For this, we use a side
polished fiber covered with a single-walled carbon nanotube thin film whose
absorption is attenuated either due to saturable absorption or electrochemical
gating. For the films thicker than 50 nm, we observe saturable absorption to
turn into light induced absorption with nonmonotonic dependence on the incident
power. With a numerical simulation and analytical approach, we identify that
this nontrivial behavior comes from mode reshaping and predict required
parameters for its observation.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:28:45 GMT""}]","2023-03-28"
"2303.14513","Soumya Jana","Soumya Jana, Sayan Kar","Shadows in dyonic Kerr-Sen black holes","24 pages, 8 figures, references added",,,,"gr-qc astro-ph.CO hep-th","http://creativecommons.org/licenses/by/4.0/","  Black holes with dyonic charges in Einstein-Maxwell-dilaton-axion
supergravity theory are revisited in the context of black hole shadows. We
consider static as well as rotating (namely the dyonic Kerr-Sen) black holes.
The matter stress-energy tensor components, sourced by the Maxwell, axion and
dilaton fields satisfy the standard energy conditions. The analytical
expressions for the horizon and the shadow radius of the static spacetimes
demonstrate their dependence on $P^2+Q^2$ ($P$, $Q$ the magnetic and electric
charges, respectively) and the mass parameter $M$. The shadow radius lies in
the range $2M <R_{shadow}<3\sqrt{3} M$ and there is no stable photon orbit
outside the horizon. Further, shadows cast by the rotating dyonic Kerr-Sen
black holes are also studied and compared graphically with their Kerr-Newman
and Kerr-Sen counterparts. Deviation of the shadow boundary is prominent with
the variation of the magnetic charge, for the relatively slowly rotating dyonic
Kerr-Sen spacetimes. We test any possible presence of a magnetic monopole
charge in the backdrop of recent EHT observations for the supermassive black
holes M87$^*$ and Sgr A$^*$. Deviation from circularity of the shadow boundary
($\Delta C$) and deviation of the average shadow radius from the Schwarzschild
shadow radius (quantified as the fractional deviation parameter $\delta$) are
the two observables used here. Observational bound on $\Delta C$ (available
only for M87$^*$) is satisfied for all theoretically allowed regions of
parameter space and thus cannot constrain the parameters. The observational
bound on $\delta$ available for Sgr A$^*$ translates into an upper limit on any
possible magnetic monopole charge linked to Sgr A$^*$ and is given as
$P\lesssim 0.873\, M$. Such a constraint on $P$ is however expected to be far
more stringent for other astrophysical tests.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:38:08 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 15:49:57 GMT""}]","2023-04-04"
"2303.14514","Mensah Folly-Gbetoula","Mensah Folly-Gbetoula","On a family of higher order recurrence relations: symmetries, formula
  solutions, periodicity and stability analysis","14pages, 2figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present formula solutions of a family of difference
equations of higher order. We discuss the periodic nature of the solutions and
we investigate the stability character of the equilibrium points. We utilize
Lie symmetry analysis as part of our approach together with some number
theoretic functions. Our findings generalize certain results in the literature.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:39:50 GMT""}]","2023-03-28"
"2303.14515","Christian Mitsch","Christian Mitsch","Specific investments under negotiated transfer pricing: effects of
  different surplus sharing parameters on managerial performance: An
  agent-based simulation with fuzzy Q-learning agents","arXiv admin note: substantial text overlap with arXiv:2301.12255",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  This paper focuses on a decentralized profit-center firm that uses negotiated
transfer pricing as an instrument to coordinate the production process.
Moreover, the firm's headquarters gives its divisions full authority over
operating decisions and it is assumed that each division can additionally make
an upfront investment decision that enhances the value of internal trade. On
early works, the paper expands the number of divisions by one downstream
division and relaxes basic assumptions, such as the assumption of common
knowledge of rationality. Based on an agent-based simulation, it is examined
whether cognitively bounded individuals modeled by fuzzy Q-learning achieve the
same results as fully rational utility maximizers. In addition, the paper
investigates different constellations of bargaining power to see whether a
deviation from the recommended optimal bargaining power leads to a higher
managerial performance. The simulation results show that fuzzy Q-learning
agents perform at least as well or better than fully individual rational
utility maximizers. The study also indicates that, in scenarios with different
marginal costs of divisions, a deviation from the recommended optimal
distribution ratio of the bargaining power of divisions can lead to higher
investment levels and, thus, to an increase in the headquarters' profit.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:45:32 GMT""}]","2023-03-28"
"2303.14516","Stamatis Alexandropoulos","Stamatis Alexandropoulos, Christos Sakaridis and Petros Maragos","OVeNet: Offset Vector Network for Semantic Segmentation",,,,,"cs.CV cs.AI cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  Semantic segmentation is a fundamental task in visual scene understanding. We
focus on the supervised setting, where ground-truth semantic annotations are
available. Based on knowledge about the high regularity of real-world scenes,
we propose a method for improving class predictions by learning to selectively
exploit information from neighboring pixels. In particular, our method is based
on the prior that for each pixel, there is a seed pixel in its close
neighborhood sharing the same prediction with the former. Motivated by this
prior, we design a novel two-head network, named Offset Vector Network
(OVeNet), which generates both standard semantic predictions and a dense 2D
offset vector field indicating the offset from each pixel to the respective
seed pixel, which is used to compute an alternative, seed-based semantic
prediction. The two predictions are adaptively fused at each pixel using a
learnt dense confidence map for the predicted offset vector field. We supervise
offset vectors indirectly via optimizing the seed-based prediction and via a
novel loss on the confidence map. Compared to the baseline state-of-the-art
architectures HRNet and HRNet+OCR on which OVeNet is built, the latter achieves
significant performance gains on two prominent benchmarks for semantic
segmentation of driving scenes, namely Cityscapes and ACDC. Code is available
at https://github.com/stamatisalex/OVeNet
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:52:42 GMT""}]","2023-03-28"
"2303.14517","Surya Mahadi","Made Raharja Surya Mahadi and Nugraha Priya Utama","Indonesian Text-to-Image Synthesis with Sentence-BERT and FastGAN","11 pages, 3 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Currently, text-to-image synthesis uses text encoder and image generator
architecture. Research on this topic is challenging. This is because of the
domain gap between natural language and vision. Nowadays, most research on this
topic only focuses on producing a photo-realistic image, but the other domain,
in this case, is the language, which is less concentrated. A lot of the current
research uses English as the input text. Besides, there are many languages
around the world. Bahasa Indonesia, as the official language of Indonesia, is
quite popular. This language has been taught in Philipines, Australia, and
Japan. Translating or recreating a new dataset into another language with good
quality will cost a lot. Research on this domain is necessary because we need
to examine how the image generator performs in other languages besides
generating photo-realistic images. To achieve this, we translate the CUB
dataset into Bahasa using google translate and manually by humans. We use
Sentence BERT as the text encoder and FastGAN as the image generator. FastGAN
uses lots of skip excitation modules and auto-encoder to generate an image with
resolution 512x512x3, which is twice as bigger as the current state-of-the-art
model (Zhang, Xu, Li, Zhang, Wang, Huang and Metaxas, 2019). We also get 4.76
+- 0.43 and 46.401 on Inception Score and Fr\'echet inception distance,
respectively, and comparable with the current English text-to-image generation
models. The mean opinion score also gives as 3.22 out of 5, which means the
generated image is acceptable by humans. Link to source code:
https://github.com/share424/Indonesian-Text-to-Image-synthesis-with-Sentence-BERT-and-FastGAN
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:54:22 GMT""}]","2023-03-28"
"2303.14518","Gabriele Giovannini","Gabriele Giovannini, Yuzhu Cui, Kazuhiro Hada, Kunwoo Yi, Hyunwook Ro,
  Bong Won Sohn, Mieko Takamura, Salvatore Buttaccio, Filippo D'Ammando,
  Marcello Giroletti, Yoshiaki Hagiwara, Motoki Kino, Evgeniya Kravchenko,
  Giuseppe Maccaferri, Alexey Melnikov, Kota ro Niinuma, Monica Orienti,
  Kiyoaki Wajima, Kazunori Akiyama, Akihiro Doi, Do-Young Byun, Tomoya Hirota,
  Mareki Honma, Taehyun Jung, Hideyuki Kobayashi, Shoko Koyama, Andrea Melis,
  Carlo Migoni, Yasuhiro Murata, Hiroshi Nagai, Satoko Sawada-Satoh, Matteo
  Stagni","The Past and Future of East Asia to Italy: Nearly Global VLBI","15 pages and 6 figures. This article belongs to the Special Issue
  Challenges in Understanding Black Hole Powered Jets with VLBI","Galaxies 2023 11(2) 49",,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present here the East Asia to Italy Nearly Global VLBI (EATING VLBI)
project. How this project started and the evolution of the international
collaboration between Korean, Japanese, and Italian researchers to study
compact sources with VLBI observations is reported. Problems related to the
synchronization of the very different arrays and technical details of the
telescopes involved are presented and discussed. The relatively high
observation frequency (22 and 43 GHz) and the long baselines between Italy and
East Asia produced high-resolution images. We present example images to
demonstrate the typical performance of the EATING VLBI array. The results
attracted international researchers and the collaboration is growing, now
including Chinese and Russian stations. New in progress projects are discussed
and future possibilities with a larger number of telescopes and a better
frequency coverage are briefly discussed herein.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:55:45 GMT""}]","2023-03-28"
"2303.14519","Rolf Findeisen","J. Pohlodek, H. Alsmeier, B. Morabito, C. Schlauch, A. Savchenko, and
  R. Findeisen","Stochastic Model Predictive Control Utilizing Bayesian Neural Networks",,,,,"eess.SY cs.LG cs.SY","http://creativecommons.org/licenses/by/4.0/","  Integrating measurements and historical data can enhance control systems
through learning-based techniques, but ensuring performance and safety is
challenging. Robust model predictive control strategies, like stochastic model
predictive control, can address this by accounting for uncertainty. Gaussian
processes are often used but have limitations with larger models and data sets.
We explore Bayesian neural networks for stochastic learning-assisted control,
comparing their performance to Gaussian processes on a wastewater treatment
plant model. Results show Bayesian neural networks achieve similar performance,
highlighting their potential as an alternative for control designs,
particularly when handling extensive data sets.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:58:11 GMT""}]","2023-03-28"
"2303.14520","Jos\'e Miguel Urbano","Dami\~ao J. Ara\'ujo, Ginaldo S. S\'a, Jos\'e Miguel Urbano","Sharp regularity for a singular fully nonlinear parabolic free boundary
  problem",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper establishes sharp local regularity estimates for viscosity
solutions of fully nonlinear parabolic free boundary problems with singular
absorption terms. The main difficulties are due to the blow-up of the source
along the free boundary and the lack of a variational structure. The proof
combines the power of the Ishii-Lions method with intrinsically parabolic
oscillation estimates. The results are new, even for second-order linear
operators in nondivergence form.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 16:59:47 GMT""}]","2023-03-28"
"2303.14521","M\'at\'e Cser\'ep","D\'avid Magyar, M\'at\'e Cser\'ep, Zolt\'an Vincell\'er, Attila D.
  Moln\'ar","Waste Detection and Change Analysis based on Multispectral Satellite
  Imagery","18 pages, 10 figures","In Proceedings of K\'EPAF 2023, Gyula, Hungary",,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  One of the biggest environmental problems of our time is the increase in
illegal landfills in forests, rivers, on river banks and other secluded places.
In addition, waste in rivers causes damage not only locally, but also
downstream, both in the water and washed ashore. Large islands of waste can
also form at hydroelectric power stations and dams, and if they continue to
flow, they can cause further damage to the natural environment along the river.
Recent studies have also proved that rivers are the main source of plastic
pollution in marine environments. Monitoring potential sources of danger is
therefore highly important for effective waste collection for related
organizations. In our research we analyze two possible forms of waste
detection: identification of hot-spots (i.e. illegal waste dumps) and
identification of water-surface river blockages. We used medium to
high-resolution multispectral satellite imagery as our data source, especially
focusing on the Tisza river as our study area. We found that using satellite
imagery and machine learning are viable to locate and to monitor the change of
the previously detected waste.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:12:22 GMT""}]","2023-03-28"
"2303.14522","Jessica M\'egane","Pedro Carvalho and Jessica M\'egane and Nuno Louren\c{c}o and Penousal
  Machado","Context Matters: Adaptive Mutation for Grammars","16 pages, 6 figures, 5 tables",,"10.1007/978-3-031-29573-7_8",,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  This work proposes Adaptive Facilitated Mutation, a self-adaptive mutation
method for Structured Grammatical Evolution (SGE), biologically inspired by the
theory of facilitated variation. In SGE, the genotype of individuals contains a
list for each non-terminal of the grammar that defines the search space. In our
proposed mutation, each individual contains an array with a different,
self-adaptive mutation rate for each non-terminal. We also propose Function
Grouped Grammars, a grammar design procedure, to enhance the benefits of the
proposed mutation. Experiments were conducted on three symbolic regression
benchmarks using Probabilistic Structured Grammatical Evolution (PSGE), a
variant of SGE. Results show our approach is similar or better when compared
with the standard grammar and mutation.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:26:20 GMT""}]","2023-03-31"
"2303.14523","Nuno Laranjeiro","Fernando Richter Vidal and Naghmeh Ivaki and Nuno Laranjeiro","OpenSCV: An Open Hierarchical Taxonomy for Smart Contract
  Vulnerabilities",,,,,"cs.CR cs.SE","http://creativecommons.org/licenses/by/4.0/","  Smart contracts are nowadays at the core of most blockchain systems, as they
specify and allow an agreement between entities that wish to perform a
transaction. As any computer program, smart contracts are subject to the
presence of residual faults, including severe security vulnerabilities, which
require that the vulnerable contract is terminated in the blockchain. In this
context, research began to be developed to prevent the deployment of smart
contract holding vulnerabilities, mostly in the form of vulnerability detection
tools. Along with these efforts, several and heterogeneous vulnerability
classification schemes arised (e.g., most notably DASP and SWC). At the time of
writing, these are mostly outdated initiatives, despite the fact that smart
contract vulnerabilities are continuously being discovered and the associated
rich information being mostly disregarded. In this paper, we propose OpenSCV, a
new and Open hierarchical taxonomy for Smart Contract Vulnerabilities, which is
open to community contributions and matches the current state of the practice,
while being prepared to handle future modifications and evolution. The taxonomy
was built based on the analysis of research on vulnerability classification,
community-maintained classification schemes, and research on smart contract
vulnerability detection. We show how OpenSCV covers the announced detection
ability of current vulnerability detection tools, and highlight its usefulness
as a resource in smart contract vulnerability research.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:31:02 GMT""},{""version"":""v2"",""created"":""Fri, 7 Apr 2023 16:24:59 GMT""}]","2023-04-10"
"2303.14524","Tao Sheng","Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, Jiawei
  Zhang","Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender
  System",,,,,"cs.IR cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have demonstrated their significant potential to
be applied for addressing various application tasks. However, traditional
recommender systems continue to face great challenges such as poor
interactivity and explainability, which actually also hinder their broad
deployment in real-world systems. To address these limitations, this paper
proposes a novel paradigm called Chat-Rec (ChatGPT Augmented Recommender
System) that innovatively augments LLMs for building conversational recommender
systems by converting user profiles and historical interactions into prompts.
Chat-Rec is demonstrated to be effective in learning user preferences and
establishing connections between users and products through in-context
learning, which also makes the recommendation process more interactive and
explainable. What's more, within the Chat-Rec framework, user's preferences can
transfer to different products for cross-domain recommendations, and
prompt-based injection of information into LLMs can also handle the cold-start
scenarios with new items. In our experiments, Chat-Rec effectively improve the
results of top-k recommendations and performs better in zero-shot rating
prediction task. Chat-Rec offers a novel approach to improving recommender
systems and presents new practical scenarios for the implementation of AIGC (AI
generated content) in recommender system studies.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:37:43 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 03:51:27 GMT""}]","2023-04-05"
"2303.14525","Rafael Potrie","Sergio R. Fenley, Rafael Potrie","Transverse minimal foliations on unit tangent bundles and applications","61 pages, 18 figures",,,,"math.GT math.DG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that if $\mathcal{F}_1$ and $\mathcal{F}_2$ are two transverse
minimal foliations on $M = T^1S$ then either they intersect in an Anosov
foliation or there exists a Reeb-surface in the intersection foliation. The
existence of a Reeb surface is incompatible with partially hyperbolic
foliations so we deduce from this that certain partially hyperbolic
diffeomorphisms in unit tangent bundles are collapsed Anosov flows. We also
conclude that every volume preserving partially hyperbolic diffeomorphism of a
unit tangent bundle is ergodic.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:40:50 GMT""}]","2023-03-28"
"2303.14526","Jue Wang","Jue Wang, Wentao Zhu, Pichao Wang, Xiang Yu, Linda Liu, Mohamed Omar,
  Raffay Hamid","Selective Structured State-Spaces for Long-Form Video Understanding","Accepted by CVPR 2023",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Effective modeling of complex spatiotemporal dependencies in long-form videos
remains an open problem. The recently proposed Structured State-Space Sequence
(S4) model with its linear complexity offers a promising direction in this
space. However, we demonstrate that treating all image-tokens equally as done
by S4 model can adversely affect its efficiency and accuracy. To address this
limitation, we present a novel Selective S4 (i.e., S5) model that employs a
lightweight mask generator to adaptively select informative image tokens
resulting in more efficient and accurate modeling of long-term spatiotemporal
dependencies in videos. Unlike previous mask-based token reduction methods used
in transformers, our S5 model avoids the dense self-attention calculation by
making use of the guidance of the momentum-updated S4 model. This enables our
model to efficiently discard less informative tokens and adapt to various
long-form video understanding tasks more effectively. However, as is the case
for most token reduction methods, the informative image tokens could be dropped
incorrectly. To improve the robustness and the temporal horizon of our model,
we propose a novel long-short masked contrastive learning (LSMCL) approach that
enables our model to predict longer temporal context using shorter input
videos. We present extensive comparative results using three challenging
long-form video understanding datasets (LVU, COIN and Breakfast), demonstrating
that our approach consistently outperforms the previous state-of-the-art S4
model by up to 9.6% accuracy while reducing its memory footprint by 23%.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:47:12 GMT""}]","2023-03-28"
"2303.14527","Stefan Stojku","Stefan Stojku, Bojana Ilic, Igor Salom and Magdalena Djordjevic","Importance of higher orders in opacity in QGP tomography","23 pages, 8 figures",,,,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  We consider the problem of including a finite number of scattering centers in
dynamical energy loss and classical DGLV formalism. Previously, either one or
an infinite number of scattering centers were considered in energy loss
calculations, while attempts to relax such approximations were largely
inconclusive or incomplete. In reality, however, the number of scattering
centers is generally estimated to be 4-5 at RHIC and the LHC, making the above
approximations (a priori) inadequate and this theoretical problem significant
for QGP tomography. We derived explicit analytical expressions for dynamical
energy loss and DGLV up to the $4^{th}$ order in opacity, resulting in complex
mathematical expressions that were, to our knowledge, obtained for the first
time. These expressions were then implemented into an appropriately generalized
DREENA framework to calculate the effects of higher orders in opacity on a wide
range of high-$p_\perp$ light and heavy flavor predictions. Results of
extensive numerical analysis, together with interpretations of nonintuitive
results, are presented. We find that, for both RHIC and the LHC, higher-order
effects on high-$p_\perp$ observables are small, and the approximation of a
single scattering center is adequate for dynamical energy loss and DGLV
formalisms.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:51:01 GMT""}]","2023-03-28"
"2303.14528","Piotr Kubala","Piotr Kubala, Micha{\l} Cie\'sla","Splay and polar order in a system of hard pear-like molecules:
  confrontation of Monte Carlo numerical simulations with density functional
  theory calculations",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Recent experimental discoveries of novel nematic types with polar order,
including ferroelectric nematic and splay nematic have brought the resurgence
of the interest in polar and modulated phases. One of the most important
factors that is widely believed to be crucial for the formation of the new
phases is the pear-like shape of the mesogenic molecules. Such molecules were
treated using second-virial density functional theory in [De Gregorio, P
\textit{et al.}, \textit{Soft Matter}, 2016, \textbf{12(23)}, 5188-5198], where
the authors showed that the $K_{11}$ splay elastic constant can become negative
due to solely entropic reasons leading to long-range splay and polar
correlations. To verify whether the predictions are correct, we performed Monte
Carlo simulations of the same hard-core molecules used in the DFT study. As our
results suggest, no polar or modulated liquid crystalline phases emerge; polar
and splay correlations are at most short-range or completely absent. On the
other hand, a polar ferroelectric splay crystal was observed.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:03:07 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 14:46:33 GMT""}]","2023-05-18"
"2303.14529","Luiz Henrique Lopes Dos Santos","Luiz Henrique Lopes dos Santos","Temporal truth and bivalence an anachronistic formal approach to
  Aristotle's De Interpretatione 9","23 pages, to be published in Journal of Ancient Philosophy, ISSN:
  1981-9471/1981-9498",,,,"math.HO math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Regarding the famous Sea Battle Argument, which Aristotle presents in De
Interpretatione 9, there has never been a general agreement not only about its
correctness but also, and mainly, about what the argument really is. According
to the most natural reading of the chapter, the argument appeals to a temporal
concept of truth and concludes that not every statement is always either true
or false. However, many of Aristotle's followers and commentators have not
adopted this reading. I believe that it has faced so much resistance for
reasons of hermeneutic charity denying the law of universal bivalence seems to
be overly disruptive to logical orthodoxy the kind of logical orthodoxy
represented by what we now call classical propositional logic, much of which
Aristotle clearly supports in many texts. I intend to show that the
logical-semantic theses that the traditional reading finds in De
Interpretatione 9 are much more conservative than they may seem to be at first
glance. First, I will show that they complement, and do not contradict in any
way, the orthodox definitions of the concepts of truth and statement that
Aristotle advances in other texts. Second, by resorting in an anachronistic
vein to concepts and methods peculiar to contemporary logic, I will show that a
trivalent modal semantics conforming to those theses can be built for a
standard formal language of the classical propositional calculus. It is
remarkable that reasonable concepts of logical truth and logical consequence
that may be defined on the basis of this trivalent modal semantics are
coextensive with their orthodox counterparts, the concepts of tautology and
tautological consequence of classical bivalent and extensional semantics.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:13:37 GMT""}]","2023-03-28"
"2303.14530","Yuki Moritani","Yuki Moritani (1,2), Akiko Kawachi (3), Atsuo T. Okazaki (4), Sho
  Chimasu (3) and Hiromi Yoshida (3) ((1) National Astronomical Observatory of
  Japan, (2) Hiroshima University, (3) Tokai University, (4) Hokkai-Gakuen
  University)","Novel application to estimate the mass-loss and the dust-formation rates
  in O-type gamma-ray binaries using near-infrared photometry","7 figures, 2 tables, Accepted to publications in PASJ",,"10.1093/pasj/psad022",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have performed the near-infrared photometric monitoring observations of
two TeV gamma-ray binaries with O-stars (LS 5039 and 1FGL J1018.6-5856), using
IRSF/SIRIUS at SAAO, in order to study the stellar parameters and their
perturbations caused by the binary interactions. The whole orbital phase was
observed multiple times and no significant variabilities including orbital
modulations are detected for both targets. Assuming that the two systems are
colliding wind binaries, we estimate the amplitude of flux variation caused by
the difference in the optical depth of O-star wind at inferior conjunction,
where the star is seen through the cavity created by pulsar wind, and other
orbital phases without pulsar-wind intervention. The derived amplitude is
<0.001 mag, which is about two orders of magnitude smaller than the observed
upper limit. Also using the upper limits of the near-infrared variability, we
for the first time obtain the upper limit of the dust formation rate resulting
from wind-wind collision in O-star gamma-ray binaries.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:21:18 GMT""}]","2023-04-26"
"2303.14531","Jingyang Zhang","Jingyang Zhang, Nathan Inkawhich, Randolph Linderman, Ryan Luley,
  Yiran Chen, Hai Li","SIO: Synthetic In-Distribution Data Benefits Out-of-Distribution
  Detection",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Building up reliable Out-of-Distribution (OOD) detectors is challenging,
often requiring the use of OOD data during training. In this work, we develop a
data-driven approach which is distinct and complementary to existing works:
Instead of using external OOD data, we fully exploit the internal
in-distribution (ID) training set by utilizing generative models to produce
additional synthetic ID images. The classifier is then trained using a novel
objective that computes weighted loss on real and synthetic ID samples
together. Our training framework, which is termed SIO, serves as a
""plug-and-play"" technique that is designed to be compatible with existing and
future OOD detection algorithms, including the ones that leverage available OOD
training data. Our experiments on CIFAR-10, CIFAR-100, and ImageNet variants
demonstrate that SIO consistently improves the performance of nearly all
state-of-the-art (SOTA) OOD detection algorithms. For instance, on the
challenging CIFAR-10 v.s. CIFAR-100 detection problem, SIO improves the average
OOD detection AUROC of 18 existing methods from 86.25\% to 89.04\% and achieves
a new SOTA of 92.94\% according to the OpenOOD benchmark. Code is available at
https://github.com/zjysteven/SIO.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:34:34 GMT""}]","2023-03-28"
"2303.14532","Yogesh Bagul","Yogesh J. Bagul","Stringent bounds for the non-zero Bernoulli numbers","8 pages",,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  We present new several sharper and sharper lower and upper bounds for the
non-zero Bernoulli numbers using Euler's formula for the Riemann zeta function.
As a particular case, we determine the best possible constants $ \alpha $ and $
\beta $ such that the double inequality $$ \frac{2\cdot (2k)!}{\pi^{2k}
(2^{2k}-1)}\frac{3^{2k}}{(3^{2k}-\alpha)} < \vert B_{2k} \vert < \frac{2\cdot
(2k)!}{\pi^{2k} (2^{2k}-1)}\frac{3^{2k}}{(3^{2k}-\beta)}, $$ holds for $ k = 1,
2, 3, \cdots.$ Our main results refine the existing bounds of $ \vert B_{2k}
\vert $ in the literature.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:36:49 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 21:46:24 GMT""},{""version"":""v3"",""created"":""Sat, 8 Apr 2023 15:30:22 GMT""}]","2023-04-11"
"2303.14533","Carter Davis","Carter Davis","The Elasticity of Quantitative Investment",,,,,"q-fin.PM q-fin.MF q-fin.RM q-fin.ST","http://creativecommons.org/licenses/by/4.0/","  What is the price elasticity of demand for canonical portfolio choice methods
in financial economics? Twelve models from the literature exhibit strikingly
inelastic demand, in contrast to classical models. This is due to the
difficulty of trading against price changes in practice, and is consistent with
demand elasticity estimates. This provides a novel answer to the inelastic
markets hypothesis, raises important concerns for the use of strongly elastic
investors in theory models, and quantifies the difficulty of trading against
potential mispricing aside from the standard limits to arbitrage frictions.
Counterfactual experiments with these demand functions exhibit large and
persistent alpha.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:42:43 GMT""}]","2023-03-28"
"2303.14534","Henri Jaffres Pr.","E. Rongione, L. Baringthon, D. She, G. Patriarche, R. Lebrun, A.
  Lemaitre, M. Morassi, N. Reyren, M. Micica, J. Mangeney, J. Tignon, F.
  Bertran, S. Dhillon, P. Le Fevre, H. Jaffres, and J.-M. George","Spin-momentum locking and ultrafast spin-charge conversion in ultrathin
  epitaxial Bi$_{1-x}$Sb$_x$ topological insulator","23 pages, 3 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  The helicity of 3D topological insulator surface states has drawn significant
attention in spintronics owing to spin-momentum locking where the carriers'
spin is oriented perpendicular to their momentum. This property can provide an
efficient method to convert charge currents into spin currents, and vice-versa,
through the Rashba-Edelstein effect. However, experimental signatures of these
surface states to the spin-charge conversion are extremely difficult to
disentangle from bulk state contributions. Here, we combine spin- and
angle-resolved photo-emission spectroscopy, and time-resolved THz emission
spectroscopy to categorically demonstrate that spin-charge conversion arises
mainly from the surface state in Bi$_{1-x}$Sb$_x$ ultrathin films, down to few
nanometers where confinement effects emerge. We correlate this large conversion
efficiency, typically at the level of the bulk spin Hall effect from heavy
metals, to the complex Fermi surface obtained from theoretical calculations of
the inverse Rashba-Edelstein response. %We demonstrate this for film thickness
down to a few nanometers, Both surface state robustness and sizeable conversion
efficiency in epitaxial Bi$_{1-x}$Sb$_x$ thin films bring new perspectives for
ultra-low power magnetic random-access memories and broadband THz generation.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:44:19 GMT""}]","2023-03-28"
"2303.14535","Kilian Batzner","Kilian Batzner, Lars Heckler, Rebecca K\""onig","EfficientAD: Accurate Visual Anomaly Detection at Millisecond-Level
  Latencies",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting anomalies in images is an important task, especially in real-time
computer vision applications. In this work, we focus on computational
efficiency and propose a lightweight feature extractor that processes an image
in less than a millisecond on a modern GPU. We then use a student-teacher
approach to detect anomalous features. We train a student network to predict
the extracted features of normal, i.e., anomaly-free training images. The
detection of anomalies at test time is enabled by the student failing to
predict their features. We propose a training loss that hinders the student
from imitating the teacher feature extractor beyond the normal images. It
allows us to drastically reduce the computational cost of the student-teacher
model, while improving the detection of anomalous features. We furthermore
address the detection of challenging logical anomalies that involve invalid
combinations of normal local features, for example, a wrong ordering of
objects. We detect these anomalies by efficiently incorporating an autoencoder
that analyzes images globally. We evaluate our method, called EfficientAD, on
32 datasets from three industrial anomaly detection dataset collections.
EfficientAD sets new standards for both the detection and the localization of
anomalies. At a latency of two milliseconds and a throughput of six hundred
images per second, it enables a fast handling of anomalies. Together with its
low error rate, this makes it an economical solution for real-world
applications and a fruitful basis for future research.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:48:33 GMT""}]","2023-03-28"
"2303.14536","Haithem Turki","Haithem Turki, Jason Y. Zhang, Francesco Ferroni, Deva Ramanan","SUDS: Scalable Urban Dynamic Scenes","CVPR 2023 Project page: https://haithemturki.com/suds/",,,,"cs.CV cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend neural radiance fields (NeRFs) to dynamic large-scale urban scenes.
Prior work tends to reconstruct single video clips of short durations (up to 10
seconds). Two reasons are that such methods (a) tend to scale linearly with the
number of moving objects and input videos because a separate model is built for
each and (b) tend to require supervision via 3D bounding boxes and panoptic
labels, obtained manually or via category-specific models. As a step towards
truly open-world reconstructions of dynamic cities, we introduce two key
innovations: (a) we factorize the scene into three separate hash table data
structures to efficiently encode static, dynamic, and far-field radiance
fields, and (b) we make use of unlabeled target signals consisting of RGB
images, sparse LiDAR, off-the-shelf self-supervised 2D descriptors, and most
importantly, 2D optical flow.
  Operationalizing such inputs via photometric, geometric, and feature-metric
reconstruction losses enables SUDS to decompose dynamic scenes into the static
background, individual objects, and their motions. When combined with our
multi-branch table representation, such reconstructions can be scaled to tens
of thousands of objects across 1.2 million frames from 1700 videos spanning
geospatial footprints of hundreds of kilometers, (to our knowledge) the largest
dynamic NeRF built to date.
  We present qualitative initial results on a variety of tasks enabled by our
representations, including novel-view synthesis of dynamic urban scenes,
unsupervised 3D instance segmentation, and unsupervised 3D cuboid detection. To
compare to prior work, we also evaluate on KITTI and Virtual KITTI 2,
surpassing state-of-the-art methods that rely on ground truth 3D bounding box
annotations while being 10x quicker to train.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:55:09 GMT""}]","2023-03-28"
"2303.14537","Rickard Br\""uel Gabrielsson","Rickard Br\""uel-Gabrielsson, Tongzhou Wang, Manel Baradad, Justin
  Solomon","Deep Augmentation: Enhancing Self-Supervised Learning through
  Transformations in Higher Activation Space",,,,,"cs.LG cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  We introduce Deep Augmentation, an approach to data augmentation using
dropout to dynamically transform a targeted layer within a neural network, with
the option to use the stop-gradient operation, offering significant
improvements in model performance and generalization. We demonstrate the
efficacy of Deep Augmentation through extensive experiments on contrastive
learning tasks in computer vision and NLP domains, where we observe substantial
performance gains with ResNets and Transformers as the underlying models. Our
experimentation reveals that targeting deeper layers with Deep Augmentation
outperforms augmenting the input data, and the simple network- and
data-agnostic nature of this approach enables its seamless integration into
computer vision and NLP pipelines.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:03:57 GMT""}]","2023-03-28"
"2303.14538","Arzu Kurt","Arzu Kurt","Interplay between Non-Markovianity of Noise and Dynamics in Quantum
  Systems","12 pages, 4 figures","Entropy 2023, 25(3), 501","10.3390/e25030501",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The non-Markovianity of open quantum system dynamics is often associated with
the bidirectional interchange of information between the system and its
environment, and it is thought to be a resource for various quantum information
tasks. We have investigated the non-Markovianity of the dynamics of a two-state
system driven by continuous time random walk-type noise, which can be Markovian
or non-Markovian depending on its residence time distribution parameters. Exact
analytical expressions for the distinguishability as well as the trace distance
and entropy-based non-Markovianity measures are obtained and used to
investigate the interplay between the non-Markovianity of the noise and that of
dynamics. Our results show that, in many cases, the dynamics are also
non-Markovian when the noise is non-Markovian. However, it is possible for
Markovian noise to cause non-Markovian dynamics and for non-Markovian noise to
cause Markovian dynamics but only for certain parameter values.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:07:31 GMT""}]","2023-03-28"
"2303.14539","James Currie","James D. Currie","The analogue of overlap-freeness for the period-doubling sequence","34 pages, 2 figures",,,,"math.CO cs.FL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Good words are binary words avoiding factors 11 and 1001, and patterns 0000
and 00010100. We show that good words bear the same relationship to the
period-doubling sequence that overlap-free words bear to the Thue-Morse
sequence. We prove an analogue of Fife's Theorem for good words, exhibit the
lexicographically least and greatest infinite good words, and determine the
patterns avoided by the period doubling word.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:07:42 GMT""}]","2023-03-28"
"2303.14540","Mehmet Mert \c{S}ahin","Mehmet Mert Sahin, Onur Dizdar, Bruno Clerckx, Huseyin Arslan","Multicarrier Rate-Splitting Multiple Access: Superiority of OFDM-RSMA
  over OFDMA and OFDM-NOMA","Submitted to IEEE for possible publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rate-splitting multiple access (RSMA) is a multiple access technique
generalizing conventional techniques, such as, space-division multiple access
(SDMA), non-orthogonal multiple access (NOMA), and physical layer
multi-casting, which aims to address multi-user interference (MUI) in
multiple-input multiple-output (MIMO) systems. In this study, we leverage the
interference management capabilities of RSMA to tackle the issue of
inter-carrier interference (ICI) in orthogonal frequency division multiplexing
(OFDM) waveform. We formulate a problem to find the optimal subcarrier and
power allocation for downlink transmission in a two-user system using RSMA and
OFDM and propose a weighted minimum mean-square error (WMMSE)-based algorithm
to obtain a solution. The sum-rate performance of the proposed OFDM-RSMA scheme
is compared with that of conventional orthogonal frequency division multiple
access (OFDMA) and OFDM-NOMA by numerical results. It is shown that the
proposed OFDM-RSMA outperforms OFDM-NOMA and OFDMA under ICI in diverse
propagation channel conditions owing to its flexible structure and robust
interference management capabilities.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:15:16 GMT""}]","2023-04-26"
"2303.14541","David Rozenberszki","David Rozenberszki, Or Litany, Angela Dai","UnScene3D: Unsupervised 3D Instance Segmentation for Indoor Scenes","Project page: https://rozdavid.github.io/unscene3d",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D instance segmentation is fundamental to geometric understanding of the
world around us. Existing methods for instance segmentation of 3D scenes rely
on supervision from expensive, manual 3D annotations. We propose UnScene3D, the
first fully unsupervised 3D learning approach for class-agnostic 3D instance
segmentation of indoor scans. UnScene3D first generates pseudo masks by
leveraging self-supervised color and geometry features to find potential object
regions. We operate on a basis of geometric oversegmentation, enabling
efficient representation and learning on high-resolution 3D data. The coarse
proposals are then refined through self-training our model on its predictions.
Our approach improves over state-of-the-art unsupervised 3D instance
segmentation methods by more than 300% Average Precision score, demonstrating
effective instance segmentation even in challenging, cluttered 3D scenes.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:15:16 GMT""}]","2023-03-28"
"2303.14542","Junaed Younus Khan","Junaed Younus Khan and Gias Uddin","Combining Contexts from Multiple Sources for Documentation-Specific Code
  Example Generation","Accepted in 30th IEEE International Conference on Software Analysis,
  Evolution and Reengineering (SANER 2023) - ERA",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Code example is a crucial part of good documentation. It helps the developers
to understand the documentation easily and use the corresponding code unit
(e.g., method) properly. However, many official documentation still lacks
(good) code example and it is one of the common documentation issues as found
by several studies. Hence in this paper, we consider automatic code example
generation for documentation, a direction less explored by the existing
research. We employ Codex, a GPT-3 based model, pre-trained on both natural and
programming languages to generate code examples from source code and
documentation given as input. Our preliminary investigation on 40 scikit-learn
methods reveals that this approach is able to generate good code examples where
72.5% code examples were executed without error (passability) and 82.5%
properly dealt with the target method and documentation (relevance). We also
find that incorporation of error logs (produced by the compiler while executing
a failed code example) in the input further improves the passability from 72.5%
to 87.5%. Thus, our investigation sets the base of documentation-specific code
example generation and warrants in-depth future studies.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:25:20 GMT""}]","2023-03-28"
"2303.14543","Yuzhou Chen","Yuzhou Chen, Yulia R. Gel","Topological Pooling on Graphs","AAAI 2023",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Graph neural networks (GNNs) have demonstrated a significant success in
various graph learning tasks, from graph classification to anomaly detection.
There recently has emerged a number of approaches adopting a graph pooling
operation within GNNs, with a goal to preserve graph attributive and structural
features during the graph representation learning. However, most existing graph
pooling operations suffer from the limitations of relying on node-wise neighbor
weighting and embedding, which leads to insufficient encoding of rich
topological structures and node attributes exhibited by real-world networks. By
invoking the machinery of persistent homology and the concept of landmarks, we
propose a novel topological pooling layer and witness complex-based topological
embedding mechanism that allow us to systematically integrate hidden
topological information at both local and global levels. Specifically, we
design new learnable local and global topological representations Wit-TopoPool
which allow us to simultaneously extract rich discriminative topological
information from graphs. Experiments on 11 diverse benchmark datasets against
18 baseline models in conjunction with graph classification tasks indicate that
Wit-TopoPool significantly outperforms all competitors across all datasets.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:30:46 GMT""}]","2023-03-28"
"2303.14544","Fatemeh Mosaiyebzadeh","Fatemeh Mosaiyebzadeh, Seyedamin Pouriyeh, Reza M. Parizi, Quan Z.
  Sheng, Meng Han, Liang Zhao, Giovanna Sannino, Daniel Mac\^edo Batista","Privacy-Enhancing Technologies in Federated Learning for the Internet of
  Healthcare Things: A Survey","15 pages, 4 figures, 5 tables",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Advancements in wearable medical devices in IoT technology are shaping the
modern healthcare system. With the emergence of the Internet of Healthcare
Things (IoHT), we are witnessing how efficient healthcare services are provided
to patients and how healthcare professionals are effectively used AI-based
models to analyze the data collected from IoHT devices for the treatment of
various diseases. To avoid privacy breaches, these data must be processed and
analyzed in compliance with the legal rules and regulations such as HIPAA and
GDPR. Federated learning is a machine leaning based approach that allows
multiple entities to collaboratively train a ML model without sharing their
data. This is particularly useful in the healthcare domain where data privacy
and security are big concerns. Even though FL addresses some privacy concerns,
there is still no formal proof of privacy guarantees for IoHT data. Privacy
Enhancing Technologies (PETs) are a set of tools and techniques that are
designed to enhance the privacy and security of online communications and data
sharing. PETs provide a range of features that help protect users' personal
information and sensitive data from unauthorized access and tracking. This
paper reviews PETs in detail and comprehensively in relation to FL in the IoHT
setting and identifies several key challenges for future research.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:34:52 GMT""}]","2023-03-28"
"2303.14545","Amitesh Sarkar","Anirban Banerjee and Amitesh Sarkar","On the spectral radius of some linear hypergraphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Here we study the spectral radii of some linear hypergraphs, that is, the
maximum moduli of the eigenvalues of their corresponding adjacency matrices. We
determine the hypertrees having the largest to seventh-largest spectral radii.
The hypertrees with the largest and the second-largest spectral radii among all
those with a given diameter are identified here. Unicyclic hypergraphs with a
fixed cycle length having the largest, the second-largest, and the
third-largest spectral radii are also determined. Furthermore, we also find
which bicyclic and tricyclic linear hypergraphs have the largest and the
second-largest spectral radii.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:53:34 GMT""}]","2023-03-28"
"2303.14546","Cody Shakespeare","Cody J. Shakespeare and Jason H. Steffen","Day 'N' Nite: Habitability of Tidally Locked Planets with Sporadic
  Rotation",,,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Tidally locked worlds provide a unique opportunity for constraining the
probable climates of certain exoplanets. They are unique in that few exoplanet
spin and obliquity states are known or will be determined in the near future:
both of which are critical in modeling climate. A recent study shows the
dynamical conditions present in the TRAPPIST-1 system make rotation and large
librations of the substellar point possible for these planets, which are
usually assumed to be tidally locked. We independently confirm the tendency for
planets in TRAPPIST-1-like systems to sporadically transition from tidally
locked libration to slow rotation using N-body simulations. We examine the
nature and frequency of these spin states to best inform energy balance models
which predict the temperature profile of the planet's surface. Our findings
show that tidally locked planets with sporadic rotation are able to be in both
long-term persistent states and chaotic states: where rapid transitions between
behaviors are present. Quasi-stable spin regimes, where the planet exhibits one
spin behavior for up to hundreds of millennia, are likely able to form stable
climate systems while the spin behavior is constant. 1D energy balance models
show that tidally locked planets with sporadic rotation around M-dwarfs will
experience a relatively small change in substellar temperature due to the lower
albedo of ice in an infrared dominant stellar spectrum. The exact effects of
large changes in temperature profiles on these planets as they rotate require
more robust climate models, like 3D global circulation models, to better
examine.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:54:14 GMT""}]","2023-03-28"
"2303.14547","G\""unther R\""udiger","G. R\""udiger and M. Schultz","The gap-size influence on the excitation of magnetorotational
  instability in cylindrical Couette flows","12 pages, 6 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The excitation conditions of the magnetorotational instability are studied
for axially unbounded Taylor-Couette flows of various gap widths between the
cylinders. The cylinders are considered as made from both perfect-conducting or
insulating material and the conducting fluid with a finite but small magnetic
Prandtl number rotates with a quasi-Keplerian velocity profile. The solutions
are optimized with respect to the wave number and the Reynolds number of the
rotation of the inner cylinder. For the axisymmetric modes we find the critical
Lundquist number of the applied axial magnetic field the lower the wider the
gap between the cylinders. A similar result is obtained for the induced cell
structure: the wider the gap the more spherical the cells are. The marginal
rotation rate of the inner cylinder -- for fixed size of the outer cylinder --
always possesses a minimum for not too wide and not too narrow gap widths. For
perfect-conducting walls the minimum lies at $r_{\rm in}\simeq 0.4$ while it is
at $r_{\rm in}\simeq 0.5$ for insulating walls where $r_{\rm in}$ is the
normalized radius of the inner cylinder. The lowest magnetic field amplitudes
to excite the instability are required for Taylor-Couette flows between
perfect-conducting cylinders with gaps corresponding to $r_{\rm in}\simeq 0.2$.
For even wider and also for very thin gaps the needed magnetic fields and
rotation frequencies are shown to become rather huge.
  Also the nonaxisymmetric modes with $|m|=1$ have been considered. Their
excitation generally requires stronger magnetic fields and higher magnetic
Reynolds numbers in comparison to those for the axisymmetric modes which is
true for wide-gap containers with $r_{\rm in} \lesssim 0.3$.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:55:45 GMT""}]","2023-03-28"
"2303.14548","Dian Chen","Dian Chen, Jie Li, Vitor Guizilini, Rares Ambrus, Adrien Gaidon","Viewpoint Equivariance for Multi-View 3D Object Detection","11 pages, 4 figures; accepted to CVPR 2023",,,,"cs.CV cs.AI cs.LG cs.RO","http://creativecommons.org/licenses/by/4.0/","  3D object detection from visual sensors is a cornerstone capability of
robotic systems. State-of-the-art methods focus on reasoning and decoding
object bounding boxes from multi-view camera input. In this work we gain
intuition from the integral role of multi-view consistency in 3D scene
understanding and geometric learning. To this end, we introduce VEDet, a novel
3D object detection framework that exploits 3D multi-view geometry to improve
localization through viewpoint awareness and equivariance. VEDet leverages a
query-based transformer architecture and encodes the 3D scene by augmenting
image features with positional encodings from their 3D perspective geometry. We
design view-conditioned queries at the output level, which enables the
generation of multiple virtual frames during training to learn viewpoint
equivariance by enforcing multi-view consistency. The multi-view geometry
injected at the input level as positional encodings and regularized at the loss
level provides rich geometric cues for 3D object detection, leading to
state-of-the-art performance on the nuScenes benchmark. The code and model are
made available at https://github.com/TRI-ML/VEDet.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:56:41 GMT""},{""version"":""v2"",""created"":""Fri, 7 Apr 2023 04:59:08 GMT""}]","2023-04-10"
"2303.14549","Wei Chen","Matheus S. M. de Sousa, Antonio L. Cruz, Wei Chen","Seeing Topological Charges by Naked Eyes","9 pages, 3 figures",,,,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The opacity of graphene is known to be approximately given by the fine
structure constant $\alpha$ times $\pi$. We point out the fact that the opacity
is roughly independent of the frequency of the light can be attributed to the
topological charge of the Dirac point. As a result, one can literally see the
topological charge by naked eyes from the opacity of graphene, and moreover it
implies that the fine structure constant is topologically protected. A similar
analysis applied to 3D topological insulators suggests that their opacity in
the infrared region is also given by $\pi\alpha$, which may be seen by naked
eyes through an infrared lens, and ideally is independent of the thickness of
the material since it is contributed solely from the topological surface
states. For 3D Dirac or Weyl semimetals, the optical absorption power is linear
to the frequency in the infrared region, with a linearity given by the fine
structure constant and the topological charge of Weyl points.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:57:27 GMT""}]","2023-03-28"
"2303.14550","Yufan Huang","Yufan Huang, C. Seshadhri, David F. Gleich","Theoretical bounds on the network community profile from low-rank
  semi-definite programming",,,,,"cs.SI math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a new connection between a technical measure called
$\mu$-conductance that arises in the study of Markov chains for sampling convex
bodies and the network community profile that characterizes size-resolved
properties of clusters and communities in social and information networks. The
idea of $\mu$-conductance is similar to the traditional graph conductance, but
disregards sets with small volume. We derive a sequence of optimization
problems including a low-rank semi-definite program from which we can derive a
lower bound on the optimal $\mu$-conductance value. These ideas give the first
theoretically sound bound on the behavior of the network community profile for
a wide range of cluster sizes. The algorithm scales up to graphs with hundreds
of thousands of nodes and we demonstrate how our framework validates the
predicted structures of real-world graphs.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:58:18 GMT""}]","2023-03-28"
"2303.14551","Zhiyue Lu","Zhongmin Zhang, Zhiyue Lu","Non-equilibrium Theoretical Framework and Universal Design Principles of
  Oscillation-Driven Catalysis",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  Traditional catalysis theory claims that catalysts speed up reactions by
introducing low activation barriers and cannot alter the thermodynamic
spontaneous reaction direction. However, if environments change rapidly,
catalysts can be driven away from stationary states and exhibit anomalous
performance. We present a geometric non-equilibrium theory and a
control-conjugate landscape to describe and explain anomalous catalytic
behaviors in rapidly oscillatory environments. Moreover, we derive a universal
design principle for engineering optimal catalytic energy landscapes to achieve
desired anomalous catalyst behaviors. Applications include but are not limited
to (1) inverting a spontaneous reaction to synthesize high-free-energy
molecules, and (2) dissipatively speeding up reactions without lowering
activation barriers. In both cases, catalysts autonomously harness energy from
non-equilibrium environments to enable such functionalities.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:00:01 GMT""}]","2023-03-28"
"2303.14552","Maciej Sypetkowski","Maciej Sypetkowski","Spatial Latent Representations in Generative Adversarial Networks for
  Image Generation",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the majority of GAN architectures, the latent space is defined as a set of
vectors of given dimensionality. Such representations are not easily
interpretable and do not capture spatial information of image content directly.
In this work, we define a family of spatial latent spaces for StyleGAN2,
capable of capturing more details and representing images that are
out-of-sample in terms of the number and arrangement of object parts, such as
an image of multiple faces or a face with more than two eyes. We propose a
method for encoding images into our spaces, together with an attribute model
capable of performing attribute editing in these spaces. We show that our
spaces are effective for image manipulation and encode semantic information
well. Our approach can be used on pre-trained generator models, and attribute
edition can be done using pre-generated direction vectors making the barrier to
entry for experimentation and use extremely low. We propose a regularization
method for optimizing latent representations, which equalizes distributions of
parts of latent spaces, making representations much closer to generated ones.
We use it for encoding images into spatial spaces to obtain significant
improvement in quality while keeping semantics and ability to use our attribute
model for edition purposes. In total, using our methods gives encoding quality
boost even as high as 30% in terms of LPIPS score comparing to standard
methods, while keeping semantics. Additionally, we propose a StyleGAN2 training
procedure on our spatial latent spaces, together with a custom spatial latent
representation distribution to make spatially closer elements in the
representation more dependent on each other than farther elements. Such
approach improves the FID score by 29% on SpaceNet, and is able to generate
consistent images of arbitrary sizes on spatially homogeneous datasets, like
satellite imagery.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:01:11 GMT""}]","2023-03-28"
"2303.14553","James P. Crutchfield","Sarah E. Marzen and Paul M. Riechers and James P. Crutchfield","Complexity-calibrated Benchmarks for Machine Learning Reveal When
  Next-Generation Reservoir Computer Predictions Succeed and Mislead","10 pages, 5 figures;
  https://csc.ucdavis.edu/~cmg/compmech/pubs/ngrc.htm",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurrent neural networks are used to forecast time series in finance,
climate, language, and from many other domains. Reservoir computers are a
particularly easily trainable form of recurrent neural network. Recently, a
""next-generation"" reservoir computer was introduced in which the memory trace
involves only a finite number of previous symbols. We explore the inherent
limitations of finite-past memory traces in this intriguing proposal. A lower
bound from Fano's inequality shows that, on highly non-Markovian processes
generated by large probabilistic state machines, next-generation reservoir
computers with reasonably long memory traces have an error probability that is
at least ~ 60% higher than the minimal attainable error probability in
predicting the next observation. More generally, it appears that popular
recurrent neural networks fall far short of optimally predicting such complex
processes. These results highlight the need for a new generation of optimized
recurrent neural network architectures. Alongside this finding, we present
concentration-of-measure results for randomly-generated but complex processes.
One conclusion is that large probabilistic state machines -- specifically,
large $\epsilon$-machines -- are key to generating challenging and
structurally-unbiased stimuli for ground-truthing recurrent neural network
architectures.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:12:26 GMT""}]","2023-03-28"
"2303.14554","Sai Mani Prudhvi Valleti","Mani Valleti, Rama k. Vasudevan, Maxim A. Ziatdinov, Sergei V. Kalinin","Deep Kernel Methods Learn Better: From Cards to Process Optimization","8 Figures, 26 pages",,,,"cs.LG cond-mat.dis-nn cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The ability of deep learning methods to perform classification and regression
tasks relies heavily on their capacity to uncover manifolds in high-dimensional
data spaces and project them into low-dimensional representation spaces. In
this study, we investigate the structure and character of the manifolds
generated by classical variational autoencoder (VAE) approaches and deep kernel
learning (DKL). In the former case, the structure of the latent space is
determined by the properties of the input data alone, while in the latter, the
latent manifold forms as a result of an active learning process that balances
the data distribution and target functionalities. We show that DKL with active
learning can produce a more compact and smooth latent space which is more
conducive to optimization compared to previously reported methods, such as the
VAE. We demonstrate this behavior using a simple cards data set and extend it
to the optimization of domain-generated trajectories in physical systems. Our
findings suggest that latent manifolds constructed through active learning have
a more beneficial structure for optimization problems, especially in
feature-rich target-poor scenarios that are common in domain sciences, such as
materials synthesis, energy storage, and molecular discovery. The jupyter
notebooks that encapsulate the complete analysis accompany the article.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:21:29 GMT""}]","2023-03-28"
"2303.14555","Sadashige Ishida","Albert Chern and Sadashige Ishida","Area formula for spherical polygons via prequantization",,,,,"math.DG math.SG","http://creativecommons.org/licenses/by/4.0/","  We present a formula for the signed area of a spherical polygon via
prequantization. In contrast to the traditional formula based on the
Gauss-Bonnet theorem that requires measuring angles, the new formula mimics
Green's theorem and is applicable to a wider range of degenerate spherical
curves and polygons.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:33:16 GMT""}]","2023-03-28"
"2303.14556","Jean Carlo Moraes","Daewon Chung, Weiyan Huang, Jean Carlo Moraes, Mar\'ia Cristina
  Pereyra and Brett D. Wick","Weighted Inequalities for $t$-Haar multipliers",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we provide necessary and sufficient conditions on a triple of
weights $(u, v, w)$ so that the $t$-Haar multipliers $T^t_{w,\sigma}, t \in
\mathbb{R}$, are uniformly (on the choice of signs $\sigma$) bounded from
$L^2(u)$ into $L^2(v)$. These dyadic operators have symbols $s(x; I) = \sigma_I
(w(x)/\langle w \rangle_I )^t$ which are functions of the space variable $x \in
\mathbb{R}$ and the frequency variable $I \in \mathcal{D}$, making them dyadic
analogues of pseudo-differential operators. Here $\mathcal{D}$ denotes the
dyadic intervals, $\sigma_I = \pm 1$, and $\langle w \rangle_I$ denotes the
integral average of $w$ on $I$. When $w\equiv 1$ we have the martingale
transform and our conditions recover the known two-weight necessary and
sufficient conditions of Nazarov, Treil and Volberg. We also show how these
conditions are simplified when $u = v$. In particular, the martingale
one-weight and the t-Haar multiplier unsigned and unweighted (corresponding to
$\sigma_I= 1$ and $u = v \equiv 1$) known results are recovered or improved. We
also obtain necessary and sufficient testing conditions of Sawyer type for the
two-weight boundedness of a single variable Haar multiplier similar to those
known for the martingale transform.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:38:49 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 12:38:11 GMT""}]","2023-03-29"
"2303.14557","Zhuoyue Lyu","Zhuoyue Lyu","Clo(o)k: A Clock That Looks","CHI '23 Human Computer Interaction Across Borders (HCIxB) Workshop
  Papers",,,,"cs.HC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  What if a clock could do more than just tell time - what if it could actually
see? This paper delves into the conceptualization, design, and construction of
a timepiece with visual perception capabilities, featuring three applications
that expand the possibilities of human-time interaction. Insights from an Open
House showcase are also shared, highlighting the unique user experiences of
this device.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:49:40 GMT""}]","2023-03-28"
"2303.14558","Sena Matsui","Sena A. Matsui (1), Tsutomu T. Takeuchi (1 and 2), Kai T. Kono (1),
  Suchetha Cooray (1) ((1) Nagoya University, (2) Institute of Statistical
  Mathematics, Japan)","Photometric Observations and Period Analysis of an SU UMa-type Dwarf
  Nova, MASTER OT J004527.52+503213.8","Accepted for publication in JAAVSO, 9 pages, 8 figures",,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  MASTER OT J004527.52+503213.8 (hereafter MASTER J004527) is a dwarf nova
discovered by the MASTER project in 2013. At 18:20 UTC on 24 October 2020,
brightening of this object was reported to vsnet-alert (24843 by Denisenko).
This was the second report of a superoutburst after its discovery. Photometric
observations were made using the 23.5-cm Schmidt-Cassegrain telescope at
Okayama University of Science observatory soon after the alert through 4
November 2020. In this work, we present the photometric data from our
observation, and the analysis of the light curves of MASTER J004527 during the
2020 outburst. We propose a method to determine the period of superhumps by
polynomial fitting, which can be applied to a light curve with many missing
data. In addition to our own data, we incorporate other all sky survey data of
the outburst to better understand the properties of the superhumps. Based on
our observations, we conclude that MASTER J004527 is an SU UMa-type dwarf nova,
since no early superhumps occurred.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:49:40 GMT""}]","2023-03-28"
"2303.14559","Hugo Luiz Mariano","Kaique Matias de Andrade Roberto, Hugo Rafael de Oliveira Ribeiro,
  Hugo Luiz Mariano, Kaique Ribeiro Prates Santos","Linear Systems, Matrices and Vector Spaces over Superfields","arXiv admin note: substantial text overlap with arXiv:2208.08537,
  arXiv:2210.03784",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by some recent developments in abstract theories of quadratic
forms, we start to develop in this work an expansion of Linear Algebra to
multivalued structures (a multialgebraic structure is essentially an algebraic
structure but endowed with some multivalued operations).
  We introduce and study matrices and determinants over a commutative
superrings (roughly, a ring where the sum and product are multivalued) and
study linear systems and vector spaces over superfields. As an application, we
obtain a fundamental result to the development of a theory of algebraic
extensions of superfields.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:54:40 GMT""}]","2023-03-28"
"2303.14560","Wenpin Tang","Wenpin Tang and Yuming Paul Zhang","The convergence rate of vanishing viscosity approximations for mean
  field games","32 pages",,,,"math.AP math.OC math.PR","http://creativecommons.org/licenses/by/4.0/","  Motivated by numerical challenges in first-order mean field games (MFGs) and
the weak noise theory for the Kardar-Parisi-Zhang equation, we consider the
problem of vanishing viscosity approximations for MFGs. We provide the first
results on the convergence rate to the vanishing viscosity limit in mean field
games, with a focus on the dimension dependence of the rate exponent. Two cases
are studied: MFGs with a local coupling and those with a nonlocal, regularizing
coupling. In the former case, we use a duality approach and our results suggest
that there may be a phase transition in the dimension dependence of vanishing
viscosity approximations in terms of the growth of the Hamiltonian and the
local coupling. In the latter case, we rely on the regularity analysis of the
solution, and derive a faster rate compared to MFGs with a local coupling. A
list of open problems are presented.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:02:48 GMT""},{""version"":""v2"",""created"":""Sun, 2 Apr 2023 15:32:16 GMT""}]","2023-04-04"
"2303.14561","Barnab\'as Szab\'o","Barnab\'as Szab\'o","High moments of theta functions and character sums",,,,,"math.NT","http://creativecommons.org/licenses/by-sa/4.0/","  Assuming the Generalised Riemann Hypothesis, we prove a sharp upper bound on
moments of shifted Dirichlet $L$-functions. We use this to obtain conditional
upper bounds on high moments of theta functions. Both of these results
strengthen theorems of Munsch, who proved almost sharp upper bounds for these
quantities. The main new ingredient of our proof comes from a paper of Harper,
who showed the related result $\int_{0}^T |\zeta(1/2+it)|^{2k} \ll_k T(\log
T)^{k^2} $ for all $k\geq 0$ under the Riemann Hypothesis. Finally, we obtain a
sharp conditional upper bound on high moments of character sums of arbitrary
length.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:06:05 GMT""}]","2023-03-28"
"2303.14562","Daniel Nakhimovich","Daniel Nakhimovich, Yinglong Miao, Kostas E. Bekris","Resolution Complete In-Place Object Retrieval given Known Object Models","7 pages, 4 figures, Accepted to IEEE International Conference on
  Robotics and Automation (ICRA) 2023",,,,"cs.RO","http://creativecommons.org/licenses/by-sa/4.0/","  This work proposes a robot task planning framework for retrieving a target
object in a confined workspace among multiple stacked objects that obstruct the
target. The robot can use prehensile picking and in-workspace placing actions.
The method assumes access to 3D models for the visible objects in the scene.
The key contribution is in achieving desirable properties, i.e., to provide (a)
safety, by avoiding collisions with sensed obstacles, objects, and occluded
regions, and (b) resolution completeness (RC) - or probabilistic completeness
(PC) depending on implementation - which indicates a solution will be
eventually found (if it exists) as the resolution of algorithmic parameters
increases. A heuristic variant of the basic RC algorithm is also proposed to
solve the task more efficiently while retaining the desirable properties.
Simulation results compare using random picking and placing operations against
the basic RC algorithm that reasons about object dependency as well as its
heuristic variant. The success rate is higher for the RC approaches given the
same amount of time. The heuristic variant is able to solve the problem even
more efficiently than the basic approach. The integration of the RC algorithm
with perception, where an RGB-D sensor detects the objects as they are being
moved, enables real robot demonstrations of safely retrieving target objects
from a cluttered shelf.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:08:09 GMT""}]","2023-03-28"
"2303.14563","Berikbol Torebek","Meiirkhan B. Borikhanov, Berikbol T. Torebek","On an inhomogeneous exterior Robin problems with critical nonlinearities","16 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper studies the large-time behavior of solutions to the Robin problem
for PDEs with critical nonlinearities. For the considered problems,
nonexistence results are obtained, which complements the interesting recent
results by Ikeda et al. [J. Differential Equations, 269 (2020), no. 1,
563-594], where critical cases were left open. Moreover, our results provide
partially answers to some other open questions previously posed by Zhang [Proc.
Roy. Soc. Edinburgh Sect. A, 131 (2001), no. 2, 451-475] and Jleli-Samet
[Nonlinear Anal., 178 (2019), 348-365].
  The proof of main results is based on methods of nonlinear capacity estimates
specifically adapted to the nature of the exterior domain. Furthermore, the
difference in our approach lies in the fact that we are considering a class of
test functions with logarithmic arguments.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:10:46 GMT""}]","2023-03-28"
"2303.14564","Songyuan Zhang","Songyuan Zhang, Yumeng Xiu, Guannan Qu, Chuchu Fan","Compositional Neural Certificates for Networked Dynamical Systems","25 pages, 8 figures; Accepted by 5th Annual Learning for Dynamics &
  Control Conference (L4DC) 2023",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Developing stable controllers for large-scale networked dynamical systems is
crucial but has long been challenging due to two key obstacles: certifiability
and scalability. In this paper, we present a general framework to solve these
challenges using compositional neural certificates based on ISS (Input-to-State
Stability) Lyapunov functions. Specifically, we treat a large networked
dynamical system as an interconnection of smaller subsystems and develop
methods that can find each subsystem a decentralized controller and an ISS
Lyapunov function; the latter can be collectively composed to prove the global
stability of the system. To ensure the scalability of our approach, we develop
generalizable and robust ISS Lyapunov functions where a single function can be
used across different subsystems and the certificates we produced for small
systems can be generalized to be used on large systems with similar structures.
We encode both ISS Lyapunov functions and controllers as neural networks and
propose a novel training methodology to handle the logic in ISS Lyapunov
conditions that encodes the interconnection with neighboring subsystems. We
demonstrate our approach in systems including Platoon, Drone formation control,
and Power systems. Experimental results show that our framework can reduce the
tracking error up to 75% compared with RL algorithms when applied to
large-scale networked systems.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:18:58 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 14:52:40 GMT""},{""version"":""v3"",""created"":""Tue, 11 Apr 2023 19:00:00 GMT""}]","2023-04-13"
"2303.14565","Chun-Tso Tsai","Chun-Tso Tsai, Seyed Mohammadhossein Tabatabaee, St\'ephan Plassart,
  Jean-Yves Le Boudec","Saihu: A Common Interface of Worst-Case Delay Analysis Tools for
  Time-Sensitive Networks",,,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Time-sensitive networks, as in the context of IEEE-TSN and IETF-Detnet,
require bounds on worst-case delays. Various network analysis tools compute
such bounds, but these tools are based on different methods and provide
different valid delay bounds. Hence, it is essential to identify the best,
smallest bounds. As of today, users must implement multiple pieces of code with
different syntaxes for each tool, as each tool is implemented by different
groups and uses different programming languages and syntaxes. This results in a
significant amount of mechanical actions from users and being error-prone. In
this paper, we present Saihu, a Python interface that integrates xTFA (supports
TFA), DiscoDNC (supports LUDB, PMOO, SFA), and Panco (supports PLP and ELP),
the three most frequently used worst-case network analysis tools. Saihu
provides a general interface that enables defining the networks in a single XML
or JSON file and executing all tools simultaneously without any adjustment for
individual tools. Saihu also exports analysis results into formatted reports
automatically, and it offers automatic network generation for certain types of
networks. Therefore, with its straightforward syntax and ease of execution,
Saihu reduces the burden on users and makes it a valuable tool for anyone
working with time-sensitive networks. Lastly, we modularize the package to
incorporate more tools in the future.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:19:17 GMT""}]","2023-03-28"
"2303.14566","Hanlin Mo","Hanlin Mo, Hongxiang Hao, Guoying Zhao","Image Moment Invariants to Rotational Motion Blur",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rotational motion blur caused by the circular motion of the camera or/and
object is common in life. Identifying objects from images affected by
rotational motion blur is challenging because this image degradation severely
impacts image quality. Therefore, it is meaningful to develop image invariant
features under rotational motion blur and then use them in practical tasks,
such as object classification and template matching. This paper proposes a
novel method to generate image moment invariants under general rotational
motion blur and provides some instances. Further, we achieve their invariance
to similarity transform. To the best of our knowledge, this is the first time
that moment invariants for rotational motion blur have been proposed in the
literature. We conduct extensive experiments on various image datasets
disturbed by similarity transform and rotational motion blur to test these
invariants' numerical stability and robustness to image noise. We also
demonstrate their performance in image classification and handwritten digit
recognition. Current state-of-the-art blur moment invariants and deep neural
networks are chosen for comparison. Our results show that the moment invariants
proposed in this paper significantly outperform other features in various
tasks.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:23:42 GMT""}]","2023-03-28"
"2303.14567","Nestor Sanchez Dr.","Benjamin Arroquia-Cuadros, Nestor Sanchez, Vicent Gomez, Pere Blay,
  Vicent Martinez-Badenes and Lorena Nieves-Seoane","Photometric classification of QSOs from ALHAMBRA survey using random
  forest","7 pages including 6 figures and 3 tables. Accepted for publication in
  Astronomy and Astrophysics","A&A 673, A48 (2023)","10.1051/0004-6361/202245531",,"astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Context: Given the current big data era in Astronomy, machine learning based
methods have being applied over the last years to identify or classify objects
like quasars, galaxies and stars from full sky photometric surveys. Aims: Here
we systematically evaluate the performance of Random Forests (RF) in
classifying quasars using either magnitudes or colours, both from broad and
narrow-band filters, as features. Methods: The working data consists of
photometry from the ALHAMBRA Gold Catalogue that we cross-matched with the
Sloan Digital Sky Survey (SDSS) and with the Million Quasars Catalogue
(Milliquas) for objects labelled as quasars, galaxies or stars. A RF classifier
is trained and tested to evaluate the effect on final accuracy and precision of
varying the free parameters and the effect of using narrow or broad-band
magnitudes or colours. Results: Best performances of the classifier yielded
global accuracy and quasar precision around 0.9. Varying model free parameters
(within reasonable ranges of values) has no significant effects on the final
classification. Using colours instead of magnitudes as features results in
better performances of the classifier, especially using colours from the
ALHAMBRA Survey. Colours that contribute the most to the classification are
those containing the near-infrared $JHK$ bands.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:30:27 GMT""}]","2023-05-03"
"2303.14568","Nathaniel Bastian PhD","Alexander M. Berenbeim, Iain J. Cruickshank, Susmit Jha, Robert H.
  Thomson, and Nathaniel D. Bastian","Measuring Classification Decision Certainty and Doubt","4 pages",,,,"stat.ML cs.AI cs.LG math.DG math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantitative characterizations and estimations of uncertainty are of
fundamental importance in optimization and decision-making processes. Herein,
we propose intuitive scores, which we call certainty and doubt, that can be
used in both a Bayesian and frequentist framework to assess and compare the
quality and uncertainty of predictions in (multi-)classification decision
machine learning problems.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:31:41 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 01:27:51 GMT""}]","2023-03-29"
"2303.14569","Artsiom Sanakoyeu","Albert Pumarola, Artsiom Sanakoyeu, Lior Yariv, Ali Thabet, Yaron
  Lipman","VisCo Grids: Surface Reconstruction with Viscosity and Coarea Grids","Published in NeurIPS 2022",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surface reconstruction has been seeing a lot of progress lately by utilizing
Implicit Neural Representations (INRs). Despite their success, INRs often
introduce hard to control inductive bias (i.e., the solution surface can
exhibit unexplainable behaviours), have costly inference, and are slow to
train. The goal of this work is to show that replacing neural networks with
simple grid functions, along with two novel geometric priors achieve comparable
results to INRs, with instant inference, and improved training times. To that
end we introduce VisCo Grids: a grid-based surface reconstruction method
incorporating Viscosity and Coarea priors. Intuitively, the Viscosity prior
replaces the smoothness inductive bias of INRs, while the Coarea favors a
minimal area solution. Experimenting with VisCo Grids on a standard
reconstruction baseline provided comparable results to the best performing INRs
on this dataset.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:32:17 GMT""}]","2023-03-28"
"2303.14570","Arvind Gupta","Arvind F. Gupta, Jonathan M. Jackson, Guillaume Hebrard, Andrea S.
  Lin, Keivan G. Stassun, Jiayin Dong, Steven Villanueva, Diana Dragomir,
  Suvrath Mahadevan, Jason T. Wright, Jose Manuel Almenara, Cullen H. Blake,
  Isabelle Boisse, Pia Cortes-Zuleta, Paul A. Dalba, Rodrigo F. Diaz, Eric B.
  Ford, Thierry Forveille, Robert Gagliano, Samuel P. Halverson, Neda Heidari,
  Shubham Kanodia, Flavien Kiefer, David W. Latham, Michael W. McElwain, Ismael
  Mireles, Joshua Pepper, George R. Ricker, Paul Robertson, Arpita Roy, Martin
  Schlecker, Christian Schwab, Sara Seager, Avi Shporer, Gudmundur Stefansson,
  Ryan C. Terrien, Eric B. Ting, Joshua N. Winn, Allison Youngblood","A High-Eccentricity Warm Jupiter Orbiting TOI-4127",,,"10.3847/1538-3881/accb9b",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We report the discovery of TOI-4127 b, a transiting, Jupiter-sized exoplanet
on a long-period ($P = 56.39879^{+0.00010}_{-0.00010}$ d), high-eccentricity
orbit around a late F-type dwarf star. This warm Jupiter was first detected and
identified as a promising candidate from a search for single-transit signals in
TESS Sector 20 data, and later characterized as a planet following two
subsequent transits (TESS Sectors 26 and 53) and follow-up ground-based RV
observations with the NEID and SOPHIE spectrographs. We jointly fit the transit
and RV data to constrain the physical ($R_p = 1.096^{+0.039}_{-0.032} R_J$,
$M_p = 2.30^{+0.11}_{-0.11} M_J$) and orbital parameters of the exoplanet.
Given its high orbital eccentricity ($e=0.7471^{+0.0078}_{-0.0086}$), TOI-4127
b is a compelling candidate for studies of warm Jupiter populations and of hot
Jupiter formation pathways. We show that the present periastron separation of
TOI-4127 b is too large for high-eccentricity tidal migration to circularize
its orbit, and that TOI-4127 b is unlikely to be a hot Jupiter progenitor
unless it is undergoing angular momentum exchange with an undetected outer
companion. Although we find no evidence for an external companion, the
available observational data are insufficient to rule out the presence of a
perturber that can excite eccentricity oscillations and facilitate tidal
migration.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:40:23 GMT""}]","2023-05-17"
"2303.14571","Arvind Gupta","Arvind F. Gupta and Megan Bedell","Fishing for Planets: A Comparative Analysis of EPRV Survey Performance
  in the Presence of Correlated Noise","24 Pages, 11 Figures",,,,"astro-ph.EP astro-ph.IM astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With dedicated exoplanet surveys underway for multiple extreme precision
radial velocity (EPRV) instruments, the near-future prospects of RV exoplanet
science are promising. These surveys' generous time allocations are expected to
facilitate the discovery of Earth analogs around bright, nearby Sun-like stars.
But survey success will depend critically on the choice of observing strategy,
which will determine the survey's ability to mitigate known sources of noise
and extract low-amplitude exoplanet signals. Here, we present an analysis of
the Fisher information content of simulated EPRV surveys, accounting for the
most recent advances in our understanding of stellar variability on both short
and long timescales (i.e., oscillations and granulation within individual
nights, and activity-induced variations across multiple nights). In this
analysis, we capture the correlated nature of stellar variability by
parameterizing these signals with Gaussian Process kernels. We describe the
underlying simulation framework as well as the physical interpretation of the
Fisher information content, and we evaluate the efficacy of EPRV survey
strategies that have been presented in the literature. We explore and compare
strategies for scheduling observations over various timescales and we make
recommendations to optimize survey performance for the detection of Earth-like
exoplanets.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:40:25 GMT""}]","2023-03-28"
"2303.14572","Yinzhan Xu","Timothy M. Chan, Virginia Vassilevska Williams, Yinzhan Xu","Fredman's Trick Meets Dominance Product: Fine-Grained Complexity of
  Unweighted APSP, 3SUM Counting, and More","To appear at STOC'23",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we carefully combine Fredman's trick [SICOMP'76] and
Matou\v{s}ek's approach for dominance product [IPL'91] to obtain powerful
results in fine-grained complexity:
  - Under the hypothesis that APSP for undirected graphs with edge weights in
$\{1, 2, \ldots, n\}$ requires $n^{3-o(1)}$ time (when $\omega=2$), we show a
variety of conditional lower bounds, including an $n^{7/3-o(1)}$ lower bound
for unweighted directed APSP and an $n^{2.2-o(1)}$ lower bound for computing
the Minimum Witness Product between two $n \times n$ Boolean matrices, even if
$\omega=2$, improving upon their trivial $n^2$ lower bounds. Our techniques can
also be used to reduce the unweighted directed APSP problem to other problems.
In particular, we show that (when $\omega = 2$), if unweighted directed APSP
requires $n^{2.5-o(1)}$ time, then Minimum Witness Product requires
$n^{7/3-o(1)}$ time.
  - We show that, surprisingly, many central problems in fine-grained
complexity are equivalent to their natural counting versions. In particular, we
show that Min-Plus Product and Exact Triangle are subcubically equivalent to
their counting versions, and 3SUM is subquadratically equivalent to its
counting version.
  - We obtain new algorithms using new variants of the Balog-Szemer\'edi-Gowers
theorem from additive combinatorics. For example, we get an $O(n^{3.83})$ time
deterministic algorithm for exactly counting the number of shortest paths in an
arbitrary weighted graph, improving the textbook $\widetilde{O}(n^{4})$ time
algorithm. We also get faster algorithms for 3SUM in preprocessed universes,
and deterministic algorithms for 3SUM on monotone sets in $\{1, 2, \ldots,
n\}^d$.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:54:03 GMT""}]","2023-03-28"
"2303.14573","Anees Peringal","Anees Peringal, Mohamad Chehadeh, Igor Boiko, Yahya Zweiri","Relay-based identification of Aerodynamic and Delay Sensor Dynamics with
  applications for Unmanned Aerial Vehicles","9 pages, 5 figures, This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we present a real-time system identification method based on
relay feedback testing with applications to multirotor unmanned aerial
vehicles. The proposed identification method provides an alternative to the
expensive lab testing of certain UAV dynamic parameters. Moreover, it has the
advantage of identifying the parameters that get changed throughout the
operation of the UAV, which requires onboard identification methods. The
modified relay feedback test (MRFT) is used to generate stable limit cycles at
frequency points that reveal the underlying UAV dynamics. The locus of the
perturbed relay system (LPRS) is used to predict the exact amplitude and
frequency of these limit cycles. Real-time identification is achieved by using
the homogeneity properties of the MRFT and the LPRS which are proven in this
paper. The proposed identification method was tested experimentally to estimate
the aerodynamic parameters as well as the onboard sensor's time delay
parameters. The MRFT testing takes a few seconds to perform, and the
identification computations take an average of 0.2 seconds to complete in
modern embedded computers. The proposed identification method is compared
against state-of-the-art alternatives. Advantages in identification accuracy
and quantification of uncertainty in estimated parameters are shown.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 22:06:29 GMT""}]","2023-03-28"
"2303.14574","Jean-Philippe Nicolas","Jack Borthwick, Eric Gourgoulhon, Jean-Philippe Nicolas","Peeling at extreme black hole horizons","33 pages, 3 figures",,,,"gr-qc math-ph math.AP math.MP","http://creativecommons.org/licenses/by/4.0/","  The starting point of this work was an intriguing similarity between the
behaviour of fields near a degenerate horizon and near the infinity of an
asymptotically flat spacetime, as revealed by the scattering theory for Dirac
fields in the ``exterior'' region of the extreme Kerr - de Sitter black hole,
developed by one of the authors (JB). However, in that situation, the
comparison was somewhat clouded by some of the analytical techniques used in
intermediate steps of the proof. The aim of the present work is to clarify the
comparison further by studying instead the peeling behaviour of solutions to
the wave equation at an extremal horizon. We focus first on the extreme
Reissner-Nordstr\""om black hole, for which the Couch-Torrence inversion (a
global conformal isometry that exchanges the horizon and infinity) makes the
analogy explicit. Then, we explore more general spherically symmetric
situations using the Couch-Torrence inversion outside of its natural context.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 22:09:36 GMT""}]","2023-03-28"
"2303.14575","Santosh Lohakare","Santosh V Lohakare and Krishna Rathore and B. Mishra","Observational constrained F(R, G) gravity cosmological model and the
  dynamical system analysis","13 pages, 6 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The geometrical and dynamical parameters of the F(R, G) gravity cosmological
model are constrained through the cosmological data sets. The functional form
of F(R, G) involves the square Ricci scalar and the higher power of the
Gauss-Bonnet invariant. The observed value of the free parameters in the
expression of H(z), the Hubble parameter, indicates a different phase of the
evolution of the Universe. In all the data sets, the early deceleration and
late time acceleration behavior of the Universe has been observed. We develop a
set of dynamical equations for a given physical system and find the numerical
solutions, along with phase-space solutions, and the stability of individual
critical points. We also discuss the asymptotic behavior of the critical points
of the system.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 22:18:59 GMT""}]","2023-03-28"
"2303.14576","Cheng Zhang","Cheng Zhang","Automatic Generation of Multiple-Choice Questions","thesis",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Creating multiple-choice questions to assess reading comprehension of a given
article involves generating question-answer pairs (QAPs) and adequate
distractors. We present two methods to tackle the challenge of QAP generations:
(1) A deep-learning-based end-to-end question generation system based on T5
Transformer with Preprocessing and Postprocessing Pipelines (TP3). We use the
finetuned T5 model for our downstream task of question generation and improve
accuracy using a combination of various NLP tools and algorithms in
preprocessing and postprocessing to select appropriate answers and filter
undesirable questions. (2) A sequence-learning-based scheme to generate
adequate QAPs via meta-sequence representations of sentences. A meta-sequence
is a sequence of vectors comprising semantic and syntactic tags. we devise a
scheme called MetaQA to learn meta sequences from training data to form pairs
of a meta sequence for a declarative sentence and a corresponding interrogative
sentence. The TP3 works well on unseen data, which is complemented by MetaQA.
Both methods can generate well-formed and grammatically correct questions.
Moreover, we present a novel approach to automatically generate adequate
distractors for a given QAP. The method is a combination of part-of-speech
tagging, named-entity tagging, semantic-role labeling, regular expressions,
domain knowledge bases, word embeddings, word edit distance, WordNet, and other
algorithms.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 22:45:54 GMT""}]","2023-03-28"
"2303.14577","Jan Hubi\v{c}ka","Tristan Bice, No\'e de Rancourt, Jan Hubi\v{c}ka, Mat\v{e}j
  Kone\v{c}n\'y","Big Ramsey degrees in the metric setting","6 pages; extended abstract",,,,"math.FA cs.DM math.CO math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Oscillation stability is an important concept in Banach space theory which
happens to be closely connected to discrete Ramsey theory. For example, Gowers
proved oscillation stability for the Banach space $c_0$ using his now famous
Ramsey theorem for $\mathrm{FIN}_k$ as the key ingredient. We develop the
theory behind this connection and introduce the notion of compact big Ramsey
degrees, extending the theory of (discrete) big Ramsey degrees. We then prove
existence of compact big Ramsey degrees for the Banach space $\ell_\infty$ and
the Urysohn sphere, with an explicit characterization in the case of
$\ell_\infty$.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 22:47:16 GMT""}]","2023-03-28"
"2303.14578","Godwin Osabutey","Pierluigi Contucci, Emanuele Mingione, Godwin Osabutey","Limit theorems for the cubic mean-field Ising model",,,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a mean-field spin model with three- and two-body interactions. The
equilibrium measure for large volumes is shown to have three pure states, the
phases of the model. They include the two with opposite magnetization and an
unpolarized one with zero magnetization, merging at the critical point. We
prove that the central limit theorem holds for a suitably rescaled
magnetization, while its violation with the typical quartic behavior appears at
the critical point.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 22:47:37 GMT""}]","2023-03-28"
"2303.14579","Thomas Finn Lidbetter","Thomas F. Lidbetter","Improved Bound for the Gerver-Ramsey Collinearity Problem","22 pages, 4 figures",,,,"math.CO cs.FL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $S$ be a finite subset of $\mathbb{Z}^n$. A vector sequence
$(\mathbf{z}_i)$ is an $S$-walk if and only if $\mathbf{z}_{i+1} -
\mathbf{z}_i$ is an element of $S$ for all $i$. Gerver and Ramsey showed in
1979 that for $S\subset \mathbb{Z}^3$ there exists an infinite $S$-walk in
which no $5^{11} + 1=48{\small,}828{\small,}126$ points are collinear. Here, we
use the same general approach, but with the aid of a computer search, to
improve the bound to $189$.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:00:04 GMT""},{""version"":""v2"",""created"":""Fri, 7 Apr 2023 22:32:55 GMT""}]","2023-04-11"
"2303.14580","Yidong Chen","Yidong Chen and Marius Junge","Noncommutative Poisson Random Measure and Its Applications",,,,,"math.OA hep-th math-ph math.MP math.PR math.QA","http://creativecommons.org/licenses/by/4.0/","  We introduce a noncommutative Poisson random measure on a von Neumann
algebra. This is a noncommutative generalization of the classical Poisson
random measure. We call this construction Poissonization. Poissonization is a
functor from the category of von Neumann algebras with normal semifinite
faithful weights to the category of von Neumann algebras with normal faithful
states. Poissonization is a natural adaptation of the second quantization to
the context of von Neumann algebras. The construction is compatible with normal
(weight-preserving) homomorphisms and unital normal completely positive
(weight-preserving) maps. We present two main applications of Poissonization.
First Poissonization provides a new framework to construct algebraic quantum
field theories that are not generalized free field theories. Second
Poissonization permits straight-forward calculations of quantum relative
entropies (and other quantum information quantities) in the case of type III
von Neumann algebras.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:06:21 GMT""}]","2023-03-28"
"2303.14581","Joseph Cohen","Joseph Cohen, Xun Huan, Jun Ni","Shapley-based Explainable AI for Clustering Applications in Fault
  Diagnosis and Prognosis","23 pages with 8 figures",,,,"cs.LG cs.SY eess.SP eess.SY","http://creativecommons.org/licenses/by/4.0/","  Data-driven artificial intelligence models require explainability in
intelligent manufacturing to streamline adoption and trust in modern industry.
However, recently developed explainable artificial intelligence (XAI)
techniques that estimate feature contributions on a model-agnostic level such
as SHapley Additive exPlanations (SHAP) have not yet been evaluated for
semi-supervised fault diagnosis and prognosis problems characterized by class
imbalance and weakly labeled datasets. This paper explores the potential of
utilizing Shapley values for a new clustering framework compatible with
semi-supervised learning problems, loosening the strict supervision requirement
of current XAI techniques. This broad methodology is validated on two case
studies: a heatmap image dataset obtained from a semiconductor manufacturing
process featuring class imbalance, and a benchmark dataset utilized in the 2021
Prognostics and Health Management (PHM) Data Challenge. Semi-supervised
clustering based on Shapley values significantly improves upon clustering
quality compared to the fully unsupervised case, deriving information-dense and
meaningful clusters that relate to underlying fault diagnosis model
predictions. These clusters can also be characterized by high-precision
decision rules in terms of original feature values, as demonstrated in the
second case study. The rules, limited to 1-2 terms utilizing original feature
scales, describe 12 out of the 16 derived equipment failure clusters with
precision exceeding 0.85, showcasing the promising utility of the explainable
clustering framework for intelligent manufacturing applications.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:13:11 GMT""}]","2023-03-28"
"2303.14582","Hongyang Zhang","Dongyue Li, Huy L. Nguyen, and Hongyang R. Zhang","Identification of Negative Transfers in Multitask Learning Using
  Surrogate Models","30 pages, 7 figures, 7 tables. Published in Transactions on Machine
  Learning Research, March 2023",,,,"cs.LG cs.AI cs.CL stat.ML","http://creativecommons.org/licenses/by/4.0/","  Multitask learning is widely used in practice to train a low-resource target
task by augmenting it with multiple related source tasks. Yet, naively
combining all the source tasks with a target task does not always improve the
prediction performance for the target task due to negative transfers. Thus, a
critical problem in multitask learning is identifying subsets of source tasks
that would benefit the target task. This problem is computationally challenging
since the number of subsets grows exponentially with the number of source
tasks; efficient heuristics for subset selection does not always capture the
relationship between task subsets and multitask learning performances. In this
paper, we introduce an efficient procedure to address this problem via
surrogate modeling. In surrogate modeling, we sample (random) subsets of source
tasks and precompute their multitask learning performances; Then, we
approximate the precomputed performances with a linear regression model that
can also be used to predict the multitask performance of unseen task subsets.
We show theoretically and empirically that fitting this model only requires
sampling linearly many subsets in the number of source tasks. The fitted model
provides a relevance score between each source task and the target task; We use
the relevance scores to perform subset selection for multitask learning by
thresholding. Through extensive experiments, we show that our approach predicts
negative transfers from multiple source tasks to target tasks much more
accurately than existing task affinity measures. Additionally, we demonstrate
that for five weak supervision datasets, our approach consistently improves
upon existing optimization methods for multi-task learning.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:16:11 GMT""}]","2023-03-28"
"2303.14583","Lingyun Ding","Lingyun Ding","Shear dispersion of multispecies electrolyte solutions in the channel
  domain",,,,,"physics.flu-dyn math.AP physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In multispecies electrolyte solutions, even in the absence of an external
electric field, differences in ion diffusivities induce an electric potential
and generate additional fluxes for each species. This electro-diffusion process
is well-described by the advection-Nernst-Planck equation. This study aims to
analyze the long-time behavior of the governing equation under the
electroneutrality and zero current conditions and investigate how the
diffusion-induced electric potential and the shear flow enhance the effective
diffusion coefficients of each species in channel domains. To achieve this
goal, the homogenization method was used to derive a reduced model of the
advection-Nernst-Planck equation in the channel domain. There are several
interesting properties of the effective equation. First, it is a generalization
of the Taylor dispersion, with a nonlinear diffusion tensor replacing the
scalar diffusion coefficient. Second, the effective equation reveals that the
system without the flow is asymptotically equivalent to the system with a
strong flow and scaled physical parameters. Furthermore, when the background
concentration is much greater than the perturbed concentration, the effective
equation reduces to a multidimensional diffusion equation, consistent with the
classical Taylor dispersion theory. However, for zero background concentration,
the ion-electric interaction results in several phenomena don't present in the
advection-diffusion equation, including upstream migration of some species,
spontaneous separation of ions, and non-monotonic dependence of the effective
diffusivity on P\'eclet numbers. Last, the dependence of effective diffusivity
on concentration and ion diffusivity suggests a method to infer the
concentration ratio of each component and ion diffusivity by measuring the
effective diffusivity.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:20:06 GMT""}]","2023-03-28"
"2303.14584","Phani Krishna Uppala","Phani Krishna Uppala, Abhishek Bamotra, Shriti Priya, Vaidehi Joshi","Learning video embedding space with Natural Language Supervision",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The recent success of the CLIP model has shown its potential to be applied to
a wide range of vision and language tasks. However this only establishes
embedding space relationship of language to images, not to the video domain. In
this paper, we propose a novel approach to map video embedding space to natural
langugage. We propose a two-stage approach that first extracts visual features
from each frame of a video using a pre-trained CNN, and then uses the CLIP
model to encode the visual features for the video domain, along with the
corresponding text descriptions. We evaluate our method on two benchmark
datasets, UCF101 and HMDB51, and achieve state-of-the-art performance on both
tasks.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:24:57 GMT""},{""version"":""v2"",""created"":""Sat, 8 Apr 2023 02:44:20 GMT""}]","2023-04-11"
"2303.14585","Yizhi Wang","Yuqing Wang, Yizhi Wang, Longhui Yu, Yuesheng Zhu, Zhouhui Lian","DeepVecFont-v2: Exploiting Transformers to Synthesize Vector Fonts with
  Higher Quality","Accepted by CVPR 2023. Code:
  https://github.com/yizhiwang96/deepvecfont-v2",,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vector font synthesis is a challenging and ongoing problem in the fields of
Computer Vision and Computer Graphics. The recently-proposed DeepVecFont
achieved state-of-the-art performance by exploiting information of both the
image and sequence modalities of vector fonts. However, it has limited
capability for handling long sequence data and heavily relies on an
image-guided outline refinement post-processing. Thus, vector glyphs
synthesized by DeepVecFont still often contain some distortions and artifacts
and cannot rival human-designed results. To address the above problems, this
paper proposes an enhanced version of DeepVecFont mainly by making the
following three novel technical contributions. First, we adopt Transformers
instead of RNNs to process sequential data and design a relaxation
representation for vector outlines, markedly improving the model's capability
and stability of synthesizing long and complex outlines. Second, we propose to
sample auxiliary points in addition to control points to precisely align the
generated and target B\'ezier curves or lines. Finally, to alleviate error
accumulation in the sequential generation process, we develop a context-based
self-refinement module based on another Transformer-based decoder to remove
artifacts in the initially synthesized glyphs. Both qualitative and
quantitative results demonstrate that the proposed method effectively resolves
those intrinsic problems of the original DeepVecFont and outperforms existing
approaches in generating English and Chinese vector fonts with complicated
structures and diverse styles.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:28:19 GMT""}]","2023-03-28"
"2303.14586","Feng Long","Feng Long, Bin B. Ren, Nicole L. Wallack, Daniel Harsono, Gregory J.
  Herczeg, Paola Pinilla, Dimitri Mawet, Michael C. Liu, Sean M. Andrews,
  Xue-Ning Bai, Sylvie Cabrit, Lucas A. Cieza, Doug Johnstone, Jarron M.
  Leisenring, Giuseppe Lodato, Yao Liu, Carlo F. Manara, Gijs D. Mulders,
  Enrico Ragusa, Steph Sallum, Yangfan Shi, Marco Tazzari, Taichi Uyama, Kevin
  Wagner, David J. Wilner, Jerry W. Xuan","A Large Double-ring Disk around the Taurus M Dwarf J04124068+2438157","15 pages, 5 figures. Accepted for publication in ApJ",,"10.3847/1538-4357/acc843",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Planet formation imprints signatures on the physical structures of disks. In
this paper, we present high-resolution ($\sim$50 mas, 8 au) Atacama Large
Millimeter/submillimeter Array (ALMA) observations of 1.3 mm dust continuum and
CO line emission toward the disk around the M3.5 star 2MASS J04124068+2438157.
The dust disk consists only of two narrow rings at radial distances of 0.47 and
0.78 arcsec ($\sim$70 and 116 au), with Gaussian $\sigma$ widths of 5.6 and 8.5
au, respectively. The width of the outer ring is smaller than the estimated
pressure scale height by $\sim25\%$, suggesting dust trapping in a radial
pressure bump. The dust disk size, set by the location of the outermost ring,
is significantly larger (by $3\sigma$) than other disks with similar millimeter
luminosity, which can be explained by an early formation of local pressure bump
to stop radial drift of millimeter dust grains. After considering the disk's
physical structure and accretion properties, we prefer planet--disk interaction
over dead zone or photoevaporation models to explain the observed dust disk
morphology. We carry out high-contrast imaging at $L'$ band using Keck/NIRC2 to
search for potential young planets, but do not identify any source above
$5\sigma$. Within the dust gap between the two rings, we reach a contrast level
of $\sim$7 mag, constraining the possible planet below $\sim$2--4 $M_{\rm
Jup}$. Analyses of the gap/ring properties suggest a $\sim$Saturn mass planet
at $\sim$90 au is likely responsible for the formation of the outer ring, which
can be potentially revealed with JWST.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:31:24 GMT""}]","2023-05-31"
"2303.14587","Shuhong Chen","Shuhong Chen, Kevin Zhang, Yichun Shi, Heng Wang, Yiheng Zhu, Guoxian
  Song, Sizhe An, Janus Kristjansson, Xiao Yang, Matthias Zwicker","PAniC-3D: Stylized Single-view 3D Reconstruction from Portraits of Anime
  Characters","CVPR 2023, code release:
  https://github.com/ShuhongChen/panic3d-anime-reconstruction",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose PAniC-3D, a system to reconstruct stylized 3D character heads
directly from illustrated (p)ortraits of (ani)me (c)haracters. Our anime-style
domain poses unique challenges to single-view reconstruction; compared to
natural images of human heads, character portrait illustrations have hair and
accessories with more complex and diverse geometry, and are shaded with
non-photorealistic contour lines. In addition, there is a lack of both 3D model
and portrait illustration data suitable to train and evaluate this ambiguous
stylized reconstruction task. Facing these challenges, our proposed PAniC-3D
architecture crosses the illustration-to-3D domain gap with a line-filling
model, and represents sophisticated geometries with a volumetric radiance
field. We train our system with two large new datasets (11.2k Vroid 3D models,
1k Vtuber portrait illustrations), and evaluate on a novel AnimeRecon benchmark
of illustration-to-3D pairs. PAniC-3D significantly outperforms baseline
methods, and provides data to establish the task of stylized reconstruction
from portrait illustrations.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:36:17 GMT""}]","2023-03-28"
"2303.14588","Bashar Al-Rfooh","Bashar Al-Rfooh, Gheith Abandah, Rami Al-Rfou","Fine-Tashkeel: Finetuning Byte-Level Models for Accurate Arabic Text
  Diacritization",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Most of previous work on learning diacritization of the Arabic language
relied on training models from scratch. In this paper, we investigate how to
leverage pre-trained language models to learn diacritization. We finetune
token-free pre-trained multilingual models (ByT5) to learn to predict and
insert missing diacritics in Arabic text, a complex task that requires
understanding the sentence semantics and the morphological structure of the
tokens. We show that we can achieve state-of-the-art on the diacritization task
with minimal amount of training and no feature engineering, reducing WER by
40%. We release our finetuned models for the greater benefit of the researchers
in the community.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:41:33 GMT""}]","2023-03-28"
"2303.14589","Bradford Windsor","Brad Windsor, Luke Martin, Anand Tyagi","SASS: Data and Methods for Subject Aware Sentence Simplification",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Sentence simplification tends to focus on the generic simplification of
sentences by making them more readable and easier to understand. This paper
provides a dataset aimed at training models that perform subject aware sentence
simplifications rather than simplifying sentences as a whole. We also test
models on that dataset which are inspired by model architecture used in
abstractive summarization. We hand generated portions of the data and augment
the dataset by further manipulating those hand written simplifications. Our
results show that data-augmentation, data-masking, and model architecture
choices used in summarization provide a solid baseline for comparison on
subject aware simplification.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:02:25 GMT""}]","2023-03-28"
"2303.14590","Gustavo Caetano-Anoll\'es","Gustavo Caetano-Anoll\'es","A note on retrodiction and machine evolution","7 pages, 1 figure",,,,"q-bio.BM","http://creativecommons.org/licenses/by/4.0/","  Biomolecular communication demands that interactions between parts of a
molecular system act as scaffolds for message transmission. It also requires an
evolving and organized system of signs - a communicative agency - for creating
and transmitting meaning. Here I explore the need to dissect biomolecular
communication with retrodiction approaches that make claims about the past
given information that is available in the present. While the passage of time
restricts the explanatory power of retrodiction, the use of molecular structure
in biology offsets information erosion. This allows description of the gradual
evolutionary rise of structural and functional innovations in RNA and proteins.
The resulting chronologies can also describe the gradual rise of molecular
machines of increasing complexity and computation capabilities. For example,
the accretion of rRNA substructures and ribosomal proteins can be traced in
time and placed within a geological timescale. Phylogenetic, algorithmic and
theoretical-inspired accretion models can be reconciled into a congruent
evolutionary model. Remarkably, the time of origin of enzymes, functional RNA,
non-ribosomal peptide synthetase (NRPS) complexes, and ribosomes suggest they
gradually climbed Chomsky's hierarchy of formal grammars, supporting the
gradual complexification of machines and communication in molecular biology.
Future retrodiction approaches and in-depth exploration of theoretical models
of computation will need to confirm such evolutionary progression.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:09:45 GMT""}]","2023-03-28"
"2303.14591","Oyku Deniz Kose","O. Deniz Kose, Yanning Shen","FairGAT: Fairness-aware Graph Attention Networks","17 pages, 8 tables",,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphs can facilitate modeling various complex systems such as gene networks
and power grids, as well as analyzing the underlying relations within them.
Learning over graphs has recently attracted increasing attention, particularly
graph neural network-based (GNN) solutions, among which graph attention
networks (GATs) have become one of the most widely utilized neural network
structures for graph-based tasks. Although it is shown that the use of graph
structures in learning results in the amplification of algorithmic bias, the
influence of the attention design in GATs on algorithmic bias has not been
investigated. Motivated by this, the present study first carries out a
theoretical analysis in order to demonstrate the sources of algorithmic bias in
GAT-based learning for node classification. Then, a novel algorithm, FairGAT,
that leverages a fairness-aware attention design is developed based on the
theoretical findings. Experimental results on real-world networks demonstrate
that FairGAT improves group fairness measures while also providing comparable
utility to the fairness-aware baselines for node classification and link
prediction.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:10:20 GMT""}]","2023-03-28"
"2303.14592","Bradford Windsor","Brad Windsor, Brandon O'Shea, Mengxi Wu","Exploring Novel Quality Diversity Methods For Generalization in
  Reinforcement Learning",,,,,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  The Reinforcement Learning field is strong on achievements and weak on
reapplication; a computer playing GO at a super-human level is still terrible
at Tic-Tac-Toe. This paper asks whether the method of training networks
improves their generalization. Specifically we explore core quality diversity
algorithms, compare against two recent algorithms, and propose a new algorithm
to deal with shortcomings in existing methods. Although results of these
methods are well below the performance hoped for, our work raises important
points about the choice of behavior criterion in quality diversity, the
interaction of differential and evolutionary training methods, and the role of
offline reinforcement learning and randomized learning in evolutionary search.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:23:29 GMT""}]","2023-03-28"
"2303.14593","Hao Shi","Hao Shi, Masato Mimura, Longbiao Wang, Jianwu Dang, Tatsuya Kawahara","Time-domain Speech Enhancement Assisted by Multi-resolution Frequency
  Encoder and Decoder",,,,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-domain speech enhancement (SE) has recently been intensively
investigated. Among recent works, DEMUCS introduces multi-resolution STFT loss
to enhance performance. However, some resolutions used for STFT contain
non-stationary signals, and it is challenging to learn multi-resolution
frequency losses simultaneously with only one output. For better use of
multi-resolution frequency information, we supplement multiple spectrograms in
different frame lengths into the time-domain encoders. They extract stationary
frequency information in both narrowband and wideband. We also adopt multiple
decoder outputs, each of which computes its corresponding resolution frequency
loss. Experimental results show that (1) it is more effective to fuse
stationary frequency features than non-stationary features in the encoder, and
(2) the multiple outputs consistent with the frequency loss improve
performance. Experiments on the Voice-Bank dataset show that the proposed
method obtained a 0.14 PESQ improvement.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:30:06 GMT""}]","2023-03-28"
"2303.14594","Vasilis Oikonomou","S.D. Odintsov, V.K. Oikonomou, F.P. Fronimos","Inflationary Dynamics and Swampland Criteria for Modified Gauss-Bonnet
  Gravity Compatible with GW170817","PRD Accepted, abstract reduced due to arXiv limitations",,"10.1103/PhysRevD.107.084007",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we present an alternative formalism for the inflationary
phenomenology of rescaled Einstein-Gauss-Bonnet models which are in agreement
with the GW170817 event. By constraining the propagation velocity of primordial
tensor perturbations, an approximate form for the time derivative of the scalar
field coupled to the Gauss-Bonnet density is extracted. In turn, the overall
degrees of freedom decrease and similar to the case of the canonical scalar
field, only one scalar function needs to be designated, while the other is
extracted from the continuity equation of the scalar field. We showcase
explicitly that the slow-roll indices can be written in a closed form as
functions of three dimensionless parameters, namely
$x=\frac{1}{2\alpha}\bigg(\frac{\kappa\xi'}{\xi''}\bigg)^2$, $\beta=8H^2\xi''$
and $\gamma=\frac{\xi'\xi'''}{\xi''^2}$ and in turn, we prove that the
Einstein-Gauss-Bonnet model can in fact produce a blue-tilted tensor spectral
index if the condition $\beta\geq1$ is satisfied, which is possible only for
Einstein-Gauss-Bonnet models with $\xi''(\phi_k)>0$. Afterwards, a brief
comment on the running of the spectral indices is made where it is shown that
$a_{\mathcal{S}}(k_*)$ and $a_{\mathcal{T}}(k_*)$ in the constrained case are
approximately of the order $\mathcal{O}(10^{-3})$, if not smaller. Last but not
least, we examine the conditions under which the Swampland criteria are
satisfied. We connect the tracking condition related to scalar field theories
with the present models, and we highlight the important feature of the models
we propose that the tracking condition can be satisfied only if the Swampland
criteria are simultaneously satisfied, however the cases with $\xi\sim1/V$ and
$\xi\sim V$ are excluded, as they cannot describe the inflationary era
properly.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:30:11 GMT""}]","2023-04-19"
"2303.14595","Qiao Gu","Qiao Gu, Dongsub Shim, Florian Shkurti","Preserving Linear Separability in Continual Learning by Backward Feature
  Projection","CVPR 2023. The code can be found at
  https://github.com/rvl-lab-utoronto/BFP",,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Catastrophic forgetting has been a major challenge in continual learning,
where the model needs to learn new tasks with limited or no access to data from
previously seen tasks. To tackle this challenge, methods based on knowledge
distillation in feature space have been proposed and shown to reduce
forgetting. However, most feature distillation methods directly constrain the
new features to match the old ones, overlooking the need for plasticity. To
achieve a better stability-plasticity trade-off, we propose Backward Feature
Projection (BFP), a method for continual learning that allows the new features
to change up to a learnable linear transformation of the old features. BFP
preserves the linear separability of the old classes while allowing the
emergence of new feature directions to accommodate new classes. BFP can be
integrated with existing experience replay methods and boost performance by a
significant margin. We also demonstrate that BFP helps learn a better
representation space, in which linear separability is well preserved during
continual learning and linear probing achieves high classification accuracy.
The code can be found at https://github.com/rvl-lab-utoronto/BFP
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:35:59 GMT""},{""version"":""v2"",""created"":""Sat, 1 Apr 2023 21:29:42 GMT""}]","2023-04-04"
"2303.14596","Rafael Sorkin","Rafael D. Sorkin","An inside view of the tensor product","plainTeX, 29 pages. To appear in: Particles, Fields and Topology,
  Celebrating A.P. Balachandran, edited by T.R. Govindrajan, et al (World
  Scientific, Singapore). Most current version will be available at
  http://www.perimeterinstitute.ca/personal/rsorkin/some.papers/ (or wherever
  my home-page may be)",,,,"math-ph gr-qc hep-th math.CT math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  Given a vector-space $~V~$ which is the tensor product of vector-spaces $A$
and $B$, we reconstruct $A$ and $B$ from the family of simple tensors
$a{\otimes}b$ within $V$. In an application to quantum mechanics, one would be
reconstructing the component subsystems of a composite system from its
unentangled pure states. Our constructions can be viewed as instances of the
category-theoretic concepts of functor and natural isomorphism, and we use this
to bring out the intuition behind these concepts, and also to critique them.
Also presented are some suggestions for further work, including a hoped-for
application to entanglement entropy in quantum field theory.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:39:36 GMT""}]","2023-03-28"
"2303.14597","Sangchul Park","Sangchul Park","Smart Cities: Striking a Balance Between Urban Resilience and Civil
  Liberties",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Cities are becoming smarter and more resilient by integrating urban
infrastructure with information technology. However, concerns grow that smart
cities might reverse progress on civil liberties when sensing, profiling, and
predicting citizen activities; undermining citizen autonomy in connectivity,
mobility, and energy consumption; and deprivatizing digital infrastructure. In
response, cities need to deploy technical breakthroughs, such as
privacy-enhancing technologies, cohort modelling, and fair and explainable
machine learning. However, as throwing technologies at cities cannot always
address civil liberty concerns, cities must ensure transparency and foster
citizen participation to win public trust about the way resilience and
liberties are balanced.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:09:11 GMT""}]","2023-03-28"
"2303.14598","Yi Tian","Yi Tian, Li Zhao, Meihong Zhu","Dynamic Game of the Dual-Channel Supply Chain Under a Carbon Subsidy
  Policy",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates the dynamic game behaviors of dual-channel supply
chains involving an oligopoly manufacturer selling low-carbon products to
online and offline retailers. The price game models under government subsidy
are discussed under three scenarios: (1) simultaneous decision, (2)
manufacturer dominates the market, and (3) retailer dominates the market. The
equilibrium strategies are compared under the government subsidy policy. Using
numerical simulation,complex characteristics of the dual-channel supply chain
under the carbon subsidy policy are investigated. The complexity of wholesale
price and sales commission of each channel are analyzed by bifurcation, largest
Lyapunov exponent and basin of attraction diagrams. Furthermore,parameter
adjustment and delayed feedback control methods are proven to be effective
approaches to chaos control.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:10:02 GMT""}]","2023-03-28"
"2303.14599","Kenta Sato","Kenta Sato","General hyperplane sections of log canonical threefolds in positive
  characteristic","28pages, 4figures",,,,"math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove that if a $3$-dimensional quasi-projective variety
$X$ over an algebraically closed field of characteristic $p>3$ has only log
canonical singularities, then so does a general hyperplane section $H$ of $X$.
We also show that the same is true for klt singularities, which is a slight
extension of \cite{ST20}. In the course of the proof, we provide a sufficient
condition for log canonical (resp.~klt) surface singularities to be
geometrically log canonical (resp.~geometrically klt) over a field.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:28:07 GMT""}]","2023-03-28"
"2303.14600","Paul Pollack","Paul Pollack and Akash Singha Roy","Distribution in coprime residue classes of polynomially-defined
  multiplicative functions","edited paragraph following Theorem 1.3, correcting a claim in the
  discussion of condition (i)","Math. Z. 303, article number 93 (2023)","10.1007/s00209-023-03240-7",,"math.NT","http://creativecommons.org/licenses/by/4.0/","  An integer-valued multiplicative function $f$ is said to be
polynomially-defined if there is a nonconstant separable polynomial $F(T)\in
\mathbb{Z}[T]$ with $f(p)=F(p)$ for all primes $p$. We study the distribution
in coprime residue classes of polynomially-defined multiplicative functions,
establishing equidistribution results allowing a wide range of uniformity in
the modulus $q$. For example, we show that the values $\phi(n)$, sampled over
integers $n \le x$ with $\phi(n)$ coprime to $q$, are asymptotically
equidistributed among the coprime classes modulo $q$, uniformly for moduli $q$
coprime to $6$ that are bounded by a fixed power of $\log{x}$.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:29:16 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 02:26:52 GMT""}]","2023-05-31"
"2303.14601","Yupei Liu","Jinyuan Jia and Yupei Liu and Yuepeng Hu and Neil Zhenqiang Gong","PORE: Provably Robust Recommender Systems against Data Poisoning Attacks","To appear in USENIX Security Symposium, 2023",,,,"cs.CR cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Data poisoning attacks spoof a recommender system to make arbitrary,
attacker-desired recommendations via injecting fake users with carefully
crafted rating scores into the recommender system. We envision a cat-and-mouse
game for such data poisoning attacks and their defenses, i.e., new defenses are
designed to defend against existing attacks and new attacks are designed to
break them. To prevent such a cat-and-mouse game, we propose PORE, the first
framework to build provably robust recommender systems in this work. PORE can
transform any existing recommender system to be provably robust against any
untargeted data poisoning attacks, which aim to reduce the overall performance
of a recommender system. Suppose PORE recommends top-$N$ items to a user when
there is no attack. We prove that PORE still recommends at least $r$ of the $N$
items to the user under any data poisoning attack, where $r$ is a function of
the number of fake users in the attack. Moreover, we design an efficient
algorithm to compute $r$ for each user. We empirically evaluate PORE on popular
benchmark datasets.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:38:11 GMT""}]","2023-03-28"
"2303.14602","Anna Kawakami","Anna Kawakami, Amanda Coston, Haiyi Zhu, Hoda Heidari, Kenneth
  Holstein","Recentering Validity Considerations through Early-Stage Deliberations
  Around AI and Policy Design",,,,,"cs.HC cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  AI-based decision-making tools are rapidly spreading across a range of
real-world, complex domains like healthcare, criminal justice, and child
welfare. A growing body of research has called for increased scrutiny around
the validity of AI system designs. However, in real-world settings, it is often
not possible to fully address questions around the validity of an AI tool
without also considering the design of associated organizational and public
policies. Yet, considerations around how an AI tool may interface with policy
are often only discussed retrospectively, after the tool is designed or
deployed. In this short position paper, we discuss opportunities to promote
multi-stakeholder deliberations around the design of AI-based technologies and
associated policies, at the earliest stages of a new project.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:50:40 GMT""}]","2023-03-28"
"2303.14603","Hina Qayyum","Hina Qayyum, Benjamin Zi Hao Zhao, Ian D. Wood, Muhammad Ikram,
  Mohamed Ali Kaafar, Nicolas Kourtellis","A longitudinal study of the top 1% toxic Twitter profiles",,,"10.1145/3578503.3583619",,"cs.SI cs.CY","http://creativecommons.org/licenses/by-sa/4.0/","  Toxicity is endemic to online social networks including Twitter. It follows a
Pareto like distribution where most of the toxicity is generated by a very
small number of profiles and as such, analyzing and characterizing these toxic
profiles is critical. Prior research has largely focused on sporadic, event
centric toxic content to characterize toxicity on the platform. Instead, we
approach the problem of characterizing toxic content from a profile centric
point of view. We study 143K Twitter profiles and focus on the behavior of the
top 1 percent producers of toxic content on Twitter, based on toxicity scores
of their tweets availed by Perspective API. With a total of 293M tweets,
spanning 16 years of activity, the longitudinal data allow us to reconstruct
the timelines of all profiles involved. We use these timelines to gauge the
behavior of the most toxic Twitter profiles compared to the rest of the Twitter
population. We study the pattern of tweet posting from highly toxic accounts,
based on the frequency and how prolific they are, the nature of hashtags and
URLs, profile metadata, and Botometer scores. We find that the highly toxic
profiles post coherent and well articulated content, their tweets keep to a
narrow theme with lower diversity in hashtags, URLs, and domains, they are
thematically similar to each other, and have a high likelihood of bot like
behavior, likely to have progenitors with intentions to influence, based on
high fake followers score. Our work contributes insight into the top 1 percent
of toxic profiles on Twitter and establishes the profile centric approach to
investigate toxicity on Twitter to be beneficial.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:55:28 GMT""}]","2023-03-28"
"2303.14604","Ashkan Yousefpour","Ashkan Yousefpour, Shen Guo, Ashish Shenoy, Sayan Ghosh, Pierre Stock,
  Kiwan Maeng, Schalk-Willem Kr\""uger, Michael Rabbat, Carole-Jean Wu, Ilya
  Mironov","Green Federated Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rapid progress of AI is fueled by increasingly large and computationally
intensive machine learning models and datasets. As a consequence, the amount of
compute used in training state-of-the-art models is exponentially increasing
(doubling every 10 months between 2015 and 2022), resulting in a large carbon
footprint. Federated Learning (FL) - a collaborative machine learning technique
for training a centralized model using data of decentralized entities - can
also be resource-intensive and have a significant carbon footprint,
particularly when deployed at scale. Unlike centralized AI that can reliably
tap into renewables at strategically placed data centers, cross-device FL may
leverage as many as hundreds of millions of globally distributed end-user
devices with diverse energy sources. Green AI is a novel and important research
area where carbon footprint is regarded as an evaluation criterion for AI,
alongside accuracy, convergence speed, and other metrics.
  In this paper, we propose the concept of Green FL, which involves optimizing
FL parameters and making design choices to minimize carbon emissions consistent
with competitive performance and training time. The contributions of this work
are two-fold. First, we adopt a data-driven approach to quantify the carbon
emissions of FL by directly measuring real-world at-scale FL tasks running on
millions of phones. Second, we present challenges, guidelines, and lessons
learned from studying the trade-off between energy efficiency, performance, and
time-to-train in a production FL system. Our findings offer valuable insights
into how FL can reduce its carbon footprint, and they provide a foundation for
future research in the area of Green AI.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:23:38 GMT""}]","2023-03-28"
"2303.14605","Victor Reis","Victor Reis, Thomas Rothvoss","The Subspace Flatness Conjecture and Faster Integer Programming","33 pages, improved bound",,,,"math.OC cs.CC cs.DM cs.DS math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a seminal paper, Kannan and Lov\'asz (1988) considered a quantity
$\mu_{KL}(\Lambda,K)$ which denotes the best volume-based lower bound on the
covering radius $\mu(\Lambda,K)$ of a convex body $K$ with respect to a lattice
$\Lambda$. Kannan and Lov\'asz proved that $\mu(\Lambda,K) \leq n \cdot
\mu_{KL}(\Lambda,K)$ and the Subspace Flatness Conjecture by Dadush (2012)
claims a $O(\log n)$ factor suffices, which would match the lower bound from
the work of Kannan and Lov\'asz.
  We settle this conjecture up to a constant in the exponent by proving that
$\mu(\Lambda,K) \leq O(\log^{3}(n)) \cdot \mu_{KL} (\Lambda,K)$. Our proof is
based on the Reverse Minkowski Theorem due to Regev and Stephens-Davidowitz
(2017). Following the work of Dadush (2012, 2019), we obtain a $(\log
n)^{O(n)}$-time randomized algorithm to solve integer programs in $n$
variables. Another implication of our main result is a near-optimal flatness
constant of $O(n \log^{4}(n))$.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:27:13 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 23:56:06 GMT""}]","2023-04-26"
"2303.14606","Chang Liu","Xiang-Rui Liu, Hanbin Deng, Yuntian Liu, Zhouyi Yin, Congrun Chen,
  Yu-Peng Zhu, Yichen Yang, Zhicheng Jiang, Zhengtai Liu, Mao Ye, Dawei Shen,
  Jia-Xin Yin, Kedong Wang, Qihang Liu, Yue Zhao, Chang Liu","Spectroscopic signature of obstructed surface states in SrIn$_2$P$_2$","20 Pages, 4 Figures","Nature Communications 14, 2905 (2023)","10.1038/s41467-023-38589-0",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The century-long development of surface sciences has witnessed the
discoveries of a variety of quantum states. In the recently proposed
""obstructed atomic insulators"", insulators with symmetric charges pinned at
virtual sites where no real atoms reside, the cleavage through these sites
could lead to a set of obstructed surface states with partial occupation. Here,
utilizing scanning tunneling microscopy, angle-resolved photoemission
spectroscopy and first-principles calculations, we observe spectroscopic
signature of obstructed surface states in SrIn$_2$P$_2$. We find a pair of
surface states originated from the pristine obstructed surface states split by
a unique surface reconstruction. The upper branch is marked with a striking
differential conductance peak followed by negative differential conductance,
signaling its localized nature, while the lower branch is found to be highly
dispersive. This pair of surface states is in consistency with our
calculational results. Our finding not only demonstrates a surface quantum
state induced by a new type of bulk-boundary correspondence, but also provides
a platform for exploring efficient catalysts and related surface engineering.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:40:13 GMT""}]","2023-05-24"
"2303.14607","Yasuaki Fujitani","Yasuaki Fujitani","Analysis of harmonic functions under lower bounds of $N$-weighted Ricci
  curvature with $\varepsilon$-range","28 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The behavior of harmonic functions on Riemannian manifolds under lower bounds
of the Ricci curvature has been studied from both analytic and geometric
viewpoints. For example, some Liouville type theorems are obtained under lower
bounds of the Ricci curvature. Recently, those results are generalized under
lower bounds of the $N$-weighted Ricci curvature $\mbox{Ric}_\psi^N$ with $N
\in [n,\infty]$. In this paper, we present a Liouville type theorem for
harmonic functions of sublinear growth and a gradient estimate of harmonic
functions on weighted Riemannian manifolds under weaker lower bounds of
$\mbox{Ric}_\psi^N$ with $N < 0$. We also prove an $L^p$-Liouville theorem
under lower bounds of $\mbox{Ric}_\psi^N$ with $N \in [n,\infty]$ in a way
different from that of [Wu, 2014]. Our results are obtained as a consequence of
an argument under lower bounds of $\mbox{Ric}_\psi^N$ with $\varepsilon$-range,
which is a unification of constant and variable curvature bounds. Among various
methods considered for the analysis of harmonic functions, this paper focuses
on methods using the Moser's iteration procedure.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:40:56 GMT""}]","2023-03-28"
"2303.14608","Seong Tae Kim","Soyoun Won, Sung-Ho Bae, Seong Tae Kim","Analyzing Effects of Mixed Sample Data Augmentation on Model
  Interpretability",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Data augmentation strategies are actively used when training deep neural
networks (DNNs). Recent studies suggest that they are effective at various
tasks. However, the effect of data augmentation on DNNs' interpretability is
not yet widely investigated. In this paper, we explore the relationship between
interpretability and data augmentation strategy in which models are trained
with different data augmentation methods and are evaluated in terms of
interpretability. To quantify the interpretability, we devise three evaluation
methods based on alignment with humans, faithfulness to the model, and the
number of human-recognizable concepts in the model. Comprehensive experiments
show that models trained with mixed sample data augmentation show lower
interpretability, especially for CutMix and SaliencyMix augmentations. This new
finding suggests that it is important to carefully adopt mixed sample data
augmentation due to the impact on model interpretability, especially in
mission-critical applications.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:01:39 GMT""}]","2023-03-28"
"2303.14610","Huxiao Luo","Huxiao Luo","Uniqueness and nondegeneracy of ground states for
  $(-\Delta)^su+u=2(I_2\star u^2)u$ in $\mathbb{R}^N$ when $s$ is close to 1","arXiv admin note: text overlap with arXiv:1301.4868 by other authors",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we study the uniqueness and nondegeneracy of ground states
to a fractional Choquard equation of the form: $(-\Delta)^su+u=2(I_2\star
u^2)u$ where $s\in(0,1)$ is sufficiently close to $1$. Our method is to make a
continuation argument with respect to the power $s\in(0,1)$ appearing in
$(-\Delta)^s$. This approach is based on [M. M. Fall and E. Valdinoci, Comm.
Math. Phys., 329 (2014) 383-404].
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:08:59 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 12:19:51 GMT""}]","2023-04-07"
"2303.14611","Alexander Shnirelman","Alexander Shnirelman","The true story of the Quantum Ergodic Theorem","15 pages, 7 figures",,,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The story on the early days of the Quantum Ergodic Theorem. Alternative
proof, underlying heuristics, physical analogies and interpretations.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:17:03 GMT""}]","2023-03-28"
"2303.14612","Alsharif Abuadbba Dr","Shahroz Tariq, Alsharif Abuadbba, Kristen Moore","Deepfake in the Metaverse: Security Implications for Virtual Gaming,
  Meetings, and Offices","3 pages. Submited to ACM ASIACCS 2023 workshop",,,,"cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The metaverse has gained significant attention from various industries due to
its potential to create a fully immersive and interactive virtual world.
However, the integration of deepfakes in the metaverse brings serious security
implications, particularly with regard to impersonation. This paper examines
the security implications of deepfakes in the metaverse, specifically in the
context of gaming, online meetings, and virtual offices. The paper discusses
how deepfakes can be used to impersonate in gaming scenarios, how online
meetings in the metaverse open the door for impersonation, and how virtual
offices in the metaverse lack physical authentication, making it easier for
attackers to impersonate someone. The implications of these security concerns
are discussed in relation to the confidentiality, integrity, and availability
(CIA) triad. The paper further explores related issues such as the darkverse,
and digital cloning, as well as regulatory and privacy concerns associated with
addressing security threats in the virtual world.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:20:44 GMT""}]","2023-03-28"
"2303.14613","Tenglong Ao","Tenglong Ao, Zeyi Zhang, Libin Liu","GestureDiffuCLIP: Gesture Diffusion Model with CLIP Latents","SIGGRAPH 2023 (Journal Track); Project Page:
  https://pku-mocca.github.io/GestureDiffuCLIP-Page/",,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The automatic generation of stylized co-speech gestures has recently received
increasing attention. Previous systems typically allow style control via
predefined text labels or example motion clips, which are often not flexible
enough to convey user intent accurately. In this work, we present
GestureDiffuCLIP, a neural network framework for synthesizing realistic,
stylized co-speech gestures with flexible style control. We leverage the power
of the large-scale Contrastive-Language-Image-Pre-training (CLIP) model and
present a novel CLIP-guided mechanism that extracts efficient style
representations from multiple input modalities, such as a piece of text, an
example motion clip, or a video. Our system learns a latent diffusion model to
generate high-quality gestures and infuses the CLIP representations of style
into the generator via an adaptive instance normalization (AdaIN) layer. We
further devise a gesture-transcript alignment mechanism that ensures a
semantically correct gesture generation based on contrastive learning. Our
system can also be extended to allow fine-grained style control of individual
body parts. We demonstrate an extensive set of examples showing the flexibility
and generalizability of our model to a variety of style descriptions. In a user
study, we show that our system outperforms the state-of-the-art approaches
regarding human likeness, appropriateness, and style correctness.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:35:46 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 10:56:36 GMT""},{""version"":""v3"",""created"":""Wed, 10 May 2023 05:41:55 GMT""}]","2023-05-11"
"2303.14614","Kai Niu","Kai Niu, Ping Zhang, Jincheng Dai, Zhongwei Si, Chao Dong","A Golden Decade of Polar Codes: From Basic Principle to 5G Applications","29 pages, 21 figures, Published in China Communications","China Communications, vol.20, no. 2, pp. 94-121, 2023","10.23919/JCC.2023.02.015",,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  After the pursuit of seventy years, the invention of polar codes indicates
that we have found the first capacity-achieving coding with low complexity
construction and decoding, which is the great breakthrough of the coding theory
in the past two decades. In this survey, we retrospect the history of polar
codes and summarize the advancement in the past ten years. First, the primary
principle of channel polarization is investigated such that the basic
construction, coding method, and classic successive cancellation (SC) decoding
are reviewed. Second, in order to improve the performance of the finite code
length, we introduce the guiding principle and conclude five design criteria
for the construction, design, and implementation of the polar code in the
practical communication system based on the exemplar schemes in the literature.
Especially, we explain the design principle behind the concatenated coding and
rate matching of polar codes in a 5G wireless system. Furthermore, the improved
SC decoding algorithms, such as SC list (SCL) decoding and SC stack (SCS)
decoding, etc., are investigated and compared. Finally, the research prospects
of polar codes for the future 6G communication system are explored, including
the optimization of short polar codes, coding construction in fading channels,
polar coded modulation and HARQ, and the polar coded transmission, namely polar
processing. Predictably, as a new coding methodology, polar codes will shine a
light on communication theory and unveil a revolution in transmission
technology.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:42:59 GMT""}]","2023-03-28"
"2303.14615","Mohammad Rostami","Ruitong Sun, Mohammad Rostami","Explainable Artificial Intelligence Architecture for Melanoma Diagnosis
  Using Indicator Localization and Self-Supervised Learning",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Melanoma is a prevalent lethal type of cancer that is treatable if diagnosed
at early stages of development. Skin lesions are a typical indicator for
diagnosing melanoma but they often led to delayed diagnosis due to high
similarities of cancerous and benign lesions at early stages of melanoma. Deep
learning (DL) can be used as a solution to classify skin lesion pictures with a
high accuracy, but clinical adoption of deep learning faces a significant
challenge. The reason is that the decision processes of deep learning models
are often uninterpretable which makes them black boxes that are challenging to
trust. We develop an explainable deep learning architecture for melanoma
diagnosis which generates clinically interpretable visual explanations for its
decisions. Our experiments demonstrate that our proposed architectures matches
clinical explanations significantly better than existing architectures.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 03:43:05 GMT""}]","2023-03-28"
"2303.14616","Seong-Yeop Jeong","Seong-Yeop Jeong and Clare Watt","The Wave Energy Density and Growth Rate for the Resonant Instability in
  Relativistic Plasmas","accepted in MNRAS",,"10.1093/mnras/stad934",,"physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  The wave instability acts in astrophysical plasmas to redistribute energy and
momentum in the absence of frequent collisions. There are many different types
of waves, and it is important to quantify the wave energy density and growth
rate for understanding what type of wave instabilities are possible in
different plasma regimes. There are many situations throughout the universe
where plasmas contain a significant fraction of relativistic particles.
Theoretical estimates for the wave energy density and growth rate are
constrained to either field-aligned propagation angles, or non-relativistic
considerations. Based on linear theory, we derive the analytic expressions for
the energy density and growth rate of an arbitrary resonant wave with an
arbitrary propagation angle in relativistic plasmas. For this derivation, we
calculate the Hermitian and anti-Hermitian parts of the relativistic-plasma
dielectric tensor. We demonstrate that our analytic expression for the wave
energy density presents an explicit energy increase of resonant waves in the
wavenumber range where the analytic expression for the growth rate is positive
(i.e., where a wave instability is driven). For this demonstration, we
numerically analyse the loss-cone driven instability, as a specific example, in
which the whistler-mode waves scatter relativistic electrons into the loss cone
in the radiation belt. Our analytic results further develop the basis for
linear theory to better understand the wave instability, and have the potential
to combine with quasi-linear theory, which allows to study the time evolution
of not only the particle momentum distribution function but also resonant wave
properties through an instability.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:01:22 GMT""}]","2023-04-05"
"2303.14617","Hongyu Ren","Hongyu Ren, Mikhail Galkin, Michael Cochez, Zhaocheng Zhu, Jure
  Leskovec","Neural Graph Reasoning: Complex Logical Query Answering Meets Graph
  Databases",,,,,"cs.DB cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex logical query answering (CLQA) is a recently emerged task of graph
machine learning that goes beyond simple one-hop link prediction and solves a
far more complex task of multi-hop logical reasoning over massive, potentially
incomplete graphs in a latent space. The task received a significant traction
in the community; numerous works expanded the field along theoretical and
practical axes to tackle different types of complex queries and graph
modalities with efficient systems. In this paper, we provide a holistic survey
of CLQA with a detailed taxonomy studying the field from multiple angles,
including graph types (modality, reasoning domain, background semantics),
modeling aspects (encoder, processor, decoder), supported queries (operators,
patterns, projected variables), datasets, evaluation metrics, and applications.
  Refining the CLQA task, we introduce the concept of Neural Graph Databases
(NGDBs). Extending the idea of graph databases (graph DBs), NGDB consists of a
Neural Graph Storage and a Neural Graph Engine. Inside Neural Graph Storage, we
design a graph store, a feature store, and further embed information in a
latent embedding store using an encoder. Given a query, Neural Query Engine
learns how to perform query planning and execution in order to efficiently
retrieve the correct results by interacting with the Neural Graph Storage.
Compared with traditional graph DBs, NGDBs allow for a flexible and unified
modeling of features in diverse modalities using the embedding store. Moreover,
when the graph is incomplete, they can provide robust retrieval of answers
which a normal graph DB cannot recover. Finally, we point out promising
directions, unsolved problems and applications of NGDB for future research.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:03:37 GMT""}]","2023-03-28"
"2303.14618","Minghan Li","Minghan Li and Lei Zhang","BoxVIS: Video Instance Segmentation with Box Annotations",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  It is expensive and labour-extensive to label the pixel-wise object masks in
a video. As a results, the amount of pixel-wise annotations in existing video
instance segmentation (VIS) datasets is small, limiting the generalization
capability of trained VIS models. An alternative but much cheaper solution is
to use bounding boxes to label instances in videos. Inspired by the recent
success of box-supervised image instance segmentation, we first adapt the
state-of-the-art pixel-supervised VIS models to a box-supervised VIS (BoxVIS)
baseline, and observe only slight performance degradation. We consequently
propose to improve BoxVIS performance from two aspects. First, we propose a
box-center guided spatial-temporal pairwise affinity (STPA) loss to predict
instance masks for better spatial and temporal consistency. Second, we collect
a larger scale box-annotated VIS dataset (BVISD) by consolidating the videos
from current VIS benchmarks and converting images from the COCO dataset to
short pseudo video clips. With the proposed BVISD and the STPA loss, our
trained BoxVIS model demonstrates promising instance mask prediction
performance. Specifically, it achieves 43.2\% and 29.0\% mask AP on the
YouTube-VIS 2021 and OVIS valid sets, respectively, exhibiting comparable or
even better generalization performance than state-of-the-art pixel-supervised
VIS models by using only 16\% annotation time and cost. Codes and data of
BoxVIS can be found at \url{https://github.com/MinghanLi/BoxVIS}.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:04:58 GMT""}]","2023-03-28"
"2303.14619","Yu-Han Ma","Tan-Ji Zhou, Yu-Han Ma, and C. P. Sun","Finite-Time Optimization of Quantum Szilard heat engine","6+10 pages, 3+4 figures, Comments are welcome",,,,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a finite-time quantum Szilard engine (QSE) with a quantum particle
with spin as the working substance (WS) to accelerate the operation of
information engines. We introduce a Maxwell's demon (MD) to probe the spin
state within a finite measurement time $t_{{\rm M}}$ to capture the which-way
information of the particle, quantified by the mutual information
$I(t_{\rm{M}})$ between WS and MD. We establish that the efficiency $\eta$ of
QSE is bounded by $\eta\leq1-(1-\eta_{\rm{C}}){\rm ln}2/I(t_{{\rm M}})$, where
$I(t_{{\rm M}})/\rm{ln}2$ characterizes the ideality of quantum measurement,
and approaches $1$ for the Carnot efficiency reached under ideal measurement in
quasi-static regime. We find that the power of QSE scales as $P\propto t_{{\rm
M}}^{3}$ in the short-time regime and as $P\propto t_{\rm M}^{-1}$ in the
long-time regime. Additionally, considering the energy cost for erasing the
MD's memory required by Landauer's principle, there exists a threshold time
that guarantees QSE to output positive work.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:08:46 GMT""}]","2023-03-28"
"2303.14620","Shuaiyu Xie","Shuaiyu Xie, Jian Wang, Bing Li, Zekun Zhang, Duantengchuan Li,
  Patrick C. K. H","PBScaler: A Bottleneck-aware Autoscaling Framework for
  Microservice-based Applications",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autoscaling is critical for ensuring optimal performance and resource
utilization in cloud applications with dynamic workloads. However, traditional
autoscaling technologies are typically no longer applicable in
microservice-based applications due to the diverse workload patterns and
complex interactions between microservices. Specifically, the propagation of
performance anomalies through interactions leads to a high number of abnormal
microservices, making it difficult to identify the root performance bottlenecks
(PBs) and formulate appropriate scaling strategies. In addition, to balance
resource consumption and performance, the existing mainstream approaches based
on online optimization algorithms require multiple iterations, leading to
oscillation and elevating the likelihood of performance degradation. To tackle
these issues, we propose PBScaler, a bottleneck-aware autoscaling framework
designed to prevent performance degradation in a microservice-based
application. The key insight of PBScaler is to locate the PBs. Thus, we propose
TopoRank, a novel random walk algorithm based on the topological potential to
reduce unnecessary scaling. By integrating TopoRank with an offline
performance-aware optimization algorithm, PBScaler optimizes replica management
without disrupting the online application. Comprehensive experiments
demonstrate that PBScaler outperforms existing state-of-the-art approaches in
mitigating performance issues while conserving resources efficiently.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:20:17 GMT""}]","2023-03-28"
"2303.14621","J.Dulangi Kanchana Ms.","J. Dulangi Kanchana, Gayashan Amarasinghe, Vishaka Nanayakkara, Amal
  Shehan Perera","A Set of Essentials for Online Learning : CSE-SET",,,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  Distance learning is not a novel concept. Education or learning conducted
online is a form of distance education. Online learning presents a convenient
alternative to traditional learning. Numerous researchers have investigated the
usage of online education in educational institutions and across nations. A set
of essentials for effective online learning are elaborated in this study to
ensure stakeholders would not get demotivated in the online learning process.
Also, the study lists a set of factors that motivate students and other
stakeholders to engage in online learning with enthusiasm and work towards
online learning.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:33:52 GMT""}]","2023-03-28"
"2303.14622","Hua-Lei Yin","Ao Shen, Xiao-Yu Cao, Yang Wang, Yao Fu, Jie Gu, Wen-Bo Liu, Chen-Xun
  Weng, Hua-Lei Yin, Zeng-Bing Chen","Experimental quantum secret sharing based on phase encoding of coherent
  states","10 pages, 5 figures, 3 tables, accepted by Sci. China-Phys. Mech.
  Astron","Sci. China-Phys. Mech. Astron. 66, 260311 (2023)","10.1007/s11433-023-2105-7",,"quant-ph cs.CR","http://creativecommons.org/licenses/by/4.0/","  Quantum secret sharing (QSS) is one of the basic communication primitives in
future quantum networks which addresses part of the basic cryptographic tasks
of multiparty communication and computation. Nevertheless, it is a challenge to
provide a practical QSS protocol with security against general attacks. A QSS
protocol that balances security and practicality is still lacking. Here, we
propose a QSS protocol with simple phase encoding of coherent states among
three parties. Removing the requirement of impractical entangled resources and
the need for phase randomization, our protocol can be implemented with
accessible technology. We provide the finite-key analysis against coherent
attacks and implement a proof-of-principle experiment to demonstrate our
scheme's feasibility. Our scheme achieves a key rate of 85.3 bps under a 35 dB
channel loss. Combined with security against general attacks and accessible
technology, our protocol is a promising candidate for practical multiparty
quantum communication networks.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:35:07 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 03:55:15 GMT""}]","2023-05-11"
"2303.14623","Gokul Swamy","Gokul Swamy, Sanjiban Choudhury, J. Andrew Bagnell, Zhiwei Steven Wu","Inverse Reinforcement Learning without Reinforcement Learning",,,,,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Inverse Reinforcement Learning (IRL) is a powerful set of techniques for
imitation learning that aims to learn a reward function that rationalizes
expert demonstrations. Unfortunately, traditional IRL methods suffer from a
computational weakness: they require repeatedly solving a hard reinforcement
learning (RL) problem as a subroutine. This is counter-intuitive from the
viewpoint of reductions: we have reduced the easier problem of imitation
learning to repeatedly solving the harder problem of RL. Another thread of work
has proved that access to the side-information of the distribution of states
where a strong policy spends time can dramatically reduce the sample and
computational complexities of solving an RL problem. In this work, we
demonstrate for the first time a more informed imitation learning reduction
where we utilize the state distribution of the expert to alleviate the global
exploration component of the RL subroutine, providing an exponential speedup in
theory. In practice, we find that we are able to significantly speed up the
prior art on continuous control tasks.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:35:53 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 06:02:25 GMT""}]","2023-06-07"
"2303.14624","Hongyang Du","Jiacheng Wang, Hongyang Du, Dusit Niyato, Zehui Xiong, Jiawen Kang,
  Shiwen Mao, and Xuemin (Sherman) Shen","Guiding AI-Generated Digital Content with Wireless Perception",,,,,"cs.AI cs.HC cs.NI","http://creativecommons.org/licenses/by/4.0/","  Recent advances in artificial intelligence (AI), coupled with a surge in
training data, have led to the widespread use of AI for digital content
generation, with ChatGPT serving as a representative example. Despite the
increased efficiency and diversity, the inherent instability of AI models poses
a persistent challenge in guiding these models to produce the desired content
for users. In this paper, we introduce an integration of wireless perception
(WP) with AI-generated content (AIGC) and propose a unified WP-AIGC framework
to improve the quality of digital content production. The framework employs a
novel multi-scale perception technology to read user's posture, which is
difficult to describe accurately in words, and transmits it to the AIGC model
as skeleton images. Based on these images and user's service requirements, the
AIGC model generates corresponding digital content. Since the production
process imposes the user's posture as a constraint on the AIGC model, it makes
the generated content more aligned with the user's requirements. Additionally,
WP-AIGC can also accept user's feedback, allowing adjustment of computing
resources at edge server to improve service quality. Experiments results verify
the effectiveness of the WP-AIGC framework, highlighting its potential as a
novel approach for guiding AI models in the accurate generation of digital
content.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:39:03 GMT""}]","2023-03-28"
"2303.14625","Norihiro Hanihara","Norihiro Hanihara","Non-commutative resolutions for Segre products and Cohen-Macaulay rings
  of hereditary representation type","35 pages",,,,"math.AC math.AG math.RA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study commutative Cohen-Macaulay rings whose Cohen-Macaulay representation
theory are controlled by representations of quivers, which we call hereditary
representation type. Based on tilting theory and cluster tilting theory, we
construct some commutative Cohen-Macaulay rings of hereditary representation
type. First we give a general existence theorem of cluster tilting module or
non-commutative crepant resolutions on the Segre product of two commutative
Gorenstein rings whenever each factor has such an object. As an application we
obtain three examples of Gorenstein rings of hereditary representation type
coming from Segre products of polynomial rings. Next we introduce extended
numerical semigroup rings which generalize numerical semigroup rings and form a
class of one-dimensional Cohen-Macaulay non-domains, and among them we provide
one family of Gorenstein rings of hereditary representation type. Furthermore,
we discuss a $4$-dimensional non-Gorenstein Cohen-Macaulay ring whose
representations are still controlled by a finite dimensional hereditary
algebra. We show that it has a unique $2$-cluster tilting object, and give a
complete classification of rigid Cohen-Macaulay modules, which turns out to be
only finitely many.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 04:59:09 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 03:16:16 GMT""}]","2023-06-02"
"2303.14626","Yukang Zhang","Yukang Zhang, Yan Yan, Jie Li, Hanzi Wang","MRCN: A Novel Modality Restitution and Compensation Network for
  Visible-Infrared Person Re-identification","Accepted by AAAI-2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visible-infrared person re-identification (VI-ReID), which aims to search
identities across different spectra, is a challenging task due to large
cross-modality discrepancy between visible and infrared images. The key to
reduce the discrepancy is to filter out identity-irrelevant interference and
effectively learn modality-invariant person representations. In this paper, we
propose a novel Modality Restitution and Compensation Network (MRCN) to narrow
the gap between the two modalities. Specifically, we first reduce the modality
discrepancy by using two Instance Normalization (IN) layers. Next, to reduce
the influence of IN layers on removing discriminative information and to reduce
modality differences, we propose a Modality Restitution Module (MRM) and a
Modality Compensation Module (MCM) to respectively distill modality-irrelevant
and modality-relevant features from the removed information. Then, the
modality-irrelevant features are used to restitute to the normalized visible
and infrared features, while the modality-relevant features are used to
compensate for the features of the other modality. Furthermore, to better
disentangle the modality-relevant features and the modality-irrelevant
features, we propose a novel Center-Quadruplet Causal (CQC) loss to encourage
the network to effectively learn the modality-relevant features and the
modality-irrelevant features. Extensive experiments are conducted to validate
the superiority of our method on the challenging SYSU-MM01 and RegDB datasets.
More remarkably, our method achieves 95.1% in terms of Rank-1 and 89.2% in
terms of mAP on the RegDB dataset.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:03:18 GMT""}]","2023-03-28"
"2303.14627","Ryota Yambe","Ryota Yambe and Satoru Hayami","Symmetry analysis of light-induced magnetic interactions via Floquet
  engineering","15 pages, 8 figures, 7 tables",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anisotropic magnetic interactions become the origins of intriguing magnetic
structures, such as helical and skyrmion structures by the
Dzyaloshinskii-Moriya interaction. In general, possible anisotropic exchange
interactions are restricted by crystal symmetry. Meanwhile, by lowering the
crystal symmetry with light, additional anisotropic magnetic interactions are
expected according to its polarization and frequency. In this study, we clarify
a relationship between anisotropic magnetic interactions and symmetry lowering
in insulating magnets irradiated by light. Based on the Floquet formalism, we
find that a variety of anisotropic two-spin and three-spin interactions are
induced via spin-dependent electric polarizations activated by light
irrespective of the presence/absence of the spatial inversion symmetry; we
systematically classify them in the hexagonal point group, tetragonal point
group, and their subgroups. Our symmetry analyses show that the light-induced
two-spin (three-spin) interaction is owing to the reduction of the point group
to a chiral point group (black and white magnetic point group). We also
demonstrate the effect of the light-induced magnetic interactions on the
magnetic structures in a triangular unit. Our results will be a symmetry-based
reference for the Floquet engineering of magnetic structures.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:13:38 GMT""}]","2023-03-28"
"2303.14628","Jiquan Zhong","Jiquan Zhong, Xiaolin Huang, Xiao Yu","Multi-Frame Self-Supervised Depth Estimation with Multi-Scale Feature
  Fusion in Dynamic Scenes","11 pages, 6 figures",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-frame methods improve monocular depth estimation over single-frame
approaches by aggregating spatial-temporal information via feature matching.
However, the spatial-temporal feature leads to accuracy degradation in dynamic
scenes. To enhance the performance, recent methods tend to propose complex
architectures for feature matching and dynamic scenes. In this paper, we show
that a simple learning framework, together with designed feature augmentation,
leads to superior performance. (1) A novel dynamic objects detecting method
with geometry explainability is proposed. The detected dynamic objects are
excluded during training, which guarantees the static environment assumption
and relieves the accuracy degradation problem of the multi-frame depth
estimation. (2) Multi-scale feature fusion is proposed for feature matching in
the multi-frame depth network, which improves feature matching, especially
between frames with large camera motion. (3) The robust knowledge distillation
with a robust teacher network and reliability guarantee is proposed, which
improves the multi-frame depth estimation without computation complexity
increase during the test. The experiments show that our proposed methods
achieve great performance improvement on the multi-frame depth estimation.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:26:30 GMT""}]","2023-03-28"
"2303.14629","Tatyana Barron","Tatyana Barron and Manimugdha Saikia","Average entropy and asymptotics",,,,,"math.DG math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the $N\to \infty$ asymptotics of the expected value of
entanglement entropy in $H_{1,N}\otimes H_{2,N}$, where $H_{1,N}$ and $H_{2,N}$
are the spaces of holomorphic sections of the $N$-th tensor powers of hermitian
ample line bundles on compact complex manifolds.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:30:18 GMT""}]","2023-03-28"
"2303.14630","Pramod Kumar Verma","P. K. Verma","Temperature Dependent Phonon Properties in Tetragonal SrTiO$_3$ and
  Orthorhombic SrZrO$_3$ Perovskites","15 pages, 17 main figures, 13 Tables, and 67 references. I am
  submiting it as a single author",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Using first-principles calculations, we have investigated
temperature-dependent phonon properties in tetragonal SrTiO$_3$ (STO) and
orthorhombic SrZrO$_3$ (SZO) perovskites. Within the quasiharmonic
approximation, we have calculated the mode Gr\""uneisen parameters, thermal
expansion, and frequency shifts for several optical modes. These shifts show a
downward trend with increasing temperature for almost all the modes in both
systems and thus add to the normal behavior of frequencies with temperature.
Next, within the third-order lattice anharmonic effect, we have investigated
the temperature dependence of linewidths and lineshifts for several phonon
modes. Except for a few modes, the lineshifts for most of the modes also show a
downward trend with temperature and thus further leading to the normal
temperature-dependent behavior of phonon modes. However, these lineshifts for a
few optical modes in both the systems show an upward trend with increasing
temperature, which, in principle, could lead to the anomalous
temperature-dependent behavior of the frequencies of these modes; but when we
add all the corrections including the quasiharmonic and third-order anharmonic
shifts to the frequencies as obtained within the harmonic approximation, the
frequencies of almost all the modes behave normally with temperature, i.e. they
display blue shifts with cooling.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:35:34 GMT""}]","2023-03-28"
"2303.14631","Tripta Bhatia","Tripta Bhatia","Stability of multi-lamellar lipid tubules in excess water",,,,,"cond-mat.soft physics.bio-ph","http://creativecommons.org/licenses/by/4.0/","  In the lyotropic phase of lipids with excess water, multilamellar tubules
(MLTs) grow from defects. A phenomenological model for the stability of MLTs is
developed that is universal and independent of the underlying growth mechanisms
of MLTs. The stability of MLTs implies that they are in hydrostatic equilibrium
and stable as elastic objects that have compression and bending elasticity. The
results show that even with 0.1 atm solvent pressure differences, the density
profile is not significantly altered, thus determining that the stability is
due to the trapped solvent. The results are of sufficient value in relation to
lamellar stability models and may have implications beyond the described MLT
models, especially in other models of membrane systems.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:35:38 GMT""}]","2023-03-28"
"2303.14632","Daniel Gonzalez Cedre","Daniel Gonzalez Cedre, Sophia Abraham, Lucas Parzianello, Eric Tsai","Temporal Egonet Subgraph Transitions",,,,,"cs.SI cs.LG","http://creativecommons.org/licenses/by/4.0/","  How do we summarize dynamic behavioral interactions? We introduce a possible
node-embedding-based solution to this question: temporal egonet subgraph
transitions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:37:37 GMT""}]","2023-03-28"
"2303.14633","Xiaoxuan Liu","Xiaoxuan Liu, Siddharth Jha, Alvin Cheung","An Evaluation of Memory Optimization Methods for Training Neural
  Networks",,,,,"cs.LG cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As models continue to grow in size, the development of memory optimization
methods (MOMs) has emerged as a solution to address the memory bottleneck
encountered when training large models. To comprehensively examine the
practical value of various MOMs, we have conducted a thorough analysis of
existing literature from a systems perspective. Our analysis has revealed a
notable challenge within the research community: the absence of standardized
metrics for effectively evaluating the efficacy of MOMs. The scarcity of
informative evaluation metrics hinders the ability of researchers and
practitioners to compare and benchmark different approaches reliably.
Consequently, drawing definitive conclusions and making informed decisions
regarding the selection and application of MOMs becomes a challenging endeavor.
To address the challenge, this paper summarizes the scenarios in which MOMs
prove advantageous for model training. We propose the use of distinct
evaluation metrics under different scenarios. By employing these metrics, we
evaluate the prevailing MOMs and find that their benefits are not universal. We
present insights derived from experiments and discuss the circumstances in
which they can be advantageous.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:40:35 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 03:31:01 GMT""}]","2023-06-06"
"2303.14634","Panagiotis Nikolaidis","Panagiotis Nikolaidis, Asim Zoulkarni and John Baras","Resource Efficiency vs Performance Isolation Tradeoff in Network Slicing",,,,,"cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  We consider the tradeoff between resource efficiency and performance
isolation that emerges when multiplexing the resource demands of Network Slices
(NSs). On the one hand, multiplexing allows the use of idle resources, which
increases resource efficiency. On the other hand, the performance of each NS
becomes susceptible to traffic surges in other NSs, which degrades performance
isolation. The analysis of this tradeoff enables network operators to determine
the effect of performance isolation on the operating cost of each NS.
  To study the tradeoff, we solve an optimization problem where we find the
multiplexing policy that requires the least provisioned resources to honor the
Service Level Agreements (SLAs) of all NSs. The SLA of each NS i states that
its resource demand should be met for $P^H_i$ fraction of time, and for $P^L_i
\leq P^H_i$ fraction of time, it should be met regardless of the demands of
other NSs.
  For resource demands that follow ergodic Markov chains, we show that the
well-known Max-Weight scheduler is an optimal multiplexing policy. Since the
Max-Weight scheduler does not require any knowledge of the statistics of the
resource demands, we also propose its use in non-markovian settings. For
resource demands obtained in the LTE module of ns-3, we show that the
Max-Weight scheduler reduces the provisioned bandwidth by 36.2% when no
performance isolation is required. Lastly, for these non-markovian resource
demands, the Max-Weight scheduler maintains its optimality since it requires as
much provisioned bandwidth as the best non-causal scheduler.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:45:15 GMT""}]","2023-03-28"
"2303.14635","Chao Lei","Chao Lei and Allan H. MacDonald","Kerr, Faraday, and Magnetoelectric Effects in MnBi$_2$Te$_4$ Thin Films","5+7 pages",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The topological magneto-electric effect (TME) is a characteristic property of
topological insulators. In this article we use a simplified coupled-Dirac-cone
electronic structure model to theoretically evaluate the THz and far infrared
Kerr and Faraday responses of thin films of MnBi$_2$Te$_4$ with up to $N=10$
septuple layers with the goal of clarifying the relationship between these
convenient magneto-optical observable and the TME. We find that for even $N$
the linear Kerr and Faraday responses to an electric field vanish in the
low-frequency limit, even though the the magnetoelectric response is large and
approximately quantized.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:00:47 GMT""}]","2023-03-28"
"2303.14636","Peter Petrik","Deshabrato Mukherjee, Benjamin Kalas, Sven Burger, Gyorgy Safran,
  Miklos Serenyi, Miklos Fried, Peter Petrik","Nanostructures for in-situ surface-enhanced Kretschmann-Raether
  ellipsometry","9 pages, 3 figures, SPIE Photonics West conference contribution","Proc. SPIE Vol. 12428 (2023) 124280S","10.1117/12.2649080",,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Spectroscopic ellipsometry is a sensitive and optical model-supported
quantitative tool to monitor interfaces. In this work, solid-liquid interfaces
are studied using the Kretschmann-Raether configuration for biosensing
applications. The interface layers support two purposes simultaneously: (i)
chemical suitability for the adsorption of molecules to be detected and (ii)
the optical enhancement of the signal to increase the sensitivity. Ellipsometry
is not only used as a sensor but also as a quantitative measurement tool to
study and understand the interface phenomena, and to develop the sensing layers
for the largest possible optical sensitivity. Plasmonic and structured layers
are of primary importance in terms of optical sensitivity. Layers structured
both in lateral and vertical directions have been studied. Optical models based
on both the transfer matrix and the finite element method were developed and
used for the structural analysis where the material and geometrical derivatives
are used in the inverse fitting process of the model data to the measurement.
Structures utilizing plasmonic, diffraction, multilayer field enhancement, and
other methods were analyzed as possible candidates for the improvement of the
optical performance of the cell. Combinatorial and periodic plasmonic surface
structures were developed to enhance the sensitivity of in-situ ellipsometry at
solid-liquid interfaces utilizing the Kretschmann-Raether (KR) geometry.
Ag$_x$Al$_{1-x}$ layers with variable compositions and Au layers with changing
periods and critical dimensions were investigated to improve the performance of
sensors based on the KR arrangement.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:05:29 GMT""}]","2023-03-28"
"2303.14637","Sixian Wang","Sixian Wang, Jincheng Dai, Xiaoqi Qin, Zhongwei Si, Kai Niu, and Ping
  Zhang","Improved Nonlinear Transform Source-Channel Coding to Catalyze Semantic
  Communications",,,,,"eess.SP cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent deep learning methods have led to increased interest in solving
high-efficiency end-to-end transmission problems. These methods, we call
nonlinear transform source-channel coding (NTSCC), extract the semantic latent
features of source signal, and learn entropy model to guide the joint
source-channel coding with variable rate to transmit latent features over
wireless channels. In this paper, we propose a comprehensive framework for
improving NTSCC, thereby higher system coding gain, better model versatility,
and more flexible adaptation strategy aligned with semantic guidance are all
achieved. This new sophisticated NTSCC model is now ready to support large-size
data interaction in emerging XR, which catalyzes the application of semantic
communications. Specifically, we propose three useful improvement approaches.
First, we introduce a contextual entropy model to better capture the spatial
correlations among the semantic latent features, thereby more accurate rate
allocation and contextual joint source-channel coding are developed accordingly
to enable higher coding gain. On that basis, we further propose response
network architectures to formulate versatile NTSCC, i.e., once-trained model
supports various rates and channel states that benefits the practical
deployment. Following this, we propose an online latent feature editing method
to enable more flexible coding rate control aligned with some specific semantic
guidance. By comprehensively applying the above three improvement methods for
NTSCC, a deployment-friendly semantic coded transmission system stands out
finally. Our improved NTSCC system has been experimentally verified to achieve
considerable bandwidth saving versus the state-of-the-art engineered VTM + 5G
LDPC coded transmission system with lower processing latency.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:09:53 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 15:11:39 GMT""}]","2023-05-25"
"2303.14638","Yang Tian","Yang Tian, Pei Sun","A non-isomorphic decomposition analysis of percolation, correlated
  systems, and renormalization groups",,,,,"cond-mat.stat-mech cond-mat.dis-nn math-ph math.MP physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Any system with internal correlations (e.g., interactions), such as spin
glasses, random media, and brains, can be studied as a network where nodes are
elements and edges denote correlated interactions. As internal correlations
increase, correlated behaviours originate and propagate among elements to
create percolation phenomena. In this work, we study percolation in correlated
systems by proposing a framework referred to as the non-isomorphic
decomposition analysis. This framework analyzes the evolution of the space of
non-isomorphic percolation configuration classes governed by internal
correlations, where a metric called as the automorphism entropy is proposed to
measure the reduction of information (i.e., freedom degrees) in the space. A
special case of our theory under the mean-field approximation is elaborated,
where all concepts can be explicitly calculated based on group theory and
percolation theory. Our framework has been applied to studying absorbing phase
transition, spreading process, and synchronization, whose results reveal the
shared properties of percolation and dynamics in different correlated systems.
First, the percolation process driven by internal correlations is intrinsically
an information loss process in the probability space of non-isomorphic
percolation configuration classes. The metric of information loss degree,
automorphism entropy, serves as a sensitive indicator of percolation transition
and related processes in diverse systems. Second, the information loss
intensity depends on the strength of internal correlations. Sufficiently strong
correlations ensure slight information losses and make specific freedom degrees
omissible, which supports the implementation of renormalization groups.
Sufficiently weak correlations, on the contrary, imply significant information
losses and make renormalization groups less effective for the correlated
system.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:16:05 GMT""}]","2023-03-28"
"2303.14639","Xihan Wang","Xihan Wang, Xi Xu, Yu Gao, Yi Yang, Yufeng Yue and Mengyin Fu","CRRS: Concentric Rectangles Regression Strategy for Multi-point
  Representation on Fisheye Images",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern object detectors take advantage of rectangular bounding boxes as a
conventional way to represent objects. When it comes to fisheye images,
rectangular boxes involve more background noise rather than semantic
information. Although multi-point representation has been proposed, both the
regression accuracy and convergence still perform inferior to the widely used
rectangular boxes. In order to further exploit the advantages of multi-point
representation for distorted images, Concentric Rectangles Regression
Strategy(CRRS) is proposed in this work. We adopt smoother mean loss to
allocate weights and discuss the effect of hyper-parameter to prediction
results. Moreover, an accurate pixel-level method is designed to obtain
irregular IoU for estimating detector performance. Compared with the previous
work for muti-point representation, the experiments show that CRRS can improve
the training performance both in accurate and stability. We also prove that
multi-task weighting strategy facilitates regression process in this design.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:19:24 GMT""}]","2023-03-28"
"2303.14640","Sixian Wang","Jincheng Dai, Sixian Wang, Ping Zhang, Xiaoqi Qin, Kai Niu, and
  Zhongwei Si","Dimensions of Semantic Coding: Explicit and Implicit",,,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in deep learning have led to increased interest in solving
high-efficiency end-to-end transmission problems using methods that employ the
nonlinear property of neural networks. These methods, we call semantic coding,
extract semantic features of the source signal across space and time, and
design source-channel coding methods to transmit these features over wireless
channels. Rapid progress has led to numerous research papers, but a
consolidation of the discovered knowledge has not yet emerged. In this article,
we gather ideas to categorize the expansive aspects on semantic coding as two
paradigms, i.e., explicit and implicit semantic coding. We first focus on those
two paradigms of semantic coding by identifying their common and different
components in building semantic communication systems. We then focus on the
applications of semantic coding to different transmission tasks. Our article
highlights the improved quality, flexibility, and capability brought by
semantic coded transmission. Finally, we point out future directions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:26:50 GMT""}]","2023-03-28"
"2303.14641","Prakash Chandra Mondal Prof.","Ritu Gupta, Ankur Malik, Vincent Vivier and Prakash Chandra Mondal","Nanoscale molecular electrochemical supercapacitors","18 pages, 6 Figures",,,,"physics.app-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Due to the shorter channel length allowing faster ion/charge movement,
nanoscale molecular thin films can be attractive electronic components for
next-generation high-performing energy storage devices. However, controlling
chemical functionalization and achieving stable electrode-molecule interfaces
at the nanoscale via covalent functionalization for low-voltage operational,
ultrafast charging/discharging remains a challenge. Herein, we present a
simple, controllable, scalable, low-cost, and versatile electrochemical
grafting approach to modulate chemical and electronic properties of graphite
rods (GRs) that are extracted from low-cost EVEREADY cells (1.5 US $ for 10
cells of 1.5 V). On the ANT-modified GR (ANT/GR), the total capacitance unveils
350-fold enhancement as compared to an unmodified GR tested with 0.1 M H2SO4
electrolyte ensured by both potentiostatic and galvanostatic measurements. Such
enhancement in capacitance is attributed to the contribution from the
electrical double layer and Faradaic charge transfer. Due to higher
conductivity, anthracene molecular layers possess more azo groups (-N=N-) over
pyrene, and naphthalene molecular films during the electrochemical grafting,
which is key to capacitance improvements. The ultra-low-loading nanofilms
expose high surface area leading to extremely high energy density. The
nanoscale molecular films (~ 23 nm thickness) show exceptional galvanostatic
charge-discharge cycling stability (10,000) that operates at low potential.
Electrochemical impedance spectroscopy was performed along with the DC
measurements to unravel in-depth charge storage performances. Electrochemically
grafted molecular films on GR show excellent balance in capacitance and
electrical conductivity, high diffusion coefficient toward ferrocene, and can
easily be synthesized in good yield on rigid to flexible electrodes.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:47:14 GMT""}]","2023-03-28"
"2303.14642","Morgan Lynch","Morgan H. Lynch","Experimental observation of a Rindler horizon","4 pages, 3 figures",,,,"hep-ph gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  In this manuscript we confirm the presence of a Rindler horizon at CERN-NA63
by exploring its thermodynamics induced by the Unruh effect in their high
energy channeling radiation experiments. By linking the entropy of the emitted
radiation to the photon number, we find the measured spectrum to be a simple
manifestation of the second law of Rindler horizon thermodynamics and thus a
direct measurement of the recoil Fulling-Davies-Unruh (FDU) temperature.
Moreover, since the experiment is born out of an ultra-relativistic positron,
and the FDU temperature is defined in the proper frame, we find that
temperature boosts as a length and thus fast objects appear colder. The
spectrum also provides us with a simple setting to measure fundamental
constants, and we employ it to measure the positron mass.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:51:29 GMT""}]","2023-03-28"
"2303.14643","Yue Zhang","YUE Zhang, Suchen Wang, Shichao Kan, Zhenyu Weng, Yigang Cen, Yap-peng
  Tan","POAR: Towards Open-World Pedestrian Attribute Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pedestrian attribute recognition (PAR) aims to predict the attributes of a
target pedestrian in a surveillance system. Existing methods address the PAR
problem by training a multi-label classifier with predefined attribute classes.
However, it is impossible to exhaust all pedestrian attributes in the real
world. To tackle this problem, we develop a novel pedestrian open-attribute
recognition (POAR) framework. Our key idea is to formulate the POAR problem as
an image-text search problem. We design a Transformer-based image encoder with
a masking strategy. A set of attribute tokens are introduced to focus on
specific pedestrian parts (e.g., head, upper body, lower body, feet, etc.) and
encode corresponding attributes into visual embeddings. Each attribute category
is described as a natural language sentence and encoded by the text encoder.
Then, we compute the similarity between the visual and text embeddings of
attributes to find the best attribute descriptions for the input images.
Different from existing methods that learn a specific classifier for each
attribute category, we model the pedestrian at a part-level and explore the
searching method to handle the unseen attributes. Finally, a many-to-many
contrastive (MTMC) loss with masked tokens is proposed to train the network
since a pedestrian image can comprise multiple attributes. Extensive
experiments have been conducted on benchmark PAR datasets with an
open-attribute setting. The results verified the effectiveness of the proposed
POAR method, which can form a strong baseline for the POAR task.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 06:59:23 GMT""}]","2023-03-28"
"2303.14644","Joya Chen","Joya Chen, Difei Gao, Kevin Qinghong Lin, Mike Zheng Shou","Affordance Grounding from Demonstration Video to Target Image","CVPR 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans excel at learning from expert demonstrations and solving their own
problems. To equip intelligent robots and assistants, such as AR glasses, with
this ability, it is essential to ground human hand interactions (i.e.,
affordances) from demonstration videos and apply them to a target image like a
user's AR glass view. The video-to-image affordance grounding task is
challenging due to (1) the need to predict fine-grained affordances, and (2)
the limited training data, which inadequately covers video-image discrepancies
and negatively impacts grounding. To tackle them, we propose Affordance
Transformer (Afformer), which has a fine-grained transformer-based decoder that
gradually refines affordance grounding. Moreover, we introduce Mask Affordance
Hand (MaskAHand), a self-supervised pre-training technique for synthesizing
video-image data and simulating context changes, enhancing affordance grounding
across video-image discrepancies. Afformer with MaskAHand pre-training achieves
state-of-the-art performance on multiple benchmarks, including a substantial
37% improvement on the OPRA dataset. Code is made available at
https://github.com/showlab/afformer.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:02:41 GMT""}]","2023-03-28"
"2303.14645","Dianyi Yang","Dianyi Yang, Jiadong Tang, Yu Gao, Yi Yang, Mengyin Fu","Sector Patch Embedding: An Embedding Module Conforming to The Distortion
  Pattern of Fisheye Image",,,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fisheye cameras suffer from image distortion while having a large field of
view(LFOV). And this fact leads to poor performance on some fisheye vision
tasks. One of the solutions is to optimize the current vision algorithm for
fisheye images. However, most of the CNN-based methods and the
Transformer-based methods lack the capability of leveraging distortion
information efficiently. In this work, we propose a novel patch embedding
method called Sector Patch Embedding(SPE), conforming to the distortion pattern
of the fisheye image. Furthermore, we put forward a synthetic fisheye dataset
based on the ImageNet-1K and explore the performance of several Transformer
models on the dataset. The classification top-1 accuracy of ViT and PVT is
improved by 0.75% and 2.8% with SPE respectively. The experiments show that the
proposed sector patch embedding method can better perceive distortion and
extract features on the fisheye images. Our method can be easily adopted to
other Transformer-based models. Source code is at
https://github.com/IN2-ViAUn/Sector-Patch-Embedding.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:20:02 GMT""}]","2023-03-28"
"2303.14646","Dacheng Wen","Dacheng Wen, Yupeng Li, Francis C.M. Lau","A Survey of Machine Learning-Based Ride-Hailing Planning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Ride-hailing is a sustainable transportation paradigm where riders access
door-to-door traveling services through a mobile phone application, which has
attracted a colossal amount of usage. There are two major planning tasks in a
ride-hailing system: (1) matching, i.e., assigning available vehicles to pick
up the riders, and (2) repositioning, i.e., proactively relocating vehicles to
certain locations to balance the supply and demand of ride-hailing services.
Recently, many studies of ride-hailing planning that leverage machine learning
techniques have emerged. In this article, we present a comprehensive overview
on latest developments of machine learning-based ride-hailing planning. To
offer a clear and structured review, we introduce a taxonomy into which we
carefully fit the different categories of related works according to the types
of their planning tasks and solution schemes, which include collective
matching, distributed matching, collective repositioning, distributed
repositioning, and joint matching and repositioning. We further shed light on
many real-world datasets and simulators that are indispensable for empirical
studies on machine learning-based ride-hailing planning strategies. At last, we
propose several promising research directions for this rapidly growing research
and practical field.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:21:03 GMT""}]","2023-03-28"
"2303.14647","Behrouz Minaei-Bidgoli","Najmeh Torabian, Behrouz Minaei-Bidgoli and Mohsen Jahanshahi","Farspredict: A benchmark dataset for link prediction","13 pages, 3 figures, 1 algorithm and 5 tables",,,,"cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Link prediction with knowledge graph embedding (KGE) is a popular method for
knowledge graph completion. Furthermore, training KGEs on non-English knowledge
graph promote knowledge extraction and knowledge graph reasoning in the context
of these languages. However, many challenges in non-English KGEs pose to
learning a low-dimensional representation of a knowledge graph's entities and
relations. This paper proposes ""Farspredict"" a Persian knowledge graph based on
Farsbase (the most comprehensive knowledge graph in Persian). It also explains
how the knowledge graph structure affects link prediction accuracy in KGE. To
evaluate Farspredict, we implemented the popular models of KGE on it and
compared the results with Freebase. Given the analysis results, some
optimizations on the knowledge graph are carried out to improve its
functionality in the KGE. As a result, a new Persian knowledge graph is
achieved. Implementation results in the KGE models on Farspredict outperforming
Freebases in many cases. At last, we discuss what improvements could be
effective in enhancing the quality of Farspredict and how much it improves.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:41:26 GMT""}]","2023-03-28"
"2303.14648","Prakash Chandra Mondal Prof.","Ranjeev Kumar Parashar, Suchita Kandpal, Prasanta Bandyopadhyay,
  Mainak Sadhukhan, Rajesh Kumar, and Prakash Chandra Mondal","Molecular lighting goes less powering","13 Pages, 7 Figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  The present era has seen tremendous demands for low-cost electrochromic
materials for visible-region multicolor display technology, paper-based,
flexible, and wearable electronic devices, smart windows, and optoelectronic
applications. Towards this goal, we report large-scale polyelectrochromic
devices fabricated on rigid to flexible ITO substrates comprising novel
anthracene containing viologen,
(1,1'-bis(anthracen-9-ylmethyl)-[4,4'-bipyridine]-1,1'-diium bromide,
abbreviated as AnV2+), and polythiophene (P3HT). Inter-estingly, the devices
show three states of reversible visible color in response to the applied bias,
sub-second to second switching time (0.7 s/1.6 s), and high coloration
efficiency (484 cm2/C), longer cycling stability up to 3000 s (103 switching
cycles). Thanks to the anthracenes moieties introduced to viologen that inhibit
formation of undesired dimer of cation radicals formed in response to the
applied bias, other-wise it would hamper the devices reconfiguration. The
devices are fully characterized, and electrochromic performances are ensured by
bias-dependent UV-Vis, and Raman spectroscopy. The fabricated electro-chromic
devices are tested with the commercially available low-cost cells to perform,
which is highly de-sired for practical applications. The computational study
facilitates the understanding of experimental re-sults. The alternating current
(AC)-based electrical impedance spectroscopy reveals that P3HT facilitates
reducing charge transfer resistance of the devices. Our work shows CMOS
compatibility and one of the best-performing devices that could pave the way
for developing cost-effective flexible, and wearable electrochromic devices.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:42:19 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 14:56:46 GMT""}]","2023-03-29"
"2303.14649","Preeti Bhandari","Preeti Bhandari, Vikas Malik and Moshe Schechter","Variable range hopping in a non-equilibrium steady state","8 pages, 7 figures",,,,"cond-mat.dis-nn","http://creativecommons.org/licenses/by/4.0/","  We propose a Monte Carlo simulation to understand electron transport in a
non-equilibrium steady state (\textit{NESS}) for the lattice Coulomb Glass
model, created by continuous excitation of single electrons to high energies
followed by relaxation of the system. Around the Fermi level, the \textit{NESS}
state approximately obeys the Fermi-Dirac statistics, with an effective
temperature ($T_{eff}$) greater than the system's bath temperature ($T$).
$T_{eff}$ is a function of $T$ and the rate of photon absorption by the system.
Furthermore, we find that the change in conductivity is only a function of
relaxation times and is almost independent of the bath temperature. Our results
indicate that the conductivity of the \textit{NESS} state can still be
characterized by the Efros-Shklovskii law with an effective temperature
$T_{eff}>T$. Additionally, the dominance of phonon-less hopping over
phonon-assisted hopping is used to explain the relevance of the hot-electron
model to the conductivity of the \textit{NESS} state.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:43:38 GMT""}]","2023-03-28"
"2303.14650","Gerardo F. Goya","Jes\'us A. Fuentes-Garc\'ia, Beatriz Sanz-Sagu\'e, Reyes Mallada, M.
  Ricardo Ibarra and Gerardo F. Goya","Magnetic nanofibers for remotely triggered catalytic activity applied to
  the degradation of organic pollutants","31 pages, 16 figures","Materials & Design 226 (2023) 111615","10.1016/j.matdes.2023.111615",,"physics.app-ph cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  This work reports on the synthesis and characterization of a new type of
electrospun magnetic nanofibers (MNFs), and their application for degradation
of organic pollutants using remote magnetic inductive heating. We describe a
simple protocol combining a fast (app. 5 min) synthesis of
MnFe\textsubscript{2}O\textsubscript{4} magnetic nanoparticles (MNPs) by
sonochemical route, optimized for inductive heating, with their subsequent
incorporation in electrospun MNFs composed of polyacrylonitrile (PAN)
nanofibers. The resulting multifunctional MNFs (average diameter $\phi = 760
\pm 150$ nm) contain up to $\approx 30%$wt. of the MNPs. The composite showed
superhydrophobic behaviour ($\theta_c = 165^\circ$) and a band gap value of
1.75 eV. We found that the presence of MNPs embedded into the polymeric
nanofibers modify the exothermic and the glass transitions temperatures
compared with pure PAN nanofibers, suggesting a strong attachment between MNPs
and polymeric chains. The MNFs could be remotely activated by alternating
magnetic fields (AMF, $f = 200-800$ kHz, $H_0 = 10-36$ kA/m) for accelerating
the catalytic reactions of the organic dye methylene blue (MB). A remarkable
stability of the MNFs against degradation under extreme pH conditions
($3<pH<10$) resulted in a sustained heating efficiency after many heating
cycles. We observed a degradation efficiency $>80%$ in the presence of hydrogen
peroxide under AMFs, attributed to Fe\textsuperscript{2+}/\textsuperscript{3+}
and Mn\textsuperscript{2+}/\textsuperscript{3+}/\textsuperscript{4+} active
centers on the surface of the MNP/MNFs observed from XPS data. The capacity of
these materials for magnetic remote activation appeals catalytic applications
under conditions of darkness or restrained access, where no photocatalytic
reactions can be achieved.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:44:00 GMT""}]","2023-03-28"
"2303.14651","Jie Hu","Jie Hu, Linyan Huang, Tianhe Ren, Shengchuan Zhang, Rongrong Ji, and
  Liujuan Cao","You Only Segment Once: Towards Real-Time Panoptic Segmentation","CVPR 2023",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose YOSO, a real-time panoptic segmentation framework.
YOSO predicts masks via dynamic convolutions between panoptic kernels and image
feature maps, in which you only need to segment once for both instance and
semantic segmentation tasks. To reduce the computational overhead, we design a
feature pyramid aggregator for the feature map extraction, and a separable
dynamic decoder for the panoptic kernel generation. The aggregator
re-parameterizes interpolation-first modules in a convolution-first way, which
significantly speeds up the pipeline without any additional costs. The decoder
performs multi-head cross-attention via separable dynamic convolution for
better efficiency and accuracy. To the best of our knowledge, YOSO is the first
real-time panoptic segmentation framework that delivers competitive performance
compared to state-of-the-art models. Specifically, YOSO achieves 46.4 PQ, 45.6
FPS on COCO; 52.5 PQ, 22.6 FPS on Cityscapes; 38.0 PQ, 35.4 FPS on ADE20K; and
34.1 PQ, 7.1 FPS on Mapillary Vistas. Code is available at
https://github.com/hujiecpp/YOSO.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:55:35 GMT""}]","2023-03-28"
"2303.14652","Bohao Peng","Bohao Peng, Zhuotao Tian, Xiaoyang Wu, Chenyao Wang, Shu Liu, Jingyong
  Su, Jiaya Jia","Hierarchical Dense Correlation Distillation for Few-Shot Segmentation","to be published in CVPR 2023, code is available at
  \url{https://github.com/Pbihao/HDMNet}",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Few-shot semantic segmentation (FSS) aims to form class-agnostic models
segmenting unseen classes with only a handful of annotations. Previous methods
limited to the semantic feature and prototype representation suffer from coarse
segmentation granularity and train-set overfitting. In this work, we design
Hierarchically Decoupled Matching Network (HDMNet) mining pixel-level support
correlation based on the transformer architecture. The self-attention modules
are used to assist in establishing hierarchical dense features, as a means to
accomplish the cascade matching between query and support features. Moreover,
we propose a matching module to reduce train-set overfitting and introduce
correlation distillation leveraging semantic correspondence from coarse
resolution to boost fine-grained segmentation. Our method performs decently in
experiments. We achieve $50.0\%$ mIoU on \coco~dataset one-shot setting and
$56.0\%$ on five-shot segmentation, respectively.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:13:12 GMT""}]","2023-03-28"
"2303.14653","Min Wang","Yingda Guan, Zhengyang Feng, Huiying Chang, Kuo Du, Tingting Li, Min
  Wang","SDTracker: Synthetic Data Based Multi-Object Tracking","cvpr2022 workshop",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present SDTracker, a method that harnesses the potential of synthetic data
for multi-object tracking of real-world scenes in a domain generalization and
semi-supervised fashion. First, we use the ImageNet dataset as an auxiliary to
randomize the style of synthetic data. With out-of-domain data, we further
enforce pyramid consistency loss across different ""stylized"" images from the
same sample to learn domain invariant features. Second, we adopt the
pseudo-labeling method to effectively utilize the unlabeled MOT17 training
data. To obtain high-quality pseudo-labels, we apply proximal policy
optimization (PPO2) algorithm to search confidence thresholds for each
sequence. When using the unlabeled MOT17 training set, combined with the
pure-motion tracking strategy upgraded via developed post-processing, we
finally reach 61.4 HOTA.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:21:22 GMT""}]","2023-03-28"
"2303.14654","Gerardo F. Goya","Zhila Shaterabadi, Gholamreza Nabiyouni, Gerardo F Goya, Meysam
  Soleymani","The effect of the magnetically dead layer on the magnetization and the
  magnetic anisotropy of the dextran coated magnetite nanoparticles","16 pages, 1 table, 3 figures","Applied Physics A (2022) 128:631","10.1007/s00339-022-05675-x",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We present a study on the magnetic behavior of dextran-coated magnetite
nanoparticles (DM NPs) with sizes between 3 and 19 nm, synthesized by
hydrothermal-assisted co-precipitation method. The decrease of saturation
magnetization ($M_s$) with decreasing particle size has been modeled by
assuming the existence of a spin-disordered layer at the particle surface,
which is magnetically dead. Based on this core-shell model and taking into
account the weight contribution of the non-magnetic coating layer (dextran) to
the whole magnetization, the dead layer thickness ($t$) and saturation
magnetization $M_s$ of the magnetic cores in our samples were estimated to be
$t = 6.8~\mathrm{\AA}$ and $M_s = 98.8~\mathrm{emu/g}$, respectively. The data
of $M_s$ were analyzed using a law of approach to saturation, indicating an
increase in effective magnetic anisotropy ($K_{eff}$) with decreasing particle
size as expected from the increased surface/volume ratio in small MNPs. The
obtained $K_{eff}$ values were successfully modeled by including an extra
contribution of dipolar interactions due to the formation of chain-like
clusters of MNPs. The surface magnetic anisotropy ($K_s$) was estimated to be
about $K_s = 1.04\times10^5~\mathrm{J/m^3}$. Our method provides a simple and
accurate way to obtain the $M_s$ core values in surface-disordered MNPs, a
relevant parameter required for magnetic modeling in many applications.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:29:31 GMT""}]","2023-03-28"
"2303.14655","Ji Qi","Ji Qi, Jifan Yu, Teng Tu, Kunyu Gao, Yifan Xu, Xinyu Guan, Xiaozhi
  Wang, Yuxiao Dong, Bin Xu, Lei Hou, Juanzi Li, Jie Tang, Weidong Guo, Hui
  Liu, Yu Xu","GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for
  Real-time Soccer Commentary Generation",,,,,"cs.CV cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the recent emergence of video captioning models, how to generate
vivid, fine-grained video descriptions based on the background knowledge (i.e.,
long and informative commentary about the domain-specific scenes with
appropriate reasoning) is still far from being solved, which however has great
applications such as automatic sports narrative. In this paper, we present
GOAL, a benchmark of over 8.9k soccer video clips, 22k sentences, and 42k
knowledge triples for proposing a challenging new task setting as
Knowledge-grounded Video Captioning (KGVC). Moreover, we conduct experimental
adaption of existing methods to show the difficulty and potential directions
for solving this valuable and applicable task.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:43:36 GMT""}]","2023-03-28"
"2303.14656","Kan Kitamura","Kan Kitamura","Discrete quantum subgroups of complex semisimple quantum groups","15 pages",,,,"math.QA math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify discrete quantum subgroups in the quantum double of the
$q$-deformation of a compact semisimple Lie group, regarded as the
complexification. We also record their classifications in some variants of
quantum groups. Along the way, we show that quantum doubles of non-Kac type
compact quantum groups do not admit the quantum analog of lattices considered
by Brannan-Chirvasitu-Viselter.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:52:30 GMT""}]","2023-03-28"
"2303.14657","Martin Donati","Martin Donati","Construction of unstable concentrated solutions of the Euler and gSQG
  equations",,,,,"math.AP math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we construct smooth initial data to the Euler and gSQG
equations that are concentrated near unstable stationary configurations of
point-vortices. We prove that those solutions are themselves unstable, in the
sense that their localization radius grows from order $\varepsilon$ to order
$\varepsilon^\beta$ (with $\beta < 1$) in a time of order $|\ln\varepsilon|$.
This proves in particular that the logarithmic lower-bound obtained in previous
papers (in particular [P. Butt\`a and C. Marchioro, Long time evolution of
concentrated Euler flows with planar symmetry, SIAM J. Math. Anal.,
50(1):735-760, 2018]) about vorticity localization in Euler and gSQG equations
is optimal. In addition we construct unstable solutions of the Euler equations
in bounded domains concentrated around a single point. To achieve this we
construct a domain whose Robin's function has a saddle point.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:57:32 GMT""}]","2023-03-28"
"2303.14658","Xuetong Wu","Xuetong Wu, Jonathan H. Manton, Uwe Aickelin, Jingge Zhu","On the tightness of information-theoretic bounds on generalization error
  of learning algorithms","32 pages, 1 figure. arXiv admin note: substantial text overlap with
  arXiv:2205.03131",,,,"cs.IT cs.LG math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent line of works, initiated by Russo and Xu, has shown that the
generalization error of a learning algorithm can be upper bounded by
information measures. In most of the relevant works, the convergence rate of
the expected generalization error is in the form of $O(\sqrt{\lambda/n})$ where
$\lambda$ is some information-theoretic quantities such as the mutual
information or conditional mutual information between the data and the learned
hypothesis. However, such a learning rate is typically considered to be
``slow"", compared to a ``fast rate"" of $O(\lambda/n)$ in many learning
scenarios. In this work, we first show that the square root does not
necessarily imply a slow rate, and a fast rate result can still be obtained
using this bound under appropriate assumptions. Furthermore, we identify the
critical conditions needed for the fast rate generalization error, which we
call the $(\eta,c)$-central condition. Under this condition, we give
information-theoretic bounds on the generalization error and excess risk, with
a fast convergence rate for specific learning algorithms such as empirical risk
minimization and its regularized version. Finally, several analytical examples
are given to show the effectiveness of the bounds.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 08:59:05 GMT""}]","2023-03-28"
"2303.14659","Xin Yue","Xin Yue, Guo-Jian Qiao, C. P. Sun","Refined Majorana phase diagram in topological insulator-superconductor
  hybrid system",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The edge state of the topological insulator coupled to a superconductor
system is able to simulate the Majorana fermion in zero energy mode since the
Kitaev-type pairing is induced by exchanging quasi-excitations in electron
tunneling. However, the present study has revealed that this physical
simulation is not valid for a larger surface gap, which is the energy gap of
the insulator's surface states. To address this issue, a refined pairing term
that depends on the surface gap has been obtained as a second-order effect of
the proximity effect, whereas the lowest order produces a constant pairing
strength. By carefully considering the dependence of pairing strength on the
surface gap, the Majorana phase diagram is re-achieved and a significant
difference from previous work is observed, where the pairing strength was
assumed to be independent of the surface gap and resulted in a conical phase
boundary.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:04:16 GMT""}]","2023-03-28"
"2303.14660","Sa Wang","Sa Wang, Wei Dai, Enke Wang, Xin-Nian Wang and Ben-Wei Zhang","Heavy-Flavour Jets in High-Energy Nuclear Collisions","27 pages, 9 figures. Contribution to the Special Issue ""Heavy-Ion
  Collisions and Multiparticle Production""","Symmetry 2023, 15(3), 727","10.3390/sym15030727",,"nucl-th hep-ph","http://creativecommons.org/licenses/by/4.0/","  Reconstructed jets initiated from heavy quarks provide a powerful tool to
probe the properties of the quark-gluon plasma (QGP) and to explore the mass
hierarchy of jet quenching. In this article, we review the recent theoretical
progresses on heavy-flavour jets in high-energy nuclear collisions at the RHIC
and LHC. We focus on the yields and substructures of charm and bottom quark
jets with jet quenching effect, such as the nuclear modification factors,
transverse momentum imbalance, angular correlation, radial profiles,
fragmentation functions, the ""dead-cone"" effect, etc.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:06:00 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 08:57:10 GMT""}]","2023-03-31"
"2303.14661","Tuan Dang Anh","Duong Trong Luyen, Nguyen Minh Tri and Dang Anh Tuan","Nontrivial solutions to the Dirichlet problems for semilinear degenerate
  elliptic equations","14 pages",,,,"math.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this article, we study the existence of non-trivial weak solutions for the
following boundary-value problem
  \begin{gather*}
  -\frac{\partial^2 u}{\partial x^2} -\left|x\right|^{2k}\frac{\partial^2
u}{\partial y^2}=f(x,y,u) \quad\text{ in }\Omega, \
  u=0 \quad\text{ on }\partial\Omega,
  \end{gather*} where $\Omega$ is a bounded domain with smooth boundary in
$\mathbb{R}^2, \Omega \cap \{x=0\}\ne \emptyset,$ $k >0,$ $f(x,y,0)=0. $
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:07:13 GMT""}]","2023-03-28"
"2303.14662","Zhiyuan Ma","Zhiyuan Ma, Xiangyu Zhu, Guojun Qi, Zhen Lei, Lei Zhang","OTAvatar: One-shot Talking Face Avatar with Controllable Tri-plane
  Rendering","Accepted by CVPR 2023. The code is available at
  https://github.com/theEricMa/OTAvatar",,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Controllability, generalizability and efficiency are the major objectives of
constructing face avatars represented by neural implicit field. However,
existing methods have not managed to accommodate the three requirements
simultaneously. They either focus on static portraits, restricting the
representation ability to a specific subject, or suffer from substantial
computational cost, limiting their flexibility. In this paper, we propose
One-shot Talking face Avatar (OTAvatar), which constructs face avatars by a
generalized controllable tri-plane rendering solution so that each personalized
avatar can be constructed from only one portrait as the reference.
Specifically, OTAvatar first inverts a portrait image to a motion-free identity
code. Second, the identity code and a motion code are utilized to modulate an
efficient CNN to generate a tri-plane formulated volume, which encodes the
subject in the desired motion. Finally, volume rendering is employed to
generate an image in any view. The core of our solution is a novel
decoupling-by-inverting strategy that disentangles identity and motion in the
latent code via optimization-based inversion. Benefiting from the efficient
tri-plane representation, we achieve controllable rendering of generalized face
avatar at $35$ FPS on A100. Experiments show promising performance of
cross-identity reenactment on subjects out of the training set and better 3D
consistency.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:12:03 GMT""}]","2023-03-28"
"2303.14663","Felix Christian Clemen","J\'ozsef Balogh, Felix Christian Clemen, Adrian Dumitrescu","Almost Congruent Triangles",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Almost $50$ years ago Erd\H{o}s and Purdy asked the following question: Given
$n$ points in the plane, how many triangles can be approximate congruent to
equilateral triangles? They pointed out that by dividing the points evenly into
three small clusters built around the three vertices of a fixed equilateral
triangle, one gets at least $\left\lfloor \frac{n}{3} \right\rfloor \cdot
\left\lfloor \frac{n+1}{3} \right\rfloor \cdot \left\lfloor \frac{n+2}{3}
\right\rfloor$ such approximate copies. In this paper we provide a matching
upper bound and thereby answer their question.
  More generally, for every triangle $T$ we determine the maximum number of
approximate congruent triangles to $T$ in a point set of size $n$. Parts of our
proof are based on hypergraph Tur\'an theory: for each point set in the plane
and a triangle $T$, we construct a $3$-uniform hypergraph
$\mathcal{H}=\mathcal{H}(T)$, which contains no hypergraph as a subgraph from a
family of forbidden hypergraphs $\mathcal{F}=\mathcal{F}(T)$. Our upper bound
on the number of edges of $\mathcal{H}$ will determine the maximum number of
triangles that are approximate congruent to $T$.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:12:16 GMT""}]","2023-03-28"
"2303.14664","Kristoffer Kortsen PhD","Kristoffer Kortsen, Siobhan Kilbride, Stephen R. Lowe, Adam Peirce and
  Michael P. Shaver","A plastics hierarchy of fates: sustainable choices for a circular future","to access the interactive tool, see
  https://lucid.app/documents/embedded/0ad93c05-0179-40bb-9468-63e25fc4dfae#",,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Plastics are ubiquitous in modern society, but the linear model of produce,
use, and dispose results in massive amounts of resource consumption and
pollution. Landfill and incineration of plastic waste is endemic, with no
consensus on a clear path towards a more sustainable model. Progress is often
hampered by a lack of clarity on what choices will enable a more sustainable
circular plastics economy. Our Plastics Hierarchy of Fates tool addresses this
by bringing together scattered information on the end-of-life fates of plastics
in a more accessible format. This tool will support manufacturing, processing,
and policy decisions in the push for a more sustainable future. Potential
sorting and recycling decisions for plastics waste are discussed in the
hierarchy and the consequences of different decisions are highlighted. The
hierarchy is meant to inform potential outcomes but can also be used to help
shape future interventions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:19:18 GMT""}]","2023-03-28"
"2303.14665","Guandong Xu","Tri Dung Duong, Qian Li, Guandong Xu","Achieving Counterfactual Fairness with Imperfect Structural Causal Model",,,,,"cs.LG cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Counterfactual fairness alleviates the discrimination between the model
prediction toward an individual in the actual world (observational data) and
that in counterfactual world (i.e., what if the individual belongs to other
sensitive groups). The existing studies need to pre-define the structural
causal model that captures the correlations among variables for counterfactual
inference; however, the underlying causal model is usually unknown and
difficult to be validated in real-world scenarios. Moreover, the
misspecification of the causal model potentially leads to poor performance in
model prediction and thus makes unfair decisions. In this research, we propose
a novel minimax game-theoretic model for counterfactual fairness that can
produce accurate results meanwhile achieve a counterfactually fair decision
with the relaxation of strong assumptions of structural causal models. In
addition, we also theoretically prove the error bound of the proposed minimax
model. Empirical experiments on multiple real-world datasets illustrate our
superior performance in both accuracy and fairness. Source code is available at
\url{https://github.com/tridungduong16/counterfactual_fairness_game_theoretic}.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:37:29 GMT""}]","2023-03-28"
"2303.14666","Tianli Zhang","Tianli Zhang, Mengqi Xue, Jiangtao Zhang, Haofei Zhang, Yu Wang,
  Lechao Cheng, Jie Song and Mingli Song","Generalization Matters: Loss Minima Flattening via Parameter
  Hybridization for Efficient Online Knowledge Distillation","Accepted by cvpr2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most existing online knowledge distillation(OKD) techniques typically require
sophisticated modules to produce diverse knowledge for improving students'
generalization ability. In this paper, we strive to fully utilize multi-model
settings instead of well-designed modules to achieve a distillation effect with
excellent generalization performance. Generally, model generalization can be
reflected in the flatness of the loss landscape. Since averaging parameters of
multiple models can find flatter minima, we are inspired to extend the process
to the sampled convex combinations of multi-student models in OKD.
Specifically, by linearly weighting students' parameters in each training
batch, we construct a Hybrid-Weight Model(HWM) to represent the parameters
surrounding involved students. The supervision loss of HWM can estimate the
landscape's curvature of the whole region around students to measure the
generalization explicitly. Hence we integrate HWM's loss into students'
training and propose a novel OKD framework via parameter hybridization(OKDPH)
to promote flatter minima and obtain robust solutions. Considering the
redundancy of parameters could lead to the collapse of HWM, we further
introduce a fusion operation to keep the high similarity of students. Compared
to the state-of-the-art(SOTA) OKD methods and SOTA methods of seeking flat
minima, our OKDPH achieves higher performance with fewer parameters, benefiting
OKD with lightweight and robust characteristics. Our code is publicly available
at https://github.com/tianlizhang/OKDPH.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:40:55 GMT""}]","2023-03-28"
"2303.14667","Rong An","Rong An and Shuai Sun and Li-Gang Cao and Feng-Shou Zhang","Constraining the nuclear symmetry energy with charge radii of the mirror
  pairs nuclei","19 pages, 4 figures, 2 tables, Submitted to Nuclear Science and
  Techniques",,,,"nucl-th hep-ex nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nuclear charge radius provides a vital role in determining the equation of
state (EoS) of isospin asymmetric nuclear matter.
  Based on the correlation between the differences of charge radii of
mirror-partner nuclei ($\Delta{R_{\mathrm{ch}}}$) and the slope parameter ($L$)
of symmetry energy at the nuclear saturation density, an analysis of the
calibrated slope parameter $L$ is performed in finite nuclei. In this work, the
relativistic and non-relativistic energy density functionals (EDFs) are
employed to make constraints on the nuclear symmetry energy through the
available databases of these mirror pairs nuclei $^{36}$Ca-$^{36}$S,
$^{38}$Ca-$^{38}$Ar and $^{54}$Ni-$^{54}$Fe. The deduced nuclear symmetry
energy is firmly located at the range of 29.89-31.85 MeV and the slope
parameter $L$ of symmetry energy essentially covers the range of 22.50-51.55
MeV.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:46:37 GMT""}]","2023-03-28"
"2303.14668","Guandong Xu","Tri Dung Duong, Qian Li, Guandong Xu","CeFlow: A Robust and Efficient Counterfactual Explanation Framework for
  Tabular Data using Normalizing Flows",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Counterfactual explanation is a form of interpretable machine learning that
generates perturbations on a sample to achieve the desired outcome. The
generated samples can act as instructions to guide end users on how to observe
the desired results by altering samples. Although state-of-the-art
counterfactual explanation methods are proposed to use variational autoencoder
(VAE) to achieve promising improvements, they suffer from two major
limitations: 1) the counterfactuals generation is prohibitively slow, which
prevents algorithms from being deployed in interactive environments; 2) the
counterfactual explanation algorithms produce unstable results due to the
randomness in the sampling procedure of variational autoencoder. In this work,
to address the above limitations, we design a robust and efficient
counterfactual explanation framework, namely CeFlow, which utilizes normalizing
flows for the mixed-type of continuous and categorical features. Numerical
experiments demonstrate that our technique compares favorably to
state-of-the-art methods. We release our source at
https://github.com/tridungduong16/fairCE.git for reproducing the results.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:51:04 GMT""}]","2023-03-28"
"2303.14669","Jacopo Viti","Ivar Lyberg, Vladimir Korepin and Jacopo Viti","Fluctuation of the phase boundary in the six-vertex model with Domain
  Wall Boundary Conditions: a Monte Carlo study","15 pages, 6 figures",,,,"cond-mat.stat-mech hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We consider the six-vertex model with Domain Wall Boundary Conditions. Our
main interest is the study of the fluctuations of the extremal lattice path
about the arctic curves. We address the problem through Monte Carlo
simulations. At $\Delta = 0$, the fluctuations of the extremal path along any
line parallel to the square diagonal were rigorously proven to follow the
Tracy-Widom distribution. We provide strong numerical evidence that this is
true also for other values of the anisotropy parameter $\Delta$ ($0\leq \Delta
< 1$). We argue that the typical width of the fluctuations of the extremal path
about the arctic curves scales as $N^{1/3}$ and provide a numerical estimate
for the parameters of the scaling random variable.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:57:03 GMT""}]","2023-03-28"
"2303.14670","Vyacheslav Pivovarchik N","Dmytro Kaliuzhnyi-Verbovetskyi, Vyacheslav Pivovarchik","Recovering the shape of a quantum caterpillar tree by two spectra","9 pages, 1 figure. arXiv admin note: substantial text overlap with
  arXiv:2301.05939",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how to find the shape of an equilateral caterpillar tree using the
spectra of the Neumann and the Dirichlet problems generated by the
Sturm-Liouville equation on this tree. We prove that in the case of a
caterpillar tree the spectra of the Neumann and Dirichlet problems uniquely
determine the shape of the tree.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:00:51 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 17:40:43 GMT""}]","2023-03-30"
"2303.14671","Yan-Ting Xie","Yan-Ting Xie, Yong-De Feng, Shou-Jun Xu","A relation between the cube polynomials of partial cubes and the clique
  polynomials of their crossing graphs","13 pages, 1figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Partial cubes are the graphs which can be embedded into hypercubes. The cube
polynomial of a graph $G$ is a counting polynomial of induced hypercubes of
$G$, which is defined as $C(G,x):=\sum_{i\geqslant 0}\alpha_i(G)x^i$ where
$\alpha_i(G)$ is the number of induced $i$-cubes (hypercubes of dimension $i$)
of $G$. The clique polynomial of $G$ is defined as $Cl(G,x):=\sum_{i\geqslant
0}a_i(G)x^i$ where $a_i(G)$ ($i\geqslant 1$) is the number of $i$-cliques
(complete subgraphs of order $i$) in $G$ and $a_0(G)=1$. Equivalently, $Cl(G,
x)$ is exactly the independence polynomial of the complement $\overline{G}$ of
$G$. The crossing graph $G^{\#}$ of a partial cube $G$ is the graph whose
vertices are corresponding to the $\Theta$-classes (the equivalent classes of
edge set) of $G$, and $\theta_1$ and $\theta_2$ are adjacent in $G^{\#}$ if and
only if they cross in $G$. In the present paper, we prove that for a partial
cube $G$, $C(G,x)\leqslant Cl(G^{\#}, x+1)$ and the equality holds if and only
if $G$ is a median graph (a special partial cube). Since every graph can be
represented as the crossing graph of a median graph [SIAM J. Discrete Math., 15
(2002) 235--251], the above necessary-and-sufficient result shows that the
study on the cube polynomials of median graphs can be transformed to the one on
the clique polynomials of general graphs (equivalently, on the independence
polynomials of their complements). In addition, we disprove the conjecture that
the cube polynomials of median graphs are unimodal.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:05:30 GMT""}]","2023-03-28"
"2303.14672","Ming Qian","Ming Qian, Jincheng Xiong, Gui-Song Xia, Nan Xue","Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs","Project Page: https://sat2density.github.io",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper aims to develop an accurate 3D geometry representation of
satellite images using satellite-ground image pairs. Our focus is on the
challenging problem of generating ground-view panoramas from satellite images.
We draw inspiration from the density field representation used in volumetric
neural rendering and propose a new approach, called Sat2Density. Our method
utilizes the properties of ground-view panoramas for the sky and non-sky
regions to learn faithful density fields of 3D scenes in a geometric
perspective. Unlike other methods that require extra 3D information during
training, our Sat2Density can automatically learn the accurate and faithful 3D
geometry via density representation from 2D-only supervision. This advancement
significantly improves the ground-view panorama synthesis task. Additionally,
our study provides a new geometric perspective to understand the relationship
between satellite and ground-view images in 3D space.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:15:33 GMT""}]","2023-03-28"
"2303.14673","Carlo A. Trugenberger","M. C. Diamantini, C. A. Trugenberger, Sheng-Zong Chen, Yu-Jung Lu,
  Chi-Te Liang and V. M. Vinokur","Type III superconductivity",,"Advanced Science 2023, 2206523",,,"cond-mat.supr-con hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superconductivity remains one of most fascinating quantum phenomena existing
on a macroscopic scale. Its rich phenomenology is usually described by the
Ginzburg-Landau (GL) theory in terms of the order parameter, representing the
macroscopic wave function of the superconducting condensate. The GL theory
addresses one of the prime superconducting properties, screening of the
electromagnetic field because it becomes massive within a superconductor, the
famous Anderson-Higgs mechanism. Here we describe another widely-spread type of
superconductivity where the Anderson-Higgs mechanism does not work and must be
replaced by the Deser-Jackiw-Templeton topological mass generation and,
correspondingly, the GL effective field theory must be replaced by an effective
topological gauge theory. These superconductors are inherently inhomogeneous
granular superconductors, where electronic granularity is either fundamental or
emerging. We show that the corresponding superconducting transition is a
three-dimensional (3D) generalization of the 2D Berezinskii-Kosterlitz-Thouless
(BKT) vortex binding-unbinding transition. The binding-unbinding of the
line-like vortices in 3D results in the Vogel-Fulcher-Tamman (VFT) scaling of
the resistance near the superconducting transition. We report experimental data
fully confirming the VFT behavior of the resistance.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:21:09 GMT""}]","2023-03-28"
"2303.14674","Yuting Liu","Yuting Liu, Shuo Cao, Marek Biesiada, Yujie Lian, Xiaolin Liu, Yilong
  Zhang","Measuring the speed of light with updated Hubble diagram of
  high-redshift standard candles","11 pages,8 figures, accepted by ApJ",,"10.3847/1538-4357/acc7a5",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The possible time variation of the fundamental constants of nature has been
an active subject of research in modern physics. In this paper, we propose a
new method to investigate such possible time variation of the speed of light
$c$ using the updated Hubble diagram of high-redshift standard candles
including Type Ia Supernovae (SNe Ia) and high-redshift quasars (based on UV-X
relation). Our findings show that the SNe Ia Pantheon sample, combined with
currently available sample of cosmic chronometers, would produce robust
constraints on the speed of light at the level of $c/c_0=1.03\pm0.03$. For the
Hubble diagram of UV+X ray quasars acting as a new type of standard candles, we
obtain $c/c_0=1.19\pm0.07$. Therefore, our results confirm that there is no
strong evidence for the deviation from the constant speed of light up to $z\sim
2$. Moreover, we discuss how our technique might be improved at much higher
redshifts ($z\sim5$), focusing on future measurements of the acceleration
parameter $X(z)$ with gravitational waves (GWs) from binary neutron star
mergers. In particular, in the framework of the second-generation space-based
GW detector, DECi-hertz Interferometer Gravitational-wave Observatory (DECIGO),
the speed of light is expected to be constrained with the precision of
$\Delta{c}/c=10^{-3}$.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:33:31 GMT""}]","2023-06-07"
"2303.14675","Naveen Prabhakar","Naveen S. Prabhakar, Martin Ro\v{c}ek","$(0,4)$ Projective Superspaces I: Interacting Linear Sigma Models","32 pages + appendices",,,,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe the projective superspace approach to supersymmetric models with
off-shell $(0,4)$ supersymmetry in two dimensions. In addition to the usual
superspace coordinates, projective superspace has extra bosonic variables --
one doublet for each $\text{SU}(2)$ in the R-symmetry $\text{SU}(2) \times
\text{SU}(2)$ which are interpreted as homogeneous coordinates on
$\mathbf{CP}^1 \times \mathbf{CP}^1$. The superfields are analytic in the
$\mathbf{CP}^1$ coordinates and this analyticity plays an important role in our
description. For instance, it leads to stringent constraints on the
interactions one can write down for a given superfield content of the model. As
an example, we describe in projective superspace Witten's ADHM sigma model -- a
linear sigma model with non-derivative interactions whose target is
$\mathbf{R}^4$ with a Yang-Mills instanton solution. The hyperk\""ahler nature
of target space and the twistor description of instantons by Ward, and Atiyah,
Hitchin, Drinfeld and Manin are natural outputs of our construction.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:38:35 GMT""}]","2023-03-28"
"2303.14676","Hanlin Wang","Hanlin Wang, Yilu Wu, Sheng Guo, Limin Wang","PDPP:Projected Diffusion for Procedure Planning in Instructional Videos","Accepted as a highlight paper at CVPR 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the problem of procedure planning in instructional
videos, which aims to make goal-directed plans given the current visual
observations in unstructured real-life videos. Previous works cast this problem
as a sequence planning problem and leverage either heavy intermediate visual
observations or natural language instructions as supervision, resulting in
complex learning schemes and expensive annotation costs. In contrast, we treat
this problem as a distribution fitting problem. In this sense, we model the
whole intermediate action sequence distribution with a diffusion model (PDPP),
and thus transform the planning problem to a sampling process from this
distribution. In addition, we remove the expensive intermediate supervision,
and simply use task labels from instructional videos as supervision instead.
Our model is a U-Net based diffusion model, which directly samples action
sequences from the learned distribution with the given start and end
observations. Furthermore, we apply an efficient projection method to provide
accurate conditional guides for our model during the learning and sampling
process. Experiments on three datasets with different scales show that our PDPP
model can achieve the state-of-the-art performance on multiple metrics, even
without the task supervision. Code and trained models are available at
https://github.com/MCG-NJU/PDPP.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:50:16 GMT""}]","2023-03-28"
"2303.14677","Alexey Fedyushkin","A. I. Fedyushkin and N. G. Bourago","The effect of controlled vibrations on the width boundary layers during
  crystal growth by the Bridgman method","14 pages, 6 figures, 21 referencies",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  By using the finite element code ASTRA, the effect of vibrations on the melt
flow in Bridgman crystal growth is investigated for the Earth and Space gravity
conditions. It is found that the vibrations significantly decrease the width of
interfacial boundary layers in Bridgman crystal growth with submerged vibrator.
The influence of the geometrical arrangement of the vibrator, the
thermo-gravitational conditions, the frequency of vibration and the rotation
effects is investigated. The averaged vibrational flow (AVF) parameters were
calculated by means of post-processing the instant thermomechanical fields
found in numerical integration of Navier-Stokes problem. The structure of AVF
depends on the physical properties of the melt and on the frequency/amplitude
values. The frequency of vibrations (vibrational Reynolds number) influences
essentially on the AVF structure. Numerical results show that the direction of
AVF depends with frequency. It is shown that for normal and low gravity
conditions the vibrations can decrease the width of boundary layers and
increase the boundary temperature gradients. This can intensify heat and mass
transfer near the solid-liquid interface and increase the rate of crystal
growth.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:52:16 GMT""}]","2023-03-28"
"2303.14678","Simon Van Mourik","Simon van Mourik, Bert van't Ooster, Michel Vellekoop","Plant Performance in Precision Horticulture: Optimal climate control
  under stochastic uncertainty",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an optimal control algorithm for crop production when
state dynamics are uncertain due to stochastic noise. The case study concerns a
50 day production round of lettuce in a greenhouse where control input consists
of daily and nightly temperature set points. The control problem was formulated
in terms of a stochastic Markov decision process with the objective to maximize
the expected net revenue at harvest time.
  The performance was compared to that of a stochastic static controller, and a
deterministic time-varying dynamic feedback controller for the case of heat
limited weather conditions, and strict requirements on harvest weight
precision. Compared to the stochastic dynamic controller, the static controller
resulted in lower maximal expected net revenue (-19 \%), less precision at
harvest time (state uncertainty increased with 86 \%), and a larger sensitivity
towards a change in starting day (varying the starting time from 0 to 10 days
caused a variation of 15 \% in expected net revenue, compared to 11\% for the
original controller). The deterministic controller also resulted in lower
maximal expected net revenue (-16 \%), and less precision at harvest time
(state uncertainty increased with 40 \%). The sensitivity of expected net
revenue towards a change in starting day increased dramatically (60 \% compared
to 11\% for the original controller).
  The results of the deterministic controller provided insights in the
trade-off between optimality in case of no noise, versus robustness to noise,
whereas the results of the static controller provided insights in importance of
dynamic feedback in achieving high precision in harvest weight. The results of
this single case study should be interpreted with caution, however they
illustrate a considerable potential benefit for stochastic greenhouse climate
control.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:53:01 GMT""}]","2023-03-28"
"2303.14679","Yongqi An","Yongqi An, Xu Zhao, Tao Yu, Haiyun Guo, Chaoyang Zhao, Ming Tang,
  Jinqiao Wang","ZBS: Zero-shot Background Subtraction via Instance-level Background
  Modeling and Foreground Selection","Accepted by CVPR 2023. Code is available at
  https://github.com/CASIA-IVA-Lab/ZBS",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background subtraction (BGS) aims to extract all moving objects in the video
frames to obtain binary foreground segmentation masks. Deep learning has been
widely used in this field. Compared with supervised-based BGS methods,
unsupervised methods have better generalization. However, previous unsupervised
deep learning BGS algorithms perform poorly in sophisticated scenarios such as
shadows or night lights, and they cannot detect objects outside the pre-defined
categories. In this work, we propose an unsupervised BGS algorithm based on
zero-shot object detection called Zero-shot Background Subtraction (ZBS). The
proposed method fully utilizes the advantages of zero-shot object detection to
build the open-vocabulary instance-level background model. Based on it, the
foreground can be effectively extracted by comparing the detection results of
new frames with the background model. ZBS performs well for sophisticated
scenarios, and it has rich and extensible categories. Furthermore, our method
can easily generalize to other tasks, such as abandoned object detection in
unseen environments. We experimentally show that ZBS surpasses state-of-the-art
unsupervised BGS methods by 4.70% F-Measure on the CDnet 2014 dataset. The code
is released at https://github.com/CASIA-IVA-Lab/ZBS.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 10:59:03 GMT""}]","2023-03-28"
"2303.14680","Roman Kezerashvili","S. B. Dubovichenko, N. A. Burkova, R. Ya. Kezerashvili, A. S.
  Tkachenko, B.M. Yeleusheva","The astrophysical $S-$factor and reaction rate for
  $^{15}$N($p,\gamma$)$^{16}$O within the modified potential cluster model","17 pages, 8 figures",,,,"nucl-th astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We study a radiative $p^{15}$N capture on the ground state of $^{16}$O at
stellar energies within the framework of a modified potential cluster model
(MPCM) with forbidden states, including low lying resonances. The investigation
of the $^{15}$N($p,\gamma $)$^{16}$O reaction includes the consideration of
$^{3}S_{1}$ resonances due to $E1$ transitions and contribution of $^{3}P_{1}$
scattering wave in $p$ + $^{15}$N channel due to $^{3}P_{1}\longrightarrow $
$^{3}P_{0}$ $M1$ transition. We calculate the astrophysical low-energy
$S-$factor and extrapolated $S(0)$ turned out to be within $34.7-40.4$
keV$\cdot $b. It is elucidated the important role of the asymptotic constant
(AC) for the $^{15}$N($p,\gamma $)$^{16}$O process with interfering
$^{3}S_{1}$(312) and $^{3}S_{1}$(962) resonances. A comparison of our
calculation for $S-$factor with existing experimental and theoretical data is
addressed and the reasonable agreement is found.
  The reaction rate is calculated and compared with the existing rates. It has
negligible dependence on the variation of AC, but shows strong impact of the
interference of $^{3}S_{1}$(312) and $^{3}S_{1}$(962) resonances, especially at
$T_{9}$ referring to the CNO Gamow windows. We present a stellar temperature
dependence on the Gamow energy and a comparison of rates for radiative proton
capture reactions for CNO cycle on nitrogen isotopes obtained in the framework
of the MPCM and give temperature windows, prevalence, and significance of each
process.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:02:47 GMT""},{""version"":""v2"",""created"":""Tue, 23 May 2023 13:26:23 GMT""}]","2023-05-24"
"2303.14681","Luca Butera","Luca Butera, Andrea Cini, Alberto Ferrante, Cesare Alippi","Relational Inductive Biases for Object-Centric Image Generation",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conditioning image generation on specific features of the desired output is a
key ingredient of modern generative models. Most existing approaches focus on
conditioning the generation based on free-form text, while some niche studies
use scene graphs to describe the content of the image to be generated. This
paper explores novel methods to condition image generation that are based on
object-centric relational representations. In particular, we propose a
methodology to condition the generation of a particular object in an image on
the attributed graph representing its structure and associated style. We show
that such architectural biases entail properties that facilitate the
manipulation and conditioning of the generative process and allow for
regularizing the training procedure. The proposed framework is implemented by
means of a neural network architecture combining convolutional operators that
operate on both the underlying graph and the 2D grid that becomes the output
image. The resulting model learns to generate multi-channel masks of the object
that can be used as a soft inductive bias in the downstream generative task.
Empirical results show that the proposed approach compares favorably against
relevant baselines on image generation conditioned on human poses.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:17:17 GMT""}]","2023-03-28"
"2303.14682","Marco Aymone M. Aymone","Marco Aymone","Sign changes of the partial sums of a random multiplicative function II","8 pages",,,,"math.NT math.PR","http://creativecommons.org/licenses/by/4.0/","  We study two models of random multiplicative functions: Rademacher random
multiplicative functions supported on the squarefree integers $f$, and
Rademacher random completely multiplicative functions $f^*$. We prove that the
partial sums $\sum_{n\leq x}f^*(n)$ and $\sum_{n\leq x}\frac{f(n)}{\sqrt{n}}$
change sign infinitely often as $x\to\infty$, almost surely. The case
$\sum_{n\leq x}\frac{f^*(n)}{\sqrt{n}}$ is leaved as an open question and we
stress the possibility of only a finite number of sign changes, almost surely.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:20:02 GMT""}]","2023-03-28"
"2303.14683","Liying Han","Liying Han, Yang Li, Hao Tan, Weiyang Zhang, Wenqi Cai, Juan Yin,
  Jigang Ren, Feihu Xu, Shengkai Liao, Chengzhi Peng","Effect of light injection on the security of practical quantum key
  distribution",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum key distribution (QKD) based on the fundamental laws of quantum
physics can allow the distribution of secure keys between distant users.
However, the imperfections in realistic devices may lead to potential security
risks, which must be accurately characterized and considered in practical
security analysis. High-speed optical modulators, being as one of the core
components of practical QKD systems, can be used to prepare the required
quantum states. Here, we find that optical modulators based on LiNbO3,
including phase modulators and intensity modulators, are vulnerable to
photorefractive effect caused by external light injection. By changing the
power of external light, eavesdroppers can control the intensities of the
prepared states, posing a potential threat to the security of QKD. We have
experimentally demonstrated the influence of light injection on LiNbO3-based
optical modulators and analyzed the security risks caused by the potential
green light injection attack, along with the corresponding countermeasures.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:22:15 GMT""}]","2023-03-28"
"2303.14684","Manis Chaudhuri","M. Chaudhuri, L. C. J. Heijmans, M. van de Kerkhof, P. Krainov, D.
  Astakhov and A. M. Yakunin","Particle charging during pulsed EUV exposures with afterglow effect",,,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The nanoparticle charging processes along with background spatial-temporal
plasma profile have been investigated with 3DPIC simulation in a pulsed EUV
exposure environment. It is found that the particle charge polarity (positive
or negative) strongly depends on its size, location and background transient
plasma conditions. The particle (100 nm diameter) charge reaches steady state
in a single pulse (20 us) within the EUV beam in contrast to particles outside
the beam that requires multiple pulses. The larger the particle size, the less
number of pulses are required to reach steady state. It is found that the
charge of a particle decreases with pressure in a faster rate outside the beam
compared to inside. The results are of importance for particle contamination
(defectivity) control strategy for EUV lithography machines.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:22:45 GMT""}]","2023-03-28"
"2303.14685","Yadong Jiang","Yadong Jiang, Huan Wang and Jing Wang","Monolayer V2MX4: A new family of quantum anomalous Hall insulators","7 pages, 4 figures",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically propose that the monolayer V$_2 MX_4$ ($M=$ W, Mo; $X=$ S,
Se) is a new family of quantum anomalous Hall insulators with sizable bulk gap
and Chern number $\mathcal{C}=-1$. The interplay between topology and magnetism
in this class of compounds are from $d$-orbitals of both V and $M$. We
construct the tight-binding model from orbital projected band structure and
symmetry analysis to uncover the origin of topology. Remarkably, the topology
is not only from the spin polarized quadratic band touching of degenerate
$d_{xz}$ and $d_{yz}$ orbitals of V guaranteed by $C_{4z}$ symmetry, but also
the band inversion between $d_{xz},d_{yz}$ orbitals of V and $d_{z^2}$ of $M$
at Fermi level, which is further gapped by spin-orbit coupling. This results in
the Chern band lying far below Fermi energy. Furthermore, the thickness
dependence of the Chern number for few multilayers shows interesting
oscillating behavior. The general physics from the $d$-orbitals here applies to
a large class of ternary transition metal chalcogenide such as Ti$_2$W$X_4$
with the space group $P$-$42m$.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:27:58 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 11:42:58 GMT""}]","2023-03-29"
"2303.14686","Sakil Ahamed","Sakil Ahamed and Subrata Majumdar","Controllability and Stabilizability of the linearized compressible
  Navier-Stokes system with Maxwell's law",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the control properties of the linearized compressible
Navier-Stokes system with Maxwell's law around a constant steady state
$(\rho_s, u_s, 0), \rho_s>0, u_s>0$ in the interval $(0, 2\pi)$ with periodic
boundary data. We explore the exact controllability of the coupled system by
means of a localized interior control acting in any of the equations when time
is large enough. We also study the boundary exact controllability of the
linearized system using a single control force when the time is sufficiently
large. In both cases, we prove the exact controllability of the system in the
space $L^2(0,2\pi)\times L^2(0, 2\pi)\times L^2(0, 2\pi)$. We establish the
exact controllability results by proving an observability inequality with the
help of an Ingham-type inequality.
  Further, using a Gramian-based approach demonstrated by Urquiza, we prove the
exponential stabilizability of the corresponding closed-loop system with an
arbitrary prescribed decay rate using boundary feedback control law.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:28:42 GMT""}]","2023-03-28"
"2303.14687","Taiki Shibata","Taiki Shibata (Okayama University of Science), Kenichi Shimizu
  (Shibaura Institute of Technology)","Exact sequences of Frobenius tensor categories","22 pages",,,,"math.QA math.CT math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a tensor functor between tensor categories $\mathcal{C}$ and
$\mathcal{D}$, we give criteria that, under certain assumptions, the
Frobeniusness of $\mathcal{C}$ or $\mathcal{D}$ implies the Frobeniusness of
the other one. We also give an affirmative answer to Natale's question asking
if the class of Frobenius tensor categories is closed under exact sequences.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:29:38 GMT""}]","2023-03-28"
"2303.14688","Yuzhou Gu","Yuzhou Gu, Yury Polyanskiy","Uniqueness of BP fixed point for the Potts model and applications to
  community detection",,,,,"math.PR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the study of sparse stochastic block model (SBM) one needs to analyze a
distributional recursion, known as belief propagation (BP) on a tree.
Uniqueness of the fixed point of this recursion implies several results about
the SBM, including optimal recovery algorithms for SBM (Mossel et al. (2016))
and SBM with side information (Mossel and Xu (2016)), and a formula for SBM
mutual information (Abbe et al. (2021)). The 2-community case corresponds to an
Ising model, for which Yu and Polyanskiy (2022) established uniqueness for all
cases.
  Here, we analyze broadcasting of $q$-ary spins on a Galton-Watson tree with
expected offspring degree $d$ and Potts channels with second-largest eigenvalue
$\lambda$. We allow for the intermediate vertices to be observed through noisy
channels (side information) We prove BP uniqueness holds with and without side
information when $d\lambda^2 \ge 1 + C \max\{\lambda, q^{-1}\}\log q$ for some
absolute constant $C>0$ independent of $q,d,\lambda$. For large $q$ and
$\lambda = o(1/\log q)$, this is asymptotically achieving the Kesten-Stigum
threshold $d\lambda^2=1$. These results imply mutual information formula and
optimal recovery algorithms for the $q$-community SBM in the corresponding
ranges.
  For $q\ge 4$, Sly (2011); Mossel et al. (2022) shows that there exist choices
of $q,d,\lambda$ below Kesten-Stigum (i.e. $d\lambda^2 < 1$) but reconstruction
is possible. Somewhat surprisingly, we show that in such regimes BP uniqueness
\textit{does not hold} at least in the presence of weak side information.
  Our technical tool is a theory of q-ary symmetric channels, that we initiate
here, generalizing the classical and widely-utilized information-theoretic
characterization of BMS (binary memoryless symmetric) channels.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:29:41 GMT""}]","2023-03-28"
"2303.14689","Yuzhou Gu","Yuzhou Gu, Yury Polyanskiy","Weak Recovery Threshold for the Hypergraph Stochastic Block Model",,,,,"math.PR cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of weak recovery for the $r$-uniform hypergraph
stochastic block model ($r$-HSBM) with two balanced communities. In HSBM a
random graph is constructed by placing hyperedges with higher density if all
vertices of a hyperedge share the same binary label. By analyzing contraction
of a non-Shannon (symmetric-KL) information measure, we prove that for $r=3,4$,
weak recovery is impossible below the Kesten-Stigum threshold. Prior work Pal
and Zhu (2021) established that weak recovery in HSBM is always possible above
the Kesten-Stigum threshold. Consequently, there is no information-computation
gap for these $r$, which (partially) resolves a conjecture of Angelini et al.
(2015). To our knowledge this is the first impossibility result for HSBM weak
recovery.
  As usual, we reduce the study of non-recovery of HSBM to the study of
non-reconstruction in a related broadcasting on hypertrees (BOHT) model. While
we show that BOHT's reconstruction threshold coincides with Kesten-Stigum for
$r=3,4$, surprisingly, we demonstrate that for $r\ge 7$ reconstruction is
possible also below the Kesten-Stigum. This shows an interesting phase
transition in the parameter $r$, and suggests that for $r\ge 7$, there might be
an information-computation gap for the HSBM. For $r=5,6$ and large degree we
propose an approach for showing non-reconstruction below Kesten-Stigum
threshold, suggesting that $r=7$ is the correct threshold for onset of the new
phase. We admit that our analysis of the $r=4$ case depends on a
numerically-verified inequality.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:29:51 GMT""}]","2023-03-28"
"2303.14690","Prabhat Kumar","Prabhat Kumar","TOPress: a MATLAB implementation for topology optimization of structures
  subjected to design-dependent pressure loads","19 Figures, MATLAB codes","Structural and Multidisciplinary Optimization, 2023","10.1007/s00158-023-03533-9",,"cs.MS cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a topology optimization setting, design-dependent fluidic pressure loads
pose several challenges as their direction, magnitude, and location alter with
topology evolution. This paper offers a compact 100-line MATLAB code, TOPress,
for topology optimization of structures subjected to fluidic pressure loads
using the method of moving asymptotes. The code is intended for pedagogical
purposes and aims to ease the beginners' and students' learning toward topology
optimization with design-dependent fluidic pressure loads. TOPress is developed
per the approach first reported in Kumar et al. (Struct Multidisc Optim
61(4):1637-1655, 2020). The Darcy law, in conjunction with the drainage term,
is used to model the applied pressure load. The consistent nodal loads are
determined from the obtained pressure field. The employed approach facilitates
inexpensive computation of the load sensitivities using the adjoint-variable
method. Compliance minimization subject to volume constraint optimization
problems are solved. The success and efficacy of the code are demonstrated by
solving benchmark numerical examples involving pressure loads, wherein the
importance of load sensitivities is also demonstrated. TOPress contains six
main parts, is described in detail, and is extended to solve different
problems. Steps to include a projection filter are provided to achieve
loadbearing designs close to~0-1. The code is provided in Appendix~B and can
also be downloaded along with its extensions from
\url{https://github.com/PrabhatIn/TOPress}.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:31:22 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 07:22:28 GMT""},{""version"":""v3"",""created"":""Thu, 13 Apr 2023 07:13:54 GMT""}]","2023-04-14"
"2303.14691","Anton Matthijs Berghuis","Anton Matthijs Berghuis, Gabriel W. Castellanos, Shunsuke Murai, Jose
  Luis Pura, Diego R. Abujetas, Erik van Heijst, Mohammad Ramezani, Jos\'e A.
  S\'anchez-Gil, and Jaime G\'omez Rivas","Room Temperature Exciton-Polariton Condensation in Silicon Metasurfaces
  Emerging from Bound States in the Continuum",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show the first experimental demonstration of room-temperature
exciton-polariton (EP) condensation from a bound state in the continuum (BIC).
This demonstration is achieved by strongly coupling stable excitons in an
organic perylene dye with the extremely long-lived BIC in a dielectric
metasurface of silicon nanoparticles. The long lifetime of the BIC, mainly due
to the suppression of radiation leakage, allows for EP thermalization to the
ground state before decaying. This property results in a condensation threshold
of less than 5 \mu J cm^{-2}, one order of magnitude lower that the lasing
threshold reported in similar systems in the weak coupling limit.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:36:42 GMT""}]","2023-03-28"
"2303.14692","Xin-Long Luo","Xin-long Luo, Hang Xiao and Sen Zhang","The regularization continuation method for optimization problems with
  nonlinear equality constraints","arXiv admin note: substantial text overlap with arXiv:2106.01122",,,,"math.OC cs.CE cs.MS cs.NA math.DS math.NA","http://creativecommons.org/licenses/by/4.0/","  This paper considers the regularization continuation method and the
trust-region updating strategy for the nonlinearly equality-constrained
optimization problem. Namely, it uses the inverse of the regularization
quasi-Newton matrix as the pre-conditioner to improve its computational
efficiency in the well-posed phase, and it adopts the inverse of the
regularization two-sided projection of the Hessian as the pre-conditioner to
improve its robustness in the ill-conditioned phase. Since it only solves a
linear system of equations at every iteration and the sequential quadratic
programming (SQP) needs to solve a quadratic programming subproblem at every
iteration, it is faster than SQP. Numerical results also show that it is more
robust and faster than SQP (the built-in subroutine fmincon.m of the
MATLAB2020a environment and the subroutine SNOPT executed in GAMS v28.2 (2019)
environment). The computational time of the new method is about one third of
that of fmincon.m for the large-scale problem. Finally, the global convergence
analysis of the new method is also given.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:40:42 GMT""}]","2023-03-28"
"2303.14693","Zlatan Ajanovic","Eveline Drijver, Rodrigo P\'erez-Dattari, Jens Kober, Cosimo Della
  Santina and Zlatan Ajanovi\'c","Robotic Packaging Optimization with Reinforcement Learning","7 pages, 5 figures, 1 table, submitted to a conference",,,,"cs.RO cs.AI cs.SY eess.SY","http://creativecommons.org/publicdomain/zero/1.0/","  Intelligent manufacturing is becoming increasingly important due to the
growing demand for maximizing productivity and flexibility while minimizing
waste and lead times. This work investigates automated secondary robotic food
packaging solutions that transfer food products from the conveyor belt into
containers. A major problem in these solutions is varying product supply which
can cause drastic productivity drops. Conventional rule-based approaches, used
to address this issue, are often inadequate, leading to violation of the
industry's requirements. Reinforcement learning, on the other hand, has the
potential of solving this problem by learning responsive and predictive policy,
based on experience. However, it is challenging to utilize it in highly complex
control schemes. In this paper, we propose a reinforcement learning framework,
designed to optimize the conveyor belt speed while minimizing interference with
the rest of the control system. When tested on real-world data, the framework
exceeds the performance requirements (99.8% packed products) and maintains
quality (100% filled boxes). Compared to the existing solution, our proposed
framework improves productivity, has smoother control, and reduces computation
time.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:42:49 GMT""}]","2023-03-28"
"2303.14694","Taras Panov","Anthony Bahri, Ivan Limonchenko, Taras Panov, Jongbaek Song and Donald
  Stanley","A stability theorem for bigraded persistence barcodes","19 pages",,,,"math.AT cs.CG cs.LG math.CO math.MG","http://creativecommons.org/licenses/by/4.0/","  We define the bigraded persistent homology modules and the bigraded barcodes
of a finite pseudo-metric space X using the ordinary and double homology of the
moment-angle complex associated with the Vietoris-Rips filtration of X. We
prove the stability theorem for the bigraded persistent double homology modules
and barcodes.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:43:29 GMT""}]","2023-03-28"
"2303.14695","Zi-Liang Zhang","Zi-Liang Zhang, Yun-Wei Yu and Xiao-Feng Cao","Diverse origins for non-repeating fast radio bursts: Rotational radio
  transient sources and cosmological compact binary merger remnants","8 pages, 7 figures. Accepted for publication in Astronomy &
  Astrophysics. Comments are welcome",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  A large number of fast radio bursts (FRBs) detected with the CHIME telescope
have enabled investigations of their energy distributions in different redshift
intervals, incorporating the consideration of the selection effects of CHIME.
As a result, we obtained a non-evolving energy function (EF) for the
high-energy FRBs (HEFRBs) of energies $E\gtrsim2\times0^{38}$ erg, which takes
the form of a power law with a low-energy exponential cutoff. On the contrary,
the energy distribution of the low-energy FRBs (LEFRBs) obviously cannot be
described by the same EF. Including the lowest dispersion measure (DM) samples,
the LEFRBs are concentrated towards the Galactic plane and their latitude
distribution is similar to that of Galactic rotational radio transients
(RRATs). These indications hint that LEFRBs might compose a special type of
RRATs, with relatively higher DMs and energies (i.e., $\sim10^{28-31}$ erg for
a reference distance of $\sim10$ kpc if they belong to the Milky Way). Finally,
we revisit the redshift-dependent event rate of HEFRBs and confirm that they
could be produced by the remnants of cosmological compact binary mergers.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:45:01 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2023 14:47:41 GMT""}]","2023-06-06"
"2303.14696","Bettina Keller","Stefanie Kieninger and Simon Ghysbrecht and Bettina G. Keller","Girsanov reweighting for simulations of underdamped Langevin dynamics.
  Theory","33 pages, 4 figures, contains the supplementary material as appendix",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The critical step in a molecular process is often a rare-event and has to be
simulated by an enhanced sampling protocol. Recovering accurate dynamical
estimates from such biased simulation is challenging. Girsanov reweighting is a
method to reweight dynamic properties formulated as path expected values. The
path probability is calculated at the time-step resolution of the
molecular-dynamics integrator. But the theory is largely limited to overdamped
Langevin dynamics. For underdamped Langevin dynamics, the absolute continuity
of the path probability ratio for the biased and unbiased potential is not
guaranteed, but it depends on the Langevin integrator. We develop a general
approach to derive the path probability ratio for Langevin integrators and to
analyze whether absolute continuity is fulfilled. We demonstrate our approach
on symmetric splitting methods for underdamped Langevin dynamics. For methods
that obey absolute continuity, and thus can be used for Girsanov reweighting,
we provide an expression for the relative path probability. %
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:53:09 GMT""}]","2023-03-28"
"2303.14697","Pascal Weil","Mallika Roy and Enric Ventura and Pascal Weil","The central tree property and algorithmic problems on subgroups of free
  groups","26 pages",,,,"math.GR cs.CC","http://creativecommons.org/licenses/by/4.0/","  We study the average case complexity of the generalized membership problem
for subgroups of free groups, and we show that it is orders of magnitude
smaller than the worst case complexity of the best known algorithms. This
applies to subgroups given by a fixed number of generators as well as to
subgroups given by an exponential number of generators. The main idea behind
this result is to exploit a generic property of tuples of words, called the
central tree property.
  An application is given to the average case complexity of the relative
primitivity problem, using Shpilrain's recent algorithm to decide primitivity,
whose average case complexity is a constant depending only on the rank of the
ambient free group.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 11:55:01 GMT""}]","2023-03-28"
"2303.14698","Tanwi Debnath","Poulami Bag, Shubhadip Nayak, Tanwi Debnath and Pulak K. Ghosh","Directed Autonomous Motion and Chiral Separation of Self-Propelled Janus
  Particles in Convection Roll Arrays",,"J. Phys. Chem. Lett. 2022, 13, 11413","10.1021/acs.jpclett.2c03193",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Self-propelled Janus particles exhibit autonomous motion thanks to engines of
their own. However, due to randomly changing direction of such motion they are
of little use for emerging nano-technological and bio-medical applications.
Here, we numerically show that the motion of chiral active Janus can be
directed subjecting them to a linear array of convection rolls. Rectification
power of self-propulsion motion here can be made more than 60% which is much
larger than earlier reports. We show that rectification of chiral Janus
particle's motion leads to conspicuous segregation of dextrogyre and levogyre
active particles from a racemic binary mixture. Further, we demonstrate how
efficiently the rectification effect can be exploited to separate dextrogyre
and levogyre particles when their intrinsic torques are distributed with
Gaussian statistics.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:01:18 GMT""}]","2023-03-28"
"2303.14699","Peter Marschik","Peter B Marschik, Amanda KL Kwong, Nelson Silva, Joy E Olsen, Martin
  Schulte-Ruether, Sven Bolte, Maria Ortqvist, Abbey Eeles, Luise Poustka,
  Christa Einspieler, Karin Nielsen-Saines, Dajie Zhang, Alicia J Spittle","Mobile solutions for clinical surveillance and evaluation in infancy --
  General Movement Apps","19 pages, 3 Figures, 2 Tables",,,,"cs.HC cs.CY cs.SE","http://creativecommons.org/licenses/by-sa/4.0/","  The Prechtl General Movements Assessment (GMA) has become a clinician and
researcher tool-box for evaluating neurodevelopment in early infancy. Given it
involves observation of infant movements from video recordings, utilising
smartphone applications to obtain these recordings seems like the natural
progression for the field. In this review, we look back on the development of
apps for acquiring general movement videos, describe the application and
research studies of available apps, and discuss future directions of mobile
solutions and their usability in research and clinical practice. We emphasise
the importance of understanding the background that has led to these
developments while introducing new technologies, including the barriers and
facilitators along the pathway. The GMApp and Baby Moves App were the first
ones developed to increase accessibility of the GMA, with two further apps,
NeuroMotion and InMotion, designed since. The Baby Moves app has been applied
most frequently. For the mobile future of GMA, we advocate collaboration to
boost the field's progression and to reduce research waste. We propose future
collaborative solutions including standardisation of cross-sites data
collection, adaption to local context and privacy laws, employment of user
feedback, and sustainable IT structures enabling continuous software updating.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:03:05 GMT""}]","2023-03-28"
"2303.14700","Xuelin Qian","Simian Luo, Xuelin Qian, Yanwei Fu, Yinda Zhang, Ying Tai, Zhenyu
  Zhang, Chengjie Wang, Xiangyang Xue","Learning Versatile 3D Shape Generation with Improved AR Models","26 pages, 26 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Auto-Regressive (AR) models have achieved impressive results in 2D image
generation by modeling joint distributions in the grid space. While this
approach has been extended to the 3D domain for powerful shape generation, it
still has two limitations: expensive computations on volumetric grids and
ambiguous auto-regressive order along grid dimensions. To overcome these
limitations, we propose the Improved Auto-regressive Model (ImAM) for 3D shape
generation, which applies discrete representation learning based on a latent
vector instead of volumetric grids. Our approach not only reduces computational
costs but also preserves essential geometric details by learning the joint
distribution in a more tractable order. Moreover, thanks to the simplicity of
our model architecture, we can naturally extend it from unconditional to
conditional generation by concatenating various conditioning inputs, such as
point clouds, categories, images, and texts. Extensive experiments demonstrate
that ImAM can synthesize diverse and faithful shapes of multiple categories,
achieving state-of-the-art performance.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:03:18 GMT""}]","2023-03-28"
"2303.14701","Shuai Ma","Guangming Shi, Dahua Gao, Shuai Ma, Minxi Yang, Yong Xiao, and Xuemei
  Xie","Mathematical Characterization of Signal Semantics and Rethinking of the
  Mathematical Theory of Information",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Shannon information theory is established based on probability and bits, and
the communication technology based on this theory realizes the information age.
The original goal of Shannon's information theory is to describe and transmit
information content. However, due to information is related to cognition, and
cognition is considered to be subjective, Shannon information theory is to
describe and transmit information-bearing signals. With the development of the
information age to the intelligent age, the traditional signal-oriented
processing needs to be upgraded to content-oriented processing. For example,
chat generative pre-trained transformer (ChatGPT) has initially realized the
content processing capability based on massive data. For many years,
researchers have been searching for the answer to what the information content
in the signal is, because only when the information content is mathematically
and accurately described can information-based machines be truly intelligent.
This paper starts from rethinking the essence of the basic concepts of the
information, such as semantics, meaning, information and knowledge, presents
the mathematical characterization of the information content, investigate the
relationship between them, studies the transformation from Shannon's signal
information theory to semantic information theory, and therefore proposes a
content-oriented semantic communication framework. Furthermore, we propose
semantic decomposition and composition scheme to achieve conversion between
complex and simple semantics. Finally, we verify the proposed characterization
of information-related concepts by implementing evolvable knowledge-based
semantic recognition.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:08:27 GMT""}]","2023-03-28"
"2303.14702","Fabio Calefato","Fabio Calefato and Luigi Quaranta and Filippo Lanubile","A Lot of Talk and a Badge: An Empirical Analysis of Personal
  Achievements in GitHub",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  GitHub has introduced gamification via personal achievements, whereby badges
are unlocked and displayed on developers' personal profile pages in recognition
of their development activities. In this paper, we present a mixed-methods
empirical investigation to study the diffusion of personal badges in GitHub in
addition to the effects of and the reactions to their introduction. First, we
conducted an observational study by mining longitudinal data for over 6,000
developers and performed correlation as well as regression analysis. Then, we
analyzed 33 answers to a survey and 312 GITHUB community discussions about
personal badges to gauge how the community reacted to the introduction of the
new feature. We found that most of the sampled developers own at least a badge,
but we also observed an increasing number of users who choose to keep their
profile private and opt out from displaying badges. Besides, badges are in
general poorly correlated with developers' qualities and dispositions such as
timeliness and desire to collaborate. We also found that, with the exception of
the Starstruck badge and the number of followers, their introduction to GitHub
had no effects. Finally, the reaction of the community has been in general
mixed, as developers find them appealing in principle but without a clear
purpose and hardly reflecting their abilities in the current form.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:08:50 GMT""}]","2023-03-28"
"2303.14703","Hadar Hezi","Hadar Hezi, Daniel Shats, Daniel Gurevich, Yosef E. Maruvka, Moti
  Freiman","Biologically-primed deep neural network improves colorectal Cancer
  Molecular subtypes prediction from H&E stained images",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Colorectal cancer (CRC) molecular subtypes play a crucial role in determining
treatment options. Immunotherapy is effective for the microsatellite
instability (MSI) subtype of CRC, but not for the microsatellite stability
(MSS) subtype. Recently, convolutional neural networks (CNNs) have been
proposed for automated determination of CRC subtypes from H\&E stained
histopathological images. However, previous CNN architectures only consider
binary outcomes of MSI or MSS, and do not account for additional biological
cues that may affect the histopathological imaging phenotype. In this study, we
propose a biologically-primed CNN (BP-CNN) architecture for CRC subtype
classification from H\&E stained images. Our BP-CNN accounts for additional
biological cues by casting the binary classification outcome into a
biologically-informed multi-class outcome. We evaluated the BP-CNN approach
using a 5-fold cross-validation experimental setup for model development on the
TCGA-CRC-DX cohort, comparing it to a baseline binary classification CNN. Our
BP-CNN achieved superior performance when using either
single-nucleotide-polymorphism (SNP) molecular features (AUC: 0.824$\pm$0.02
vs. 0.761$\pm$0.04, paired t-test, p$<$0.05) or CpG-Island methylation
phenotype (CIMP) molecular features (AUC: 0.834$\pm$0.01 vs. 0.787$\pm$0.03,
paired t-test, p$<$0.05). A combination of CIMP and SNP models further improved
classification accuracy (AUC: 0.847$\pm$0.01 vs. 0.787$\pm$0.03, paired t-test,
p$=$0.01). Our BP-CNN approach has the potential to provide insight into the
biological cues that influence cancer histopathological imaging phenotypes and
to improve the accuracy of deep-learning-based methods for determining cancer
subtypes from histopathological imaging data.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:13:29 GMT""}]","2023-03-28"
"2303.14704","Guorun Wang","Guorun Wang, Jun Yang, Yaoru Sun","Task-oriented Memory-efficient Pruning-Adapter",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Outstanding performance and growing size of Large Language Models has led
to increased attention in parameter efficient learning. The two predominant
approaches are Adapters and Pruning. Adapters are to freeze the model and give
it a new weight matrix on the side, which can significantly reduce the time and
memory of training, but the cost is that the evaluation and testing will
increase the time and memory consumption. Pruning is to cut off some weight and
re-distribute the remaining weight, which sacrifices the complexity of training
at the cost of extremely high memory and training time, making the cost of
evaluation and testing relatively low. So efficiency of training and inference
can't be obtained in the same time. In this work, we propose a task-oriented
Pruning-Adapter method that achieve a high memory efficiency of training and
memory, and speeds up training time and ensures no significant decrease in
accuracy in GLUE tasks, achieving training and inference efficiency at the same
time.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:18:00 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 03:44:38 GMT""}]","2023-04-07"
"2303.14705","Mohammad Modiri","Mohammad Modiri","Control of synaptic plasticity via the fusion of reinforcement learning
  and unsupervised learning in neural networks","Draft version. arXiv admin note: substantial text overlap with
  arXiv:2303.07273",,,,"cs.NE cs.AI cs.LG cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The brain can learn to execute a wide variety of tasks quickly and
efficiently. Nevertheless, most of the mechanisms that enable us to learn are
unclear or incredibly complicated. Recently, considerable efforts have been
made in neuroscience and artificial intelligence to understand and model the
structure and mechanisms behind the amazing learning capability of the brain.
However, in the current understanding of cognitive neuroscience, it is widely
accepted that synaptic plasticity plays an essential role in our amazing
learning capability. This mechanism is also known as the Credit Assignment
Problem (CAP) and is a fundamental challenge in neuroscience and Artificial
Intelligence (AI). The observations of neuroscientists clearly confirm the role
of two important mechanisms including the error feedback system and
unsupervised learning in synaptic plasticity. With this inspiration, a new
learning rule is proposed via the fusion of reinforcement learning (RL) and
unsupervised learning (UL). In the proposed computational model, the nonlinear
optimal control theory is used to resemble the error feedback loop systems and
project the output error to neurons membrane potential (neurons state), and an
unsupervised learning rule based on neurons membrane potential or neurons
activity are utilized to simulate synaptic plasticity dynamics to ensure that
the output error is minimized.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:18:03 GMT""}]","2023-03-28"
"2303.14706","Qian Wang","Qian Wang, Yiqun Wang, Michael Birsak, Peter Wonka","BlobGAN-3D: A Spatially-Disentangled 3D-Aware Generative Model for
  Indoor Scenes",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D-aware image synthesis has attracted increasing interest as it models the
3D nature of our real world. However, performing realistic object-level editing
of the generated images in the multi-object scenario still remains a challenge.
Recently, a 2D GAN termed BlobGAN has demonstrated great multi-object editing
capabilities on real-world indoor scene datasets. In this work, we propose
BlobGAN-3D, which is a 3D-aware improvement of the original 2D BlobGAN. We
enable explicit camera pose control while maintaining the disentanglement for
individual objects in the scene by extending the 2D blobs into 3D blobs. We
keep the object-level editing capabilities of BlobGAN and in addition allow
flexible control over the 3D location of the objects in the scene. We test our
method on real-world indoor datasets and show that our method can achieve
comparable image quality compared to the 2D BlobGAN and other 3D-aware GAN
baselines while being able to enable camera pose control and object-level
editing in the challenging multi-object real-world scenarios.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:23:11 GMT""}]","2023-03-28"
"2303.14707","Xinhang Liu","Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang","Clean-NeRF: Reformulating NeRF to account for View-Dependent
  Observations",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  While Neural Radiance Fields (NeRFs) had achieved unprecedented novel view
synthesis results, they have been struggling in dealing with large-scale
cluttered scenes with sparse input views and highly view-dependent appearances.
Specifically, existing NeRF-based models tend to produce blurry rendering with
the volumetric reconstruction often inaccurate, where a lot of reconstruction
errors are observed in the form of foggy ""floaters"" hovering within the entire
volume of an opaque 3D scene. Such inaccuracies impede NeRF's potential for
accurate 3D NeRF registration, object detection, segmentation, etc., which
possibly accounts for only limited significant research effort so far to
directly address these important 3D fundamental computer vision problems to
date. This paper analyzes the NeRF's struggles in such settings and proposes
Clean-NeRF for accurate 3D reconstruction and novel view rendering in complex
scenes. Our key insights consist of enforcing effective appearance and geometry
constraints, which are absent in the conventional NeRF reconstruction, by 1)
automatically detecting and modeling view-dependent appearances in the training
views to prevent them from interfering with density estimation, which is
complete with 2) a geometric correction procedure performed on each traced ray
during inference. Clean-NeRF can be implemented as a plug-in that can
immediately benefit existing NeRF-based methods without additional input. Codes
will be released.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:24:31 GMT""}]","2023-03-28"
"2303.14708","Huiru Wang","Huiru Wang, Xiuhong Li, Zenyu Ren, Dan Yang, chunming Ma","Exploring Multimodal Sentiment Analysis via CBAM Attention and
  Double-layer BiLSTM Architecture",,,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Because multimodal data contains more modal information, multimodal sentiment
analysis has become a recent research hotspot. However, redundant information
is easily involved in feature fusion after feature extraction, which has a
certain impact on the feature representation after fusion. Therefore, in this
papaer, we propose a new multimodal sentiment analysis model. In our model, we
use BERT + BiLSTM as new feature extractor to capture the long-distance
dependencies in sentences and consider the position information of input
sequences to obtain richer text features. To remove redundant information and
make the network pay more attention to the correlation between image and text
features, CNN and CBAM attention are added after splicing text features and
picture features, to improve the feature representation ability. On the
MVSA-single dataset and HFM dataset, compared with the baseline model, the ACC
of our model is improved by 1.78% and 1.91%, and the F1 value is enhanced by
3.09% and 2.0%, respectively. The experimental results show that our model
achieves a sound effect, similar to the advanced model.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:34:01 GMT""}]","2023-03-28"
"2303.14709","Jordanka Kovaceva","Jordanka Kovaceva, Nikolce Murgovski, Bal\'azs Kulcs\'ar, Henk
  Wymeersch, Jonas B\""argman","Critical Zones for Comfortable Collision Avoidance with a Leading
  Vehicle",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides a general framework for efficiently obtaining the
appropriate intervention time for collision avoidance systems to just avoid a
rear-end crash. The proposed framework incorporates a driver comfort model and
a vehicle model. We show that there is a relationship between driver steering
manoeuvres based on acceleration and jerk, and steering angle and steering
angle rate profiles. We investigate how four different vehicle models influence
the time when steering needs to be initiated to avoid a rear-end collision. The
models assessed were: a dynamic bicycle model (DM), a steady-state cornering
model (SSCM), a kinematic model (KM) and a point mass model (PMM). We show that
all models can be described by a parameter-varying linear system. We provide
three algorithms for steering that use a linear system to compute the
intervention time efficiently for all four vehicle models. Two of the
algorithms use backward reachability simulation and one uses forward
simulation. Results show that the SSCM, KM and PMM do not accurately estimate
the intervention time for a certain set of vehicle conditions. Due to its fast
computation time, DM with a backward reachability algorithm can be used for
rapid offline safety benefit assessment, while DM with a forward simulation
algorithm is better suited for online real-time usage.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:35:51 GMT""}]","2023-03-28"
"2303.14710","Martin P\'epin","Martin P\'epin and Alfredo Viola","Asymptotic analysis and efficient random sampling of directed ordered
  acyclic graphs","32 pages, 12 figures. For the implementation of the algorithms, see
  https://github.com/Kerl13/randdag",,,,"cs.DM math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Directed acyclic graphs (DAGs) are directed graphs in which there is no path
from a vertex to itself. DAGs are an omnipresent data structure in computer
science and the problem of counting the DAGs of given number of vertices and to
sample them uniformly at random has been solved respectively in the 70's and
the 00's. In this paper, we propose to explore a new variation of this model
where DAGs are endowed with an independent ordering of the out-edges of each
vertex, thus allowing to model a wide range of existing data structures. We
provide efficient algorithms for sampling objects of this new class, both with
or without control on the number of edges, and obtain an asymptotic equivalent
of their number. We also show the applicability of our method by providing an
effective algorithm for the random generation of classical labelled DAGs with a
prescribed number of vertices and edges, based on a similar approach. This is
the first known algorithm for sampling labelled DAGs with full control on the
number of edges, and it meets a need in terms of applications, that had already
been acknowledged in the literature.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:39:56 GMT""}]","2023-03-28"
"2303.14711","Marcel Reimann","Marcel Reimann, Jungeun Won, Hiroyuki Takahashi, Antonio Yaghy,
  Yunchan Hwang, Stefan Ploner, Junhong Lin, Jessica Girgis, Kenneth Lam, Siyu
  Chen, Nadia K. Waheed, Andreas Maier, James G. Fujimoto","Unsupervised detection of small hyperreflective features in ultrahigh
  resolution optical coherence tomography","Accepted as poster at BVM workshop 2023
  (https://www.bvm-workshop.org/). The arXiv version provides full quality
  figures. 6 pages content (2 figures)",,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recent advances in optical coherence tomography such as the development of
high speed ultrahigh resolution scanners and corresponding signal processing
techniques may reveal new potential biomarkers in retinal diseases. Newly
visible features are, for example, small hyperreflective specks in age-related
macular degeneration. Identifying these new markers is crucial to investigate
potential association with disease progression and treatment outcomes.
Therefore, it is necessary to reliably detect these features in 3D volumetric
scans. Because manual labeling of entire volumes is infeasible a need for
automatic detection arises. Labeled datasets are often not publicly available
and there are usually large variations in scan protocols and scanner types.
Thus, this work focuses on an unsupervised approach that is based on local
peak-detection and random walker segmentation to detect small features on each
B-scan of the volume.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:45:42 GMT""}]","2023-03-28"
"2303.14712","Sivaprasad Kumar S","Surya Giri and S. Sivaprasad Kumar","Toeplitz determinants of Logarithmic coefficients for Starlike and
  Convex functions",,,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we deal with the sharp bounds of certain Toeplitz determinants
whose entries are the logarithmic coefficients of analytic univalent functions
$f$ such that the quantity $z f'(z)/f(z)$ takes values in a specific domain
lying in the right half plane. The established results provide the bounds for
the classes of starlike and convex functions, as well as various of their
subclasses.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:45:52 GMT""}]","2023-03-28"
"2303.14713","Peng Liang","Aakash Ahmad, Muhammad Waseem, Peng Liang, Mahdi Fehmideh, Arif Ali
  Khan, David Georg Reichelt, Tommi Mikkonen","Engineering Software Systems for Quantum Computing as a Service: A
  Mapping Study",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Quantum systems have started to emerge as a disruptive technology and
enabling platforms - exploiting the principles of quantum mechanics - to
achieve quantum supremacy in computing. Academic research, industrial projects
(e.g., Amazon Braket), and consortiums like 'Quantum Flagship' are striving to
develop practically capable and commercially viable quantum computing (QC)
systems and technologies. Quantum Computing as a Service (QCaaS) is viewed as a
solution attuned to the philosophy of service-orientation that can offer QC
resources and platforms, as utility computing, to individuals and organisations
who do not own quantum computers. To understand the quantum service development
life cycle and pinpoint emerging trends, we used evidence-based software
engineering approach to conduct a systematic mapping study (SMS) of research
that enables or enhances QCaaS. The SMS process retrieved a total of 55
studies, and based on their qualitative assessment we selected 9 of them to
investigate (i) the functional aspects, design models, patterns, programming
languages, deployment platforms, and (ii) trends of emerging research on QCaaS.
The results indicate three modelling notations and a catalogue of five design
patterns to architect QCaaS, whereas Python (native code or frameworks) and
Amazon Braket are the predominant solutions to implement and deploy QCaaS
solutions. From the quantum software engineering (QSE) perspective, this SMS
provides empirically grounded findings that could help derive processes,
patterns, and reference architectures to engineer software services for QC.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 12:50:22 GMT""}]","2023-03-28"
"2303.14714","Jaan Parts","Aubrey D.N.J. de Grey, Jaan Parts","On lower bounds of the order of $k$-chromatic unit distance graphs",,"Geombinatorics 32/2 (2022) 72-74",,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Here we give refined numerical values for the minimum number of vertices of
$k$-chromatic unit distance graphs in the Euclidean plane.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:02:20 GMT""}]","2023-03-28"
"2303.14715","Manoj Kumar","Federico Corberi, Manoj Kumar, Eugenio Lippiello, Paolo Politi","Domain statistics in the relaxation of the one-dimensional Ising model
  with strong long-range interactions","10 pages",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After a zero temperature quench, we study the kinetics of the one-dimensional
Ising model with long-range interactions between spins at distance $r$ decaying
as $r^{-\alpha}$, with $\alpha \le 1$. As shown in our recent study [SciPost
Phys 10, 109 (2021)] that only a fraction of the non-equilibrium trajectories
is characterized by the presence of coarsening domains while in the remaining
ones the system is quickly driven towards a magnetised state. Restricting to
realisations displaying coarsening we compute numerically the probability
distribution of the size of the domains and find that it exhibits a scaling
behaviour with an unusual $\alpha$-dependent power-law decay. This peculiar
behaviour is also related to the divergence of the average size of domains with
system size at finite times. Such a scenario differs from the one observed when
$\alpha>1$, where the distribution decays exponentially. Finally, based on
numerical results and on analytical calculations we argue that the average
domain size grows asymptotically linearly in time.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:02:27 GMT""}]","2023-03-28"
"2303.14716","Giovanni Montana","Alex Beeson and Giovanni Montana","Balancing policy constraint and ensemble size in uncertainty-based
  offline reinforcement learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Offline reinforcement learning agents seek optimal policies from fixed data
sets. With environmental interaction prohibited, agents face significant
challenges in preventing errors in value estimates from compounding and
subsequently causing the learning process to collapse. Uncertainty estimation
using ensembles compensates for this by penalising high-variance value
estimates, allowing agents to learn robust policies based on data-driven
actions. However, the requirement for large ensembles to facilitate sufficient
penalisation results in significant computational overhead. In this work, we
examine the role of policy constraints as a mechanism for regulating
uncertainty, and the corresponding balance between level of constraint and
ensemble size. By incorporating behavioural cloning into policy updates, we
show empirically that sufficient penalisation can be achieved with a much
smaller ensemble size, substantially reducing computational demand while
retaining state-of-the-art performance on benchmarking tasks. Furthermore, we
show how such an approach can facilitate stable online fine tuning, allowing
for continued policy improvement while avoiding severe performance drops.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:03:11 GMT""}]","2023-03-28"
"2303.14717","Jianhui Yu","Jianhui Yu, Hao Zhu, Liming Jiang, Chen Change Loy, Weidong Cai, Wayne
  Wu","CelebV-Text: A Large-Scale Facial Text-Video Dataset","Accepted by CVPR2023. Project Page: https://celebv-text.github.io/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-driven generation models are flourishing in video generation and
editing. However, face-centric text-to-video generation remains a challenge due
to the lack of a suitable dataset containing high-quality videos and highly
relevant texts. This paper presents CelebV-Text, a large-scale, diverse, and
high-quality dataset of facial text-video pairs, to facilitate research on
facial text-to-video generation tasks. CelebV-Text comprises 70,000 in-the-wild
face video clips with diverse visual content, each paired with 20 texts
generated using the proposed semi-automatic text generation strategy. The
provided texts are of high quality, describing both static and dynamic
attributes precisely. The superiority of CelebV-Text over other datasets is
demonstrated via comprehensive statistical analysis of the videos, texts, and
text-video relevance. The effectiveness and potential of CelebV-Text are
further shown through extensive self-evaluation. A benchmark is constructed
with representative methods to standardize the evaluation of the facial
text-to-video generation task. All data and models are publicly available.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:06:35 GMT""}]","2023-03-28"
"2303.14718","Kazuki Sugihara","Kazuki Sugihara, Moju Zhao, Takuzumi Nishio, Tasuku Makabe, Kei Okada,
  Masayuki Inaba","Design and Control of a Humanoid Equipped with Flight Unit and Wheels
  for Multimodal Locomotion","8 pages 17 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humanoids are versatile robotic platforms because of their limbs with
multiple degrees of freedom. Although humanoids can walk like humans, the speed
is relatively slow, and they cannot run over large barriers. To address these
problems, we aim to achieve rapid terrestrial locomotion ability and
simultaneously expand the domain of locomotion to the air by utilizing thrust
for propulsion. In this paper, we first describe an optimized construction
method of a humanoid robot equipped with wheels and a flight unit to achieve
these abilities. Then, we describe the integrated control framework of the
proposed flying humanoid for each mode of locomotion: aerial locomotion, leg
locomotion, and wheel locomotion. Finally, we achieved multimodal locomotion
and aerial manipulation experiments using the robot platform proposed in this
work. To the best of our knowledge, it is the first time to achieve three
different types of locomotion, including flight, by a single humanoid.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:09:14 GMT""}]","2023-03-28"
"2303.14719","Victor Shirandami","Victor Shirandami","Dense Forests Constructed from Grids","18 pages",,,,"math.NT math.MG","http://creativecommons.org/licenses/by/4.0/","  A dense forest is a set $F \subset \mathbb{R}^n$ with the property that for
all $\varepsilon > 0$ there exists a number $V(\varepsilon) > 0$ such that all
line segments of length $V(\varepsilon)$ are $\varepsilon$-close to a point in
$F$. The function $V$ is called a visibility function of $F$. In this paper we
study dense forests constructed from finite unions of translated lattices
(grids). First, we provide a necessary and sufficient condition for a finite
union of grids to be a dense forest in terms of the irrationality properties of
the matrices defining them. This answers a question raised by Adiceam, Solomon,
and Weiss (2022). To complement this, we further show that such sets
generically admit effective visibility bounds in the following sense: for all
$\eta > 0$, there exists a $k \in \mathbb{N}$ such that almost all unions of
$k$ grids are dense forests admitting a visibility function $V(\varepsilon) \ll
\varepsilon^{-(n-1) -\eta}$. This is arbitrarily close to optimal in the sense
that if a finite union of grids admits a visibility function $V$, then this
function necessarily satisfies $V(\varepsilon) \gg \varepsilon^{-(n-1)}$. One
of the main novelties of this work is that the notion of `almost all' is
considered with respect to several underlying measures, which are defined
according to the Iwasawa decomposition of the matrices used to define the
grids. In this respect, the results obtained here vastly extend those of
Adiceam, Solomon, and Weiss (2022) who provided similar effective visibility
bounds for a particular family of generic unimodular lattices.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:11:49 GMT""}]","2023-03-28"
"2303.14720","Bashar I. Ahmad","Nermin Caber, Jiaming Liang, Bashar I. Ahmad, Simon Godsill, Alexandra
  Bremers, Philip Thomas, David Oxtoby and Lee Skrypchuk","Driver Profiling and Bayesian Workload Estimation Using Naturalistic
  Peripheral Detection Study Data",,,,,"eess.SP cs.LG cs.SY eess.SY","http://creativecommons.org/publicdomain/zero/1.0/","  Monitoring drivers' mental workload facilitates initiating and maintaining
safe interactions with in-vehicle information systems, and thus delivers
adaptive human machine interaction with reduced impact on the primary task of
driving. In this paper, we tackle the problem of workload estimation from
driving performance data. First, we present a novel on-road study for
collecting subjective workload data via a modified peripheral detection task in
naturalistic settings. Key environmental factors that induce a high mental
workload are identified via video analysis, e.g. junctions and behaviour of
vehicle in front. Second, a supervised learning framework using
state-of-the-art time series classifiers (e.g. convolutional neural network and
transform techniques) is introduced to profile drivers based on the average
workload they experience during a journey. A Bayesian filtering approach is
then proposed for sequentially estimating, in (near) real-time, the driver's
instantaneous workload. This computationally efficient and flexible method can
be easily personalised to a driver (e.g. incorporate their inferred average
workload profile), adapted to driving/environmental contexts (e.g. road type)
and extended with data streams from new sources. The efficacy of the presented
profiling and instantaneous workload estimation approaches are demonstrated
using the on-road study data, showing $F_{1}$ scores of up to 92% and 81%,
respectively.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:15:44 GMT""}]","2023-03-28"
"2303.14721","Claudius Heyer","Claudius Heyer","The Geometrical Lemma for Smooth Representations in Natural
  Characteristic","32 pages. Comments welcome!",,,,"math.RT math.NT","http://creativecommons.org/licenses/by/4.0/","  The Geometrical Lemma is a classical result in the theory of (complex) smooth
representations of $p$-adic reductive groups, which helps to analyze the
parabolic restriction of a parabolically induced representation by providing a
filtration whose graded pieces are (smaller) parabolic inductions of parabolic
restrictions. In this article, we establish the Geometrical Lemma for the
derived category of smooth mod $p$ representations of a $p$-adic reductive
group.
  As an important application we compute higher extension groups between
parabolically induced representations, which in a slightly different context
had been achieved by Hauseux assuming a conjecture of Emerton concerning the
higher ordinary parts functor. We also compute the (cohomology functors of the)
left adjoint of derived parabolic induction on principal series and generalized
Steinberg representations.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:18:04 GMT""}]","2023-03-28"
"2303.14722","Jaan Parts","Jaan Parts","More certainty in coloring the plane with a forbidden distance interval",,"Geombinatorics 32/4 (2023) 159-185",,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  In the mysterious and colorful world of chromatic numbers, where there are a
lot of unknown, there is an amazing thing. It turns out that for some intervals
of forbidden distances on the plane, one can specify the exact value of the
chromatic number $\chi$. Two sets of such intervals have been found, for
$\chi=7$ and 9. We call them islands of certainty. Here we increase the size of
these islands, and add three new ones with $\chi=8$, 12, 13. We also %formulate
conjectures which predict conjecture islands for $\chi=14$, 15, 16. Are there
islands of certainty for $\chi$=10 or 11? This is still a mystery. Roll up for
the Mystery Tour.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:19:50 GMT""}]","2023-03-28"
"2303.14723","Zongsheng Zhou","Zongsheng Zhou, Weinan Ye, Hong-Gang Luo, Jize Zhao, Jun Chang","Robust superconducting correlation against inter-site interactions in
  the extended two-leg Hubbard ladder",,,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The Hubbard and related models serve as a fundamental starting point in
understanding the novel experimental phenomena in correlated electron
materials, such as superconductivity, Mott insulator, magnetism and stripe
phases. Recent numerical simulations indicate that the emergence of
superconductivity is connected with the next nearest-neighbor hopping
$t^\prime$ in the Hubbard model. However, the impacts of complex inter-site
electron interaction in the $t^\prime$-Hubbard model are less explored.
Utilizing the state-of-art density-matrix renormalization group method, we
investigate the $t^\prime$-Hubbard model on a two-leg ladder with inter-site
interactions extended to the fourth neighbor sites. The accurate numerical
results show that the quasi-long-range superconducting correlation remains
stable under the repulsive nearest-neighbor and the next nearest-neighbor
interactions though these interactions are against the superconductivity. The
ground state properties are also undisturbed by the longer-range repulsive
interactions. In addition, inspired by recent experiments on one-dimensional
cuprates chain $\mathrm{Ba}_{2-x}\mathrm{Sr}_x\mathrm{CuO}_{3+\delta}$, which
implies an effective attraction between the nearest neighbors may exist in the
cuprates superconductors, we also show that the attractive interaction between
the nearest neighbors significantly enhances the superconducting correlation
when it is comparable to the strength of the nearest-neighbor hopping
$t^\prime$. Stronger attraction drives the system into a Luther-Emery liquid
phase. Nevertheless, with the attraction further increasing, the system enters
an electron-hole phase separation and the superconducting correlation is
destroyed. Finally, we investigate the effects of on-site Coulomb interaction
on superconductivity.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:26:17 GMT""}]","2023-03-28"
"2303.14724","Vasilis Oikonomou","V.K. Oikonomou, Konstantinos-Rafail Revis, Ilias C. Papadimitriou,
  Maria-Myrto Pegioudi","Swampland Criteria and Constraints on Inflation in a $f(R,T)$ Gravity
  Theory","IJMPD Accepted",,"10.1142/S0218271823500347",,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we worked in the framework of an inflationary $f(R,T)$ theory,
in the presence of a canonical scalar field. More specifically, the
$f(R,T)=\gamma R+2\kappa\alpha T$ gravity. The values of the dimensionless
parameters $\alpha$ and $\gamma$ are taken to be $\alpha \geq 0$ and $0 <
\gamma \leq 1$. The motivation for that study was the striking similarities
between the slow-roll parameters of the inflationary model used in this work
and the ones obtained by the rescaled Einstein-Hilbert gravity inflation
$f(R)=\alpha R$. We examined a variety of potentials to determine if they agree
with the current Planck Constraints. In addition, we checked whether these
models satisfy the Swampland Criteria and we specified the exact region of the
parameter space that produces viable results for each model. As we mention in
Section IV the inflationary $f(R,T)$ theory used in this work can not produce a
positive $n_T$ which implies that the stochastic gravitational wave background
will not be detectable.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:42:53 GMT""}]","2023-06-07"
"2303.14725","Fei Yu","Fei Yu, Hongbo Zhang, Prayag Tiwari, Benyou Wang","Natural Language Reasoning, A Survey","https://github.com/FreedomIntelligence/ReasoningNLP",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This survey paper proposes a clearer view of natural language reasoning in
the field of Natural Language Processing (NLP), both conceptually and
practically. Conceptually, we provide a distinct definition for natural
language reasoning in NLP, based on both philosophy and NLP scenarios, discuss
what types of tasks require reasoning, and introduce a taxonomy of reasoning.
Practically, we conduct a comprehensive literature review on natural language
reasoning in NLP, mainly covering classical logical reasoning, natural language
inference, multi-hop question answering, and commonsense reasoning. The paper
also identifies and views backward reasoning, a powerful paradigm for
multi-step reasoning, and introduces defeasible reasoning as one of the most
important future directions in natural language reasoning research. We focus on
single-modality unstructured natural language text, excluding neuro-symbolic
techniques and mathematical reasoning.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:44:18 GMT""},{""version"":""v2"",""created"":""Sat, 13 May 2023 15:56:44 GMT""}]","2023-05-16"
"2303.14726","Xiaoming Li","Xiaoming Li, Wangmeng Zuo, Chen Change Loy","Learning Generative Structure Prior for Blind Text Image
  Super-resolution","CVPR 2023. Code: https://github.com/csxmli2016/MARCONet",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blind text image super-resolution (SR) is challenging as one needs to cope
with diverse font styles and unknown degradation. To address the problem,
existing methods perform character recognition in parallel to regularize the SR
task, either through a loss constraint or intermediate feature condition.
Nonetheless, the high-level prior could still fail when encountering severe
degradation. The problem is further compounded given characters of complex
structures, e.g., Chinese characters that combine multiple pictographic or
ideographic symbols into a single character. In this work, we present a novel
prior that focuses more on the character structure. In particular, we learn to
encapsulate rich and diverse structures in a StyleGAN and exploit such
generative structure priors for restoration. To restrict the generative space
of StyleGAN so that it obeys the structure of characters yet remains flexible
in handling different font styles, we store the discrete features for each
character in a codebook. The code subsequently drives the StyleGAN to generate
high-resolution structural details to aid text SR. Compared to priors based on
character recognition, the proposed structure prior exerts stronger
character-specific guidance to restore faithful and precise strokes of a
designated character. Extensive experiments on synthetic and real datasets
demonstrate the compelling performance of the proposed generative structure
prior in facilitating robust text SR.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:54:28 GMT""}]","2023-03-28"
"2303.14727","Zhengzhe Liu","Zhengzhe Liu, Xiaojuan Qi, Chi-Wing Fu","One Thing One Click++: Self-Training for Weakly Supervised 3D Scene
  Understanding","arXiv admin note: substantial text overlap with arXiv:2104.02246",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  3D scene understanding, e.g., point cloud semantic and instance segmentation,
often requires large-scale annotated training data, but clearly, point-wise
labels are too tedious to prepare. While some recent methods propose to train a
3D network with small percentages of point labels, we take the approach to an
extreme and propose ``One Thing One Click,'' meaning that the annotator only
needs to label one point per object. To leverage these extremely sparse labels
in network training, we design a novel self-training approach, in which we
iteratively conduct the training and label propagation, facilitated by a graph
propagation module. Also, we adopt a relation network to generate the
per-category prototype to enhance the pseudo label quality and guide the
iterative training. Besides, our model can be compatible to 3D instance
segmentation equipped with a point-clustering strategy. Experimental results on
both ScanNet-v2 and S3DIS show that our self-training approach, with
extremely-sparse annotations, outperforms all existing weakly supervised
methods for 3D semantic and instance segmentation by a large margin, and our
results are also comparable to those of the fully supervised counterparts.
Codes and models are available at
https://github.com/liuzhengzhe/One-Thing-One-Click.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 13:57:00 GMT""}]","2023-03-28"
"2303.14728","Hangjie Ji","Hangjie Ji, Thomas P. Witelski","Coarsening of thin films with weak condensation","22 pages, 10 figures",,,,"physics.flu-dyn math.AP math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A lubrication model can be used to describe the dynamics of a weakly volatile
viscous fluid layer on a hydrophobic substrate. Thin layers of the fluid are
unstable to perturbations and break up into slowly evolving interacting
droplets. A reduced-order dynamical system is derived from the lubrication
model based on the nearest-neighbor droplet interactions in the weak
condensation limit. Dynamics for periodic arrays of identical drops and
pairwise droplet interactions are investigated which provide insights to the
coarsening dynamics of a large droplet system. Weak condensation is shown to be
a singular perturbation, fundamentally changing the long-time coarsening
dynamics for the droplets and the overall mass of the fluid in two additional
regimes of long-time dynamics.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:09:00 GMT""}]","2023-03-28"
"2303.14729","Knut Dundas Mor{\aa}","XENON Collaboration: E. Aprile, K. Abe, F. Agostini, S. Ahmed
  Maouloud, L. Althueser, B. Andrieu, E. Angelino, J. R. Angevaare, V. C.
  Antochi, D. Ant\'on Martin, F. Arneodo, L. Baudis, A. L. Baxter, M. Bazyk, L.
  Bellagamba, R. Biondi, A. Bismark, E. J. Brookes, A. Brown, S. Bruenner, G.
  Bruno, R. Budnik, T. K. Bui, C. Cai, J. M. R. Cardoso, D. Cichon, A. P.
  Cimental Chavez, A. P. Colijn, J. Conrad, J. J. Cuenca-Garc\'ia, J. P.
  Cussonneau, V. D'Andrea, M. P. Decowski, P. Di Gangi, S. Di Pede, S. Diglio,
  K. Eitel, A. Elykov, S. Farrell, A. D. Ferella, C. Ferrari, H. Fischer, M.
  Flierman, W. Fulgione, C. Fuselli, P. Gaemers, R. Gaior, A. Gallo Rosso, M.
  Galloway, F. Gao, R. Glade-Beucke, L. Grandi, J. Grigat, H. Guan, M. Guida,
  R. Hammann, A. Higuera, C. Hils, L. Hoetzsch, N. F. Hood, J. Howlett, M.
  Iacovacci, Y. Itow, J. Jakob, F. Joerg, A. Joy, N. Kato, M. Kara, P.
  Kavrigin, S. Kazama, M. Kobayashi, G. Koltman, A. Kopec, F. Kuger, H.
  Landsman, R. F. Lang, L. Levinson, I. Li, S. Li, S. Liang, S. Lindemann, M.
  Lindner, K. Liu, J. Loizeau, F. Lombardi, J. Long, J. A. M. Lopes, Y. Ma, C.
  Macolino, J. Mahlstedt, A. Mancuso, L. Manenti, F. Marignetti, T. Marrod\'an
  Undagoitia, K. Martens, J. Masbou, D. Masson, E. Masson, S. Mastroianni, M.
  Messina, K. Miuchi, K. Mizukoshi, A. Molinario, S. Moriyama, K. Mor{\aa}, Y.
  Mosbacher, M. Murra, J. M\""uller, K. Ni, U. Oberlack, B. Paetsch, J. Palacio,
  R. Peres, C. Peters, J. Pienaar, M. Pierre, V. Pizzella, G. Plante, J. Qi, J.
  Qin, D. Ram\'irez Garc\'ia, R. Singh, L. Sanchez, J. M. F. dos Santos, I.
  Sarnoff, G. Sartorelli, J. Schreiner, D. Schulte, P. Schulte, H. Schulze
  Ei{\ss}ing, M. Schumann, L. Scotto Lavina, M. Selvi, F. Semeria, P. Shagin,
  S. Shi, E. Shockley, M. Silva, H. Simgen, A. Takeda, P.-L. Tan, A. Terliuk,
  D. Thers, F. Toschi, G. Trinchero, C. Tunnell, F. T\""onnies, K. Valerius, G.
  Volta, C. Weinheimer, M. Weiss, D. Wenz, C. Wittweg, T. Wolf, V. H. S. Wu, Y.
  Xing, D. Xu, Z. Xu, M. Yamashita, L. Yang, J. Ye, L. Yuan, G. Zavattini, M.
  Zhong, T. Zhu","First Dark Matter Search with Nuclear Recoils from the XENONnT
  Experiment","Limit points are included in the submission file",,,,"hep-ex astro-ph.CO astro-ph.IM hep-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We report on the first search for nuclear recoils from dark matter in the
form of weakly interacting massive particles (WIMPs) with the XENONnT
experiment which is based on a two-phase time projection chamber with a
sensitive liquid xenon mass of $5.9$~t. During the approximately 1.1 tonne-year
exposure used for this search, the intrinsic $^{85}$Kr and $^{222}$Rn
concentrations in the liquid target were reduced to unprecedentedly low levels,
giving an electronic recoil background rate of
$(15.8\pm1.3)~\mathrm{events}/(\mathrm{t\cdot y \cdot keV})$ in the region of
interest. A blind analysis of nuclear recoil events with energies between
$3.3$~keV and $60.5$~keV finds no significant excess. This leads to a minimum
upper limit on the spin-independent WIMP-nucleon cross section of $2.58\times
10^{-47}~\mathrm{cm}^2$ for a WIMP mass of $28~\mathrm{GeV}/c^2$ at $90\%$
confidence level. Limits for spin-dependent interactions are also provided.
Both the limit and the sensitivity for the full range of WIMP masses analyzed
here improve on previous results obtained with the XENON1T experiment for the
same exposure.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:13:02 GMT""}]","2023-03-28"
"2303.14730","Xuelin Qian","Xuelin Qian, Yikai Wang, Yanwei Fu, Xinwei Sun, Xiangyang Xue,
  Jianfeng Feng","Joint fMRI Decoding and Encoding with Latent Embedding Alignment","12 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The connection between brain activity and corresponding visual stimuli is
crucial in comprehending the human brain. While deep generative models have
exhibited advancement in recovering brain recordings by generating images
conditioned on fMRI signals, accomplishing high-quality generation with
consistent semantics continues to pose challenges. Moreover, the prediction of
brain activity from visual stimuli remains a formidable undertaking. In this
paper, we introduce a unified framework that addresses both fMRI decoding and
encoding. Commencing with the establishment of two latent spaces capable of
representing and reconstructing fMRI signals and visual images, respectively,
we proceed to align the fMRI signals and visual images within the latent space,
thereby enabling a bidirectional transformation between the two domains. Our
Latent Embedding Alignment (LEA) model concurrently recovers visual stimuli
from fMRI signals and predicts brain activity from images within a unified
framework. The performance of LEA surpasses that of existing methods on
multiple benchmark fMRI decoding and encoding datasets. By integrating fMRI
decoding and encoding, LEA offers a comprehensive solution for modeling the
intricate relationship between brain activity and visual stimuli.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:14:58 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 02:22:18 GMT""}]","2023-06-06"
"2303.14731","Mrinal Kanti Roychowdhury","Amit Priyadarshi, Mrinal K. Roychowdhury, Manuj Verma","Quantization dimension for inhomogeneous bi-Lipschitz IFS",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  Let $\nu$ be a Borel probability measure on a $d$-dimensional Euclidean space
$\mathbb{R}^d$, $d\geq 1$, with a compact support, and let $(p_0, p_1, p_2,
\ldots, p_N)$ be a probability vector with $p_j>0$ for $1\leq j\leq N$. Let
$\{S_j: 1\leq j\leq N\}$ be a set of contractive mappings on $\mathbb R^d$.
Then, a Borel probability measure $\mu$ on $\mathbb R^d$ such that
$\mu=\sum_{j=1}^N p_j\mu\circ S_j^{-1}+p_0\nu$ is called an inhomogeneous
measure, also known as a condensation measure on $\mathbb R^d$. For a given
$r\in (0, +\infty)$, the quantization dimension of order $r$, if it exists,
denoted by $D_r(\mu)$, of a Borel probability measure $\mu$ on $\mathbb R^d$
represents the speed at which the $n$th quantization error of order $r$
approaches to zero as the number of elements $n$ in an optimal set of $n$-means
for $\mu$ tends to infinity. In this paper, we investigate the quantization
dimension for such a condensation measure.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:22:15 GMT""}]","2023-03-28"
"2303.14732","Minsu Park","Minsu Park, Suman Kalyan Maity, Stefan Wuchty, Dashun Wang","Interdisciplinary Papers Supported by Disciplinary Grants Garner Deep
  and Broad Scientific Impact",,,,,"cs.DL cs.SI econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Interdisciplinary research has emerged as a hotbed for innovation and
discoveries. The increasing dominance of grant-supported research, combined
with growing interest in funding interdisciplinary work, raises fundamental
questions on the role of interdisciplinary grants in supporting high-impact
interdisciplinary advances. Here we develop a measurement framework to quantify
the interdisciplinarity of both research grants and publications and apply it
to 350K grants from 164 funding agencies over 26 countries and 1.3M papers that
acknowledged the support of these grants from 1985 to 2009. Our analysis
uncovers two contradictory patterns. On the one hand, interdisciplinary grants
tend to produce interdisciplinary papers and interdisciplinary papers are
associated with high impact. On the other hand, compared to their disciplinary
counterparts, interdisciplinary grants produce much fewer papers and
interdisciplinary papers that they support have substantially reduced impact.
We show that the key to resolving this discrepancy lies in the power of
disciplinary grants: Highly interdisciplinary papers supported by deeply
disciplinary grants garner disproportionately high impacts from both core
disciplines and broader fields. Further, the broad and deep impacts of
disciplinary grants are not simply due to funding size, reception of ideas
within disciplinary boundaries, or collaborative formats. When it comes to
producing key interdisciplinary advances, disciplinary grants appear to do more
with less and seem especially powerful when paired with other similar
disciplinary grants. Amidst the rapid rise of support for interdisciplinary
work across the sciences, these results highlight the underexplored role of
disciplinary grants in driving crucial interdisciplinary advances, suggesting
that interdisciplinary research is a risky endeavor and requires deep
disciplinary expertise and investments.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:27:13 GMT""}]","2023-03-28"
"2303.14733","Hoang Minh Trinh","Nhat-Minh Le-Phan, Minh Hoang Trinh, Phuoc Doan Nguyen","Randomized Matrix Weighted Consensus","10 pages, 2 figures, preprint",,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by/4.0/","  In this paper, a randomized gossip-type matrix-weighted consensus algorithm
is proposed for both leaderless and leader-follower topologies. Under some mild
assumptions, the proposed pairwise asynchronous update algorithm achieves a
consensus in expectation. Moreover, the probability distribution, the weighting
matrices, and the updating step size jointly determine the upper bound of the
$\epsilon$-convergence time of the algorithm. The theoretical result is
verified by several simulation examples.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:28:43 GMT""}]","2023-03-28"
"2303.14734","Paolo Bonetti","Paolo Bonetti, Alberto Maria Metelli, Marcello Restelli","Interpretable Linear Dimensionality Reduction based on Bias-Variance
  Analysis",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  One of the central issues of several machine learning applications on real
data is the choice of the input features. Ideally, the designer should select
only the relevant, non-redundant features to preserve the complete information
contained in the original dataset, with little collinearity among features and
a smaller dimension. This procedure helps mitigate problems like overfitting
and the curse of dimensionality, which arise when dealing with high-dimensional
problems. On the other hand, it is not desirable to simply discard some
features, since they may still contain information that can be exploited to
improve results. Instead, dimensionality reduction techniques are designed to
limit the number of features in a dataset by projecting them into a
lower-dimensional space, possibly considering all the original features.
However, the projected features resulting from the application of
dimensionality reduction techniques are usually difficult to interpret. In this
paper, we seek to design a principled dimensionality reduction approach that
maintains the interpretability of the resulting features. Specifically, we
propose a bias-variance analysis for linear models and we leverage these
theoretical results to design an algorithm, Linear Correlated Features
Aggregation (LinCFA), which aggregates groups of continuous features with their
average if their correlation is ""sufficiently large"". In this way, all features
are considered, the dimensionality is reduced and the interpretability is
preserved. Finally, we provide numerical validations of the proposed algorithm
both on synthetic datasets to confirm the theoretical results and on real
datasets to show some promising applications.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:30:38 GMT""}]","2023-03-28"
"2303.14735","Thomas Kruse","Matthias Ehrhardt and Thomas Kruse and Antoine Tordeux","The Collective Dynamics of a Stochastic Port-Hamiltonian Self-Driven
  Agent Model in One Dimension",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The collective motion of self-driven agents is a phenomenon of great interest
in interacting particle systems. In this paper, we develop and analyze a model
of agent motion in one dimension with periodic boundaries using a stochastic
port-Hamiltonian system (PHS). The interaction model is symmetric and based on
nearest neighbors. The distance-based terms and kinematic relations correspond
to the skew-symmetric Hamiltonian structure of the PHS, while the velocity
difference terms make the system dissipative. The originality of the approaches
lies in the stochastic noise that plays the role of an external input. It turns
out that the stochastic PHS with a quadratic potential is an Ornstein-Uhlenbeck
process, for which we explicitly determine the distribution for any time $t\ge
0$ and in the limit $t\to\infty$.
  We characterize the collective motion by showing that the agents' mean
velocity is Brownian noise whose fluctuations increase with time, while the
variance of the agents' velocities and distances, which quantify the
coordination of the agents' motion, converge. The motion model does not specify
a preferred direction of motion. However, assuming a equilibrium uniform
starting configuration, the results show that the noise triggers rapidly
coordinated agent motion determined by the Brownian behavior of the mean
velocity. Interestingly, simulation results show that some theoretical
properties obtained with the Ornstein-Uhlenbeck process also hold for the
nonlinear model with general interaction potential.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:31:50 GMT""}]","2023-03-28"
"2303.14736","Shuangping Huang","Gang Dai, Yifan Zhang, Qingfeng Wang, Qing Du, Zhuliang Yu, Zhuoman
  Liu, Shuangping Huang","Disentangling Writer and Character Styles for Handwriting Generation","accepted by CVPR 2023. Source code: https://github.com/dailenson/SDT",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training machines to synthesize diverse handwritings is an intriguing task.
Recently, RNN-based methods have been proposed to generate stylized online
Chinese characters. However, these methods mainly focus on capturing a person's
overall writing style, neglecting subtle style inconsistencies between
characters written by the same person. For example, while a person's
handwriting typically exhibits general uniformity (e.g., glyph slant and aspect
ratios), there are still small style variations in finer details (e.g., stroke
length and curvature) of characters. In light of this, we propose to
disentangle the style representations at both writer and character levels from
individual handwritings to synthesize realistic stylized online handwritten
characters. Specifically, we present the style-disentangled Transformer (SDT),
which employs two complementary contrastive objectives to extract the style
commonalities of reference samples and capture the detailed style patterns of
each sample, respectively. Extensive experiments on various language scripts
demonstrate the effectiveness of SDT. Notably, our empirical findings reveal
that the two learned style representations provide information at different
frequency magnitudes, underscoring the importance of separate style extraction.
Our source code is public at: https://github.com/dailenson/SDT.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:32:02 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 13:36:44 GMT""}]","2023-04-03"
"2303.14737","Mark Petersen","Mark Petersen, Russ Tedrake","Growing Convex Collision-Free Regions in Configuration Space using
  Nonlinear Programming",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  One of the most difficult parts of motion planning in configuration space is
ensuring a trajectory does not collide with task-space obstacles in the
environment. Generating regions that are convex and collision free in
configuration space can separate the computational burden of collision checking
from motion planning. To that end, we propose an extension to IRIS (Iterative
Regional Inflation by Semidefinite programming) [5] that allows it to operate
in configuration space. Our algorithm, IRIS-NP (Iterative Regional Inflation by
Semidefinite & Nonlinear Programming), uses nonlinear optimization to add the
separating hyperplanes, enabling support for more general nonlinear
constraints. Developed in parallel to Amice et al. [1], IRIS-NP trades rigorous
certification that regions are collision free for probabilistic certification
and the benefit of faster region generation in the configuration-space
coordinates. IRIS-NP also provides a solid initialization to C-IRIS to reduce
the number of iterations required for certification. We demonstrate that
IRIS-NP can scale to a dual-arm manipulator and can handle additional nonlinear
constraints using the same machinery. Finally, we show ablations of elements of
our implementation to demonstrate their importance.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:37:06 GMT""}]","2023-03-28"
"2303.14738","Belal Alsinglawi","Inoj Neupane, Belal Alsinglawi, Khaled Rabie","Indoor Positioning using Wi-Fi and Machine Learning for Industry 5.0",,,,,"cs.RO cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Humans and robots working together in an environment to enhance human
performance is the aim of Industry 5.0. Although significant progress in
outdoor positioning has been seen, indoor positioning remains a challenge. In
this paper, we introduce a new research concept by exploiting the potential of
indoor positioning for Industry 5.0. We use Wi-Fi Received Signal Strength
Indicator (RSSI) with trilateration using cheap and easily available ESP32
Arduino boards for positioning as well as sending effective route signals to a
human and a robot working in a simulated-indoor factory environment in
real-time. We utilized machine learning models to detect safe closeness between
two co-workers (a human subject and a robot). Experimental data and analysis
show an average deviation of less than 1m from the actual distance while the
targets are mobile or stationary.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:37:08 GMT""}]","2023-03-28"
"2303.14739","Zhentao Liu","Zhentao Liu, Yu Fang, Changjian Li, Han Wu, Yuan Liu, Zhiming Cui,
  Dinggang Shen","Geometry-Aware Attenuation Field Learning for Sparse-View CBCT
  Reconstruction",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cone Beam Computed Tomography (CBCT) is the most widely used imaging method
in dentistry. As hundreds of X-ray projections are needed to reconstruct a
high-quality CBCT image (i.e., the attenuation field) in traditional
algorithms, sparse-view CBCT reconstruction has become a main focus to reduce
radiation dose. Several attempts have been made to solve it while still
suffering from insufficient data or poor generalization ability for novel
patients. This paper proposes a novel attenuation field encoder-decoder
framework by first encoding the volumetric feature from multi-view X-ray
projections, then decoding it into the desired attenuation field. The key
insight is when building the volumetric feature, we comply with the multi-view
CBCT reconstruction nature and emphasize the view consistency property by
geometry-aware spatial feature querying and adaptive feature fusing. Moreover,
the prior knowledge information learned from data population guarantees our
generalization ability when dealing with sparse view input. Comprehensive
evaluations have demonstrated the superiority in terms of reconstruction
quality, and the downstream application further validates the feasibility of
our method in real-world clinics.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:38:42 GMT""}]","2023-03-28"
"2303.14740","Saikat Das","Saikat Das and Suparna Roychowdhury","Chaotic dynamics of off-equatorial orbits around Pseudo-Newtonian
  Schwarzschild and Kerr-like compact objects surrounded by dipolar halo","17 pages, 14 figures",,,,"gr-qc astro-ph.HE nlin.CD","http://creativecommons.org/licenses/by/4.0/","  In this paper, we implement a generalized pseudo-Newtonian potential and
prescribe a numerical fitting formalism, to study the off-equatorial orbits
inclined at a certain angle with the equatorial plane around both Schwarzschild
and Kerr-like compact object primaries surrounded by a dipolar halo of matter.
The chaotic dynamics of the orbits are detailed for both non-relativistic and
special-relativistic test particles. The dependence of the degree of chaos on
the rotation parameter $a$ and the inclination angle $i$ is established
individually using widely used indicators, such as the Poincar\'e Map and the
Lyapunov Characteristic Number. We find that although the chaoticity of the
orbits has a positive correlation with $i$, the growth in the chaotic behaviour
is not systematic. There exists a threshold value of the inclination angle
$i_{\text{c}}$, after which the degree of chaos shows a sharp increase. On the
other hand, the chaoticity of the inclined orbits anti-correlates with $a$ at
the lower inclination angles. At higher values of $i$, the degree of chaos is
maximum for the maximally counter-rotating compact objects, though it has a
weak negative, sometimes positive, correlation with $a$ at its higher values.
The studies performed with several initial conditions and orbital parameters
reveal the intricate nature of the system.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:45:59 GMT""}]","2023-03-28"
"2303.14741","J\""urg Fr\""ohlich","J\""urg Fr\""ohlich","Gauge Invariance and Anomalies in Condensed Matter Physics","4 figures, 42 pages; will appear in 'Journal of Mathematical Physics'
  (AIP publishing)","JMP22-AR-MATP2022-01853","10.1063/5.0135142",,"cond-mat.str-el math-ph math.MP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper begins with a summary of a powerful formalism for the study of
electronic states in condensed matter physics called ""Gauge Theory of
States/Phases of Matter."" The chiral anomaly, which plays quite a prominent
role in that formalism, is recalled. I then sketch an application of the chiral
anomaly in 1+1 dimensions to quantum wires. Subsequently, some elements of the
quantum Hall effect in two-dimensional (2D) gapped (""incompressible"") electron
liquids are reviewed. In particular, I discuss the role of anomalous chiral
edge currents and of anomaly inflow in 2D gapped electron liquids with
explicitly or spontaneously broken time reversal, i.e., in Hall- and Chern
insulators. The topological Chern-Simons action yielding the transport
equations valid in the bulk of such systems and the associated anomalous edge
action are derived. The results of a general classification of ""abelian"" Hall
insulators are outlined. After some remarks on induced Chern-Simons actions, I
sketch results on certain 2D chiral photonic wave guides. I then continue with
an analysis of chiral edge spin-currents and the bulk response equations in
time-reversal invariant 2D topological insulators of electron gases with
spin-orbit interactions. The ""chiral magnetic effect"" in 3D systems and
axion-electrodynamics are reviewed next. This prepares the ground for an
outline of a general theory of 3D topological insulators, including ""axionic
insulators"". Some remarks on Weyl semi-metals, which exhibit the chiral
magnetic effect, and on Mott transitions in 3D systems with dynamical
axion-like degrees of freedom conclude this review.}
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:47:47 GMT""}]","2023-04-12"
"2303.14742","Baochang Ma","Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Lei Zhang,
  Baochang Ma, Xiangang Li","Exploring the Impact of Instruction Data Scaling on Large Language
  Models: An Empirical Study on Real-World Use Cases",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The success of ChatGPT has recently attracted numerous efforts to replicate
it, with instruction-tuning strategies being a key factor in achieving
remarkable results. Instruction-tuning not only significantly enhances the
model's performance and generalization but also makes the model's generated
results more consistent with human speech patterns. However current research
rarely studies the impact of different amounts of instruction data on model
performance, especially in the real-world use cases. In this paper we explore
the performance of large language models based on instruction tuning across
different scales of instruction data. An evaluation dataset consisting of 12
major online use cases is constructed in the experiment. With Bloomz-7B1-mt as
the base model, the results show that 1) merely increasing the amount of
instruction data leads to continuous improvement in tasks such as open-ended
generation, 2) in tasks such as math and code, the model performance curve
remains quite flat while increasing data size. We further analyze the possible
causes of these phenomena and propose potential future research directions such
as effectively selecting high-quality training data, scaling base models and
training methods specialized for hard tasks. We will release our training and
evaluation datasets, as well as model checkpoints.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:49:37 GMT""}]","2023-03-28"
"2303.14743","Luisa Beghin","Luisa Beghin, Lorenzo Cristofaro, Roberto Garrappa","Renewal processes linked to fractional relaxation equations with
  variable order","15 pages, 4 fig",,,,"math.PR math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and study here a renewal process defined by means of a
time-fractional relaxation equation with derivative order $\alpha(t)$ varying
with time $t\geq0$. In particular, we use the operator introduced by Scarpi in
the Seventies and later reformulated in the regularized Caputo sense in
Garrappa et al. (2021), inside the framework of the so-called general
fractional calculus. The model obtained extends the well-known time-fractional
Poisson process of fixed order $\alpha \in (0,1)$ and tries to overcome its
limitation consisting in the constancy of the derivative order (and therefore
of the memory degree of the interarrival times) with respect to time. The
variable order renewal process is proved to fall outside the usual subordinated
representation, since it can not be simply defined as a Poisson process with
random time (as happens in the standard fractional case). Finally a related
continuous-time random walk model is analysed and its limiting behavior
established.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:50:10 GMT""}]","2023-03-28"
"2303.14744","Kuniaki Saito","Kuniaki Saito, Donghyun Kim, Piotr Teterwak, Rogerio Feris, Kate
  Saenko","Mind the Backbone: Minimizing Backbone Distortion for Robust Object
  Detection","Project page: http://ai.bu.edu/mind_back/",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Building object detectors that are robust to domain shifts is critical for
real-world applications. Prior approaches fine-tune a pre-trained backbone and
risk overfitting it to in-distribution (ID) data and distorting features useful
for out-of-distribution (OOD) generalization. We propose to use Relative
Gradient Norm (RGN) as a way to measure the vulnerability of a backbone to
feature distortion, and show that high RGN is indeed correlated with lower OOD
performance. Our analysis of RGN yields interesting findings: some backbones
lose OOD robustness during fine-tuning, but others gain robustness because
their architecture prevents the parameters from changing too much from the
initial model. Given these findings, we present recipes to boost OOD robustness
for both types of backbones. Specifically, we investigate regularization and
architectural choices for minimizing gradient updates so as to prevent the
tuned backbone from losing generalizable features. Our proposed techniques
complement each other and show substantial improvements over baselines on
diverse architectures and datasets. Code is available at
https://github.com/VisionLearningGroup/mind_back.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:50:43 GMT""},{""version"":""v2"",""created"":""Mon, 15 May 2023 18:52:42 GMT""}]","2023-05-17"
"2303.14745","Una Pale","Una Pale, Tomas Teijeiro, David Atienza","Combining General and Personalized Models for Epilepsy Detection with
  Hyperdimensional Computing",,,,,"cs.NE cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Epilepsy is a chronic neurological disorder with a significant prevalence.
However, there is still no adequate technological support to enable epilepsy
detection and continuous outpatient monitoring in everyday life.
Hyperdimensional (HD) computing is an interesting alternative for wearable
devices, characterized by a much simpler learning process and also lower memory
requirements. In this work, we demonstrate a few additional aspects in which HD
computing, and the way its models are built and stored, can be used for further
understanding, comparing, and creating more advanced machine learning models
for epilepsy detection. These possibilities are not feasible with other
state-of-the-art models, such as random forests or neural networks. We compare
inter-subject similarity of models per different classes (seizure and
non-seizure), then study the process of creation of generalized models from
personalized ones, and in the end, how to combine personalized and generalized
models to create hybrid models. This results in improved epilepsy detection
performance. We also tested knowledge transfer between models created on two
different datasets. Finally, all those examples could be highly interesting not
only from an engineering perspective to create better models for wearables, but
also from a neurological perspective to better understand individual epilepsy
patterns.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:51:25 GMT""}]","2023-03-28"
"2303.14746","Xian-Li Yin","Xian-Li Yin, Jie-Qiao Liao","Giant-atom entanglement in waveguide-QED systems including non-Markovian
  effect","12 pages,5 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the generation of quantum entanglement between two giant atoms
coupled to a common one-dimensional waveguide. Here each giant atom interacts
with the waveguide at two separate coupling points. Within the Wigner-Weisskopf
framework for single coupling points, we obtain the time-delayed quantum master
equations governing the evolution of the two giant atoms for three different
coupling configurations: separated, braided, and nested couplings. For each
coupling configuration, we consider both the Markovian and non-Markovian
entanglement dynamics of the giant atoms, which are initially in two different
separable states: single- and double-excitation states. Our results show that
the generated entanglement depends on the phase shift, time delay, atomic
initial state, and the coupling configuration. For the single-excitation
initial state, there exists the steady-state entanglement for each coupling in
both the Markovian and non-Markovian regimes due to the appearance of the dark
state. For the double-excitation initial state, we observe entanglement sudden
birth via adjusting the phase shift in both regimes. In particular, the
maximally achievable entanglement for the nested coupling is about one order of
magnitude larger than those of separate and braided couplings. We also find
that the maximal entanglement for these three coupling configurations can be
enhanced in the case of small time delays. This work can be utilized for the
generation and control of entanglement in quantum networks based on giant-atom
waveguide-QED systems, which have wide potential applications in quantum
information processing.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:56:52 GMT""}]","2023-03-28"
"2303.14747","Xiaolong Shen","Xiaolong Shen, Zongxin Yang, Xiaohan Wang, Jianxin Ma, Chang Zhou, Yi
  Yang","Global-to-Local Modeling for Video-based 3D Human Pose and Shape
  Estimation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video-based 3D human pose and shape estimations are evaluated by intra-frame
accuracy and inter-frame smoothness. Although these two metrics are responsible
for different ranges of temporal consistency, existing state-of-the-art methods
treat them as a unified problem and use monotonous modeling structures (e.g.,
RNN or attention-based block) to design their networks. However, using a single
kind of modeling structure is difficult to balance the learning of short-term
and long-term temporal correlations, and may bias the network to one of them,
leading to undesirable predictions like global location shift, temporal
inconsistency, and insufficient local details. To solve these problems, we
propose to structurally decouple the modeling of long-term and short-term
correlations in an end-to-end framework, Global-to-Local Transformer (GLoT).
First, a global transformer is introduced with a Masked Pose and Shape
Estimation strategy for long-term modeling. The strategy stimulates the global
transformer to learn more inter-frame correlations by randomly masking the
features of several frames. Second, a local transformer is responsible for
exploiting local details on the human mesh and interacting with the global
transformer by leveraging cross-attention. Moreover, a Hierarchical Spatial
Correlation Regressor is further introduced to refine intra-frame estimations
by decoupled global-local representation and implicit kinematic constraints.
Our GLoT surpasses previous state-of-the-art methods with the lowest model
parameters on popular benchmarks, i.e., 3DPW, MPI-INF-3DHP, and Human3.6M.
Codes are available at https://github.com/sxl142/GLoT.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 14:57:49 GMT""}]","2023-03-28"
"2303.14748","Yuying Zhao","Xiaojie Wang, Yuying Zhao, and Zhongqiang Zhang","Weak error analysis for strong approximation schemes of SDEs with
  super-linear coefficients","This should be the replacement of the arxiv article 2112.15102 but
  not a new submission.",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We present an error analysis of weak convergence of one-step numerical
schemes for stochastic differential equations (SDEs) with super-linearly
growing coefficients. Following Milstein's weak error analysis on the one-step
approximation of SDEs, we prove a general conclusion on weak convergence of the
one-step discretization of the SDEs mentioned above. As applications, we show
the weak convergence rates for several numerical schemes of half-order strong
convergence, such as tamed and balanced schemes. Numerical examples are
presented to verify our theoretical analysis.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:00:22 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 16:05:16 GMT""}]","2023-03-29"
"2303.14749","Pasha Zusmanovich","Pasha Zusmanovich","A variant of Baer's theorem","3 pages; to appear in Rocky Mountain Journal of Mathematics",,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  We provide a variant of Baer's theorem about isomorphism of endomorphism
rings of vector spaces over division rings, where the full endomorphism rings
are replaced by some subrings of finitary maps.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:02:23 GMT""}]","2023-03-28"
"2303.14750","Nelson Rosa Jr.","Nelson Rosa, Bassel Katamish, Maximilian Raff, C. David Remy","An Approach for Generating Families of Energetically Optimal Gaits from
  Passive Dynamic Walking Gaits","Code available, see
  https://github.com/nr-codes/OptimalGaitsForCompassGait",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a class of biped robots with impulsive dynamics and a non-empty set of
passive gaits (unactuated, periodic motions of the biped model), we present a
method for computing continuous families of locally optimal gaits with respect
to a class of commonly used energetic cost functions (e.g., the integral of
torque-squared). We compute these families using only the passive gaits of the
biped, which are globally optimal gaits with respect to these cost functions.
Our approach fills in an important gap in the literature when computing a
library of locally optimal gaits, which often do not make use of these globally
optimal solutions as seed values. We demonstrate our approach on a well-studied
two-link biped model.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:07:22 GMT""}]","2023-03-28"
"2303.14751","Hoang Minh Trinh","Minh Hoang Trinh, Hoang Huy Vu, Nhat-Minh Le-Phan, Quyen Ngoc Nguyen","Matrix-Scaled Consensus over Undirected Networks","12 pages, 5 figures, preprint",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose matrix-scaled consensus algorithms for linear
dynamical agents interacted over an undirected network. The goal of these
algorithms is making the matrix-scaled state vectors of all agents to
asymptotically agree. Algebraic properties of the matrix-scaled Laplacian are
firstly examined. Second, we propose matrix-scaled consensus algorithms for
networks of single integrators with or without constant parametric
uncertainties. Third, observer-based matrix-scaled synchronization algorithms
for networks of homogeneous or heterogeneous linear agents are proposed. The
effectiveness of each proposed algorithm is asserted by rigorous analysis and
supported by numerical simulations.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:08:58 GMT""}]","2023-03-28"
"2303.14752","Haolin Zou","Victor de la Pena, Henryk Gzyl, Silvia Mayoral, Haolin Zou and
  Demissie Alemayehu","Prediction and estimation of random variables with infinite mean or
  variance",,,,,"math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose an optimal predictor of a random variable that has
either an infinite mean or an infinite variance. The method consists of
transforming the random variable such that the transformed variable has a
finite mean and finite variance. The proposed predictor is a generalized
arithmetic mean which is similar to the notion of certainty price in utility
theory. Typically, the transformation consists of a parametric family of
bijections, in which case the parameter might be chosen to minimize the
prediction error in the transformed coordinates. The statistical properties of
the estimator of the proposed predictor are studied, and confidence intervals
are provided. The performance of the procedure is illustrated using simulated
and real data.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:09:51 GMT""}]","2023-03-28"
"2303.14753","Andreas Kirsch","Andreas Kirsch","Does ""Deep Learning on a Data Diet"" reproduce? Overall yes, but GraNd at
  Initialization does not","5 pages",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  The paper 'Deep Learning on a Data Diet' by Paul et al. (2021) introduces two
innovative metrics for pruning datasets during the training of neural networks.
While we are able to replicate the results for the EL2N score at epoch 20, the
same cannot be said for the GraNd score at initialization. The GraNd scores
later in training provide useful pruning signals, however. The GraNd score at
initialization calculates the average gradient norm of an input sample across
multiple randomly initialized models before any training has taken place. Our
analysis reveals a strong correlation between the GraNd score at initialization
and the input norm of a sample, suggesting that the latter could have been a
cheap new baseline for data pruning. Unfortunately, neither the GraNd score at
initialization nor the input norm surpasses random pruning in performance. This
contradicts one of the findings in Paul et al. (2021). We were unable to
reproduce their CIFAR-10 results using both an updated version of the original
JAX repository and in a newly implemented PyTorch codebase. An investigation of
the underlying JAX/FLAX code from 2021 surfaced a bug in the checkpoint
restoring code that was fixed in April 2021
(https://github.com/google/flax/commit/28fbd95500f4bf2f9924d2560062fa50e919b1a5).
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:13:19 GMT""}]","2023-04-03"
"2303.14754","Iosif Petrakis","Iosif Petrakis","Categories with dependent arrows","20 pages",,,,"math.CT math.LO","http://creativecommons.org/licenses/by/4.0/","  We present an abstract, categorical formulation of dependent functions in a
fundamental manner and independently from the Sigma-construction. For that, we
define first the notion of a category with family-arrows, or a $\f$-category. A
$(\f, \Sigma)$-category is a $\f$-category with Sigma-objects, where a $(\f,
\Sigma)$-category with a terminal object is exactly a type-category of Pitts,
or a category with attributes of Cartmell. We introduce categories with
dependent arrows, or $\di$-categories, and we show that every $(\f,
\Sigma)$-category is a $\di$-category in a canonical way. The notion of a
Sigma-object in a $\di$-Category is affected by the existence of dependent
arrows, and we show that every $(\f, \Sigma)$-category is a $(\di,
\Sigma)$-category in a canonical way.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:18:02 GMT""}]","2023-03-28"
"2303.14755","J. G. Cardoso","J. G. Cardoso","A Torsional Two-Component Description of the Motion of Dirac Particles
  at Early Stages of the Cosmic Evolution","The third phrase of Section 1, as well as the footnote 4, have been
  slightly modified",,,,"gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is assumed that the non-singular big-bang birth of the Universe as set
forth by Einstein-Cartan's theory particularly brought about the appearance of
the cosmic microwave and dark energy backgrounds, dark matter, gravitons as
well as of Dirac particles. On account of this assumption, a two-component
description of the motion of quarks and leptons prior to the occurrence of
hadronization is presented within the framework of the torsionful
{\epsilon}-formalism of Infeld and van der Waerden. The relevant field
equations are settled on the basis of the implementation of conjugate minimal
coupling covariant derivative operators that carry additively typical
potentials for the cosmic backgrounds such as geometrically specified in a
previous work. It appears that the derivation of the wave equations which
control the spacetime propagation of Dirac fields at very early stages of the
cosmic evolution, must be tied up with the applicability of certain subsidiary
relations. The wave equations themselves suggest that quarks and leptons
interact not only with both of the cosmic backgrounds, but also with dark
matter. Nevertheless, it becomes manifest that the inner structure of the
framework allowed for does not give rise at all to any interaction between
gravitons and Dirac particles. The overall formulation ascribes an
intrinsically non-geometric character to Dirac's theory, in addition to
exhibiting a formal evidence that dark energy and dark matter must have
partaken of a cosmic process of hadronization.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:19:50 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 15:59:20 GMT""}]","2023-03-30"
"2303.14756","Petya Nedkova","Valentin Deliyski, Galin Gyulchev, Petya Nedkova, Stoytcho Yazadjiev","Polarized image of equatorial emission in horizonless spacetimes: naked
  singularities","27 pages, 10 figures",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We study the linear polarization from the accretion disk around weakly and
strongly naked Janis-Newman-Winicour singularities. We consider an analytical
toy model of thin magnetized fluid ring orbiting in the equatorial plane and
emitting synchrotron radiation. The observable polarized images are calculated
and compared to the Schwarzschild black hole for physical parameters compatible
with the radio source M87. For small inclination angles the direct images of
the weakly naked singularities closely mimic the Schwarzschild black hole. The
deviation in the polarization properties increases if we consider larger
inclination angles or higher order images as for indirect images the
polarization intensity grows several times in magnitude compared to black
holes. Strongly naked singularities produce significant observational
signatures already in the direct images. They create a second image of the
fluid ring with times larger polarization intensity and characteristic twist of
the polarization direction. Due to this additional structure they can be
distinguished in polarimetric experiments.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:20:59 GMT""}]","2023-03-28"
"2303.14757","Dmitry Artamonov","D.V. Artamonov","Models of representations for classical series of Lie algebras","37 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A model of representations of a Lie algebra is a representation which a
direct sum of all irreducible finite dimensional representations taken with
multiplicity $1$. In the paper an explicit construction of a model of
representation for all series of classical Lie algebras is given. The
construction does not differ much for different series. The space of the model
is constructed as a space of polynomial solutions of a system of partial
differential equations. The equations in this system are constructed form
relations between minors of matrices from the corresponding Lie group. This
system has a simplification which is very close to the GKZ system, that is
satisfied by $A$-hypergeometric functions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:21:12 GMT""}]","2023-03-28"
"2303.14758","Asma Jodeiri Akbarfam","Asma Jodeiri Akbarfam, Sina Barazandeh, Hoda Maleki, Deepti Gupta","DLACB: Deep Learning Based Access Control Using Blockchain",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In general, deep learning models use to make informed decisions immensely.
Developed models are mainly based on centralized servers, which face several
issues, including transparency, traceability, reliability, security, and
privacy. In this research, we identify a research gap in a distributed
nature-based access control that can solve those issues. The innovative
technology blockchain could fill this gap and provide a robust solution.
Blockchain's immutable and distributed nature designs a useful framework in
various domains such as medicine, finance, and government, which can also
provide access control as opposed to centralized methods that rely on trusted
third parties to access the resources. In existing frameworks, a traditional
access control approach is developed using blockchain, which depends on
predefined policies and permissions that are not reliable. In this research, we
propose DLACB: Deep Learning Based Access Control Using Blockchain, which
utilizes a deep learning access control mechanism to determine a user's
permissions on a given resource. This proposed framework authenticates the
users and logs the access requests on the blockchain to recognize malicious
users. The results show that this proposed framework operates correctly for all
possible scenarios.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:25:09 GMT""}]","2023-03-28"
"2303.14759","Max Reinhold Jahnke","Max Reinhold Jahnke","Closed elliptic structures on compact semisimple Lie groups","12 pages; comments are welcome",,,,"math.DG math.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we prove that, under a topological condition, the cohomology
associated with left-invariant elliptic structures on compact semisimple Lie
groups can be computed using only left-invariant forms. This reduces the
analytical problem to a purely algebraic one, while also providing a
generalization of the classic works of Chevalley and Eilenberg [CE48] on the de
Rham cohomology of compact Lie groups and of Pittie [Pit88] on the Dolbeault
cohomology of compact semisimple Lie groups to the context of elliptic
structures. We use spectral sequences as our primary tool, which facilitates
the construction of an isomorphism between the left-invariant differential
complex and the usual differential complex.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:40:59 GMT""}]","2023-03-28"
"2303.14760","Daniel Speckhard","Daniel T. Speckhard, Christian Carbogno, Luca Ghiringhelli, Sven
  Lubeck, Matthias Scheffler, Claudia Draxl","Extrapolation to complete basis-set limit in density-functional theory
  by quantile random-forest models",,,,,"physics.comp-ph cond-mat.mtrl-sci stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The numerical precision of density-functional-theory (DFT) calculations
depends on a variety of computational parameters, one of the most critical
being the basis-set size. The ultimate precision is reached with an infinitely
large basis set, i.e., in the limit of a complete basis set (CBS). Our aim in
this work is to find a machine-learning model that extrapolates finite
basis-size calculations to the CBS limit. We start with a data set of 63 binary
solids investigated with two all-electron DFT codes, exciting and FHI-aims,
which employ very different types of basis sets. A quantile-random-forest model
is used to estimate the total-energy correction with respect to a fully
converged calculation as a function of the basis-set size. The random-forest
model achieves a symmetric mean absolute percentage error of lower than 25% for
both codes and outperforms previous approaches in the literature. Our approach
also provides prediction intervals, which quantify the uncertainty of the
models' predictions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:43:37 GMT""},{""version"":""v2"",""created"":""Fri, 31 Mar 2023 19:44:06 GMT""},{""version"":""v3"",""created"":""Thu, 1 Jun 2023 12:22:51 GMT""}]","2023-06-02"
"2303.14761","Karol Kampf","Karol Kampf, Jiri Novotny, Jaroslav Trnka and Petr Vasko","Goldstone bosons on celestial sphere and conformal soft theorems","45 pages of the main text, 6 appendices and 6 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study celestial amplitudes of Goldstone bosons and
conformal soft theorems. Motivated by the success of soft bootstrap in momentum
space and the important role of the soft limit behavior of tree-level
amplitudes, our goal is to extend some of the methods to the celestial sphere.
The crucial ingredient of the calculation is the Mellin transformation which
transforms four-dimensional scattering amplitudes to correlation functions of
primary operators in the celestial CFT. The soft behavior of the amplitude is
then translated to the singularities of the correlator. Only for amplitudes in
""UV completed theories"" (with sufficiently good high energy behavior) the
Mellin integration can be properly performed, in all other cases, the celestial
amplitude is only defined in a distributional sense with delta functions. We
provide many examples of celestial amplitudes in UV-completed models including
linear sigma models and Z-theory, which is a certain completion of the SU(N)
non-linear sigma model. We also comment on the BCFW-like and soft recursion
relations for celestial amplitudes and the extension of soft bootstrap ideas.
45 pages of main text + 6 appendicess and 6 figures
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:45:24 GMT""}]","2023-03-28"
"2303.14762","Denys Gobov","Denys Gobov, Olga Solovei","Approaches to Improving the Accuracy of Machine Learning Models in
  Requirements Elicitation Techniques Selection",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Selecting techniques is a crucial element of the business analysis approach
planning in IT projects. Particular attention is paid to the choice of
techniques for requirements elicitation. One of the promising methods for
selecting techniques is using machine learning algorithms trained on the
practitioners' experience considering different projects' contexts. The
effectiveness of ML models is significantly affected by the balance of the
training dataset, which is violated in the case of popular techniques. The
paper aims to analyze the efficiency of the Synthetic Minority Over-sampling
Technique usage in Machine Learning models for elicitation technique selection
in case of the imbalanced training dataset and possible ways for positive
feature importance selection. The computational experiment results confirmed
the effectiveness of using the proposed approaches to improve the accuracy of
machine learning models for selecting requirements elicitation techniques.
Proposed approaches can be used to build Machine Learning models for business
analysis activities planning in IT projects.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:51:42 GMT""}]","2023-03-28"
"2303.14763","Tsuyoshi Miyatsu","Tsuyoshi Miyatsu, Myung-Ki Cheoun, Kyungsik Kim, Koichi Saito","Can the PREX-2 and CREX results be understood by relativistic mean-field
  models with the astrophysical constraints?","7 pages, 6 figures, 4 tables",,,,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  We construct new effective interactions using the relativistic mean-field
models with the isoscalar- and isovector-meson mixing,
$\sigma^{2}\bm{\delta}^{2}$ and
$\omega_{\mu}\omega^{\mu}\bm{\rho}_{\nu}\bm{\rho}^{\nu}$. Taking into account
the particle flow data in heavy-ion collisions, the observed mass of PSR
J0740$+$6620, and the tidal deformability of a neutron star from binary merger
events, GW170817 and GW190814, we study the ground-state properties of finite,
closed-shell nuclei, and try to explain the recent results from the PREX-2 and
CREX experiments. It is found that the $\sigma$--$\delta$ mixing is very
powerful to understand the terrestrial experiments and astrophysical
observations of neutron stars self-consistently. We can predict the large
neutron skin thickness of $^{208}$Pb, $R_{\rm skin}^{208}=0.243$~fm, using the
slope parameter of nuclear symmetry energy, $L=70$~MeV, which is consistent
with the PREX-2 result. However, to explain the CREX data, it is preferable to
adopt the small value of $L=20$~MeV. It is very difficult to understand the
PREX-2 and CREX results simultaneously within relativistic mean-field models.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:54:18 GMT""}]","2023-03-28"
"2303.14764","Xiangwei Yin","Wenxing Zhang, Tianjun Li, Xiangwei Yin","The $Z$ resonance, inelastic dark matter, and new physics anomalies in
  the Simple Extension of the Standard Model (SESM) with general scalar
  potential","22 pages, 6 figures, 5 tables",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the generic scalar potential with CP-violation, and study the $Z$
resonance and inelastic dark matter in the Simple Extension of the Standard
Model (SESM), which can explain the dark matter as well as new physics
anomalies such as the B physics anomalies and muon anomalous magnetic moment,
etc. With the new scalar potential terms, we obtain the mass splittings for the
real and imaginary parts of scalar fields. And thus we can have the DM
co-annihilation process mediated by $Z$ boson, which couples exclusively to the
CP-even and CP-odd parts of scalar fields. This is a brand new feature compared
to the previous study. For the CP conserving case, we present the viable
parameter space for the Higgs and $Z$ resonances, which can explain the B
physics anomalies, muon anomalous magnetic moment, and dark matter relic
density, as well as evade the constraint from the XENON1T direct detection
simultaneously. For the CP-violating case, we consider the inelastic dark
matter, and study four concrete scenarios for the inelastic DM-nucleon
scatterings mediated by the Higgs and $Z$ bosons in details. Also, we present
the benchmark points which satisfy the aforementioned constraints. Furthermore,
we investigate the constraints from the dark matter-electron inelastic
scattering processes mediated by the Higgs and $Z$ bosons in light of the
XENONnT data. We show that the constraint on the $Z$ mediated process is weak,
while the Higgs mediated process excludes the dark matter with mass around
several MeV.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:56:02 GMT""}]","2023-03-28"
"2303.14765","Benjamin Kenwright","Benjamin Kenwright","A Survey on Dual-Quaternions","arXiv admin note: text overlap with arXiv:2303.13395",,,,"math.OC cs.RO","http://creativecommons.org/licenses/by/4.0/","  Over the past few years, the applications of dual-quaternions have not only
developed in many different directions but has also evolved in exciting ways in
several areas. As dual-quaternions offer an efficient and compact symbolic form
with unique mathematical properties. While dual-quaternions are now common
place in many aspects of research and implementation, such as, robotics and
engineering through to computer graphics and animation, there are still a large
number of avenues for exploration with huge potential benefits. This article is
the first to provide a comprehensive review of the dual-quaternion landscape.
In this survey, we present a review of dual-quaternion techniques and
applications developed over the years while providing insights into current and
future directions. The article starts with the definition of dual-quaternions,
their mathematical formulation, while explaining key aspects of importance
(e.g., compression and ambiguities). The literature review in this article is
divided into categories to help manage and visualize the application of
dual-quaternions for solving specific problems. A timeline illustrating key
methods is presented, explaining how dual-quaternion approaches have progressed
over the years. The most popular dual-quaternion methods are discussed with
regard to their impact in the literature, performance, computational cost and
their real-world results (compared to associated models). Finally, we indicate
the limitations of dual-quaternion methodologies and propose future research
directions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 15:58:39 GMT""}]","2023-03-28"
"2303.15473","Simon Diemert","Simon Diemert, Jens H Weber","Can Large Language Models assist in Hazard Analysis?",,,,,"cs.HC cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable
natural language processing and generation capabilities and have been applied
to a variety tasks, such as source code generation. This paper explores the
potential of integrating LLMs in the hazard analysis for safety-critical
systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a
human analyst interacts with an LLM via a context-aware chat session and uses
the responses to support elicitation of possible hazard causes. In this
experiment, we explore CoHA with three increasingly complex versions of a
simple system, using Open AI's ChatGPT service. The quality of ChatGPT's
responses were systematically assessed to determine the feasibility of CoHA
given the current state of LLM technology. The results suggest that LLMs may be
useful for supporting human analysts performing hazard analysis.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 19:43:27 GMT""}]","2023-03-29"
"2303.15474","Jie Liu","Zhuoying Zhao, Ziling Tan, Pinghui Mo, Xiaonan Wang, Dan Zhao, Xin
  Zhang, Ming Tao, and Jie Liu","A Heterogeneous Parallel Non-von Neumann Architecture System for
  Accurate and Efficient Machine Learning Molecular Dynamics",,,"10.1109/TCSI.2023.3255199",,"cs.LG cs.AR cs.NE cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a special-purpose system to achieve high-accuracy and
high-efficiency machine learning (ML) molecular dynamics (MD) calculations. The
system consists of field programmable gate array (FPGA) and application
specific integrated circuit (ASIC) working in heterogeneous parallelization. To
be specific, a multiplication-less neural network (NN) is deployed on the
non-von Neumann (NvN)-based ASIC (SilTerra 180 nm process) to evaluate atomic
forces, which is the most computationally expensive part of MD. All other
calculations of MD are done using FPGA (Xilinx XC7Z100). It is shown that, to
achieve similar-level accuracy, the proposed NvN-based system based on low-end
fabrication technologies (180 nm) is 1.6x faster and 10^2-10^3x more energy
efficiency than state-of-the-art vN based MLMD using graphics processing units
(GPUs) based on much more advanced technologies (12 nm), indicating superiority
of the proposed NvN-based heterogeneous parallel architecture.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:43:49 GMT""}]","2023-03-29"
"2303.15475","Kaijun Shen","Kaijun Shen, Kewei Sun, and Yang Zhao","Simulation of emission spectra of transition-metal dichalcogenide
  monolayers with the multimode Brownian oscillator model",,"J. Phys. Chem. A 126, 2706-2715 (2022)","10.1021/acs.jpca.2c01522",,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The multimode Brownian oscillator model is employed to simulate the emission
spectra of transition metal dichalcogenide monolayers. Good agreement is
obtained between measured and simulated photoluminescence spectra of WSe2, WS2,
MoSe2 and MoS2 at various temperatures. The Huang-Rhys factor extracted from
the model can be associated with that from the modified semi-empirical Varshni
equation at high temperatures. Individual mechanisms leading to the unique
temperature-dependent emission spectra of those TMDs are validated by the MBO
fitting, while it is in turn confirmed that the MBO analysis is an effective
method for studying the optical properties of TMD monolayers. Parameters
extractd from the MBO fitting can be used to explore exciton-photon-phonon
dynamics of TMDs in a more comprehensive model.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:22:23 GMT""}]","2023-03-29"
"2303.15476","Felix Christian Clemen","Felix Christian Clemen, Adam Zsolt Wagner","A note on balanced edge-colorings avoiding rainbow cliques of size four","2 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A balanced edge-coloring of the complete graph is an edge-coloring such that
every vertex is incident to each color the same number of times. In this short
note, we present a construction of a balanced edge-coloring with six colors of
the complete graph on $n=13^k$ vertices, for every positive integer $k$, with
no rainbow $K_4$. This solves a problem by Erd\H{o}s and Tuza.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 09:36:42 GMT""}]","2023-03-29"
"2303.16080","Zdzislaw Musielak","Z.E. Musielak","Atomic Model of Dark Matter Halo and Its Quantum Structure",,,,,"physics.gen-ph","http://creativecommons.org/licenses/by/4.0/","  A quantum theory of dark matter particles in a spherical halo is developed by
using a new asymmetric equation, which is complementary to the Schr\""odinger
equation. The theory predicts that each dark matter halo has its core and
envelope with very distinct physical properties. The core is free of any
quantum structure and its dark matter particles are in random motion and
frequently collide with each other. However, the envelope has a global quantum
structure that contains quantized orbits populated by the particles. The
predicted quantum structure of the halo resembles an atom, hence, it is named
the atomic model of dark matter halo. Applications of the theory to a dark
matter halo with a given density profile are described, and predictions of the
theory are discussed.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:56:04 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 20:13:13 GMT""}]","2023-04-12"
"2303.16117","Thomas Wong","Thomas Wong, Mauricio Barahona","Feature Engineering Methods on Multivariate Time-Series Data for
  Financial Data Science Competitions","arXiv admin note: substantial text overlap with arXiv:2303.07925",,,,"q-fin.ST cs.LG","http://creativecommons.org/licenses/by/4.0/","  This paper is a work in progress. We are looking for collaborators to provide
us financial datasets in Equity/Futures market to conduct more bench-marking
studies. The authors have papers employing similar methods applied on the
Numerai dataset, which is freely available but obfuscated.
  We apply different feature engineering methods for time-series to US market
price data. The predictive power of models are tested against Numerai-Signals
targets.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 00:57:35 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 17:27:16 GMT""}]","2023-04-19"
"2303.16754","Kinyua Gikunda Dr.","Irad Mwendo, Kinyua Gikunda, Anthony Maina","Deep transfer learning for detecting Covid-19, Pneumonia and
  Tuberculosis using CXR images -- A Review",,,,,"eess.IV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Chest X-rays remains to be the most common imaging modality used to diagnose
lung diseases. However, they necessitate the interpretation of experts
(radiologists and pulmonologists), who are few. This review paper investigates
the use of deep transfer learning techniques to detect COVID-19, pneumonia, and
tuberculosis in chest X-ray (CXR) images. It provides an overview of current
state-of-the-art CXR image classification techniques and discusses the
challenges and opportunities in applying transfer learning to this domain. The
paper provides a thorough examination of recent research studies that used deep
transfer learning algorithms for COVID-19, pneumonia, and tuberculosis
detection, highlighting the advantages and disadvantages of these approaches.
Finally, the review paper discusses future research directions in the field of
deep transfer learning for CXR image classification, as well as the potential
for these techniques to aid in the diagnosis and treatment of lung diseases.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:36:47 GMT""}]","2023-03-30"
"2303.16764","Siyang Zhao","Han Liu, Feng Zhang, Xiaotong Zhang, Siyang Zhao, Fenglong Ma,
  Xiao-Ming Wu, Hongyang Chen, Hong Yu, Xianchao Zhang","Boosting Few-Shot Text Classification via Distribution Estimation","Accepted to AAAI 2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distribution estimation has been demonstrated as one of the most effective
approaches in dealing with few-shot image classification, as the low-level
patterns and underlying representations can be easily transferred across
different tasks in computer vision domain. However, directly applying this
approach to few-shot text classification is challenging, since leveraging the
statistics of known classes with sufficient samples to calibrate the
distributions of novel classes may cause negative effects due to serious
category difference in text domain. To alleviate this issue, we propose two
simple yet effective strategies to estimate the distributions of the novel
classes by utilizing unlabeled query samples, thus avoiding the potential
negative transfer issue. Specifically, we first assume a class or sample
follows the Gaussian distribution, and use the original support set and the
nearest few query samples to estimate the corresponding mean and covariance.
Then, we augment the labeled samples by sampling from the estimated
distribution, which can provide sufficient supervision for training the
classification model. Extensive experiments on eight few-shot text
classification datasets show that the proposed method outperforms
state-of-the-art baselines significantly.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 05:58:39 GMT""}]","2023-03-30"
"2303.16780","Bradford Windsor","Brad Windsor, Kevin Choi","Thistle: A Vector Database in Rust",,,,,"cs.IR cs.AI","http://creativecommons.org/licenses/by/4.0/","  We present Thistle, a fully functional vector database. Thistle is an entry
into the domain of latent knowledge use in answering search queries, an ongoing
research topic at both start-ups and search engine companies. We implement
Thistle with several well-known algorithms, and benchmark results on the MS
MARCO dataset. Results help clarify the latent knowledge domain as well as the
growing Rust ML ecosystem.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:56:23 GMT""}]","2023-03-30"
"2303.16955","Soumyadip Sarkar","Soumyadip Sarkar","A Generative Modeling Approach Using Quantum Gates",,,,,"quant-ph cs.LG","http://creativecommons.org/licenses/by/4.0/","  In recent years, quantum computing has emerged as a promising technology for
solving complex computational problems. Generative modeling is a technique that
allows us to learn and generate new data samples similar to the original
dataset. In this paper, we propose a generative modeling approach using quantum
gates to generate new samples from a given dataset. We start with a brief
introduction to quantum computing and generative modeling. Then, we describe
our proposed approach, which involves encoding the dataset into quantum states
and using quantum gates to manipulate these states to generate new samples. We
also provide mathematical details of our approach and demonstrate its
effectiveness through experimental results on various datasets.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 18:01:50 GMT""}]","2023-03-31"
"2303.17485","Debasish Jana","Debasish Jana, Sven Malama, Sriram Narasimhan, Ertugrul Taciroglu","Edge Ranking of Graphs in Transportation Networks using a Graph Neural
  Network (GNN)",,,,,"cs.SI cs.AI","http://creativecommons.org/licenses/by/4.0/","  Many networks, such as transportation, power, and water distribution, can be
represented as graphs. Crucial challenge in graph representations is
identifying the importance of graph edges and their influence on overall
network efficiency and information flow performance. For example, important
edges in a transportation network are those roads that, when affected, will
significantly alter the network's overall efficiency. Commonly used approach to
finding such important edges is ``edge betweenness centrality'' (EBC), an edge
ranking measure to determine the influential edges of the graph based on
connectivity and information spread. Computing the EBC utilizing the common
Brandes algorithm involves calculating the shortest paths for every node pair,
which can be computationally expensive and restrictive, especially for large
graphs. Changes in the graph parameters, e.g., in the edge weight or the
addition and deletion of nodes or edges, require the recalculation of the EBC.
As the main contribution, we propose an approximate method to estimate the EBC
using a Graph Neural Network (GNN), a deep learning-based approach. We show
that it is computationally efficient compared to the conventional method,
especially for large graphs. The proposed method of GNN-based edge ranking is
evaluated on several synthetic graphs and a real-world transportation data set.
We show that this framework can estimate the approximate edge ranking much
faster compared to the conventional method. This approach is inductive, i.e.,
training and testing are performed on different sets of graphs with varying
numbers of nodes and edges. The proposed method is especially suitable for
applications on large-scale networks when edge information is desired, for
example, in urban infrastructure improvement projects, power, and water network
resilience analyses, and optimizing resource allocations in engineering
networks.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 20:45:30 GMT""}]","2023-03-31"
"2303.18131","Ruoxi Chen","Ruoxi Chen, Haibo Jin, Jinyin Chen, Haibin Zheng","AdvCheck: Characterizing Adversarial Examples via Local Gradient
  Checking","26 pages",,,,"cs.CR cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) are vulnerable to adversarial examples, which may
lead to catastrophe in security-critical domains. Numerous detection methods
are proposed to characterize the feature uniqueness of adversarial examples, or
to distinguish DNN's behavior activated by the adversarial examples. Detections
based on features cannot handle adversarial examples with large perturbations.
Besides, they require a large amount of specific adversarial examples. Another
mainstream, model-based detections, which characterize input properties by
model behaviors, suffer from heavy computation cost. To address the issues, we
introduce the concept of local gradient, and reveal that adversarial examples
have a quite larger bound of local gradient than the benign ones. Inspired by
the observation, we leverage local gradient for detecting adversarial examples,
and propose a general framework AdvCheck. Specifically, by calculating the
local gradient from a few benign examples and noise-added misclassified
examples to train a detector, adversarial examples and even misclassified
natural inputs can be precisely distinguished from benign ones. Through
extensive experiments, we have validated the AdvCheck's superior performance to
the state-of-the-art (SOTA) baselines, with detection rate ($\sim \times 1.2$)
on general adversarial attacks and ($\sim \times 1.4$) on misclassified natural
inputs on average, with average 1/500 time cost. We also provide interpretable
results for successful detection.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 17:46:09 GMT""}]","2023-04-03"
"2304.00007","Adnan Qayyum","Adnan Qayyum, Muhammad Bilal, Muhammad Hadi, Pawe{\l} Capik, Massimo
  Caputo, Hunaid Vohra, Ala Al-Fuqaha, and Junaid Qadir","Can We Revitalize Interventional Healthcare with AI-XR Surgical
  Metaverses?","To appear in IEEE Metacom, this is a preprint author copy",,,,"cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Recent advancements in technology, particularly in machine learning (ML),
deep learning (DL), and the metaverse, offer great potential for
revolutionizing surgical science. The combination of artificial intelligence
and extended reality (AI-XR) technologies has the potential to create a
surgical metaverse, a virtual environment where surgeries can be planned and
performed. This paper aims to provide insight into the various potential
applications of an AI-XR surgical metaverse and the challenges that must be
addressed to bring its full potential to fruition. It is important for the
community to focus on these challenges to fully realize the potential of the
AI-XR surgical metaverses. Furthermore, to emphasize the need for secure and
robust AI-XR surgical metaverses and to demonstrate the real-world implications
of security threats to the AI-XR surgical metaverses, we present a case study
in which the ``an immersive surgical attack'' on incision point localization is
performed in the context of preoperative planning in a surgical metaverse.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:36:22 GMT""}]","2023-04-04"
"2304.06471","Ruiqi Yang","Eric Modesitt, Ruiqi Yang, Qi Liu","Two Heads are Better than One: A Bio-inspired Method for Improving
  Classification on EEG-ET Data","6 pages, 3 figures, HCI International 2023 Poster",,,,"eess.SP cs.HC cs.LG","http://creativecommons.org/licenses/by/4.0/","  Classifying EEG data is integral to the performance of Brain Computer
Interfaces (BCI) and their applications. However, external noise often
obstructs EEG data due to its biological nature and complex data collection
process. Especially when dealing with classification tasks, standard EEG
preprocessing approaches extract relevant events and features from the entire
dataset. However, these approaches treat all relevant cognitive events equally
and overlook the dynamic nature of the brain over time. In contrast, we are
inspired by neuroscience studies to use a novel approach that integrates
feature selection and time segmentation of EEG data. When tested on the
EEGEyeNet dataset, our proposed method significantly increases the performance
of Machine Learning classifiers while reducing their respective computational
complexity.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:44:39 GMT""}]","2023-04-14"
"2304.06491","Abdur Rab Dhruba","Abdur Rab Dhruba, Kazi Nabiul Alam, Md. Shakib Khan, Sananda Saha,
  Mohammad Monirujjaman Khan, Mohammed Baz, Mehedi Masud, and Mohammed A.
  AlZain","IoT-Based Water Quality Assessment System for Industrial Waste
  WaterHealthcare Perspective",,,"10.1155/2022/3769965",,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  The environment, especially water, gets polluted due to industrialization and
urbanization. Pollution due to industrialization and urbanization has harmful
effects on both the environment and the lives on Earth. This polluted water can
cause food poisoning, diarrhea, short-term gastrointestinal problems,
respiratory diseases, skin problems, and other serious health complications. In
a developing country like Bangladesh, where ready-made garments sector is one
of the major sources of the total Gross Domestic Product (GDP), most of the
wastes released from the garment factories are dumped into the nearest rivers
or canals. Hence, the quality of the water of these bodies become very
incompatible for the living beings, and so, it has become one of the major
threats to the environment and human health. In addition, the amount of fish in
the rivers and canals in Bangladesh is decreasing day by day as a result of
water pollution. Therefore, to save fish and other water animals and the
environment, we need to monitor the quality of the water and find out the
reasons for the pollution. Real-time monitoring of the quality of water is
vital for controlling water pollution. Most of the approaches for controlling
water pollution are mainly biological and lab-based, which takes a lot of time
and resources. To address this issue, we developed an Internet of Things
(IoT)-based real-time water quality monitoring system, integrated with a mobile
application. The proposed system in this research measures some of the most
important indexes of water, including the potential of hydrogen (pH), total
dissolved solids (TDS), and turbidity, and temperature of water. The proposed
system results will be very helpful in saving the environment, and thus,
improving the health of living creatures on Earth.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 07:17:18 GMT""}]","2023-04-14"
"2304.06512","Xingqi Wu","Henglin Pu, Xingqi Wu","Investigating Skin Temperature-Based Overheating in mmWave Smartphones
  Power and Thermal Models for Optimal Non-Throttling Performance",,,,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  5G mmWave, as a revolutionary cellular technology, holds monumental potential
for innovations in many academic and industrial areas. However, widespread
adoption of this technology is hindered by the severe overheating issues
experienced by current Commercial Off-The-Shelf (COTS) mmWave smartphones. This
study aims to identify the root causes of device skin temperature related
throttling during 5G transmission, and to quantify power reduction required to
prevent such throttling in a given ambient temperature. The key insight of our
paper is leveraging the power model and thermal model of mmWave smartphone to
acquire the quantitative relationship among power consumption, ambient
temperature and device skin temperature. This approach allows us to determine
the extent of power reduction required to prevent throttling under specific
ambient temperature conditions.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:27:44 GMT""}]","2023-04-14"
"2304.06513","Liangqi Yuan","Liangqi Yuan, Houlin Chen, Robert Ewing, Jia Li","Passive Radio Frequency-based 3D Indoor Positioning System via Ensemble
  Learning","DDDAS 2022",,,,"eess.SP cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Passive radio frequency (PRF)-based indoor positioning systems (IPS) have
attracted researchers' attention due to their low price, easy and customizable
configuration, and non-invasive design. This paper proposes a PRF-based
three-dimensional (3D) indoor positioning system (PIPS), which is able to use
signals of opportunity (SoOP) for positioning and also capture a scenario
signature. PIPS passively monitors SoOPs containing scenario signatures through
a single receiver. Moreover, PIPS leverages the Dynamic Data Driven
Applications System (DDDAS) framework to devise and customize the sampling
frequency, enabling the system to use the most impacted frequency band as the
rated frequency band. Various regression methods within three ensemble learning
strategies are used to train and predict the receiver position. The PRF
spectrum of 60 positions is collected in the experimental scenario, and three
criteria are applied to evaluate the performance of PIPS. Experimental results
show that the proposed PIPS possesses the advantages of high accuracy,
configurability, and robustness.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 21:13:00 GMT""}]","2023-04-14"
"2304.06632","Wensheng Gan","Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, Hong Lin","AI-Generated Content (AIGC): A Survey","Preprint. 14 figures, 4 tables",,,,"cs.AI cs.CY cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To address the challenges of digital intelligence in the digital economy,
artificial intelligence-generated content (AIGC) has emerged. AIGC uses
artificial intelligence to assist or replace manual content generation by
generating content based on user-inputted keywords or requirements. The
development of large model algorithms has significantly strengthened the
capabilities of AIGC, which makes AIGC products a promising generative tool and
adds convenience to our lives. As an upstream technology, AIGC has unlimited
potential to support different downstream applications. It is important to
analyze AIGC's current capabilities and shortcomings to understand how it can
be best utilized in future applications. Therefore, this paper provides an
extensive overview of AIGC, covering its definition, essential conditions,
cutting-edge capabilities, and advanced features. Moreover, it discusses the
benefits of large-scale pre-trained models and the industrial chain of AIGC.
Furthermore, the article explores the distinctions between auxiliary generation
and automatic generation within AIGC, providing examples of text generation.
The paper also examines the potential integration of AIGC with the Metaverse.
Lastly, the article highlights existing issues and suggests some future
directions for application.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 02:22:12 GMT""}]","2023-04-14"
"2304.12305","Md. Kamrujjaman","Mahadee Al Mobin and Md. Kamrujjaman","Downscaling Epidemiological Time Series Data for Improving Forecasting
  Accuracy: An Algorithmic Approach","33 pages",,,,"stat.OT","http://creativecommons.org/licenses/by/4.0/","  Data scarcity and discontinuity are common occurrences in the healthcare and
epidemiological dataset and often need help in forming an educative decision
and forecasting the upcoming scenario. Often, these data are stored as
monthly/yearly aggregate where the prevalent forecasting tools like
Autoregressive Integrated Moving Average (ARIMA), Seasonal Autoregressive
Integrated Moving Average (SARIMA), and TBATS often fail to provide
satisfactory results. Artificial data synthesis methods have been proven to be
a powerful tool for tackling these challenges. The paper aims to propose a
downscaling data algorithm based on the underlying distribution. Our findings
show that the synthesized data is in agreement with the original data in terms
of trend, seasonality, and residuals, and the synthesized data provides a
stable foothold for the forecasting tools to generate a much more accurate
forecast of the situation.
","[{""version"":""v1"",""created"":""Sun, 26 Mar 2023 01:09:48 GMT""}]","2023-04-25"
"2304.12319","Xi Zhang","Xi Zhang and Xiaolin Wu","LVQAC: Lattice Vector Quantization Coupled with Spatially Adaptive
  Companding for Efficient Learned Image Compression","Accepted by CVPR 2023",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, numerous end-to-end optimized image compression neural networks
have been developed and proved themselves as leaders in rate-distortion
performance. The main strength of these learnt compression methods is in
powerful nonlinear analysis and synthesis transforms that can be facilitated by
deep neural networks. However, out of operational expediency, most of these
end-to-end methods adopt uniform scalar quantizers rather than vector
quantizers, which are information-theoretically optimal. In this paper, we
present a novel Lattice Vector Quantization scheme coupled with a spatially
Adaptive Companding (LVQAC) mapping. LVQ can better exploit the inter-feature
dependencies than scalar uniform quantization while being computationally
almost as simple as the latter. Moreover, to improve the adaptability of LVQ to
source statistics, we couple a spatially adaptive companding (AC) mapping with
LVQ. The resulting LVQAC design can be easily embedded into any end-to-end
optimized image compression system. Extensive experiments demonstrate that for
any end-to-end CNN image compression models, replacing uniform quantizer by
LVQAC achieves better rate-distortion performance without significantly
increasing the model complexity.
","[{""version"":""v1"",""created"":""Sat, 25 Mar 2023 23:34:15 GMT""}]","2023-04-26"
