"2305.14181","Paolo Antonelli","Paolo Antonelli and Boris Shakarov","Existence and Large Time Behavior for a Dissipative Variant of the
  Rotational NLS Equation","32 pages, comments welcome",,,,"math.AP math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a dissipative variant of the Gross-Pitaevskii equation with
rotation. The model contains a nonlocal, nonlinear term that forces the
conservation of $L^2$-norm of solutions. We are motivated by several physical
experiments and numerical simulations studying the formation of vortices in
Bose-Einstein condensates. We show local and global well-posedness of this
model and investigate the asymptotic behavior of its solutions. In the linear
case, the solution asymptotically tends to the eigenspace associated with the
smallest eigenvalue in the decomposition of the initial datum. In the nonlinear
case, we obtain weak convergence to a stationary state. Moreover, for initial
energies in a specific range, we prove strong asymptotic stability of ground
state solutions.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:00:17 GMT""}]","2023-05-24"
"2305.14182","Martenq Kaas","Marten H. L. Kaas, Zoe Porter, Ernest Lim, Aisling Higham, Sarah
  Khavandi and Ibrahim Habli","Ethics in conversation: Building an ethics assurance case for autonomous
  AI-enabled voice agents in healthcare","19 pages, 3 figures, 1 table, pre-print of paper for Trustworthy
  Autonomous Systems conference",,,,"cs.CY","http://creativecommons.org/licenses/by/4.0/","  The deployment and use of AI systems should be both safe and broadly
ethically acceptable. The principles-based ethics assurance argument pattern is
one proposal in the AI ethics landscape that seeks to support and achieve that
aim. The purpose of this argument pattern or framework is to structure
reasoning about, and to communicate and foster confidence in, the ethical
acceptability of uses of specific real-world AI systems in complex
socio-technical contexts. This paper presents the interim findings of a case
study applying this ethics assurance framework to the use of Dora, an AI-based
telemedicine system, to assess its viability and usefulness as an approach. The
case study process to date has revealed some of the positive ethical impacts of
the Dora platform, as well as unexpected insights and areas to prioritise for
evaluation, such as risks to the frontline clinician, particularly in respect
of clinician autonomy. The ethics assurance argument pattern offers a practical
framework not just for identifying issues to be addressed, but also to start to
construct solutions in the form of adjustments to the distribution of benefits,
risks and constraints on human autonomy that could reduce ethical disparities
across affected stakeholders. Though many challenges remain, this research
represents a step in the direction towards the development and use of safe and
ethically acceptable AI systems and, ideally, a shift towards more
comprehensive and inclusive evaluations of AI systems in general.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:04:59 GMT""}]","2023-05-24"
"2305.14183","Micha{\l} Kijaczko","Micha{\l} Kijaczko","Asymptotics of weighted Gagliardo seminorms","12 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider fractional Sobolev spaces equipped with weights
being powers of the distance to the boundary of the domain. We prove the
versions of Bourgain--Brezis--Mironescu and Maz'ya--Shaposhnikova asymptotic
formulae for weighted fractional Gagliardo seminorms. For $p>1$ we also provide
a nonlocal characterization of classical weighted Sobolev spaces with power
weights.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:06:05 GMT""}]","2023-05-24"
"2305.14184","Han Cai","Han Cai, Jay C. LeFebvre, Hao Li, Ethan Y. Cho, Nobuyuki Yoshikawa and
  Shane A. Cybart","High-Temperature Superconductor Quantum Flux Parametron for
  Energy-Efficient Logic",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As we rapidly advance through the information age, the power consumed by
computers, data centers, and networks grows exponentially. This has inspired a
race to develop alternative low-power computational technologies. A new
adiabatic configuration of a decades-old superconducting digital logic device
has darted into the lead called quantum flux parametrons (QFP). QFP operate
with dissipation so low that they seemingly violate the laws of thermodynamics.
In just a short span of time, they have gone from simple single NOT gates to
complex processors containing thousands of gates. They are fabricated from
elemental niobium superconductors cooled to just a few degrees above absolute
zero. However, their efficiency is so great that for large high-performance
computers with several gates, the energy savings are immense. For smaller
computational platforms QFPs from high-temperature superconductors (high-Tc)
are highly desirable. In this work, we take the first steps towards this goal
with the demonstration of a high-T C QFP shift register. Our device is
fabricated using focused helium ion beam lithography where the material is
modified with an ion beam at the nanoscale to directly pattern these circuits
into a high-T C thin film. We validate the correct logical operation at 25 K,
over 6 times higher than niobium devices with an estimated bit energy of 0.1
attoJoule at 10 GHz.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:06:37 GMT""}]","2023-05-24"
"2305.14185","Fabio Chalub","Fabio A.C.C. Chalub, Antonio G\'omez-Corral, Mart\'in
  L\'opez-Garc\'ia, and F\'atima Palacios-Rodr\'iguez","A Markov chain model to investigate the spread of antibiotic-resistant
  bacteria in hospitals","22 pages, 5 figures",,,,"q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a Markov chain model to describe the spread of a single
bacterial species in a hospital ward where patients may be free of bacteria or
may carry bacterial strains that are either sensitive or resistant to
antimicrobial agents. The aim is to determine the probability law of the exact
reproduction number Rexact,0 which is here defined as the random number of
secondary infections generated by those patients who are accommodated in a
predetermined bed before a patient who is free of bacteria is accommodated in
this bed for the first time. Specifically, we decompose the exact reproduction
number Rexact,0 into two contributions allowing us to distinguish between
infections due to the sensitive and the resistant bacterial strains. Our
methodology is mainly based on structured Markov chains and the use of related
matrix-analytic methods.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:06:56 GMT""}]","2023-05-24"
"2305.14186","Jessica Page","Jessica Page, Tyson Littenberg","Bayesian Time Delay Interferometry for Orbiting LISA: Accounting for the
  Time Dependence of Spacecraft Separations",,,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previous work demonstrated effective laser frequency noise (LFN) suppression
for Laser Interferometer Space Antenna (LISA) data from raw phasemeter
measurements using a Markov Chain Monte Carlo (MCMC) algorithm with fractional
delay interpolation (FDI) techniques to estimate the spacecraft separation
parameters required for time-delay interferometry (TDI) under the assumption of
a rigidly rotating LISA configuration. Including TDI parameters in the LISA
data model as part of a global fit analysis pipeline enables gravitational wave
inferences to be marginalized over uncertainty in the spacecraft separations.
Here we extend the algorithm's capability to perform data-driven TDI on LISA in
Keplerian orbits, which introduce a time-dependence in the arm-length
parameters and at least $\mathcal{O}$(M) times greater computational cost since
the filter must be applied for every sample in the time series of sample size
M. We find feasibility of arm-length estimation on $\sim$day-long time scales
by using a novel Taylor-expanded version of the fractional delay interpolation
filter that allows half of the filter computation to be calculated and stored
before MCMC iterations and requires shorter filter lengths than previously
reported. We demonstrate LFN suppression for orbiting LISA using accurate
arm-length estimates parameterized by Keplerian orbital parameters under the
assumption of unperturbed analytical Keplerian orbits, and explore the
potential extension of these methods to arbitrary numerical orbits.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:07:30 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 15:00:11 GMT""}]","2023-05-29"
"2305.14187","Steven Tomsovic","Steven Tomsovic, Juan Diego Urbina, and Klaus Richter","Controlling quantum chaos: time-dependent kicked rotor","12 pages, 8 figures, 1 table",,,,"quant-ph cond-mat.quant-gas nlin.CD","http://creativecommons.org/licenses/by/4.0/","  One major objective of controlling classical chaotic dynamical systems is
exploiting the system's extreme sensitivity to initial conditions in order to
arrive at a predetermined target state. In a recent letter [Phys.~Rev.~Lett.
130, 020201 (2023)], a generalization of this targeting method to quantum
systems was demonstrated using successive unitary transformations that counter
the natural spreading of a quantum state. In this paper further details are
given and an important quite general extension is established. In particular,
an alternate approach to constructing the coherent control dynamics is given,
which introduces a new time-dependent, locally stable control Hamiltonian that
continues to use the chaotic heteroclinic orbits previously introduced, but
without the need of countering quantum state spreading. Implementing that
extension for the quantum kicked rotor generates a much simpler approximate
control technique than discussed in the letter, which is a little less
accurate, but far more easily realizable in experiments. The simpler method's
error can still be made to vanish as $\hbar \rightarrow 0$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:07:34 GMT""}]","2023-05-24"
"2305.14188","Iuri Frosio","Iuri Frosio and Jan Kautz","The Best Defense is a Good Offense: Adversarial Augmentation against
  Adversarial Attacks",,"CVPR 2023",,,"cs.LG cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many defenses against adversarial attacks (\eg robust classifiers,
randomization, or image purification) use countermeasures put to work only
after the attack has been crafted. We adopt a different perspective to
introduce $A^5$ (Adversarial Augmentation Against Adversarial Attacks), a novel
framework including the first certified preemptive defense against adversarial
attacks. The main idea is to craft a defensive perturbation to guarantee that
any attack (up to a given magnitude) towards the input in hand will fail. To
this aim, we leverage existing automatic perturbation analysis tools for neural
networks. We study the conditions to apply $A^5$ effectively, analyze the
importance of the robustness of the to-be-defended classifier, and inspect the
appearance of the robustified images. We show effective on-the-fly defensive
augmentation with a robustifier network that ignores the ground truth label,
and demonstrate the benefits of robustifier and classifier co-training. In our
tests, $A^5$ consistently beats state of the art certified defenses on MNIST,
CIFAR10, FashionMNIST and Tinyimagenet. We also show how to apply $A^5$ to
create certifiably robust physical objects. Our code at
https://github.com/NVlabs/A5 allows experimenting on a wide range of scenarios
beyond the man-in-the-middle attack tested here, including the case of physical
attacks.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:07:58 GMT""}]","2023-05-24"
"2305.14189","Di Wu","Di Wu and Christof Monz","Beyond Shared Vocabulary: Increasing Representational Word Similarities
  across Languages for Multilingual Machine Translation","11 pages, 2 figures",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using a shared vocabulary is common practice in Multilingual Neural Machine
Translation (MNMT). In addition to its simple design, shared tokens play an
important role in positive knowledge transfer, which manifests naturally when
the shared tokens refer to similar meanings across languages. However, natural
flaws exist in such a design as well: 1) when languages use different writing
systems, transfer is inhibited, and 2) even if languages use similar writing
systems, shared tokens may have completely different meanings in different
languages, increasing ambiguity. In this paper, we propose a re-parameterized
method for building embeddings to alleviate the first problem. More
specifically, we define word-level information transfer pathways via word
equivalence classes and rely on graph networks to fuse word embeddings across
languages. Our experiments demonstrate the advantages of our approach: 1) the
semantics of embeddings are better aligned across languages, 2) our method
achieves significant BLEU improvements on high- and low-resource MNMT, and 3)
only less than 1.0\% additional trainable parameters are required with a
limited increase in computational costs.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:11:00 GMT""}]","2023-05-24"
"2305.14190","Alireza Ahmadianyazdi","Alireza Ahmadianyazdi, Isaac J. Miller, Albert Folch","Tunable Resins with PDMS-like Elastic Modulus for Stereolithographic
  3D-printing of Multimaterial Microfluidic Actuators",,,,,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Stereolithographic 3D-printing (SLA) permits facile fabrication of
high-precision microfluidic and lab-on-a-chip devices. SLA photopolymers often
yield parts with low mechanical compliancy in sharp contrast to elastomers such
as poly (dimethyl siloxane) (PDMS). On the other hand, SLA-printable elastomers
with soft mechanical properties do not fulfill the distinct requirements for a
highly manufacturable resin in microfluidics (e.g., high-resolution
printability, transparency, low-viscosity). These limitations restrict our
ability to SLA-print efficient microfluidic actuators containing dynamic,
movable elements. Here we introduce low-viscous photopolymer resins based on a
tunable blend of poly(ethylene glycol) diacrylate (PEGDA, Mw~258) and poly
(ethylene glycol methyl ether) methacrylate (PEGMEMA, Mw~300) monomers. In
these blends, which we term PEGDA-co-PEGMEMA, tuning the PEGMEMA-to-PEGDA ratio
alters the elastic modulus of the printed plastics by ~400-fold, reaching that
of PDMS. Through the addition of PEGMEMA, moreover, PEGDA-co-PEGMEMA retains
desirable properties of highly manufacturable PEGDA such as low viscosity,
solvent compatibility, cytocompatibility and low drug absorptivity. With
PEGDA-co-PEGMEMA, we SLA-printed drastically enhanced fluidic actuators
including microvalves, micropumps, and microregulators with a hybrid structure
containing a flexible PEGDA-co-PEGMEMA membrane within a rigid PEGDA housing.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:11:49 GMT""}]","2023-05-24"
"2305.14191","G\'abor Heged\""us Dr","G\'abor Heged\""us","Non-uniform skew versions of Bollob\'as' Theorem",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A_1, \ldots ,A_m$ and $B_1, \ldots ,B_m$ be subsets of $[n]$ and let $t$
be a non-negative integer with the following property: $|A_i \cap B_i|\leq t$
for each $i$ and $|A_i\cap B_j|>t$ whenever $i< j$. Then $m\leq 2^{n-t}$. Our
proof uses Lov\'asz' tensor product method.
  We prove the following skew version of Bollob\'as' Theorem. Let $A_1, \ldots
,A_m$ and $B_1, \ldots ,B_m$ be finite sets of $[n]$ satisfying the conditions
$A_i \cap B_i =\emptyset$ for each $i$ and $A_i\cap B_j\ne \emptyset$ for each
$i< j$. Then $$ \sum_{i=1}^m \frac{1}{{|A_i|+|B_i| \choose |A_i|}}\leq n+1. $$
Both upper bounds are sharp.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:11:57 GMT""}]","2023-05-24"
"2305.14192","Vladimir Georgiev","Daniele Barbera and Vladimir Georgiev","Local and global solutions on arcs for the Ericksen -- Leslie problem in
  the whole space","40 p",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The work deals with the Ericksen-Leslie System for nematic liquid crystals on
the whole space. In our work we suppose the initial condition of the
orientation field stays on an arc connecting two fixed orthogonal vectors on
the unit sphere. Thanks to this geometric assumption, we prove through energy a
priori estimates the local existence and the global existence for small initial
data of a solution in low regularity Sobolev spaces.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:12:12 GMT""}]","2023-05-24"
"2305.14193","Weite Pi","Woonam Lim, Miguel Moreira, Weite Pi","Cohomological $\chi$-dependence of ring structure for the moduli of
  one-dimensional sheaves on $\mathbb{P}^2$","19 pages, comments are welcome!",,,,"math.AG","http://creativecommons.org/licenses/by/4.0/","  We prove that the cohomology rings of the moduli space $M_{d,\chi}$ of
one-dimensional sheaves on the projective plane are not isomorphic for general
different choices of the Euler characteristics. This stands in contrast to the
$\chi$-independence of the Betti numbers of these moduli spaces. As a
corollary, we deduce that $M_{d,\chi}$ are topologically different unless they
are related by obvious symmetries, strengthening a previous result of Woolf
distinguishing them as algebraic varieties.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:12:33 GMT""}]","2023-05-24"
"2305.14194","Heejun Shin","Heejun Shin, Danielle Braun, Kezia Irene, Joseph Antonelli","A spatial interference approach to account for mobility in air pollution
  studies with multivariate continuous treatments",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  We develop new methodology to improve our understanding of the causal effects
of multivariate air pollution exposures on public health. Typically, exposure
to air pollution for an individual is measured at their home geographic region,
though people travel to different regions with potentially different levels of
air pollution. To account for this, we incorporate estimates of the mobility of
individuals from cell phone mobility data to get an improved estimate of their
exposure to air pollution. We treat this as an interference problem, where
individuals in one geographic region can be affected by exposures in other
regions due to mobility into those areas. We propose policy-relevant estimands
and derive expressions showing the extent of bias one would obtain by ignoring
this mobility. We additionally highlight the benefits of the proposed
interference framework relative to a measurement error framework for accounting
for mobility. We develop novel estimation strategies to estimate causal effects
that account for this spatial spillover utilizing flexible Bayesian
methodology. Empirically we find that this leads to improved estimation of the
causal effects of air pollution exposures over analyses that ignore spatial
spillover caused by mobility.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:13:41 GMT""}]","2023-05-24"
"2305.14195","Anthony Sicilia","Anthony Sicilia, Jennifer C. Gates, and Malihe Alikhani","How Old is GPT?: The HumBEL Framework for Evaluating Language Models
  using Human Demographic Data","17 pages, 10 figures, 5 tables",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  While large pre-trained language models (LMs) find greater use across NLP,
existing evaluation protocols do not consider how LM language use aligns with
particular human demographic groups, which can be an important consideration in
conversational AI applications. To remedy this gap, we consider how LM language
skills can be measured and compared to human sub-populations. We suggest
clinical techniques from Speech Language Pathology, which has well-established
norms for acquisition of language skills, organized by (human) age. We conduct
evaluation with a domain expert (i.e., a clinically licensed speech language
pathologist), and also propose automated techniques to substitute clinical
evaluation at scale. We find LM capability varies widely depending on task with
GPT-3.5 mimicking the ability of a typical 6-9 year old at tasks requiring
inference about word meanings and simultaneously outperforming a typical 21
year old at memorization. GPT-3.5 (InstructGPT) also has trouble with social
language use, exhibiting less than 50\% of the tested pragmatic skills. It
shows errors in understanding particular word parts-of-speech and associative
word relations, among other lexical features. Ultimately, findings reiterate
the importance of considering demographic alignment and conversational goals
when using these models as public-facing tools. Our framework will be publicly
available via code, data, and a python package.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:15:24 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 02:55:24 GMT""}]","2023-05-25"
"2305.14196","Uri Shaham","Uri Shaham and Maor Ivgi and Avia Efrat and Jonathan Berant and Omer
  Levy","ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding",,,,,"cs.CL cs.AI cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  We introduce ZeroSCROLLS, a zero-shot benchmark for natural language
understanding over long texts, which contains only test sets, without training
or development data. We adapt six tasks from the SCROLLS benchmark, and add
four new datasets, including two novel information fusing tasks, such as
aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a
comprehensive evaluation of both open-source and closed large language models,
finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest
average score. However, there is still room for improvement on multiple open
challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to
pass the naive baseline. As the state of the art is a moving target, we invite
researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:15:31 GMT""}]","2023-05-24"
"2305.14197","Michael Perelshtein R.","M. R. Perelshtein, A. I. Pakhomchik, Ar. A. Melnikov, M. Podobrii, A.
  Termanova, I. Kreidich, B. Nuriev, S. Iudin, C. W. Mansell, V. M. Vinokur","NISQ-compatible approximate quantum algorithm for unconstrained and
  constrained discrete optimization",,,,,"quant-ph math.OC","http://creativecommons.org/licenses/by/4.0/","  Quantum algorithms are getting extremely popular due to their potential to
significantly outperform classical algorithms. Yet, applying quantum algorithms
to optimization problems meets challenges related to the efficiency of quantum
algorithms training, the shape of their cost landscape, the accuracy of their
output, and their ability to scale to large-size problems. Here, we present an
approximate gradient-based quantum algorithm for hardware-efficient circuits
with amplitude encoding. We show how simple linear constraints can be directly
incorporated into the circuit without additional modification of the objective
function with penalty terms. We employ numerical simulations to test it on
MaxCut problems with complete weighted graphs with thousands of nodes and run
the algorithm on a superconducting quantum processor. We find that for
unconstrained MaxCut problems with more than 1000 nodes, the hybrid approach
combining our algorithm with a classical solver called CPLEX can find a better
solution than CPLEX alone. This demonstrates that hybrid optimization is one of
the leading use cases for modern quantum devices.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:17:57 GMT""}]","2023-05-24"
"2305.14198","Cristian Andr\'es Giuppone","Cristian Giuppone, Adri\'an Rodr\'iguez, Viviam Alencastro, Fernando
  Roig, Tabar\'e Gallardo","Mapping the structure of the planetary 2:1 mean motion resonance. The
  TOI-216, K2-24, and HD27894 systems","16 pages. 16 figures",,"10.1007/s10569-022-10112-5",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mean motion resonances (MMR) are a frequent phenomenon among extrasolar
planetary systems. Current observations indicate that many systems have planets
that are close to or inside the 2:1 MMR, when the orbital period of one of the
planets is twice the other. Analytical models to describe this particular MMR
can only be reduced to integrable approximations in a few specific cases. While
there are successful approaches to the study of this MMR in the case of very
elliptic and/or very inclined orbits using semi-analytical or semi-numerical
methods, these may not be enough to completely understand the resonant
dynamics.
  In this work, we propose to apply a well-established numerical method to
assess the global portrait of the resonant dynamics, which consists in
constructing dynamical maps. Combining these maps with the results from a
semi-analytical method, helps to better understand the underlying dynamics of
the 2:1 MMR, and to identify the behaviors that can be expected in different
regions of the phase space and for different values of the model parameters.
  We verify that the family of stable resonant equilibria bifurcate from
symmetric to asymmetric librations, depending on the mass ratio and
eccentricities of the resonant planets pair. This introduces new structures in
the phase space, that turns the classical V-shape of the MMR, in the semi-major
axis vs. eccentricity space, into a sand clock shape. We construct dynamical
maps for three extrasolar planetary systems, TOI-216, HD27894, and K2-24, and
discuss their phase space structure and their stability in the light of the
orbital fits available in the literature.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:18:03 GMT""}]","2023-05-24"
"2305.14199","Stanley Burris","Stanley Burris","Boole's Chapter XV: Syllogism Details",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Boole's famous 1854 book {\em The Laws of Thought\/} the mathematical
analysis of Aristotelian logic was relegated to Chapter XV, the last chapter
before his treatment of probability theory. This chapter is Boole's tour de
force to show that he had a uniform method to obtain all valid syllogisms in
his version of Aristotelian logic, namely he applied {\em reduction}, {\em
elimination} and {\em solution} in that order to equational expressions for the
premises. The premises of a syllogism were expressed as a pair of equations in
8 variables, but then all algebraic steps between this and the final
expressions for $x$, $vx$ and $1-x$ were omitted. The somewhat tedious details
of those missing steps are given in this note. It is assumed that the reader is
familiar with Boole's reduction, elimination and solution theorems.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:18:55 GMT""}]","2023-05-24"
"2305.14200","Sida I. Wang","Sida I. Wang","Accessing Higher Dimensions for Unsupervised Word Translation",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The striking ability of unsupervised word translation has been demonstrated
with the help of word vectors / pretraining; however, they require large
amounts of data and usually fails if the data come from different domains. We
propose coocmap, a method that can use either high-dimensional co-occurrence
counts or their lower-dimensional approximations. Freed from the limits of low
dimensions, we show that relying on low-dimensional vectors and their
incidental properties miss out on better denoising methods and useful world
knowledge in high dimensions, thus stunting the potential of the data. Our
results show that unsupervised translation can be achieved more easily and
robustly than previously thought -- less than 80MB and minutes of CPU time is
required to achieve over 50\% accuracy for English to Finnish, Hungarian, and
Chinese translations when trained on similar data; even under domain mismatch,
we show coocmap still works fully unsupervised on English NewsCrawl to Chinese
Wikipedia and English Europarl to Spanish Wikipedia, among others. These
results challenge prevailing assumptions on the necessity and superiority of
low-dimensional vectors, and suggest that similarly processed co-occurrences
can outperform dense vectors on other tasks too.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:19:30 GMT""}]","2023-05-24"
"2305.14201","Tiedong Liu","Tiedong Liu and Bryan Kian Hsiang Low","Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks",,,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  We introduce Goat, a fine-tuned LLaMA model that significantly outperforms
GPT-4 on a range of arithmetic tasks. Fine-tuned on a synthetically generated
dataset, Goat achieves state-of-the-art performance on BIG-bench arithmetic
sub-task. In particular, the zero-shot Goat-7B matches or even surpasses the
accuracy achieved by the few-shot PaLM-540B. Surprisingly, Goat can achieve
near-perfect accuracy on large-number addition and subtraction through
supervised fine-tuning only, which is almost impossible with previous
pretrained language models, such as Bloom, OPT, GPT-NeoX, etc. We attribute
Goat's exceptional performance to LLaMA's consistent tokenization of numbers.
To tackle more challenging tasks like large-number multiplication and division,
we propose an approach that classifies tasks based on their learnability, and
subsequently decomposes unlearnable tasks, such as multi-digit multiplication
and division, into a series of learnable tasks by leveraging basic arithmetic
principles. We thoroughly examine the performance of our model, offering a
comprehensive evaluation of the effectiveness of our proposed decomposition
steps. Additionally, Goat-7B can be easily trained using LoRA on a 24GB VRAM
GPU, facilitating reproducibility for other researchers. We release our model,
dataset, and the Python script for dataset generation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:20:30 GMT""}]","2023-05-24"
"2305.14202","Silei Xu","Silei Xu, Theo Culhane, Meng-Hsi Wu, Sina J. Semnani, Monica S. Lam","Complementing GPT-3 with Few-Shot Sequence-to-Sequence Semantic Parsing
  over Wikidata",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  As the largest knowledge base, Wikidata is a massive source of knowledge,
complementing large language models with well-structured data. In this paper,
we present WikiWebQuestions, a high-quality knowledge base question answering
benchmark for Wikidata. This new benchmark uses real-world human data with
SPARQL annotation to facilitate a more accurate comparison with large language
models utilizing the up-to-date answers from Wikidata. Additionally, a baseline
for this benchmark is established with an effective training data synthesis
methodology and WikiSP, a Seq2Seq semantic parser, that handles large noisy
knowledge graphs. Experimental results illustrate the effectiveness of this
methodology, achieving 69% and 59% answer accuracy in the dev set and test set,
respectively. We showed that we can pair semantic parsers with GPT-3 to provide
a combination of verifiable results and qualified guesses that can provide
useful answers to 97% of the questions in the dev set of our benchmark.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:20:43 GMT""}]","2023-05-24"
"2305.14203","Keitaro Tanaka","Sara Kashiwagi, Keitaro Tanaka, Qi Feng, Shigeo Morishima","Improving the Gap in Visual Speech Recognition Between Normal and Silent
  Speech Based on Metric Learning","Accepted by INTERSPEECH 2023",,,,"eess.AS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel metric learning approach to address the
performance gap between normal and silent speech in visual speech recognition
(VSR). The difference in lip movements between the two poses a challenge for
existing VSR models, which exhibit degraded accuracy when applied to silent
speech. To solve this issue and tackle the scarcity of training data for silent
speech, we propose to leverage the shared literal content between normal and
silent speech and present a metric learning approach based on visemes.
Specifically, we aim to map the input of two speech types close to each other
in a latent space if they have similar viseme representations. By minimizing
the Kullback-Leibler divergence of the predicted viseme probability
distributions between and within the two speech types, our model effectively
learns and predicts viseme identities. Our evaluation demonstrates that our
method improves the accuracy of silent VSR, even when limited training data is
available.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:20:46 GMT""}]","2023-05-24"
"2305.14204","Andrea Sipos","Andrea Sipos and Nima Fazeli","MultiSCOPE: Disambiguating In-Hand Object Poses with Proprioception and
  Tactile Feedback","Accepted to RSS 2023",,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a method for estimating in-hand object poses using
proprioception and tactile feedback from a bimanual robotic system. Our method
addresses the problem of reducing pose uncertainty through a sequence of
frictional contact interactions between the grasped objects. As part of our
method, we propose 1) a tool segmentation routine that facilitates contact
location and object pose estimation, 2) a loss that allows reasoning over
solution consistency between interactions, and 3) a loss to promote converging
to object poses and contact locations that explain the external force-torque
experienced by each arm. We demonstrate the efficacy of our method in a
task-based demonstration both in simulation and on a real-world bimanual
platform and show significant improvement in object pose estimation over single
interactions. Visit www.mmintlab.com/multiscope/ for code and videos.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:24:17 GMT""}]","2023-05-24"
"2305.14205","Fantine Huot","Fantine Huot, Joshua Maynez, Chris Alberti, Reinald Kim Amplayo,
  Priyanka Agrawal, Constanza Fierro, Shashi Narayan, Mirella Lapata","$\mu$PLAN: Summarizing using a Content Plan as Cross-Lingual Bridge","EMNLP 2023 Submission",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Cross-lingual summarization consists of generating a summary in one language
given an input document in a different language, allowing for the dissemination
of relevant content across speakers of other languages. However, this task
remains challenging, mainly because of the need for cross-lingual datasets and
the compounded difficulty of summarizing and translating. This work presents
$\mu$PLAN, an approach to cross-lingual summarization that uses an intermediate
planning step as a cross-lingual bridge. We formulate the plan as a sequence of
entities that captures the conceptualization of the summary, i.e. identifying
the salient content and expressing in which order to present the information,
separate from the surface form. Using a multilingual knowledge base, we align
the entities to their canonical designation across languages. $\mu$PLAN models
first learn to generate the plan and then continue generating the summary
conditioned on the plan and the input. We evaluate our methodology on the
XWikis dataset on cross-lingual pairs across four languages and demonstrate
that this planning objective achieves state-of-the-art performance in terms of
ROUGE and faithfulness scores. Moreover, this planning approach improves the
zero-shot transfer to new cross-lingual language pairs compared to non-planning
baselines.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:25:21 GMT""}]","2023-05-24"
"2305.14206","Nicol\'as F. Barrera","Nicol\'as F. Barrera, Patricio Fuentealba, Francisco Mu\~noz, Tatiana
  G\'omez, Carlos C\'ardenas","Formation of $\text{H}_{2}$ on polycyclic aromatic hydrocarbons under
  conditions of the ISM: an ab initio molecular dynamics study",,,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Understanding how the $\mathrm{H}_2$ molecule is formed under the chemical
conditions of the interstellar media (ISM) is critical to the whole chemistry
of it. Formation of $\mathrm{H}_2$ in the ISM requires a third body acting as a
reservoir of energy. Polycyclic aromatic hydrocarbons (PAH's) are excellent
candidates to play that role. In this work we simulated the collisions of
hydrogen atoms with coronene to form $\mathrm{H}_2$ via the Eley-Rideal
mechanism. To do so, we used Born-Oppenheimer (ab initio) Molecular Dynamics
simulations. Our results show that that adsorption of H atoms and subsequent
release of $\mathrm{H}_2$ readily happen on coronene for H atoms with kinetic
energy as large as 1 eV. Special attention is paid to dissipation and partition
of the energy released in the reactions. The capacity of coronene to dissipate
collision and reaction energies depends varies with the reaction site. Inner
sites dissipate energy easier and faster than edge sites, thus evidencing an
interplay between the potential energy surface around the reaction center and
its ability to cool the projectile. As for the the recombination of H atoms and
the subsequent formation of $\mathrm{H}_{2}$, it is observed that $\sim 15\%$
of the energy is dissipated by the coronene molecule as vibrational energy and
the remaining energy is carried by $\mathrm{H}_{2}$. The $\mathrm{H}_{2}$
molecules desorb from coronene with an excited vibrational state ($\upsilon
\geq 3$), a large amount of translational kinetic energy ($\geq$ 0.4 eV) and
with a small activation of the rotational degree of freedom.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:25:58 GMT""}]","2023-05-24"
"2305.14207","Jun Cen","Jun Cen, Yizheng Wu, Kewei Wang, Xingyi Li, Jingkang Yang, Yixuan Pei,
  Lingdong Kong, Ziwei Liu, Qifeng Chen","SAD: Segment Any RGBD","Technical report of Segment Any RGBD. Project url:
  https://github.com/Jun-CEN/SegmentAnyRGBD",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Segment Anything Model (SAM) has demonstrated its effectiveness in
segmenting any part of 2D RGB images. However, SAM exhibits a stronger emphasis
on texture information while paying less attention to geometry information when
segmenting RGB images. To address this limitation, we propose the Segment Any
RGBD (SAD) model, which is specifically designed to extract geometry
information directly from images. Inspired by the natural ability of humans to
identify objects through the visualization of depth maps, SAD utilizes SAM to
segment the rendered depth map, thus providing cues with enhanced geometry
information and mitigating the issue of over-segmentation. We further include
the open-vocabulary semantic segmentation in our framework, so that the 3D
panoptic segmentation is fulfilled. The project is available on
https://github.com/Jun-CEN/SegmentAnyRGBD.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:26:56 GMT""}]","2023-05-24"
"2305.14208","Anmol Kabra","Anmol Kabra, Ethan R. Elenberg","Domain Private Transformers",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large, general purpose language models have demonstrated impressive
performance across many different conversational domains. While multi-domain
language models achieve low overall perplexity, their outputs are not
guaranteed to stay within the domain of a given input prompt. This paper
proposes domain privacy as a novel way to quantify how likely a conditional
language model will leak across domains. We also develop policy functions based
on token-level domain classification, and propose an efficient fine-tuning
method to improve the trained model's domain privacy. Experiments on membership
inference attacks show that our proposed method has comparable resiliency to
methods adapted from recent literature on differentially private language
models.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:27:12 GMT""}]","2023-05-24"
"2305.14209","Kun Qian","Kun Qian, Yuanyuan Wang, Peter Jung, Yilei Shi, and Xiao Xiang Zhu","Basis Pursuit Denoising via Recurrent Neural Network Applied to
  Super-resolving SAR Tomography",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding sparse solutions of underdetermined linear systems commonly requires
the solving of L1 regularized least squares minimization problem, which is also
known as the basis pursuit denoising (BPDN). They are computationally expensive
since they cannot be solved analytically. An emerging technique known as deep
unrolling provided a good combination of the descriptive ability of neural
networks, explainable, and computational efficiency for BPDN. Many unrolled
neural networks for BPDN, e.g. learned iterative shrinkage thresholding
algorithm and its variants, employ shrinkage functions to prune elements with
small magnitude. Through experiments on synthetic aperture radar tomography
(TomoSAR), we discover the shrinkage step leads to unavoidable information loss
in the dynamics of networks and degrades the performance of the model. We
propose a recurrent neural network (RNN) with novel sparse minimal gated units
(SMGUs) to solve the information loss issue. The proposed RNN architecture with
SMGUs benefits from incorporating historical information into optimization, and
thus effectively preserves full information in the final output. Taking TomoSAR
inversion as an example, extensive simulations demonstrated that the proposed
RNN outperforms the state-of-the-art deep learning-based algorithm in terms of
super-resolution power as well as generalization ability. It achieved a 10% to
20% higher double scatterers detection rate and is less sensitive to phase and
amplitude ratio differences between scatterers. Test on real TerraSAR-X
spotlight images also shows a high-quality 3-D reconstruction of the test site.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:28:02 GMT""}]","2023-05-24"
"2305.14210","Shengnan An","Shengnan An, Bo Zhou, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng,
  Weizhu Chen and Jian-Guang Lou","Skill-Based Few-Shot Selection for In-Context Learning","18 pages, 6 figures",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In-Context learning is the paradigm that adapts large language models to
downstream tasks by providing a few examples. Few-shot selection -- selecting
appropriate examples for each test instance separately -- is important for
in-context learning. In this paper, we propose Skill-KNN, a skill-based
few-shot selection method for in-context learning. The key advantages of
Skill-KNN include: (1) it addresses the problem that existing methods based on
pre-trained embeddings can be easily biased by surface natural language
features that are not important for the target task; (2) it does not require
training or fine-tuning of any models, making it suitable for frequently
expanding or changing example banks. The key insight is to optimize the inputs
fed into the embedding model, rather than tuning the model itself. Technically,
Skill-KNN generates the skill-based representations for each test case and
candidate example by utilizing a pre-processing few-shot prompting, thus
eliminating unimportant surface features. Experimental results across four
cross-domain semantic parsing tasks and four backbone models show that
Skill-KNN significantly outperforms existing methods.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:28:29 GMT""}]","2023-05-24"
"2305.14211","Yixuan Weng","Minjun Zhu, Yixuan Weng, Shizhu He, Kang Liu, Jun Zhao","Towards Graph-hop Retrieval and Reasoning in Complex Question Answering
  over Textual Database",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Textual question answering (TQA) systems, complex questions often require
retrieving multiple textual fact chains with multiple reasoning steps. While
existing benchmarks are limited to single-chain or single-hop retrieval
scenarios. In this paper, we propose to conduct Graph-Hop -- a novel
multi-chains and multi-hops retrieval and reasoning paradigm in complex
question answering. We construct a new benchmark called ReasonGraphQA, which
provides explicit and fine-grained evidence graphs for complex questions to
support interpretable reasoning, comprehensive and detailed reasoning. And
ReasonGraphQA also shows an advantage in reasoning diversity and scale.
Moreover, We propose a strong graph-hop baseline called Bidirectional Graph
Retrieval (BGR) method for generating an explanation graph of textual evidence
in knowledge reasoning and question answering. We have thoroughly evaluated
existing evidence retrieval and reasoning models on the ReasonGraphQA.
Experiments highlight Graph-Hop is a promising direction for answering complex
questions, but it still has certain limitations. We have further studied
mitigation strategies to meet these challenges and discuss future directions.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:28:42 GMT""}]","2023-05-24"
"2305.14212","Anthony Bahri","A.Bahri, M. Bendersky, F.R. Cohen and S. Gitler","Symmetric Products and a Cartan-type formula for polyhedral products","arXiv admin note: substantial text overlap with arXiv:2009.06818",,,,"math.AT math.CO","http://creativecommons.org/licenses/by/4.0/","  We give a geometric method for determining the cohomology groups of a
polyhedral product under suitable freeness conditions or with coefficients
taken in a field. This is done by considering first the special case for which
the pairs of spaces are wedge decomposable. We derive a decomposition for these
polyhedral products which resembles a Cartan formula. The theory of symmetric
products is used then to generalize the result to polyhedral products involving
arbitrary pairs. This leads to a direct computation of the Hilbert-Poincar\'e
series and to other applications.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:29:53 GMT""}]","2023-05-24"
"2305.14213","Griffin Kearney","Griffin M. Kearney, Kasey M. Laurent, Reece V. Kearney","Maximum Likelihood Filtering for Particle Tracking in Turbulent Flows","16 Pages, 6 Figures, Pre-print",,,,"physics.flu-dyn math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Lagrangian Particle Tracking (LPT) enables practitioners to study various
concepts in turbulence by measuring particle positions in flows of interest.
This data is subject to measurement errors, and filtering techniques are
applied to mitigate these errors and improve the accuracy of analyses utilizing
the data. We develop a new type of position filter through use of maximum
likelihood estimation by considering both measurement errors and stochastic
process physics. The maximum likelihood estimation scheme we develop is general
and can accommodate many different stochastic process models, enabling it to be
applied to many different turbulent flows. In this work, we propose a process
model similar to existing, complimentary work in the development of B-splines.
We compare our filtering scheme to existing schemes and find that our filter
out performs the scheme proposed by Mordant et al. (2004) considerably, and
produces similar performance to spline filters, proposed by Gesemann (2018). In
comparing to the latter, we note that the maximum likelihood treatment provides
a general framework which is capable of producing different filters based on
the physics of interest, whereas the spline filters are built on less specific
filtering theory and are therefore more difficult to adapt across diverse use
cases in fluids. We quantify the performance of each of the filtering methods
using error metrics which consider both noise reduction as well as signal
degradation, and together these are used to define a concept of filter
efficiency. The maximum likelihood filter developed in this work is shown to be
the most efficient among all the methods examined when applied to simulated
isotropic turbulence data from the Johns Hopkins Database.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:31:04 GMT""}]","2023-05-24"
"2305.14214","Benjamin Minixhofer","Benjamin Minixhofer, Jonas Pfeiffer, Ivan Vuli\'c","CompoundPiece: Evaluating and Improving Decompounding Performance of
  Language Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While many languages possess processes of joining two or more words to create
compound words, previous studies have been typically limited only to languages
with excessively productive compound formation (e.g., German, Dutch) and there
is no public dataset containing compound and non-compound words across a large
number of languages. In this work, we systematically study decompounding, the
task of splitting compound words into their constituents, at a wide scale. We
first address the data gap by introducing a dataset of 255k compound and
non-compound words across 56 diverse languages obtained from Wiktionary. We
then use this dataset to evaluate an array of Large Language Models (LLMs) on
the decompounding task. We find that LLMs perform poorly, especially on words
which are tokenized unfavorably by subword tokenization. We thus introduce a
novel methodology to train dedicated models for decompounding. The proposed
two-stage procedure relies on a fully self-supervised objective in the first
stage, while the second, supervised learning stage optionally fine-tunes the
model on the annotated Wiktionary data. Our self-supervised models outperform
the prior best unsupervised decompounding models by 13.9% accuracy on average.
Our fine-tuned models outperform all prior (language-specific) decompounding
tools. Furthermore, we use our models to leverage decompounding during the
creation of a subword tokenizer, which we refer to as CompoundPiece.
CompoundPiece tokenizes compound words more favorably on average, leading to
improved performance on decompounding over an otherwise equivalent model using
SentencePiece tokenization.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:32:27 GMT""}]","2023-05-24"
"2305.14215","Chang-Yu Tai","Chang-You Tai, Ziru Chen, Tianshu Zhang, Xiang Deng and Huan Sun","Exploring Chain-of-Thought Style Prompting for Text-to-SQL",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional supervised approaches for text-to-SQL parsing often require
large amounts of annotated data, which is costly to obtain in practice.
Recently, in-context learning with large language models (LLMs) has caught
increasing attention due to its superior few-shot performance in a wide range
of tasks. However, most attempts to use in-context learning for text-to-SQL
parsing still lag behind supervised methods. We hypothesize that the
under-performance is because text-to-SQL parsing requires complex, multi-step
reasoning. In this paper, we systematically study how to enhance the reasoning
ability of LLMs for text-to-SQL parsing through chain-of-thought (CoT) style
promptings including CoT prompting and Least-to-Most prompting. Our experiments
demonstrate that iterative prompting as in Least-to-Most prompting may be
unnecessary for text-to-SQL parsing and directly applying existing CoT style
prompting methods leads to error propagation issues. By improving multi-step
reasoning while avoiding much detailed information in the reasoning steps which
may lead to error propagation, our new method outperforms existing ones by 2.4
point absolute gains on the Spider development set.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:32:36 GMT""}]","2023-05-24"
"2305.14216","Chengbin Xuan","Chengbin Xuan, Feng Zhang, Faliang Yin, Hak-Keung Lam","Constrained Proximal Policy Optimization",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of constrained reinforcement learning (CRL) holds significant
importance as it provides a framework for addressing critical safety
satisfaction concerns in the field of reinforcement learning (RL). However,
with the introduction of constraint satisfaction, the current CRL methods
necessitate the utilization of second-order optimization or primal-dual
frameworks with additional Lagrangian multipliers, resulting in increased
complexity and inefficiency during implementation. To address these issues, we
propose a novel first-order feasible method named Constrained Proximal Policy
Optimization (CPPO). By treating the CRL problem as a probabilistic inference
problem, our approach integrates the Expectation-Maximization framework to
solve it through two steps: 1) calculating the optimal policy distribution
within the feasible region (E-step), and 2) conducting a first-order update to
adjust the current policy towards the optimal policy obtained in the E-step
(M-step). We establish the relationship between the probability ratios and KL
divergence to convert the E-step into a convex optimization problem.
Furthermore, we develop an iterative heuristic algorithm from a geometric
perspective to solve this problem. Additionally, we introduce a conservative
update mechanism to overcome the constraint violation issue that occurs in the
existing feasible region method. Empirical evaluations conducted in complex and
uncertain environments validate the effectiveness of our proposed method, as it
performs at least as well as other baselines.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:33:55 GMT""}]","2023-05-24"
"2305.14217","Stefaan Vaes","Amine Marrakchi and Stefaan Vaes","Ergodic states on type III$_1$ factors and ergodic actions",,,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the early days of Tomita-Takesaki theory, it is known that a von
Neumann algebra $M$ that admits a state $\varphi$ with trivial centralizer
$M_\varphi$ must be a type III$_1$ factor, but the converse remained open. We
solve this problem and prove that such ergodic states form a dense $G_\delta$
set among all faithful normal states on any III$_1$ factor with separable
predual. Through Connes' Radon-Nikodym cocycle theorem, this problem is related
to the existence of ergodic cocycle perturbations for outer group actions,
which we consider in the second part of the paper.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:33:55 GMT""}]","2023-05-24"
"2305.14218","Kriti Aggarwal","Kriti Aggarwal, Aditi Khandelwal, Kumar Tanmay, Owais Mohammed Khan,
  Qiang Liu, Monojit Choudhury, Hardik Hansrajbhai Chauhan, Subhojit Som,
  Vishrav Chaudhary, Saurabh Tiwary","DUBLIN -- Document Understanding By Language-Image Network",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Visual document understanding is a complex task that involves analyzing both
the text and the visual elements in document images. Existing models often rely
on manual feature engineering or domain-specific pipelines, which limit their
generalization ability across different document types and languages. In this
paper, we propose DUBLIN, which is pretrained on web pages using three novel
objectives: Masked Document Content Generation Task, Bounding Box Task, and
Rendered Question Answering Task, that leverage both the spatial and semantic
information in the document images. Our model achieves competitive or
state-of-the-art results on several benchmarks, such as Web-Based Structural
Reading Comprehension, Document Visual Question Answering, Key Information
Extraction, Diagram Understanding, and Table Question Answering. In particular,
we show that DUBLIN is the first pixel-based model to achieve an EM of 77.75
and F1 of 84.25 on the WebSRC dataset. We also show that our model outperforms
the current pixel-based SoTA models on DocVQA and AI2D datasets by 2% and 21%,
respectively. Also, DUBLIN is the first ever pixel-based model which achieves
comparable performance to text-based SoTA methods on XFUND dataset for Semantic
Entity Recognition showcasing its multilingual capability. Moreover, we create
new baselines for text-based datasets by rendering them as document images to
promote research in this direction.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:34:09 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 07:03:56 GMT""}]","2023-05-25"
"2305.14219","Edmund Chadwick Dr","Edmund Chadwick","Existence, Smoothness and Uniqueness (in smooth space) of the
  Navier-Stokes equation by using a new Boundary Integral representation","36 pages, 9 figures",,,,"math.AP math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Consider an exterior space-time domain where the incompressible Navier-Stokes
equation and continuity equation hold with no bodies or force fields present,
and smooth velocity at initial time. This is equivalent to the velocity being
impulsively instantaneously started into motion and further assume that this
force impulse is bounded. A smooth solution with a Stokeslet far-field decay
for all subsequent time is sought and found, demonstrating existence and
smoothness. This is given by a space-time boundary integral velocity
representation by a single layer potential linear distribution of Navier-Stokes
fundamental solutions called NSlets. This is obtained by extending the theory
of hydrodynamic potentials to also include a non-linear potential that
subsequently drops out of the formulation. Zero initial velocity gives the null
solution and so there can be only one smooth solution demonstrating uniqueness
in smooth space, but this is not to say that there are not other possible
solutions in the wider class of non-smooth spaces.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:34:40 GMT""}]","2023-05-24"
"2305.14220","Jiayin Dong","Jiayin Dong and Daniel Foreman-Mackey","A Hierarchical Bayesian Framework for Inferring the Stellar Obliquity
  Distribution","10 pages, 6 figures; AJ submitted, revised in response to the referee
  report; reproducible workflow built with showyourwork; open-source code can
  be found at https://github.com/jiayindong/obliquity",,,,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stellar obliquity, the angle between a planet's orbital axis and its host
star's spin axis, traces the formation and evolution of a planetary system. In
transiting exoplanet observations, only the sky-projected stellar obliquity can
be measured, but this can be de-projected using an estimate of the stellar
obliquity. In this paper, we introduce a flexible, hierarchical Bayesian
framework that can be used to infer the stellar obliquity distribution solely
from sky-projected stellar obliquities, including stellar inclination
measurements when available. We demonstrate that while a constraint on the
stellar inclination is crucial for measuring the obliquity of an individual
system, it is not required for robust determination of the population-level
stellar obliquity distribution. In practice, the constraints on the stellar
obliquity distribution are mainly driven by the sky-projected stellar
obliquities.
  When applying the framework to all systems with measured sky-projected
stellar obliquity, which are mostly Hot Jupiter systems, we find that the
inferred population-level obliquity distribution is unimodal and peaked at zero
degrees. The misaligned systems have nearly isotropic stellar obliquities with
no strong clustering near 90 degrees. The diverse range of stellar obliquities
prefers dynamic mechanisms, such as planet-planet scattering after a convergent
disk migration, which could produce both prograde and retrograde orbits of
close-in planets with no strong inclination concentrations other than 0
degrees.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:35:08 GMT""}]","2023-05-24"
"2305.14221","Xinyu Zhu","Xinyu Zhu, Cheng Yang, Bei Chen, Siheng Li, Jian-Guang Lou, Yujiu Yang","Question Answering as Programming for Solving Time-Sensitive Questions",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we try to apply Large Language Models (LLMs) to reframe the
Question Answering task as Programming (QAaP). Due to the inherent dynamic
nature of the real world, factual questions frequently involve a symbolic
constraint: time, solving these questions necessitates not only extensive world
knowledge, but also advanced reasoning ability to satisfy the temporal
constraints. Despite the remarkable intelligence exhibited by LLMs in various
NLP tasks, our experiments reveal that the aforementioned problems continue to
pose a significant challenge to existing LLMs. To solve these time-sensitive
factual questions, considering that modern LLMs possess superior ability in
both natural language understanding and programming,we endeavor to leverage
LLMs to represent diversely expressed text as well-structured code, and thereby
grasp the desired knowledge along with the underlying symbolic constraint.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:35:16 GMT""}]","2023-05-24"
"2305.14223","Max Smith","Max Olan Smith, Michael P. Wellman","Co-Learning Empirical Games and World Models",,,,,"cs.MA cs.AI cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Game-based decision-making involves reasoning over both world dynamics and
strategic interactions among the agents. Typically, empirical models capturing
these respective aspects are learned and used separately. We investigate the
potential gain from co-learning these elements: a world model for dynamics and
an empirical game for strategic interactions. Empirical games drive world
models toward a broader consideration of possible game dynamics induced by a
diversity of strategy profiles. Conversely, world models guide empirical games
to efficiently discover new strategies through planning. We demonstrate these
benefits first independently, then in combination as realized by a new
algorithm, Dyna-PSRO, that co-learns an empirical game and a world model. When
compared to PSRO -- a baseline empirical-game building algorithm, Dyna-PSRO is
found to compute lower regret solutions on partially observable general-sum
games. In our experiments, Dyna-PSRO also requires substantially fewer
experiences than PSRO, a key algorithmic advantage for settings where
collecting player-game interaction data is a cost-limiting factor.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:37:21 GMT""}]","2023-05-24"
"2305.14224","Jonas Pfeiffer","Jonas Pfeiffer, Francesco Piccinno, Massimo Nicosia, Xinyi Wang,
  Machel Reid, Sebastian Ruder","mmT5: Modular Multilingual Pre-Training Solves Source Language
  Hallucinations",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multilingual sequence-to-sequence models perform poorly with increased
language coverage and fail to consistently generate text in the correct target
language in few-shot settings. To address these challenges, we propose mmT5, a
modular multilingual sequence-to-sequence model. mmT5 utilizes
language-specific modules during pre-training, which disentangle
language-specific information from language-agnostic information. We identify
representation drift during fine-tuning as a key limitation of modular
generative models and develop strategies that enable effective zero-shot
transfer. Our model outperforms mT5 at the same parameter sizes by a large
margin on representative natural language understanding and generation tasks in
40+ languages. Compared to mT5, mmT5 raises the rate of generating text in the
correct language under zero-shot settings from 7% to 99%, thereby greatly
alleviating the source language hallucination problem.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:38:01 GMT""}]","2023-05-24"
"2305.14225","Kung-Hsiang Huang","Kung-Hsiang Huang, Hou Pong Chan, Kathleen McKeown, Heng Ji","ManiTweet: A New Benchmark for Identifying Manipulation of News on
  Social Media",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Considerable advancements have been made to tackle the misrepresentation of
information derived from reference articles in the domains of fact-checking and
faithful summarization. However, an unaddressed aspect remains - the
identification of social media posts that manipulate information within
associated news articles. This task presents a significant challenge, primarily
due to the prevalence of personal opinions in such posts. We present a novel
task, identifying manipulation of news on social media, which aims to detect
manipulation in social media posts and identify manipulated or inserted
information. To study this task, we have proposed a data collection schema and
curated a dataset called ManiTweet, consisting of 3.6K pairs of tweets and
corresponding articles. Our analysis demonstrates that this task is highly
challenging, with large language models (LLMs) yielding unsatisfactory
performance. Additionally, we have developed a simple yet effective basic model
that outperforms LLMs significantly on the ManiTweet dataset. Finally, we have
conducted an exploratory analysis of human-written tweets, unveiling intriguing
connections between manipulation and the domain and factuality of news
articles, as well as revealing that manipulated sentences are more likely to
encapsulate the main story or consequences of a news outlet.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:40:07 GMT""}]","2023-05-24"
"2305.14226","Gernot Alber","Maximilian Schumacher, Gernot Alber","Bipartite entanglement detection by local generalized measurements",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Entanglement detection by local measurements, which can possibly be performed
by far distant observers, are of particular interest for applications in
quantum key distribution and quantum communication. In this paper sufficient
conditions for arbitrary dimensional bipartite entanglement detection based on
correlation matrices and joint probability distributions of such local
measurements are investigated. In particular, their dependence on the nature of
the local measurements is explored for typical bipartite quantum states and for
measurements involving local orthonormal hermitian operators bases (LOOs) or
generalized measurements based on informationally complete positive operator
valued measures of the recently introduced $(N,M)$-type ($(N,M)$-POVMs)
\cite{NMPOVM}. It is shown that symmetry properties of $(N,M)$-POVMs imply that
sufficient conditions for bipartite entanglement detection exhibit peculiar
scaling properties relating different equally efficient local entanglement
detection scenarios. For correlation-matrix based bipartite local entanglement
detection, for example, this has the consequence that LOOs and all
informationally complete $(N,M)$-POVMs are equally powerful. With the help of a
hit-and-run Monte-Carlo algorithm the effectiveness of local entanglement
detection of typical bipartite quantum states is explored numerically. For this
purpose Euclidean volume ratios between locally detectable entangled states and
all bipartite quantum states are determined.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:40:48 GMT""}]","2023-05-24"
"2305.14227","Vladimir V Kisil","Vladimir V. Kisil","Transmutations from the Covariant Transform on the Heisenberg Group and
  an Extended Umbral Principle","16 pages, RevTex",,,,"math.AP math.CO math.FA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We discuss several seemingly assorted objects: the umbral calculus,
generalised translations and associated transmutations, symbolic calculus of
operators. The common framework for them is representations of the Weyl algebra
of the Heisenberg group by ladder operators. Transporting various properties
between different implementations we review some classic results and new
opportunities.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:44:43 GMT""}]","2023-05-24"
"2305.14228","Matthias Stiefenhofer","Matthias Stiefenhofer","Formal and Analytic Diagonalization of Operator functions","54 pages, 2 figures",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give conditions for local diagonalization of analytic operator families
acting between real or complex Banach spaces. The transformations are
constructed from an operator Toeplitz matrix obtained from Jordan chains of
increasing length. The basic assumption is given by stabilization of the Jordan
chains at length k in the sense that no root elements with finite rank above k
are allowed to exist. Jordan chains with infinite rank may appear. These
assumptions ensure finite pole order equal to k of the generalized inverse. The
Smith form arises immediately.
  Smooth continuation of kernels and ranges towards appropriate limit spaces is
considered using associated families of analytic projection functions. No
Fredholm properties or other finiteness assumptions, besides the pole order,
are assumed. Real and complex Banach spaces are treated without difference by
elementary analysis of the system of undetermined coefficients.
  Formal power series solutions of the system of undetermined coefficients are
constructed, which are turning into convergent solutions, as soon as
analyticity of the operator family and continuity of the projections is
assumed. Along these lines, results concerning linear Artin approximation
follow immediately, which are well known in finite dimensions. The main
technical tool is given by a defining equation of Nakayama Lemma type.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:44:46 GMT""}]","2023-05-24"
"2305.14229","Jack Brady","Jack Brady, Roland S. Zimmermann, Yash Sharma, Bernhard Sch\""olkopf,
  Julius von K\""ugelgen, Wieland Brendel","Provably Learning Object-Centric Representations","Oral at ICML 2023. The first two authors as well as the last two
  authors contributed equally. Code is available at
  https://brendel-group.github.io/objects-identifiability",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning structured representations of the visual world in terms of objects
promises to significantly improve the generalization abilities of current
machine learning models. While recent efforts to this end have shown promising
empirical progress, a theoretical account of when unsupervised object-centric
representation learning is possible is still lacking. Consequently,
understanding the reasons for the success of existing object-centric methods as
well as designing new theoretically grounded methods remains challenging. In
the present work, we analyze when object-centric representations can provably
be learned without supervision. To this end, we first introduce two assumptions
on the generative process for scenes comprised of several objects, which we
call compositionality and irreducibility. Under this generative process, we
prove that the ground-truth object representations can be identified by an
invertible and compositional inference model, even in the presence of
dependencies between objects. We empirically validate our results through
experiments on synthetic data. Finally, we provide evidence that our theory
holds predictive power for existing object-centric models by showing a close
correspondence between models' compositionality and invertibility and their
empirical identifiability.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:44:49 GMT""}]","2023-05-24"
"2305.14230","Neha Verma","Neha Verma, Kenton Murray, Kevin Duh","Exploring Representational Disparities Between Multilingual and
  Bilingual Translation Models",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Multilingual machine translation has proven immensely useful for low-resource
and zero-shot language pairs. However, language pairs in multilingual models
sometimes see worse performance than in bilingual models, especially when
translating in a one-to-many setting. To understand why, we examine the
geometric differences in the representations from bilingual models versus those
from one-to-many multilingual models. Specifically, we evaluate the isotropy of
the representations, to measure how well they utilize the dimensions in their
underlying vector space. Using the same evaluation data in both models, we find
that multilingual model decoder representations tend to be less isotropic than
bilingual model decoder representations. Additionally, we show that much of the
anisotropy in multilingual decoder representations can be attributed to
modeling language-specific information, therefore limiting remaining
representational capacity.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:46:18 GMT""}]","2023-05-24"
"2305.14231","Shuo Yang","Yuchen Guo, Jian-Hao Zhang, Zhen Bi, Shuo Yang","Triggering Boundary Phase Transitions through Bulk Measurements in 2D
  Cluster States","7 pages, 6 figures",,,,"quant-ph cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We investigate the phase diagram at the boundary of an infinite
two-dimensional cluster state subject to bulk measurements using tensor network
methods. The state is subjected to uniform measurements $M =
\cos{\theta}Z+\sin{\theta}X$ on the lower boundary qubits and all bulk qubits.
Our results show that the boundary of the system exhibits volume-law
entanglement at the measurement angle $\theta = \pi/2$ and area-law
entanglement for any $\theta < \pi/2$. Within the area-law phase, a phase
transition occurs at $\theta_c=1.371$. The phase with $\theta
\in(\theta_c,\pi/2)$ is characterized by a non-injective matrix product state,
which cannot be realized as the unique ground state of a 1D local, gapped
Hamiltonian. Instead, it resembles a cat state with spontaneous symmetry
breaking. These findings demonstrate that the phase diagram of the boundary of
a two-dimensional system can be more intricate than that of a standard
one-dimensional system.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:46:32 GMT""}]","2023-05-24"
"2305.14232","Yu Zhang","Yu Zhang, Hao Cheng, Zhihong Shen, Xiaodong Liu, Ye-Yi Wang, Jianfeng
  Gao","Pre-training Multi-task Contrastive Learning Models for Scientific
  Literature Understanding","15 pages",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scientific literature understanding tasks have gained significant attention
due to their potential to accelerate scientific discovery. Pre-trained language
models (LMs) have shown effectiveness in these tasks, especially when tuned via
contrastive learning. However, jointly utilizing pre-training data across
multiple heterogeneous tasks (e.g., extreme classification, citation
prediction, and literature search) remains largely unexplored. To bridge this
gap, we propose a multi-task contrastive learning framework, SciMult, with a
focus on facilitating common knowledge sharing across different scientific
literature understanding tasks while preventing task-specific skills from
interfering with each other. To be specific, we explore two techniques --
task-aware specialization and instruction tuning. The former adopts a
Mixture-of-Experts Transformer architecture with task-aware sub-layers; the
latter prepends task-specific instructions to the input text so as to produce
task-aware outputs. Extensive experiments on a comprehensive collection of
benchmark datasets verify the effectiveness of our task-aware specialization
strategy in various tasks, where we outperform state-of-the-art scientific LMs.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:47:22 GMT""}]","2023-05-24"
"2305.14233","Ning Ding","Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu,
  Zhiyuan Liu, Maosong Sun, Bowen Zhou","Enhancing Chat Language Models by Scaling High-quality Instructional
  Conversations",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-tuning on instruction data has been widely validated as an effective
practice for implementing chat language models like ChatGPT. Scaling the
diversity and quality of such data, although straightforward, stands a great
chance of leading to improved performance. This paper aims to improve the upper
bound of open-source models further. We first provide a systematically
designed, diverse, informative, large-scale dataset of instructional
conversations, UltraChat, which does not involve human queries. Our objective
is to capture the breadth of interactions that a human might have with an AI
assistant and employs a comprehensive framework to generate multi-turn
conversation iteratively. UltraChat contains 1.5 million high-quality
multi-turn dialogues and covers a wide range of topics and instructions. Our
statistical analysis of UltraChat reveals its superiority in various key
metrics, including scale, average length, diversity, coherence, etc.,
solidifying its position as a leading open-source dataset. Building upon
UltraChat, we fine-tune a LLaMA model to create a powerful conversational
model, UltraLLaMA. Our evaluations indicate that UltraLLaMA consistently
outperforms other open-source models, including Vicuna, the previously
recognized state-of-the-art open-source model. The dataset and the model will
be publicly released\footnote{\url{https://github.com/thunlp/UltraChat}}.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:49:14 GMT""}]","2023-05-24"
"2305.14234","Mingyi Hou","Benny Avelin, Mingyi Hou and Kaj Nystr\""om","A Galerkin type method for kinetic Fokker Planck equations based on
  Hermite expansions","24 pages, corrected the reference list",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we develop a Galerkin-type approximation, with quantitative
error estimates, for weak solutions to the Cauchy problem for kinetic
Fokker-Planck equations in the domain $(0, T) \times D \times \mathbb{R}^d$,
where $D$ is either $\mathbb{T}^d$ or $\mathbb{R}^d$. Our approach is based on
a Hermite expansion in the velocity variable only, with a hyperbolic system
that appears as the truncation of the Brinkman hierarchy, as well as ideas from
$\href{arXiv:1902.04037v2}{Alb+21}$ and additional energy-type estimates that
we have developed. We also establish the regularity of the solution based on
the regularity of the initial data and the source term.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:49:58 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 06:44:29 GMT""}]","2023-05-26"
"2305.14235","Ruochen Zhang","Ruochen Zhang, Samuel Cahyawijaya, Jan Christian Blaise Cruz and Alham
  Fikri Aji","Multilingual Large Language Models Are Not (Yet) Code-Switchers",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Multilingual Large Language Models (LLMs) have recently shown great
capability in various tasks, exhibiting state-of-the-art performance using
few-shot or zero-shot prompting methods. While these models have been
extensively studied in tasks where inputs are assumed to be in a single
language, less attention has been paid to exploring their performance when
inputs involve code-switching (CSW). In this paper, we provide an extensive
empirical study of various multilingual LLMs and benchmark their performance in
three tasks: sentiment analysis, machine translation, and word-level language
identification. Our findings indicate that despite multilingual LLMs showing
promising outcomes in certain tasks when using zero-/few-shot prompting, their
performance still falls short on average when compared to smaller finetuned
models. We argue that LLMs that are ""multilingual"" are not necessarily
code-switching compatible and extensive future research is required to fully
bridge this gap.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:50:48 GMT""}]","2023-05-24"
"2305.14236","Lingteng Qiu","Lingteng Qiu, Guanying Chen, Jiapeng Zhou, Mutian Xu, Junle Wang and
  Xiaoguang Han","REC-MV: REconstructing 3D Dynamic Cloth from Monocular Videos","CVPR2023; Project Page:https://lingtengqiu.github.io/2023/REC-MV/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reconstructing dynamic 3D garment surfaces with open boundaries from
monocular videos is an important problem as it provides a practical and
low-cost solution for clothes digitization. Recent neural rendering methods
achieve high-quality dynamic clothed human reconstruction results from
monocular video, but these methods cannot separate the garment surface from the
body. Moreover, despite existing garment reconstruction methods based on
feature curve representation demonstrating impressive results for garment
reconstruction from a single image, they struggle to generate temporally
consistent surfaces for the video input. To address the above limitations, in
this paper, we formulate this task as an optimization problem of 3D garment
feature curves and surface reconstruction from monocular video. We introduce a
novel approach, called REC-MV, to jointly optimize the explicit feature curves
and the implicit signed distance field (SDF) of the garments. Then the open
garment meshes can be extracted via garment template registration in the
canonical space. Experiments on multiple casually captured datasets show that
our approach outperforms existing methods and can produce high-quality dynamic
garment surfaces. The source code is available at
https://github.com/GAP-LAB-CUHK-SZ/REC-MV.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:53:10 GMT""},{""version"":""v2"",""created"":""Sat, 27 May 2023 17:01:54 GMT""}]","2023-05-30"
"2305.14237","Wenting Zhao","Wenting Zhao and Justin T. Chiu and Claire Cardie and Alexander M.
  Rush","HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale
  Supervision",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Explainable multi-hop question answering (QA) not only predicts answers but
also identifies rationales, i. e. subsets of input sentences used to derive the
answers. This problem has been extensively studied under the supervised
setting, where both answer and rationale annotations are given. Because
rationale annotations are expensive to collect and not always available, recent
efforts have been devoted to developing methods that do not rely on supervision
for rationales. However, such methods have limited capacities in modeling
interactions between sentences, let alone reasoning across multiple documents.
This work proposes a principled, probabilistic approach for training
explainable multi-hop QA systems without rationale supervision. Our approach
performs multi-hop reasoning by explicitly modeling rationales as sets,
enabling the model to capture interactions between documents and sentences
within a document. Experimental results show that our approach is more accurate
at selecting rationales than the previous methods, while maintaining similar
accuracy in predicting answers.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:53:49 GMT""}]","2023-05-24"
"2305.14238","Rocco D'Agostino","Rocco D'Agostino, Matteo Califano, Nicola Menadeo, Daniele Vernieri","The role of spatial curvature in the primordial gravitational wave power
  spectrum","14 pages, 4 figures",,,"ET-0162A-23","astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the effects of non-vanishing spatial curvature on the
propagation of primordial gravitational waves produced during inflation. In
particular, we consider tensor perturbations over a homogeneous and isotropic
background, and describe the propagation of gravitational waves in the de
Sitter phase with spatially curved geometries. We thus derive the expression of
the primordial power spectrum at the horizon crossing, in the case of open and
closed universes. Then, we analyze how tensor modes propagate in the
post-inflationary era, showing the evolution of transfer functions in the
radiation and matter epochs, as well as the matching conditions in the
intermediate regime. To account for the intrinsic nature of different
relativistic species, we also explore the corrections to the standard behavior
of the radiation energy density. For this purpose, we introduce the effective
number of degrees of freedom of relativistic particles contributing to the
primordial energy and entropy densities. Under the subhorizon approximation, we
obtain the spectral energy density of relic gravitational waves in terms of the
curvature density parameter. Finally, we discuss the capability of present and
future experiments to detect the primordial gravitational wave signal at
different frequency regimes.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:54:09 GMT""}]","2023-05-24"
"2305.14239","Yixin Liu","Yixin Liu, Alexander R. Fabbri, Pengfei Liu, Dragomir Radev, Arman
  Cohan","On Learning to Summarize with Large Language Models as References","GitHub Repo: https://github.com/yixinL7/SumLLM",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies have found that summaries generated by large language models
(LLMs) are favored by human annotators over the original reference summaries in
commonly used summarization datasets. Therefore, we investigate a new learning
paradigm of text summarization models that considers the LLMs as the reference
or the gold-standard oracle on commonly used summarization datasets such as the
CNN/DailyMail dataset. To examine the standard practices that are aligned with
the new learning setting, we propose a novel training method that is based on
contrastive learning with LLMs as a summarization quality evaluator. For this
reward-based training method, we investigate two different methods of utilizing
LLMs for summary quality evaluation, namely GPTScore and GPTRank. Our
experiments on the CNN/DailyMail dataset demonstrate that smaller summarization
models trained by our proposed method can achieve performance equal to or
surpass that of the reference LLMs, as evaluated by the LLMs themselves. This
underscores the efficacy of our proposed paradigm in enhancing model
performance over the standard maximum likelihood estimation (MLE) training
method, and its efficiency since it only requires a small budget to access the
LLMs. We release the training scripts, model outputs, and LLM-based evaluation
results to facilitate future studies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:56:04 GMT""}]","2023-05-24"
"2305.14240","Mikel Artetxe","Mikel Artetxe, Vedanuj Goswami, Shruti Bhosale, Angela Fan, Luke
  Zettlemoyer","Revisiting Machine Translation for Cross-lingual Classification",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Translation (MT) has been widely used for cross-lingual
classification, either by translating the test set into English and running
inference with a monolingual model (translate-test), or translating the
training set into the target languages and finetuning a multilingual model
(translate-train). However, most research in the area focuses on the
multilingual models rather than the MT component. We show that, by using a
stronger MT system and mitigating the mismatch between training on original
text and running inference on machine translated text, translate-test can do
substantially better than previously assumed. The optimal approach, however, is
highly task dependent, as we identify various sources of cross-lingual transfer
gap that affect different tasks and approaches differently. Our work calls into
question the dominance of multilingual models for cross-lingual classification,
and prompts to pay more attention to MT-based baselines.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:56:10 GMT""}]","2023-05-24"
"2305.14241","Lucien Hardy","Saba Etezad-Razavi and Lucien Hardy","Paradox with Phase-Coupled Interferometers","Comments welcome",,,,"quant-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  A pair of interferometers can be coupled by allowing one path from each to
overlap such that if the particles meet in this overlap region, they
annihilate. It was shown by one of us over thirty years ago that such
annihilation-coupled interferometers can exhibit apparently paradoxical
behaviour. More recently, Bose et al. and Marletto and Vedral have considered a
pair of interferometers that are phase-coupled (where the coupling is through
gravitational interaction). In this case one path from each interferometer
undergoes a phase-coupling interaction. We show that these phase-coupled
interferometers exhibit the same apparent paradox as the annihilation-coupled
interferometers, though in a curiously dual manner.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:56:48 GMT""}]","2023-05-24"
"2305.14242","Keisuke Inomata","Keisuke Harigaya, Keisuke Inomata, Takahiro Terada","Axion Poltergeist","6 pages, 4 figures (Supplemental Material: 12 pages, 3 figures)",,,"CTPU-PTC-23-19","hep-ph astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rotations of axion fields in the early universe can produce dark matter and
the matter-antimatter asymmetry of the universe. We point out that the rotation
can generate an observable amount of a stochastic gravitational-wave (GW)
background. It can be doubly enhanced in a class of models in which the
equation of state of the rotations rapidly changes from a non-relativistic
matter-like one to a kination-like one by 1) the so-called Poltergeist
mechanism and 2) slower redshift of GWs compared to the axion kination fluid.
In supersymmetric UV completion, future GW observations can probe the
supersymmetry-breaking scale up to $10^7\,$GeV even if the axion does not
directly couple to the Standard Model fields.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:58:48 GMT""}]","2023-05-24"
"2305.14243","Manuel Tran","Manuel Tran, Amal Lahiani, Yashin Dicente Cid, Fabian J. Theis,
  Tingying Peng, Eldad Klaiman","Training Transitive and Commutative Multimodal Transformers with LoReTTa","Paper will undergo a revision",,,,"cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Collecting a multimodal dataset with two paired modalities A and B or B and C
is difficult in practice. Obtaining a dataset with three aligned modalities A,
B, and C is even more challenging. For example, some public medical datasets
have only genetic sequences and microscopic images for one patient, and only
genetic sequences and radiological images for another - but no dataset includes
both microscopic and radiological images for the same patient. This makes it
difficult to integrate and combine all modalities into a large pre-trained
neural network. We introduce LoReTTa (Linking mOdalities with a tRansitive and
commutativE pre-Training sTrAtegy) to address this understudied problem. Our
self-supervised framework combines causal masked modeling with the rules of
commutativity and transitivity to transition within and between different
modalities. Thus, it can model the relation A -> C with A -> B -> C. Given a
dataset containing only the disjoint combinations (A, B) and (B, C), we show
that a transformer pre-trained with LoReTTa can handle any modality combination
at inference time, including the never-seen pair (A, C) and the triplet (A, B,
C). We evaluate our approach on a multimodal dataset derived from MNIST
containing speech, vision, and language, as well as a real-world medical
dataset containing mRNA, miRNA, and RPPA samples from TCGA. Compared to
traditional pre-training methods, we observe up to a 100-point reduction in
perplexity for autoregressive generation tasks and up to a 15% improvement in
classification accuracy for previously unseen modality pairs during the
pre-training phase.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:58:55 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 08:37:21 GMT""}]","2023-05-30"
"2305.14244","Shengchao Chen","Shengchao Chen, Guodong Long, Tao Shen, Tianyi Zhou, Jing Jiang","Spatial-temporal Prompt Learning for Federated Weather Forecasting","Under Review",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated weather forecasting is a promising collaborative learning framework
for analyzing meteorological data across participants from different countries
and regions, thus embodying a global-scale real-time weather data predictive
analytics platform to tackle climate change. This paper is to model the
meteorological data in a federated setting where many distributed low-resourced
sensors are deployed in different locations. Specifically, we model the
spatial-temporal weather data into a federated prompt learning framework that
leverages lightweight prompts to share meaningful representation and structural
knowledge among participants. Prompts-based communication allows the server to
establish the structural topology relationships among participants and further
explore the complex spatial-temporal correlations without transmitting private
data while mitigating communication overhead. Moreover, in addition to a
globally shared large model at the server, our proposed method enables each
participant to acquire a personalized model that is highly customized to tackle
climate changes in a specific geographic area. We have demonstrated the
effectiveness of our method on classical weather forecasting tasks by utilizing
three spatial-temporal multivariate time-series weather data.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 16:59:20 GMT""}]","2023-05-24"
"2305.14245","Gregorio Garc\'ia-Valladares","Gregorio Garc\'ia-Valladares, Carlos A. Plata, Antonio Prados and
  Alessandro Manacorda","Optimal resetting strategies for search processes in heterogeneous
  environments","23 pages, 9 figures",,,,"cond-mat.stat-mech cond-mat.dis-nn math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In many physical situations, there appears the problem of reaching a single
target that is spatially distributed. Here we analyse how stochastic resetting,
also spatially distributed, can be used to improve the search process when the
target location is quenched, i.e. it does not evolve in time. More
specifically, we consider a model with minimal but sufficient ingredients that
allows us to derive analytical results for the relevant physical quantities,
such as the first passage time distribution. We focus on the minimisation of
the mean first passage time and its fluctuations (standard deviation), which
proves to be non-trivial. Our analysis shows that the no-disorder case is
singular: for small disorder, the resetting rate distribution that minimises
the mean first passage time leads to diverging fluctuations -- which impinge on
the practicality of this minimisation. Interestingly, this issue is healed by
minimising the fluctuations: the associated resetting rate distribution gives
first passage times that are very close to the optimal ones.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:00:08 GMT""}]","2023-05-24"
"2305.14246","Jocelyn Shen","Jocelyn Shen, Maarten Sap, Pedro Colon-Hernandez, Hae Won Park,
  Cynthia Breazeal","Modeling Empathic Similarity in Personal Narratives",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The most meaningful connections between people are often fostered through
expression of shared vulnerability and emotional experiences in personal
narratives. We introduce a new task of identifying similarity in personal
stories based on empathic resonance, i.e., the extent to which two people
empathize with each others' experiences, as opposed to raw semantic or lexical
similarity, as has predominantly been studied in NLP. Using insights from
social psychology, we craft a framework that operationalizes empathic
similarity in terms of three key features of stories: main events, emotional
trajectories, and overall morals or takeaways. We create EmpathicStories, a
dataset of 1,500 personal stories annotated with our empathic similarity
features, and 2,000 pairs of stories annotated with empathic similarity scores.
Using our dataset, we fine-tune a model to compute empathic similarity of story
pairs, and show that this outperforms semantic similarity models on automated
correlation and retrieval metrics. Through a user study with 150 participants,
we also assess the effect our model has on retrieving stories that users
empathize with, compared to naive semantic similarity-based retrieval, and find
that participants empathized significantly more with stories retrieved by our
model. Our work has strong implications for the use of empathy-aware models to
foster human connection and empathy between people.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:00:45 GMT""}]","2023-05-24"
"2305.14247","D\'avid P\'eter Kov\'acs","David Peter Kovacs, Ilyes Batatia, Eszter Sara Arany, Gabor Csanyi","Evaluation of the MACE Force Field Architecture: from Medicinal
  Chemistry to Materials Science",,,,,"physics.chem-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The MACE architecture represents the state of the art in the field of machine
learning force fields for a variety of in-domain, extrapolation and low-data
regime tasks. In this paper, we further evaluate MACE by fitting models for
published benchmark datasets. We show that MACE generally outperforms
alternatives for a wide range of systems from amorphous carbon and general
small molecule organic chemistry to large molecules and liquid water. We
demonstrate the capabilities of the model on tasks ranging from constrained
geometry optimisation to molecular dynamics simulations and find excellent
performance across all tested domains. We show that MACE is very data
efficient, and can reproduce experimental molecular vibrational spectra when
trained on as few as 50 randomly selected reference configurations. We further
demonstrate that the strictly local atom-centered model is sufficient for such
tasks even in the case of large molecules and weakly interacting molecular
assemblies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:01:25 GMT""}]","2023-05-24"
"2305.14248","Thomas Bonis","Thomas Bonis","Improved rates of convergence for the multivariate Central Limit Theorem
  in Wasserstein distance",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We provide new bounds for rates of convergence of the multivariate Central
Limit Theorem in Wasserstein distances of order $p \geq 2$. In particular, we
obtain an asymptotic bound for measures with a continuous component which we
conjecture to be optimal.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:02:42 GMT""}]","2023-05-24"
"2305.14249","Blake Jackson","Blake Jackson","An Intersection-Dimension Formula for Preprojective Modules of Type
  $\widetilde{D}_n$","27 pages, 14 figures",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proves the existence of an intersection-dimension formula for
preprojective modules over path algebras of type $\widetilde{D}_n$. Identical
intersection-dimension formulas have previously been provided for modules over
path algebras of type $A_n, D_n,$ and $\widetilde{A}_n$ due to Schiffler as
well as He, Zhou, and Zhu. These modules can be represented geometrically by
some set of curves on special surfaces. The intersection-dimension formula is
an equality of the intersection number between two curves and the dimensions of
the first extension spaces between the two modules they represent. This paper
takes a direct approach to proving the formula utilizing the known structure of
the Auslander-Reiten quiver of type $\widetilde{D}_n$. Future work will extend
the formula to the entire module category (not just the preprojective modules)
over path algebras of type $\widetilde{D}_n$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:03:46 GMT""}]","2023-05-24"
"2305.14250","Peter Clark","Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson,
  Hinrich Schutze, Peter Clark","Language Models with Rationality",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  While large language models (LLMs) are proficient at question-answering (QA),
the dependencies between their answers and other ""beliefs"" they may have about
the world are typically unstated, and may even be in conflict. Our goal is to
uncover such dependencies and reduce inconsistencies among them, so that
answers are supported by faithful, system-believed chains of reasoning drawn
from a consistent network of beliefs. Our approach, which we call REFLEX, is to
add a ""rational"", self-reflecting layer on top of the LLM. First, given a
question, we construct a belief graph using a backward-chaining process to
materialize relevant model ""beliefs"" (including beliefs about answer
candidates) and the inferential relationships between them. Second, we identify
and minimize contradictions in that graph using a formal constraint reasoner.
We find that REFLEX significantly improves consistency (by 8%-11% absolute)
without harming overall answer accuracy, resulting in answers supported by
faithful chains of reasoning drawn from a more consistent belief system. This
suggests a new style of system architecture, in which an LLM extended with a
rational layer of self-reflection can repair latent inconsistencies within the
LLM alone.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:04:25 GMT""}]","2023-05-24"
"2305.14251","Sewon Min","Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang
  Wei Koh, Mohit Iyyer, Luke Zettlemoyer, Hannaneh Hajishirzi","FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long
  Form Text Generation","23 pages, 7 figures",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Evaluating the factuality of long-form text generated by large language
models (LMs) is non-trivial because (1) generations often contain a mixture of
supported and unsupported pieces of information, making binary judgments of
quality inadequate, and (2) human evaluation is time-consuming and costly. In
this paper, we introduce FActScore (Factual precision in Atomicity Score), a
new evaluation that breaks a generation into a series of atomic facts and
computes the percentage of atomic facts supported by a reliable knowledge
source. We conduct an extensive human evaluation to obtain FActScores of people
biographies generated by several state-of-the-art commercial LMs --
InstructGPT, ChatGPT, and the retrieval-augmented PerplexityAI -- and report
new analysis demonstrating the need for such a fine-grained score (e.g.,
ChatGPT only achieves 58%). Since human evaluation is costly, we also introduce
an automated model that estimates FActScore, using retrieval and a strong
language model, with less than a 2% error rate. Finally, we use this automated
metric to evaluate 6,500 generations from a new set of 13 recent LMs that would
have cost $26K if evaluated by humans, with various findings: GPT-4 and ChatGPT
are more factual than public models, and Vicuna and Alpaca are some of the best
public models.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:06:00 GMT""}]","2023-05-24"
"2305.14252","Andre Souto","Mariano Lemus, Ricardo Faleiro, Paulo Mateus, Nikola Paunkovi\'c,
  Andr\'e Souto","Quantum Kolmogorov complexity and quantum correlations in
  deterministic-control quantum Turing machines","31 pages",,,,"quant-ph cs.CC math-ph math.MP","http://creativecommons.org/publicdomain/zero/1.0/","  This work presents a study of Kolmogorov complexity for general quantum
states from the perspective of deterministic-control quantum Turing Machines
(dcq-TM). We extend the dcq-TM model to incorporate mixed state inputs and
outputs, and define dcq-computable states as those that can be approximated by
a dcq-TM. Moreover, we introduce (conditional) Kolmogorov complexity of quantum
states and use it to study three particular aspects of the algorithmic
information contained in a quantum state: a comparison of the information in a
quantum state with that of its classical representation as an array of real
numbers, an exploration of the limits of quantum state copying in the context
of algorithmic complexity, and study of the complexity of correlations in
quantum systems, resulting in a correlation-aware definition for algorithmic
mutual information that satisfies symmetry of information property.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:07:58 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 10:36:33 GMT""}]","2023-06-05"
"2305.14253","Chris Hughes","Christopher Hughes, Greg Martin, Andrew Pearce-Crump","A heuristic for discrete mean values of the derivative of the Riemann
  zeta function",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Shanks conjectured that $\zeta ' (\rho)$, where $\rho$ ranges over
non-trivial zeros of the Riemann zeta function, is real and positive in the
mean. We present a history of this problem, including a generalisation to all
higher-order derivatives $\zeta^{(n)}(s)$, for which the sign of the mean
alternatives between positive for odd $n$ and negative for even $n$.
Furthermore, we give a simple heuristic that provides the leading term
(including its sign) of the asymptotic formula for the average value of
$\zeta^{(n)}(\rho)$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:08:08 GMT""}]","2023-05-24"
"2305.14254","Yiyun Fan","Yiyun Fan, John Billingham, and Kristoffer van der Zee","A Shape-Newton Method for Free-boundary Problems Subject to The
  Bernoulli Boundary Condition",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We develop a shape-Newton method for solving generic free-boundary problems
where one of the free-boundary conditions is governed by the Bernoulli
equation. The Newton-like scheme is developed by employing shape derivatives in
the weak forms, which allows us to update the position of the free surface and
the potential on the free boundary by solving a boundary-value problem at each
iteration. To validate the effectiveness of the approach, we apply the scheme
to solve a problem involving the flow over a submerged triangular obstacle.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:09:14 GMT""}]","2023-05-24"
"2305.14255","Tanchumin Xu","Tanchumin Xu, Yunshu Zhang and Shu Yang","Augmented match weighted estimators for average treatment effects",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Propensity score matching (PSM) and augmented inverse propensity weighting
(AIPW) are widely used in observational studies to estimate causal effects. The
two approaches present complementary features. The AIPW estimator is doubly
robust and locally efficient but can be unstable when the propensity scores are
close to zero or one due to weighting by the inverse of the propensity score.
On the other hand, PSM circumvents the instability of propensity score
weighting but it hinges on the correctness of the propensity score model and
cannot attain the semiparametric efficiency bound. Besides, the fixed number of
matches, K, renders PSM nonsmooth and thus invalidates standard nonparametric
bootstrap inference.
  This article presents novel augmented match weighted (AMW) estimators that
combine the advantages of matching and weighting estimators. AMW adheres to the
form of AIPW for its double robustness and local efficiency but it mitigates
the instability due to weighting. We replace inverse propensity weights with
matching weights resulting from PSM with unfixed K. Meanwhile, we propose a new
cross-validation procedure to select K that minimizes the mean squared error
anchored around an unbiased estimator of the causal estimand. Besides, we
derive the limiting distribution for the AMW estimators showing that they enjoy
the double robustness property and can achieve the semiparametric efficiency
bound if both nuisance models are correct. As a byproduct of unfixed K which
smooths the AMW estimators, nonparametric bootstrap can be adopted for variance
estimation and inference. Furthermore, simulation studies and real data
applications support that the AMW estimators are stable with extreme propensity
scores and their variances can be obtained by naive bootstrap.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:10:08 GMT""}]","2023-05-24"
"2305.14256","Oleg Vasilyev","Oleg Vasilyev, Fumika Isono, John Bohannon","Linear Cross-Lingual Mapping of Sentence Embeddings","6 pages, 6 tables",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Semantics of a sentence is defined with much less ambiguity than semantics of
a single word, and it should be better preserved by translation to another
language. If multilingual sentence embeddings intend to represent sentence
semantics, then the similarity between embeddings of any two sentences must be
invariant with respect to translation. Based on this suggestion, we consider a
simple linear cross-lingual mapping as a possible improvement of the
multilingual embeddings. We also consider deviation from orthogonality
conditions as a measure of deficiency of the embeddings.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:10:37 GMT""}]","2023-05-24"
"2305.14257","Robert Lo","Abishek Sridhar, Robert Lo, Frank F. Xu, Hao Zhu, Shuyan Zhou","Hierarchical Prompting Assists Large Language Model on Web Navigation","16 pages, 5 figures",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) struggle on processing complicated observations
in interactive decision making. To alleviate this issue, we propose a simple
hierarchical prompting approach. Diverging from previous prompting approaches
that always put the \emph{full} observation~(\eg a web page) to the prompt, we
propose to first construct an action-aware observation which is more
\emph{condensed} and \emph{relevant} with a dedicated \summ prompt. The \actor
prompt then predicts the next action based on the summarized history. While our
method has broad applicability, we particularly demonstrate its efficacy in the
complex domain of web navigation where a full observation often contains
redundant and irrelevant information. Our approach outperforms the previous
state-of-the-art prompting mechanism with the same LLM by 6.2\% on task success
rate, demonstrating its potential on interactive decision making tasks with
long observation traces.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:10:39 GMT""}]","2023-05-24"
"2305.14258","Zheng Xie","Zheng Xie, Yu Liu, Hao-Yuan He, Ming Li, Zhi-Hua Zhou","Weakly Supervised AUC Optimization: A Unified Partial AUC Approach",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since acquiring perfect supervision is usually difficult, real-world machine
learning tasks often confront inaccurate, incomplete, or inexact supervision,
collectively referred to as weak supervision. In this work, we present WSAUC, a
unified framework for weakly supervised AUC optimization problems, which covers
noisy label learning, positive-unlabeled learning, multi-instance learning, and
semi-supervised learning scenarios. Within the WSAUC framework, we first frame
the AUC optimization problems in various weakly supervised scenarios as a
common formulation of minimizing the AUC risk on contaminated sets, and
demonstrate that the empirical risk minimization problems are consistent with
the true AUC. Then, we introduce a new type of partial AUC, specifically, the
reversed partial AUC (rpAUC), which serves as a robust training objective for
AUC maximization in the presence of contaminated labels. WSAUC offers a
universal solution for AUC optimization in various weakly supervised scenarios
by maximizing the empirical rpAUC. Theoretical and experimental results under
multiple settings support the effectiveness of WSAUC on a range of weakly
supervised AUC optimization tasks.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:11:33 GMT""}]","2023-05-26"
"2305.14259","Qingyun Wang","Qingyun Wang, Doug Downey, Heng Ji, Tom Hope","Learning to Generate Novel Scientific Directions with Contextualized
  Literature-based Discovery","21 pages. Code and resource is available at
  https://github.com/EagleW/CLBD",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Literature-Based Discovery (LBD) aims to discover new scientific knowledge by
mining papers and generating hypotheses. Standard LBD is limited to predicting
pairwise relations between discrete concepts (e.g., drug-disease links). LBD
also ignores critical contexts like experimental settings (e.g., a specific
patient population where a drug is evaluated) and background knowledge and
motivations that human scientists consider (e.g., to find a drug candidate
without specific side effects). We address these limitations with a novel
formulation of contextualized-LBD (C-LBD): generating scientific hypotheses in
natural language, while grounding them in a context that controls the
hypothesis search space. We present a new modeling framework using retrieval of
``inspirations'' from a heterogeneous network of citations and knowledge graph
relations, and create a new dataset derived from papers. In automated and human
evaluations, our models improve over baselines, including powerful large
language models (LLMs), but also reveal challenges on the road to building
machines that generate new scientific knowledge.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:12:08 GMT""}]","2023-05-24"
"2305.14260","Yue Fan","Yue Fan, Kaizhi Zheng, Jing Gu, Xin Eric Wang","R2H: Building Multimodal Navigation Helpers that Respond to Help",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The ability to assist humans during a navigation task in a supportive role is
crucial for intelligent agents. Such agents, equipped with environment
knowledge and conversational abilities, can guide individuals through
unfamiliar terrains by generating natural language responses to their
inquiries, grounded in the visual information of their surroundings. However,
these multimodal conversational navigation helpers are still underdeveloped.
This paper proposes a new benchmark, Respond to Help (R2H), to build multimodal
navigation helpers that can respond to help, based on existing dialog-based
embodied datasets. R2H mainly includes two tasks: (1) Respond to Dialog History
(RDH), which assesses the helper agent's ability to generate informative
responses based on a given dialog history, and (2) Respond during Interaction
(RdI), which evaluates the helper agent's ability to maintain effective and
consistent cooperation with a task performer agent during navigation in
real-time. Furthermore, we propose a novel task-oriented multimodal response
generation model that can see and respond, named SeeRee, as the navigation
helper to guide the task performer in embodied tasks. Through both automatic
and human evaluations, we show that SeeRee produces more effective and
informative responses than baseline methods in assisting the task performer
with different navigation tasks. Project website:
https://sites.google.com/view/respond2help/home.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:12:09 GMT""}]","2023-05-24"
"2305.14261","V\'ictor Manuel Jim\'enez","V. M. Jim\'enez and M. De Le\'on","New notions of uniformity and homogeneity of Cosserat media","arXiv admin note: text overlap with arXiv:1708.00337",,,,"math.DG math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study internal properties of a Cosserat media. In fact, by
using groupoids and smooth distributions, we obtain a three canonical
equations. The \textit{non-holonomic material equation for Cosserat media}
characterizes the uniformity of the material. The \textit{holonomic material
equation for Cosserat media} permits us to study when a Cosserat material is a
second-grade material. It is remarkable that these two equations also provide
us a unique and maximal division of the Cosserat medium into uniform and
second-grade parts, respectively. Finally, we present a proper definition of
homogeneity of the Cosserat medium, without assuming uniformity. Thus, the
\textit{homogeneity equation for Cosserat media} characterizes this notion of
homogeneity.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:13:31 GMT""}]","2023-05-24"
"2305.14262","Varsha Ramachandran","V. Ramachandran, J. Klencki, A. A. C. Sander, D. Pauli, T. Shenar, L.
  M. Oskinova, and W.-R. Hamann","A partially stripped massive star in a Be binary at low metallicity: A
  missing link towards Be X-ray binaries and double neutron star mergers","To be published in A&A",,,,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Standard binary evolutionary models predict a significant population of core
helium-burning stars that lost their hydrogen-rich envelope after mass transfer
via Roche-lobe overflow. However, there is a scarcity of observations of such
stripped stars in the intermediate mass regime (~1.5 - 8$ M_{\odot}$), which
are thought to be prominent progenitors of SN Ib/c. Especially at low
metallicity, a significant fraction of these stars is expected to be only
partially stripped, retaining a significant amount of hydrogen on their
surfaces. For the first time, we discovered a partially stripped massive star
in a binary with a Be-type companion located in the Small Magellanic Cloud
(SMC) using a detailed spectroscopic analysis. The stripped-star nature of the
primary is revealed by the extreme CNO abundance pattern and very high
luminosity-to-mass ratio, which suggest that the primary is likely
shell-hydrogen burning. Our target SMCSGS-FS 69 is the most luminous and most
massive system among the known stripped star + Be binaries, with Mstripped ~3$
M_{\odot}$ and MBe ~17$ M_{\odot}$. Binary evolutionary tracks suggest an
initial mass of Mini $\gtrsim 12 M_{\odot}$ for the stripped star and predict
it to be in a transition phase towards a hot compact He star, which will
eventually produce a stripped-envelope supernova. Our target marks the first
representative of a so-far missing evolutionary stage in the formation pathway
of Be X-ray binaries and double neutron star mergers.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:15:35 GMT""}]","2023-05-24"
"2305.14263","Milind Agarwal","Milind Agarwal, Md Mahfuz Ibn Alam, Antonios Anastasopoulos","LIMIT: Language Identification, Misidentification, and Translation using
  Hierarchical Models in 350+ Languages","25 pages, 2 figures, 13 tables",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Knowing the language of an input text/audio is a necessary first step for
using almost every natural language processing (NLP) tool such as taggers,
parsers, or translation systems. Language identification is a well-studied
problem, sometimes even considered solved; in reality, most of the world's 7000
languages are not supported by current systems. This lack of representation
affects large-scale data mining efforts and further exacerbates data shortage
for low-resource languages. We take a step towards tackling the data bottleneck
by compiling a corpus of over 50K parallel children's stories in 350+ languages
and dialects, and the computation bottleneck by building lightweight
hierarchical models for language identification. Our data can serve as
benchmark data for language identification of short texts and for understudied
translation directions such as those between Indian or African languages. Our
proposed method, Hierarchical LIMIT, uses limited computation to expand
coverage into excluded languages while maintaining prediction quality.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:15:43 GMT""}]","2023-05-24"
"2305.14264","Katerina Margatina","Katerina Margatina and Timo Schick and Nikolaos Aletras and Jane
  Dwivedi-Yu","Active Learning Principles for In-Context Learning with Large Language
  Models",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  The remarkable advancements in large language models (LLMs) have
significantly enhanced the performance in few-shot learning settings. By using
only a small number of labeled examples, referred to as demonstrations, LLMs
can effectively grasp the task at hand through in-context learning. However,
the process of selecting appropriate demonstrations has received limited
attention in prior work. This paper addresses the issue of identifying the most
informative demonstrations for few-shot learning by approaching it as a
pool-based Active Learning (AL) problem over a single iteration. Our objective
is to investigate how AL algorithms can serve as effective demonstration
selection methods for in-context learning. We compare various standard AL
algorithms based on uncertainty, diversity, and similarity, and consistently
observe that the latter outperforms all other methods, including random
sampling. Notably, uncertainty sampling, despite its success in conventional
supervised learning scenarios, performs poorly in this context. Our extensive
experimentation involving a diverse range of GPT and OPT models across $24$
classification and multi-choice tasks, coupled with thorough analysis,
unambiguously demonstrates that in-context example selection through AL
prioritizes high-quality examples that exhibit low uncertainty and bear
similarity to the test examples.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:16:04 GMT""}]","2023-05-24"
"2305.14265","Liyang Sun","Timothy B. Armstrong, Patrick Kline, Liyang Sun","Adapting to Misspecification","58 pages, 12 figures",,,,"econ.EM stat.ME","http://creativecommons.org/licenses/by/4.0/","  Empirical research typically involves a robustness-efficiency tradeoff. A
researcher seeking to estimate a scalar parameter can invoke strong assumptions
to motivate a restricted estimator that is precise but may be heavily biased,
or they can relax some of these assumptions to motivate a more robust, but
variable, unrestricted estimator. When a bound on the bias of the restricted
estimator is available, it is optimal to shrink the unrestricted estimator
towards the restricted estimator. For settings where a bound on the bias of the
restricted estimator is unknown, we propose adaptive shrinkage estimators that
minimize the percentage increase in worst case risk relative to an oracle that
knows the bound. We show that adaptive estimators solve a weighted convex
minimax problem and provide lookup tables facilitating their rapid computation.
Revisiting five empirical studies where questions of model specification arise,
we examine the advantages of adapting to -- rather than testing for --
misspecification.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:16:09 GMT""}]","2023-05-24"
"2305.14266","Dmitry Svintsov","Dmitry Svintsov and Georgy Alymov","Refraction laws for two-dimensional plasmons",,,,,"physics.optics cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Despite numerous applications of two-dimensional plasmons for electromagnetic
energy manipulation at the nanoscale, their quantitative refraction and
reflection laws (analogs of Fresnel formulas in optics) have not yet been
established. This fact can be traced down to the strong non-locality of
equations governing the 2d plasmon propagation. Here, we tackle this difficulty
by direct solution of plasmon scattering problem with Wiener-Hopf technique. We
obtain the reflection and transmission coefficients for 2d plasmons at the
discontinuity of 2d conductivity at arbitrary incidence angle, for both gated
and non-gated 2d systems. At a certain incidence angle, the absolute
reflectivity has a pronounced dip reaching zero for gated plasmons. The dip is
associated with wave passage causing no dynamic charge accumulation at the
boundary. For all incidence angles, the reflection has a non-trivial phase
different from zero and $\pi$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:16:53 GMT""}]","2023-05-24"
"2305.14267","Martin Gonzalez","Martin Gonzalez, Nelson Fernandez, Thuy Tran, Elies Gherbi, Hatem
  Hajri, Nader Masmoudi","SEEDS: Exponential SDE Solvers for Fast High-Quality Sampling from
  Diffusion Models","52 pages. Comments are welcome!",,,,"cs.LG cs.CV cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  A potent class of generative models known as Diffusion Probabilistic Models
(DPMs) has become prominent. A forward diffusion process adds gradually noise
to data, while a model learns to gradually denoise. Sampling from pre-trained
DPMs is obtained by solving differential equations (DE) defined by the learnt
model, a process which has shown to be prohibitively slow. Numerous efforts on
speeding-up this process have consisted on crafting powerful ODE solvers.
Despite being quick, such solvers do not usually reach the optimal quality
achieved by available slow SDE solvers. Our goal is to propose SDE solvers that
reach optimal quality without requiring several hundreds or thousands of NFEs
to achieve that goal. In this work, we propose Stochastic Exponential
Derivative-free Solvers (SEEDS), improving and generalizing Exponential
Integrator approaches to the stochastic case on several frameworks. After
carefully analyzing the formulation of exact solutions of diffusion SDEs, we
craft SEEDS to analytically compute the linear part of such solutions. Inspired
by the Exponential Time-Differencing method, SEEDS uses a novel treatment of
the stochastic components of solutions, enabling the analytical computation of
their variance, and contains high-order terms allowing to reach optimal quality
sampling $\sim3$-$5\times$ faster than previous SDE methods. We validate our
approach on several image generation benchmarks, showing that SEEDS outperforms
or is competitive with previous SDE solvers. Contrary to the latter, SEEDS are
derivative and training free, and we fully prove strong convergence guarantees
for them.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:19:54 GMT""}]","2023-05-24"
"2305.14268","Zi-Yi Dou","Zi-Yi Dou, Feng Gao, Nanyun Peng","Masked Path Modeling for Vision-and-Language Navigation",,,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by/4.0/","  Vision-and-language navigation (VLN) agents are trained to navigate in
real-world environments by following natural language instructions. A major
challenge in VLN is the limited availability of training data, which hinders
the models' ability to generalize effectively. Previous approaches have
attempted to address this issue by introducing additional supervision during
training, often requiring costly human-annotated data that restricts
scalability. In this paper, we introduce a masked path modeling (MPM)
objective, which pretrains an agent using self-collected data for downstream
navigation tasks. Our proposed method involves allowing the agent to actively
explore navigation environments without a specific goal and collect the paths
it traverses. Subsequently, we train the agent on this collected data to
reconstruct the original path given a randomly masked subpath. This way, the
agent can actively accumulate a diverse and substantial amount of data while
learning conditional action generation. To evaluate the effectiveness of our
technique, we conduct experiments on various VLN datasets and demonstrate the
versatility of MPM across different levels of instruction complexity. Our
results exhibit significant improvements in success rates, with enhancements of
1.32\%, 1.05\%, and 1.19\% on the val-unseen split of the Room-to-Room,
Room-for-Room, and Room-across-Room datasets, respectively. Furthermore, we
conduct an analysis that highlights the potential for additional improvements
when the agent is allowed to explore unseen environments prior to testing.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:20:20 GMT""}]","2023-05-24"
"2305.14269","Giulia Rizzoli","Giulia Rizzoli, Donald Shenaj, Pietro Zanuttigh","Source-Free Domain Adaptation for RGB-D Semantic Segmentation with
  Vision Transformers","8 pages, 4 figures",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  With the increasing availability of depth sensors, multimodal frameworks that
combine color information with depth data are attracting increasing interest.
In the challenging task of semantic segmentation, depth maps allow to
distinguish between similarly colored objects at different depths and provide
useful geometric cues. On the other side, ground truth data for semantic
segmentation is burdensome to be provided and thus domain adaptation is another
significant research area. Specifically, we address the challenging source-free
domain adaptation setting where the adaptation is performed without reusing
source data. We propose MISFIT: MultImodal Source-Free Information fusion
Transformer, a depth-aware framework which injects depth information into a
segmentation module based on vision transformers at multiple stages, namely at
the input, feature and output levels. Color and depth style transfer helps
early-stage domain alignment while re-wiring self-attention between modalities
creates mixed features allowing the extraction of better semantic content.
Furthermore, a depth-based entropy minimization strategy is also proposed to
adaptively weight regions at different distances. Our framework, which is also
the first approach using vision transformers for source-free semantic
segmentation, shows noticeable performance improvements with respect to
standard strategies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:20:47 GMT""}]","2023-05-24"
"2305.14270","Haonan Lu","Haonan Lu and Shuai Mu and Siddhartha Sen and Wyatt Lloyd","NCC: Natural Concurrency Control for Strictly Serializable Datastores by
  Avoiding the Timestamp-Inversion Pitfall","This paper will appear at OSDI 23. We hope to use Arxiv to submit our
  technical reports of this paper. We would greatly appreciate it if our
  submission could be approved as soon as possible, so we could include a link
  to this technical report in the the camera-ready version. Thank you",,,,"cs.DC","http://creativecommons.org/publicdomain/zero/1.0/","  Strictly serializable datastores greatly simplify the development of correct
applications by providing strong consistency guarantees. However, existing
techniques pay unnecessary costs for naturally consistent transactions, which
arrive at servers in an order that is already strictly serializable. We find
these transactions are prevalent in datacenter workloads. We exploit this
natural arrival order by executing transaction requests with minimal costs
while optimistically assuming they are naturally consistent, and then leverage
a timestamp-based technique to efficiently verify if the execution is indeed
consistent. In the process of designing such a timestamp-based technique, we
identify a fundamental pitfall in relying on timestamps to provide strict
serializability, and name it the timestamp-inversion pitfall. We find
timestamp-inversion has affected several existing works.
  We present Natural Concurrency Control (NCC), a new concurrency control
technique that guarantees strict serializability and ensures minimal costs --
i.e., one-round latency, lock-free, and non-blocking execution -- in the best
(and common) case by leveraging natural consistency. NCC is enabled by three
key components: non-blocking execution, decoupled response control, and
timestamp-based consistency check. NCC avoids timestamp-inversion with a new
technique: response timing control, and proposes two optimization techniques,
asynchrony-aware timestamps and smart retry, to reduce false aborts. Moreover,
NCC designs a specialized protocol for read-only transactions, which is the
first to achieve the optimal best-case performance while ensuring strict
serializability, without relying on synchronized clocks. Our evaluation shows
that NCC outperforms state-of-the-art solutions by an order of magnitude on
many workloads.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:21:30 GMT""}]","2023-05-24"
"2305.14271","Zhuoran Fang","Zhuoran Fang, Bassem Tossoun, Antoine Descos, Di Liang, Xue Huang,
  Geza Kurczveil, Arka Majumdar, Raymond G. Beausoleil","Fast and energy-efficient non-volatile III-V-on-silicon photonic phase
  shifter based on memristors",,,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Silicon photonics has evolved from lab research to commercial products in the
past decade as it plays an increasingly crucial role in data communication for
next-generation data centers and high performance computing1. Recently,
programmable silicon photonics has also found new applications in quantum2 and
classical 3 information processing. A key component of programmable silicon
photonic integrated circuits (PICs) is the phase shifter, traditionally
realized via the thermo-optic or plasma dispersion effect which are weak,
volatile, and power hungry. A non-volatile phase shifter can circumvent these
limitations by requiring zero power to maintain the switched phases. Previously
non-volatile phase modulation was achieved via phase-change4 or ferroelectric
materials5, but the switching energy remains high (pico to nano joules) and the
speed is slow (micro to milli seconds). Here, we report a non-volatile
III-V-on-silicon photonic phase shifter based on HfO2 memristor with sub-pJ
switching energy (~400fJ), representing over an order of magnitude improvement
in energy efficiency compared to the state of the art. The non-volatile phase
shifter can be switched reversibly using a single 100ns pulse and exhibits an
excellent endurance over 800 cycles. This technology can enable future
energy-efficient programmable PICs for data centers, optical neural networks,
and quantum information processing.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:22:41 GMT""}]","2023-05-24"
"2305.14272","Kyle DeBry","Kyle DeBry, Jasmine Sinanan-Singh, Colin D. Bruzewicz, David Reens,
  May E. Kim, Matthew P. Roychowdhury, Robert McConnell, Isaac L. Chuang, and
  John Chiaverini","Experimental quantum channel discrimination using metastable states of a
  trapped ion","Main text: 6 pages, 4 figures. Supplementary Material: 7 pages, 5
  figures, 2 tables",,,,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present experimental demonstrations of accurate and unambiguous
single-shot discrimination between three quantum channels using a single
trapped $^{40}\text{Ca}^{+}$ ion. The three channels cannot be distinguished
unambiguously using repeated single channel queries, the natural classical
analogue. We develop techniques for using the 6-dimensional $\text{D}_{5/2}$
state space for quantum information processing, and we implement protocols to
discriminate quantum channel analogues of phase shift keying and amplitude
shift keying data encodings used in classical radio communication. The
demonstrations achieve discrimination accuracy exceeding $99\%$ in each case,
limited entirely by known experimental imperfections.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:22:44 GMT""}]","2023-05-24"
"2305.14273","Hyun Jeong","Hyun Jeong, Kohei Kamada, Alexei A. Starobinsky, Jun'ichi Yokoyama","Reheating process in the $R^2$ inflationary model with the baryogenesis
  scenario","13 pages, 9 figures",,,"RESCEU-13/23","hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Post-inflationary evolution and (re)heating of the viable inflationary model,
the $R^2$ one, is made more realistic by including the leptogenesis scenario
into it. For this purpose, right-handed Majorana neutrinos with a large mass
are added to the matter sector of the Standard Model to explain the neutrino
oscillation experiments and the baryon asymmetry of the Universe. We have found
parameters that characterize this model: non-minimal coupling of the Higgs
field $\xi$ and the mass of the right-handed Majorana neutrino $M_{N_\alpha}$.
We have analyzed the effect of these parameters on the reheating process and
the resultant physical quantities: spectral indices and baryon asymmetry.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:23:42 GMT""}]","2023-05-24"
"2305.14274","Purbayan Chakraborty","B. V. Rajarama Bhat, Purbayan Chakraborty, Uwe Franz","Error Basis and Quantum Channel",,,,,"quant-ph math-ph math.MP math.OA","http://creativecommons.org/licenses/by/4.0/","  The Weyl operators give a convenient basis of $M_n(\mathbb{C})$ which is also
orthonormal with respect to the Hilbert-Schmidt inner product. The properties
of such a basis can be generalised to the notion of a nice error basis(NEB), as
introduced by E. Knill. We can use an NEB of $M_n(\mathbb{C})$ to construct an
NEB for $Lin(M_n(\mathbb{C}))$, the space of linear maps on $M_n(\mathbb{C})$.
Any linear map on $M_n(\mathbb{C})$ will then correspond to a $n^2\times n^2$
coefficient matrix in the basis decomposition with respect to such an NEB of
$Lin(M_n(\mathbb{C}))$. Positivity, complete (co)positivity or other properties
of a linear map can be characterised in terms of such a coefficient matrix.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:23:56 GMT""}]","2023-05-24"
"2305.14275","Yash Patel","Yash Patel, Declan McNamara, Jackson Loper, Jeffrey Regier, Ambuj
  Tewari","Variational Inference with Coverage Guarantees",,,,,"stat.ME cs.LG","http://creativecommons.org/licenses/by/4.0/","  Amortized variational inference produces a posterior approximator that can
compute a posterior approximation given any new observation. Unfortunately,
there are few guarantees about the quality of these approximate posteriors. We
propose Conformalized Amortized Neural Variational Inference (CANVI), a
procedure that is scalable, easily implemented, and provides guaranteed
marginal coverage. Given a collection of candidate amortized posterior
approximators, CANVI constructs conformalized predictors based on each
candidate, compares the predictors using a metric known as predictive
efficiency, and returns the most efficient predictor. CANVI ensures that the
resulting predictor constructs regions that contain the truth with high
probability (exactly how high is prespecified by the user). CANVI is agnostic
to design decisions in formulating the candidate approximators and only
requires access to samples from the forward model, permitting its use in
likelihood-free settings. We prove lower bounds on the predictive efficiency of
the regions produced by CANVI and explore how the quality of a posterior
approximation relates to the predictive efficiency of prediction regions based
on that approximation. Finally, we demonstrate the accurate calibration and
high predictive efficiency of CANVI on a suite of simulation-based inference
benchmark tasks and an important scientific task: analyzing galaxy emission
spectra.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:24:04 GMT""}]","2023-05-24"
"2305.14276","Ada Chan","Ada Chan and Peter Sin","Pretty good state transfer among large sets of vertices",,,,,"math.CO quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a continuous-time quantum walk on a network of qubits, pretty good state
transfer is the phenomenon of state transfer between two vertices with fidelity
arbitrarily close to 1. We construct families of graphs to demonstrate that
there is no bound on the size of a set of vertices that admit pretty good state
transfer between any two vertices of the set.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:24:14 GMT""}]","2023-05-24"
"2305.14277","Yaroslav Zhumagulov","Yaroslav Zhumagulov and Denis Kochan and Jaroslav Fabian","Emergent correlated phases in rhombohedral trilayer graphene induced by
  proximity spin-orbit and exchange coupling",,,,,"cond-mat.str-el cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The impact of proximity-induced spin-orbit and exchange coupling on the
correlated phase diagram of rhombohedral trilayer graphene (RTG) is
investigated theoretically. By employing \emph{ab initio}-fitted effective
models of RTG encapsulated by transition metal dichalcogenides (spin-orbit
proximity effect) and ferromagnetic Cr$_2$Ge$_2$Te$_6$ (exchange proximity
effect), we incorporate the Coulomb interactions within the random-phase
approximation to explore potential correlated phases at different displacement
field and doping. We find a rich spectrum of spin-valley resolved Stoner and
intervalley coherence instabilities induced by the spin-orbit proximity
effects, such as the emergence of a \textit{spin-valley-coherent} phase due to
the presence of valley-Zeeman coupling. Similarly, proximity exchange removes
the phase degeneracies by biasing the spin direction, enabling a
magneto-correlation effect -- strong sensitivity of the correlated phases to
the relative magnetization orientations (parallel or antiparallel) of the
encapsulating ferromagnetic layers.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:24:31 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 10:53:29 GMT""}]","2023-06-05"
"2305.14278","Rico Huhnstock","Rico Huhnstock, Lukas Paetzold, Maximilian Merkel, Piotr Ku\'swik,
  Arno Ehresmann","Combined funnel, concentrator, and particle valve functional element for
  magnetophoretic bead transport based on engineered magnetic domain patterns","30 pages and 4 figures (main article), 2 pages Supporting Information",,,,"physics.app-ph cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Controlled actuation of superparamagnetic beads (SPBs) within a microfluidic
environment using tailored dynamic magnetic field landscapes (MFLs) is a potent
approach for the realization of point-of-care diagnostics within Lab-on-a-chip
(LOC) systems. Making use of an engineered magnetic domain pattern as the MFL
source, a functional LOC-element with combined magnetophoretic funnel,
concentrator, and valve functions for micron-sized SPBs is presented. A
parallel-stripe domain pattern design with periodically increasing/decreasing
stripe lengths has been fabricated in a topographically flat continuous
exchange biased (EB) thin film system by ion bombardment induced magnetic
patterning (IBMP). It is demonstrated that, upon application of external
magnetic field pulses, a fully reversible concentration of SPBs at the domain
pattern focal point occurs. In addition, it is shown that this functionality
may be used as an SPB funnel, allowing only a maximum number of particles to
pass through the focal point. Adjusting the pulse time length, the focal point
can be clogged up for incoming SPBs, resembling an on-and-off switchable
particle valve. The observations are supported by quantitative theoretical
force considerations.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:25:55 GMT""}]","2023-05-24"
"2305.14279","Angelica Chen","Angelica Chen, Jason Phang, Alicia Parrish, Vishakh Padmakumar, Chen
  Zhao, Samuel R. Bowman, Kyunghyun Cho","Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have achieved widespread success on a variety of
in-context few-shot tasks, but this success is typically evaluated via
correctness rather than consistency. We argue that self-consistency is an
important criteria for valid multi-step reasoning and propose two types of
self-consistency that are particularly important for multi-step logic --
hypothetical consistency (the ability for a model to predict what its output
would be in a hypothetical other context) and compositional consistency
(consistency of a model's outputs for a compositional task even when an
intermediate step is replaced with the model's output for that step). We
demonstrate that four sizes of the GPT-3 model exhibit poor consistency rates
across both types of consistency on four different tasks (Wikipedia,
DailyDialog, arithmetic, and GeoQuery).
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:25:59 GMT""}]","2023-05-24"
"2305.14280","Elizabeth Salesky","Elizabeth Salesky, Neha Verma, Philipp Koehn, Matt Post","Pixel Representations for Multilingual Translation and Data-efficient
  Cross-lingual Transfer",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and demonstrate how to effectively train multilingual machine
translation models with pixel representations. We experiment with two different
data settings with a variety of language and script coverage, and show
performance competitive with subword embeddings. We analyze various properties
of pixel representations to better understand where they provide potential
benefits and the impact of different scripts and data representations. We
observe that these properties not only enable seamless cross-lingual transfer
to unseen scripts, but make pixel representations more data-efficient than
alternatives such as vocabulary expansion. We hope this work contributes to
more extensible multilingual models for all languages and scripts.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:26:50 GMT""}]","2023-05-24"
"2305.14281","Emanuele Bugliarello","Emanuele Bugliarello, Aida Nematzadeh, Lisa Anne Hendricks","Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining","Work in progress",,,,"cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work in vision-and-language pretraining has investigated supervised
signals from object detection data to learn better, fine-grained multimodal
representations. In this work, we take a step further and explore how we add
supervision from small-scale visual relation data. In particular, we propose
two pretraining approaches to contextualise visual entities in a multimodal
setup. With verbalised scene graphs, we transform visual relation triplets into
structured captions, and treat them as additional views of images. With masked
relation prediction, we further encourage relating entities from visually
masked contexts. When applied to strong baselines pretrained on large amounts
of Web data, zero-shot evaluations on both coarse-grained and fine-grained
tasks show the efficacy of our methods in learning multimodal representations
from weakly-supervised relations data.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:27:12 GMT""}]","2023-05-24"
"2305.14282","Wenda Xu","Wenda Xu, Danqing Wang, Liangming Pan, Zhenqiao Song, Markus Freitag,
  William Yang Wang, Lei Li","INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with
  Automatic Feedback","Work in progress",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  The field of automatic evaluation of text generation made tremendous progress
in the last few years. In particular, since the advent of neural metrics, like
COMET, BLEURT, and SEScore2, the newest generation of metrics show a high
correlation with human judgment. Unfortunately, quality scores generated with
neural metrics are not interpretable, and it is unclear which part of the
generation output is criticized by the metrics. To address this limitation, we
present INSTRUCTSCORE, an open-source, explainable evaluation metric for text
generation. By harnessing both explicit human instruction and the implicit
knowledge of GPT4, we fine-tune a LLAMA model to create an evaluative metric
that can produce a diagnostic report aligned with human judgment. We evaluate
INSTRUCTSCORE on the WMT22 Zh-En translation task, where our 7B model surpasses
other LLM-based baselines, including those based on 175B GPT3. Impressively,
our INSTRUCTSCORE, even without direct supervision from human-rated data,
achieves performance levels on par with state-of-the-art metrics like COMET22,
which was fine-tuned on human ratings.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:27:22 GMT""}]","2023-05-24"
"2305.14283","Xinbei Ma","Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, Nan Duan","Query Rewriting for Retrieval-Augmented Large Language Models","working in progress",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Large Language Models (LLMs) play a powerful \textit{Reader} of the
\textit{Retrieve-then-Read} pipeline, making great progress in knowledge-based
open-domain tasks. This work introduces a new framework,
\textit{Rewrite-Retrieve-Read} that improves the retrieval-augmented method
from the perspective of the query rewriting. Prior studies mostly contribute to
adapt the retriever or stimulate the reader. Different from them, our approach
pay attention of the query adaptation. Because the original query can not be
always optimal to retrieve for the LLM, especially in the real world.(1) We
first prompt an LLM to rewrite the queries, then conduct retrieval-augmented
reading. (2) We further apply a small language model as a trainable rewriter,
which rewrite the search query to cater to the frozen retriever and the LLM
reader. To fine-tune the rewriter, we first use a pseudo data to conduct
supervised warm-up training. Then the \textit{Retrieve-then-Read} pipeline is
modeled as a reinforcement learning context. The rewriter is further trained as
a policy model by maximize the reward of the pipeline performance. Evaluation
is performed on two downstream tasks, open-domain QA and multiple choice. Our
framework is proved effective and scalable.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:27:50 GMT""}]","2023-05-24"
"2305.14284","Ahmed Jellal","Nadia Benlakhouy, Ahmed Jellal, Michael Schreiber","Transport properties of hybrid single-bilayer graphene interfaces in
  magnetic field","8 pages, 7 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The electronic properties of a hybrid system made of single-bilayer graphene
structures subjected to a perpendicular magnetic field are studied for the
zigzag boundaries of the junction, zigzag-1 (ZZ1) and zigzag-2 (ZZ2). These
later examples exhibit different behaviors that have been investigated using
the continuum Dirac model. Our results reveal that the conductance depends on
the width of bilayer graphene for ZZ1 and shows maxima for ZZ2 as a function of
the magnetic field, in contrast to ZZ1. It is found that interfaces have
significant impacts on the transmission probability, with the confinement of
the ZZ1 boundary being more substantial than that of ZZ2
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:28:01 GMT""}]","2023-05-24"
"2305.14285","Rosario Lo Franco","Matteo Piccolini, Vittorio Giovannetti, Rosario Lo Franco","Robust engineering of maximally entangled states by identical particle
  interferometry","9 pages, 6 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a procedure for the robust preparation of maximally entangled
states of identical fermionic qubits, studying the role played by particle
statistics in the process. The protocol exploits externally activated noisy
channels to reset the system to a known state. The subsequent interference
effects generated at a beam splitter result in a mixture of maximally entangled
Bell states and NOON states. We also discuss how every maximally entangled
state of two fermionic qubits distributed over two spatial modes can be
obtained from one another by fermionic passive optical transformations. Using a
pseudospin-insensitive, non-absorbing, parity check detector, the proposed
technique is thus shown to deterministically prepare any arbitrary maximally
entangled state of two identical fermions. These results extend recent findings
related to bosonic qubits. Finally, we analyze the performance of the protocol
for both bosons and fermions when the externally activated noisy channels are
not used and the two qubits undergo standard types of noise. The results supply
further insights towards viable strategies for noise-protected entanglement
exploitable in quantum-enhanced technologies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:29:20 GMT""}]","2023-05-24"
"2305.14286","Koen Minartz","Koen Minartz, Yoeri Poels, Simon Koop, Vlado Menkovski","Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks are emerging as a tool for scalable data-driven simulation of
high-dimensional dynamical systems, especially in settings where numerical
methods are infeasible or computationally expensive. Notably, it has been shown
that incorporating domain symmetries in deterministic neural simulators can
substantially improve their accuracy, sample efficiency, and parameter
efficiency. However, to incorporate symmetries in probabilistic neural
simulators that can simulate stochastic phenomena, we need a model that
produces equivariant distributions over trajectories, rather than equivariant
function approximations. In this paper, we propose Equivariant Probabilistic
Neural Simulation (EPNS), a framework for autoregressive probabilistic modeling
of equivariant distributions over system evolutions. We use EPNS to design
models for a stochastic n-body system and stochastic cellular dynamics. Our
results show that EPNS considerably outperforms existing neural network-based
methods for probabilistic simulation. More specifically, we demonstrate that
incorporating equivariance in EPNS improves simulation quality, data
efficiency, rollout stability, and uncertainty quantification. We conclude that
EPNS is a promising method for efficient and effective data-driven
probabilistic simulation in a diverse range of domains.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:30:10 GMT""}]","2023-05-24"
"2305.14287","Max Weinreich","Max Weinreich","The dynamical degree of billiards in an algebraic curve","46 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce an algebraic formulation of billiards on plane curves $C_0$ over
algebraically closed fields, extending Glutsyuk's complex billiards. For any
nondegenerate algebraic curve $C_0$ of degree $d \geq 2$, algebraic billiards
is a rational $(d-1)$-to-$(d-1)$ surface correspondence on the space of unit
cotangent vectors based on $C_0$. We prove that the dynamical degree of the
billiards correspondence is at most an explicit cubic algebraic integer $\rho_d
< d^2 - d - 3$, depending only on the degree $d$ of $C_0$. As a corollary, for
general real algebraic curves, the topological entropy of the classical
billiards map is at most $\log \rho_d$. We further show that the billiards
correspondence satisfies the singularity confinement property and preserves a
natural $2$-form. To prove our bounds, we construct a birational model that
partially resolves the indeterminacy of algebraic billiards.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:31:04 GMT""}]","2023-05-24"
"2305.14288","Chenxi Whitehouse","Chenxi Whitehouse, Monojit Choudhury, Alham Fikri Aji","LLM-powered Data Augmentation for Enhanced Crosslingual Performance",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  This paper aims to explore the potential of leveraging Large Language Models
(LLMs) for data augmentation in crosslingual commonsense reasoning datasets,
where the available training data is extremely limited. To achieve this, we
employ several LLMs including Dolly-v2, StableVicuna, ChatGPT, and GPT-4 to
augment three datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we
assess the effectiveness of fine-tuning smaller crosslingual models, mBERT and
XLMR, using the synthesised data. We compare the performance of training with
data generated in English and target languages, as well as translating the
English-generated data into the target languages. Our experiments reveal the
overall advantages of incorporating data generated by LLMs. Training on
synthetic data generated by GPT-4, whether English or multilingual, improves
performance consistently compared to the baseline. Other models also exhibit an
overall increase in performance, however, their effectiveness decreases in some
settings. We also ask native speakers to evaluate the naturalness and logical
soundness of the generated examples for different languages. Human evaluation
reveals that LLMs like ChatGPT and GPT-4 excel at generating natural text in
most languages, except a few such as Tamil. Moreover, ChatGPT trails behind in
generating plausible alternatives in comparison to the original dataset, while
GPT-4 demonstrates competitive logic consistency in the synthesised data.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:33:27 GMT""}]","2023-05-24"
"2305.14289","Xili Yi","Xili Yi, Nima Fazeli","Precise Object Sliding with Top Contact via Asymmetric Dual Limit
  Surfaces","10 pages, 11 figures, accepted in Robotics: Science and Systems (RSS
  2023), Daegu, Republic of Korea",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we discuss the mechanics and planning algorithms to slide an
object on a horizontal planar surface via frictional patch contact made with
its top surface. Here, we propose an asymmetric dual limit surface model to
determine slip boundary conditions for both the top and bottom contact. With
this model, we obtain a range of twists that can keep the object in sticking
contact with the robot end-effector while slipping on the supporting plane.
Based on these constraints, we derive a planning algorithm to slide objects
with only top contact to arbitrary goal poses without slippage between end
effector and the object. We validate the proposed model empirically and
demonstrate its predictive accuracy on a variety of object geometries and
motions. We also evaluate the planning algorithm over a variety of objects and
goals demonstrate an orientation error improvement of 90\% when compared to
methods naive to linear path planners.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:33:37 GMT""}]","2023-05-24"
"2305.14290","Karol Gietka","Karol Gietka, Christoph Hotter, and Helmut Ritsch","Unique Steady-State Squeezing in a Driven Quantum Rabi Model","9 pages, 3 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Squeezing is essential to many quantum technologies and our understanding of
quantum physics. Here we develop a theory of steady-state squeezing that can be
generated in the closed and open quantum Rabi as well as Dicke model. To this
end, we eliminate the spin dynamics which effectively leads to an abstract
harmonic oscillator whose eigenstates are squeezed with respect to the physical
harmonic oscillator. The generated form of squeezing has the unique property of
time-independent uncertainties and squeezed dynamics, a novel type of quantum
behavior. Such squeezing might find applications in continuous back-action
evading measurements and should already be observable in optomechanical systems
and Coulomb crystals.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:34:12 GMT""}]","2023-05-24"
"2305.14291","Nicholas Deas","Nicholas Deas and Jessi Grieser and Shana Kleiner and Desmond Patton
  and Elsbeth Turcan and Kathleen McKeown","Evaluation of African American Language Bias in Natural Language
  Generation",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We evaluate how well LLMs understand African American Language (AAL) in
comparison to their performance on White Mainstream English (WME), the
encouraged ""standard"" form of English taught in American classrooms. We measure
LLM performance using automatic metrics and human judgments for two tasks: a
counterpart generation task, where a model generates AAL (or WME) given WME (or
AAL), and a masked span prediction (MSP) task, where models predict a phrase
that was removed from their input. Our contributions include: (1) evaluation of
six pre-trained, large language models on the two language generation tasks;
(2) a novel dataset of AAL text from multiple contexts (social media, hip-hop
lyrics, focus groups, and linguistic interviews) with human-annotated
counterparts in WME; and (3) documentation of model performance gaps that
suggest bias and identification of trends in lack of understanding of AAL
features.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:34:37 GMT""}]","2023-05-24"
"2305.14292","Sina Semnani","Sina J. Semnani, Violet Z. Yao, Heidi C. Zhang, Monica S. Lam","WikiChat: A Few-Shot LLM-Based Chatbot Grounded with Wikipedia",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite recent advances in Large Language Models (LLMs), users still cannot
trust the information provided in their responses. LLMs cannot speak accurately
about events that occurred after their training, which are often topics of
great interest to users, and, as we show in this paper, they are highly prone
to hallucination when talking about less popular (tail) topics. This paper
presents WikiChat, a few-shot LLM-based chatbot that is grounded with live
information from Wikipedia. Through many iterations of experimentation, we have
crafte a pipeline based on information retrieval that (1) uses LLMs to suggest
interesting and relevant facts that are individually verified against
Wikipedia, (2) retrieves additional up-to-date information, and (3) composes
coherent and engaging time-aware responses. We propose a novel hybrid
human-and-LLM evaluation methodology to analyze the factuality and
conversationality of LLM-based chatbots. We focus on evaluating important but
previously neglected issues such as conversing about recent and tail topics. We
evaluate WikiChat against strong fine-tuned and LLM-based baselines across a
diverse set of conversation topics. We find that WikiChat outperforms all
baselines in terms of the factual accuracy of its claims, by up to 12.1%, 28.3%
and 32.7% on head, recent and tail topics, while matching GPT-3.5 in terms of
providing natural, relevant, non-repetitive and informational responses.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:37:36 GMT""}]","2023-05-24"
"2305.14293","Chenxi Whitehouse","Chenxi Whitehouse, Clara Vania, Alham Fikri Aji, Christos
  Christodoulopoulos, Andrea Pierleoni","WebIE: Faithful and Robust Information Extraction on the Web","ACL 2023 Main Conference",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Extracting structured and grounded fact triples from raw text is a
fundamental task in Information Extraction (IE). Existing IE datasets are
typically collected from Wikipedia articles, using hyperlinks to link entities
to the Wikidata knowledge base. However, models trained only on Wikipedia have
limitations when applied to web domains, which often contain noisy text or text
that does not have any factual information. We present WebIE, the first
large-scale, entity-linked closed IE dataset consisting of 1.6M sentences
automatically collected from the English Common Crawl corpus. WebIE also
includes negative examples, i.e. sentences without fact triples, to better
reflect the data on the web. We annotate ~25K triples from WebIE through
crowdsourcing and introduce mWebIE, a translation of the annotated set in four
other languages: French, Spanish, Portuguese, and Hindi. We evaluate the
in-domain, out-of-domain, and zero-shot cross-lingual performance of generative
IE models and find models trained on WebIE show better generalisability. We
also propose three training strategies that use entity linking as an auxiliary
task. Our experiments show that adding Entity-Linking objectives improves the
faithfulness of our generative IE models.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:37:53 GMT""}]","2023-05-24"
"2305.14294","Alessandro Sinibaldi","Alessandro Sinibaldi, Clemens Giuliani, Giuseppe Carleo, Filippo
  Vicentini","Unbiasing time-dependent Variational Monte Carlo by projected quantum
  evolution","8+6 pages, 6 figures",,,,"quant-ph cond-mat.other physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We analyze the accuracy and sample complexity of variational Monte Carlo
approaches to simulate the dynamics of many-body quantum systems classically.
By systematically studying the relevant stochastic estimators, we are able to:
(i) prove that the most used scheme, the time-dependent Variational Monte Carlo
(tVMC), is affected by a systematic statistical bias or exponential sample
complexity when the wave function contains some (possibly approximate) zeros,
an important case for fermionic systems and quantum information protocols; (ii)
show that a different scheme based on the solution of an optimization problem
at each time step is free from such problems; (iii) improve the sample
complexity of this latter approach by several orders of magnitude with respect
to previous proofs of concept. Finally, we apply our advancements to study the
high-entanglement phase in a protocol of non-Clifford unitary dynamics with
local random measurements in 2D, first benchmarking on small spin lattices and
then extending to large systems.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:38:10 GMT""}]","2023-05-24"
"2305.14295","Francesco Giovanni Celiberto","Francesco Giovanni Celiberto","Vector quarkonia at the LHC with JETHAD: A high-energy viewpoint","38 pages, 8 figures, 473 references. Invited review article",,,,"hep-ph hep-ex nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this review we discuss and extend the study of the inclusive production of
vector quarkonia, $J/\psi$ and $\Upsilon$, emitted with large transverse
momenta and rapidities at the LHC. We adopt the novel ZCW19$^+$ determination
to depict the quarkonium production mechanism at the next-to-leading level of
perturbative QCD. This approach is based on the nonrelativistic QCD formalism
well adapted to describe the production of a quarkonium state from the
collinear fragmentation of a gluon or a constituent heavy quark at the lowest
energy scale. We rely upon the NLL/NLO$^+$ hybrid high-energy and collinear
factorization for differential cross sections, where the standard collinear
formalism is enhanced by the BFKL resummation of next-to-leading energy
logarithms arising in the $t$-channel. We employ the JETHAD method to analyze
the behavior of rapidity distributions for double inclusive vector-quarkonium
and inclusive vector-quarkonium plus jet emissions. We discovered that the
natural stability of the high-energy series, previously observed in observables
sensitive to the emission of hadrons with heavy flavor detected in the rapidity
acceptance of LHC barrel calorimeters, becomes even more manifest when these
particles are tagged in forward regions covered by endcaps. Our findings brace
the important message that vector quarkonia at the LHC via the hybrid
factorization offer a unique chance to perform precision studies of high-energy
QCD, as well as an intriguing opportunity to shed light on the quarkonium
production puzzle.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:39:36 GMT""}]","2023-05-24"
"2305.14296","Kundan Krishna","Kundan Krishna, Prakhar Gupta, Sanjana Ramprasad, Byron C. Wallace,
  Jeffrey P. Bigham, Zachary C. Lipton","USB: A Unified Summarization Benchmark Across Tasks and Domains",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An abundance of datasets exist for training and evaluating models on the task
of summary generation.However, these datasets are often derived heuristically,
and lack sufficient annotations to support research into all aspects of
summarization, such as evidence extraction and controllable summarization. We
introduce a benchmark comprising 8 tasks that require multi-dimensional
understanding of summarization, e.g., surfacing evidence for a summary,
assessing its correctness, and gauging its relevance to different topics. We
compare various methods on this benchmark and discover that on multiple tasks,
moderately-sized fine-tuned models consistently outperform much larger few-shot
prompted language models. For factuality related tasks, we also evaluate
existing heuristics to create training data and find that training on them
performs worse than training on $20\times$ less human-labeled data. Our
benchmark consists of data from 6 different domains, allowing us to study
cross-domain performance of trained models. We find that for some tasks, the
amount of training data matters more than the domain where it comes from, while
for other tasks training specifically on data from the target domain, even if
limited, is more beneficial. Our work fulfills the need for a well-annotated
summarization benchmark with diverse tasks, and provides useful insights about
the impact of the quality, size and domain of training data.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:39:54 GMT""}]","2023-05-24"
"2305.14297","Thomas Izgin","Thomas Izgin and David I. Ketcheson and Andreas Meister","Order conditions for Runge--Kutta-like methods with solution-dependent
  coefficients","22 pages, 0 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, many positivity-preserving schemes for initial value
problems have been constructed by modifying a Runge--Kutta (RK) method by
weighting the right-hand side of the system of differential equations with
solution-dependent factors. These include the classes of modified
Patankar--Runge--Kutta (MPRK) and Geometric Conservative (GeCo) methods.
Compared to traditional RK methods, the analysis of accuracy and stability of
these methods is more complicated. In this work, we provide a comprehensive and
unifying theory of order conditions for such RK-like methods, which differ from
original RK schemes in that their coefficients are solution-dependent. The
resulting order conditions are themselves solution-dependent and obtained using
the theory of NB-series, and thus, can easily be read off from labeled N-trees.
We present for the first time order conditions for MPRK and GeCo schemes of
arbitrary order; For MPRK schemes, the order conditions are given implicitly in
terms of the stages. From these results, we recover as particular cases all
known order conditions from the literature for first- and second-order GeCo as
well as first-, second- and third-order MPRK methods. Additionally, we derive
sufficient and necessary conditions in an explicit form for 3rd and 4th order
GeCo schemes as well as 4th order MPRK methods.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:40:08 GMT""}]","2023-05-24"
"2305.14298","En Yu","En Yu, Tiancai Wang, Zhuoling Li, Yuang Zhang, Xiangyu Zhang, Wenbing
  Tao","MOTRv3: Release-Fetch Supervision for End-to-End Multi-Object Tracking",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although end-to-end multi-object trackers like MOTR enjoy the merits of
simplicity, they suffer from the conflict between detection and association
seriously, resulting in unsatisfactory convergence dynamics. While MOTRv2
partly addresses this problem, it demands an additional detection network for
assistance. In this work, we serve as the first to reveal that this conflict
arises from the unfair label assignment between detect queries and track
queries during training, where these detect queries recognize targets and track
queries associate them. Based on this observation, we propose MOTRv3, which
balances the label assignment process using the developed release-fetch
supervision strategy. In this strategy, labels are first released for detection
and gradually fetched back for association. Besides, another two strategies
named pseudo label distillation and track group denoising are designed to
further improve the supervision for detection and association. Without the
assistance of an extra detection network during inference, MOTRv3 achieves
impressive performance across diverse benchmarks, e.g., MOT17, DanceTrack.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:40:13 GMT""}]","2023-05-24"
"2305.14299","Minsik Oh","Minsik Oh, Jiwei Li, Guoyin Wang","TaDSE: Template-aware Dialogue Sentence Embeddings",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning high quality sentence embeddings from dialogues has drawn increasing
attentions as it is essential to solve a variety of dialogue-oriented tasks
with low annotation cost. However, directly annotating and gathering utterance
relationships in conversations are difficult, while token-level annotations,
\eg, entities, slots and templates, are much easier to obtain. General sentence
embedding methods are usually sentence-level self-supervised frameworks and
cannot utilize token-level extra knowledge. In this paper, we introduce
Template-aware Dialogue Sentence Embedding (TaDSE), a novel augmentation method
that utilizes template information to effectively learn utterance
representation via self-supervised contrastive learning framework. TaDSE
augments each sentence with its corresponding template and then conducts
pairwise contrastive learning over both sentence and template. We further
enhance the effect with a synthetically augmented dataset that enhances
utterance-template relation, in which entity detection (slot-filling) is a
preliminary step. We evaluate TaDSE performance on five downstream benchmark
datasets. The experiment results show that TaDSE achieves significant
improvements over previous SOTA methods, along with a consistent Intent
Classification task performance improvement margin. We further introduce a
novel analytic instrument of Semantic Compression method, for which we discover
a correlation with uniformity and alignment. Our code will be released soon.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:40:41 GMT""}]","2023-05-24"
"2305.14300","Orr Fischer","Orr Fischer, Merav Parter","Distributed CONGEST Algorithms against Mobile Adversaries","Accepted to PODC23",,,,"cs.DS cs.DC","http://creativecommons.org/licenses/by/4.0/","  In their seminal PODC 1991 paper, Ostrovsky and Yung introduced the study of
distributed computation in the presence of mobile adversaries which can
dynamically appear throughout the network. Over the years, this setting has
been studied mostly under the assumption that the communication graph is
fully-connected. Resilient CONGEST algorithms for general graphs, on the other
hand, are currently known only for the classical static setting, i.e., where
the set of corrupted edges (or nodes) is fixed throughout the entire
computation.
  We fill this gap by providing round-efficient simulations that translate
given CONGEST algorithms into equivalent algorithms that are resilient against
$f$-mobile edge adversaries. Our main results are:
  -Perfect-Security with Mobile Eavesdroppers: A translation of any $r$-round
$f$-static-secure algorithm into an equivalent $\Theta(f)$-mobile-secure
algorithm with $\Theta(r)$ rounds. We also show that the $f$-static-secure
algorithms of [Hitron, Parter and Yogev, DISC 2022 & ITCS 2023] can be modified
into $f$-mobile-secure algorithms with the same number of rounds.
  -Resilience with Mobile Byzantine Adversaries: An $f$-mobile-byzantine
simulation which is based on a decomposition of the graph into low-diameter
edge-disjoint spanning trees. This provides us with near-optimal CONGEST
compilers for expander graphs. It also leads to near-optimal compilers in the
congested-clique model against $\Theta(n)$-mobile adversaries. For general
$(2f+1)$ edge-connected graphs with $f$-mobile adversary, we almost match the
bounds known for the $f$-static setting, when provided a trusted pre-processing
phase.
  Our results are based on a collection of tools from interactive coding
[Gelles, Found. Trends Theor. Comput. Sci. 2017], linear sketches and
low-congestion graph decomposition. The introduced toolkit might have further
applications for resilient computation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:42:29 GMT""}]","2023-05-24"
"2305.14301","Fangda Li","Fangda Li, Zhiqiang Hu, Wen Chen, Avinash Kak","A Laplacian Pyramid Based Generative H&E Stain Augmentation Network",,,,,"eess.IV cs.CV","http://creativecommons.org/licenses/by/4.0/","  Hematoxylin and Eosin (H&E) staining is a widely used sample preparation
procedure for enhancing the saturation of tissue sections and the contrast
between nuclei and cytoplasm in histology images for medical diagnostics.
However, various factors, such as the differences in the reagents used, result
in high variability in the colors of the stains actually recorded. This
variability poses a challenge in achieving generalization for machine-learning
based computer-aided diagnostic tools. To desensitize the learned models to
stain variations, we propose the Generative Stain Augmentation Network (G-SAN)
-- a GAN-based framework that augments a collection of cell images with
simulated yet realistic stain variations. At its core, G-SAN uses a novel and
highly computationally efficient Laplacian Pyramid (LP) based generator
architecture, that is capable of disentangling stain from cell morphology.
Through the task of patch classification and nucleus segmentation, we show that
using G-SAN-augmented training data provides on average 15.7% improvement in F1
score and 7.3% improvement in panoptic quality, respectively. Our code is
available at https://github.com/lifangda01/GSAN-Demo.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:43:18 GMT""}]","2023-05-24"
"2305.14302","Yongfeng Zhang","Shijie Geng and Juntao Tan and Shuchang Liu and Zuohui Fu and Yongfeng
  Zhang","VIP5: Towards Multimodal Foundation Models for Recommendation",,,,,"cs.IR cs.AI cs.HC cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computer Vision (CV), Natural Language Processing (NLP), and Recommender
Systems (RecSys) are three prominent AI applications that have traditionally
developed independently, resulting in disparate modeling and engineering
methodologies. This has impeded the ability for these fields to directly
benefit from each other's advancements. With the increasing availability of
multimodal data on the web, there is a growing need to consider various
modalities when making recommendations for users. With the recent emergence of
foundation models, large language models have emerged as a potential
general-purpose interface for unifying different modalities and problem
formulations. In light of this, we propose the development of a multimodal
foundation model by considering both visual and textual modalities under the P5
recommendation paradigm (VIP5) to unify various modalities and recommendation
tasks. This will enable the processing of vision, language, and personalization
information in a shared architecture for improved recommendations. To achieve
this, we introduce multimodal personalized prompts to accommodate multiple
modalities under a shared format. Additionally, we propose a
parameter-efficient training method for foundation models, which involves
freezing the backbone and fine-tuning lightweight adapters, resulting in
improved recommendation performance and increased efficiency in terms of
training time and memory usage.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:43:46 GMT""}]","2023-05-24"
"2305.14303","Yilun Zhao","Yilun Zhao, Zhenting Qi, Linyong Nan, Boyu Mi, Yixin Liu, Weijin Zou,
  Simeng Han, Xiangru Tang, Yumo Xu, Arman Cohan, Dragomir Radev","QTSumm: A New Benchmark for Query-Focused Table Summarization","work in progress",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  People primarily consult tables to conduct data analysis or answer specific
questions. Text generation systems that can provide accurate table summaries
tailored to users' information needs can facilitate more efficient access to
relevant data insights. However, existing table-to-text generation studies
primarily focus on converting tabular data into coherent statements, rather
than addressing information-seeking purposes. In this paper, we define a new
query-focused table summarization task, where text generation models have to
perform human-like reasoning and analysis over the given table to generate a
tailored summary, and we introduce a new benchmark named QTSumm for this task.
QTSumm consists of 5,625 human-annotated query-summary pairs over 2,437 tables
on diverse topics. Moreover, we investigate state-of-the-art models (i.e., text
generation, table-to-text generation, and large language models) on the QTSumm
dataset. Experimental results and manual analysis reveal that our benchmark
presents significant challenges in table-to-text generation for future
research.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:43:51 GMT""}]","2023-05-24"
"2305.14304","Jianxin Chen","Fang Zhang, Xing Zhu, Rui Chao, Cupjin Huang, Linghang Kong, Guoyang
  Chen, Dawei Ding, Haishan Feng, Yihuai Gao, Xiaotong Ni, Liwei Qiu, Zhe Wei,
  Yueming Yang, Yang Zhao, Yaoyun Shi, Weifeng Zhang, Peng Zhou, Jianxin Chen","A Classical Architecture For Digital Quantum Computers","12 pages, 12 figures",,,,"quant-ph cs.AR","http://creativecommons.org/licenses/by/4.0/","  Scaling bottlenecks the making of digital quantum computers, posing
challenges from both the quantum and the classical components. We present a
classical architecture to cope with a comprehensive list of the latter
challenges {\em all at once}, and implement it fully in an end-to-end system by
integrating a multi-core RISC-V CPU with our in-house control electronics.
  Our architecture enables scalable, high-precision control of large quantum
processors and accommodates evolving requirements of quantum hardware. A
central feature is a microarchitecture executing quantum operations in parallel
on arbitrary predefined qubit groups. Another key feature is a reconfigurable
quantum instruction set that supports easy qubit re-grouping and instructions
extensions.
  As a demonstration, we implement the widely-studied surface code quantum
computing workflow, which is instructive for being demanding on both the
controllers and the integrated classical computation. Our design, for the first
time, reduces instruction issuing and transmission costs to constants, which do
not scale with the number of qubits, without adding any overheads in decoding
or dispatching.
  Rather than relying on specialized hardware for syndrome decoding, our system
uses a dedicated multi-core CPU for both qubit control and classical
computation, including syndrome decoding. This simplifies the system design and
facilitates load-balancing between the quantum and classical components. We
implement recent proposals as decoding firmware on a RISC-V system-on-chip
(SoC) that parallelizes general inner decoders. By using our in-house
Union-Find and PyMatching 2 implementations, we can achieve unprecedented
decoding capabilities of up to distances 47 and 67 with the currently available
SoCs, under realistic and optimistic assumptions of physical error rate
$p=0.001 and p=0.0001, respectively, all in just 1 \textmu s.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:44:06 GMT""}]","2023-05-24"
"2305.14305","Genly Le\'on","Esteban Gonz\'alez, Kimet Jusufi, Genly Leon and Emmanuel N. Saridakis","Observational Constraints on Yukawa Cosmology and Connection with Black
  Hole Shadows","11 pages, 4 figures. Minor changes",,,,"astro-ph.CO gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We confront Yukawa modified cosmology, proposed in arXiv:2304.11492 by Jusufi
et al., with data from Supernovae Type Ia (SNe Ia) and Hubble parameter (OHD)
observations. Yukawa cosmology is obtained from a Yukawa-like gravitational
potential, with coupling parameter $\alpha$ and wavelength parameter $\lambda$,
which gives rise to modified Friedmann equations. We show that the agreement
with observations is very efficient, and within $1\sigma$ confidence level we
find the best-fit parameters $\lambda=2693_{-1262}^{+1191}\, \rm Mpc$, and
$\alpha=0.416_{-0.326}^{+1.137}$, and a graviton mass of approximately $m_g
\simeq 5.6\times 10^{-43}$ GeV. Additionally, we establish a connection between
the effective dark matter and dark energy density parameters and the angular
radius of the black hole shadow of the SgrA and M87 black holes in the
low-redshift limit, which is consistent with the findings of the Event Horizon
Telescope.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:45:06 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 16:41:37 GMT""}]","2023-05-31"
"2305.14306","Junyuan Ouyang","Junyuan Ouyang and Xiao Liu and Haoyao Chen","Hierarchical Adaptive Voxel-guided Sampling for Real-time Applications
  in Large-scale Point Clouds",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While point-based neural architectures have demonstrated their efficacy, the
time-consuming sampler currently prevents them from performing real-time
reasoning on scene-level point clouds. Existing methods attempt to overcome
this issue by using random sampling strategy instead of the commonly-adopted
farthest point sampling~(FPS), but at the expense of lower performance. So the
effectiveness/efficiency trade-off remains under-explored. In this paper, we
reveal the key to high-quality sampling is ensuring an even spacing between
points in the subset, which can be naturally obtained through a grid. Based on
this insight, we propose a hierarchical adaptive voxel-guided point sampler
with linear complexity and high parallelization for real-time applications.
Extensive experiments on large-scale point cloud detection and segmentation
tasks demonstrate that our method achieves competitive performance with the
most powerful FPS, at an amazing speed that is more than 100 times faster. This
breakthrough in efficiency addresses the bottleneck of the sampling step when
handling scene-level point clouds. Furthermore, our sampler can be easily
integrated into existing models and achieves a 20$\sim$80\% reduction in
runtime with minimal effort. The code will be available at
https://github.com/OuyangJunyuan/pointcloud-3d-detector-tensorrt
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:45:49 GMT""}]","2023-05-24"
"2305.14307","Robert Morabito","Robert Morabito, Jad Kabbara, Ali Emami","Debiasing should be Good and Bad: Measuring the Consistency of Debiasing
  Techniques in Language Models","9 pages (excluding references), accepted at ACL Findings 2023",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Debiasing methods that seek to mitigate the tendency of Language Models (LMs)
to occasionally output toxic or inappropriate text have recently gained
traction. In this paper, we propose a standardized protocol which distinguishes
methods that yield not only desirable results, but are also consistent with
their mechanisms and specifications. For example, we ask, given a debiasing
method that is developed to reduce toxicity in LMs, if the definition of
toxicity used by the debiasing method is reversed, would the debiasing results
also be reversed? We used such considerations to devise three criteria for our
new protocol: Specification Polarity, Specification Importance, and Domain
Transferability. As a case study, we apply our protocol to a popular debiasing
method, Self-Debiasing, and compare it to one we propose, called Instructive
Debiasing, and demonstrate that consistency is as important an aspect to
debiasing viability as is simply a desirable result. We show that our protocol
provides essential insights into the generalizability and interpretability of
debiasing methods that may otherwise go overlooked.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:45:54 GMT""}]","2023-05-24"
"2305.14308","Haldun \""Ozg\""ur Bay{\i}nd{\i}r","Haldun \""Ozg\""ur Bay{\i}nd{\i}r","Algebraic $K$-theory of the two-periodic first Morava $K$-theory",,,,,"math.AT math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using the root adjunction formalism developed in an earlier work and
logarithmic THH, we obtain a simplified computation of $T(2)_*\text{K}(ku)$ for
$p>3$. Our computational methods also provide $T(2)_*\text{K}(ku/p)$, where
$ku/p$ is the $2$-periodic Morava $K$-theory spectrum of height $1$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:46:14 GMT""}]","2023-05-24"
"2305.14309","Yongtao Liu","Yongtao Liu, Anna N. Morozovska, Ayana Ghosh, Kyle P. Kelley, Eugene
  A. Eliseev, Jinyuan Yao, Ying Liu, and Sergei V. Kalinin","Disentangling stress and curvature effects in layered 2D ferroelectric
  CuInP2S6","20 pages; 7 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Nanoscale ferroelectric 2D materials offer unique opportunity to investigate
curvature and strain effects on materials functionalities. Among these,
CuInP2S6 (CIPS) has attracted tremendous research interest in recent years due
to combination of room temperature ferroelectricity, scalability to a few
layers thickness, and unique ferrielectric properties due to coexistence of 2
polar sublattices. Here, we explore the local curvature and strain effect on
the polarization in CIPS via piezoresponse force microscopy and spectroscopy.
To explain the observed behaviors and decouple the curvature and strain effects
in 2D CIPS, we introduce finite element Landau-Ginzburg-Devonshire model. The
results show that bending induces ferrielectric domains in CIPS, and the
polarization-voltage hysteresis loops differ in bending and non-bending
regions. Our simulation indicates that the flexoelectric effect can affect
local polarization hysteresis. These studies open a novel pathway for the
fabrication of curvature-engineered nanoelectronic devices.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:48:08 GMT""}]","2023-05-24"
"2305.14310","Yida Mu","Yida Mu, Ben P. Wu, William Thorne, Ambrose Robinson, Nikolaos
  Aletras, Carolina Scarton, Kalina Bontcheva, Xingyi Song","Navigating Prompt Complexity for Zero-Shot Classification: A Study of
  Large Language Models in Computational Social Science",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Instruction-tuned Large Language Models (LLMs) have exhibited impressive
language understanding and the capacity to generate responses that follow
specific instructions. However, due to the computational demands associated
with training these models, their applications often rely on zero-shot
settings. In this paper, we evaluate the zero-shot performance of two publicly
accessible LLMs, ChatGPT and OpenAssistant, in the context of Computational
Social Science classification tasks, while also investigating the effects of
various prompting strategies. Our experiment considers the impact of prompt
complexity, including the effect of incorporating label definitions into the
prompt, using synonyms for label names, and the influence of integrating past
memories during the foundation model training. The findings indicate that in a
zero-shot setting, the current LLMs are unable to match the performance of
smaller, fine-tuned baseline transformer models (such as BERT). Additionally,
we find that different prompting strategies can significantly affect
classification accuracy, with variations in accuracy and F1 scores exceeding
10%.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:48:21 GMT""}]","2023-05-24"
"2305.14311","Grigoris Velegkas","Alkis Kalavasis, Amin Karbasi, Shay Moran, Grigoris Velegkas","Statistical Indistinguishability of Learning Algorithms",,,,,"cs.LG cs.DS stat.ML","http://creativecommons.org/licenses/by/4.0/","  When two different parties use the same learning rule on their own data, how
can we test whether the distributions of the two outcomes are similar? In this
paper, we study the similarity of outcomes of learning rules through the lens
of the Total Variation (TV) distance of distributions. We say that a learning
rule is TV indistinguishable if the expected TV distance between the posterior
distributions of its outputs, executed on two training data sets drawn
independently from the same distribution, is small. We first investigate the
learnability of hypothesis classes using TV indistinguishable learners. Our
main results are information-theoretic equivalences between TV
indistinguishability and existing algorithmic stability notions such as
replicability and approximate differential privacy. Then, we provide
statistical amplification and boosting algorithms for TV indistinguishable
learners.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:49:56 GMT""}]","2023-05-24"
"2305.14312","Tsu-Jui Fu","Tsu-Jui Fu and Wenhan Xiong and Yixin Nie and Jingyu Liu and Barlas
  O\u{g}uz and William Yang Wang","Text-guided 3D Human Generation from 2D Collections","Project website: https://text-3dh.github.io/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D human modeling has been widely used for engaging interaction in gaming,
film, and animation. The customization of these characters is crucial for
creativity and scalability, which highlights the importance of controllability.
In this work, we introduce Text-guided 3D Human Generation (\texttt{T3H}),
where a model is to generate a 3D human, guided by the fashion description.
There are two goals: 1) the 3D human should render articulately, and 2) its
outfit is controlled by the given text. To address this \texttt{T3H} task, we
propose Compositional Cross-modal Human (CCH). CCH adopts cross-modal attention
to fuse compositional human rendering with the extracted fashion semantics.
Each human body part perceives relevant textual guidance as its visual
patterns. We incorporate the human prior and semantic discrimination to enhance
3D geometry transformation and fine-grained consistency, enabling it to learn
from 2D collections for data efficiency. We conduct evaluations on DeepFashion
and SHHQ with diverse fashion attributes covering the shape, fabric, and color
of upper and lower clothing. Extensive experiments demonstrate that CCH
achieves superior results for \texttt{T3H} with high efficiency.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:50:15 GMT""}]","2023-05-24"
"2305.14313","Katharina Laubscher","Katharina Laubscher, Jay D. Sau, and Sankar Das Sarma","Majorana zero modes in gate-defined germanium hole nanowires",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically study gate-defined one-dimensional channels in planar Ge
hole gases as a potential platform for non-Abelian Majorana zero modes. We
model the valence band holes in the Ge channel by adding appropriate
confinement potentials to the 3D Luttinger-Kohn Hamiltonian, additionally
taking into account a magnetic field applied parallel to the channel, an
out-of-plane electric field, as well as the effect of compressive strain in the
parent quantum well. Assuming that the Ge channel is proximitized by an
$s$-wave superconductor (such as, e.g., Al) we calculate the topological phase
diagrams for different channel geometries, showing that sufficiently narrow Ge
hole channels can indeed enter a topological superconducting phase with
Majorana zero modes at the channel ends. We estimate the size of the
topological gap and its dependence on various system parameters such as channel
width, strain, and the applied out-of-plane electric field, allowing us to
critically discuss under which conditions Ge hole channels may manifest
Majorana zero modes. Since ultra-clean Ge quantum wells with hole mobilities
exceeding one million and mean-free paths on the order of many microns already
exist, gate-defined Ge hole channels may be able to overcome some of the
problems caused by the presence of substantial disorder in more conventional
Majorana platforms.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:50:30 GMT""}]","2023-05-24"
"2305.14314","Tim Dettmers","Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer","QLoRA: Efficient Finetuning of Quantized LLMs","Extended NeurIPS submission",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present QLoRA, an efficient finetuning approach that reduces memory usage
enough to finetune a 65B parameter model on a single 48GB GPU while preserving
full 16-bit finetuning task performance. QLoRA backpropagates gradients through
a frozen, 4-bit quantized pretrained language model into Low Rank
Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all
previous openly released models on the Vicuna benchmark, reaching 99.3% of the
performance level of ChatGPT while only requiring 24 hours of finetuning on a
single GPU. QLoRA introduces a number of innovations to save memory without
sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is
information theoretically optimal for normally distributed weights (b) double
quantization to reduce the average memory footprint by quantizing the
quantization constants, and (c) paged optimziers to manage memory spikes. We
use QLoRA to finetune more than 1,000 models, providing a detailed analysis of
instruction following and chatbot performance across 8 instruction datasets,
multiple model types (LLaMA, T5), and model scales that would be infeasible to
run with regular finetuning (e.g. 33B and 65B parameter models). Our results
show that QLoRA finetuning on a small high-quality dataset leads to
state-of-the-art results, even when using smaller models than the previous
SoTA. We provide a detailed analysis of chatbot performance based on both human
and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable
alternative to human evaluation. Furthermore, we find that current chatbot
benchmarks are not trustworthy to accurately evaluate the performance levels of
chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to
ChatGPT. We release all of our models and code, including CUDA kernels for
4-bit training.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:50:33 GMT""}]","2023-05-24"
"2305.14315","Maximilian F. Steffen","Maximilian F. Steffen","Estimating a multivariate L\'evy density based on discrete observations",,,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Existing results for the estimation of the L\'evy measure are mostly limited
to the onedimensional setting. We apply the spectral method to multidimensional
L\'evy processes in order to construct a nonparametric estimator for the
multivariate jump distribution. We prove convergence rates for the uniform
estimation error under both a low- and a high-frequency observation regime. The
method is robust to various dependence structures. Along the way, we present a
uniform risk bound for the multivariate empirical characteristic function and
its partial derivatives. The method is illustrated with simulation examples.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:51:00 GMT""}]","2023-05-24"
"2305.14316","Timo Peltola","N. Akchurin, G. Altopp, B. Burkle, W. D. Frey, U. Heintz, N. Hinton,
  M. Hoeferkamp, Y. Kazhykarim, V. Kuryatkov, T. Mengke, T. Peltola, S. Seidel,
  E. Spencer, M. Tripathi, J. Voelker","Modeling of Surface Damage at the Si/SiO$_2$-interface of Irradiated
  MOS-capacitors","Corresponding author: T. Peltola. 24 pages, 17 figures, 6 tables",,,"APDL-2023-001","physics.ins-det","http://creativecommons.org/publicdomain/zero/1.0/","  Surface damage caused by ionizing radiation in SiO$_2$ passivated silicon
particle detectors consists mainly of the accumulation of a positively charged
layer along with trapped-oxide-charge and interface traps inside the oxide and
close to the Si/SiO$_2$-interface. High density positive interface net charge
can be detrimental to the operation of a multi-channel $n$-on-$p$ sensor since
the inversion layer generated under the Si/SiO$_2$-interface can cause loss of
position resolution by creating a conduction channel between the electrodes. In
the investigation of the radiation-induced accumulation of oxide charge and
interface traps, a capacitance-voltage characterization study of n/$\gamma$-
and $\gamma$-irradiated Metal-Oxide-Semiconductor (MOS) capacitors showed that
close agreement between measurement and simulation were possible when oxide
charge density was complemented by both acceptor- and donor-type deep interface
traps with densities comparable to the oxide charges. Corresponding inter-strip
resistance simulations of a $n$-on-$p$ sensor with the tuned oxide charge
density and interface traps show close agreement with experimental results. The
beneficial impact of radiation-induced accumulation of deep interface traps on
inter-electrode isolation may be considered in the optimization of the
processing parameters of isolation implants on $n$-on-$p$ sensors for the
extreme radiation environments.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:51:06 GMT""}]","2023-05-24"
"2305.14317","Kate Napier","Kate Napier and Mike Gladders and Keren Sharon and H{\aa}kon Dahle and
  Aidan P. Cloonan and Guillaume Mahler and Isaiah Escapa and Josh Garza and
  Andrew Kisare and Natalie Malagon and Simon Mork and Kunwanhui Niu and Riley
  Rosener and Jamar Sullivan Jr. and Marie Tagliavia and Marcos Tamargo and
  Raul Teixeira and Kabelo Tsiane and Grace Wagner and Yunchong Zhang and Megan
  Zhao","COOL-LAMPS. V. Discovery of COOL J0335$-$1927, a Gravitationally Lensed
  Quasar at $z$=3.27 with an Image Separation of 23.3""","8 pages, 4 figures, 1 table",,,,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of COOL J0335$-$1927, a quasar at $z$ = 3.27 lensed
into three images with a maximum separation of 23.3"" by a galaxy cluster at $z$
= 0.4178. We construct a parametric strong gravitational lens model using
ground-based imaging, constrained by the redshift and positions of the quasar
images as well as the positions of three other multiply-imaged background
galaxies. Using our best-fit lens model, we calculate the predicted time delays
between the three quasar images to be $\Delta$t$_{AB}=$ $241^{+41}_{-12}$ and
$\Delta$t$_{AC}=$ $-64^{+3}_{-33}$ days. We also present g-band photometry from
archival DECaLS imaging, and new multi-epoch observations obtained between
September 18, 2022 UT and February 22, 2023 UT, which demonstrate significant
variability in the quasar and which will eventually enable a measurement of the
time delay between the three quasar images.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:51:10 GMT""}]","2023-05-24"
"2305.14318","Cheng Qian","Cheng Qian, Chi Han, Yi R. Fung, Yujia Qin, Zhiyuan Liu, Heng Ji","CREATOR: Disentangling Abstract and Concrete Reasonings of Large
  Language Models through Tool Creation",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Language Models (LLMs) have demonstrated significant progress in
utilizing external APIs as tools for various tasks. However, their tool-using
ability is limited by the availability of suitable APIs and the instability of
implicit reasoning, particularly when simultaneously engaging in reasoning
about plans and actual calculations. To address these limitations, we propose
CREATOR, a novel framework that empowers LLMs to create their own tools through
documentation and code realization. CREATOR disentangles the LLM's ability into
two distinct phases: abstract tool creation and concrete decision execution,
which results in improved LLM performance. We evaluate CREATOR on two
established benchmarks: MATH, which consists of challenging math competition
problems, and TabMWP, which includes diverse tabular contents for
problem-solving. Remarkably, CREATOR significantly outperforms existing
chain-of-thought (CoT), program-of-thought (PoT), and tool-using baselines on
these two benchmarks. Additionally, we present a new dataset, Creation
Challenge, comprising 2K diverse questions, to highlight the necessity and
benefits of LLMs' tool creation ability in effectively addressing these
problems. Furthermore, our research reveals that leveraging LLMs as tool
creators facilitates knowledge transfer, and LLMs exhibit varying levels of
tool creation abilities, enabling them to flexibly tackle diverse situations.
Our study represents a promising avenue for maximizing the potential of LLMs
and advancing toward truly intelligent and adaptable AI systems.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:51:52 GMT""}]","2023-05-24"
"2305.14319","Thomas Trogdon","Thomas Trogdon","On the convergence of spectral methods involving non-compact operators",,,,,"math.NA cs.NA math.FA math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by Fredholm theory, we develop a framework to establish the
convergence of spectral methods for operator equations $\mathcal L u = f$. The
framework posits the existence of a left-Fredholm regulator for $\mathcal L$
and the existence of a sufficiently good approximation of this regulator.
Importantly, the numerical method itself need not make use of this extra
approximant. We apply the framework to finite-section and collocation-based
numerical methods for solving differential equations with periodic boundary
conditions and to solving Riemann--Hilbert problems on the unit circle. We also
obtain improved results concerning the approximation of eigenvalues of
differential operators with periodic coefficients.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:53:12 GMT""}]","2023-05-24"
"2305.14320","Vivek Nair","Vivek Nair, Viktor Radulov, James F. O'Brien","Results of the 2023 Census of Beat Saber Users: Virtual Reality Gaming
  Population Insights and Factors Affecting Virtual Reality E-Sports
  Performance","for interactive version, see https://www.beatleader.xyz/census2023",,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emergence of affordable standalone virtual reality (VR) devices has
allowed VR technology to reach mass-market adoption in recent years, driven
primarily by the popularity of VR gaming applications such as Beat Saber.
However, despite being the top-grossing VR application to date and the most
popular VR e-sport, the population of over 6 million Beat Saber users has not
yet been widely studied. In this report, we present a large-scale comprehensive
survey of Beat Saber players (N=1,006) that sheds light on several important
aspects of this population, including their background, biometrics,
demographics, health information, behavioral patterns, and technical device
specifications. We further provide insights into the emerging field of VR
e-sports by analyzing correlations between responses and an authoritative
measure of in-game performance.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:53:29 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 04:10:11 GMT""}]","2023-05-31"
"2305.14321","William Brannon","William Brannon, Suyash Fulay, Hang Jiang, Wonjune Kang, Brandon Roy,
  Jad Kabbara, Deb Roy","ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and
  Text Embeddings","3 figures, 9 tables",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose ConGraT(Contrastive Graph-Text pretraining), a general,
self-supervised method for jointly learning separate representations of texts
and nodes in a parent (or ``supervening'') graph, where each text is associated
with one of the nodes. Datasets fitting this paradigm are common, from social
media (users and posts), to citation networks over articles, to link graphs
over web pages. We expand on prior work by providing a general,
self-supervised, joint pretraining method, one which does not depend on
particular dataset structure or a specific task. Our method uses two separate
encoders for graph nodes and texts, which are trained to align their
representations within a common latent space. Training uses a batch-wise
contrastive learning objective inspired by prior work on joint text and image
encoding. As graphs are more structured objects than images, we also extend the
training objective to incorporate information about node similarity and
plausible next guesses in matching nodes and texts. Experiments on various
datasets reveal that ConGraT outperforms strong baselines on various downstream
tasks, including node and text category classification and link prediction.
Code and certain datasets are available at
https://github.com/wwbrannon/congrat.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:53:30 GMT""}]","2023-05-24"
"2305.14322","Ali Modarressi","Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, Hinrich Sch\""utze","RET-LLM: Towards a General Read-Write Memory for Large Language Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LLMs) have significantly advanced the field of natural
language processing (NLP) through their extensive parameters and comprehensive
data utilization. However, existing LLMs lack a dedicated memory unit, limiting
their ability to explicitly store and retrieve knowledge for various tasks. In
this paper, we propose RET-LLM a novel framework that equips LLMs with a
general write-read memory unit, allowing them to extract, store, and recall
knowledge from the text as needed for task performance. Inspired by Davidsonian
semantics theory, we extract and save knowledge in the form of triplets. The
memory unit is designed to be scalable, aggregatable, updatable, and
interpretable. Through qualitative evaluations, we demonstrate the superiority
of our proposed framework over baseline approaches in question answering tasks.
Moreover, our framework exhibits robust performance in handling temporal-based
question answering tasks, showcasing its ability to effectively manage
time-dependent information.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:53:38 GMT""}]","2023-05-24"
"2305.14323","Zhipeng Chen","Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne Xin Zhao and
  Ji-Rong Wen","ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large
  Language Models","11 pages, working in progress",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although large language models (LLMs) have achieved excellent performance in
a variety of evaluation benchmarks, they still struggle in complex reasoning
tasks which require specific knowledge and multi-hop reasoning. To improve the
reasoning abilities, we propose \textbf{ChatCoT}, a tool-augmented
chain-of-thought reasoning framework for chat-based LLMs. In ChatCoT, we model
the chain-of-thought~(CoT) reasoning as multi-turn conversations, to utilize
tools in a more natural way through chatting. At each turn, LLMs can either
interact with tools or perform the reasoning. Our approach can effectively
leverage the multi-turn conversation ability of chat-based LLMs, and integrate
the thought chain following and tools manipulation in a unified way. Specially,
we initialize the early turns of the conversation by the tools, tasks and
reasoning format, and propose an iterative \emph{tool-augmented reasoning} step
to perform step-by-step tool-augmented reasoning. The experiment results on two
complex reasoning datasets (MATH and HotpotQA) have shown the effectiveness of
ChatCoT on complex reasoning tasks, achieving a 6.8\% relative improvement over
the state-of-the-art baseline. Our code and data are available at:
\url{https://github.com/RUCAIBOX/ChatCoT}.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:54:33 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 11:40:59 GMT""}]","2023-05-25"
"2305.14324","Daniel Deutsch","Daniel Deutsch and George Foster and Markus Freitag","Ties Matter: Modifying Kendall's Tau for Modern Metric Meta-Evaluation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Kendall's tau is frequently used to meta-evaluate how well machine
translation (MT) evaluation metrics score individual translations. Its focus on
pairwise score comparisons is intuitive but raises the question of how ties
should be handled, a gray area that has motivated different variants in the
literature. We demonstrate that, in settings like modern MT meta-evaluation,
existing variants have weaknesses arising from their handling of ties, and in
some situations can even be gamed. We propose a novel variant that gives
metrics credit for correctly predicting ties, as well as an optimization
procedure that automatically introduces ties into metric scores, enabling fair
comparison between metrics that do and do not predict ties. We argue and
provide experimental evidence that these modifications lead to fairer
Kendall-based assessments of metric performance.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:54:57 GMT""}]","2023-05-24"
"2305.14325","Yilun Du","Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, Igor
  Mordatch","Improving Factuality and Reasoning in Language Models through Multiagent
  Debate","Project Webpage and Code:
  https://composable-models.github.io/llm_debate/",,,,"cs.CL cs.AI cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have demonstrated remarkable capabilities in
language generation, understanding, and few-shot learning in recent years. An
extensive body of work has explored how their performance may be further
improved through the tools of prompting, ranging from verification,
self-consistency, or intermediate scratchpads. In this paper, we present a
complementary approach to improve language responses where multiple language
model instances propose and debate their individual responses and reasoning
processes over multiple rounds to arrive at a common final answer. Our findings
indicate that this approach significantly enhances mathematical and strategic
reasoning across a number of tasks. We also demonstrate that our approach
improves the factual validity of generated content, reducing fallacious answers
and hallucinations that contemporary models are prone to. Our approach may be
directly applied to existing black-box models and uses identical procedure and
prompts for all tasks we investigate. Overall, our findings suggest that such
""society of minds"" approach has the potential to significantly advance the
capabilities of LLMs and pave the way for further breakthroughs in language
generation and understanding.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:55:11 GMT""}]","2023-05-24"
"2305.14326","Chan Young Park","Lucille Njoo, Chan Young Park, Octavia Stappart, Marvin Thielk, Yi Chu
  and Yulia Tsvetkov","TalkUp: A Novel Dataset Paving the Way for Understanding Empowering
  Language",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Empowering language is important in many real-world contexts, from education
to workplace dynamics to healthcare. Though language technologies are growing
more prevalent in these contexts, empowerment has not been studied in NLP, and
moreover, it is inherently challenging to operationalize because of its subtle,
implicit nature. This work presents the first computational exploration of
empowering language. We first define empowerment detection as a new task,
grounding it in linguistic and social psychology literature. We then
crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons
why these posts are empowering to readers, and the social relationships between
posters and readers. Our preliminary analyses show that this dataset, which we
call TalkUp, can be used to train language models that capture empowering and
disempowering language. More broadly, as it is rich with the ambiguities and
diverse interpretations of real-world language, TalkUp provides an avenue to
explore implication, presuppositions, and how social context influences the
meaning of language.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:55:34 GMT""}]","2023-05-24"
"2305.14327","Da Yin","Da Yin, Xiao Liu, Fan Yin, Ming Zhong, Hritik Bansal, Jiawei Han,
  Kai-Wei Chang","Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation","Work in progress",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Instruction tuning has emerged to enhance the capabilities of large language
models (LLMs) in providing appropriate outputs based on input instructions.
However, existing methods for collecting instruction-tuning data suffer from
limitations in scalability and affordability. In this paper, we propose
Dynosaur, a dynamic growth paradigm for instruction-tuning data curation. Built
upon the metadata of existing NLP datasets, we generate multiple task
instructions applicable to various NLP datasets and determine the relevant data
fields for constructing instruction-tuning data with LLMs. Dynosaur offers
several advantages: 1) lower generation costs (less than $12 for generating
800K instruction-tuning data), 2) good quality of instruction-tuning data
(better performance than Alpaca and Instruction GPT-4 on Super-NI with
comparable data sizes), and 3) the ability to grow dynamically by incorporating
new datasets from Huggingface Datasets Platform. We further investigate
continual learning as an approach to learning with the ever-growing
instruction-tuning dataset. We demonstrate that replay methods not only help
mitigate forgetting issues but help generalize to unseen tasks better. As a
novel continual learning scenario for instruction tuning, selecting tasks based
on instruction representations can be an effective replaying strategy. Code and
data are released at \url{https://github.com/WadeYin9712/Dynosaur}.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:56:26 GMT""}]","2023-05-24"
"2305.14328","Binwei Yao","Binwei Yao, Ming Jiang, Diyi Yang, Junjie Hu","Empowering LLM-based Machine Translation with Cultural Awareness",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Traditional neural machine translation (NMT) systems often fail to translate
sentences that contain culturally specific information. Most previous NMT
methods have incorporated external cultural knowledge during training, which
requires fine-tuning on low-frequency items specific to the culture. Recent
in-context learning utilizes lightweight prompts to guide large language models
(LLMs) to perform machine translation, however, whether such an approach works
in terms of injecting culture awareness into machine translation remains
unclear. To this end, we introduce a new data curation pipeline to construct a
culturally relevant parallel corpus, enriched with annotations of
cultural-specific entities. Additionally, we design simple but effective
prompting strategies to assist this LLM-based translation. Extensive
experiments show that our approaches can largely help incorporate cultural
knowledge into LLM-based machine translation, outperforming traditional NMT
systems in translating cultural-specific sentences.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:56:33 GMT""}]","2023-05-24"
"2305.14329","Fivos Kalogiannis","Fivos Kalogiannis, Ioannis Panageas","Zero-sum Polymatrix Markov Games: Equilibrium Collapse and Efficient
  Computation of Nash Equilibria","Added missing proofs for the infinite-horizon",,,,"cs.GT cs.MA cs.SI","http://creativecommons.org/licenses/by/4.0/","  The works of (Daskalakis et al., 2009, 2022; Jin et al., 2022; Deng et al.,
2023) indicate that computing Nash equilibria in multi-player Markov games is a
computationally hard task. This fact raises the question of whether or not
computational intractability can be circumvented if one focuses on specific
classes of Markov games. One such example is two-player zero-sum Markov games,
in which efficient ways to compute a Nash equilibrium are known. Inspired by
zero-sum polymatrix normal-form games (Cai et al., 2016), we define a class of
zero-sum multi-agent Markov games in which there are only pairwise interactions
described by a graph that changes per state. For this class of Markov games, we
show that an $\epsilon$-approximate Nash equilibrium can be found efficiently.
To do so, we generalize the techniques of (Cai et al., 2016), by showing that
the set of coarse-correlated equilibria collapses to the set of Nash
equilibria. Afterwards, it is possible to use any algorithm in the literature
that computes approximate coarse-correlated equilibria Markovian policies to
get an approximate Nash equilibrium.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:56:45 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 17:57:58 GMT""}]","2023-05-30"
"2305.14330","Susung Hong","Susung Hong, Junyoung Seo, Sunghwan Hong, Heeseong Shin, Seungryong
  Kim","Large Language Models are Frame-level Directors for Zero-shot
  Text-to-Video Generation","The code and demo will be available at
  https://github.com/KU-CVLAB/DirecT2V",,,,"cs.CV cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  In the paradigm of AI-generated content (AIGC), there has been increasing
attention in extending pre-trained text-to-image (T2I) models to text-to-video
(T2V) generation. Despite their effectiveness, these frameworks face challenges
in maintaining consistent narratives and handling rapid shifts in scene
composition or object placement from a single user prompt. This paper
introduces a new framework, dubbed DirecT2V, which leverages instruction-tuned
large language models (LLMs) to generate frame-by-frame descriptions from a
single abstract user prompt. DirecT2V utilizes LLM directors to divide user
inputs into separate prompts for each frame, enabling the inclusion of
time-varying content and facilitating consistent video generation. To maintain
temporal consistency and prevent object collapse, we propose a novel value
mapping method and dual-softmax filtering. Extensive experimental results
validate the effectiveness of the DirecT2V framework in producing visually
coherent and consistent videos from abstract user prompts, addressing the
challenges of zero-shot video generation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:57:09 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 04:14:59 GMT""}]","2023-06-02"
"2305.14331","Navita Goyal","Navita Goyal, Eleftheria Briakou, Amanda Liu, Connor Baumler, Claire
  Bonial, Jeffrey Micher, Clare R. Voss, Marine Carpuat, Hal Daum\'e III","What Else Do I Need to Know? The Effect of Background Information on
  Users' Reliance on AI Systems","12 pages",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  AI systems have shown impressive performance at answering questions by
retrieving relevant context. However, with the increasingly large models, it is
impossible and often undesirable to constrain models' knowledge or reasoning to
only the retrieved context. This leads to a mismatch between the information
that these models access to derive the answer and the information available to
the user consuming the AI predictions to assess the AI predicted answer. In
this work, we study how users interact with AI systems in absence of sufficient
information to assess AI predictions. Further, we ask the question of whether
adding the requisite background alleviates the concerns around over-reliance in
AI predictions. Our study reveals that users rely on AI predictions even in the
absence of sufficient information needed to assess its correctness. Providing
the relevant background, however, helps users catch AI errors better, reducing
over-reliance on incorrect AI predictions. On the flip side, background
information also increases users' confidence in their correct as well as
incorrect judgments. Contrary to common expectation, aiding a user's perusal of
the context and the background through highlights is not helpful in alleviating
the issue of over-confidence stemming from availability of more information.
Our work aims to highlight the gap between how NLP developers perceive
informational need in human-AI interaction and the actual human interaction
with the information available to them.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:57:12 GMT""}]","2023-05-24"
"2305.14332","Benjamin Muller","Benjamin Muller, John Wieting, Jonathan H. Clark, Tom Kwiatkowski,
  Sebastian Ruder, Livio Baldini Soares, Roee Aharoni, Jonathan Herzig, Xinyi
  Wang","Evaluating and Modeling Attribution for Cross-Lingual Question Answering",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trustworthy answer content is abundant in many high-resource languages and is
instantly accessible through question answering systems, yet this content can
be hard to access for those that do not speak these languages. The leap forward
in cross-lingual modeling quality offered by generative language models offers
much promise, yet their raw generations often fall short in factuality. To
improve trustworthiness in these systems, a promising direction is to attribute
the answer to a retrieved source, possibly in a content-rich language different
from the query. Our work is the first to study attribution for cross-lingual
question answering. First, we collect data in 5 languages to assess the
attribution level of a state-of-the-art cross-lingual QA system. To our
surprise, we find that a substantial portion of the answers is not attributable
to any retrieved passages (up to 50% of answers exactly matching a gold
reference) despite the system being able to attend directly to the retrieved
text. Second, to address this poor attribution level, we experiment with a wide
range of attribution detection techniques. We find that Natural Language
Inference models and PaLM 2 fine-tuned on a very small amount of attribution
data can accurately detect attribution. Based on these models, we improve the
attribution level of a cross-lingual question-answering system. Overall, we
show that current academic generative cross-lingual QA systems have substantial
shortcomings in attribution and we build tooling to mitigate these issues.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:57:46 GMT""}]","2023-05-24"
"2305.14333","Xu Zhao","Xu Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, Qizhe Xie","Automatic Model Selection with Large Language Models for Reasoning",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Chain-of-Thought and Program-Aided Language Models represent two distinct
reasoning methods, each with its own strengths and weaknesses. We demonstrate
that it is possible to combine the best of both worlds by using different
models for different problems, employing a large language model (LLM) to
perform model selection. Through a theoretical analysis, we discover that the
performance improvement is determined by the differences between the combined
methods and the success rate of choosing the correct model. On eight reasoning
datasets, our proposed approach shows significant improvements. Furthermore, we
achieve new state-of-the-art results on GSM8K and SVAMP with accuracies of
96.5% and 93.7%, respectively. Our code is publicly available at
https://github.com/XuZhao0/Model-Selection-Reasoning.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:57:59 GMT""}]","2023-05-24"
"2305.14334","Grace Luo","Grace Luo, Lisa Dunlap, Dong Huk Park, Aleksander Holynski, Trevor
  Darrell","Diffusion Hyperfeatures: Searching Through Time and Space for Semantic
  Correspondence",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion models have been shown to be capable of generating high-quality
images, suggesting that they could contain meaningful internal representations.
Unfortunately, the feature maps that encode a diffusion model's internal
information are spread not only over layers of the network, but also over
diffusion timesteps, making it challenging to extract useful descriptors. We
propose Diffusion Hyperfeatures, a framework for consolidating multi-scale and
multi-timestep feature maps into per-pixel feature descriptors that can be used
for downstream tasks. These descriptors can be extracted for both synthetic and
real images using the generation and inversion processes. We evaluate the
utility of our Diffusion Hyperfeatures on the task of semantic keypoint
correspondence: our method achieves superior performance on the SPair-71k real
image benchmark. We also demonstrate that our method is flexible and
transferable: our feature aggregation network trained on the inversion features
of real image pairs can be used on the generation features of synthetic image
pairs with unseen objects and compositions. Our code is available at
\url{https://diffusion-hyperfeatures.github.io}.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:58:05 GMT""}]","2023-05-24"
"2305.14335","Henghui Ding","Shuting He, Xudong Jiang, Wei Jiang, Henghui Ding","Prototype Adaption and Projection for Few- and Zero-shot 3D Point Cloud
  Semantic Segmentation","IEEE TIP",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we address the challenging task of few-shot and zero-shot 3D
point cloud semantic segmentation. The success of few-shot semantic
segmentation in 2D computer vision is mainly driven by the pre-training on
large-scale datasets like imagenet. The feature extractor pre-trained on
large-scale 2D datasets greatly helps the 2D few-shot learning. However, the
development of 3D deep learning is hindered by the limited volume and instance
modality of datasets due to the significant cost of 3D data collection and
annotation. This results in less representative features and large intra-class
feature variation for few-shot 3D point cloud segmentation. As a consequence,
directly extending existing popular prototypical methods of 2D few-shot
classification/segmentation into 3D point cloud segmentation won't work as well
as in 2D domain. To address this issue, we propose a Query-Guided Prototype
Adaption (QGPA) module to adapt the prototype from support point clouds feature
space to query point clouds feature space. With such prototype adaption, we
greatly alleviate the issue of large feature intra-class variation in point
cloud and significantly improve the performance of few-shot 3D segmentation.
Besides, to enhance the representation of prototypes, we introduce a
Self-Reconstruction (SR) module that enables prototype to reconstruct the
support mask as well as possible. Moreover, we further consider zero-shot 3D
point cloud semantic segmentation where there is no support sample. To this
end, we introduce category words as semantic information and propose a
semantic-visual projection model to bridge the semantic and visual spaces. Our
proposed method surpasses state-of-the-art algorithms by a considerable 7.90%
and 14.82% under the 2-way 1-shot setting on S3DIS and ScanNet benchmarks,
respectively. Code is available at https://github.com/heshuting555/PAP-FZS3D.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:58:05 GMT""}]","2023-05-24"
"2305.14336","Fan Bai","Fan Bai, Junmo Kang, Gabriel Stanovsky, Dayne Freitag, Alan Ritter","Schema-Driven Information Extraction from Heterogeneous Tables",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this paper, we explore the question of whether language models (LLMs) can
support cost-efficient information extraction from complex tables. We introduce
schema-driven information extraction, a new task that uses LLMs to transform
tabular data into structured records following a human-authored schema. To
assess various LLM's capabilities on this task, we develop a benchmark composed
of tables from three diverse domains: machine learning papers, chemistry
tables, and webpages. Accompanying the benchmark, we present InstrucTE, a table
extraction method based on instruction-tuned LLMs. This method necessitates
only a human-constructed extraction schema, and incorporates an error-recovery
strategy. Notably, InstrucTE demonstrates competitive performance without
task-specific labels, achieving an F1 score ranging from 72.3 to 95.7.
Moreover, we validate the feasibility of distilling more compact table
extraction models to minimize extraction costs and reduce API reliance. This
study paves the way for the future development of instruction-following models
for cost-efficient table extraction.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:58:10 GMT""}]","2023-05-24"
"2305.14337","Nelson F. Liu","Nelson F. Liu and Kenton Lee and Kristina Toutanova","Anchor Prediction: Automatic Refinement of Internet Links","10 pages, 2 figures",,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Internet links enable users to deepen their understanding of a topic by
providing convenient access to related information. However, the majority of
links are unanchored -- they link to a target webpage as a whole, and readers
may expend considerable effort localizing the specific parts of the target
webpage that enrich their understanding of the link's source context. To help
readers effectively find information in linked webpages, we introduce the task
of anchor prediction, where the goal is to identify the specific part of the
linked target webpage that is most related to the source linking context. We
release the AuthorAnchors dataset, a collection of 34K naturally-occurring
anchored links, which reflect relevance judgments by the authors of the source
article. To model reader relevance judgments, we annotate and release
ReaderAnchors, an evaluation set of anchors that readers find useful. Our
analysis shows that effective anchor prediction often requires jointly
reasoning over lengthy source and target webpages to determine their implicit
relations and identify parts of the target webpage that are related but not
redundant. We benchmark a performant T5-based ranking approach to establish
baseline performance on the task, finding ample room for improvement.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:58:21 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 07:12:33 GMT""}]","2023-05-25"
"2305.14338","Matthew Smart","Matthew Smart, Stanislav Shvartsman, Hayden Nunley","A model of replicating coupled oscillators generates naturally occurring
  cell networks",,,,,"nlin.AO math.DS q-bio.CB","http://creativecommons.org/licenses/by-nc-nd/4.0/","  When a founder cell and its progeny divide with incomplete cytokinesis, a
network forms in which each intercellular bridge corresponds to a past mitotic
event. Networks built in this manner are required for gamete production in many
animals, and different species have evolved very different final network
topologies. While mechanisms regulating network assembly have been identified
in particular organisms, we lack a quantitative framework to understand network
assembly and inter-species variability. Motivated by cell networks responsible
for oocyte production in invertebrates, where the final topology is typically
invariant within each species, we devise a mathematical model for generating
cell networks: each node is an oscillator, and after a full cycle, the node
produces a daughter to which it remains connected. These cell cycle
oscillations on the nodes are transient and coupled via diffusion over the
network's edges. By variation of three biologically motivated parameters, our
model generates nearly all such networks currently reported across
invertebrates. Furthermore, small parameter variations can rationalize cases of
within-species variation. Because cell networks outside of the ovary often form
less deterministically, we propose generalizations of our model to account for
different sources of stochasticity.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:01 GMT""}]","2023-05-24"
"2305.14339","Bin Zhuang","Bin Zhuang, No\'e Lugaz, Nada Al-Haddad, R\'eka M. Winslow, Camilla
  Scolini, Charles J. Farrugia, and Antoinette B. Galvin","Evolution of the Radial Size and Expansion of Coronal Mass Ejections
  Investigated by Combining Remote and In-Situ Observations","Accepted by ApJ",,,,"astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  A fundamental property of coronal mass ejections (CMEs) is their radial
expansion, which determines the increase in the CME radial size and the
decrease in the CME magnetic field strength as the CME propagates. CME radial
expansion can be investigated either by using remote observations or by in-situ
measurements based on multiple spacecraft in radial conjunction. However, there
have been only few case studies combining both remote and in-situ observations.
It is therefore unknown if the radial expansion estimated remotely in the
corona is consistent with that estimated locally in the heliosphere. To address
this question, we first select 22 CME events between the years 2010 and 2013,
which were well observed by coronagraphs and by two or three spacecraft in
radial conjunction. We use the graduated cylindrical shell model to estimate
the radial size, radial expansion speed, and a measure of the dimensionless
expansion parameter of CMEs in the corona. The same parameters and two
additional measures of the radial-size increase and magnetic-field-strength
decrease with heliocentric distance of CMEs based on in-situ measurements are
also calculated. For most of the events, the CME radial size estimated by
remote observations is inconsistent with the in-situ estimates. We further
statistically analyze the correlations of these expansion parameters estimated
using remote and in-situ observations, and discuss the potential reasons for
the inconsistencies and their implications for the CME space weather
forecasting.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:13 GMT""}]","2023-05-24"
"2305.14340","Ramalingam Kailasham","R. Kailasham and Aditya S. Khair","Effect of speed fluctuations on the collective dynamics of active disks","10 pages, 10 figures, 8 supplementary videos",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Numerical simulations are performed on the collective dynamics of active
disks, whose self-propulsion speed ($U$) varies in time, and whose orientation
evolves according to rotational Brownian motion. Two protocols for the
evolution of speed are considered: (i) a deterministic one involving a periodic
change in U at a frequency $\omega$; and (ii) a stochastic one in which the
speeds are drawn from a power-law distribution at time-intervals governed by a
Poissonian process of rate $\beta$. In the first case, an increase in $\omega$
causes the disks to go from a clustered state to a homogeneous one through a
transition that has an intriguing analogy to the 2D Ising model, provided that
the direction of self-propulsion is allowed to reverse. Similarly, in the
second case, for a fixed value of $\beta$, the extent of cluster-breakup is
larger when reversals in the self-propulsion direction are permitted.
Motility-induced phase separation of the disks may therefore be avoided in
active matter suspensions in which the constituents are allowed to reverse
their self-propulsion direction, immaterial of the precise temporal nature of
the reversal (deterministic or stochastic). Equally, our results demonstrate
that phase separation could occur even in the absence of a time-averaged
motility of an individual active agent, provided that the rate of direction
reversals is smaller than the orientational diffusion rate.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:13 GMT""}]","2023-05-24"
"2305.14341","Lucy Lu Wang","Yue Guo, Tal August, Gondy Leroy, Trevor Cohen, Lucy Lu Wang","APPLS: A Meta-evaluation Testbed for Plain Language Summarization",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  While there has been significant development of models for Plain Language
Summarization (PLS), evaluation remains a challenge. This is in part because
PLS involves multiple, interrelated language transformations (e.g., adding
background explanations, removing specialized terminology). No metrics are
explicitly engineered for PLS, and the suitability of other text generation
evaluation metrics remains unclear. To address these concerns, our study
presents a granular meta-evaluation testbed, APPLS, designed to evaluate
existing metrics for PLS. Drawing on insights from previous research, we define
controlled perturbations for our testbed along four criteria that a metric of
plain language should capture: informativeness, simplification, coherence, and
faithfulness. Our analysis of metrics using this testbed reveals that current
metrics fail to capture simplification, signaling a crucial gap. In response,
we introduce POMME, a novel metric designed to assess text simplification in
PLS. We demonstrate its correlation with simplification perturbations and
validate across a variety of datasets. Our research contributes the first
meta-evaluation testbed for PLS and a comprehensive evaluation of existing
metrics, offering insights with relevance to other text generation tasks.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:19 GMT""}]","2023-05-24"
"2305.14342","Hong Liu","Hong Liu, Zhiyuan Li, David Hall, Percy Liang, Tengyu Ma","Sophia: A Scalable Stochastic Second-order Optimizer for Language Model
  Pre-training",,,,,"cs.LG cs.CL math.OC","http://creativecommons.org/licenses/by/4.0/","  Given the massive cost of language model pre-training, a non-trivial
improvement of the optimization algorithm would lead to a material reduction on
the time and cost of training. Adam and its variants have been state-of-the-art
for years, and more sophisticated second-order (Hessian-based) optimizers often
incur too much per-step overhead. In this paper, we propose Sophia,
Second-order Clipped Stochastic Optimization, a simple scalable second-order
optimizer that uses a light-weight estimate of the diagonal Hessian as the
pre-conditioner. The update is the moving average of the gradients divided by
the moving average of the estimated Hessian, followed by element-wise clipping.
The clipping controls the worst-case update size and tames the negative impact
of non-convexity and rapid change of Hessian along the trajectory. Sophia only
estimates the diagonal Hessian every handful of iterations, which has
negligible average per-step time and memory overhead. On language modeling with
GPT-2 models of sizes ranging from 125M to 770M, Sophia achieves a 2x speed-up
compared with Adam in the number of steps, total compute, and wall-clock time.
Theoretically, we show that Sophia adapts to the curvature in different
components of the parameters, which can be highly heterogeneous for language
modeling tasks. Our run-time bound does not depend on the condition number of
the loss.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:21 GMT""}]","2023-05-24"
"2305.14343","Alejandro Escontrela","Alejandro Escontrela and Ademi Adeniji and Wilson Yan and Ajay Jain
  and Xue Bin Peng and Ken Goldberg and Youngwoon Lee and Danijar Hafner and
  Pieter Abbeel","Video Prediction Models as Rewards for Reinforcement Learning","22 pages, 18 figures, 4 tables. under review",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Specifying reward signals that allow agents to learn complex behaviors is a
long-standing challenge in reinforcement learning. A promising approach is to
extract preferences for behaviors from unlabeled videos, which are widely
available on the internet. We present Video Prediction Rewards (VIPER), an
algorithm that leverages pretrained video prediction models as action-free
reward signals for reinforcement learning. Specifically, we first train an
autoregressive transformer on expert videos and then use the video prediction
likelihoods as reward signals for a reinforcement learning agent. VIPER enables
expert-level control without programmatic task rewards across a wide range of
DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction
model allows us to derive rewards for an out-of-distribution environment where
no expert data is available, enabling cross-embodiment generalization for
tabletop manipulation. We see our work as starting point for scalable reward
specification from unlabeled videos that will benefit from the rapid advances
in generative modeling. Source code and datasets are available on the project
website: https://escontrela.me/viper
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:33 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 17:38:44 GMT""}]","2023-05-31"
"2305.14344","Agrim Gupta","Agrim Gupta, Jiajun Wu, Jia Deng, Li Fei-Fei","Siamese Masked Autoencoders","Project page https://siam-mae-video.github.io/",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Establishing correspondence between images or scenes is a significant
challenge in computer vision, especially given occlusions, viewpoint changes,
and varying object appearances. In this paper, we present Siamese Masked
Autoencoders (SiamMAE), a simple extension of Masked Autoencoders (MAE) for
learning visual correspondence from videos. SiamMAE operates on pairs of
randomly sampled video frames and asymmetrically masks them. These frames are
processed independently by an encoder network, and a decoder composed of a
sequence of cross-attention layers is tasked with predicting the missing
patches in the future frame. By masking a large fraction ($95\%$) of patches in
the future frame while leaving the past frame unchanged, SiamMAE encourages the
network to focus on object motion and learn object-centric representations.
Despite its conceptual simplicity, features learned via SiamMAE outperform
state-of-the-art self-supervised methods on video object segmentation, pose
keypoint propagation, and semantic part propagation tasks. SiamMAE achieves
competitive results without relying on data augmentation, handcrafted
tracking-based pretext tasks, or other techniques to prevent representational
collapse.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:46 GMT""}]","2023-05-24"
"2305.14345","Taeksoo Kim","Taeksoo Kim, Shunsuke Saito, Hanbyul Joo","NCHO: Unsupervised Learning for Neural 3D Composition of Humans and
  Objects","The project page is available at https://taeksuu.github.io/ncho/",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep generative models have been recently extended to synthesizing 3D digital
humans. However, previous approaches treat clothed humans as a single chunk of
geometry without considering the compositionality of clothing and accessories.
As a result, individual items cannot be naturally composed into novel
identities, leading to limited expressiveness and controllability of generative
3D avatars. While several methods attempt to address this by leveraging
synthetic data, the interaction between humans and objects is not authentic due
to the domain gap, and manual asset creation is difficult to scale for a wide
variety of objects. In this work, we present a novel framework for learning a
compositional generative model of humans and objects (backpacks, coats,
scarves, and more) from real-world 3D scans. Our compositional model is
interaction-aware, meaning the spatial relationship between humans and objects,
and the mutual shape change by physical contact is fully incorporated. The key
challenge is that, since humans and objects are in contact, their 3D scans are
merged into a single piece. To decompose them without manual annotations, we
propose to leverage two sets of 3D scans of a single person with and without
objects. Our approach learns to decompose objects and naturally compose them
back into a generative human model in an unsupervised manner. Despite our
simple setup requiring only the capture of a single subject with objects, our
experiments demonstrate the strong generalization of our model by enabling the
natural composition of objects to diverse identities in various poses and the
composition of multiple objects, which is unseen in training data.
https://taeksuu.github.io/ncho/
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:52 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 13:51:25 GMT""}]","2023-05-30"
"2305.14346","Theresa Anderson","Theresa C. Anderson and Eyvindur A. Palsson","A framework for discrete bilinear spherical averages and applications to
  $\ell^p$-improving estimates",,,,,"math.CA math.NT","http://creativecommons.org/licenses/by/4.0/","  We provide a refined pointwise upper bound for the discrete bilinear
spherical averaging operator. This builds on the slicing techniques of Jeong
and Lee in the discrete (number theoretic) setting, and significantly tightens
the bounds from previous work of the authors. A variety of applications are
presented, most notably to $\ell^p$-improving estimates.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:58 GMT""}]","2023-05-24"
"2305.14347","Nikhil Sarin","Nikhil Sarin, Axel Brandenburg, Brynmor Haskell","Confronting the neutron star population with inverse cascades","Submitted. 6 pages, 3 figures",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The origin and evolution of magnetic fields of neutron stars from birth has
long been a source of debate. Here, motivated by recent simulations of the Hall
cascade with magnetic helicity, we invoke a model where the large-scale
magnetic field of neutron stars grows as a product of small-scale turbulence
through an inverse cascade. We apply this model to a simulated population of
neutron stars at birth and show how this model can account for the evolution of
such objects across the $P\dot{P}$ diagram, explaining both pulsar and magnetar
observations. Under the assumption that small-scale turbulence is responsible
for large-scale magnetic fields, we place a lower limit on the spherical
harmonic degree of the energy-carrying magnetic eddies of $\approx 40$. Our
results favor the presence of a highly resistive pasta layer at the base of the
neutron star crust. We further discuss the implications of this paradigm on
direct observables, such as the nominal age and braking index of pulsars.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:59 GMT""}]","2023-05-24"
"2305.14348","Robert Throckmorton","Robert E. Throckmorton and S. Das Sarma","A generalized model of the noise spectrum of a two-level fluctuator in
  the presence of an electron subbath","6+$\epsilon$ pages, 4 figures. To be submitted for publication",,,,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The work of Ahn derives the noise power spectrum of a two-level fluctuator
(TLF) in the case that it interacts only with a subregion of a full electron
bath and thus is subject to a fluctuating temperature. However, Eq.~(1), which
gives the variance of the subbath temperature in terms of the heat capacity, in
that work carries the implicit assumption that the heat capacity of this
subbath may be taken to be a constant, which is a good approximation at higher
temperatures, but breaks down at lower temperatures. We thus extend this work
to the case in which the fact that the electronic heat capacity of a
two-dimensional electron gas (2DEG) $C_V\propto T$, rather than constant in
temperature, is fully taken into account. We show that, at low temperatures,
the resulting power spectrum of the noise $S(\omega)\propto e^{-C/T^{3/8}}$, in
contrast to $S(\omega)\propto e^{-C'/T^{1/3}}$ as found previously, where $C$
and $C'$ are constants. We also compare the numerical results that one would
obtain from the two models and find that our results for $S(\omega)$ can differ
from those of Ahn by several orders of magnitude at low temperatures.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:59 GMT""}]","2023-05-24"
"2305.14410","Dinesh Khandelwal","Harman Singh, Poorva Garg, Mohit Gupta, Kevin Shah, Arnab Kumar
  Mondal, Dinesh Khandelwal, Parag Singla, Dinesh Garg","Image Manipulation via Multi-Hop Instructions -- A New Dataset and
  Weakly-Supervised Neuro-Symbolic Approach",,,,,"cs.CV cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are interested in image manipulation via natural language text -- a task
that is useful for multiple AI applications but requires complex reasoning over
multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning
(NSCL), which has been quite effective for the task of Visual Question
Answering (VQA), for the task of image manipulation. Our system referred to as
NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and
only requires weak supervision in the form of annotated data for VQA. NeuroSIM
parses an instruction into a symbolic program, based on a Domain Specific
Language (DSL) comprising of object attributes and manipulation operations,
that guides its execution. We create a new dataset for the task, and extensive
experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA
baselines that make use of supervised data for manipulation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:59:10 GMT""}]","2023-05-25"
"2305.14411","Temple He","Temple He, Ana-Maria Raclariu, Kathryn M. Zurek","From Shockwaves to the Gravitational Memory Effect","30 pages, 1 figure",,,"CALT-TH 2023-013","hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the relationship between shockwave geometries and the gravitational
memory effect in four-dimensional asymptotically flat spacetime. In particular,
we show the 't Hooft commutation relations of shockwave operators are
equivalent to the commutation relation between soft and Goldstone modes
parametrizing a sector of the gravitational phase space. We demonstrate this
equivalence via a diffeomorphism that takes the shockwave metric to a metric
whose transverse traceless component is the gravitational memory. The shockwave
momentum in 't Hooft's analysis is related to the soft graviton mode, which is
responsible for the memory effect, while the shift in the shockwave position is
related to the Goldstone mode. This equivalence opens new directions to utilize
the gravitational memory effect to explore the observational implications of
shockwave geometries in flat space.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:00 GMT""}]","2023-05-25"
"2305.14412","Pierre Heidmann","Pierre Heidmann, Nicholas Speeney, Emanuele Berti and Ibrahima Bah","Cavity effect in the quasinormal mode spectrum of topological stars","17 pages + Appendix, 11 figures",,,,"gr-qc hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study scalar perturbations of topological solitons, smooth horizonless
solutions in five-dimensional Einstein-Maxwell theory that correspond to
coherent states of gravity via the dynamics of extra compact dimensions. First,
we compute scalar quasinormal modes for topological stars that have a single
unstable photon sphere, and we show that the spectrum is very similar to that
of a black hole with the same photon sphere. Next, we study topological stars
that have both a stable inner photon sphere and an unstable one. The first few
quasinormal modes are localized around the inner photon sphere. The spectrum
also contains ''black-hole like modes'' localized at the unstable outer photon
sphere. The frequencies of these modes are similar to those of a black hole,
but their imaginary part is smaller due to a cavity effect associated with the
inner photon sphere. The longer damping produced by this trapping effect may
have implications for black hole spectroscopy.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:00 GMT""}]","2023-05-25"
"2305.14413","Eros Vanzella","E. Vanzella, F. Loiacono, P. Bergamini, U. Mestric, M. Castellano, P.
  Rosati, M. Meneghetti, C. Grillo, F. Calura, M. Mignoli, M. Bradac, A. Adamo,
  G. Rihtarsic, M. Dickinson, M. Gronke, A. Zanella, F. Annibali, C. Willott,
  M. Messa, E. Sani, A. Acebron, A. Bolamperti, A. Comastri, R. Gilli, K. I.
  Caputi, M. Ricotti, C. Gruppioni, S. Ravindranath, A. Mercurio, V. Strait, N.
  Martis, R. Pascale, G. B. Caminha, M. Annunziatella","An extremely metal poor star complex in the reionization era:
  Approaching Population III stars with JWST","15 pages, 10 figures, 1 table. Submitted to A&A. Comments welcome",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present JWST/NIRSpec integral field spectroscopy (IFS) of a lensed
Population III candidate stellar complex (dubbed Lensed And Pristine 1, LAP1),
with a lensing-corrected stellar mass ~<10^4 Msun, absolute luminosity M_UV >
-11.2 (m_UV > 35.6), confirmed at redshift 6.639 +/- 0.004. The system is
strongly amplified (\mu >~ 100) by straddling a critical line of the Hubble
Frontier Field galaxy cluster MACS J0416. Despite the stellar continuum is
currently not detected in the Hubble and JWST/NIRCam and NIRISS imaging,
arclet-like shapes of Lyman and Balmer lines, Lya, Hg, Hb and Ha are detected
with NIRSpec IFS with signal-to-noise ratios SNR=5-13 and large equivalent
widths (>300-2000A), along with a remarkably weak [OIII]4959-5007 at SNR ~ 4.
LAP1 shows a large ionizing photon production efficiency,
log(\xi_{ion}[erg~Hz^{-1}])>26. From the metallicity indexes R23 =
([OIII]4959-5007 + [OII]3727) / Hb ~< 0.74 and R3 = ([OIII]5007 / Hb) = 0.55
+/- 0.14, we derive an oxygen abundance 12+log(O/H) ~< 6.3. Intriguingly, the
Ha emission is also measured in mirrored sub-components where no [OIII] is
detected, providing even more stringent upper limits on the metallicity if
in-situ star formation is ongoing in this region (12+log(O/H) < 6, or Z < 0.002
Zsun). The formal stellar mass limit of the sub-components would correspond to
~10^{3} Msun or M_UV fainter than -10. Alternatively, such a metal-free pure
line emitting region could be the first case of a fluorescing HI gas region,
induced by transverse escaping ionizing radiation from a nearby star-complex.
The presence of large equivalent-width hydrogen lines and the deficiency of
metal lines in such a small region, make LAP1 the most metal poor star-forming
region currently known in the reionization era and a promising site that may
host isolated, pristine stars.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:00 GMT""}]","2023-05-25"
"2305.14414","Annalisa Citro","Annalisa Citro, Danielle A. Berg, Dawn K. Erb, Matthew W. Auger,
  George D. Becker, Bethan L. James and Evan D. Skillman","J0332-3557: A comprehensive metallicity analysis of a z~3.8
  gravitationally lensed galaxy","26 pages, 16 figures",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We provide one of the most comprehensive metallicity studies at z ~ 4 by
analyzing the UV/optical HST photometry, and rest-frame VLT-FORS2 ultraviolet
and VLT-XSHOOTER optical spectra of J0332-3557, a gravitationally lensed galaxy
magnified by a factor of 20. With a 5{\sigma} detection of the auroral O III]
{\lambda}1666 line, we are able to derive a direct gas metallicity estimate for
our target. We find Zgas = 12 + log(O/H) = 8.26 +/- 0.06, which is compatible
with an increasing of both the gas fraction and the outflow metal loading
factor from z ~ 0 to z ~ 4. J0332 is the most metal-rich individual galaxy at z
> 3.6 for which the C/O ratio has been measured. We derive a low log(C/O)=
-1.02 +/- 0.2, which suggests that J0332 is in the early stages of ISM carbon
enrichment driven mostly by massive stars. The low C/O also indicates that
J0332 is characterized by a low star formation efficiency, higher yields of
oxygen and longer burst duration. We find that the EW[C III]1906,9 is as low as
~ 3 {\AA}. The main drivers of the low EW[C III]1906,9 are the higher gas
metallicity and the low C/O. J0332 is characterized by one diffuse and two more
compact regions ~ 1 kpc in size. We find that the carbon emission mostly
originates in the compact knots.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:00 GMT""}]","2023-05-25"
"2305.14415","Alexandros Ziampras","Alexandros Ziampras, Richard P. Nelson, Roman R. Rafikov","Modeling planet-induced gaps and rings in ALMA disks: the role of
  in-plane radiative diffusion","18 pages, 28 figures, 4 tables; submitted to MNRAS",,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  ALMA observations of protoplanetary disks in dust continuum emission reveal a
variety of annular structures. Attributing the existence of such features to
embedded planets is a popular scenario, supported by studies using
hydrodynamical models. Recent work has shown that radiative cooling greatly
influences the capability of planet-driven spiral density waves to transport
angular momentum, ultimately deciding the number, position, and depth of rings
and gaps that a planet can carve in a disk. However, radiation transport has
only been treated via local thermal relaxation, not taking into account
radiative diffusion along the disk plane. We compare the previous
state-of-the-art models of planet-disk interaction with local cooling
prescriptions to our new models that include cooling in the vertical direction
and radiative diffusion in the plane of the disk, and show that the response of
the disk to the induced spiral waves can differ significantly when comparing
these two treatments of the disk thermodynamics. We follow up with synthetic
emission maps of ALMA systems, and show that our new models reproduce the
observations found in the literature better than models with local cooling. We
conclude that appropriate treatment of radiation transport is key to
constraining the parameter space when interpreting ALMA observations using the
planet-disk interaction scenario.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:00 GMT""}]","2023-05-25"
"2305.14416","Ivan Khaymovich","Daniil Kochergin, Ivan M. Khaymovich, Olga Valba, and Alexander Gorsky","Anatomy of the fragmented Hilbert space: eigenvalue tunneling, quantum
  scars and localization in the perturbed random regular graph","27 pages, 9 figures, 87 references + 4 pages, 4 figures in Appendices",,,,"cond-mat.dis-nn hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the properties of the random regular graph with node degree $d$
perturbed by chemical potentials $\mu_k$ for a number of short $k$-cycles. We
analyze both numerically and analytically the phase diagram of the model in the
$(\mu_k,d)$ plane. The critical curve separating the homogeneous and
clusterized phases is found and it is demonstrated that the clusterized phase
itself generically is separated as the function of $d$ into the phase with
ideal clusters and phase with coupled ones when the continuous spectrum gets
formed. The eigenstate spatial structure of the model is investigated and it is
found that there are localized scar-like states in the delocalized part of the
spectrum, that are related to the topologically equivalent nodes in the graph.
We also reconsider the localization of the states in the non-perturbative band
formed by eigenvalue instantons and find the semi-Poisson level spacing
distribution. The Anderson transition for the case of combined ($k$-cycle)
structural and diagonal (Anderson) disorders is investigated. It is found that
the critical diagonal disorder gets reduced sharply at the clusterization phase
transition, but does it unevenly in non-perturbative and mid-spectrum bands,
due to the scars, present in the latter. The applications of our findings to
$2$d quantum gravity are discussed.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:00 GMT""}]","2023-05-25"
"2305.14417","William Pannell","William H. Pannell, Andreas Stergiou","Scalar-Fermion Fixed Points in the $\varepsilon$ Expansion","45 pages, 20 figures, 10 tables",,,,"hep-th cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  The one-loop beta functions for systems of $N_s$ scalars and $N_f$ fermions
interacting via a general potential are analysed as tensorial equations in
$4-\varepsilon$ dimensions. Two distinct bounds on combinations of invariants
constructed from the couplings are derived and, subject to an assumption, are
used to prove that at one-loop order the anomalous dimensions of the elementary
fields are universally restricted by $\gamma_\phi\leq\frac{1}{2}\,\varepsilon$
and $\gamma_\psi\leq\frac{1}{2}N_s\,\varepsilon$. For each root of the Yukawa
beta function there is a number of roots of the quartic beta function, giving
rise to the concept of `levels' of fixed points in scalar-fermion theories. It
is proven that if a stable fixed point exists within a certain level, then it
is the only such fixed point at that level. Solving the beta function
equations, both analytically and numerically, for low numbers of scalars and
fermions, well-known and novel fixed points are found and their stability
properties are examined. While a number of fixed points saturate one out of the
two bounds, only one fixed point is found which saturates both of them.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:01 GMT""}]","2023-05-25"
"2305.14418","Guillermo Barro","Guillermo Barro, Pablo G. Perez-Gonzalez, Dale D. Kocevski, Elizabeth
  J. McGrath, Jonathan R. Trump, Raymond C. Simons, Rachel S. Somerville, L. Y.
  Aaron Yung, Pablo Arrabal Haro, Michaela B. Bagley, Nikko J. Cleri, Luca
  Costantin, Kelcey Davis, Mark Dickinson, Steve L. Finkelstein, Mauro
  Giavalisco, Carlos Gomez-Guijarro, Nimish P. Hathi, Michaela Hirschmann,
  Hollis B. Akins, Benne W. Holwerda, Marc Huertas-Company, Ray A. Lucas, Casey
  Papovich, Lise-Marie Seille, Sandro Tacchella, Stephen M. Wilkins, Alexander
  de la Vega, Guang Yang, Jorge A. Zavala","Extremely red galaxies at $z=5-9$ with MIRI and NIRSpec: dusty galaxies
  or obscured AGNs?","26 pages, 10 figures, submitted to ApJ",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We study a new population of extremely red objects (EROs) recently discovered
by JWST based on their NIRCam colors F277W$-$F444W $>1.5$ mag. We find 37 EROs
in the CEERS field with F444W $<28$ mag and photometric redshifts between
$5<z<7$, with median $z=6.9^{+1.0}_{-1.6}$. Surprisingly, despite their red
long-wavelength colors, these EROs have blue short-wavelength colors
(F150W$-$F200W$\sim$0 mag) indicative of bimodal SEDs with a red, steep slope
in the rest-frame optical, and a blue, flat slope in the rest-frame UV.
Moreover, all these EROs are unresolved, point-like sources in all NIRCam
bands. We analyze the spectral energy distributions of 8 of them with MIRI and
NIRSpec observations using stellar population models and AGN templates. We find
that a dusty galaxy or an obscured AGN provide similarly good SED fits but
different stellar properties: massive and dusty, log M/M_sun$\sim$10 and
A$_{\rm V}\gtrsim3$ mag, or low mass and obscuration, log M/M_sun$\sim$7.5 and
A$_{\rm V}\sim0$ mag, hosting an obscured QSO. SED modeling does not favor
either scenario, but their unresolved sizes are more suggestive of an AGN. If
any EROs are confirmed to have log M/M_sun$\gtrsim10.5$, it would increase
pre-JWST number densities at $z>7$ by up to a factor $\sim$60. Similarly, if
they are OSOs with luminosities in the L$_{\rm bol}>10^{46-47}$ erg s$^{-1}$
range, their number would exceed that of bright blue QSOs by more than two
orders of magnitude. Additional photometry at mid-IR wavelengths will reveal
the true nature of the red continuum emission in these EROs and will place this
puzzling population in the right context of galaxy evolution.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:01 GMT""}]","2023-05-25"
"2305.14419","Constant Auclair","Constant Auclair, Erwan Allys, Fran\c{c}ois Boulanger, Matthieu
  B\'ethermin, Athanasia Gkogkou, Guilaine Lagache, Antoine Marchal,
  Marc-Antoine Miville-Desch\^enes, Bruno R\'egaldo-Saint Blancard and Pablo
  Richard","Separation of dust emission from the Cosmic Infrared Background in
  Herschel observations with Wavelet Phase Harmonics","Submitted to A&A. Comments welcome",,,,"astro-ph.GA astro-ph.CO astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The low brightness dust emission at high Galactic latitude is of interest to
study the interplay between physical processes in shaping the structure of the
interstellar medium (ISM), as well as to statistically characterize dust
emission as a foreground to the Cosmic Microwave Background (CMB). Progress in
this avenue of research have been hampered by the difficulty of separating the
dust emission from the Cosmic Infrared Background (CIB). We demonstrate that
dust and CIB may be effectively separated based on their different structure on
the sky and use the separation to characterize the structure of diffuse dust
emission on angular scales where CIB is a significant component in terms of
power. We use scattering transform statistics, the Wavelet Phase Harmonics
(WPH), to perform a statistical component separation using Herschel SPIRE
observations. This component separation is done only from observational data
using non-Gaussian properties as a lever arm, and is done at a single 250
microns frequency. This method, that we validate on mock data, gives us access
to non-Gaussian statistics of the interstellar dust and an output dust map
essentially free from CIB contamination. Our statistical modelling
characterizes the non-Gaussian structure of the diffuse ISM down to the
smallest scales observed by Herschel. We recover the power-law shape of the
dust power spectrum up to a wavenumber of 2 arcmin$^{-1}$ where the dust signal
represents 2 percent of the total power. The output dust map reveals coherent
structures at the smallest scales which were hidden by the CIB anisotropies. It
opens new observational perspectives on the formation of structure in the
diffuse ISM which we discuss with reference to past work. We have succeeded to
perform a statistical separation from observational data only at a single
frequency by using non-Gaussian statistics.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:02 GMT""}]","2023-05-25"
"2305.14420","Seokhoon Yun","Francesco D'Eramo, Giuseppe Lucente, Newton Nath, Seokhoon Yun","Terrestrial detection of hidden vectors produced by solar nuclear
  reactions","40 pages, 9 figures; v2: numerical mistake in the analysis corrected,
  updated results and discussion",,,,"hep-ph astro-ph.SR hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar nuclear reactions can occasionally produce sub-MeV elusive beyond the
Standard Model particles that escape the solar interior without further
interactions. This study focuses on massive spin-one particles. We construct
the general theoretical framework and identify two crucial mixing sources
involving the photon, which facilitate communication between the hidden and
visible sectors: kinetic mixing with the photon, and plasma-induced mixing due
to thermal electron loops. For both cases, we focus on the second stage of the
solar proton-proton chain and evaluate the fluxes of monochromatic 5.49~MeV
hidden vectors produced by the $p(d, ^3{\rm He})\gamma^\prime$ nuclear
reaction. We then investigate their terrestrial detection via Compton-like
scatterings. The incoming fluxes are polarized, and we evaluate the cross
sections for Compton-like scatterings for transverse and longitudinal vectors.
Finally, we apply this framework to a concrete case by investigating the
sensitivity of the forthcoming Jiangmen Underground Neutrino Observatory (JUNO)
experiment and identifying parameter space where current terrestrial bounds
will be improved.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:02 GMT""},{""version"":""v2"",""created"":""Sun, 28 May 2023 19:35:40 GMT""}]","2023-05-30"
"2305.14421","A.I. Malz","Alex I. Malz, Mi Dai, Kara A. Ponder, Emille E.O. Ishida, Santiago
  Gonzalez-Gaitain, Rupesh Durgesh, Alberto Krone-Martins, Rafael S. de Souza,
  Noble Kennamer, Sreevarsha Sreejith, Lluis Galbany, The LSST Dark Energy
  Science Collaboration (DESC), The Cosmostatistics Initiative (COIN)","Are classification metrics good proxies for SN Ia cosmological
  constraining power?","9 pages, 6 figures; submitted to A&A",,,,"astro-ph.CO astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Context: When selecting a classifier to use for a supernova Ia (SN Ia)
cosmological analysis, it is common to make decisions based on metrics of
classification performance, i.e. contamination within the photometrically
classified SN Ia sample, rather than a measure of cosmological constraining
power. If the former is an appropriate proxy for the latter, this practice
would save those designing an analysis pipeline from the computational expense
of a full cosmology forecast. Aims: This study tests the assumption that
classification metrics are an appropriate proxy for cosmology metrics. Methods:
We emulate photometric SN Ia cosmology samples with controlled contamination
rates of individual contaminant classes and evaluate each of them under a set
of classification metrics. We then derive cosmological parameter constraints
from all samples under two common analysis approaches and quantify the impact
of contamination by each contaminant class on the resulting cosmological
parameter estimates. Results: We observe that cosmology metrics are sensitive
to both the contamination rate and the class of the contaminating population,
whereas the classification metrics are insensitive to the latter. Conclusions:
We therefore discourage exclusive reliance on classification-based metrics for
cosmological analysis design decisions, e.g. classifier choice, and instead
recommend optimizing using a metric of cosmological parameter constraining
power.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:02 GMT""}]","2023-05-25"
"2305.14422","Misha Yutushui","Misha Yutushui and David F. Mross","Identifying non-Abelian anyons with upstream noise","4 pages, 3 figures",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Non-Abelian phases are among the most highly-prized but elusive states of
matter. We show that upstream noise measurements can identify the putative
non-Abelian fractional quantum Hall plateaus at filling factors
$\nu=\frac{12}{5}$ or in any half-filled Landau level. Interfacing these states
with any readily-available Abelian state yields a binary outcome of upstream
noise or no noise. Judicious choices of the Abelian states can produce a
sequence of yes--no outcomes that fingerprint the possible non-Abelian phase by
ruling out its competitors.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:03 GMT""}]","2023-05-25"
"2305.14423","Valentin Cr\'epel","Valentin Cr\'epel, Aaron Dunbrack, Daniele Guerci, John Bonini,
  Jennifer Cano","Chiral model of twisted bilayer graphene realized in a monolayer",,,,,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We demonstrate that a single layer of graphene subject to a superlattice
potential nearly commensurate to a $\sqrt{3} \times \sqrt{3}$ supercell exactly
maps to the chiral model of twisted bilayer graphene, albeit with half as many
degrees of freedom. We comprehensively review the properties of this
``half-chiral model,'' including the interacting phases stabilized at integer
fillings and the effects of substrate-induced symmetry breaking. We list
candidate substrates that could produce a superlattice potential on graphene
with the correct periodicity to access the flat band limit. Experimental
measurements on a half-chiral moire heterostructure, in which valley-skyrmions
cannot form, could yield insights on the physics they mediate in twisted
bilayer graphene.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:04 GMT""}]","2023-05-25"
"2305.14424","Zun Yi Brent Tan","Brent Tan and Drummond B. Fielding","Cloud Atlas: Navigating the Multiphase Landscape of Tempestuous Galactic
  Winds","32 pages, 34 figures; Submitted to MNRAS",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Galaxies comprise intricate networks of interdependent processes which
together govern their evolution. Central among these are the multiplicity of
feedback channels, which remain incompletely understood. One outstanding
problem is the understanding and modeling of the multiphase nature of galactic
winds, which play a crucial role in galaxy formation and evolution. We present
the results of three dimensional magnetohydrodynamical tall box interstellar
medium patch simulations with clustered supernova driven outflows.
Fragmentation of the interstellar medium during superbubble breakout seeds the
resulting hot outflow with a population of cool clouds. We focus on analyzing
and modeling the origin and properties of these clouds. Their presence induces
large scale turbulence, which in turn leads to complex cloud morphologies.
Cloud sizes are well described by a power law distribution and mass growth
rates can be modelled using turbulent radiative mixing layer theory. Turbulence
provides significant pressure support in the clouds, while magnetic fields only
play a minor role. We conclude that many of the physical insights and analytic
scalings derived from idealized small scale simulations translate well to
larger scale, more realistic turbulent magnetized winds, thus paving a path
towards their necessary yet challenging inclusion in global-scale galaxy
models.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:04 GMT""}]","2023-05-25"
"2305.14425","Mohamed Anber","Mohamed M. Anber, Erich Poppitz","Noninvertible anomalies in $SU(N)\times U(1)$ gauge theories","18 pages",,,,"hep-th cond-mat.str-el hep-lat","http://creativecommons.org/licenses/by/4.0/","  We study $4$-dimensional $SU(N)\times U(1)$ gauge theories with a single
massless Dirac fermion in the $2$-index symmetric/antisymmetric representations
and show that they are endowed with a noninvertible $0$-form $\widetilde
{\mathbb Z}_{2(N\pm 2)}^{\chi}$ chiral symmetry along with a $1$-form $\mathbb
Z_N^{(1)}$ center symmetry. By using the Hamiltonian formalism and putting the
theory on a spatial three-torus $\mathbb T^3$, we construct the non-unitary
gauge invariant operator corresponding to $\widetilde {\mathbb Z}_{2(N\pm
2)}^{\chi}$ and find that it acts nontrivially in sectors of the Hilbert space
characterized by selected magnetic fluxes. When we subject $\mathbb T^3$ to
$\mathbb Z_N^{(1)}$ twists, for $N$ even, in selected magnetic flux sectors,
the algebra of $\widetilde {\mathbb Z}_{2(N\pm 2)}^{\chi}$ and $\mathbb
Z_N^{(1)}$ fails to commute by a $\mathbb Z_2$ phase. We interpret this
noncommutativity as a mixed anomaly between the noninvertible and the $1$-form
symmetries. The anomaly implies that all states in the torus Hilbert space with
the selected magnetic fluxes exhibit a two-fold degeneracy for arbitrary
$\mathbb T^3$ size. The degenerate states are labeled by discrete electric
fluxes and are characterized by nonzero expectation values of condensates.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:10 GMT""}]","2023-05-25"
"2305.14426","Andrea Solfanelli","Andrea Solfanelli, Stefano Ruffo, Sauro Succi, Nicol\`o Defenu","Stabilization of Discrete Time-Crystaline Response on a Superconducting
  Quantum Computer by increasing the Interaction Range",,,,,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents a novel method for reproducing the dynamics of systems
with couplings beyond nearest neighbors using a superconducting quantum
processor. Quantum simulation of complex quantum many-body systems is a
promising short-term goal of noisy intermediate-scale quantum (NISQ) devices.
However, the limited connectivity of native qubits hinders the implementation
of quantum algorithms that require long-range interactions. We show that
utilizing the universality of quantum processor native gates allows the
implementation of couplings among physically disconnected qubits. To
demonstrate the effectiveness of our method, we implement a quantum simulation,
on IBM quantum superconducting processors, of a Floquet-driven quantum spin
chain featuring interactions beyond nearest neighbors. Specifically, we
benchmark the prethermal stabilization of discrete Floquet time crystalline
response as the interaction range increases, a phenomenon which was never
experimentally observed before. Our method enables the study of systems with
tunable interaction ranges, opening up new opportunities to explore the physics
of long-range interacting quantum systems.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:12 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 21:18:34 GMT""}]","2023-05-29"
"2305.14427","Stefan Sandner","S. Sandner, P. Hernandez, J. Lopez-Pavon and N. Rius","Predicting the baryon asymmetry with degenerate right-handed neutrinos","28 + 4 pages, 8 figures",,,"IFIC/23-18, FTUV-23-0519.8654","hep-ph astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We consider the generation of a baryon asymmetry in an extension of the
Standard Model with two singlet Majorana fermions that are degenerate above the
electroweak phase transition. The model can explain neutrino masses as well as
the observed matter-antimatter asymmetry, for masses of the heavy singlets
below the electroweak scale. The only physical CP violating phases in the model
are those in the PMNS mixing matrix, i.e. the Dirac phase and a Majorana phase
that enter light neutrino observables. We present an accurate analytic
approximation for the baryon asymmetry in terms of CP flavour invariants, and
derive the correlations with neutrino observables. We demonstrate that the
measurement of CP violation in neutrino oscillations as well as the mixings of
the heavy neutral leptons with the electron, muon and tau flavours suffice to
pin down the matter-antimatter asymmetry from laboratory measurements.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:14 GMT""}]","2023-05-25"
"2305.14428","Wentao Bao","Wentao Bao, Lichang Chen, Heng Huang, Yu Kong","Prompting Language-Informed Distribution for Compositional Zero-Shot
  Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The compositional zero-shot learning (CZSL) task aims to recognize unseen
compositional visual concepts (i.e., sliced tomatoes), where the models are
learned only from the seen compositions (i.e., sliced potatoes and red
tomatoes). Thanks to the prompt tuning on large pre-trained visual language
models such as CLIP, recent literature shows impressively better CZSL
performance than traditional vision-based methods. However, the key aspects
that impact the generalization to unseen compositions, including the diversity
and informativeness of class context, and the entanglement between visual
primitives (i.e., states and objects), are not properly addressed in existing
CLIP-based CZSL literature. In this paper, we propose a model by prompting the
language-informed distribution, aka., PLID, for the CZSL task. Specifically,
the PLID leverages pre-trained large language models (LLM) to 1) formulate the
language-informed class distribution, and 2) enhance the compositionality of
the softly prompted class embedding. Moreover, a stochastic logit mixup
strategy is proposed to dynamically fuse the decisions from the predictions in
the compositional and the primitive logit space. Orthogonal to the existing
literature of soft, hard, or distributional prompts, our method advocates
prompting the LLM-supported class distribution that leads to a better
compositional zero-shot generalization. Experimental results on MIT-States,
UT-Zappos, and C-GQA datasets show the superior performance of the PLID to the
prior arts. The code and models will be publicly released.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:22 GMT""}]","2023-05-25"
"2305.14429","Ben King","B. King","Classical Radiation Reaction in Red-Shifted Harmonics","7 pages, 3 figures",,,,"hep-ph physics.class-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The collision of a finite electromagnetic plane wave with an electron subject
to the Landau-Lifshitz radiation reaction force is studied. A locally
monochromatic approximation is derived and compared to numerical evaluation of
the exact plane wave result. Energy and transverse momentum spectra are
calculated, which clearly display the red-shifting of harmonic features due to
radiation reaction effects. Simple formulas are presented to predict the
shifting of harmonic edges, whose position can be used in experiments as
evidence of radiation reaction.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:28 GMT""}]","2023-05-31"
"2305.14430","Jorge Segovia","P.G. Ortega, D.R. Entem, F. Fernandez and J. Segovia","Unraveling the nature of the novel $\mathbf{T_{cs}}$ and
  $\mathbf{T_{c\bar s}}$ tetraquark candidates","10 pages, 4 tables",,,,"hep-ph hep-ex hep-lat nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using proton-proton collisions at centre-of-mass energies $7$, $8$, and $13$
TeV, with a total integrated luminosity of $9\,\text{fb}^{-1}$, the LHCb
collaboration has performed amplitude analyses of the $B^+\to D^+D^-K^+$,
$B^+\to D^- D_s^+ \pi^+$ and $B^0\to \bar{D}^0 D_s^+ \pi^-$ decays, observing
that new $T_{cs}$ and $T_{c\bar s}$ resonances are required in order to explain
the experimental data. These signals could be the first observation of
tetraquark candidates that do not contain a heavy quark-antiquark pair; in
fact, they consist of four different flavours of quarks, one of which is a
doubly charged open-charm state. We present herein an analysis of the $T_{cs}$
and $T_{c\bar s}$ states, which is an extension of our recently published study
of similar $T_{cc}^+$ exotic candidates. Our theoretical framework is a
constituent-quark-model-based coupled-channels calculation of $qq^\prime \bar s
\bar c$ and $cq\bar s\bar q^{\prime}$ tetraquark sectors for $T_{cs}$ and
$T_{c\bar s}$ structures, respectively. We explore the nature, and pole
position, of the singularities that appear in the scattering matrix with
spin-parity quantum numbers: $J^P=0^\pm$, $1^\mp$, and $2^\pm$. The constituent
quark model has been widely used in the heavy quark sector, and thus all model
parameters are already constrained from previous works. This makes our
predictions robust and parameter-free. We find many singularities in the
solution of various scattering-matrix problems which are either virtual states
or resonances, but not bound states. Some of them fit well with the
experimental observations of the spin-parity, mass and width of $T_{cs}$ and
$T_{c\bar s}$ candidates, and thus tentative assignments are made; however,
with caution, because the experimental Breit-Wigner parameters are related to
the pole characteristics.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:28 GMT""}]","2023-05-25"
"2305.14431","Avia Noah","Avia Noah, Yishay Zur, Nofar Fridman, Sourabh Singh, Alon Gutfreund,
  Edwin Herrera, Atzmon Vakahi, Sergei Remennik, Martin Emile Huber, Snir
  Gazit, Hermann Suderow, Hadar Steinberg, Oded Millo, and Yonathan Anahory","Nano-Patterned Magnetic Edges in CrGeTe3 for Quasi 1-D Spintronic
  Devices","Main text: 13 pages, 4 figures. Supplementary information: 8 pages, 6
  figures",,"10.1021/acsanm.3c01008",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The synthesis of two-dimensional van der Waals magnets has paved the way for
both technological applications and fundamental research on magnetism confined
to ultra-small length scales. Edge magnetic moments in ferromagnets are
expected to be less magnetized than in the sample interior because of the
reduced amount of neighboring ferromagnetic spins at the sample edge. We
recently demonstrated that CrGeTe3 (CGT) flakes thinner than 10 nm are hard
ferromagnets; i.e., they exhibit an open hysteresis loop. In contrast, thicker
flakes exhibit zero net remnant field in the interior, with hard ferromagnetism
present only at the cleaved edges. This experimental observation suggests that
a nontrivial interaction exists between the sample edge and the interior. Here,
we demonstrate that artificial edges fabricated by focus ion beam etching also
display hard ferromagnetism. This enables us to write magnetic nanowires in CGT
directly and use this method to characterize the magnetic interaction between
the interior and edge. The results indicate that the interior saturation and
depolarization fields depend on the lateral dimensions of the sample. Most
notably, the interior region between the edges of a sample narrower than 300 nm
becomes a hard ferromagnet, suggesting an enhancement of the magnetic exchange
induced by the proximity of the edges. Last, we find that the CGT regions
amorphized by the gallium beam are nonmagnetic, which introduces a novel method
to tune the local magnetic properties of CGT films, potentially enabling
integration into spintronic devices.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:33 GMT""}]","2023-05-25"
"2305.14432","Tsun Hin Navin Tsung","Tsun Hin Navin Tsung, S. Peng Oh, Chad Bustard","The Impact of Cosmic Rays on Thermal and Hydrostatic Stability in
  Galactic Halos","33 pages, 25 figures, submitted to MNRAS",,,,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We investigate how cosmic rays (CRs) affect thermal and hydrostatic stability
of circumgalactic (CGM) gas, in simulations with both CR streaming and
diffusion. Local thermal instability can be suppressed by CR-driven entropy
mode propagation, in accordance with previous analytic work. However, there is
only a narrow parameter regime where this operates, before CRs overheat the
background gas. As mass dropout from thermal instability causes the background
density and hence plasma $\beta \equiv P_g/P_B$ to fall, the CGM becomes
globally unstable. At the cool disk to hot halo interface, a sharp drop in
density boosts Alfven speeds and CR gradients, driving a transition from
diffusive to streaming transport. CR forces and heating strengthen, while
countervailing gravitational forces and radiative cooling weaken, resulting in
a loss of both hydrostatic and thermal equilibrium. In lower $\beta$ halos, CR
heating drives a hot, single-phase diffuse wind with velocities $v \propto
(t_\mathrm{heat}/t_\mathrm{ff})^{-1}$, which exceeds the escape velocity when
$t_\mathrm{heat}/t_\mathrm{ff} \lesssim 0.4$. In higher $\beta$ halos, CR
forces drive multi-phase winds with cool, dense fountain flows and significant
turbulence. These flows are CR dominated due to ""trapping"" of CRs by weak
transverse B-fields, and have the highest mass loading factors. Thus, local
thermal instability can result in winds or fountain flows where either the heat
or momentum input of CRs dominates.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:38 GMT""}]","2023-05-25"
"2305.14433","Daniel Parrochia","Daniel Parrochia","Global warming in figures and the question of its treatment: some
  historical and epistemological views","34 pages, 10 figures",,,,"physics.soc-ph physics.pop-ph","http://creativecommons.org/licenses/by/4.0/","  We first recall fundamentals of elementary climate physics: solar constant,
radiative balance, greenhouse effect, astronomical parameters of the climate
(theory of Milankovitch). Without disputing the analyzes of climatologists and
the famous Keeling curve revealing in an indisputable way the increase in
CO$_{2}$ in the atmosphere since the industrial revolution, we nevertheless
insist on the main contributor to the greenhouse effect which is, as we know,
water vapor. Faced with the difficulties that there will be in imposing
zero-carbon policies everywhere in the world (and especially in developing
countries), we show that it would perhaps be in our interest to act on soil
drought, which amounts, in fact, to being interested in the clouds. The
decrease in cloud cover, due to a lack of water fixation in the soil, in fact
increases the general temperature and therefore the greenhouse effect. Acting
on CO$_{2}$ will always have, in this context, much less effect than acting on
water vapor, even indirectly. Despite the difficulty of making this action
sustainable, due to the balance of atmospheric water vapor and the oceans, it
would be in our interest not to neglect this path and also possibly increase
forest cover for this purpose, given the problems of setting up zero-carbon
policy on a global scale. In desperation, one can also consider protecting the
Earth with an artificial dust cloud.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:00:53 GMT""}]","2023-05-25"
"2305.14434","Yew Ken Chia","Yew Ken Chia, Hui Chen, Wei Han, Guizhen Chen, Sharifah Mahani
  Aljunied, Soujanya Poria, Lidong Bing","Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment
  Triplet Extraction",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aspect Sentiment Triplet Extraction (ASTE) is a subtask of Aspect-Based
Sentiment Analysis (ABSA) that considers each opinion term, their expressed
sentiment, and the corresponding aspect targets. However, existing methods are
limited to the in-domain setting with two domains. Hence, we propose a
domain-expanded benchmark to address the in-domain, out-of-domain and
cross-domain settings. We support the new benchmark by annotating more than
4000 data samples for two new domains based on hotel and cosmetics reviews. Our
analysis of five existing methods shows that while there is a significant gap
between in-domain and out-of-domain performance, generative methods have a
strong potential for domain generalization. Our datasets, code implementation
and models are available at https://github.com/DAMO-NLP-SG/domain-expanded-aste .
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:01:49 GMT""}]","2023-05-25"
"2305.14435","Amir Sharon","Amir Sharon, Doron Kushnir, Wenlong Yuan, Lucas Macri, Adam Riess","Reassessing the Constraints from SH0ES Extragalactic Cepheid Amplitudes
  on Systematic Blending Bias","20 pages, 12 figures. Submitted to MNRAS",,,,"astro-ph.CO astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The SH0ES collaboration Hubble constant determination is in a
$\mathord{\sim}5\sigma$ difference with the \textit{Planck} value, known as the
Hubble tension. The accuracy of the Hubble constant measured with extragalactic
Cepheids depends on robust stellar-crowding background estimation. Riess et al.
2020 (R20) compared the light curves amplitudes of extragalactic and MW
Cepheids to constrain an unaccounted systematic blending bias,
$\gamma=-0.029\pm0.037\,\rm{mag}$, which cannot explain the required,
$\gamma=0.24\pm0.05\,\rm{mag}$, to resolve the Hubble tension. Further checks
by Riess et al. 2022 demonstrate that a possible blending is not likely related
to the size of the crowding correction. We repeat the R20 analysis, with the
following main differences: 1. We limit the extragalactic and MW Cepheids
comparison to periods $P\lesssim50\,\rm{d}$, since the number of MW Cepheids
with longer periods is minimal; 2. We use publicly available data to
recalibrate amplitude ratios of MW Cepheids in standard passbands; 3. We
remeasure the amplitudes of Cepheids in NGC 5584 and NGC 4258 in two HST
filters (F555W and F350LP) to improve the empirical constraint on their
amplitude ratio $A^{555}/A^{350}$. We show that the filter transformations
introduce an $\mathord{\approx}0.04\,\rm{mag}$ uncertainty in determining
$\gamma$, not included by R20. While our final estimate,
$\gamma=0.013\pm0.057\,\rm{mag}$, is consistent with the value derived by R20,
the error is somewhat larger, and the best-fit value is shifted by
$\mathord{\approx}0.04\,\rm{mag}$. Although the obtained $\gamma$ for this
crowding test is consistent with zero, folding (in quadratures) it is
$\mathord{\approx}3.0\sigma$ away from aligning with \textit{Planck}. Future
observations, especially with JWST, would allow better calibration of $\gamma$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:02:04 GMT""}]","2023-05-25"
"2305.14436","Giles Blaney Ph.D.","Giles Blaney, Fernando Ivich, Angelo Sassaroli, Mark Niedre, and
  Sergio Fantini","Dual-ratio approach for detection of point fluorophores in biological
  tissue",,,,,"physics.med-ph physics.optics q-bio.QM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Significance: Diffuse in-vivo Flow Cytometry (DiFC) is an emerging
fluorescence sensing method to non-invasively detect labeled circulating cells
in-vivo. However, due to Signal-to-Noise Ratio (SNR) constraints largely
attributed to background tissue autofluorescence, DiFC's measurement depth is
limited.
  Aim: The Dual-Ratio (DR) / Dual-Slope (DS) is a new optical measurement
method that aims to suppress noise and enhance SNR to deep tissue regions. We
aim to investigate the combination of DR and DiFC to improve circulating cells'
maximum detectable depth and SNR.
  Approach: Phantom experiments were used to estimate the key parameters in a
diffuse fluorescence excitation and emission model. This model and parameters
were implemented in Monte-Carlo to simulate DR DiFC while varying noise and
autofluorescence parameters to identify the advantages and limitations of the
proposed technique.
  Results: Two key factors must be true to give DR DiFC an advantage over
traditional DiFC; first, the fraction of noise that DR methods cannot cancel
cannot be above the order of 10%. Second, DR DiFC has an advantage if the
distribution of tissue autofluorescence contributors is surface-weighted.
  Conclusions: DR cancelable noise may be designed for (e.g. through the use of
source multiplexing), and indications point to the autofluorescence
contributors' distribution being truly surface-weighted in-vivo. Successful and
worthwhile implementation of DR DiFC depends on these considerations, but
indications point to DR DiFC having possible advantages over traditional DiFC.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:04:05 GMT""}]","2023-05-25"
"2305.14437","Mattia Carlo Sormani","Mattia C. Sormani, Ashley T. Barnes, Jiayi Sun, Sophia K. Stuber, Eva
  Schinnerer, Eric Emsellem, Adam K. Leroy, Simon C.O. Glover, Jonathan D.
  Henshaw, Sharon E. Meidt, Justus Neumann, Miguel Querejeta, Thomas G.
  Williams, Frank Bigiel, Cosima Eibensteiner, Francesca Fragkoudi, Rebecca C.
  Levy, Kathryn Grasha, Ralf S. Klessen, J. M. Diederik Kruijssen, Nadine
  Neumayer, Francesca Pinna, Erik W. Rosolowsky, Rowan J. Smith, Yu-Hsuan Teng,
  Robin G. Tress, Elizabeth J. Watkins","Fuelling the nuclear ring of NGC 1097","Accepted in MNRAS",,"10.1093/mnras/stad1554",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galactic bars can drive cold gas inflows towards the centres of galaxies. The
gas transport happens primarily through the so-called bar ``dust lanes'', which
connect the galactic disc at kpc scales to the nuclear rings at hundreds of pc
scales much like two gigantic galactic rivers. Once in the ring, the gas can
fuel star formation activity, galactic outflows, and central supermassive black
holes. Measuring the mass inflow rates is therefore important to understanding
the mass/energy budget and evolution of galactic nuclei. In this work, we use
CO datacubes from the PHANGS-ALMA survey and a simple geometrical method to
measure the bar-driven mass inflow rate onto the nuclear ring of the barred
galaxy NGC~1097. The method assumes that the gas velocity in the bar lanes is
parallel to the lanes in the frame co-rotating with the bar, and allows one to
derive the inflow rates from sufficiently sensitive and resolved
position-position-velocity diagrams if the bar pattern speed and galaxy
orientations are known. We find an inflow rate of $\dot{M}=(3.0 \pm 2.1)\, \rm
M_\odot\, yr^{-1}$ averaged over a time span of 40 Myr, which varies by a
factor of a few over timescales of $\sim$10 Myr. Most of the inflow appears to
be consumed by star formation in the ring which is currently occurring at a
rate of ${\rm SFR}\simeq~1.8$-$2 \rm M_\odot\, yr^{-1}$, suggesting that the
inflow is causally controlling the star formation rate in the ring as a
function of time.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:04:23 GMT""}]","2023-05-31"
"2305.14438","Lennart Klebl","Ammon Fischer and Lennart Klebl and Jonas B. Hauck and Alexander
  Rothstein and Lutz Waldecker and Bernd Beschoten and Tim O. Wehling and Dante
  M. Kennes","Spin and Charge Fluctuation Induced Pairing in ABCB Tetralayer Graphene","5 pages, 4 figures, supplementary information",,,,"cond-mat.supr-con cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the recent experimental realization of ABCB stacked tetralayer
graphene [Wirth et al., ACS Nano 16, 16617 (2022)], we study correlated
phenomena in moir\'e-less graphene tetralayers for realistic interaction
profiles using an orbital resolved random phase approximation approach. We
demonstrate that magnetic fluctuations originating from local interactions are
crucial close to the van Hove singularities on the electron- and hole-doped
side promoting layer selective ferrimagnetic states. Spin fluctuations around
these magnetic states enhance unconventional spin-triplet, valley-singlet
superconductivity with $f$-wave symmetry due to intervalley scattering. Charge
fluctuations arising from long range Coulomb interactions promote doubly
degenerate $p$-wave superconductivity close to the van Hove singularities. At
the conduction band edge of ABCB graphene, we find that both spin and charge
fluctuations drive $f$-wave superconductivity. Our analysis suggests a strong
competition between superconducting states emerging from long- and short-ranged
Coulomb interactions and thus stresses the importance of microscopically
derived interaction profiles to make reliable predictions for the origin of
superconductivity in graphene based heterostructures.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:04:48 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 13:00:43 GMT""}]","2023-05-26"
"2305.14439","Ewelina Mulawa","Ewelina Mulawa","A detailed description of the generalized Calabi type Kahler surfaces","28 pages. arXiv admin note: text overlap with arXiv:1906.11640",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study QCH K\""ahler surfaces, i.e. 4-dimensional Riemannian
manifolds (of signature (++++)) admitting a K\""ahler complex structure with
quasi-constant holomorphic sectional curvature. We give a detailed description
of QCH K\""ahler surfaces of generalized Calabi type.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:06:20 GMT""}]","2023-05-25"
"2305.14440","Andrea Placidi PhD","Andrea Placidi, Gianluca Grignani, Troels Harmark, Marta Orselli, Sara
  Gliorio, and Alessandro Nagar","2.5PN accurate waveform information for generic-planar-orbit binaries in
  effective one-body models","14 pages",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide the post-Newtonian (PN) waveform for binary systems in motion
along generic planar orbits at 2.5PN accuracy, in terms of the dynamical
variables of the effective one-body (EOB) formalism. In addition to the
calculation of the higher order terms for all the contributions to the waveform
that have been already considered in previous avatars of EOB models, we also
compute the EOB expression of the oscillatory memory terms. These are purely
non-circular contributions, first appearing at 1.5PN order, that have been so
far neglected in the EOB literature. This should foster their inclusion in EOB
models and the definitive assessment of their role in shaping gravitational
wave signals at infinity. To further promote the application of our results, we
also derive associated non-circular factors according to the waveform
factorization prescription of the non-circular EOB model TEOBResumS-DALI; the
result is a set of ready-to-use non-circular factors that can be directly
implemented as extra non-circular corrections in the waveform of
TEOBResumS-DALI.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:07:03 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 07:59:59 GMT""}]","2023-05-30"
"2305.14441","Zhihan Zhang","Zhihan Zhang and Wenhao Yu and Zheng Ning and Mingxuan Ju and Meng
  Jiang","Exploring Contrast Consistency of Open-Domain Question Answering Systems
  on Minimally Edited Questions","Accepted at TACL. This is a pre-MIT Press publication version",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Contrast consistency, the ability of a model to make consistently correct
predictions in the presence of perturbations, is an essential aspect in NLP.
While studied in tasks such as sentiment analysis and reading comprehension, it
remains unexplored in open-domain question answering (OpenQA) due to the
difficulty of collecting perturbed questions that satisfy factuality
requirements. In this work, we collect minimally edited questions as
challenging contrast sets to evaluate OpenQA models. Our collection approach
combines both human annotation and large language model generation. We find
that the widely used dense passage retriever (DPR) performs poorly on our
contrast sets, despite fitting the training set well and performing
competitively on standard test sets. To address this issue, we introduce a
simple and effective query-side contrastive loss with the aid of data
augmentation to improve DPR training. Our experiments on the contrast sets
demonstrate that DPR's contrast consistency is improved without sacrificing its
accuracy on the standard test sets.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:07:04 GMT""}]","2023-05-25"
"2305.14442","Michalis Titsias","Michalis K. Titsias","Optimal Preconditioning and Fisher Adaptive Langevin Sampling","20 pages, 14 figures",,,,"stat.ML cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define an optimal preconditioning for the Langevin diffusion by
analytically maximizing the expected squared jumped distance. This yields as
the optimal preconditioning an inverse Fisher information covariance matrix,
where the covariance matrix is computed as the outer product of log target
gradients averaged under the target. We apply this result to the Metropolis
adjusted Langevin algorithm (MALA) and derive a computationally efficient
adaptive MCMC scheme that learns the preconditioning from the history of
gradients produced as the algorithm runs. We show in several experiments that
the proposed algorithm is very robust in high dimensions and significantly
outperforms other methods, including a closely related adaptive MALA scheme
that learns the preconditioning with standard adaptive MCMC as well as the
position-dependent Riemannian manifold MALA sampler.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:07:44 GMT""}]","2023-05-25"
"2305.14443","J. Stanton","J. Stanton (1), R. Sharankova (1), K. Seiya (1), M. Wesley (1) ((1)
  Fermilab)","Beam Loss Monitoring with Fixed and Translating Scintillation Detectors
  Along the Fermilab Drift-tube Linac","14th International Particle Accelerator Conf. (IPAC23), Venice,
  Italy, May 2023",,,"FERMILAB-CONF-23-202-AD","physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The Fermilab Linac is a roughly 145 meter linear accelerator that accelerates
H- beam from 750 keV to 400 MeV and provides beam for the Booster and the rest
of the accelerator chain. The first section of the Linac is a Drift-Tube Linac
(DTL), which in its current state, suffers from a lack of instrumentation along
its length. As a result, operational staff do not have access to the diagnostic
information needed to tune the critical components of this accelerator, such as
the quadrupole magnets within the drift tubes. This work presents an effort to
utilize both fixed and translating scintillation detectors to investigate beam
loss along the first two cavities of the DTL.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:08:43 GMT""}]","2023-05-25"
"2305.14444","Valerio De Luca","Valerio De Luca, Justin Khoury, Sam S. C. Wong","Non-linearities in the tidal Love numbers of black holes","30 pages",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tidal Love numbers describe the linear response of a compact object under the
presence of external tidal perturbations, and they are found to vanish exactly
for black holes within General Relativity. In this paper we investigate the
tidal deformability of neutral black holes when non-linearities in the theory
are taken into account. As a case in point, we consider scalar tidal
perturbations on the black hole background, and find that the tidal Love
numbers may be non vanishing depending on the scalar interactions in the bulk
theory. Remarkably, for non-linear sigma models, we find that the tidal Love
numbers vanish to all orders in perturbation theory.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:09:46 GMT""}]","2023-05-25"
"2305.14445","Jenny Chen","Jenny Chen (1), Benjamin Ades-Aron (1), Hong-Hsi Lee (2), Michelle
  Pang (3), Dmitry S. Novikov (1), Jelle Veraart (1), Els Fieremans (1)","Optimization and Validation of the DESIGNER dMRI preprocessing pipeline
  in white matter aging",,,,,"physics.med-ph physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  DESIGNER, a preprocessing pipeline for clinically acquired diffusion MRI
data, has been modified to improve denoising and target Gibbs ringing for
partial Fourier acquisitions. Here, we compare DESIGNER against other pipelines
on a large clinical dMRI dataset (554 controls, 25 to 75 years old) and
assessed DESIGNER's denoise and degibbs methods using ground truth phantom.
Results show DESIGNER provides more accurate and robust parameter maps.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:09:56 GMT""}]","2023-05-25"
"2305.14446","Sarunas Verner","Marcos A. G. Garcia, Mathias Pierre, Sarunas Verner","A New Window into Gravitationally Produced Scalar Dark Matter","6 pages, 3 figures (Supplementary Material: 13 pages, 5 figures)",,,"DESY-23-065","hep-ph astro-ph.CO gr-qc","http://creativecommons.org/licenses/by/4.0/","  Conventional scenarios of purely gravitationally produced dark matter with
masses below the Hubble parameter at the end of inflation are in tension with
Cosmic Microwave Background (CMB) constraints on the isocurvature power
spectrum. We explore a more general scenario with a non-minimal coupling
between the scalar dark matter field and gravity, which allows for
significantly lighter scalar dark matter masses compared to minimal coupling
predictions. By imposing relic abundance, isocurvature, Lyman-$\alpha$, and Big
Bang Nucleosynthesis (BBN) constraints, we show the viable parameter space for
these models. Our findings demonstrate that the presence of a non-minimal
coupling expands the parameter space, yielding a dark matter mass lower bound
of $2 \times 10^{-4} \, \rm{eV}$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:10:23 GMT""}]","2023-05-25"
"2305.14447","Joanne Pledger Dr","Joanne L. Pledger and Michael M. Shara","Possible detection of the progenitor of the Type II supernova SN2023ixf","5 pages, 3 figures, 1 table, submitted to ApJL",,,,"astro-ph.SR astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Stellar evolution theory predicts multiple pathways to the explosive deaths
of stars as supernovae. Locating and characterizing the progenitors of
well-studied supernovae is important to constrain the theory, and to justify
and design future surveys to improve on progenitor detections. Here we report
the serendipitous pre-explosion imaging, by the Hubble Space Telescope, of
SN2023ixf, one of the nearest extragalactic supernovae ever discovered, in the
galaxy M101. The extremely red color and absolute magnitude
M(F814W)=-5.42+/-0.06mag suggest that the progenitor was a red supergiant and
comparison with stellar evolutionary isochrones suggests a mass of ~12M_Sun.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:11:14 GMT""}]","2023-05-25"
"2305.14448","Daniel Gra\c{c}a","Daniel S. Gra\c{c}a and Ning Zhong","Robust non-computability and stability of dynamical systems","arXiv admin note: substantial text overlap with arXiv:2109.15080",,,,"math.LO cs.LO math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we examine the relationship between the stability of the
dynamical system $x^{\prime}=f(x)$ and the computability of its basins of
attraction. We present a computable $C^{\infty}$ system $x^{\prime}=f(x)$ that
possesses a computable and stable equilibrium point, yet whose basin of
attraction is robustly non-computable in a neighborhood of $f$ in the sense
that both the equilibrium point and the non-computability of its associated
basin of attraction persist when $f$ is slightly perturbed. This indicates that
local stability near a stable equilibrium point alone is insufficient to
guarantee the computability of its basin of attraction. However, we also
demonstrate that the basins of attraction associated with a structurally stable
- globally stable - planar system are computable. Our findings suggest that the
global stability of a system plays a pivotal role in determining the
computability of its basins of attraction.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:12:56 GMT""}]","2023-05-25"
"2305.14449","Zheng Chen","Zheng Chen, Ziyan Jiang, Fan Yang, Eunah Cho, Xing Fan, Xiaojiang
  Huang, Yanbin Lu, Aram Galstyan","Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust
  Conversational Understanding",,,,,"cs.AI cs.IR cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Conversational AI systems such as Alexa need to understand defective queries
to ensure robust conversational understanding and reduce user friction. These
defective queries often arise from user ambiguities, mistakes, or errors in
automatic speech recognition (ASR) and natural language understanding (NLU).
  Personalized query rewriting is an approach that focuses on reducing defects
in queries by taking into account the user's individual behavior and
preferences. It typically relies on an index of past successful user
interactions with the conversational AI. However, unseen interactions within
the user's history present additional challenges for personalized query
rewriting. This paper presents our ""Collaborative Query Rewriting"" approach,
which specifically addresses the task of rewriting new user interactions that
have not been previously observed in the user's history. This approach builds a
""User Feedback Interaction Graph"" (FIG) of historical user-entity interactions
and leverages multi-hop graph traversal to enrich each user's index to cover
future unseen defective queries. The enriched user index is called a
Collaborative User Index and contains hundreds of additional entries. To
counteract precision degradation from the enlarged index, we add additional
transformer layers to the L1 retrieval model and incorporate graph-based and
guardrail features into the L2 ranking model.
  Since the user index can be pre-computed, we further investigate the
utilization of a Large Language Model (LLM) to enhance the FIG for user-entity
link prediction in the Video/Music domains. Specifically, this paper
investigates the Dolly-V2 7B model. We found that the user index augmented by
the fine-tuned Dolly-V2 generation significantly enhanced the coverage of
future unseen user interactions, thereby boosting QR performance on unseen
queries compared with the graph traversal only approach.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:15:29 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jun 2023 12:42:45 GMT""}]","2023-06-06"
"2305.14450","Ridong Han","Ridong Han, Tao Peng, Chaohao Yang, Benyou Wang, Lu Liu, Xiang Wan","Is Information Extraction Solved by ChatGPT? An Analysis of Performance,
  Evaluation Criteria, Robustness and Errors","23 pages, version 1.0",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ChatGPT has stimulated the research boom in the field of large language
models. In this paper, we assess the capabilities of ChatGPT from four
perspectives including Performance, Evaluation Criteria, Robustness and Error
Types. Specifically, we first evaluate ChatGPT's performance on 17 datasets
with 14 IE sub-tasks under the zero-shot, few-shot and chain-of-thought
scenarios, and find a huge performance gap between ChatGPT and SOTA results.
Next, we rethink this gap and propose a soft-matching strategy for evaluation
to more accurately reflect ChatGPT's performance. Then, we analyze the
robustness of ChatGPT on 14 IE sub-tasks, and find that: 1) ChatGPT rarely
outputs invalid responses; 2) Irrelevant context and long-tail target types
greatly affect ChatGPT's performance; 3) ChatGPT cannot understand well the
subject-object relationships in RE task. Finally, we analyze the errors of
ChatGPT, and find that ""unannotated spans"" is the most dominant error type.
This raises concerns about the quality of annotated data, and indicates the
possibility of annotating data with ChatGPT. The data and code are released at
Github site.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:17:43 GMT""}]","2023-05-25"
"2305.14451","Mohit Yadav","Mohit Yadav, Daniel Sheldon, Cameron Musco","Kernel Interpolation with Sparse Grids","Accepted at Neural Information Processing Systems (NeurIPS) 2022",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Structured kernel interpolation (SKI) accelerates Gaussian process (GP)
inference by interpolating the kernel covariance function using a dense grid of
inducing points, whose corresponding kernel matrix is highly structured and
thus amenable to fast linear algebra. Unfortunately, SKI scales poorly in the
dimension of the input points, since the dense grid size grows exponentially
with the dimension. To mitigate this issue, we propose the use of sparse grids
within the SKI framework. These grids enable accurate interpolation, but with a
number of points growing more slowly with dimension. We contribute a novel
nearly linear time matrix-vector multiplication algorithm for the sparse grid
kernel matrix. Next, we describe how sparse grids can be combined with an
efficient interpolation scheme based on simplices. With these changes, we
demonstrate that SKI can be scaled to higher dimensions while maintaining
accuracy.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:17:49 GMT""}]","2023-05-26"
"2305.14452","Qidong Yang","Qidong Yang, Alex Hernandez-Garcia, Paula Harder, Venkatesh Ramesh,
  Prasanna Sattegeri, Daniela Szwarcman, Campbell D. Watson, David Rolnick","Fourier Neural Operators for Arbitrary Resolution Climate Data
  Downscaling","Presented at the ICLR 2023 workshop on ""Tackling Climate Change with
  Machine Learning""",,,,"cs.LG physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Climate simulations are essential in guiding our understanding of climate
change and responding to its effects. However, it is computationally expensive
to resolve complex climate processes at high spatial resolution. As one way to
speed up climate simulations, neural networks have been used to downscale
climate variables from fast-running low-resolution simulations, but
high-resolution training data are often unobtainable or scarce, greatly
limiting accuracy. In this work, we propose a downscaling method based on the
Fourier neural operator. It trains with data of a small upsampling factor and
then can zero-shot downscale its input to arbitrary unseen high resolution.
Evaluated both on ERA5 climate model data and on the Navier-Stokes equation
solution data, our downscaling model significantly outperforms state-of-the-art
convolutional and generative adversarial downscaling models, both in standard
single-resolution downscaling and in zero-shot generalization to higher
upsampling factors. Furthermore, we show that our method also outperforms
state-of-the-art data-driven partial differential equation solvers on
Navier-Stokes equations. Overall, our work bridges the gap between simulation
of a physical process and interpolation of low-resolution output, showing that
it is possible to combine both approaches and significantly improve upon each
other.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:25:08 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 13:03:25 GMT""}]","2023-05-31"
"2305.14453","Subba Reddy Oota","Pavan Kalyan Reddy Neerudu, Subba Reddy Oota, Mounika Marreddy,
  Venkateswara Rao Kagita, Manish Gupta","On Robustness of Finetuned Transformer-based NLP Models","16 pages, 8 figures",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Transformer-based pretrained models like BERT, GPT-2 and T5 have been
finetuned for a large number of natural language processing (NLP) tasks, and
have been shown to be very effective. However, while finetuning, what changes
across layers in these models with respect to pretrained checkpoints is
under-studied. Further, how robust are these models to perturbations in input
text? Does the robustness vary depending on the NLP task for which the models
have been finetuned? While there exists some work on studying robustness of
BERT finetuned for a few NLP tasks, there is no rigorous study which compares
this robustness across encoder only, decoder only and encoder-decoder models.
  In this paper, we study the robustness of three language models (BERT, GPT-2
and T5) with eight different text perturbations on the General Language
Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and
STIR) to quantify changes between pretrained and finetuned language model
representations across layers. GPT-2 representations are more robust than BERT
and T5 across multiple types of input perturbation. Although models exhibit
good robustness broadly, dropping nouns, verbs or changing characters are the
most impactful. Overall, this study provides valuable insights into
perturbation-specific weaknesses of popular Transformer-based models which
should be kept in mind when passing inputs.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:25:18 GMT""}]","2023-05-25"
"2305.14454","Ben Anson","Sebastian Ober, Ben Anson, Edward Milsom and Laurence Aitchison","An Improved Variational Approximate Posterior for the Deep Wishart
  Process",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep kernel processes are a recently introduced class of deep Bayesian models
that have the flexibility of neural networks, but work entirely with Gram
matrices. They operate by alternately sampling a Gram matrix from a
distribution over positive semi-definite matrices, and applying a deterministic
transformation. When the distribution is chosen to be Wishart, the model is
called a deep Wishart process (DWP). This particular model is of interest
because its prior is equivalent to a deep Gaussian process (DGP) prior, but at
the same time it is invariant to rotational symmetries, leading to a simpler
posterior distribution. Practical inference in the DWP was made possible in
recent work (""A variational approximate posterior for the deep Wishart process""
Ober and Aitchison 2021a) where the authors used a generalisation of the
Bartlett decomposition of the Wishart distribution as the variational
approximate posterior. However, predictive performance in that paper was less
impressive than one might expect, with the DWP only beating a DGP on a few of
the UCI datasets used for comparison. In this paper, we show that further
generalising their distribution to allow linear combinations of rows and
columns in the Bartlett decomposition results in better predictive performance,
while incurring negligible additional computation cost.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:26:29 GMT""}]","2023-05-25"
"2305.14455","Bruno Leonardo Canto Martins","Bruno L. Canto Martins, Yuri S. Messias, Maria I. Arruda
  Gon\c{c}alves, Izan C. Le\~ao, Roseane L. Gomes, Lorenza F. Barraza, Dasaev
  O. Fontinele, and Jos\'e R. De Medeiros","On the behaviour of spin-orbit connection of exoplanets","15 pages, 1 figure in main paper, 6 supplementary figures. Published
  in Nature Astronomy, May 2023",,"10.1038/s41550-023-01976-0",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Star-planet interactions play, among other things, a crucial role in
planetary orbital configurations by circularizing orbits, aligning the star and
planet spin and synchronizing stellar rotation with orbital motions. This is
especially true for innermost giant planets, which can be schematized as binary
systems with a very large mass ratio. Despite a few examples where spin-orbit
synchronization has been obtained, there is no demographic study on synchronous
regimes in those systems yet. Here we use a sample of 1,055 stars with
innermost planet companions to show the existence of three observational loci
of star-planet synchronization regimes. Two of them have dominant fractions of
subsynchronous and supersynchronous star-planet systems, and a third less
populated regime of potentially synchronized systems. No synchronous
star-planet system with a period higher than 40 days has been detected yet.
This landscape is different from eclipsing binary systems, most of which are
synchronized. We suggest that planets in a stable asynchronous spin state
belonging to star-planet systems in a supersynchronized regime offer the most
favourable conditions for habitability.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:27:35 GMT""},{""version"":""v2"",""created"":""Sun, 28 May 2023 13:25:08 GMT""}]","2023-05-30"
"2305.14456","Tarek Naous","Tarek Naous, Michael J. Ryan, Wei Xu","Having Beer after Prayer? Measuring Cultural Bias in Large Language
  Models",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Are language models culturally biased? It is important that language models
conform to the cultural aspects of the communities they serve. However, we show
in this paper that language models suffer from a significant bias towards
Western culture when handling and generating text in Arabic, often preferring,
and producing Western-fitting content as opposed to the relevant Arab content.
We quantify this bias through a likelihood scoring-based metric using naturally
occurring contexts that we collect from online social media. Our experiments
reveal that both Arabic monolingual and multilingual models exhibit bias
towards Western culture in eight different cultural aspects: person names,
food, clothing, location, literature, beverage, religion, and sports. Models
also tend to exhibit more bias when prompted with Arabic sentences that are
more linguistically aligned with English. These findings raise concerns about
the cultural relevance of current language models. Our analyses show that
providing culture-indicating tokens or culturally-relevant demonstrations to
the model can help in debiasing.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:27:51 GMT""}]","2023-05-25"
"2305.14457","Mengxia Yu","Mengxia Yu, Zhihan Zhang, Wenhao Yu, Meng Jiang","Pre-training Language Models for Comparative Reasoning",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose a novel framework to pre-train language models for
enhancing their abilities of comparative reasoning over texts. While recent
research has developed models for NLP tasks that require comparative reasoning,
they suffer from costly manual data labeling and limited generalizability to
different tasks. Our approach involves a scalable method for collecting data
for text-based entity comparison, which leverages both structured and
unstructured data, and the design of three novel pre-training tasks. Evaluation
on a range of downstream tasks including comparative question answering,
question generation, and summarization shows that our pre-training framework
significantly improves the comparative reasoning abilities of language models,
especially under low-resource conditions. This work also releases the first
integrated benchmark for comparative reasoning over texts.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:28:42 GMT""}]","2023-05-25"
"2305.14458","Yao Dou","David Heineman, Yao Dou, Mounica Maddela, Wei Xu","Dancing Between Success and Failure: Edit-level Simplification
  Evaluation using SALSA",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Large language models (e.g., GPT-3.5) are uniquely capable of producing
highly rated text simplification, yet current human evaluation methods fail to
provide a clear understanding of systems' specific strengths and weaknesses. To
address this limitation, we introduce SALSA, an edit-based human annotation
framework that enables holistic and fine-grained text simplification
evaluation. We develop twenty one linguistically grounded edit types, covering
the full spectrum of success and failure across dimensions of conceptual,
syntactic and lexical simplicity. Using SALSA, we collect 12K edit annotations
on 700 simplifications, revealing discrepancies in the distribution of
transformation approaches performed by fine-tuned models, few-shot LLMs and
humans, and finding GPT-3.5 performs more quality edits than humans, but still
exhibits frequent errors. Using our fine-grained annotations, we develop
LENS-SALSA, a reference-free automatic simplification metric, trained to
predict sentence- and word-level quality simultaneously. Additionally, we
introduce word-level quality estimation for simplification and report promising
baseline results. Our training material, annotation toolkit, and data are
released at http://salsa-eval.com.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:30:49 GMT""}]","2023-05-25"
"2305.14459","Yunzhe Li","Yunzhe Li, Qian Chen, Weixiang Yan, Wen Wang, Qinglin Zhang, Hari
  Sundaram","Enhancing Generation through Summarization Duality and Explicit Outline
  Control","6 pages",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatically open-ended long text generation poses significant challenges
due to semantic incoherence and plot implausibility. Previous works usually
alleviate this problem through outlines in the form of short phrases or
abstractive signals by designing unsupervised tasks, which tend to be unstable
and weakly interpretable.
  Assuming that a summary serves as a mature outline, we introduce a two-stage,
summary-enhanced outline supervised generation framework. This framework
leverages the dual characteristics of the summarization task to improve outline
prediction, resulting in more explicit and plausible outlines. Furthermore, we
identify an underutilization issue in outline-based generation with both
standard pretrained language models (e.g., GPT-2, BART) and large language
models (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit
outline control method for more effective utilization of generated outlines.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:33:52 GMT""}]","2023-05-25"
"2305.14460","Abbas Sharifi","Mohsen Ahmadi, Ahmad Gholizadeh Lonbar, Mohammadsadegh Nouri, Amir
  Sharifzadeh Javidi, Ali Tarlani Beris, Abbas Sharifi, Ali Salimi-Tarazouj","Supervised Multi-Regional Segmentation Machine Learning Architecture for
  Digital Twin Applications in Coastal Regions",,,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study explores the use of a digital twin model and deep learning method
to build a global terrain and altitude map based on USGS information. The goal
is to artistically represent various landforms while incorporating precise
elevation modifications in the terrain map and encoding land height in the
altitude map. A random selection of 5000 segments from the worldwide map
guarantees the inclusion of significant characteristics in the subsets, with
rescaling according to latitude accounting for distortions caused by map
projection. The process of generating segmentation maps involves using
unsupervised clustering and classification methods, segmenting the terrain into
seven groups: Water, Grassland, Forest, Hills, Desert, Mountain, and Tundra.
Each group is assigned a unique color, and median filtering is used to improve
map characteristics. Random parameters are added to provide diversity and avoid
duplication in overlapping image sets. The U-Net network is deployed for the
segmentation task, with training conducted on the seven terrain classes.
Cross-validation is carried out every 10 epochs to gauge the model's
performance. The segmentation maps produced accurately categorize the terrain,
as evidenced by the ROC curve and AUC values. The main goal of this research is
to create a digital twin model of Florida's coastal area. This is achieved
through the application of deep learning methods and satellite imagery from
Google Earth, resulting in a detailed depiction of the coast of Florida. The
digital twin acts as both a physical and a simulation model of the area,
emphasizing its capability to capture and replicate real-world locations. The
model effectively creates a global terrain and altitude map with precise
segmentation and capture of important land features. The results confirm the
effectiveness of the digital twin, especially in depicting Florida's coastline.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:35:33 GMT""}]","2023-05-25"
"2305.14461","Diego Arroyuelo Darroyue","Diego Arroyuelo, Gabriel Carmona, H\'ector Larra\~naga, Francisco
  Riveros, Erick Sep\'ulveda","Engineering Rank/Select Data Structures for Big-Alphabet Strings",,,,,"cs.DS","http://creativecommons.org/licenses/by-sa/4.0/","  Big-alphabet strings are common in several scenarios such as information
retrieval and natural-language processing. The efficient storage and processing
of such strings usually introduces several challenges that are not witnessed in
smaller-alphabets strings. This paper studies the efficient implementation of
one of the most effective approaches for dealing with big-alphabet strings,
namely the \emph{alphabet-partitioning} approach. The main contribution is a
compressed data structure that supports the fundamental operations rank and
select efficiently. We show experimental results that indicate that our
implementation outperforms the current realizations of the
alphabet-partitioning approach. In particular, the time for operation select
can be improved by about 80%, using only 11% more space than current
alphabet-partitioning schemes. We also show the impact of our data structure on
several applications, like the intersection of inverted lists (where
improvements of up to 60% are achieved, using only 2% of extra space), the
representation of run-length compressed strings, and the
distributed-computation processing of rank and select operations.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:35:39 GMT""}]","2023-05-25"
"2305.14462","Hanlin Mo","Hanlin Mo and Guoying Zhao","Sorted Convolutional Network for Achieving Continuous Rotational
  Invariance",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The topic of achieving rotational invariance in convolutional neural networks
(CNNs) has gained considerable attention recently, as this invariance is
crucial for many computer vision tasks such as image classification and
matching. In this letter, we propose a Sorting Convolution (SC) inspired by
some hand-crafted features of texture images, which achieves continuous
rotational invariance without requiring additional learnable parameters or data
augmentation. Further, SC can directly replace the conventional convolution
operations in a classic CNN model to achieve its rotational invariance. Based
on MNIST-rot dataset, we first analyze the impact of convolutional kernel
sizes, different sampling and sorting strategies on SC's rotational invariance,
and compare our method with previous rotation-invariant CNN models. Then, we
combine SC with VGG, ResNet and DenseNet, and conduct classification
experiments on popular texture and remote sensing image datasets. Our results
demonstrate that SC achieves the best performance in the aforementioned tasks.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:37:07 GMT""}]","2023-05-25"
"2305.14463","Tarek Naous","Tarek Naous, Michael J. Ryan, Mohit Chandra, Wei Xu","Towards Massively Multi-domain Multilingual Readability Assessment",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present ReadMe++, a massively multi-domain multilingual dataset for
automatic readability assessment. Prior work on readability assessment has been
mostly restricted to the English language and one or two text domains.
Additionally, the readability levels of sentences used in many previous
datasets are assumed on the document-level other than sentence-level, which
raises doubt about the quality of previous evaluations. We address those gaps
in the literature by providing an annotated dataset of 6,330 sentences in
Arabic, English, and Hindi collected from 64 different domains of text. Unlike
previous datasets, ReadMe++ offers more domain and language diversity and is
manually annotated at a sentence level using the Common European Framework of
Reference for Languages (CEFR) and through a Rank-and-Rate annotation framework
that reduces subjectivity in annotation. Our experiments demonstrate that
models fine-tuned using ReadMe++ achieve strong cross-lingual transfer
capabilities and generalization to unseen domains. ReadMe++ will be made
publicly available to the research community.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:37:30 GMT""}]","2023-05-25"
"2305.14464","Doyeol (David) Ahn","Doyeol Ahn (1,2) ((1) Department of Electrical and Computer
  Engineering, University of Seoul, Seoul, Republic of Korea (2) First Quantum,
  Inc, Seoul, Republic of Korea)","Non-Markovian cost function for quantum error mitigation with Dirac
  Gamma matrices representation","arXiv admin note: text overlap with arXiv:2302.05053",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we explore the non-Markovian cost function for quantum error
mitigation (QEM) and the representation of two-qubit operators using Dirac
Gamma matrices, central to the structure of relativistic quantum mechanics. The
primary focus of quantum computing research, particularly with noisy
intermediate-scale quantum (NISQ) devices, is on reducing errors and
decoherence for practical application. While much of the existing research
concentrates on Markovian noise sources, the study of non-Markovian sources is
crucial given their inevitable presence in most solid-state quantum computing
devices. We introduce a non-Markovian model of quantum state evolution and a
corresponding QEM cost function for NISQ devices, considering an environment
typified by simple harmonic oscillators as a noise source. The Dirac Gamma
matrices, integral to areas of physics like quantum field theory and
supersymmetry, share a common algebraic structure with two-qubit gate
operators. By representing the latter using Gamma matrices, we are able to more
effectively analyze and manipulate these operators due to the distinct
properties of Gamma matrices. We evaluate the fluctuations of the output
quantum state for identity and SWAP gate operations in two-qubit operations
across various input states. By comparing these results with experimental data
from ion-trap and superconducting quantum computing systems, we estimate the
key parameters of the QEM cost functions. Our results reveal that as the
coupling strength between the quantum system and its environment increases, so
does the QEM cost function. This study underscores the importance of
non-Markovian models for understanding quantum state evolution and the
practical implications of the QEM cost function when assessing experimental
results from NISQ devices.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:38:09 GMT""}]","2023-05-25"
"2305.14465","Wei Zhang","Chao Li, Michael Rapoport, Wei Zhang","Arithmetic Fundamental Lemma for the spherical Hecke algebra","47 pages",,,,"math.NT math.AG math.RT","http://creativecommons.org/licenses/by/4.0/","  We define Hecke correspondences and Hecke operators on unitary RZ spaces and
study their basic geometric properties, including a commutativity conjecture on
Hecke operators. Then we formulate the Arithmetic Fundamental Lemma conjecture
for the spherical Hecke algebra. We also formulate a conjecture on the
abundance of spherical Hecke functions with identically vanishing first
derivative of orbital integrals. We prove these conjectures for the case
$U(1)\times U(2)$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:39:56 GMT""}]","2023-05-25"
"2305.14466","Soumik Bhattacharya Dr.","Soumik Bhattacharya, Vandana Tripathi, S. L. Tabor, A. Volya, P. C.
  Bender, C. Benetti, M. P. Carpenter, J. J. Carroll, A. Chester, C. J. Chiara,
  K. Childers, B. R. Clark, B. P. Crider, J. T. Harke, S. N. Liddick, R. S.
  Lubna, S. Luitel, B. Longfellow, M. J. Mogannam, T. H. Ogunbeku, J. Perello,
  A. L. Richard, E. Rubino, S. Saha, O. A. Shehu, R. Unz, Y. Xiao, and Yiyi Zhu","$\beta^-$ decay of neutron-rich $^{45}$Cl at magic number N=28","11 pages, 10 figures",,,,"nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Results from the study of $\beta^-$-decay of $^{45}$Cl, produced in the
fragmentation of a 140-MeV/u $^{48}$Ca beam, are presented. The half-life for
$^{45}$Cl $\beta$-decay is measured to be 513(36) ms. The $\beta^-$ and
$\beta^- 1n$ decay of $^{45}$Cl populated excited states in $^{45,44}$Ar,
respectively. On the basis of $\gamma$-ray singles and $\gamma$-$\gamma$
coincidence data, decay schemes for the two daughter nuclei have been
established. They are compared with shell model calculations using the FSU
interaction. The low-lying negative parity states for $^{45}$Ar are well
described by a single particle (neutron) occupying orbitals near the Fermi
surface, whereas neutron excitations across the $N = 20$ shell gap are needed
to explain the positive-parity states which are expected to be populated in
allowed Gamow-Teller $\beta$-decay of $^{45}$Cl. The highest $\beta$-feeding to
the 5/2$^+$ state in $^{45}$Ar from the ground state of $^{45}$Cl points
towards a 3/2$^+$ spin-parity assignment of the ground state of the parent over
the other possibility of 1/2$^+$. The high Q$_{\beta^-}$ value of $^{45}$Cl
decay allows for the population of $1p1h$ states above the neutron separation
energy in $^{45}$Ar leading to positive parity states of $^{44}$Ar being
populated by removal of one neutron from the $sd$ shell. The spin-parities of
the excited levels in $^{44}$Ar are tentatively assigned for the first time by
comparison with the shell model calculations. The 2978~keV level of $^{44}$Ar
is identified as the excited 0$^+$ level which could correspond to a different
configuration from the ground state.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:45:03 GMT""}]","2023-05-25"
"2305.14467","Anatol Garioud","Anatol Garioud, Apolline De Wit, Marc Poup\'ee, Marion Valette,
  S\'ebastien Giordano, Boris Wattrelos","FLAIR #2: textural and temporal information for semantic segmentation
  from multi-source optical imagery",,,"10.13140/RG.2.2.30938.93128/1",,"cs.CV cs.LG eess.IV","http://creativecommons.org/licenses/by-sa/4.0/","  The FLAIR #2 dataset hereby presented includes two very distinct types of
data, which are exploited for a semantic segmentation task aimed at mapping
land cover. The data fusion workflow proposes the exploitation of the fine
spatial and textural information of very high spatial resolution (VHR)
mono-temporal aerial imagery and the temporal and spectral richness of high
spatial resolution (HR) time series of Copernicus Sentinel-2 satellite images.
The French National Institute of Geographical and Forest Information (IGN), in
response to the growing availability of high-quality Earth Observation (EO)
data, is actively exploring innovative strategies to integrate these data with
heterogeneous characteristics. IGN is therefore offering this dataset to
promote innovation and improve our knowledge of our territories.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:47:19 GMT""}]","2023-05-25"
"2305.14468","Eleonora Gualdoni","Sophia Harrison, Eleonora Gualdoni, Gemma Boleda","Run Like a Girl! Sports-Related Gender Bias in Language and Vision",,,,,"cs.CV cs.CL","http://creativecommons.org/licenses/by/4.0/","  Gender bias in Language and Vision datasets and models has the potential to
perpetuate harmful stereotypes and discrimination. We analyze gender bias in
two Language and Vision datasets. Consistent with prior work, we find that both
datasets underrepresent women, which promotes their invisibilization. Moreover,
we hypothesize and find that a bias affects human naming choices for people
playing sports: speakers produce names indicating the sport (e.g. 'tennis
player' or 'surfer') more often when it is a man or a boy participating in the
sport than when it is a woman or a girl, with an average of 46% vs. 35% of
sports-related names for each gender. A computational model trained on these
naming data reproduces the bias. We argue that both the data and the model
result in representational harm against women.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:52:11 GMT""}]","2023-05-25"
"2305.14469","Mathieu Mivelle Dr","Ye Mou, Xingyu Yang, Bruno Gallas, and Mathieu Mivelle","A Reversed Inverse Faraday Effect","arXiv admin note: text overlap with arXiv:2301.05971",,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  The inverse Faraday effect is a magneto-optical process allowing the
magnetization of matter by an optical excitation carrying a non-zero spin of
light. In particular, a right circular polarization generates a magnetization
in the direction of light propagation and a left circular polarization in the
opposite direction to this propagation. We demonstrate here that by
manipulating the spin density of light, i.e., its polarization, in a plasmonic
nanostructure, we generate a reversed inverse Faraday effect. A right circular
polarization will generate a magnetization in the opposite direction of the
light propagation, a left circular polarization in the direction of
propagation. Also, we demonstrate that this new physical phenomenon is chiral,
generating a strong magnetic field only for one helicity of the light, the
opposite helicity producing this effect only for the mirror structure. This new
optical concept opens the way to the generation of magnetic fields with
unpolarized light, finding application in the ultrafast manipulation of
magnetic domains and processes, such as spin precession, spin currents, and
waves, magnetic skyrmion or magnetic circular dichroism, with direct
applications in data storage and processing technologies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:52:21 GMT""}]","2023-05-25"
"2305.14470","Mark Van der Merwe","Mark Van der Merwe, Youngsun Wi, Dmitry Berenson, Nima Fazeli","Integrated Object Deformation and Contact Patch Estimation from
  Visuo-Tactile Feedback","12 pages",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reasoning over the interplay between object deformation and force
transmission through contact is central to the manipulation of compliant
objects. In this paper, we propose Neural Deforming Contact Field (NDCF), a
representation that jointly models object deformations and contact patches from
visuo-tactile feedback using implicit representations. Representing the object
geometry and contact with the environment implicitly allows a single model to
predict contact patches of varying complexity. Additionally, learning geometry
and contact simultaneously allows us to enforce physical priors, such as
ensuring contacts lie on the surface of the object. We propose a neural network
architecture to learn a NDCF, and train it using simulated data. We then
demonstrate that the learned NDCF transfers directly to the real-world without
the need for fine-tuning. We benchmark our proposed approach against a baseline
representing geometry and contact patches with point clouds. We find that NDCF
performs better on simulated data and in transfer to the real-world.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:53:24 GMT""}]","2023-05-25"
"2305.14471","Xuanyu Zhang","Xuanyu Zhang and Bingbing Li and Qing Yang","CGCE: A Chinese Generative Chat Evaluation Benchmark for General and
  Financial Domains",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Generative chat models, such as ChatGPT and GPT-4, have revolutionized
natural language generation (NLG) by incorporating instructions and human
feedback to achieve significant performance improvements. However, the lack of
standardized evaluation benchmarks for chat models, particularly for Chinese
and domain-specific models, hinders their assessment and progress. To address
this gap, we introduce the Chinese Generative Chat Evaluation (CGCE) benchmark,
focusing on general and financial domains. The CGCE benchmark encompasses
diverse tasks, including 200 questions in the general domain and 150 specific
professional questions in the financial domain. Manual scoring evaluates
factors such as accuracy, coherence, expression clarity, and completeness. The
CGCE benchmark provides researchers with a standardized framework to assess and
compare Chinese generative chat models, fostering advancements in NLG research.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:54:15 GMT""}]","2023-05-25"
"2305.14472","Spenser Talkington","Spenser Talkington, Eugene J. Mele","Terahertz Circular Dichroism in Commensurate Twisted Bilayer Graphene","9 pages, 7 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report calculations of terahertz ellipticities in large-angle,
21.79$^\circ$ and 38.21$^\circ$, commensurate twisted bilayer graphene, and
predict values as high as 1.5 millidegrees in the terahertz region for this
non-magnetic material. This terahertz circular dichroism exhibits a magnitude
comparable to that of chiral materials in the visible region. At low
frequencies, the dichroic response is mediated by strong interlayer
hybridization, which allows us to probe the symmetry and strength of these
couplings. Crucially, lateral interlayer translation tunes this response, in
contrast to small twist angle bilayer graphene's near invariance under under
interlayer translation. We examine the magnitude and phase of the interlayer
coupling for all structures containing fewer than 400 atoms per unit cell.
Finally, we find that the dichroism can be manipulated by applying an electric
field or with doping.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:00:03 GMT""}]","2023-05-25"
"2305.14473","Jorge Antezana","Jorge Antezana and Sheldy Ombrosi","Weighted maximal inequalities on hyperbolic spaces","21 pages, 3 figures",,,,"math.CA math.FA","http://creativecommons.org/licenses/by/4.0/","  In this work we develop a weight theory in the setting of hyperbolic spaces.
Our starting point is a variant of the well-known endpoint Fefferman-Stein
inequality for the centered Hardy-Littlewood maximal function. This inequality
generalizes, in the hyperbolic setting, the weak $(1,1)$ estimates obtained by
Str\""omberg in ""Weak type L1 estimates for maximal functions on noncompact
symmetric spaces"", Ann. of Math. 114 (1981), where Str\""omberg answered a
question posed by Stein and Wainger in ""Problems in harmonic analysis related
to curvature"", Bull. Amer. Math. Soc. 84 (1978). Our approach is based on a
combination of geometrical arguments and the techniques used in the discrete
setting of regular trees by Naor and Tao in ""Random martingales and
localization of maximal inequalities"", J. Funct. Anal. 259 (2010). This variant
of the Fefferman-Stein inequality paves the road to weighted estimates for the
maximal function for $p>1$. On the one hand, we show that the classical $A_p$
conditions are not the right ones in this setting. On the other hand, we
provide sharp sufficient conditions for weighted weak and strong type $(p,p)$
boundedness of the centered maximal function, when $p>1$. The sharpness is in
the sense that, given $p>1$, we can construct a weight satisfying our
sufficient condition for that $p$, and so it satisfies the weak type $(p,p)$
inequality, but the strong type $(p,p)$ inequality fails. In particular, the
weak type $(q,q)$ fails as well for every $q < p$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:02:41 GMT""}]","2023-05-25"
"2305.14474","Maria Giovanna Mora","Maria Giovanna Mora","Nonlocal anisotropic interactions of Coulomb type",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we review some recent results on nonlocal interaction problems.
The focus is on interaction kernels that are anisotropic variants of the
classical Coulomb kernel. In other words, while preserving the same singularity
at zero of the Coulomb kernel, they present preferred directions of
interaction. For kernels of this kind and general confinement we will prove
existence and uniqueness of minimisers of the corresponding energy. In the case
of a quadratic confinement we will review a recent result by Carrillo & Shu
about the explicit characterisation of minimisers, and present a new proof,
which has the advantage of being extendable to higher dimension. In light of
this result, we will re-examine some previous works motivated by applications
to dislocation theory in materials science. Finally, we will discuss some
related results and open questions.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:05:01 GMT""}]","2023-05-25"
"2305.14475","Juan Flores Torres","Juan Flores Torres","Moduli Space of Bi-Invariant Metrics","14 pages, 1 figure",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we focus on describing the space of bi-invariant metrics in a
Lie group up to isometry. I.e, that is, metrics invariant under both left and
right translations. We show that $\mathfrak{BI}$, the moduli space of
bi-invariant metrics, is an orbifold. Moreover we give an explicit description
of this orbifold, and of $\mathfrak{EBI}$, the space of bi-invariant metrics
equivalent under isometries and scalar multiplies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:06:21 GMT""}]","2023-05-25"
"2305.14476","Alvio Renzini","Alvio Renzini","A Transient Overcooling in the Early Universe? Clues from Globular
  Clusters Formation","Four pages, no figures, submitted to MNRAS on May 22, 2023",,,,"astro-ph.GA","http://creativecommons.org/publicdomain/zero/1.0/","  The mere existence of multiple stellar generations in Milky Way globular
clusters indicates that each generation was unable to stop star formation, that
instead persisted unimpeded for several million years. This evidence argues for
an extended stage of star formation within a forming globular cluster, during
which stellar feedback was substantially ineffective and the nascent globular
cluster was able to accrete processed gas from its surrounding, and efficiently
convert it into successive stellar generations. It has been argued that such
delayed feedback results from core collapse in most massive stars failing to
trigger an energetic supernova explosion, but rather leading directly to black
hole formation. Thus, globular clusters offer a concrete phenomenological
example for the lack of feedback in young starbursts, an option that has been
widely advocated to account for the unexpected abundance of UV-luminous
galaxies at z = 9-16, as revealed by JWST observations. The paper is meant to
attract attention to this opportunity for a synergic cooperation of globular
cluster and high redshift research.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:08:06 GMT""}]","2023-05-25"
"2305.14477","Elisa Riccietti","Serge Gratton, Valentin Mercier, Elisa Riccietti, Philippe L. Toint","A Block-Coordinate Approach of Multi-level Optimization with an
  Application to Physics-Informed Neural Networks",,,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-level methods are widely used for the solution of large-scale problems,
because of their computational advantages and exploitation of the
complementarity between the involved sub-problems. After a re-interpretation of
multi-level methods from a block-coordinate point of view, we propose a
multi-level algorithm for the solution of nonlinear optimization problems and
analyze its evaluation complexity. We apply it to the solution of partial
differential equations using physics-informed neural networks (PINNs) and show
on a few test problems that the approach results in better solutions and
significant computational savings
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:12:02 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 06:48:38 GMT""}]","2023-05-26"
"2305.14478","Lars Vilhuber","Lars Vilhuber","Reproducibility and Transparency versus Privacy and Confidentiality:
  Reflections from a Data Editor",,,,,"econ.GN q-fin.EC stat.OT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Transparency and reproducibility are often seen in opposition to privacy and
confidentiality. Data that need to be kept confidential are seen as an
impediment to reproducibility, and privacy would seem to inhibit transparency.
I bring a more nuanced view to the discussion, and show, using examples from
over 1,000 reproducibility assessments, that confidential data can very well be
used in reproducible and transparent research. The key insight is that access
to most confidential data, while tedious, is open to hundreds if not thousands
of researchers. In cases where few researchers can consider accessing such data
in the future, reproducibility services, such as those provided by some
journals, can provide some evidence for effective reproducibility even when the
same data may not be available for future research.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:17:38 GMT""}]","2023-05-25"
"2305.14479","Fumiya Okazaki","Fumiya Okazaki","The probabilistic characterization of weakly harmonic maps with respect
  to non-local Dirichlet forms","26 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We characterize weakly harmonic maps with respect to non-local Dirichlet
forms by Markov processes and martingales. In particular, we can obtain
discontinuous martingales on Riemanian manifolds by inserting symmetric stable
processes into fractional harmonic maps in a weak sense. We also consider the
continuity of weakly harmonic maps along the paths of Markov processes, which
is called the fine continuity. We show that the fine continuity implies the
continuity with respect to the Euclidean topology in some situations containing
cases of energy minimizing maps.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:19:37 GMT""}]","2023-05-25"
"2305.14480","Zihao Fu","Zihao Fu, Meiru Zhang, Zaiqiao Meng, Yannan Shen, Anya Okhmatovskaia,
  David Buckeridge, Nigel Collier","BAND: Biomedical Alert News Dataset",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Infectious disease outbreaks continue to pose a significant threat to human
health and well-being. To improve disease surveillance and understanding of
disease spread, several surveillance systems have been developed to monitor
daily news alerts and social media. However, existing systems lack thorough
epidemiological analysis in relation to corresponding alerts or news, largely
due to the scarcity of well-annotated reports data. To address this gap, we
introduce the Biomedical Alert News Dataset (BAND), which includes 1,508
samples from existing reported news articles, open emails, and alerts, as well
as 30 epidemiology-related questions. These questions necessitate the model's
expert reasoning abilities, thereby offering valuable insights into the
outbreak of the disease. The BAND dataset brings new challenges to the NLP
world, requiring better disguise capability of the content and the ability to
infer important information. We provide several benchmark tasks, including
Named Entity Recognition (NER), Question Answering (QA), and Event Extraction
(EE), to show how existing models are capable of handling these tasks in the
epidemiology domain. To the best of our knowledge, the BAND corpus is the
largest corpus of well-annotated biomedical outbreak alert news with
elaborately designed questions, making it a valuable resource for
epidemiologists and NLP researchers alike.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:21:00 GMT""}]","2023-05-25"
"2305.14481","Konstantin Dobler","Konstantin Dobler and Gerard de Melo","FOCUS: Effective Embedding Initialization for Specializing Pretrained
  Multilingual Models on a Single Language",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using model weights pretrained on a high-resource language as a warm start
can reduce the need for data and compute to obtain high-quality language models
in low-resource languages. To accommodate the new language, the pretrained
vocabulary and embeddings need to be adapted. Previous work on embedding
initialization for such adapted vocabularies has mostly focused on monolingual
source models. In this paper, we investigate the multilingual source model
setting and propose FOCUS - Fast Overlapping Token Combinations Using
Sparsemax, a novel embedding initialization method that outperforms previous
work when adapting XLM-R. FOCUS represents newly added tokens as combinations
of tokens in the overlap of the pretrained and new vocabularies. The
overlapping tokens are selected based on semantic similarity in an auxiliary
token embedding space. Our implementation of FOCUS is publicly available on
GitHub.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:21:53 GMT""}]","2023-05-25"
"2305.14482","Jind\v{r}ich Libovick\'y","Jind\v{r}ich Libovick\'y","Is a Prestigious Job the same as a Prestigious Country? A Case Study on
  Multilingual Sentence Embeddings and European Countries","10 pages, 1 figure",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study how multilingual sentence representations capture European countries
and how this differs across European languages. We prompt the models with
templated sentences that we machine-translate into 12 European languages and
analyze the most prominent dimensions in the embeddings. Our analysis reveals
that the most prominent country feature in the embedding is its economic
strength in terms of GPD. When prompted specifically for job prestige, the
embedding space clearly distinguishes high and low-prestige jobs. The
occupational dimension is uncorrelated with the most dominant country
dimensions for three out of four studied models. One model: Distilled
Multilingual Universal Sentence Encoder, however, exhibited a connection
between occupational prestige and country of origin, which is a potential
source of nationality-based discrimination. Our findings are consistent across
languages and, to some extent, with the exception mentioned above, across
studied representation models.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:24:42 GMT""}]","2023-05-25"
"2305.14483","Yang Yu","Jing-Cheng Pang, Pengyuan Wang, Kaiyuan Li, Xiong-Hui Chen, Jiacheng
  Xu, Zongzhang Zhang, and Yang Yu","Language Model Self-improvement by Reinforcement Learning Contemplation",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large Language Models (LLMs) have exhibited remarkable performance across
various natural language processing (NLP) tasks. However, fine-tuning these
models often necessitates substantial supervision, which can be expensive and
time-consuming to obtain. This paper introduces a novel unsupervised method
called LanguageModel Self-Improvement by Reinforcement Learning Contemplation
(SIRLC) that improves LLMs without reliance on external labels. Our approach is
grounded in the observation that it is simpler for language models to assess
text quality than to generate text. Building on this insight, SIRLC assigns
LLMs dual roles as both student and teacher. As a student, the LLM generates
answers to unlabeled questions, while as a teacher, it evaluates the generated
text and assigns scores accordingly. The model parameters are updated using
reinforcement learning to maximize the evaluation score. We demonstrate that
SIRLC can be applied to various NLP tasks, such as reasoning problems, text
generation, and machine translation. Our experiments show that SIRLC
effectively improves LLM performance without external supervision, resulting in
a 5.6% increase in answering accuracy for reasoning tasks and a rise in
BERTScore from 0.82 to 0.86 for translation tasks. Furthermore, SIRLC can be
applied to models of different sizes, showcasing its broad applicability.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:25:52 GMT""}]","2023-05-25"
"2305.14484","Massimiliano Galeazzi","Sicong Huang, Nico Cappelluti, Massimiliano Galeazzi, Anjali Gupta,
  Wenhao Liu, Eugenio Ursino, Tomykkutty J. Velliyedathu","Point source contribution to the Diffuse X-ray Background below 1 keV
  and its effect on our understanding of the circum-galactic medium","18 pages, 13 figures, 5 tables","The Astrophysical Journal, Volume 947, Issue 2, id.49, 2023","10.3847/1538-4357/acaf7b",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We studied the spectral signature of different components of the Diffuse
X-ray Background (DXB), including Local Hot Bubble (LHB), Solar Wind Charge
Exchange (SWCX), Galactic Halo, and typically unresolved point sources
(galaxies and AGN), in the direction of the Chandra Deep Field South (CDFS)
using the 4 Ms XMM-Newton survey and Chandra 4 Ms Source Catalog. In this
paper, we present our results showing how the different components contribute
to the DXB below 1 keV. In particular, we have found that ~6% of the emission
at 3/4 keV (all-sky average value ~ 3$\times10^{-3}$ cm$^{-6}$pc), which is
typically associated with Galactic Halo (GH) and Circum-galactic medium (CGM)
is, in fact, due to emission from typically unresolved galaxies.
  We will discuss the effect that this has on our understanding of GH and CGM,
and to our understanding of the missing CGM baryons.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:27:41 GMT""}]","2023-05-25"
"2305.14485","Arijit Khan","Arijit Khan","Knowledge Graphs Querying","accepted at ACM SIGMOD Record 2023","ACM SIGMOD Record 2023",,,"cs.DB cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Knowledge graphs (KGs) such as DBpedia, Freebase, YAGO, Wikidata, and NELL
were constructed to store large-scale, real-world facts as (subject, predicate,
object) triples -- that can also be modeled as a graph, where a node (a subject
or an object) represents an entity with attributes, and a directed edge (a
predicate) is a relationship between two entities. Querying KGs is critical in
web search, question answering (QA), semantic search, personal assistants, fact
checking, and recommendation. While significant progress has been made on KG
construction and curation, thanks to deep learning recently we have seen a
surge of research on KG querying and QA. The objectives of our survey are
two-fold. First, research on KG querying has been conducted by several
communities, such as databases, data mining, semantic web, machine learning,
information retrieval, and natural language processing (NLP), with different
focus and terminologies; and also in diverse topics ranging from graph
databases, query languages, join algorithms, graph patterns matching, to more
sophisticated KG embedding and natural language questions (NLQs). We aim at
uniting different interdisciplinary topics and concepts that have been
developed for KG querying. Second, many recent advances on KG and query
embedding, multimodal KG, and KG-QA come from deep learning, IR, NLP, and
computer vision domains. We identify important challenges of KG querying that
received less attention by graph databases, and by the DB community in general,
e.g., incomplete KG, semantic matching, multimodal data, and NLQs. We conclude
by discussing interesting opportunities for the data management community, for
instance, KG as a unified data model and vector-based query processing.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:32:42 GMT""}]","2023-05-25"
"2305.14486","Jadie Adams","Jadie Adams and Shireen Elhabian","Point2SSM: Learning Morphological Variations of Anatomies from Point
  Cloud","Under review",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce Point2SSM, a novel unsupervised learning approach that can
accurately construct correspondence-based statistical shape models (SSMs) of
anatomy directly from point clouds. SSMs are crucial in clinical research for
analyzing the population-level morphological variation in bones and organs.
However, traditional methods for creating SSMs have limitations that hinder
their widespread adoption, such as the need for noise-free surface meshes or
binary volumes, reliance on assumptions or predefined templates, and
simultaneous optimization of the entire cohort leading to lengthy inference
times given new data. Point2SSM overcomes these barriers by providing a
data-driven solution that infers SSMs directly from raw point clouds, reducing
inference burdens and increasing applicability as point clouds are more easily
acquired. Deep learning on 3D point clouds has seen recent success in
unsupervised representation learning, point-to-point matching, and shape
correspondence; however, their application to constructing SSMs of anatomies is
largely unexplored. In this work, we benchmark state-of-the-art point cloud
deep networks on the task of SSM and demonstrate that they are not robust to
the challenges of anatomical SSM, such as noisy, sparse, or incomplete input
and significantly limited training data. Point2SSM addresses these challenges
via an attention-based module that provides correspondence mappings from
learned point features. We demonstrate that the proposed method significantly
outperforms existing networks in terms of both accurate surface sampling and
correspondence, better capturing population-level statistics.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:36:24 GMT""}]","2023-05-25"
"2305.14487","Erik Fitzke","Jakob Kaltwasser, Joschka Seip, Erik Fitzke, Maximilian Tippmann, and
  Thomas Walther","Reducing the number of single-photon detectors in quantum key
  distribution networks by time multiplexing","6 pages, 5 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We demonstrate a method to reduce the number of single-photon detectors
(SPDs) required in multi-party quantum key distribution (QKD) networks by a
factor of two by using detector time multiplexing (DTM). We implement the DTM
scheme for an entanglement-based time-bin protocol and compare QKD results with
and without DTM in our QKD network with four users. When small efficiency
losses are acceptable, DTM enables cost-effective, scalable implementations of
multi-user QKD networks.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:36:42 GMT""}]","2023-05-25"
"2305.14488","Peter Ralph","Alison M. Etheridge and Thomas G. Kurtz and Ian Letter and Peter L.
  Ralph and Terence Tsui Ho Lung","Looking forwards and backwards: dynamics and genealogies of locally
  regulated populations",,,,,"math.PR q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  We introduce a broad class of spatial models to describe how spatially
heterogeneous populations live, die, and reproduce. Individuals are represented
by points of a point measure, whose birth and death rates can depend both on
spatial position and local population density, defined via the convolution of
the point measure with a nonnegative kernel. We pass to three different scaling
limits: an interacting superprocess, a nonlocal partial differential equation
(PDE), and a classical PDE. The classical PDE is obtained both by first scaling
time and population size to pass to the nonlocal PDE, and then scaling the
kernel that determines local population density; and also (when the limit is a
reaction-diffusion equation) by simultaneously scaling the kernel width,
timescale and population size in our individual based model. A novelty of our
model is that we explicitly model a juvenile phase: offspring are thrown off in
a Gaussian distribution around the location of the parent, and reach (instant)
maturity with a probability that can depend on the population density at the
location at which they land. Although we only record mature individuals, a
trace of this two-step description remains in our population models, resulting
in novel limits governed by a nonlinear diffusion. Using a lookdown
representation, we retain information about genealogies and, in the case of
deterministic limiting models, use this to deduce the backwards in time motion
of the ancestral lineage of a sampled individual. We observe that knowing the
history of the population density is not enough to determine the motion of
ancestral lineages in our model. We also investigate the behaviour of lineages
for three different deterministic models of a population expanding its range as
a travelling wave: the Fisher-KPP equation, the Allen-Cahn equation, and a
porous medium equation with logistic growth.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:37:00 GMT""}]","2023-05-25"
"2305.14489","Nghia T. Le","Nghia T. Le, Alan Ritter","Are Large Language Models Robust Zero-shot Coreference Resolvers?",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Recent progress in domain adaptation for coreference resolution relies on
continued training using annotated data from target domains. At the same time,
pre-trained large language models (LMs) have exhibited strong zero- and
few-shot learning abilities across a wide range of NLP tasks including pronoun
resolution. While this demonstrates evidence of coreference ability, previous
work has mostly studied this ability using simple sentence-level datasets such
as the Winograd Schema Challenge. In this work, we assess the feasibility of
zero-shot learning for coreference resolution by evaluating instruction-tuned
language models on more difficult, linguistically-complex coreference
benchmarks (e.g., CoNLL-2012). We demonstrate that zero-shot prompting
outperforms current unsupervised coreference systems. Further investigations
reveal the robust zero-shot generalization ability of instruction-tuned LMs
across a wide range of domains, languages, and time periods, as well as a
strong reliance on high-quality mention detection systems.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:38:28 GMT""}]","2023-05-25"
"2305.14490","Xiang Zhang","Xiang Zhang, Yu Gu, Huan Yan, Yantong Wang, Mianxiong Dong, Kaoru Ota,
  Fuji Ren, Yusheng Ji","Wital: A COTS WiFi Devices Based Vital Signs Monitoring System Using
  NLOS Sensing Model","Accepted by IEEE THMS","IEEE Transactions on Human-Machine Systems,2023","10.1109/THMS.2023.3264247",,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Vital sign (breathing and heartbeat) monitoring is essential for patient care
and sleep disease prevention. Most current solutions are based on wearable
sensors or cameras; however, the former could affect sleep quality, while the
latter often present privacy concerns. To address these shortcomings, we
propose Wital, a contactless vital sign monitoring system based on low-cost and
widespread commercial off-the-shelf (COTS) Wi-Fi devices. There are two
challenges that need to be overcome. First, the torso deformations caused by
breathing/heartbeats are weak. How can such deformations be effectively
captured? Second, movements such as turning over affect the accuracy of vital
sign monitoring. How can such detrimental effects be avoided? For the former,
we propose a non-line-of-sight (NLOS) sensing model for modeling the
relationship between the energy ratio of line-of-sight (LOS) to NLOS signals
and the vital sign monitoring capability using Ricean K theory and use this
model to guide the system construction to better capture the deformations
caused by breathing/heartbeats. For the latter, we propose a motion
segmentation method based on motion regularity detection that accurately
distinguishes respiration from other motions, and we remove periods that
include movements such as turning over to eliminate detrimental effects. We
have implemented and validated Wital on low-cost COTS devices. The experimental
results demonstrate the effectiveness of Wital in monitoring vital signs.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:38:40 GMT""}]","2023-05-25"
"2305.14491","Miti Patel","M. Patel, B. P. Gompertz, P. T. O'Brien, G. P. Lamb, R. L. C.
  Starling, P. A Evans, L. Amati, A. J. Levan, M. Nicholl, J. Lyman, K. Ackley,
  M. J. Dyer, K. Ulaczyk, D. Steeghs, D. K. Galloway, V. S. Dhillon, G. Ramsay,
  K. Noysena, R. Kotak, R. P. Breton, L. K. Nuttall, E. Palle, D. Pollacco","GRB 201015A and the nature of low-luminosity soft gamma-ray bursts","15 pages, 4 figures",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  GRB 201015A is a peculiarly low luminosity, spectrally soft gamma-ray burst
(GRB), with $T_{\rm 90} = 9.8 \pm 3.5$ s (time interval of detection of 90\% of
photons from the GRB), and an associated supernova (likely to be type Ic or
Ic-BL). GRB 201015A has an isotropic energy $E_{\gamma,\rm iso} = 1.75 ^{+0.60}
_{-0.53} \times 10^{50}$ erg, and photon index $\Gamma = 3.00 ^{+0.50}
_{-0.42}$ (15-150 keV). It follows the Amati relation, a correlation between
$E_{\gamma,\rm iso}$ and spectral peak energy $E_{\rm p}$ followed by long
GRBs. It appears exceptionally soft based on $\Gamma$, the hardness ratio of HR
= $0.47 \pm 0.24$, and low-$E_{\rm p}$, so we have compared it to other GRBs
sharing these properties. These events can be explained by shock breakout,
poorly collimated jets, and off-axis viewing. Follow-up observations of the
afterglow taken in the X-ray, optical, and radio, reveal a surprisingly late
flattening in the X-ray from $t = (2.61 \pm 1.27)\times 10^4$ s to $t = 1.67
^{+1.14} _{-0.65} \times 10^6$ s. We fit the data to closure relations
describing the synchrotron emission, finding the electron spectral index to be
$p = 2.42 ^{+0.44} _{-0.30}$, and evidence of late-time energy injection with
coefficient $q = 0.24 ^{+0.24} _{-0.18}$. The jet half opening angle lower
limit ($\theta_{j} \ge 16^{\circ}$) is inferred from the non-detection of a jet
break. The launch of SVOM and Einstein Probe in 2023, should enable detection
of more low luminosity events like this, providing a fuller picture of the
variety of GRBs.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:42:29 GMT""}]","2023-05-25"
"2305.14492","Arkadiy Saakyan","Sky CH-Wang, Arkadiy Saakyan, Oliver Li, Zhou Yu, Smaranda Muresan","Sociocultural Norm Similarities and Differences via Situational
  Alignment and Explainable Textual Entailment",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Designing systems that can reason across cultures requires that they are
grounded in the norms of the contexts in which they operate. However, current
research on developing computational models of social norms has primarily
focused on American society. Here, we propose a novel approach to discover and
compare descriptive social norms across Chinese and American cultures. We
demonstrate our approach by leveraging discussions on a Chinese Q&A
platform-Zhihu-and the existing SocialChemistry dataset as proxies for
contrasting cultural axes, align social situations cross-culturally, and
extract social norms from texts using in-context learning. Embedding
Chain-of-Thought prompting in a human-AI collaborative framework, we build a
high-quality dataset of 3,069 social norms aligned with social situations
across Chinese and American cultures alongside corresponding free-text
explanations. To test the ability of models to reason about social norms across
cultures, we introduce the task of explainable social norm entailment, showing
that existing models under 3B parameters have significant room for improvement
in both automatic and human evaluation. Further analysis of cross-cultural norm
differences based on our dataset shows empirical alignment with the social
orientations framework, revealing several situational and descriptive nuances
in norms across these cultures.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:43:47 GMT""}]","2023-05-25"
"2305.14493","Junyu Mao","Junyu Mao and Stuart E. Middleton and Mahesan Niranjan","Prompt position really matters in few-shot and zero-shot NLU tasks",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Prompt-based models have made remarkable advancements in the fields of
zero-shot and few-shot learning, attracting a lot of attention from
researchers. Developing an effective prompt template plays a critical role.
However, prior studies have mainly focused on prompt vocabulary selection or
embedding initialization with the reserved prompt position fixed. In this
empirical study, we conduct the most comprehensive analysis to date of prompt
position option for natural language understanding tasks. Our findings quantify
the substantial impact prompt position has on model performance. We observe
that the prompt position used in prior studies is often sub-optimal for both
zero-shot and few-shot settings. These findings suggest prompt position
optimisation as an interesting research direction alongside the existing focus
on prompt engineering.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:45:45 GMT""}]","2023-05-25"
"2305.14494","Wang Ruijie","Xinyi Liu, Jinning Li, Dachun Sun, Ruijie Wang, Tarek Abdelzaher, Matt
  Brown, Anthony Barricelli, Matthias Kirchner, Arslan Basharat","Unsupervised Image Classification by Ideological Affiliation from
  User-Content Interaction Patterns","n Proc. PhoMemes (in conjunction with ICWSM), Limassol, Cyprus, June
  2023",,,,"cs.SI","http://creativecommons.org/licenses/by/4.0/","  The proliferation of political memes in modern information campaigns calls
for efficient solutions for image classification by ideological affiliation.
While significant advances have recently been made on text classification in
modern natural language processing literature, understanding the political
insinuation in imagery is less developed due to the hard nature of the problem.
Unlike text, where meaning arises from juxtaposition of tokens (words) within
some common linguistic structures, image semantics emerge from a much less
constrained process of fusion of visual concepts. Thus, training a model to
infer visual insinuation is possibly a more challenging problem. In this paper,
we explore an alternative unsupervised approach that, instead, infers
ideological affiliation from image propagation patterns on social media. The
approach is shown to improve the F1-score by over 0.15 (nearly 25%) over
previous unsupervised baselines, and then by another 0.05 (around 7%) in the
presence of a small amount of supervision.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:51:00 GMT""}]","2023-05-25"
"2305.14495","Fiorenzo Stoppa","F. Stoppa, R. Ruiz de Austri, P. Vreeswijk, S. Bhattacharyya, S.
  Caron, S. Bloemen, G. Zaharijas, G. Principe, V. Vodeb, E. Cator, and G.
  Nelemans","AutoSourceID-FeatureExtractor. Optical images analysis using a Two-Step
  MVE Network for feature estimation and uncertainty characterization",,,,,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Aims. In astronomy, machine learning has demonstrated success in various
tasks such as source localization, classification, anomaly detection, and
segmentation. However, feature regression remains an area with room for
improvement. We aim to design a network that can accurately estimate sources'
features and their uncertainties from single-band image cutouts, given the
approximated locations of the sources provided by the previously developed code
ASID-L or other external catalogues. Methods. The algorithm presented here,
AutoSourceID-FeatureExtractor (ASID-FE), uses single-band cutouts of 32x32
pixels around the localized sources to estimate flux, sub-pixel centre
coordinates, and their uncertainties. ASID-FE employs what we call a TS-MVE, a
Two-Step Mean Variance Estimator approach to first estimate the features and
then their uncertainties without the need for additional information, e.g.
Point Spread Function (PSF). Results. We show that ASID-FE, trained on
synthetic images from the MeerLICHT telescope, can predict more accurate
features with respect to similar codes like SourceExtractor and that the
two-step method can estimate well-calibrated uncertainties that are better
behaved compared to similar methods that use deep ensembles of simple MVE
networks. Finally, we evaluate the model on real images from the MeerLICHT
telescope and the Zwicky Transients Facility (ZTF) to test its Transfer
Learning abilities.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:53:12 GMT""}]","2023-05-25"
"2305.14496","Tobias Sutter","Arnab Ganguly, Tobias Sutter","Optimal Learning via Moderate Deviations Theory","35 pages, 3 figures",,,,"stat.ML math.OC math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a statistically optimal approach for learning a function
value using a confidence interval in a wide range of models, including general
non-parametric estimation of an expected loss described as a stochastic
programming problem or various SDE models. More precisely, we develop a
systematic construction of highly accurate confidence intervals by using a
moderate deviation principle-based approach. It is shown that the proposed
confidence intervals are statistically optimal in the sense that they satisfy
criteria regarding exponential accuracy, minimality, consistency,
mischaracterization probability, and eventual uniformly most accurate (UMA)
property. The confidence intervals suggested by this approach are expressed as
solutions to robust optimization problems, where the uncertainty is expressed
via the underlying moderate deviation rate function induced by the
data-generating process. We demonstrate that for many models these optimization
problems admit tractable reformulations as finite convex programs even when
they are infinite-dimensional.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:57:57 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 19:51:18 GMT""}]","2023-06-02"
"2305.14497","Zhiheng Xi","Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao, Tao Gui,
  Qi Zhang, Xuanjing Huang","Self-Polish: Enhance Reasoning in Large Language Models via Problem
  Refinement","Preprint",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prompting methods such as Chain-of-Thought (CoT) have shed new light on
enhancing the reasoning capabilities of large language models, and researchers
have extensively explored the generation process of rationales and answers.
However, they have overlooked the potential challenges posed by the poor
quality of reasoning problems, which may influence the reasoning performance
significantly. In this work, we propose Self-Polish (SP), a novel method that
facilitates the model's problem-solving process by prompting them to
progressively refine the given problems to be more comprehensible and solvable.
Specifically, the method teaches models to eliminate irrelevant information,
rearrange the logic structure and organize local conditions into new ones
parallelly. SP is orthogonal to all other prompting methods, making it
convenient to integrate with state-of-the-art techniques for further
improvement. We conduct thorough experiments on five benchmarks to illustrate
the effectiveness of the proposed method. For example, with Text-davinci-003,
our method boosts the performance of standard few-shot prompting by $8.0\%$ on
GSM8K and $17.8\%$ on MultiArith; it also improves the performance of CoT by
$6.0\%$ on GSM8K and $6.0\%$ on MathQA, respectively. Furthermore, our method
also showcases impressive performance on robustness evaluation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:58:30 GMT""}]","2023-05-25"
"2305.14498","Andrew Cameron","Andrew R. Cameron, Kate L. Fenwick, Sandra W. L. Cheng, Sacha Schwarz,
  Benjamin MacLellan, Philip J. Bustard, Duncan England, Benjamin Sussman,
  Kevin J. Resch","Ultrafast Measurement of Energy-Time Entanglement with an Optical Kerr
  Shutter","5 pages, 4 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent experimental progress in quantum optics has enabled measurement of
single photons on ultrafast timescales, beyond the resolution limit of single
photon detectors. The energy-time degree of freedom has emerged as a promising
avenue for quantum technologies, as entanglement between the frequency and
temporal properties of two photons can be fully explored and utilized. Here, we
implement optical Kerr shutters in single mode fibers to map out the
sub-picosecond correlations of energy-time entangled photon pairs. These
measurements, in addition to joint spectral measurements of the photon pair
state, are used to verify entanglement by means of the violation of a
time-bandwidth inequality.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:02:20 GMT""}]","2023-05-25"
"2305.14499","Livio Baldini Soares","Livio Baldini Soares, Daniel Gillick, Jeremy R. Cole, Tom Kwiatkowski","NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive
  Decoders",,,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  Neural document rerankers are extremely effective in terms of accuracy.
However, the best models require dedicated hardware for serving, which is
costly and often not feasible. To avoid this serving-time requirement, we
present a method of capturing up to 86% of the gains of a Transformer
cross-attention model with a lexicalized scoring function that only requires
10-6% of the Transformer's FLOPs per document and can be served using commodity
CPUs. When combined with a BM25 retriever, this approach matches the quality of
a state-of-the art dual encoder retriever, that still requires an accelerator
for query encoding. We introduce NAIL (Non-Autoregressive Indexing with
Language models) as a model architecture that is compatible with recent
encoder-decoder and decoder-only large language models, such as T5, GPT-3 and
PaLM. This model architecture can leverage existing pre-trained checkpoints and
can be fine-tuned for efficiently constructing document representations that do
not require neural processing of queries.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:09:52 GMT""}]","2023-05-25"
"2305.14500","Sukrit Venkatagiri","Jacob Thebault-Spieker, Sukrit Venkatagiri, Naomi Mine, Kurt Luther","Diverse Perspectives Can Mitigate Political Bias in Crowdsourced Content
  Moderation","Accepted to the 2023 ACM Conference on Fairness, Accountability, and
  Transparency (FAccT 2023). To cite please use the reference available at this
  URL: https://doi.org/10.1145/3593013.3594080",,"10.1145/3593013.3594080",,"cs.HC cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In recent years, social media companies have grappled with defining and
enforcing content moderation policies surrounding political content on their
platforms, due in part to concerns about political bias, disinformation, and
polarization. These policies have taken many forms, including disallowing
political advertising, limiting the reach of political topics, fact-checking
political claims, and enabling users to hide political content altogether.
However, implementing these policies requires human judgement to label
political content, and it is unclear how well human labelers perform at this
task, or whether biases affect this process. Therefore, in this study we
experimentally evaluate the feasibility and practicality of using crowd workers
to identify political content, and we uncover biases that make it difficult to
identify this content. Our results problematize crowds composed of seemingly
interchangeable workers, and provide preliminary evidence that aggregating
judgements from heterogeneous workers may help mitigate political biases. In
light of these findings, we identify strategies to achieving fairer labeling
outcomes, while also better supporting crowd workers at this task and
potentially mitigating biases.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:10:43 GMT""}]","2023-05-25"
"2305.14501","Carla Figueira de Morisson Faria","L. Cruz Rodriguez, T. Rook, B. B. Augstein, A. S. Maxwell, C. Figueira
  de Morisson Faria","Forward and hybrid path-integral methods in photoelectron holography:
  sub-barrier corrections, initial sampling and momentum mapping","23 pages revtex, 14 figures",,,,"physics.atom-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  We construct a strong-field path integral method with full Coulomb
distortion, in which electron orbits are forward propagated, and contrast the
results with those from a hybrid forward-boundary method. These methods are
applied to ultrafast photoelectron holography. In the forward method, we derive
a non-adiabatic ionization rate from the Coulomb quantum-orbit strong-field
approximation (CQSFA), which includes sub-barrier Coulomb corrections and is
used to weight the initial orbit ensemble. In the hybrid forward-boundary CQSFA
(H-CQSFA), we probe different initial sampling distributions, uniform and
otherwise, and their influence on photoelectron momentum distributions (PMDs).
We show that the sub-barrier Coulomb corrections broaden the resulting PMDs and
improve the agreement of the rate-based method with the H-CQSFA and
\textit{ab-initio} methods. Furthermore, in the hybrid approach, initial biased
sampling emphasizes rescattering ridges and interferences in high-energy
ranges, while an initial uniform sampling guarantees accurate modeling of the
holographic patterns near the ionization threshold or polarization axis. Our
results are explained using the initial to final momentum mapping for different
types of interfering trajectories.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:11:07 GMT""}]","2023-05-25"
"2305.14502","Alexander Scarlatos","Alexander Scarlatos and Andrew Lan","RetICL: Sequential Retrieval of In-Context Examples with Reinforcement
  Learning",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Many recent developments in large language models focus on prompting them to
perform specific tasks. One effective prompting method is in-context learning,
where the model performs a (possibly new) generation/prediction task given one
(or more) examples. Past work has shown that the choice of examples can make a
large impact on task performance. However, finding good examples is not
straightforward since the definition of a representative group of examples can
vary greatly depending on the task. While there are many existing methods for
selecting in-context examples, they generally score examples independently,
ignoring the dependency between them and the order in which they are provided
to the large language model. In this work, we propose Retrieval for In-Context
Learning (RetICL), a learnable method for modeling and optimally selecting
examples sequentially for in-context learning. We frame the problem of
sequential example selection as a Markov decision process, design an example
retriever model using an LSTM, and train it using proximal policy optimization
(PPO). We validate RetICL on math problem solving datasets and show that it
outperforms both heuristic and learnable baselines, and achieves
state-of-the-art accuracy on the TabMWP dataset. We also use case studies to
show that RetICL implicitly learns representations of math problem solving
strategies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:15:56 GMT""}]","2023-05-25"
"2305.14503","Heon Lee","Heon Lee","On the Instability of Fractional Reserve Banking",,,,,"econ.TH","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper develops a dynamic monetary model to study the (in)stability of
the fractional reserve banking system. The model shows that the fractional
reserve banking system can endanger stability in that equilibrium is more prone
to exhibit endogenous cyclic, chaotic, and stochastic dynamics under lower
reserve requirements, although it can increase consumption in the steady-state.
Introducing endogenous unsecured credit to the baseline model does not change
the main results. This paper also provides empirical evidence that is
consistent with the prediction of the model. The calibrated exercise suggests
that this channel could be another source of economic fluctuations.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:16:50 GMT""}]","2023-05-25"
"2305.14504","Peter Schiansky","Peter Schiansky, Julia Kalb, Esther Sztatecsny, Marie-Christine
  Roehsner, Tobias Guggemos, Alessandro Trenti, Mathieu Bozzio, Philip Walther","Demonstration of quantum-digital payments","Data and supplementary material will be made openly available upon
  publication",,,,"quant-ph cs.CR","http://creativecommons.org/licenses/by/4.0/","  Digital contactless payments have replaced physical banknotes in many aspects
of our daily lives. Similarly to banknotes, they are easy to use, unique,
tamper-resistant and untraceable, but additionally have to withstand attackers
and data breaches in the digital world. Current technology substitutes
customers' sensitive data by randomized tokens, and secures the uniqueness of
each digital purchase with a cryptographic function, called a cryptogram.
However, computationally powerful attacks violate the security of these
functions. Quantum technology, on the other hand, has the unique potential to
guarantee payment protection even in the presence of infinite computational
power. Here, we show how quantum light can secure daily digital payments in a
practical manner by generating inherently unforgeable quantum-cryptograms. We
implement the full scheme over an urban optical fiber link, and show its
robustness to noise and loss-dependent attacks. Unlike previously proposed
quantum-security protocols, our solution does not depend on challenging
long-term quantum storage or a network of trusted agents and authenticated
channels. The envisioned scenario is practical with near-term technology and
has the potential to herald a new era of real-world, quantum-enabled security.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:20:14 GMT""}]","2023-05-25"
"2305.14505","Simon Markfelder","Daniel W. Boutros, Simon Markfelder and Edriss S. Titi","Nonuniqueness of generalised weak solutions to the primitive and Prandtl
  equations","73 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a convex integration scheme for constructing nonunique weak
solutions to the hydrostatic Euler equations (also known as the inviscid
primitive equations of oceanic and atmospheric dynamics) in both two and three
dimensions. We also develop such a scheme for the construction of nonunique
weak solutions to the three-dimensional viscous primitive equations, as well as
the two-dimensional Prandtl equations.
  While in [D.W. Boutros, S. Markfelder and E.S. Titi, arXiv:2208.08334 (2022)]
the classical notion of weak solution to the hydrostatic Euler equations was
generalised, we introduce here a further generalisation. For such generalised
weak solutions we show the existence and nonuniqueness for a large class of
initial data. Moreover, we construct infinitely many examples of generalised
weak solutions which do not conserve energy. The barotropic and baroclinic
modes of solutions to the hydrostatic Euler equations (which are the average
and the fluctuation of the horizontal velocity in the $z$-coordinate,
respectively) that are constructed have different regularities.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:23:27 GMT""}]","2023-05-25"
"2305.14506","Y. Samuel Wang","Y. Samuel Wang, Mladen Kolar, Mathias Drton","Confidence Sets for Causal Orderings",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Causal discovery procedures aim to deduce causal relationships among
variables in a multivariate dataset. While various methods have been proposed
for estimating a single causal model or a single equivalence class of models,
less attention has been given to quantifying uncertainty in causal discovery in
terms of confidence statements. The primary challenge in causal discovery is
determining a causal ordering among the variables. Our research offers a
framework for constructing confidence sets of causal orderings that the data do
not rule out. Our methodology applies to structural equation models and is
based on a residual bootstrap procedure to test the goodness-of-fit of causal
orderings. We demonstrate the asymptotic validity of the confidence set
constructed using this goodness-of-fit test and explain how the confidence set
may be used to form sub/supersets of ancestral relationships as well as
confidence intervals for causal effects that incorporate model uncertainty.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:23:42 GMT""}]","2023-05-25"
"2305.14507","Shashank Sonkar","Shashank Sonkar, Richard G. Baraniuk","Deduction under Perturbed Evidence: Probing Student Simulation
  Capabilities of Large Language Models",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We explore whether Large Language Models (LLMs) are capable of logical
reasoning with distorted facts, which we call Deduction under Perturbed
Evidence (DUPE). DUPE presents a unique challenge to LLMs since they typically
rely on their parameters, which encode mostly accurate information, to reason
and make inferences. However, in DUPE, LLMs must reason over manipulated or
falsified evidence present in their prompts, which can result in false
conclusions that are valid only under the manipulated evidence. Our goal with
DUPE is to determine whether LLMs can arrive at these false conclusions and
identify whether the dominant factor influencing the deduction process is the
encoded data in the parameters or the manipulated evidence in the prompts. To
evaluate the DUPE capabilities of LLMs, we create a DUPEd version of the
StrategyQA dataset, where facts are manipulated to reverse the answer to the
question. Our findings show that even the most advanced GPT models struggle to
reason on manipulated facts - showcasing poor DUPE skills - with accuracy
dropping by 45% compared to the original dataset. We also investigate prompt
settings inspired from student simulation models, which mitigate the accuracy
drop to some extent. Our findings have practical implications for understanding
the performance of LLMs in real-world applications such as student simulation
models that involve reasoning over inaccurate information.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:26:03 GMT""}]","2023-05-25"
"2305.14508","Jesse Madnick","Gavin Ball, Jesse Madnick","A Spinorial Hopf Differential for Associative Submanifolds","10 pages",,,,"math.DG","http://creativecommons.org/licenses/by/4.0/","  Given a CMC surface in $R^3$, its traceless second fundamental form can be
viewed as a holomorphic section called the Hopf differential. By analogy, we
show that for an associative submanifold of a 7-manifold $M^7$ with
$G_2$-structure, its traceless second fundamental form can be viewed as a
twisted spinor. Moreover, if $M$ is $R^7$, $T^7$, or $S^7$ with the standard
$G_2$-structure, then this twisted spinor is harmonic. Consequently, every
non-totally-geodesic associative 3-fold in $R^7$, $T^7$, and $S^7$ admits
non-vanishing harmonic twisted spinors. Analogous results hold for special
Lagrangians in $R^6$ and $T^6$, coassociative 4-folds in $R^7$ and $T^7$, and
Cayley 4-folds in $R^8$ and $T^8$.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:26:32 GMT""}]","2023-05-25"
"2305.14509","Francesco Coti Zelati","M. C. Baglio, F. Coti Zelati, S. Campana, G. Busquet, P. D'Avanzo, S.
  Giarratana, M. Giroletti, F. Ambrosino, S. Crespi, A. Miraval Zanon, X. Hou,
  D. Li, J. Li, P. Wang, D. M. Russell, D. F. Torres, K. Alabarta, P. Casella,
  S. Covino, D. M. Bramich, D. de Martino, M. M\'endez, S. E. Motta, A.
  Papitto, P. Saikia, F. Vincentelli","Matter ejections behind the highs and lows of the transitional
  millisecond pulsar PSR J1023+0038","25 pages, 12 figures, 9 tables. Submitted to Astronomy and
  Astrophysics",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Transitional millisecond pulsars are an emerging class of sources linking
low-mass X-ray binaries to millisecond radio pulsars in binary systems. These
pulsars alternate between a radio pulsar state and an active low-luminosity
X-ray disc state. During the active state, these sources exhibit two distinct
emission modes (high and low) that alternate unpredictably, abruptly, and
incessantly. X-ray to optical pulsations are observed only during the high
mode. Knowledge of the root reason for this puzzling behaviour remains elusive.
This paper presents the results of the most extensive multi-wavelength campaign
ever conducted on the transitional pulsar prototype, PSR J1023+0038, covering
from radio to X-rays. The campaign was carried out over two nights in June
2021, and involved 12 different telescopes and instruments including
XMM-Newton, HST, VLT/FORS2 (in polarimetric mode), ALMA, VLA and FAST. By
modelling the broadband spectral energy distributions in both emission modes,
we show that the mode switches are caused by changes in the innermost region of
the accretion disc. These changes trigger the emission of discrete mass
ejections, which occur on top of a compact jet, as testified by the detection
of at least one short-duration millimetre flare with ALMA at the high-to-low
mode switch. A subsequent re-enshrouding of the pulsar completes the scenario
behind the mode switches.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:29:26 GMT""}]","2023-05-25"
"2305.14510","Vladislav Kochev D.","Vladislav D. Kochev, Seidali S. Seidov, Pavel D. Grigoriev","On the size of superconducting islands on the density-wave background in
  organic metals","13 pages, 3 figures",,,,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most high-$T_c$ superconductors are spatially inhomogeneous. Usually, this
heterogeneity originates from the interplay of various types of electronic
ordering. It affects various superconducting properties, such as the transition
temperature, magnetic upper critical field, critical current, etc. In this
paper we analyze the parameters of spatial phase segregation during the
first-order transition between superconductivity (SC) and a charge- or
spin-density wave state in quasi-one-dimensional metals with imperfect nesting,
typical to organic superconductors. An external pressure or another driving
parameter increases the transfer integrals in electron dispersion, which only
slightly affects SC but violates the Fermi-surface nesting and suppresses the
density wave (DW). At a critical pressure $P_{c}$ the transition from DW to SC
occurs. We estimate the characteristic size of SC islands during this phase
transition in organic metals in two ways. Using the Ginzburg-Landau expansion
we analytically obtain a lower bound for the size of SC domains. To estimate
more specific interval of possible size of the SC islands in (TMTSF)$_2$PF$_6$
samples we perform numerical calculations of the percolation probability via SC
domains and compare it with experimental resistivity data. This helps to
develop a consistent microscopic description of SC spatial heterogeneity in
various organic superconductors.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:30:09 GMT""}]","2023-05-25"
"2305.14511","Andr\'es Dar\'io Berm\'udez Manjarres","A. D. Berm\'udez Manjarres","Adiabatic driving and geometric phases in classical systems",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the concepts of adiabatic driving and geometric phases of classical
integrable systems under the Koopman-von Neumann formalism. In close relation
to what happens to a quantum state, a classical Koopman-von Neumann eigenstate
will acquire a geometric phase factor $exp\left\{ i\Phi\right\} $ after a
closed variation of the parameters $\lambda$ in its associated Hamiltonian. The
explicit form of $\Phi$ is then derived for integrable systems, and its
relation with the Hannay angles is shown. Additionally, we use quantum formulas
to write a classical adiabatic gauge potential that generates adiabatic unitary
flow between classical eigenstates, and we explicitly show the relationship
between the potential and the classical geometric phase.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:32:57 GMT""}]","2023-05-25"
"2305.14512","Jakob Gabriel","Jakob Gabriel, Joachim Deutscher","Robust Cooperative Output Regulation for Networks of Hyperbolic PIDE-ODE
  Systems","16 pages, 5 figures, accepted for publication in IEEE Transactions on
  Automatic Control",,"10.1109/TAC.2023.3272871",,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper the robust cooperative output regulation problem for
multi-agent systems (MAS) with general heterodirectional hyperbolic PIDE-ODE
agents is considered. This setup also covers networks of ODEs with arbitrarily
long input and output delays. The output of the agents can be defined at all
boundaries, in-domain and may depend on the ODE state, while disturbances act
on the agents in-domain, at the boundaries, the output and the ODE. The
communication network is described by a constant digraph and if its Laplacian
is reducible, then heterogeneous agents are permitted also in the nominal case.
The solution is based on the cooperative internal model principle, which
requires to include a diffusively driven internal model in the controller. The
corresponding state feedback regulator design starts with a local backstepping
stabilization of the coupled hyperbolic PIDE-ODE systems. It is shown that the
remaining simultaneous stabilization of the MAS can be traced back to the
simultaneous stabilization of the finite-dimensional cooperative internal
model. Solvability conditions in terms of the network topology and the agents
transfer behavior are presented. The new design method is applied to the
formation control of a platoon of uncertain heavy ropes carrying loads to
verify its applicability. Simulations confirm the synchronization performance
achieved by the resulting networked controller.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:37:37 GMT""}]","2023-05-25"
"2305.14513","Dominik Werner Wolf","Dominik Werner Wolf and Markus Ulrich and Alexander Braun","Windscreen Optical Quality for AI Algorithms: Refractive Power and MTF
  not Sufficient","Submitted to IEEE ITSC-2023",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Windscreen optical quality is an important aspect of any advanced driver
assistance system, and also for future autonomous driving, as today at least
some cameras of the sensor suite are situated behind the windscreen. Automotive
mass production processes require measurement systems that characterize the
optical quality of the windscreens in a meaningful way, which for modern
perception stacks implies meaningful for artificial intelligence (AI)
algorithms. The measured optical quality needs to be linked to the performance
of these algorithms, such that performance limits - and thus production
tolerance limits - can be defined. In this article we demonstrate that the main
metric established in the industry - refractive power - is fundamentally not
capable of capturing relevant optical properties of windscreens. Further, as
the industry is moving towards the modulation transfer function (MTF) as an
alternative, we mathematically show that this metric cannot be used on
windscreens alone, but that the windscreen forms a novel optical system
together with the optics of the camera system. Hence, the required goal of a
qualification system that is installed at the windscreen supplier and
independently measures the optical quality cannot be achieved using MTF. We
propose a novel concept to determine the optical quality of windscreens and to
use simulation to link this optical quality to the performance of AI
algorithms, which can hopefully lead to novel inspection systems.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:41:04 GMT""}]","2023-05-25"
"2305.14514","Mario Neves Junior","O. Abla and M. J. Neves","Effects of wave propagation in canonical Poisson gauge theory under an
  external magnetic field","18 pages, no figures",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The non-commutative electrodynamics based on the canonical Poisson gauge
theory is studied in this paper. We investigate the effects of the plane wave
solutions in the non-commutative field equations when the theory is submitted
to an external and uniform magnetic field. The energy-momentum tensor,
symmetric and gauge invariant, is obtained from the non-commutative field
equations. The plane wave solutions for the gauge potential yield the wave
equations in the momentum space, using the linear approximation on the
non-commutative parameter. Thereby, we obtain the dispersion relations of the
gauge theory in the presence of an external and uniform electromagnetic field.
We discuss the birefringence phenomenon that depends on the non-commutative
parameter, and using the bound of the PVLAS experiment for the vacuum magnetic
birefringence, we estimate a theoretical value for non-commutative parameter.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:41:09 GMT""}]","2023-05-25"
"2305.14515","Clare C. Yu","Dan Mickelsen, Herve M. Carruzzo, Susan N. Coppersmith and Clare C. Yu","Effects of Temperature Fluctuations on Charge Noise in Quantum Dot
  Qubits","8 pages, 5 figures",,,,"cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Silicon quantum dot qubits show great promise but suffer from charge noise
with a 1/f^\alpha spectrum, where f is frequency and \alpha \lesssim 1. It has
recently been proposed that 1/f^\alpha noise spectra can emerge from a few
thermally activated two-level fluctuators in the presence of sub-bath
temperature fluctuations associated with a two-dimensional electron gas
(2DEG)~\cite{Ahn2021}. We investigate this proposal by doing Monte Carlo
simulations of a single Ising spin in a bath with a fluctuating temperature. We
find that to obtain noise with a $1/f^\alpha$ spectrum with $alpha \lesssim 1
down to low frequencies, the duration of temperature fluctuations must be
comparable to the inverse of the lowest frequency at which the noise is
measured. This result is consistent with an analytic calculation in which the
fluctuator is a two-state system with dynamics governed by time-dependent
switching rates. In this case we find that the noise spectrum follows a
Lorentzian at frequencies lower than the inverse of the average duration of the
lowest switching rate. We then estimate relaxation times of thermal
fluctuations by considering thermal diffusion in an electron gas in a confined
geometry. We conclude that temperature fluctuations in a 2DEG sub-bath would
require an unphysically long duration to be consistent with experimental
measurements of 1/f-like charge noise in quantum dots at frequencies extending
well below 1 Hz.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:45:07 GMT""}]","2023-05-25"
"2305.14516","Taekyung Heo","Srinivas Sridharan, Taekyung Heo, Louis Feng, Zhaodong Wang, Matt
  Bergeron, Wenyin Fu, Shengbao Zheng, Brian Coutinho, Saeed Rashidi, Changhai
  Man, Tushar Krishna","Chakra: Advancing Performance Benchmarking and Co-design using
  Standardized Execution Traces",,,,,"cs.LG cs.DC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Benchmarking and co-design are essential for driving optimizations and
innovation around ML models, ML software, and next-generation hardware. Full
workload benchmarks, e.g. MLPerf, play an essential role in enabling fair
comparison across different software and hardware stacks especially once
systems are fully designed and deployed. However, the pace of AI innovation
demands a more agile methodology to benchmark creation and usage by simulators
and emulators for future system co-design. We propose Chakra, an open graph
schema for standardizing workload specification capturing key operations and
dependencies, also known as Execution Trace (ET). In addition, we propose a
complementary set of tools/capabilities to enable collection, generation, and
adoption of Chakra ETs by a wide range of simulators, emulators, and
benchmarks. For instance, we use generative AI models to learn latent
statistical properties across thousands of Chakra ETs and use these models to
synthesize Chakra ETs. These synthetic ETs can obfuscate key proprietary
information and also target future what-if scenarios. As an example, we
demonstrate an end-to-end proof-of-concept that converts PyTorch ETs to Chakra
ETs and uses this to drive an open-source training system simulator
(ASTRA-sim). Our end-goal is to build a vibrant industry-wide ecosystem of
agile benchmarks and tools to drive future AI system co-design.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:45:45 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 16:22:27 GMT""}]","2023-05-29"
"2305.14517","Oleksii Tsepa","Oleksii Tsepa, Bohdan Naida, Bo Wang","CongFu: Conditional Graph Fusion for Drug Synergy Prediction",,,,,"cs.LG cs.AI q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Drug synergy, characterized by the amplified combined effect of multiple
drugs, presents a critical phenomenon for optimizing therapeutic outcomes.
However, limited data on drug synergy, arising from the vast number of possible
drug combinations and computational costs, motivate the need for predictive
methods. In this work, we introduce CongFu, a novel Conditional Graph Fusion
Layer, designed to predict drug synergy. CongFu employs an attention mechanism
and a bottleneck to extract local graph contexts and conditionally fuse graph
data within a global context. Its modular architecture enables flexible
replacement of layer modules, including readouts and graph encoders,
facilitating customization for diverse applications. To evaluate the
performance of CongFu, we conduct comprehensive experiments on four datasets,
encompassing three distinct setups for drug synergy prediction. Remarkably,
CongFu achieves state-of-the-art results on 11 out of 12 benchmark datasets,
demonstrating its ability to capture intricate patterns of drug synergy.
Through extensive ablation studies, we validate the significance of individual
layer components, affirming their contributions to overall predictive
performance. By addressing the challenge of predicting drug synergy in untested
drug pairs, CongFu opens new avenues for optimizing drug combinations and
advancing personalized medicine.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:46:17 GMT""}]","2023-05-25"
"2305.14518","Michael Wolman","Alexander S. Kechris and Michael S. Wolman","An effective version of Nadkarni's Theorem","26 pages",,,,"math.LO math.DS","http://creativecommons.org/licenses/by/4.0/","  Nadkarni's Theorem asserts that for a countable Borel equivalence relation
(CBER) exactly one of the following holds: (1) It has an invariant Borel
probability measure or (2) it admits a Borel compression, i.e., a Borel
injection that maps each equivalence class to a proper subset of it. We prove
in this paper an effective version of Nadkarni's Theorem, which shows that if a
CBER is effectively Borel, then either alternative (1) above holds or else it
admits an effectively Borel compression. As a consequence if a CBER is
effectively Borel and admits a Borel compression, then it actually admits an
effectively Borel compression. We also prove an effective version of the
ergodic decomposition theorem. Finally a counterexample is given to show that
alternative (1) above does not admit an effective version.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:47:24 GMT""}]","2023-05-25"
"2305.14519","Xiaoshan Xu","Ahsan Ullah, Balamurugan Balasubramanian, Bibek Tiwari, Bharat Giri,
  David J. Sellmyer, Ralph Skomski, Xiaoshan Xu","Berry Curvature and Topological Hall Effect in Magnetic Nanoparticles",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analytical calculations and micromagnetic simulations are used to determine
the Berry curvature and topological Hall effect (THE) due to conduction
electrons in small ferromagnetic particles. Our focus is on small particles of
nonellipsoidal shapes, where noncoplanar spin structures yield a nonzero
topological Hall signal quantified by the skyrmion number Q. We consider two
mechanisms leading to noncoplanarity in aligned nanoparticles, namely
flower-state spin configurations due to stray fields near corners and edges,
and curling-type magnetostatic selfinteractions. In very small particles, the
reverse magnetic fields enhance Q due to the flower state until the reversal
occurs, whereas for particles with a radius greater than coherence radius Rcoh
the Q jumps to a larger value at the nucleation field representing the
transition from the flower state to the curling state. We calculate the
Skyrmion density (average Berry curvature) from these spin structures as a
function of particle size and applied magnetic field. Our simulation results
agree with analytical calculations for both flower state and flux closure
states. We showed the presence of Berry curvature in small particles as long as
the size of the particle is less than the single domain limit. Using magnetic
force microscopy (MFM), we also showed that in a nanodot of Co with a suitable
size, a magnetic vortex state with perpendicular (turned-up) magnetization at
the core is realized which can be manifested for Berry curvature and emergent
magnetic field in confined geometries for single domain state at room
temperature.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:48:15 GMT""}]","2023-05-25"
"2305.14520","Francesco Pecora","Francesco Pecora, Sergio Servidio, Yan Yang, William H. Matthaeus,
  Alexandros Chasapis, Antonella Greco, Daniel J. Gershman, Barbara L. Giles,
  and James L. Burch","Three-dimensional energy transfer in space plasma turbulence from
  multipoint measurement",,,,,"physics.space-ph astro-ph.IM astro-ph.SR physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  A novel multispacecraft technique applied to Magnetospheric Multiscale (MMS)
mission data collected in the Earth's magnetosheath enables evaluation of the
energy cascade rate solving the full Yaglom's equation in a turbulent space
plasma. The method differs from existing approaches in that (i) it is
inherently three-dimensional; (ii) it provides a statistically significant
number of estimates from a single data stream; and (iii) it allows for a direct
visualization of energy flux in turbulent plasmas. This new technique will
ultimately provide a realistic, comprehensive picture of the turbulence process
in plasmas.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:48:51 GMT""}]","2023-05-25"
"2305.14521","Yihao Xue","Yihao Xue, Ali Payani, Yu Yang, Baharan Mirzasoleiman","Eliminating Spurious Correlations from Pre-trained Models via Data
  Mixing",,,,,"cs.LG cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  Machine learning models pre-trained on large datasets have achieved
remarkable convergence and robustness properties. However, these models often
exploit spurious correlations between certain attributes and labels, which are
prevalent in the majority of examples within specific categories but are not
predictive of these categories in general. The learned spurious correlations
may persist even after fine-tuning on new data, which degrades models'
performance on examples that do not exhibit the spurious correlation. In this
work, we propose a simple and highly effective method to eliminate spurious
correlations from pre-trained models. The key idea of our method is to leverage
a small set of examples with spurious attributes, and balance the spurious
attributes across all classes via data mixing. We theoretically confirm the
effectiveness of our method, and empirically demonstrate its state-of-the-art
performance on various vision and NLP tasks, including eliminating spurious
correlations from pre-trained ResNet50 on Waterbirds and CelebA, adversarially
pre-trained ResNet50 on ImageNet, and BERT pre-trained on CivilComments.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:49:45 GMT""}]","2023-05-25"
"2305.14523","Artemis Tsantiri","A. Tsantiri (1, 2, 3), A. Palmisano-Kyle (1, 2, 3), A. Spyrou (1, 2,
  3), P. Mohr (4), H. C. Berg (1, 2, 3), P. A. DeYoung (5), A. C. Dombos (1, 2,
  3), P. Gastis (6, 3), E. C. Good (2, 3), C. M. Harris (1, 2, 3), S. N.
  Liddick (7, 2, 3), S. M. Lyons (1, 2, 3), O. Olivas-Gomez (8), G. Owens-Fryar
  (1, 2, 3), J. Pereira (1, 2, 3), A. L. Richard (1, 2, 3), A. Simon (8), M. K.
  Smith (1, 2) and R. G. T. Zegers (1, 2, 3) ((1) Department of Physics and
  Astronomy, Michigan State University, East Lansing, MI 48824, USA, (2)
  Facility for Rare Isotope Beams, Michigan State University, East Lansing, MI
  48824, USA, (3) Joint Institute for Nuclear Astrophysics - Center for the
  Evolution of the Elements, East Lansing, MI 48824, USA, (4) Institute for
  Nuclear Research (Atomki), H-4001 Debrecen, Hungary, (5) Physics Department,
  Hope College, Holland, MI 49423, USA, (6) Department of Physics, Central
  Michigan University, Mt Pleasant, MI 48859, USA, (7) Department of Chemistry,
  Michigan State University, East Lansing, MI 48824, USA, (8) Department of
  Physics, University of Notre Dame, Notre Dame, IN 46556, USA)","Cross Section Measurement of the $^{82}$Kr(p,$\gamma$)$^{83}$Rb Reaction
  in Inverse Kinematics",,"Phys. Rev. C 107, 035808 (2023)","10.1103/PhysRevC.107.035808",,"nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The total cross section of the $^{82}$Kr(p,$\gamma$)$^{83}$Rb reaction was
measured for the first time at effective center-of-mass energies between 2.4
and 3.0 MeV, within the relevant Gamow window for the astrophysical $\gamma$
process. The experiment took place at the National Superconducting Cyclotron
Laboratory at Michigan State University using the ReA facility. A $^{82}$Kr
beam was directed onto a hydrogen gas cell located at the center of the Summing
NaI(Tl) (SuN) detector. The obtained spectra were analyzed using the
$\gamma$-summing technique and the extracted cross section was compared to
standard statistical model calculations using the \textsc{non-smoker} and
\textsc{talys} codes. The comparison indicates that standard statistical model
calculations tend to overproduce the cross section of the
$^{82}$Kr(p,$\gamma$)$^{83}$Rb reaction relative to the experimentally measured
values. Furthermore, the experimental data was used to provide additional
constraints on the nuclear level density and $\gamma$-ray strength function
used in the statistical model calculations.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:56:42 GMT""}]","2023-05-25"
"2305.14524","Alexey Khartov","A. A. Khartov","Some criteria of rational infinite divisibility for distribution
  functions",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  We study distribution functions $F$ that have the property of rational
infinite divisibility: there exist some infinitely divisible distribution
functions $F_1$ and $F_2$ such that $F_1=F*F_2$. We study a class
$\boldsymbol{Q}$ of such distribution functions, which is a wide natural
extension of the well-known class of infinitely divisible distribution
functions. We are interested in general criteria of membership of
$\boldsymbol{Q}$. The obtained conditions are formulated in terms of
characteristic functions and they seem to be convenient for the application.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:56:42 GMT""}]","2023-05-25"
"2305.14525","Chen Chen","Chen Chen, Zhicheng Liu","The State of the Art in Creating Visualization Corpora for Automated
  Chart Analysis","To appear at EuroVis 2023",,"10.1111/cgf.14855",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a state-of-the-art report on visualization corpora in automated
chart analysis research. We survey 56 papers that created or used a
visualization corpus as the input of their research techniques or systems.
Based on a multi-level task taxonomy that identifies the goal, method, and
outputs of automated chart analysis, we examine the property space of existing
chart corpora along five dimensions: format, scope, collection method,
annotations, and diversity. Through the survey, we summarize common patterns
and practices of creating chart corpora, identify research gaps and
opportunities, and discuss the desired properties of future benchmark corpora
and the required tools to create them.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:59:15 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2023 21:19:40 GMT""}]","2023-06-06"
"2305.14526","Barry Sanders","Barry C Sanders","Perspective on electromagnetically induced transparency vs Autler-Townes
  splitting","4 pp","AVS Quantum Sci. 5, 024403 (2023)","10.1116/5.0149908",,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Electromagnetically induced transparency and Autler-Townes splitting are two
distinct yet related effects. These phenomena are relevant to quantum
technologies, including quantum memory, quantum switching, and quantum
transduction. Here, the similarities and differences between these phenomena
along historical and conceptual lines are discussed and their realizations on
various physical platforms including atomic gases, superconducting circuits,
and optomechanics are elaborated. In particular, the author clarifies two
approaches to assessing which phenomenon is observed based on a black-box
approach of modeling the output, given a particular input vs analyzing the
underpinning physics. Furthermore, the author highlights the ability to effect
a continuous transition between the two seemingly disparate phenomena.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:59:24 GMT""}]","2023-05-25"
"2305.14527","Alexander Kapitanov","Alexander Kapitanov, Karina Kvanchiani, Alexander Nagaev, Elizaveta
  Petrova","Slovo: Russian Sign Language Dataset","russian sign language recognition dataset, open-source",,,,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  One of the main challenges of the sign language recognition task is the
difficulty of collecting a suitable dataset due to the gap between deaf and
hearing society. In addition, the sign language in each country differs
significantly, which obliges the creation of new data for each of them. This
paper presents the Russian Sign Language (RSL) video dataset Slovo, produced
using crowdsourcing platforms. The dataset contains 20,000 FullHD recordings,
divided into 1,000 classes of RSL gestures received by 194 signers. We also
provide the entire dataset creation pipeline, from data collection to video
annotation, with the following demo application. Several neural networks are
trained and evaluated on the Slovo to demonstrate its teaching ability.
Proposed data and pre-trained models are publicly available.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:00:42 GMT""}]","2023-05-25"
"2305.14528","Alex Shtoff","Alex Shtoff and Elie Abboud and Rotem Stram and Oren Somekh","Basis Function Encoding of Numerical Features in Factorization Machines
  for Improved Accuracy",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Factorization machine (FM) variants are widely used for large scale real-time
content recommendation systems, since they offer an excellent balance between
model accuracy and low computational costs for training and inference. These
systems are trained on tabular data with both numerical and categorical
columns. Incorporating numerical columns poses a challenge, and they are
typically incorporated using a scalar transformation or binning, which can be
either learned or chosen a-priori. In this work, we provide a systematic and
theoretically-justified way to incorporate numerical features into FM variants
by encoding them into a vector of function values for a set of functions of
one's choice.
  We view factorization machines as approximators of segmentized functions,
namely, functions from a field's value to the real numbers, assuming the
remaining fields are assigned some given constants, which we refer to as the
segment. From this perspective, we show that our technique yields a model that
learns segmentized functions of the numerical feature spanned by the set of
functions of one's choice, namely, the spanning coefficients vary between
segments. Hence, to improve model accuracy we advocate the use of functions
known to have strong approximation power, and offer the B-Spline basis due to
its well-known approximation power, availability in software libraries, and
efficiency. Our technique preserves fast training and inference, and requires
only a small modification of the computational graph of an FM model. Therefore,
it is easy to incorporate into an existing system to improve its performance.
Finally, we back our claims with a set of experiments, including synthetic,
performance evaluation on several data-sets, and an A/B test on a real online
advertising system which shows improved performance.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:10:17 GMT""}]","2023-05-25"
"2305.14529","Chong Wang","Chong Wang, Xiu Gu, Shu Chen and Yu-xi Liu","Topological edge state transfer via topological adiabatic passage","arXiv admin note: substantial text overlap with arXiv:1711.06829",,,,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  The study of quantum state transfer has led to a variety of research efforts
utilizing quantum simulators. By exploiting the tunability of the qubit
frequency and qubit-qubit coupling, a superconducting qubit chain can simulate
various topological band models. In our study, we demonstrate that a spin-up
state can be transported along a topological qubit chain by modulating the
coupling strengths and the qubit frequencies. We here propose another more
straightforward approach to theoretically interpret this state transfer
process. We show that the Hilebert space of the qubit chain can be restricted
into the subspace of the only two edge states when investigating this process,
and the Hamiltonian can degenerate to a two-state Landau-Zener (LZ) model.
Therefore the state transfer process in this topological qubit chain is
equivalent to the same process through the adiabatic passage of the LZ model.
Further more, we show how to use this approach to generalize the state transfer
process from one-qubit Fock state to two-qubit Bell state.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:10:30 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 12:02:39 GMT""}]","2023-05-31"
"2305.14530","Sushant Saryal","Sushant Saryal and Deepak Dhar","Cusp singularities in the distribution of orientations of
  asymmetrically-pivoted hard discs on a lattice","8 pages, 8 figures",,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  We study a system of equal-sized circular discs each with an asymmetrically
placed pivot at a fixed distance from the center. The pivots are fixed at the
vertices of a regular triangular lattice. The discs can rotate freely about the
pivots, with the constraint that no discs can overlap with each other. Our
Monte Carlo simulations show that the one-point probability distribution of
orientations shows multiple cusp-like singularities. We determine the exact
positions and qualitative behavior of these singularities. In addition to these
geometrical singularities, we also find that the system shows order-disorder
transitions, with a disordered phase at large lattice spacings, a phase with
spontaneously broken orientational lattice symmetry at small lattice spacings,
and an intervening Berezinskii-Kosterlitz-Thouless phase in between.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:15:44 GMT""},{""version"":""v2"",""created"":""Sun, 28 May 2023 19:54:55 GMT""}]","2023-05-30"
"2305.14531","David Mohaisen","Mohammed Alqadhi, Ali Alkinoon, Saeed Salem, David Mohaisen","Understanding the Country-Level Security of Free Content Websites and
  their Hosting Infrastructure","10 pages, 2 figures, 4 tables",,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper examines free content websites (FCWs) and premium content websites
(PCWs) in different countries, comparing them to general websites. The focus is
on the distribution of malicious websites and their correlation with the
national cyber security index (NCSI), which measures a country's cyber security
maturity and its ability to deter the hosting of such malicious websites. By
analyzing a dataset comprising 1,562 FCWs and PCWs, along with Alexa's top
million websites dataset sample, we discovered that a majority of the
investigated websites are hosted in the United States. Interestingly, the
United States has a relatively low NCSI, mainly due to a lower score in privacy
policy development. Similar patterns were observed for other countries With
varying NCSI criteria. Furthermore, we present the distribution of various
categories of FCWs and PCWs across countries. We identify the top hosting
countries for each category and provide the percentage of discovered malicious
websites in those countries. Ultimately, the goal of this study is to identify
regional vulnerabilities in hosting FCWs and guide policy improvements at the
country level to mitigate potential cyber threats.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:31:02 GMT""}]","2023-05-25"
"2305.14532","Christophe De Beule","Christophe De Beule and E. J. Mele","Berry Curvature Spectroscopy from Bloch Oscillations","5 + 4 pages, 3 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We demonstrate that the Berry curvature of an isolated Bloch miniband in
two-dimensional superlattices can be probed by the dressed linear optical
response when a uniform static field is applied to the system. In particular,
when the static field is sufficiently strong such that full Bloch oscillations
occur before the crystal momentum relaxes to equilibrium, the optical response
of the dressed system becomes resonant at the Bloch frequencies. The latter are
in the THz regime when the superlattice periodicity is of the order of 10 nm.
Using a band-projected semiclassical theory, we define a dressed optical
conductivity and find that the height of the resonances in the dressed Hall
conductivity are proportional to the Fourier components of the Berry curvature.
We illustrate our results with a low-energy model on an effective honeycomb
lattice.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:33:06 GMT""}]","2023-05-25"
"2305.14533","Jo\~ao Sedoc","Huda Khayrallah and Zuhaib Akhtar and Edward Cohen and Jo\~ao Sedoc","How to Choose How to Choose Your Chatbot: A Massively Multi-System
  MultiReference Data Set for Dialog Metric Evaluation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We release MMSMR, a Massively Multi-System MultiReference dataset to enable
future work on metrics and evaluation for dialog. Automatic metrics for
dialogue evaluation should be robust proxies for human judgments; however, the
verification of robustness is currently far from satisfactory. To quantify the
robustness correlation and understand what is necessary in a test set, we
create and release an 8-reference dialog dataset by extending single-reference
evaluation sets and introduce this new language learning conversation dataset.
We then train 1750 systems and evaluate them on our novel test set and the
DailyDialog dataset. We release the novel test set, and model hyper parameters,
inference outputs, and metric scores for each system on a variety of datasets.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:33:43 GMT""}]","2023-05-25"
"2305.14534","Muhammad Umar Salman","Muhammad Umar Salman, Asif Hanif, Shady Shehata, Preslav Nakov","Detecting Propaganda Techniques in Code-Switched Social Media Text",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Propaganda is a form of communication intended to influence the opinions and
the mindset of the public to promote a particular agenda. With the rise of
social media, propaganda has spread rapidly, leading to the need for automatic
propaganda detection systems. Most work on propaganda detection has focused on
high-resource languages, such as English, and little effort has been made to
detect propaganda for low-resource languages. Yet, it is common to find a mix
of multiple languages in social media communication, a phenomenon known as
code-switching. Code-switching combines different languages within the same
text, which poses a challenge for automatic systems. With this in mind, here we
propose the novel task of detecting propaganda techniques in code-switched
text. To support this task, we create a corpus of 1,030 texts code-switching
between English and Roman Urdu, annotated with 20 propaganda techniques, which
we make publicly available. We perform a number of experiments contrasting
different experimental setups, and we find that it is important to model the
multilinguality directly (rather than using translation) as well as to use the
right fine-tuning strategy. The code and the dataset are publicly available at
https://github.com/mbzuai-nlp/propaganda-codeswitched-text
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:37:26 GMT""}]","2023-05-25"
"2305.14535","Kexin Huang","Kexin Huang, Ying Jin, Emmanuel Candes, Jure Leskovec","Uncertainty Quantification over Graph with Conformalized Graph Neural
  Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Neural Networks (GNNs) are powerful machine learning prediction models
on graph-structured data. However, GNNs lack rigorous uncertainty estimates,
limiting their reliable deployment in settings where the cost of errors is
significant. We propose conformalized GNN (CF-GNN), extending conformal
prediction (CP) to graph-based models for guaranteed uncertainty estimates.
Given an entity in the graph, CF-GNN produces a prediction set/interval that
provably contains the true label with pre-defined coverage probability (e.g.
90%). We establish a permutation invariance condition that enables the validity
of CP on graph data and provide an exact characterization of the test-time
coverage. Moreover, besides valid coverage, it is crucial to reduce the
prediction set size/interval length for practical use. We observe a key
connection between non-conformity scores and network structures, which
motivates us to develop a topology-aware output correction model that learns to
update the prediction and produces more efficient prediction sets/intervals.
Extensive experiments show that CF-GNN achieves any pre-defined target marginal
coverage while significantly reducing the prediction set/interval size by up to
74% over the baselines. It also empirically achieves satisfactory conditional
coverage over various raw and network features.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:38:23 GMT""}]","2023-05-25"
"2305.14536","Jakub Macina","Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Tanmay Sinha, Manu
  Kapur, Iryna Gurevych, Mrinmaya Sachan","MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties
  Grounded in Math Reasoning Problems","Jakub Macina, Nico Daheim, and Sankalan Pal Chowdhury contributed
  equally to this work. Code and dataset available:
  https://github.com/eth-nlped/mathdial",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Although automatic dialogue tutors hold great potential in making education
personalized and more accessible, research on such systems has been hampered by
a lack of sufficiently large and high-quality datasets. However, collecting
such datasets remains challenging, as recording tutoring sessions raises
privacy concerns and crowdsourcing leads to insufficient data quality. To
address this problem, we propose a framework to semi-synthetically generate
such dialogues by pairing real teachers with a large language model (LLM)
scaffolded to represent common student errors. In this paper, we describe our
ongoing efforts to use this framework to collect MathDial, a dataset of
currently ca. 1.5k tutoring dialogues grounded in multi-step math word
problems. We show that our dataset exhibits rich pedagogical properties,
focusing on guiding students using sense-making questions to let them explore
problems. Moreover, we outline that MathDial and its grounding annotations can
be used to finetune language models to be more effective tutors (and not just
solvers) and highlight remaining challenges that need to be addressed by the
research community. We will release our dataset publicly to foster research in
this socially important area of NLP.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:44:56 GMT""}]","2023-05-25"
"2305.14537","Christian Ikeokwu","Christian Borgs, Jennifer Chayes, Christian Ikeokwu, Ellen Vitercik","Disincentivizing Polarization in Social Networks",,,,,"cs.CY cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  On social networks, algorithmic personalization drives users into filter
bubbles where they rarely see content that deviates from their interests. We
present a model for content curation and personalization that avoids filter
bubbles, along with algorithmic guarantees and nearly matching lower bounds. In
our model, the platform interacts with $n$ users over $T$ timesteps, choosing
content for each user from $k$ categories. The platform receives stochastic
rewards as in a multi-arm bandit. To avoid filter bubbles, we draw on the
intuition that if some users are shown some category of content, then all users
should see at least a small amount of that content. We first analyze a naive
formalization of this intuition and show it has unintended consequences: it
leads to ``tyranny of the majority'' with the burden of diversification borne
disproportionately by those with minority interests. This leads us to our model
which distributes this burden more equitably. We require that the probability
any user is shown a particular type of content is at least $\gamma$ times the
average probability all users are shown that type of content. Full
personalization corresponds to $\gamma = 0$ and complete homogenization
corresponds to $\gamma = 1$; hence, $\gamma$ encodes a hard cap on the level of
personalization. We also analyze additional formulations where the platform can
exceed its cap but pays a penalty proportional to its constraint violation. We
provide algorithmic guarantees for optimizing recommendations subject to these
constraints. These include nearly matching upper and lower bounds for the
entire range of $\gamma \in [0,1]$ showing that the reward of a multi-agent
variant of UCB is nearly optimal. Using real-world preference data, we
empirically verify that under our model, users share the burden of
diversification with only minor utility loss under our constraints.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:47:31 GMT""}]","2023-05-25"
"2305.14538","Fr\'ed\'eric Odermatt","Fr\'ed\'eric Odermatt and B\'eni Egressy and Roger Wattenhofer","Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural
  Machine Translation","14 pages, 7 figures",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper presents a plug-and-play approach for translation with terminology
constraints. Terminology constraints are an important aspect of many modern
translation pipelines. In both specialized domains and newly emerging domains
(such as the COVID-19 pandemic), accurate translation of technical terms is
crucial. Recent approaches often train models to copy terminologies from the
input into the output sentence by feeding the target terminology along with the
input. But this requires expensive training whenever the underlying language
model is changed or the system should specialize to a new domain. We propose
Cascade Beam Search, a plug-and-play terminology-forcing approach that requires
no training. Cascade Beam Search has two parts: 1) logit manipulation to
increase the probability of target terminologies and 2) a cascading beam setup
based on grid beam search, where beams are grouped by the number of
terminologies they contain. We evaluate the performance of our approach by
competing against the top submissions of the WMT21 terminology translation
task. Our plug-and-play approach performs on par with the winning submissions
without using a domain-specific language model and with no additional training.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:48:02 GMT""}]","2023-05-25"
"2305.14539","Rebecca Martin","Rebecca G. Martin","Superorbital periods of Be/X-ray binaries driven by stellar spin
  precession","Accepted for publication in MNRAS Letters",,"10.1093/mnrasl/slad061",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superorbital periods are observed in the optical light curves of many
Be/X-ray binaries yet their origin has remained somewhat elusive. We suggest
that precession of the spin axis of the Be star can drive superorbital periods,
particularly for short orbital period binaries. We consider the short orbital
period ($P_{\rm orb}=16.6\,\rm day$) and highly eccentric ($e_{\rm b}=0.72$)
Be/X-ray binary A0538-66 that has a superorbital period of $421\,\rm day$.
First we show that the spin axis precession timescale is about twice the
observed superorbital period. Then, with hydrodynamic simulations we show that
the Be star decretion disc can remain locked to the equator of the precessing
Be star. At each periastron passage of the neutron star, material is accreted
into a disc around the neutron star. The neutron star disc nodally precesses on
the same timescale as the Be star disc and therefore both discs can contribute
to the observed superorbital period. For wider and less eccentric binary
systems, the Be star disc can have a larger radial extent and more complex
behaviour is expected as a result of disc warping and breaking.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:49:17 GMT""}]","2023-06-07"
"2305.14540","Philippe Laban","Philippe Laban, Wojciech Kry\'sci\'nski, Divyansh Agarwal, Alexander
  R. Fabbri, Caiming Xiong, Shafiq Joty, Chien-Sheng Wu","LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the recent appearance of LLMs in practical settings, having methods that
can effectively detect factual inconsistencies is crucial to reduce the
propagation of misinformation and improve trust in model outputs. When testing
on existing factual consistency benchmarks, we find that a few large language
models (LLMs) perform competitively on classification benchmarks for factual
inconsistency detection compared to traditional non-LLM methods. However, a
closer analysis reveals that most LLMs fail on more complex formulations of the
task and exposes issues with existing evaluation benchmarks, affecting
evaluation precision. To address this, we propose a new protocol for
inconsistency detection benchmark creation and implement it in a 10-domain
benchmark called SummEdits. This new benchmark is 20 times more cost-effective
per sample than previous benchmarks and highly reproducible, as we estimate
inter-annotator agreement at about 0.9. Most LLMs struggle on SummEdits, with
performance close to random chance. The best-performing model, GPT-4, is still
8\% below estimated human performance, highlighting the gaps in LLMs' ability
to reason about facts and detect inconsistencies when they occur.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:50:06 GMT""}]","2023-05-25"
"2305.14541","Eric Ruzomberka","Eric Ruzomberka and Yongkyu Jang and David J. Love and H. Vincent Poor","Adversarial Channels with O(1)-Bit Partial Feedback",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider point-to-point communication over $q$-ary adversarial channels
with partial noiseless feedback. In this setting, a sender Alice transmits $n$
symbols from a $q$-ary alphabet over a noisy forward channel to a receiver Bob,
while Bob sends feedback to Alice over a noiseless reverse channel. In the
forward channel, an adversary can inject both symbol errors and erasures up to
an error fraction $p \in [0,1]$ and erasure fraction $r \in [0,1]$,
respectively. In the reverse channel, Bob's feedback is partial such that he
can send at most $B(n) \geq 0$ bits during the communication session.
  As a case study on minimal partial feedback, we initiate the study of the
$O(1)$-bit feedback setting in which $B$ is $O(1)$ in $n$. As our main result,
we provide a tight characterization of zero-error capacity under $O(1)$-bit
feedback for all $q \geq 2$, $p \in [0,1]$ and $r \in [0,1]$, which we prove
this result via novel achievability and converse schemes inspired by recent
studies of causal adversarial channels without feedback. Perhaps surprisingly,
we show that $O(1)$-bits of feedback are sufficient to achieve the zero-error
capacity of the $q$-ary adversarial error channel with full feedback when the
error fraction $p$ is sufficiently small.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:51:38 GMT""}]","2023-05-25"
"2305.14542","Agustina Czenky","Agustina Czenky, William Gvozdjak, Julia Plavnik","Classification of low-rank odd-dimensional modular categories","Comments welcome!",,,"Hamburger Beitr. zur Mathematik Nr 942; ZMP-HH/23-8","math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that any odd-dimensional modular tensor category of rank at most 23
is pointed. We also show that an odd-dimensional modular tensor category of
rank 25 is either pointed, perfect, or equivalent to
$\text{Rep}(D^\omega(\mathbb Z_7\rtimes \mathbb Z_3))$. In addition, we prove
that odd-dimensional modular tensor categories of rank between $27$ and $49$
not congruent to $1$ modulo $8$ are either pointed or perfect. Finally, we give
partial classification results for ranks 33, 41 and 49.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:57:10 GMT""}]","2023-05-25"
"2305.14543","Yirui Liu","Yirui Liu, Xinghao Qiao, Yulong Pei, Liying Wang","DF2M: An Explainable Deep Bayesian Nonparametric Model for
  High-Dimensional Functional Time Series",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper, we present Deep Functional Factor Model (DF2M), a Bayesian
nonparametric model for analyzing high-dimensional functional time series. The
DF2M makes use of the Indian Buffet Process and the multi-task Gaussian Process
with a deep kernel function to capture non-Markovian and nonlinear temporal
dynamics. Unlike many black-box deep learning models, the DF2M provides an
explainable way to use neural networks by constructing a factor model and
incorporating deep neural networks within the kernel function. Additionally, we
develop a computationally efficient variational inference algorithm for
inferring the DF2M. Empirical results from four real-world datasets demonstrate
that the DF2M offers better explainability and superior predictive accuracy
compared to conventional deep learning models for high-dimensional functional
time series.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:59:13 GMT""}]","2023-05-25"
"2305.14544","Shengwen Gan","Shengwen Gan","Hausdorff dimension of unions of $k$-planes","14 pages",,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a conjecture of H\'era on the dimension of unions of $k$-planes. Let
$0<k \le d<n$ be integers, and $\beta\in[0,k+1)$. If $\mathcal{V}\subset
A(k,n)$, with $\text{dim}(\mathcal{V})=(k+1)(d-k)+\beta$, then
$\text{dim}(\bigcup_{V\in\mathcal{V}}V)\ge d+\min\{1,\beta\}$. The proof
combines a recent idea of Zahl and the Brascamp-Lieb inequality.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:00:16 GMT""}]","2023-05-25"
"2305.14545","Nicol\'as Matte Bon","Nicol\'as Matte Bon, Volodymyr Nekrashevych and Tianyi Zheng","Liouville property for groups and conformal dimension","36 pages, 5 figures",,,,"math.GR math.DS math.PR","http://creativecommons.org/licenses/by/4.0/","  We study the (Alfhors-regular) conformal dimension of the limit space of a
contracting self-similar group and its connection to random walk entropy on the
group. We show that if $G$ is a finitely generated contracting group, and if
the conformal dimension of its limit space is strictly less than 2, then every
symmetric random walk with finite second moment on $G$ has the Liouville
property. As a corollary, every such group is amenable. This criterion applies
to all previously known examples of amenable contracting groups, and to many
new ones. In particular, it implies that for every post-critically finite
complex rational function $f$ whose Julia set is not the whole sphere, the
iterated monodromy group of $f$ is amenable.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:01:33 GMT""}]","2023-05-25"
"2305.14546","Vamsikrishna Chemudupati","Vamsikrishna Chemudupati, Marzieh Tahaei, Heitor Guimaraes, Arthur
  Pimentel, Anderson Avila, Mehdi Rezagholizadeh, Boxing Chen, Tiago Falk","On the Transferability of Whisper-based Representations for
  ""In-the-Wild"" Cross-Task Downstream Speech Applications",,,,,"eess.AS cs.CL cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large self-supervised pre-trained speech models have achieved remarkable
success across various speech-processing tasks. The self-supervised training of
these models leads to universal speech representations that can be used for
different downstream tasks, ranging from automatic speech recognition (ASR) to
speaker identification. Recently, Whisper, a transformer-based model was
proposed and trained on large amount of weakly supervised data for ASR; it
outperformed several state-of-the-art self-supervised models. Given the
superiority of Whisper for ASR, in this paper we explore the transferability of
the representation for four other speech tasks in SUPERB benchmark. Moreover,
we explore the robustness of Whisper representation for ``in the wild'' tasks
where speech is corrupted by environment noise and room reverberation.
Experimental results show Whisper achieves promising results across tasks and
environmental conditions, thus showing potential for cross-task real-world
deployment.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:02:55 GMT""}]","2023-05-25"
"2305.14547","Yuting Wu","Yuting Wu, Qiwen Wang, Ziyu Wang, Xinxin Wang, Buvna Ayyagari,
  Siddarth Krishnan, Michael Chudzik and Wei D. Lu","Bulk-Switching Memristor-based Compute-In-Memory Module for Deep Neural
  Network Training",,,,,"cs.AR cs.ET cs.LG","http://creativecommons.org/licenses/by/4.0/","  The need for deep neural network (DNN) models with higher performance and
better functionality leads to the proliferation of very large models. Model
training, however, requires intensive computation time and energy.
Memristor-based compute-in-memory (CIM) modules can perform vector-matrix
multiplication (VMM) in situ and in parallel, and have shown great promises in
DNN inference applications. However, CIM-based model training faces challenges
due to non-linear weight updates, device variations, and low-precision in
analog computing circuits. In this work, we experimentally implement a
mixed-precision training scheme to mitigate these effects using a
bulk-switching memristor CIM module. Lowprecision CIM modules are used to
accelerate the expensive VMM operations, with high precision weight updates
accumulated in digital units. Memristor devices are only changed when the
accumulated weight update value exceeds a pre-defined threshold. The proposed
scheme is implemented with a system-on-chip (SoC) of fully integrated analog
CIM modules and digital sub-systems, showing fast convergence of LeNet training
to 97.73%. The efficacy of training larger models is evaluated using realistic
hardware parameters and shows that that analog CIM modules can enable efficient
mix-precision DNN training with accuracy comparable to full-precision software
trained models. Additionally, models trained on chip are inherently robust to
hardware variations, allowing direct mapping to CIM inference chips without
additional re-training.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:03:08 GMT""}]","2023-05-25"
"2305.14548","Qi Zeng","Hou Pong Chan, Qi Zeng, Heng Ji","Interpretable Automatic Fine-grained Inconsistency Detection in Text
  Summarization","Accepted by ACL Findings 2023. Code and data are available at
  https://github.com/kenchan0226/fineGrainedFact",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing factual consistency evaluation approaches for text summarization
provide binary predictions and limited insights into the weakness of
summarization systems. Therefore, we propose the task of fine-grained
inconsistency detection, the goal of which is to predict the fine-grained types
of factual errors in a summary. Motivated by how humans inspect factual
inconsistency in summaries, we propose an interpretable fine-grained
inconsistency detection model, FineGrainFact, which explicitly represents the
facts in the documents and summaries with semantic frames extracted by semantic
role labeling, and highlights the related semantic frames to predict
inconsistency. The highlighted semantic frames help verify predicted error
types and correct inconsistent summaries. Experiment results demonstrate that
our model outperforms strong baselines and provides evidence to support or
refute the summary.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:11:47 GMT""}]","2023-05-25"
"2305.14549","Yinghao Li","Yinghao Li, Colin Lockard, Prashant Shiralkar, Chao Zhang","Extracting Shopping Interest-Related Product Types from the Web",,,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Recommending a diversity of product types (PTs) is important for a good
shopping experience when customers are looking for products around their
high-level shopping interests (SIs) such as hiking. However, the SI-PT
connection is typically absent in e-commerce product catalogs and expensive to
construct manually due to the volume of potential SIs, which prevents us from
establishing a recommender with easily accessible knowledge systems. To
establish such connections, we propose to extract PTs from the Web pages
containing hand-crafted PT recommendations for SIs. The extraction task is
formulated as binary HTML node classification given the general observation
that an HTML node in our target Web pages can present one and only one PT
phrase. Accordingly, we introduce TrENC, which stands for Tree-Transformer
Encoders for Node Classification. It improves the inter-node dependency
modeling with modified attention mechanisms that preserve the long-term sibling
and ancestor-descendant relations. TrENC also injects SI into node features for
better semantic representation. Trained on pages regarding limited SIs, TrEnc
is ready to be applied to other unobserved interests. Experiments on our
manually constructed dataset, WebPT, show that TrENC outperforms the best
baseline model by 2.37 F1 points in the zero-shot setup. The performance
indicates the feasibility of constructing SI-PT relations and using them to
power downstream applications such as search and recommendation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:18:01 GMT""}]","2023-05-25"
"2305.14550","Prajjwal Bhargava","Prajjwal Bhargava, Rohan Chitnis, Alborz Geramifard, Shagun Sodhani,
  Amy Zhang","Sequence Modeling is a Robust Contender for Offline Reinforcement
  Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Offline reinforcement learning (RL) allows agents to learn effective,
return-maximizing policies from a static dataset. Three major paradigms for
offline RL are Q-Learning, Imitation Learning, and Sequence Modeling. A key
open question is: which paradigm is preferred under what conditions? We study
this question empirically by exploring the performance of representative
algorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), and
Decision Transformer (DT) -- across the commonly used D4RL and Robomimic
benchmarks. We design targeted experiments to understand their behavior
concerning data suboptimality and task complexity. Our key findings are: (1)
Sequence Modeling requires more data than Q-Learning to learn competitive
policies but is more robust; (2) Sequence Modeling is a substantially better
choice than both Q-Learning and Imitation Learning in sparse-reward and
low-quality data settings; and (3) Sequence Modeling and Imitation Learning are
preferable as task horizon increases, or when data is obtained from human
demonstrators. Based on the overall strength of Sequence Modeling, we also
investigate architectural choices and scaling trends for DT on Atari and D4RL
and make design recommendations. We find that scaling the amount of data for DT
by 5x gives a 2.5x average score improvement on Atari.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:19:14 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 17:48:31 GMT""}]","2023-05-29"
"2305.14551","Andrey Palaev","Andrey Palaev and Rustam A. Lukmanov and Adil Khan","Exploring Semantic Variations in GAN Latent Spaces via Matrix
  Factorization","Accepted at ICLR 2023 Tiny Papers",,,,"cs.CV cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Controlled data generation with GANs is desirable but challenging due to the
nonlinearity and high dimensionality of their latent spaces. In this work, we
explore image manipulations learned by GANSpace, a state-of-the-art method
based on PCA. Through quantitative and qualitative assessments we show: (a)
GANSpace produces a wide range of high-quality image manipulations, but they
can be highly entangled, limiting potential use cases; (b) Replacing PCA with
ICA improves the quality and disentanglement of manipulations; (c) The quality
of the generated images can be sensitive to the size of GANs, but regardless of
their complexity, fundamental controlling directions can be observed in their
latent spaces.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:23:37 GMT""}]","2023-05-25"
"2305.14552","Tianyi Li","Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Javad Hosseini, Mark
  Johnson, Mark Steedman","Sources of Hallucination by Large Language Models on Inference Tasks",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Large Language Models (LLMs) are claimed to be capable of Natural Language
Inference (NLI), necessary for applied tasks like question answering and
summarization, yet this capability is under-explored. We present a series of
behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which
probe their behavior using controlled experiments. We establish two factors
which predict much of their performance, and propose that these are major
sources of hallucination in generative LLM. First, the most influential factor
is memorization of the training data. We show that models falsely label NLI
test samples as entailing when the hypothesis is attested in the training text,
regardless of the premise. We further show that named entity IDs are used as
""indices"" to access the memorized data. Second, we show that LLMs exploit a
further corpus-based heuristic using the relative frequencies of words. We show
that LLMs score significantly worse on NLI test samples which do not conform to
these factors than those which do; we also discuss a tension between the two
factors, and a performance trade-off.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:24:44 GMT""}]","2023-05-25"
"2305.14553","Andrew Lohn","Micah Musser, Andrew Lohn, James X. Dempsey, Jonathan Spring, Ram
  Shankar Siva Kumar, Brenda Leong, Christina Liaghati, Cindy Martinez, Crystal
  D. Grant, Daniel Rohrer, Heather Frase, Jonathan Elliott, John Bansemer,
  Mikel Rodriguez, Mitt Regan, Rumman Chowdhury, Stefan Hermanek","Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and
  Legal Implications",,,"10.51593/2022CA003",,"cs.CR cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  In July 2022, the Center for Security and Emerging Technology (CSET) at
Georgetown University and the Program on Geopolitics, Technology, and
Governance at the Stanford Cyber Policy Center convened a workshop of experts
to examine the relationship between vulnerabilities in artificial intelligence
systems and more traditional types of software vulnerabilities. Topics
discussed included the extent to which AI vulnerabilities can be handled under
standard cybersecurity processes, the barriers currently preventing the
accurate sharing of information about AI vulnerabilities, legal issues
associated with adversarial attacks on AI systems, and potential areas where
government support could improve AI vulnerability management and mitigation.
  This report is meant to accomplish two things. First, it provides a
high-level discussion of AI vulnerabilities, including the ways in which they
are disanalogous to other types of vulnerabilities, and the current state of
affairs regarding information sharing and legal oversight of AI
vulnerabilities. Second, it attempts to articulate broad recommendations as
endorsed by the majority of participants at the workshop.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:27:53 GMT""}]","2023-05-25"
"2305.14554","Anand Puthirath Balan","Lucas M. Sassi, Sathvik Ajay Iyengar, Anand B. Puthirath, Yuefei
  Huang, Xingfu Li, Tanguy Terlier, Ali Mojibpour, Ana Paula C. Teixeira,
  Palash Bharadwaj, Chandra Sekhar Tiwary, Robert Vajtai, Saikat Talapatra,
  Boris Yakobson and Pulickel M. Ajayan","Bottom-up Integration of TMDCs with Pre-Patterned Device Architectures
  via Transfer-free Chemical Vapor Deposition","32 pages, 5 Figures",,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional (2D) transition metal dichalcogenides (TMDCs) remain a topic
of immense interest. Specifically, given their low operational switching costs,
they find many niche applications in new computing architectures with the
promise of continued miniaturization. However, challenges lie in Back End of
Line (BEOL) integration temperature and time compliance regarding current
requirements for crystal growth. Additionally, deleterious and time-consuming
transfer processes and multiple steps involved in channel/contact engineering
can cripple device performance. This work demonstrates kinetics-governed
in-situ growth regimes (surface or edge growth from gold) of WSe2 and provides
a mechanistic understanding of these regimes via energetics across various
material interfaces. As a proof-of-concept, field effect transistors (FET) with
an in-situ grown WSe2 channel across Au contacts are fabricated, demonstrating
a 2D semiconductor transistor via a transfer-free method within the 450-600 C
2h-time window requirement BEOL integration. We leverage directional edge
growth to fabricate contacts with robust thickness-dependent Schottky-to-Ohmic
behavior. By transitioning between Au and SiO2 growth substrates in situ, this
work achieves strain-induced subthreshold swing of 140 mV/decade, relatively
high mobility of 107 +- 19 cm2V-1s-1, and robust ON/OFF ratios 10^6 in the
fabricated FETs.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:28:43 GMT""}]","2023-05-25"
"2305.14555","Zhijing Jin","Yuxin Ren, Qipeng Guo, Zhijing Jin, Shauli Ravfogel, Mrinmaya Sachan,
  Bernhard Sch\""olkopf, Ryan Cotterell","All Roads Lead to Rome? Exploring the Invariance of Transformers'
  Representations",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Transformer models bring propelling advances in various NLP tasks, thus
inducing lots of interpretability research on the learned representations of
the models. However, we raise a fundamental question regarding the reliability
of the representations. Specifically, we investigate whether transformers learn
essentially isomorphic representation spaces, or those that are sensitive to
the random seeds in their pretraining process. In this work, we formulate the
Bijection Hypothesis, which suggests the use of bijective methods to align
different models' representation spaces. We propose a model based on invertible
neural networks, BERT-INN, to learn the bijection more effectively than other
existing bijective methods such as the canonical correlation analysis (CCA). We
show the advantage of BERT-INN both theoretically and through extensive
experiments, and apply it to align the reproduced BERT embeddings to draw
insights that are meaningful to the interpretability research. Our code is at
https://github.com/twinkle0331/BERT-similarity.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:30:43 GMT""}]","2023-05-25"
"2305.14556","Tiziano Labruna","Tiziano Labruna, Sofia Brenna, Andrea Zaninello, Bernardo Magnini","Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented
  Dialogues and Annotations",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Large pre-trained language models have exhibited unprecedented capabilities
in producing high-quality text via prompting techniques. This fact introduces
new possibilities for data collection and annotation, particularly in
situations where such data is scarce, complex to gather, expensive, or even
sensitive. In this paper, we explore the potential of these models to generate
and annotate goal-oriented dialogues, and conduct an in-depth analysis to
evaluate their quality. Our experiments employ ChatGPT, and encompass three
categories of goal-oriented dialogues (task-oriented, collaborative, and
explanatory), two generation modes (interactive and one-shot), and two
languages (English and Italian). Based on extensive human-based evaluations, we
demonstrate that the quality of generated dialogues and annotations is on par
with those generated by humans.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:31:01 GMT""}]","2023-05-25"
"2305.14557","Ryan Lau","Ryan M. Lau, Jason Wang, Matthew J. Hankins, Thayne Currie, Vincent
  Deo, Izumi Endo, Olivier Guyon, Yinuo Han, Anthony P. Jones, Nemanja
  Jovanovic, Julien Lozi, Anthony F. J. Moffat, Takashi Onaka, Garreth Ruane,
  Andreas A. C. Sander, Samaporn Tinyanont, Peter G. Tuthill, Gerd Weigelt,
  Peredur M. Williams, and Sebastien Vievard","From Dust to Nanodust: Resolving Circumstellar Dust from the
  Colliding-Wind Binary Wolf-Rayet (WR) 140","21 pages, 8 figures, Accepted for publication in ApJ",,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Wolf-Rayet (WR) 140 is the archetypal periodic dust-forming colliding-wind
binary that hosts a carbon-rich WR (WC) star and an O-star companion with an
orbital period of 7.93 years and an orbital eccentricity of 0.9. Throughout the
past several decades, multiple dust-formation episodes from WR 140 have been
observed that are linked to the binary orbit and occur near the time of
periastron passage. Given its predictable dust-formation episodes, WR 140
presents an ideal astrophysical laboratory for investigating the formation and
evolution of dust in the hostile environment around a massive binary system. In
this paper, we present near- and mid-infrared (IR) spectroscopic and imaging
observations of WR 140 with Subaru/SCExAO+CHARIS, Keck/NIRC2+PyWFS, and
Subaru/COMICS taken between 2020 June and Sept that resolve the circumstellar
dust emission linked to its most recent dust-formation episode in 2016 Dec. Our
spectral energy distribution (SED) analysis of WR 140's resolved circumstellar
dust emission reveals the presence of a hot ($T_\mathrm{d}\sim1000$ K) near-IR
dust component that is co-spatial with the previously known and cooler
($T_\mathrm{d}\sim500$ K) mid-IR dust component composed of $300-500$
{\AA}-sized dust grains. We attribute the hot near-IR dust emission to the
presence of nano-sized (""nanodust"") grains and suggest they were formed from
grain-grain collisions or the rotational disruption of the larger grain size
population by radiative torques in the strong radiation field from the central
binary. Lastly, we speculate on the astrophysical implications of nanodust
formation around colliding-wind WC binaries, which may present an early source
of carbonaceous nanodust in the interstellar medium.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:32:32 GMT""}]","2023-05-25"
"2305.14558","Vidushi Adlakha","Vidushi Adlakha and Eric Kuo","Statistical causal inference methods for observational research in PER:
  a primer",,,,,"stat.ME physics.ed-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent critiques of Physics Education Research (PER) studies have revoiced
the critical issues when drawing causal inferences from observational data
where no intervention is present. In response to a call for a ""causal reasoning
primer"", this paper discusses some of the fundamental issues underlying
statistical causal inference. In reviewing these issues, we discuss
well-established causal inference methods commonly applied in other fields and
discuss their application to PER. Using simulated data sets, we illustrate (i)
why analysis for causal inference should control for confounders but not
control for mediators and colliders and (ii) that multiple proposed causal
models can fit a highly correlated data set. Finally, we discuss how these
causal inference methods can be used to represent and explain existing issues
in quantitative PER. Throughout, we discuss a central issue: quantitative
results from observational studies cannot support a researcher's proposed
causal model over other alternative models. To address this issue, we propose
an explicit role for observational studies in PER that draw statistical causal
inferences: proposing future intervention studies and predicting their
outcomes. Mirroring a broader connection between theoretical motivating
experiments in physics, observational studies in PER can make quantitative
predictions of the causal effects of interventions, and future intervention
studies can test those predictions directly.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:33:44 GMT""}]","2023-05-25"
"2305.14559","Klaudiusz Czudek","Klaudiusz Czudek","Mixing of generic simple symmetric random walk on the circle","19 pages, no figures",,,,"math.PR math.DS","http://creativecommons.org/licenses/by/4.0/","  Fix an irrational number $\alpha$ and a smooth, positive function
$\mathfrak{p}$ on the circle. If a particle is placed at a point $x\in \mathbb
R/\mathbb Z$, then in the next step it jumps to $x+\alpha$ with probability
$\mathfrak{p}(x)$ and to $x-\alpha$ with probability $1-\mathfrak{p}(x)$. Sinai
proved that if $\mathfrak{p}$ is asymmetric (in certain sense) or
$\mathfrak{p}$ is symmetric and $\alpha$ is Diophantine then this random walk
is mixing. Here we show it is mixing for every irrational frequency and generic
symmetric absolutely continuous $\mathfrak{p}$. This can be rephrased as mixing
of environment viewed from a particle. This partially answers a question posed
by Dolgopyat, Fayad and Saprykina in 2019.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:43:19 GMT""}]","2023-05-25"
"2305.14560","Margarite LaBorde","Margarite L. LaBorde","A Menagerie of Symmetry Testing Quantum Algorithms","PhD Dissertation, Louisiana State University (2023). 188 pages, 27
  figures",,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis aims to establish notions of symmetry for quantum states and
channels as well as describe algorithms to test for these properties on quantum
computers. Ideally, the work will serve as a self-contained overview of the
subject. We begin by establishing the necessary mathematical background. We
show how to generate a notion of symmetry from a discrete, finite group and how
this generalizes to a continuous group. We then use these notions to
investigate Hamiltonian symmetries. We propose quantum algorithms capable of
testing whether a Hamiltonian exhibits symmetry with respect to a group and
show that this algorithm is DQC1-Complete. We next discuss tests of symmetry
for quantum states. We prove that the acceptance probability of each algorithm
is equal to the maximum symmetric fidelity of the state being tested and
establish various generalizations of the resource theory of asymmetry. In the
next chapter, we show that the analytical form of the acceptance probability of
such a test is given by the cycle index polynomial of the symmetric group
$S_k$. We derive a family of quantum separability tests, each of which is
generated by a finite group; for all such algorithms, we show that the
acceptance probability is determined by the cycle index polynomial of the
group. Finally, we produce and analyze explicit circuit constructions for these
tests, showing that the tests corresponding to the symmetric and cyclic groups
can be executed with $O(k^2)$ and $O(k\log(k))$ controlled-SWAP gates,
respectively, where $k$ is the number of copies of the state. Finally, we
include additional results not previously published; specifically, we give a
test for symmetry of a quantum state using density matrix exponentiation, a
further result of Hamiltonian symmetry measurements when using Abelian groups,
and an alternate Hamiltonian symmetry test construction for a block-encoded
Hamiltonian.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:55:02 GMT""}]","2023-05-25"
"2305.14561","Yifan Qin","Yifan Qin, Zheyu Yan, Wujie Wen, Xiaobo Sharon Hu and Yiyu Shi","Negative Feedback Training: A Novel Concept to Improve Robustness of
  NVCiM DNN Accelerators",,,,,"cs.LG cs.AI cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compute-in-Memory (CiM) utilizing non-volatile memory (NVM) devices presents
a highly promising and efficient approach for accelerating deep neural networks
(DNNs). By concurrently storing network weights and performing matrix
operations within the same crossbar structure, CiM accelerators offer DNN
inference acceleration with minimal area requirements and exceptional energy
efficiency. However, the stochasticity and intrinsic variations of NVM devices
often lead to performance degradation, such as reduced classification accuracy,
compared to expected outcomes. Although several methods have been proposed to
mitigate device variation and enhance robustness, most of them rely on overall
modulation and lack constraints on the training process. Drawing inspiration
from the negative feedback mechanism, we introduce a novel training approach
that uses a multi-exit mechanism as negative feedback to enhance the
performance of DNN models in the presence of device variation. Our negative
feedback training method surpasses state-of-the-art techniques by achieving an
impressive improvement of up to 12.49% in addressing DNN robustness against
device variation.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:56:26 GMT""}]","2023-05-25"
"2305.14562","Yi Hu","Yi Hu, Chaoran Zhang, Edward Andert, Harshul Singh, Aviral
  Shrivastava, James Laudon, Yanqi Zhou, Bob Iannucci, Carlee Joe-Wong","GiPH: Generalizable Placement Learning for Adaptive Heterogeneous
  Computing","to be published in Proceedings of Machine Learning and Systems 5
  (MLSys 2023)",,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Careful placement of a computational application within a target device
cluster is critical for achieving low application completion time. The problem
is challenging due to its NP-hardness and combinatorial nature. In recent
years, learning-based approaches have been proposed to learn a placement policy
that can be applied to unseen applications, motivated by the problem of placing
a neural network across cloud servers. These approaches, however, generally
assume the device cluster is fixed, which is not the case in mobile or edge
computing settings, where heterogeneous devices move in and out of range for a
particular application. We propose a new learning approach called GiPH, which
learns policies that generalize to dynamic device clusters via 1) a novel graph
representation gpNet that efficiently encodes the information needed for
choosing a good placement, and 2) a scalable graph neural network (GNN) that
learns a summary of the gpNet information. GiPH turns the placement problem
into that of finding a sequence of placement improvements, learning a policy
for selecting this sequence that scales to problems of arbitrary size. We
evaluate GiPH with a wide range of task graphs and device clusters and show
that our learned policy rapidly find good placements for new problem instances.
GiPH finds placements with up to 30.5% lower completion times, searching up to
3X faster than other search-based placement policies.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:02:21 GMT""}]","2023-05-25"
"2305.14563","Aida Wofford","Aida Wofford, Andr\'es Sixtos, Stephane Charlot, Gustavo Bruzual,
  Fergus Cullen, Thomas M. Stanton, Svea Hern\'andez, Linda J. Smith, Matthew
  Hayes","Extreme broad He\2 emission at high and low redshifts: the dominant role
  of VMS in NGC 3125-A1 and CDFS131717","17 pages, 17 figures, accepted in MNRAS",,"10.1093/mnras/stad1622",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Super star cluster (SSC) A1 (3.1E5 Msun) in NGC 3125 has one of the strongest
(EW = 4.6 +/- 0.5 Ang) broad (FWHM = 1131 +\- 40 km/s) He II 1640 emission
lines in the nearby Universe and constitutes an important template for
interpreting observations of extreme He II emitters out to redshifts of z =
2-3. We use Cosmic Origins Spectrograph (COS) observations of A1 to show that
there is no significant contamination of the He II line with nebular emission
and that the line is redshifted by 121 +/-17 km/s relative to ISM lines. We
compare the COS G130M + G160M observations of A1 to recent binary BPASS and
single-star Charlot & Bruzual (C&B) simple stellar population (SSP) models with
Very Massive Stars (VMS) of up to 300 Msun. We suggest why BPASS models fail to
reproduce A1's He II emission. On the other hand, a C&B model with Z = 0.008,
age = 2.2 Myr, and VMS approaching the Eddington limit provides an excellent
fit to the He II emission and fits reasonably well C III 1175, N V 1238,1241,
and C IV 1548, 1551. We present O V 1371 line-profile predictions showing that
this line constitutes an important tracer of youth and VMS in galaxies.
Finally, we discuss the presence of VMS in CDFS131717, a highly star-forming
low-metallicity galaxy located at z = 3.071, which has a tentative detection of
O V absorption and strong broad He II emission. These features are rare and
hint to the presence of short-lived VMS in the galaxy. Our results show the
effect of the latest developments of stellar wind theory and the importance of
accounting for VMS in models.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:02:32 GMT""}]","2023-06-07"
"2305.14564","Simeng Sun","Simeng Sun, Yang Liu, Shuohang Wang, Chenguang Zhu, Mohit Iyyer","PEARL: Prompting Large Language Models to Plan and Execute Actions Over
  Long Documents",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Strategies such as chain-of-thought prompting improve the performance of
large language models (LLMs) on complex reasoning tasks by decomposing input
examples into intermediate steps. However, it remains unclear how to apply such
methods to reason over long input documents, in which both the decomposition
and the output of each intermediate step are non-trivial to obtain. In this
work, we propose PEARL, a prompting framework to improve reasoning over long
documents, which consists of three stages: action mining, plan formulation, and
plan execution. More specifically, given a question about a long document,
PEARL decomposes the question into a sequence of actions (e.g., SUMMARIZE,
FIND_EVENT, FIND_RELATION) and then executes them over the document to obtain
the answer. Each stage of PEARL is implemented via zero-shot or few-shot
prompting of LLMs (in our work, GPT-4) with minimal human input. We evaluate
PEARL on a challenging subset of the QuALITY dataset, which contains questions
that require complex reasoning over long narrative texts. PEARL outperforms
zero-shot and chain-of-thought prompting on this dataset, and ablation
experiments show that each stage of PEARL is critical to its performance.
Overall, PEARL is a first step towards leveraging LLMs to reason over long
documents.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:06:04 GMT""}]","2023-05-25"
"2305.14565","Justin Forlano","Andreia Chapouto, Justin Forlano","Invariant measures for the periodic KdV and mKdV equations using
  complete integrability","32 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the real-valued defocusing modified Korteweg-de Vries equation
(mKdV) on the circle. Based on the complete integrability of mKdV,
Killip-Vi\c{s}an-Zhang (2018) discovered a conserved quantity which they used
to prove low regularity a priori bounds for solutions. It has been an open
question if this conserved quantity can be used to define invariant measures
supported at fractional Sobolev regularities. Motivated by this question, we
construct probability measures supported on $H^s(\mathbb{T})$ for $0<s<1/2$
invariant under the mKdV flow. We then use the Miura transform to obtain
invariant measures for the Korteweg-de Vries equation, whose supports are
rougher than the white noise measure.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:06:20 GMT""}]","2023-05-25"
"2305.14566","Haoju Leng","Haoju Leng, Ruining Deng, Zuhayr Asad, R. Michael Womick, Haichun
  Yang, Lipeng Wan, and Yuankai Huo","An Accelerated Pipeline for Multi-label Renal Pathology Image
  Segmentation at the Whole Slide Image Level",,,"10.1117/12.2653651",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep-learning techniques have been used widely to alleviate the
labour-intensive and time-consuming manual annotation required for pixel-level
tissue characterization. Our previous study introduced an efficient single
dynamic network - Omni-Seg - that achieved multi-class multi-scale pathological
segmentation with less computational complexity. However, the patch-wise
segmentation paradigm still applies to Omni-Seg, and the pipeline is
time-consuming when providing segmentation for Whole Slide Images (WSIs). In
this paper, we propose an enhanced version of the Omni-Seg pipeline in order to
reduce the repetitive computing processes and utilize a GPU to accelerate the
model's prediction for both better model performance and faster speed. Our
proposed method's innovative contribution is two-fold: (1) a Docker is released
for an end-to-end slide-wise multi-tissue segmentation for WSIs; and (2) the
pipeline is deployed on a GPU to accelerate the prediction, achieving better
segmentation quality in less time. The proposed accelerated implementation
reduced the average processing time (at the testing stage) on a standard needle
biopsy WSI from 2.3 hours to 22 minutes, using 35 WSIs from the Kidney Tissue
Atlas (KPMP) Datasets. The source code and the Docker have been made publicly
available at https://github.com/ddrrnn123/Omni-Seg.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:07:53 GMT""}]","2023-05-25"
"2305.14567","Leo Feng","Leo Feng, Frederick Tung, Hossein Hajimirsadeghi, Yoshua Bengio,
  Mohamed Osama Ahmed","Constant Memory Attentive Neural Processes",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Processes (NPs) are efficient methods for estimating predictive
uncertainties. NPs comprise of a conditioning phase where a context dataset is
encoded, a querying phase where the model makes predictions using the context
dataset encoding, and an updating phase where the model updates its encoding
with newly received datapoints. However, state-of-the-art methods require
additional memory which scales linearly or quadratically with the size of the
dataset, limiting their applications, particularly in low-resource settings. In
this work, we propose Constant Memory Attentive Neural Processes (CMANPs), an
NP variant which only requires constant memory for the conditioning, querying,
and updating phases. In building CMANPs, we propose Constant Memory Attention
Block (CMAB), a novel general-purpose attention block that can compute its
output in constant memory and perform updates in constant computation.
Empirically, we show CMANPs achieve state-of-the-art results on meta-regression
and image completion tasks while being (1) significantly more memory efficient
than prior methods and (2) more scalable to harder settings.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:10:19 GMT""}]","2023-05-25"
"2305.14568","Xiaohao Cai","Jiahui Liu, Xiaohao Cai, and Mahesan Niranjan","GO-LDA: Generalised Optimal Linear Discriminant Analysis",,,,,"cs.CV cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Linear discriminant analysis (LDA) has been a useful tool in pattern
recognition and data analysis research and practice. While linearity of class
boundaries cannot always be expected, nonlinear projections through pre-trained
deep neural networks have served to map complex data onto feature spaces in
which linear discrimination has served well. The solution to binary LDA is
obtained by eigenvalue analysis of within-class and between-class scatter
matrices. It is well known that the multiclass LDA is solved by an extension to
the binary LDA, a generalised eigenvalue problem, from which the largest
subspace that can be extracted is of dimension one lower than the number of
classes in the given problem. In this paper, we show that, apart from the first
of the discriminant directions, the generalised eigenanalysis solution to
multiclass LDA does neither yield orthogonal discriminant directions nor
maximise discrimination of projected data along them. Surprisingly, to the best
of our knowledge, this has not been noted in decades of literature on LDA. To
overcome this drawback, we present a derivation with a strict theoretical
support for sequentially obtaining discriminant directions that are orthogonal
to previously computed ones and maximise in each step the Fisher criterion. We
show distributions of projections along these axes and demonstrate that
discrimination of data projected onto these discriminant directions has optimal
separation, which is much higher than those from the generalised eigenvectors
of the multiclass LDA. Using a wide range of benchmark tasks, we present a
comprehensive empirical demonstration that on a number of pattern recognition
and classification problems, the optimal discriminant subspaces obtained by the
proposed method, referred to as GO-LDA (Generalised Optimal LDA), can offer
superior accuracy.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:11:05 GMT""}]","2023-05-25"
"2305.14569","Srijan Bansal","Srijan Bansal, Semih Yavuz, Bo Pang, Meghana Bhat, Yingbo Zhou","Few-shot Unified Question Answering: Tuning Models or Prompts?",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Question-answering (QA) tasks often investigate specific question types,
knowledge domains, or reasoning skills, leading to specialized models catering
to specific categories of QA tasks. While recent research has explored the idea
of unified QA models, such models are usually explored for high-resource
scenarios and require re-training to extend their capabilities. To overcome
these drawbacks, the paper explores the potential of two paradigms of tuning,
model, and prompts, for unified QA under a low-resource setting. The paper
provides an exhaustive analysis of their applicability using 16 QA datasets,
revealing that prompt tuning can perform as well as model tuning in a few-shot
setting with a good initialization. The study also shows that parameter-sharing
results in superior few-shot performance, simple knowledge transfer techniques
for prompt initialization can be effective, and prompt tuning achieves a
significant performance boost from pre-training in a low-resource regime. The
research offers insights into the advantages and limitations of prompt tuning
for unified QA in a few-shot setting, contributing to the development of
effective and efficient systems in low-resource scenarios.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:14:38 GMT""}]","2023-05-25"
"2305.14570","Billie Goolsby","Tony G. Chen, Billie C. Goolsby, Guadalupe Bernal, Lauren A.
  O'Connell, Mark R. Cutkosky","Feed Me: Robotic Infiltration of Poison Frog Families","10 pages, 6 figures, to be presented at Living Machines 2023",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present the design and operation of tadpole-mimetic robots prepared for a
study of the parenting behaviors of poison frogs, which pair bond and raise
their offspring. The mission of these robots is to convince poison frog parents
that they are tadpoles, which need to be fed. Tadpoles indicate this need, at
least in part, by wriggling with a characteristic frequency and amplitude.
While the study is in progress, preliminary indications are that the TadBots
have passed their test, at least for father frogs. We discuss the design and
operational requirements for producing convincing TadBots and provide some
details of the study design and plans for future work.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:21:06 GMT""}]","2023-05-25"
"2305.14571","Li Sun","Li Sun, Florian Luisier, Kayhan Batmanghelich, Dinei Florencio, Cha
  Zhang","From Characters to Words: Hierarchical Pre-trained Language Model for
  Open-vocabulary Language Understanding","Accepted to ACL 2023 Main Conference",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Current state-of-the-art models for natural language understanding require a
preprocessing step to convert raw text into discrete tokens. This process known
as tokenization relies on a pre-built vocabulary of words or sub-word
morphemes. This fixed vocabulary limits the model's robustness to spelling
errors and its capacity to adapt to new domains. In this work, we introduce a
novel open-vocabulary language model that adopts a hierarchical two-level
approach: one at the word level and another at the sequence level. Concretely,
we design an intra-word module that uses a shallow Transformer architecture to
learn word representations from their characters, and a deep inter-word
Transformer module that contextualizes each word representation by attending to
the entire word sequence. Our model thus directly operates on character
sequences with explicit awareness of word boundaries, but without biased
sub-word or word-level vocabulary. Experiments on various downstream tasks show
that our method outperforms strong baselines. We also demonstrate that our
hierarchical model is robust to textual corruption and domain shift.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:22:20 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 03:36:13 GMT""}]","2023-05-31"
"2305.14572","Peter Petreczky","Raktim Abir, Igor Akushevich, Tolga Altinoluk, Daniele Paolo Anderle,
  Fatma P. Aslan, Alessandro Bacchetta, Baha Balantekin, Joao Barata, Marco
  Battaglieri, Carlos A. Bertulani, Guillaume Beuf, Chiara Bissolotti, Dani\""el
  Boer, M. Boglione, Radja Boughezal, Eric Braaten, Nora Brambilla, Vladimir
  Braun, Duane Byer, Francesco Giovanni Celiberto, Yang-Ting Chien, Ian C.
  Clo\""et, Martha Constantinou, Wim Cosyn, Aurore Courtoy, Alexander Czajka,
  Umberto D'Alesio, Giuseppe Bozzi, Igor Danilkin, Debasish Das, Daniel de
  Florian, Andrea Delgado, J. P. B. C. de Melo, William Detmold, Michael
  D\""oring, Adrian Dumitru, Miguel G. Echevarria, Robert Edwards, Gernot
  Eichmann, Bruno El-Bennich, Michael Engelhardt, Cesar Fernandez-Ramirez,
  Christian Fischer, Geofrey Fox, Adam Freese, Leonard Gamberg, Maria Vittoria
  Garzelli, Francesco Giacosa, Gustavo Gil da Silveira, Derek Glazier, Victor
  P. Goncalves, Silas Grossberndt, Feng-Kun Guo, Rajan Gupta, Yoshitaka Hatta,
  Martin Hentschinski, Astrid Hiller Blin, Radja Boughezal, Timothy Hobbs,
  Alexander Ilyichev, Jamal Jalilian-Marian, Chueng-Ryong Ji, Shuo Jia,
  Zhong-Bo Kang, Bishnu Karki, Weiyao Ke, Vladimir Khachatryan, Dmitri
  Kharzeev, Spencer R. Klein, Vladimir Korepin, Yuri Kovchegov, Brandon
  Kriesten, Shunzo Kumano, Wai Kin Lai, Richard Lebed, Christopher Lee, Kyle
  Lee, Hai Tao Li, Jifeng Liao, Huey-Wen Lin, Keh-Fei Liu, Simonetta Liuti,
  C\'edric Lorc\'e, Magno V. T. Machado, Heikki Mantysaari, Vincent Mathieu,
  Nilmani Mathur, Yacine Mehtar-Tani, Wally Melnitchouk, Emanuele Mereghetti,
  Andreas Metz, Johannes K.L. Michel, Gerald Miller, Hamlet Mkrtchyan, Asmita
  Mukherjee, Swagato Mukherjee, Piet Mulders, St\'ephane Munier, Francesco
  Murgia, P. M. Nadolsky, John W Negele, Duff Neill, Jan Nemchik, E. Nocera,
  Vitalii Okorokov, Fredrick Olness, Barbara Pasquini, Chao Peng, Peter
  Petreczky, Frank Petriello, Alessandro Pilloni, Bernard Pire, Cristian
  Pisano, Daniel Pitonyak, Michal Praszalowicz, Alexei Prokudin, Jianwei Qiu,
  Marco Radici, Kh\'epani Raya, Felix Ringer, Jennifer Rittenhouse West,
  Arkaitz Rodas, Simone Rodini, Juan Rojo, Farid Salazar, Elena Santopinto,
  Misak Sargsian, Nobuo Sato, Bjoern Schenke, Stella Schindler, Gunar Schnell,
  Peter Schweitzer, Ignazio Scimemi, Jorge Segovia, Kirill
  Semenov-Tian-Shansky, Phiala Shanahan, Ding-Yu Shao, Matt Sievert, Andrea
  Signori, Rajeev Singh, Vladi Skokov, Qin-Tao Song, Stanislav Srednyak, Iain
  W. Stewart, Raza Sabbir Sufian, Eric Swanson, Sergey Syritsyn, Adam
  Szczepaniak, Pawel Sznajder, Asli Tandogan, Yossathorn Tawabutr, A. Tawfik,
  John Terry, Tobias Toll, Oleksandr Tomalak, Fidele Twagirayezu, Raju
  Venugopalan, Ivan Vitev, Alexey Vladimirov, Werner Vogelsang, Ramona Vogt,
  Gojko Vujanovic, Wouter Waalewijn, Xiang-Peng Wang, Bo-Wen Xiao, Hongxi Xing,
  Yi-Bo Yang, Xiaojun Yao, Feng Yuan, Yong Zhao, Pia Zurita","The case for an EIC Theory Alliance: Theoretical Challenges of the EIC","44 pages, ReVTeX, White Paper on EIC Theory Alliance",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We outline the physics opportunities provided by the Electron Ion Collider
(EIC). These include the study of the parton structure of the nucleon and
nuclei, the onset of gluon saturation, the production of jets and heavy flavor,
hadron spectroscopy and tests of fundamental symmetries. We review the present
status and future challenges in EIC theory that have to be addressed in order
to realize this ambitious and impactful physics program, including how to
engage a diverse and inclusive workforce. In order to address these many-fold
challenges, we propose a coordinated effort involving theory groups with
differing expertise is needed. We discuss the scientific goals and scope of
such an EIC Theory Alliance.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:22:39 GMT""}]","2023-05-25"
"2305.14573","Yinxing (Allen) Zang","Allen Zang, Xinan Chen, Alexander Kolar, Joaquin Chung, Martin
  Suchara, Tian Zhong, Rajkumar Kettimuthu","Entanglement Distribution in Quantum Repeater with Purification and
  Optimized Buffer Time","6 pages, 4 figures, IEEE INFOCOM'23 NetSciQCom 2023",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum repeater networks that allow long-distance entanglement distribution
will be the backbone of distributed quantum information processing. In this
paper we explore entanglement distribution using quantum repeaters with
optimized buffer time, equipped with noisy quantum memories and performing
imperfect entanglement purification and swapping. We observe that increasing
the number of memories on end nodes leads to a higher entanglement distribution
rate per memory and higher probability of high-fidelity entanglement
distribution, at least for the case with perfect operations. When imperfect
operations are considered, however, we make the surprising observation that the
per-memory entanglement rate decreases with increasing number of memories. Our
results suggest that building quantum repeaters that perform well under
realistic conditions requires careful modeling and design that takes into
consideration the operations and resources that are finite and imperfect.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:23:34 GMT""}]","2023-05-25"
"2305.14574","Erin George","Erin George, Joyce Chew, Deanna Needell","Detecting and Mitigating Indirect Stereotypes in Word Embeddings","15 pages",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Societal biases in the usage of words, including harmful stereotypes, are
frequently learned by common word embedding methods. These biases manifest not
only between a word and an explicit marker of its stereotype, but also between
words that share related stereotypes. This latter phenomenon, sometimes called
""indirect bias,'' has resisted prior attempts at debiasing. In this paper, we
propose a novel method called Biased Indirect Relationship Modification (BIRM)
to mitigate indirect bias in distributional word embeddings by modifying biased
relationships between words before embeddings are learned. This is done by
considering how the co-occurrence probability of a given pair of words changes
in the presence of words marking an attribute of bias, and using this to
average out the effect of a bias attribute. To evaluate this method, we perform
a series of common tests and demonstrate that measures of bias in the word
embeddings are reduced in exchange for minor reduction in the semantic quality
of the embeddings. In addition, we conduct novel tests for measuring indirect
stereotypes by extending the Word Embedding Association Test (WEAT) with new
test sets for indirect binary gender stereotypes. With these tests, we
demonstrate the presence of more subtle stereotypes not addressed by previous
work. The proposed method is able to reduce the presence of some of these new
stereotypes, serving as a crucial next step towards non-stereotyped word
embeddings.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:23:49 GMT""}]","2023-05-25"
"2305.14575","Abhineet Singh","Abhineet Singh, Ila Jasra, Omar Mouhammed, Nidheesh Dadheech, Nilanjan
  Ray, James Shapiro","Towards Early Prediction of Human iPSC Reprogramming Success",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents advancements in automated early-stage prediction of the
success of reprogramming human induced pluripotent stem cells (iPSCs) as a
potential source for regenerative cell therapies.The minuscule success rate of
iPSC-reprogramming of around $ 0.01% $ to $ 0.1% $ makes it labor-intensive,
time-consuming, and exorbitantly expensive to generate a stable iPSC line.
Since that requires culturing of millions of cells and intense biological
scrutiny of multiple clones to identify a single optimal clone. The ability to
reliably predict which cells are likely to establish as an optimal iPSC line at
an early stage of pluripotency would therefore be ground-breaking in rendering
this a practical and cost-effective approach to personalized medicine. Temporal
information about changes in cellular appearance over time is crucial for
predicting its future growth outcomes. In order to generate this data, we first
performed continuous time-lapse imaging of iPSCs in culture using an ultra-high
resolution microscope. We then annotated the locations and identities of cells
in late-stage images where reliable manual identification is possible. Next, we
propagated these labels backwards in time using a semi-automated tracking
system to obtain labels for early stages of growth. Finally, we used this data
to train deep neural networks to perform automatic cell segmentation and
classification. Our code and data are available at
https://github.com/abhineet123/ipsc_prediction.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:26:35 GMT""}]","2023-05-25"
"2305.14576","Josip Juki\'c","Josip Juki\'c, Jan \v{S}najder","Parameter-Efficient Language Model Tuning with Active Learning in
  Low-Resource Settings",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pre-trained language models (PLMs) have ignited a surge in demand for
effective fine-tuning techniques, particularly in low-resource domains and
languages. Active learning (AL), a set of algorithms designed to decrease
labeling costs by minimizing label complexity, has shown promise in confronting
the labeling bottleneck. Concurrently, adapter modules, designed for
parameter-efficient fine-tuning (PEFT), have showcased notable potential in
low-resource settings. However, the interplay between AL and adapter-based PEFT
remains unexplored. In our study, we empirically investigate PEFT behavior with
AL in low-resource settings for text classification tasks. Our findings affirm
the superiority of PEFT over full-fine tuning (FFT) in low-resource settings
and demonstrate that this advantage persists in AL setups. Finally, we delve
into the properties of PEFT and FFT through the lens of forgetting dynamics and
instance-level representations, linking them to AL instance selection behavior
and the stability of PEFT. Our research underscores the synergistic potential
of AL, PEFT, and TAPT in low-resource settings, paving the way for advancements
in efficient and effective fine-tuning.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:27:20 GMT""}]","2023-05-25"
"2305.14577","Alex Wilf","Alex Wilf, Syeda Nahida Akter, Leena Mathur, Paul Pu Liang, Sheryl
  Mathew, Mengrou Shou, Eric Nyberg, Louis-Philippe Morency","Difference-Masking: Choosing What to Mask in Continued Pretraining",,,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning (SSL) and the objective of masking-and-predicting in
particular have led to promising SSL performance on a variety of downstream
tasks. However, while most approaches randomly mask tokens, there is strong
intuition from the field of education that deciding what to mask can
substantially improve learning outcomes. We introduce Difference-Masking, an
approach that automatically chooses what to mask during continued pretraining
by considering what makes an unlabelled target domain different from the
pretraining domain. Empirically, we find that Difference-Masking outperforms
baselines on continued pretraining settings across four diverse language and
multimodal video tasks. The cross-task applicability of Difference-Masking
supports the effectiveness of our framework for SSL pretraining in language,
vision, and other domains.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:31:02 GMT""}]","2023-05-25"
"2305.14578","Margarita Bugue\~no","Margarita Bugue\~no, Gerard de Melo","Connecting the Dots: What Graph-Based Text Representations Work Best for
  Text Classification using Graph Neural Networks?","17 pages, 2 figures, 15 tables. The Appendix starts on page 12",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the success of Graph Neural Networks (GNNs) for structure-aware machine
learning, numerous studies have explored their application to text
classification, as an alternative to traditional feature representation models.
However, most studies considered just a specific domain and validated on data
with particular characteristics. This work presents an extensive empirical
investigation of graph-based text representation methods proposed for text
classification, identifying practical implications and open challenges in the
field. We compare several GNN architectures as well as BERT across five
datasets, encompassing short and also long documents. The results show that: i)
graph performance is highly related to the textual input features and domain,
ii) despite its outstanding performance, BERT has difficulties converging when
dealing with short texts, iii) graph methods are particularly beneficial for
longer documents.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:31:24 GMT""}]","2023-05-25"
"2305.14579","Xiwen Li","Xiwen Li, Tristalee Mangin, Surojit Saha, Evan Blanchard, Dillon Tang,
  Henry Poppe, Nathan Searle, Ouk Choi, Kerry Kelly, and Ross Whitaker","Real-Time Idling Vehicles Detection Using Combined Audio-Visual Deep
  Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combustion vehicle emissions contribute to poor air quality and release
greenhouse gases into the atmosphere, and vehicle pollution has been associated
with numerous adverse health effects. Roadways with extensive waiting and/or
passenger drop off, such as schools and hospital drop-off zones, can result in
high incidence and density of idling vehicles. This can produce micro-climates
of increased vehicle pollution. Thus, the detection of idling vehicles can be
helpful in monitoring and responding to unnecessary idling and be integrated
into real-time or off-line systems to address the resulting pollution. In this
paper we present a real-time, dynamic vehicle idling detection algorithm. The
proposed idle detection algorithm and notification rely on an algorithm to
detect these idling vehicles. The proposed method relies on a multi-sensor,
audio-visual, machine-learning workflow to detect idling vehicles visually
under three conditions: moving, static with the engine on, and static with the
engine off. The visual vehicle motion detector is built in the first stage, and
then a contrastive-learning-based latent space is trained for classifying
static vehicle engine sound. We test our system in real-time at a hospital
drop-off point in Salt Lake City. This in-situ dataset was collected and
annotated, and it includes vehicles of varying models and types. The
experiments show that the method can detect engine switching on or off
instantly and achieves 71.01 mean average precision (mAP).
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:35:43 GMT""}]","2023-05-25"
"2305.14580","Lucas Gris","Lucas Rafael Stefanel Gris and Ricardo Marcacini and Arnaldo Candido
  Junior and Edresson Casanova and Anderson Soares and Sandra Maria Alu\'isio","Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic
  Modeling of life histories of the Museum of the Person",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic speech recognition (ASR) systems play a key role in applications
involving human-machine interactions. Despite their importance, ASR models for
the Portuguese language proposed in the last decade have limitations in
relation to the correct identification of punctuation marks in automatic
transcriptions, which hinder the use of transcriptions by other systems,
models, and even by humans. However, recently Whisper ASR was proposed by
OpenAI, a general-purpose speech recognition model that has generated great
expectations in dealing with such limitations. This chapter presents the first
study on the performance of Whisper for punctuation prediction in the
Portuguese language. We present an experimental evaluation considering both
theoretical aspects involving pausing points (comma) and complete ideas
(exclamation, question, and fullstop), as well as practical aspects involving
transcript-based topic modeling - an application dependent on punctuation marks
for promising performance. We analyzed experimental results from videos of
Museum of the Person, a virtual museum that aims to tell and preserve people's
life histories, thus discussing the pros and cons of Whisper in a real-world
scenario. Although our experiments indicate that Whisper achieves
state-of-the-art results, we conclude that some punctuation marks require
improvements, such as exclamation, semicolon and colon.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:37:29 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 12:09:55 GMT""}]","2023-05-29"
"2305.14581","Smrithan Ravichandran","Smrithan Ravichandran, Andrew Longman, Marine Huault, Roberto Lera,
  Calvin Z. He, Robert Fedosejevs, Luis Roso and Wendell T. Hill III","Imaging electron angular distributions to assess a full-power
  petawatt-class laser focus","10 pages, 6 figures, submitted to Physical Review A",,,,"physics.ins-det physics.app-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a novel technique to assess the focal volume of petawatt-class
lasers at full power. Our approach exploits quantitative measurement of the
angular distribution of electrons born in the focus via ionization of rarefied
gas, which are accelerated forward and ejected ponderomotively by the field. We
show that a bivariate ($\theta, \phi$) angular distribution, which was obtained
with image plates, not only enables the peak intensity to be extracted, it also
reflects nonideality of the focal-spot intensity distribution. In our prototype
demonstration at intensities of a few $\times 10^{19}$ to a few $\times
10^{20}$ $\mathrm{W/cm^2}$, an f/10 optic produced a focal spot in the paraxial
regime, allowing a plane-wave parameterization of the peak intensity
($\tan{\theta} \propto 1/a_0$) to be compared with our measurements;
qualitative agreement was found. Furthermore, we show that scintillation
detection of electrons is sensitive to real-time, shot-to-shot fluctuations,
which means the technique would support single-shot measurement. Finally, we
estimate that this approach should be usable with electrons up to intensities
$\sim 10^{21}\ \mathrm{W/cm^2}$ before angular measurements start to be less
effective. However, angular measurements will again be possible at $\sim
10^{24}\ \mathrm{W/cm^2}$ when protons become relativistic within a single
cycle.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:38:45 GMT""}]","2023-05-25"
"2305.14582","Ziqi Zhao","Ziqi Zhao, Yucheng Shi, Shushan Wu, Fan Yang, Wenzhan Song, Ninghao
  Liu","Interpretation of Time-Series Deep Models: A Survey","18 pages, 3 figures, 1 table",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning models developed for time-series associated tasks have become
more widely researched nowadays. However, due to the unintuitive nature of
time-series data, the interpretability problem -- where we understand what is
under the hood of these models -- becomes crucial. The advancement of similar
studies in computer vision has given rise to many post-hoc methods, which can
also shed light on how to explain time-series models. In this paper, we present
a wide range of post-hoc interpretation methods for time-series models based on
backpropagation, perturbation, and approximation. We also want to bring focus
onto inherently interpretable models, a novel category of interpretation where
human-understandable information is designed within the models. Furthermore, we
introduce some common evaluation metrics used for the explanations, and propose
several directions of future researches on the time-series interpretability
problem. As a highlight, our work summarizes not only the well-established
interpretation methods, but also a handful of fairly recent and under-developed
techniques, which we hope to capture their essence and spark future endeavours
to innovate and improvise.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:43:26 GMT""}]","2023-05-25"
"2305.14583","Alexander Hoyle","Alexander Hoyle, Rupak Sarkar, Pranav Goel, Philip Resnik","Making the Implicit Explicit: Implicit Content as a First Class Citizen
  in NLP",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Language is multifaceted. A given utterance can be re-expressed in equivalent
forms, and its implicit and explicit content support various logical and
pragmatic inferences. When processing an utterance, we consider these different
aspects, as mediated by our interpretive goals -- understanding that ""it's dark
in here"" may be a veiled direction to turn on a light. Nonetheless, NLP methods
typically operate over the surface form alone, eliding this nuance.
  In this work, we represent language with language, and direct an LLM to
decompose utterances into logical and plausible inferences. The reduced
complexity of the decompositions makes them easier to embed, opening up novel
applications. Variations on our technique lead to state-of-the-art improvements
on sentence embedding benchmarks, a substantive application in computational
political science, and to a novel construct-discovery process, which we
validate with human annotations.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:45:20 GMT""}]","2023-05-25"
"2305.14584","Kangkang Duan","Kangkang Duan and Zhengbo Zou","Learning from demonstrations: An intuitive VR environment for imitation
  learning of construction robots","22 pages, 8 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Construction robots are challenging the traditional paradigm of labor
intensive and repetitive construction tasks. Present concerns regarding
construction robots are focused on their abilities in performing complex tasks
consisting of several subtasks and their adaptability to work in unstructured
and dynamic construction environments. Imitation learning (IL) has shown
advantages in training a robot to imitate expert actions in complex tasks and
the policy thereafter generated by reinforcement learning (RL) is more adaptive
in comparison with pre-programmed robots. In this paper, we proposed a
framework composed of two modules for imitation learning of construction
robots. The first module provides an intuitive expert demonstration collection
Virtual Reality (VR) platform where a robot will automatically follow the
position, rotation, and actions of the expert's hand in real-time, instead of
requiring an expert to control the robot via controllers. The second module
provides a template for imitation learning using observations and actions
recorded in the first module. In the second module, Behavior Cloning (BC) is
utilized for pre-training, Generative Adversarial Imitation Learning (GAIL) and
Proximal Policy Optimization (PPO) are combined to achieve a trade-off between
the strength of imitation vs. exploration. Results show that imitation
learning, especially when combined with PPO, could significantly accelerate
training in limited training steps and improve policy performance.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:46:57 GMT""}]","2023-05-25"
"2305.14585","Andrew Engel","Andrew Engel, Zhichao Wang, Natalie S. Frank, Ioana Dumitriu, Sutanay
  Choudhury, Anand Sarwate, Tony Chiang","Robust Explanations for Deep Neural Networks via Pseudo Neural Tangent
  Kernel Surrogate Models","9 pages, 4 figures, 3 tables",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the ways recent progress has been made on explainable AI has been via
explain-by-example strategies, specifically, through data attribution tasks.
The feature spaces used to attribute decisions to training data, however, have
not been compared against one another as to whether they form a truly
representative surrogate model of the neural network (NN). Here, we demonstrate
the efficacy of surrogate linear feature spaces to neural networks through two
means: (1) we establish that a normalized psuedo neural tangent kernel (pNTK)
is more correlated to the neural network decision functions than embedding
based and influence based alternatives in both computer vision and large
language model architectures; (2) we show that the attributions created from
the normalized pNTK more accurately select perturbed training data in a data
poisoning attribution task than these alternatives. Based on these
observations, we conclude that kernel linear models are effective surrogate
models across multiple classification architectures and that pNTK-based kernels
are the most appropriate surrogate feature space of all kernels studied.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:51:53 GMT""}]","2023-05-25"
"2305.14586","Kangkang Duan","Kangkang Duan, Christine Wun Ki Suen, and Zhengbo Zou","MARC: A multi-agent robots control framework for enhancing reinforcement
  learning in construction tasks","19 pages",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Letting robots emulate human behavior has always posed a challenge,
particularly in scenarios involving multiple robots. In this paper, we
presented a framework aimed at achieving multi-agent reinforcement learning for
robot control in construction tasks. The construction industry often
necessitates complex interactions and coordination among multiple robots,
demanding a solution that enables effective collaboration and efficient task
execution. Our proposed framework leverages the principles of proximal policy
optimization and developed a multi-agent version to enable the robots to
acquire sophisticated control policies. We evaluated the effectiveness of our
framework by learning four different collaborative tasks in the construction
environments. The results demonstrated the capability of our approach in
enabling multiple robots to learn and adapt their behaviors in complex
construction tasks while effectively preventing collisions. Results also
revealed the potential of combining and exploring the advantages of
reinforcement learning algorithms and inverse kinematics. The findings from
this research contributed to the advancement of multi-agent reinforcement
learning in the domain of construction robotics. By enabling robots to behave
like human counterparts and collaborate effectively, we pave the way for more
efficient, flexible, and intelligent construction processes.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:52:31 GMT""}]","2023-05-25"
"2305.14587","Hamed Rahimi","Hamed Rahimi, Jacob Louis Hoover, David Mimno, Hubert Naacke, Camelia
  Constantin, Bernd Amann","Contextualized Topic Coherence Metrics",,,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent explosion in work on neural topic modeling has been criticized for
optimizing automated topic evaluation metrics at the expense of actual
meaningful topic identification. But human annotation remains expensive and
time-consuming. We propose LLM-based methods inspired by standard human topic
evaluations, in a family of metrics called Contextualized Topic Coherence
(CTC). We evaluate both a fully automated version as well as a semi-automated
CTC that allows human-centered evaluation of coherence while maintaining the
efficiency of automated methods. We evaluate CTC relative to five other metrics
on six topic models and find that it outperforms automated topic coherence
methods, works well on short documents, and is not susceptible to meaningless
but high-scoring topics.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:53:29 GMT""}]","2023-05-25"
"2305.14588","Daniel Simig","Sebastian Cadavid-Sanchez, Khalil Kacem, Rafael Aparecido Martins
  Frade, Johannes Boehm, Thomas Chaney, Danial Lashkari, Daniel Simig","Evaluating end-to-end entity linking on domain-specific knowledge bases:
  Learning about ancient technologies from museum collections",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  To study social, economic, and historical questions, researchers in the
social sciences and humanities have started to use increasingly large
unstructured textual datasets. While recent advances in NLP provide many tools
to efficiently process such data, most existing approaches rely on generic
solutions whose performance and suitability for domain-specific tasks is not
well understood. This work presents an attempt to bridge this domain gap by
exploring the use of modern Entity Linking approaches for the enrichment of
museum collection data. We collect a dataset comprising of more than 1700 texts
annotated with 7,510 mention-entity pairs, evaluate some off-the-shelf
solutions in detail using this dataset and finally fine-tune a recent
end-to-end EL model on this data. We show that our fine-tuned model
significantly outperforms other approaches currently available in this domain
and present a proof-of-concept use case of this model. We release our dataset
and our best model.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:53:58 GMT""}]","2023-05-25"
"2305.14589","Xiaofeng Liu","Xiaofeng Liu, Jerry L. Prince, Fangxu Xing, Jiachen Zhuo, Reese
  Timothy, Maureen Stone, Georges El Fakhri, Jonghye Woo","Attentive Continuous Generative Self-training for Unsupervised Domain
  Adaptive Medical Image Translation","Accepted to Medical Image Analysis",,,,"eess.IV cs.CV cs.LG physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Self-training is an important class of unsupervised domain adaptation (UDA)
approaches that are used to mitigate the problem of domain shift, when applying
knowledge learned from a labeled source domain to unlabeled and heterogeneous
target domains. While self-training-based UDA has shown considerable promise on
discriminative tasks, including classification and segmentation, through
reliable pseudo-label filtering based on the maximum softmax probability, there
is a paucity of prior work on self-training-based UDA for generative tasks,
including image modality translation. To fill this gap, in this work, we seek
to develop a generative self-training (GST) framework for domain adaptive image
translation with continuous value prediction and regression objectives.
Specifically, we quantify both aleatoric and epistemic uncertainties within our
GST using variational Bayes learning to measure the reliability of synthesized
data. We also introduce a self-attention scheme that de-emphasizes the
background region to prevent it from dominating the training process. The
adaptation is then carried out by an alternating optimization scheme with
target domain supervision that focuses attention on the regions with reliable
pseudo-labels. We evaluated our framework on two cross-scanner/center,
inter-subject translation tasks, including tagged-to-cine magnetic resonance
(MR) image translation and T1-weighted MR-to-fractional anisotropy translation.
Extensive validations with unpaired target domain data showed that our GST
yielded superior synthesis performance in comparison to adversarial training
UDA methods.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:57:44 GMT""}]","2023-05-25"
"2305.14590","Sijia Wang","Pritika Ramu, Sijia Wang, Lalla Mouatadid, Joy Rimchala, Lifu Huang","RE$^2$: Region-Aware Relation Extraction from Visually Rich Documents",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Current research in form understanding predominantly relies on large
pre-trained language models, necessitating extensive data for pre-training.
However, the importance of layout structure (i.e., the spatial relationship
between the entity blocks in the visually rich document) to relation extraction
has been overlooked. In this paper, we propose REgion-Aware Relation Extraction
(RE$^2$) that leverages region-level spatial structure among the entity blocks
to improve their relation prediction. We design an edge-aware graph attention
network to learn the interaction between entities while considering their
spatial relationship defined by their region-level representations. We also
introduce a constraint objective to regularize the model towards consistency
with the inherent constraints of the relation extraction task. Extensive
experiments across various datasets, languages and domains demonstrate the
superiority of our proposed approach.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:07:40 GMT""}]","2023-05-25"
"2305.14591","Kexun Zhang","Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, Lei Li","ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers",,,,,"cs.CL cs.SE","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) excel at implementing code from functionality
descriptions, but struggle with algorithmic problems that require not only
implementation but also identification of the suitable algorithm. Moreover,
LLM-generated programs lack guaranteed correctness and require human
verification. To address these challenges, we propose ALGO, a framework that
synthesizes Algorithmic programs with LLM-Generated Oracles to guide the
creation and verify their correctness. ALGO first generates a probably correct
but possibly slow reference oracle by prompting an LLM to exhaustively
enumerate all the combinations of relevant variables. This oracle is then
utilized to guide an arbitrary search strategy in exploring the algorithm space
and to verify the algorithms synthesized. Our study shows that the
LLM-generated oracles are correct for 88% of the cases. With the oracles as
verifiers, ALGO can be integrated with any existing code generation model in a
model-agnostic manner to enhance its performance. Experiments show that when
equipped with ALGO, we achieve an 8x better one-submission pass rate over the
Codex model and a 2.6x better one-submission pass rate over CodeT, the current
state-of-the-art model on CodeContests. We can also get 1.3x better pass rate
over the ChatGPT Code Interpreter on unseen problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:10:15 GMT""}]","2023-05-25"
"2305.14592","Ruohao Guo","Ruohao Guo, Wei Xu, Alan Ritter","Instruction Tuning with Lexicons for Zero-Shot Style Classification",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Style is used to convey authors' intentions and attitudes. Despite the
success of large pre-trained language models on style classification, prior
work relies on fine-tuning with labeled examples. Prompting large language
models to classify style without fine-tuning is challenging because language
styles can be difficult to define. In this study, we investigate the
effectiveness of style lexicons as a means for instructing language models how
to identify new styles that are unseen during training. Our experiments show
that lexicon-based instructions improve transfer zero-shot performance
significantly. We will release our code and data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:17:36 GMT""}]","2023-05-25"
"2305.14593","Yuling Yao","Yuling Yao, Justin Domke","Discriminative calibration",,,,,"stat.ML cs.LG stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To check the accuracy of Bayesian computations, it is common to use
rank-based simulation-based calibration (SBC). However, SBC has drawbacks: The
test statistic is somewhat ad-hoc, interactions are difficult to examine,
multiple testing is a challenge, and the resulting p-value is not a divergence
metric. We propose to replace the marginal rank test with a flexible
classification approach that learns test statistics from data. This measure
typically has a higher statistical power than the SBC rank test and returns an
interpretable divergence measure of miscalibration, computed from
classification accuracy. This approach can be used with different data
generating processes to address likelihood-free inference or traditional
inference methods like Markov chain Monte Carlo or variational inference. We
illustrate an automated implementation using neural networks and
statistically-inspired features, and validate the method with numerical and
real data experiments.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:18:48 GMT""}]","2023-05-25"
"2305.14594","Salem Lahlou","Salem Lahlou, Joseph D. Viviano, Victor Schmidt","torchgfn: A PyTorch GFlowNet library",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The increasing popularity of generative flow networks (GFlowNets or GFNs) is
accompanied with a proliferation of code sources. This hinders the
implementation of new features, such as training losses, that can readily be
compared to existing ones, on a set of common environments. In addition to
slowing down research in the field of GFlowNets, different code bases use
different conventions, that might be confusing for newcomers. `torchgfn` is a
library built on top of PyTorch, that aims at addressing both problems. It
provides user with a simple API for environments, and useful abstractions for
samplers and losses. Multiple examples are provided, replicating published
results. The code is available in https://github.com/saleml/torchgfn.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:20:59 GMT""}]","2023-05-25"
"2305.14595","Serena Wang","Serena Wang, Stephen Bates, P. M. Aronow, Michael I. Jordan","Operationalizing Counterfactual Metrics: Incentives, Ranking, and
  Information Asymmetry",,,,,"cs.LG cs.CY cs.GT","http://creativecommons.org/licenses/by/4.0/","  From the social sciences to machine learning, it has been well documented
that metrics to be optimized are not always aligned with social welfare. In
healthcare, Dranove et al. [12] showed that publishing surgery mortality
metrics actually harmed the welfare of sicker patients by increasing provider
selection behavior. Using a principal-agent model, we directly study the
incentive misalignments that arise from such average treated outcome metrics,
and show that the incentives driving treatment decisions would align with
maximizing total patient welfare if the metrics (i) accounted for
counterfactual untreated outcomes and (ii) considered total welfare instead of
average welfare among treated patients. Operationalizing this, we show how
counterfactual metrics can be modified to satisfy desirable properties when
used for ranking. Extending to realistic settings when the providers observe
more about patients than the regulatory agencies do, we bound the decay in
performance by the degree of information asymmetry between the principal and
the agent. In doing so, our model connects principal-agent information
asymmetry with unobserved heterogeneity in causal inference.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:24:38 GMT""}]","2023-05-25"
"2305.14596","Sarah Wiegreffe","Sarah Wiegreffe, Matthew Finlayson, Oyvind Tafjord, Peter Clark,
  Ashish Sabharwal","Attentiveness to Answer Choices Doesn't Always Entail High QA Accuracy",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  When large language models (LMs) are applied in zero- or few-shot settings to
discriminative tasks such as multiple-choice questions, their attentiveness
(i.e., probability mass) is spread across many vocabulary tokens that are not
valid choices. Such a spread across multiple surface forms with identical
meaning is thought to cause an underestimation of a model's true performance,
referred to as the ""surface form competition"" (SFC) hypothesis. This has
motivated the introduction of various probability normalization methods.
However, many core questions remain unanswered. How do we measure SFC or
attentiveness? Are there direct ways of increasing attentiveness on valid
choices? Does increasing attentiveness always improve task accuracy? We propose
a mathematical formalism for studying this phenomenon, provide a metric for
quantifying attentiveness, and identify a simple method for increasing it --
namely, in-context learning with even just one example containing answer
choices. The formalism allows us to quantify SFC and bound its impact. Our
experiments on three diverse datasets and six LMs reveal several surprising
findings. For example, encouraging models to generate a valid answer choice
can, in fact, be detrimental to task performance for some LMs, and prior
probability normalization methods are less effective (sometimes even
detrimental) to instruction-tuned LMs. We conclude with practical insights for
effectively using prompted LMs for multiple-choice tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:27:00 GMT""}]","2023-05-25"
"2305.14597","Zhijing Jin","Yiwen Ding, Jiarui Liu, Zhiheng Lyu, Kun Zhang, Bernhard Schoelkopf,
  Zhijing Jin, Rada Mihalcea","Voices of Her: Analyzing Gender Differences in the AI Publication World",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  While several previous studies have analyzed gender bias in research, we are
still missing a comprehensive analysis of gender differences in the AI
community, covering diverse topics and different development trends. Using the
AI Scholar dataset of 78K researchers in the field of AI, we identify several
gender differences: (1) Although female researchers tend to have fewer overall
citations than males, this citation difference does not hold for all
academic-age groups; (2) There exist large gender homophily in co-authorship on
AI papers; (3) Female first-authored papers show distinct linguistic styles,
such as longer text, more positive emotion words, and more catchy titles than
male first-authored papers. Our analysis provides a window into the current
demographic trends in our AI community, and encourages more gender equality and
diversity in the future. Our code and data are at
https://github.com/causalNLP/ai-scholar-gender.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:40:49 GMT""}]","2023-05-25"
"2305.14598","Yutong Zhou","Yutong Zhou and Nobutaka Shimada","Vision + Language Applications: A Survey","Accepted by GCV @CVPR2023",,,,"cs.CV cs.MM","http://creativecommons.org/licenses/by/4.0/","  Text-to-image generation has attracted significant interest from researchers
and practitioners in recent years due to its widespread and diverse
applications across various industries. Despite the progress made in the domain
of vision and language research, the existing literature remains relatively
limited, particularly with regard to advancements and applications in this
field. This paper explores a relevant research track within multimodal
applications, including text, vision, audio, and others. In addition to the
studies discussed in this paper, we are also committed to continually updating
the latest relevant papers, datasets, application projects and corresponding
information at https://github.com/Yutong-Zhou-cv/Awesome-Text-to-Image
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:42:06 GMT""}]","2023-05-25"
"2305.14599","James Y. Huang","James Y. Huang, Wenlin Yao, Kaiqiang Song, Hongming Zhang, Muhao Chen,
  Dong Yu","Bridging Continuous and Discrete Spaces: Interpretable Sentence
  Representation Learning via Compositional Operations",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional sentence embedding models encode sentences into vector
representations to capture useful properties such as the semantic similarity
between sentences. However, in addition to similarity, sentence semantics can
also be interpreted via compositional operations such as sentence fusion or
difference. It is unclear whether the compositional semantics of sentences can
be directly reflected as compositional operations in the embedding space. To
more effectively bridge the continuous embedding and discrete text spaces, we
explore the plausibility of incorporating various compositional properties into
the sentence embedding space that allows us to interpret embedding
transformations as compositional sentence operations. We propose InterSent, an
end-to-end framework for learning interpretable sentence embeddings that
supports compositional sentence operations in the embedding space. Our method
optimizes operator networks and a bottleneck encoder-decoder model to produce
meaningful and interpretable sentence embeddings. Experimental results
demonstrate that our method significantly improves the interpretability of
sentence embeddings on four textual generation tasks over existing approaches
while maintaining strong performance on traditional semantic similarity tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:44:49 GMT""}]","2023-05-25"
"2305.14600","Tao Li","Tao Li, Ghazaleh Kazeminejad, Susan W. Brown, Martha Palmer, Vivek
  Srikumar","Learning Semantic Role Labeling from Compatible Label Sequences",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the question of how to efficiently learn from disjoint,
compatible label sequences. We argue that the compatible structures between
disjoint label sets help model learning and inference. We verify this
hypothesis on the task of semantic role labeling (SRL), specifically, tagging a
sentence with two role sequences: VerbNet arguments and PropBank arguments.
Prior work has shown that cross-task interaction improves performance. However,
the two tasks are still separately decoded, running the risk of generating
structurally inconsistent label sequences (as per lexicons like SEMLINK). To
eliminate this issue, we first propose a simple and effective setup that
jointly handles VerbNet and PropBank labels as one sequence. With this setup,
we show that enforcing SEMLINK constraints during decoding constantly improves
the overall F1. With special input constructions, our joint model infers
VerbNet arguments from PropBank arguments with over 99% accuracy. We also
propose a constrained marginal model that uses SEMLINK information during
training to further benefit from the large amounts of PropBank-only data. Our
models achieve state-of-the-art F1's on VerbNet and PropBank argument labeling
on the CoNLL05 dataset with strong out-of-domain generalization.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:46:02 GMT""}]","2023-05-25"
"2305.14601","Chiyoung Song","Chiyoung Song, Dongjae Lee","FaceFusion: Exploiting Full Spectrum of Multiple Datasets",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The size of training dataset is known to be among the most dominating aspects
of training high-performance face recognition embedding model. Building a large
dataset from scratch could be cumbersome and time-intensive, while combining
multiple already-built datasets poses the risk of introducing large amount of
label noise. We present a novel training method, named FaceFusion. It creates a
fused view of different datasets that is untainted by identity conflicts, while
concurrently training an embedding network using the view in an end-to-end
fashion. Using the unified view of combined datasets enables the embedding
network to be trained against the entire spectrum of the datasets, leading to a
noticeable performance boost. Extensive experiments confirm superiority of our
method, whose performance in public evaluation datasets surpasses not only that
of using a single training dataset, but also that of previously known methods
under various training circumstances.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:51:04 GMT""}]","2023-05-25"
"2305.14602","Siddhartha Sarkar","Siddhartha Sarkar, Mohamed El Hedi Bahri, Andrej Ko\v{s}mrlj","Statistical mechanics of nanotubes",,,,,"cond-mat.stat-mech cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  We investigate the effect of thermal fluctuations on the mechanical
properties of nanotubes by employing tools from statistical physics. For 2D
sheets it was previously shown that thermal fluctuations effectively
renormalize elastic moduli beyond a characteristic temperature-dependent
thermal length scale (a few nanometers for graphene at room temperature), where
the bending rigidity increases, while the in-plane elastic moduli reduce in a
scale-dependent fashion with universal power law exponents. However, the
curvature of nanotubes produces new phenomena. In nanotubes, competition
between stretching and bending costs associated with radial fluctuations
introduces a characteristic elastic length scale, which is proportional to the
geometric mean of the radius and effective thickness. Beyond elastic length
scale, we find that the in-plane elastic moduli stop renormalizing in the axial
direction, while they continue to renormalize in the circumferential direction
beyond the elastic length scale albeit with different universal exponents. The
bending rigidity, however, stops renormalizing in the circumferential direction
at the elastic length scale. These results were verified using molecular
dynamics simulations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:55:40 GMT""}]","2023-05-25"
"2305.14603","Li Zhang","Li Zhang, Hainiu Xu, Abhinav Kommula, Niket Tandon, Chris
  Callison-Burch","OpenPI2.0: An Improved Dataset for Entity Tracking in Texts",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Representing texts as information about entities has long been deemed
effective in event reasoning. We propose OpenPI2.0, an improved dataset for
tracking entity states in procedural texts. OpenPI2.0 features not only
canonicalized entities that facilitate evaluation, but also salience
annotations including both manual labels and automatic predictions. Regarding
entity salience, we provide a survey on annotation subjectivity, modeling
feasibility, and downstream applications in tasks such as question answering
and classical planning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:57:35 GMT""}]","2023-05-25"
"2305.14604","Jason Milionis","Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden","Automated Market Making and Arbitrage Profits in the Presence of Fees","27 pages",,,,"q-fin.MF math.OC q-fin.PM q-fin.PR q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the impact of trading fees on the profits of arbitrageurs trading
against an automated marker marker (AMM) or, equivalently, on the adverse
selection incurred by liquidity providers due to arbitrage. We extend the model
of Milionis et al. [2022] for a general class of two asset AMMs to both
introduce fees and discrete Poisson block generation times. In our setting, we
are able to compute the expected instantaneous rate of arbitrage profit in
closed form. When the fees are low, in the fast block asymptotic regime, the
impact of fees takes a particularly simple form: fees simply scale down
arbitrage profits by the fraction of time that an arriving arbitrageur finds a
profitable trade.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 00:59:32 GMT""}]","2023-05-25"
"2305.14605","Francisco Rodriguez","Francisco Rodr\'iguez","Estimating causal effects of sanctions impacts: what role for
  country-level studies?",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  This article reviews recent advances in addressing empirical identification
issues in cross-country and country-level studies and their implications for
the identification of the effectiveness and consequences of economic sanctions.
I argue that, given the difficulties in assessing causal relationships in
cross-national data, country-level case studies can serve as a useful and
informative complement to cross-national regression studies. However, I also
warn that case studies pose a set of additional potential empirical pitfalls
which can obfuscate rather than clarify the identification of causal mechanisms
at work. Therefore, the most sensible way to read case study evidence is as a
complement rather than as a substitute to cross-national research.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:00:42 GMT""}]","2023-05-25"
"2305.14606","James Schmidt","James Schmidt","Taylor Learning",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Empirical risk minimization stands behind most optimization in supervised
machine learning. Under this scheme, labeled data is used to approximate an
expected cost (risk), and a learning algorithm updates model-defining
parameters in search of an empirical risk minimizer, with the aim of thereby
approximately minimizing expected cost. Parameter update is often done by some
sort of gradient descent. In this paper, we introduce a learning algorithm to
construct models for real analytic functions using neither gradient descent nor
empirical risk minimization. Observing that such functions are defined by local
information, we situate familiar Taylor approximation methods in the context of
sampling data from a distribution, and prove a nonuniform learning result.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:10:58 GMT""}]","2023-05-25"
"2305.14607","Aayushya Agarwal","Aayushya Agarwal, Larry Pileggi","An Equivalent Circuit Approach to Distributed Optimization",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed optimization is an essential paradigm to solve large-scale
optimization problems in modern applications where big-data and
high-dimensionality creates a computational bottleneck. Distributed
optimization algorithms that exhibit fast convergence allow us to fully utilize
computing resources and effectively scale to larger optimization problems in a
myriad of areas ranging from machine learning to power systems. In this work,
we introduce a new centralized distributed optimization algorithm (ECADO)
inspired by an equivalent circuit model of the distributed problem. The
equivalent circuit (EC) model provides a physical analogy to derive new
insights to develop a fast-convergent algorithm. The main contributions of this
approach are: 1) a weighting scheme based on a circuit-inspired aggregate
sensitivity analysis, and 2) an adaptive step-sizing derived from a stable,
Backward-Euler numerical integration. We demonstrate that ECADO exhibits faster
convergence compared to state-of-the art distributed optimization methods and
provably converges for nonconvex problems. We leverage the ECADO features to
solve convex and nonconvex optimization problems with large datasets such as:
distributing data for logistic regression, training a deep neural network model
for classification, and solving a high-dimensional problem security-constrained
optimal power flow problem. Compared to state-of-the-art centralized methods,
including ADMM, centralized gradient descent, and DANE, this new ECADO approach
is shown to converge in fewer iterations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:11:03 GMT""}]","2023-05-25"
"2305.14608","Feiyang Wu","Feiyang Wu, Jingyang Ke, Anqi Wu","Inverse Reinforcement Learning with the Average Reward Criterion",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  We study the problem of Inverse Reinforcement Learning (IRL) with an
average-reward criterion. The goal is to recover an unknown policy and a reward
function when the agent only has samples of states and actions from an
experienced agent. Previous IRL methods assume that the expert is trained in a
discounted environment, and the discount factor is known. This work alleviates
this assumption by proposing an average-reward framework with efficient
learning algorithms. We develop novel stochastic first-order methods to solve
the IRL problem under the average-reward setting, which requires solving an
Average-reward Markov Decision Process (AMDP) as a subproblem. To solve the
subproblem, we develop a Stochastic Policy Mirror Descent (SPMD) method under
general state and action spaces that needs $\mathcal{{O}}(1/\varepsilon)$ steps
of gradient computation. Equipped with SPMD, we propose the Inverse Policy
Mirror Descent (IPMD) method for solving the IRL problem with a
$\mathcal{O}(1/\varepsilon^2)$ complexity. To the best of our knowledge, the
aforementioned complexity results are new in IRL. Finally, we corroborate our
analysis with numerical experiments using the MuJoCo benchmark and additional
control tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:12:08 GMT""}]","2023-05-25"
"2305.14609","Yi-Ming Chen","Yiming Chen, and Sihui Wang, and Dong Xu","Association of stroke lesion distributions with atrial fibrillation
  detected after stroke",,,,,"q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Background Atrial fibrillation is often missed by traditional intermittent
electrocardiogram monitoring after ischemic stroke due to its paroxysmal and
asymptomatic nature. The knowledge of the unique characteristics of the
population with atrial fibrillation detected after stroke (AFDAS) enables more
ischemic stroke patients to benefit from more aggressive anticoagulation
therapy and AF management. Method This is an observational, retrospective, MRI
imaging-based single-center study. Patients with AFDAS were matched in 1:3
ratio with patients without AF (NoAF)and patients with known AF before
stroke(KAF) in PSM model based on age, gender, and time from stroke onset to
admission. Multivariate logistic models were used to test the association of
MRI-based stroke lesion distribution, other clinical parameters and AF. A
backward stepwise elimination regression was conducted to identify the most
important variables. Results Compared to the NoAF group(n=103), the patients
with AFDAS (n=42) had more cortical involvement(p=0.016), as well as
temporal(p<0.001) and insular lobes(p=0.018) infraction. After performing a
backward stepwise elimination model in regression analysis, the temporal lobe
infraction(OR 0.274, 95%CI 0.090-0.838, p=0.023) remained independently
associated with the detection of AF. Compared to the KAF group(n=89), LAD(OR
1.113, 95%CI 1.022-1.211, p=0.014), Number of lobes infarction(p=0.012),
3-lobes involvement(OR 0.177, 95%CI 0.056-0.559, p=0.003), and left hemisphere
lobe involvement(OR 5.966, 95%CI 2.273-15.817, p<0.001)) were independently
associated with AFDAS and KAF. Conclusions Ischemic stroke patients with AF
detected after stroke present more temporal lobe infraction and cortical
involvement. These lesion distribution characteristics with clinical
characteristics together may help in stratifying patients with long-term
cardiac monitoring after stroke.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:14:08 GMT""}]","2023-05-25"
"2305.14610","Bryan Li","Bryan Li, Chris Callison-Burch","This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language
  Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of geopolitical bias -- a tendency to report
different geopolitical knowledge depending on the linguistic context. As a case
study, we consider territorial disputes between countries. For example, for the
widely contested Spratly Islands, would an LM be more likely to say they belong
to China if asked in Chinese, vs. to the Philippines if asked in Tagalog? To
evaluate if such biases exist, we first collect a dataset of territorial
disputes from Wikipedia, then associate each territory with a set of
multilingual, multiple-choice questions. This dataset, termed BorderLines,
consists of 250 territories with questions in 45 languages. We pose these
question sets to language models, and analyze geopolitical bias in their
responses through several proposed quantitative metrics. The metrics compare
between responses in different question languages as well as to the actual
geopolitical situation. The phenomenon of geopolitical bias is a uniquely
cross-lingual evaluation, contrasting with prior work's monolingual (mostly
English) focus on bias evaluation. Its existence shows that the knowledge of
LMs, unlike multilingual humans, is inconsistent across languages.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:16:17 GMT""}]","2023-05-25"
"2305.14611","Mulong Xie","Mulong Xie, Jiaming Ye, Zhenchang Xing, Lei Ma","NiCro: Purely Vision-based, Non-intrusive Cross-Device and
  Cross-Platform GUI Testing",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  To ensure app compatibility and smoothness of user experience across diverse
devices and platforms, developers have to perform cross-device, cross-platform
testing of their apps, which is laborious. There comes a recently increasing
trend of using a record and replay approach to facilitate the testing process.
However, the graphic user interface (GUI) of an app running on different
devices and platforms differs dramatically. This complicates the record and
replay process as the presence, appearance and layout of the GUI widgets in the
recording phase and replaying phase can be inconsistent. Existing techniques
resort to instrumenting into the underlying system to obtain the app metadata
for widget identification and matching between various devices. But such
intrusive practices are limited by the accessibility and accuracy of the
metadata on different platforms. On the other hand, several recent works
attempt to derive the GUI information by analyzing the GUI image. Nevertheless,
their performance is curbed by the applied preliminary visual approaches and
the failure to consider the divergence of the same GUI displayed on different
devices. To address the challenge, we propose a non-intrusive cross-device and
cross-platform system NiCro. NiCro utilizes the state-of-the-art GUI widget
detector to detect widgets from GUI images and then analyses a set of
comprehensive information to match the widgets across diverse devices. At the
system level, NiCro can interact with a virtual device farm and a robotic arm
system to perform cross-device, cross-platform testing non-intrusively. We
first evaluated NiCro by comparing its multi-modal widget and GUI matching
approach with 4 commonly used matching techniques. Then, we further examined
its overall performance on 8 various devices, using it to record and replay 107
test cases of 28 popular apps and the home page to show its effectiveness.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:19:05 GMT""}]","2023-05-25"
"2305.14612","Xiong Zhao","Ziyu Gong, Xiong Zhao, Chen Yang","Assessment of Anterior Cruciate Ligament Injury Risk Based on Human Key
  Points Detection Algorithm","17 pages,and 6 figures",,,,"cs.CV stat.AP","http://creativecommons.org/licenses/by/4.0/","  This paper aims to detect the potential injury risk of the anterior cruciate
ligament (ACL) by proposing an ACL potential injury risk assessment algorithm
based on key points of the human body detected using computer vision
technology. To obtain the key points data of the human body in each frame,
OpenPose, an open source computer vision algorithm, was employed. The obtained
data underwent preprocessing and were then fed into an ACL potential injury
feature extraction model based on the Landing Error Evaluation System (LESS).
This model extracted several important parameters, including the knee flexion
angle, the trunk flexion on the sagittal plane, trunk flexion angle on the
frontal plane, the ankle knee horizontal distance, and the ankle shoulder
horizontal distance. Each of these features was assigned a threshold interval,
and a segmented evaluation function was utilized to score them accordingly. To
calculate the final score of the participant, the score values were input into
a weighted scoring model designed based on the Analytic Hierarchy Process
(AHP). The AHP based model takes into account the relative importance of each
feature in the overall assessment. The results demonstrate that the proposed
algorithm effectively detects the potential risk of ACL injury. The proposed
algorithm demonstrates its effectiveness in detecting ACL injury risk, offering
valuable insights for injury prevention and intervention strategies in sports
and related fields. Code is available at:
https://github.com/ZiyuGong-proj/Assessment-of-ACL-Injury-Risk-Based-on-Openpose
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:22:26 GMT""}]","2023-05-25"
"2305.14613","Jeremy Cole","Jeremy R. Cole, Michael J.Q. Zhang, Daniel Gillick, Julian Martin
  Eisenschlos, Bhuwan Dhingra, and Jacob Eisenstein","Selectively Answering Ambiguous Questions","10 pages, 5 figures, 2 pages of appendix",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trustworthy language models should abstain from answering questions when they
do not know the answer. However, the answer to a question can be unknown for a
variety of reasons. Prior research has focused on the case in which the
question is clear and the answer is unambiguous but possibly unknown. However,
the answer to a question can also be unclear due to uncertainty of the
questioner's intent or context. We investigate question answering from this
perspective, focusing on answering a subset of questions with a high degree of
accuracy, from a set of questions in which many are inherently ambiguous. In
this setting, we find that the most reliable approach to calibration involves
quantifying repetition within a set of sampled model outputs, rather than the
model's likelihood or self-verification as used in prior work. % We find this
to be the case across different types of uncertainty, varying model scales and
both with or without instruction tuning. Our results suggest that
sampling-based confidence scores help calibrate answers to relatively
unambiguous questions, with more dramatic improvements on ambiguous questions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:25:38 GMT""}]","2023-05-25"
"2305.14614","Joseph M. Hellerstein","Joseph M. Hellerstein, Shadaj Laddad, Mae Milano, Conor Power, Mingwei
  Samuel","Invited Paper: Initial Steps Toward a Compiler for Distributed Programs",,"The 5th workshop on Advanced tools, program- ming languages, and
  PLatforms for Implementing and Evaluating algorithms for Distributed systems
  (ApPLIED 2023), June 19, 2023, Orlando, FL, USA","10.1145/3584684.3597272",,"cs.DC cs.DB cs.PL","http://creativecommons.org/licenses/by/4.0/","  In the Hydro project we are designing a compiler toolkit that can optimize
for the concerns of distributed systems, including scale-up and scale-down,
availability, and consistency of outcomes across replicas. This invited paper
overviews the project, and provides an early walk-through of the kind of
optimization that is possible. We illustrate how type transformations as well
as local program transformations can combine, step by step, to convert a
single-node program into a variety of distributed design points that offer the
same semantics with different performance and deployment characteristics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:28:01 GMT""}]","2023-05-25"
"2305.14615","Hyungsung Yun","Ki-Ahm Lee and Hyungsung Yun","Boundary Regularity for viscosity solutions of Fully nonlinear
  degenerate/singular parabolic equations","30 pages",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we establish the boundary regularity results for viscosity
solutions of fully nonlinear degenerate/singular parabolic equations of the
form $$u_t - x_n^{\gamma} F(D^2 u,x,t) = f,$$ where $\gamma<1$. These equations
are motivated by the porous media type equations. We show the boundary
$C^{1,\alpha}$-regularity of functions in their solutions class and the
boundary $C^{2,\alpha}$-regularity of solutions. As an application, we derive
the global regularity results and the solvability of the Cauchy-Dirichlet
problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:29:06 GMT""}]","2023-05-25"
"2305.14616","Pin-Er Chen","Pin-Er Chen, Hsin-Yu Chou, Po-Ya Angela Wang, Yu-Hsiang Tseng, Shu-Kai
  Hsieh","Exploring the Grounding Issues in Image Caption","10 pages, 10 figures",,,,"cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores the grounding issue concerning multimodal semantic
representation from a computational cognitive-linguistic view. Five perceptual
properties of groundedness are annotated and analyzed: Affordance, Perceptual
salience, Object number, Gaze cueing, and Ecological Niche Association (ENA).
We annotated selected images from the Flickr30k dataset with exploratory
analyses and statistical modeling of their captions. Our findings suggest that
a comprehensive understanding of an object or event requires cognitive
attention, semantic distinctions in linguistic expression, and multimodal
construction. During this construction process, viewers integrate situated
meaning and affordance into multimodal semantics, which is consolidated into
image captions used in the image-text dataset incorporating visual and textual
elements. Our findings suggest that situated meaning and affordance grounding
are critical for grounded natural language understanding systems to generate
appropriate responses and show the potential to advance the understanding of
human construal in diverse situations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:30:50 GMT""}]","2023-05-25"
"2305.14617","Sahithya Ravi","Sahithya Ravi, Raymond Ng, Vered Shwartz","COMET-M: Reasoning about Multiple Events in Complex Sentences",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the speaker's intended meaning often involves drawing
commonsense inferences to reason about what is not stated explicitly. In
multi-event sentences, it requires understanding the relationships between
events based on contextual knowledge. We propose COMET-M (Multi-Event), an
event-centric commonsense model capable of generating commonsense inferences
for a target event within a complex sentence. COMET-M builds upon COMET
(Bosselut et al., 2019), which excels at generating event-centric inferences
for simple sentences, but struggles with the complexity of multi-event
sentences prevalent in natural text. To overcome this limitation, we curate a
multi-event inference dataset of 35K human-written inferences. We trained
COMET-M on the human-written inferences and also created baselines using
automatically labeled examples. Experimental results demonstrate the
significant performance improvement of COMET-M over COMET in generating
multi-event inferences. Moreover, COMET-M successfully produces distinct
inferences for each target event, taking the complete context into
consideration. COMET-M holds promise for downstream tasks involving natural
text such as coreference resolution, dialogue, and story understanding.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:35:01 GMT""}]","2023-05-25"
"2305.14618","Wenting Zhao","Wenting Zhao and Justin T. Chiu and Claire Cardie and Alexander M.
  Rush","Abductive Commonsense Reasoning Exploiting Mutually Exclusive
  Explanations","accepted at ACL'23",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Abductive reasoning aims to find plausible explanations for an event. This
style of reasoning is critical for commonsense tasks where there are often
multiple plausible explanations. Existing approaches for abductive reasoning in
natural language processing (NLP) often rely on manually generated annotations
for supervision; however, such annotations can be subjective and biased.
Instead of using direct supervision, this work proposes an approach for
abductive commonsense reasoning that exploits the fact that only a subset of
explanations is correct for a given context. The method uses posterior
regularization to enforce a mutual exclusion constraint, encouraging the model
to learn the distinction between fluent explanations and plausible ones. We
evaluate our approach on a diverse set of abductive reasoning datasets;
experimental results show that our approach outperforms or is comparable to
directly applying pretrained language models in a zero-shot manner and other
knowledge-augmented zero-shot methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:35:10 GMT""}]","2023-05-25"
"2305.14619","Satoru Hayami","Satoru Hayami, Ryota Yambe","Field-direction-dependent skyrmion crystals in noncentrosymmetric cubic
  magnets: A comparison between point groups $(O,T)$ and $T_{\rm d}$","11 pages, 11 figures, accepted for publication in PRB",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the instability toward a skyrmion crystal (SkX) in
noncentrosymmetric cubic magnets with an emphasis on a comparison between point
groups $(O,T)$ and $T_{\rm d}$. By constructing low-temperature magnetic phase
diagrams under an external magnetic field for three directions based on
numerically simulated annealing, we find that the system under the point group
$(O,T)$ exhibits different two types of SkXs depending on the field direction,
while that under $T_{\rm d}$ does not show such an instability. The difference
between them is understood from the difference in the momentum-dependent
Dzyaloshinskii-Moriya interaction under each point group. Meanwhile, we show
that the system under $T_{\rm d}$ leads to the SkX instability by considering
an additional effect of the uniaxial strain, which lowers the symmetry to
$D_{\rm 2d}$. We obtain two different SkXs: N\'eel-type and anti-type SkXs, the
former of which is stabilized in the presence of the interactions at the
three-dimensional ordering wave vectors. The present results provide rich
topological spin textures in the three-dimensional systems, which are sensitive
to the magnetic-field direction and point-group symmetry.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:36:36 GMT""}]","2023-05-25"
"2305.14620","ChongYang Liu","ChongYang Liu, XiaoMin Shen, Bin Zhou, Jun Gao","Automated calculation of Jet fragmentation at NLO in QCD","35 pages, 15 figures, 3 tables; comments are welcome",,,,"hep-ph hep-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  We present FMNLO, a framework to combine general-purpose Monte Carlo
generators and fragmentation functions (FFs). It is based on a hybrid scheme of
phase-space slicing method and local subtraction method, and accurate to
next-to-leading order (NLO) in QCD. The new framework has been interfaced to
MG5 aMC@NLO and made publicly available in this work. We demonstrate its unique
ability by giving theoretical predictions of various fragmentation measurements
at the LHC, followed by comparison with the data. With the help of
interpolation techniques, FMNLO allows for fast calculation of fragmentation
processes for a large number of different FFs, which makes it a promising tool
for future fits of FFs. As an example, we perform a NLO fit of parton
fragmentation functions to unidentified charged hadrons using measurements at
the LHC. We find the ATLAS data from inclusive dijet production show a strong
constraining power. Notable disparities are found between our gluon FF and that
of BKK, DSS and NNFF, indicating the necessities of additional constraints and
data for gluon fragmentation function.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:37:57 GMT""}]","2023-05-25"
"2305.14621","Setareh Dabiri","Setareh Dabiri, Vasileios Lioutas, Berend Zwartsenberg, Yunpeng Liu,
  Matthew Niedoba, Xiaoxuan Liang, Dylan Green, Justice Sefas, Jonathan Wilder
  Lavington, Frank Wood, Adam Scibior","Realistically distributing object placements in synthetic training data
  improves the performance of vision-based object detection models",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  When training object detection models on synthetic data, it is important to
make the distribution of synthetic data as close as possible to the
distribution of real data. We investigate specifically the impact of object
placement distribution, keeping all other aspects of synthetic data fixed. Our
experiment, training a 3D vehicle detection model in CARLA and testing on
KITTI, demonstrates a substantial improvement resulting from improving the
object placement distribution.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:39:41 GMT""}]","2023-05-25"
"2305.14622","Debaditya Shome","Debaditya Shome, Kuldeep Yadav","EXnet: Efficient In-context Learning for Data-less Text classification",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Large pre-trained language models (PLMs) have made significant progress in
encoding world knowledge and spawned a new set of learning paradigms including
zero-shot, few-shot, and in-context learning. Many language tasks can be
modeled as a set of prompts (for example, is this text about geography?) and
language models can provide binary answers, i.e., Yes or No. There is evidence
to suggest that the next-word prediction used by many PLMs does not align well
with zero-shot paradigms. Therefore, PLMs are fine-tuned as a
question-answering system. In-context learning extends zero-shot learning by
incorporating prompts and examples, resulting in increased task accuracy. Our
paper presents EXnet, a model specifically designed to perform in-context
learning without any limitations on the number of examples. We argue that
in-context learning is an effective method to increase task accuracy, and
providing examples facilitates cross-task generalization, especially when it
comes to text classification tasks. With extensive experiments, we show that
even our smallest model (15M parameters) generalizes to several unseen
classification tasks and domains.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:40:57 GMT""}]","2023-05-25"
"2305.14623","Miaoran Li","Miaoran Li, Baolin Peng, Zhu Zhang","Self-Checker: Plug-and-Play Modules for Fact-Checking with Large
  Language Models",,,,,"cs.CL","http://creativecommons.org/publicdomain/zero/1.0/","  Fact-checking is an essential task in NLP that is commonly utilized for
validating the factual accuracy of claims. Prior work has mainly focused on
fine-tuning pre-trained languages models on specific datasets, which can be
computationally intensive and time-consuming. With the rapid development of
large language models (LLMs), such as ChatGPT and GPT-3, researchers are now
exploring their in-context learning capabilities for a wide range of tasks. In
this paper, we aim to assess the capacity of LLMs for fact-checking by
introducing Self-Checker, a framework comprising a set of plug-and-play modules
that facilitate fact-checking by purely prompting LLMs in an almost zero-shot
setting. This framework provides a fast and efficient way to construct
fact-checking systems in low-resource environments. Empirical results
demonstrate the potential of Self-Checker in utilizing LLMs for fact-checking.
However, there is still significant room for improvement compared to SOTA
fine-tuned models, which suggests that LLM adoption could be a promising
approach for future fact-checking research.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:46:07 GMT""}]","2023-05-25"
"2305.14624","Prashant Singh Dr","Ashish Kumar, Prashant Singh, Manoj K. Harbola","Density Functional Theory of Material Design$:$ Fundamentals and
  Applications$-II$","41 pages, 4 figures, 4 table",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the second and the final part of the review on density functional
theory (DFT), referred to as DFT-II. In the first review, DFT-I, we have
discussed wavefunction-based methods, their complexity, and the basic of
density functional theory. In DFT-II, we focus on fundamentals of DFT and their
implications for the betterment of the theory. We start our presentation with
the exact DFT result followed by the concept of exchange-correlation (xc) or
Fermi-Coulomb hole and its relation with xc energy functional. We also provide
the exact conditions for the xc-hole, xc-energy and xc-potential along with
their physical interpretation. Next, we describe the extension of DFT for
non-integer numbers of electrons, the piecewise linearity of total energy and
discontinuity of chemical potential at integer particle numbers, and derivative
discontinuity of the xc potential, which has consequences on fundamental gap of
solids. After that, we present how one obtain more accurate xc energy
functionals by going beyond LDA. We discuss the gradient expansion
approximation (GEA), generalized gradient approximation (GGA), and hybrid
functional approaches to designing better xc energy functionals that give
accurate total energies but fail to predict properties like the ionization
potential and the band gap. Thus, we describe different methods of modeling
these potentials and the results of their application for the calculation of
the band gaps of different solids to highlight accuracy of different xc
potential. Finally, we conclude with a glimpse on orbital-free density
functional theory and the machine learning approach .
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:48:26 GMT""}]","2023-05-25"
"2305.14625","Shufan Wang","Shufan Wang, Yixiao Song, Andrew Drozdov, Aparna Garimella, Varun
  Manjunatha, Mohit Iyyer","KNN-LM Does Not Improve Open-ended Text Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the generation quality of interpolation-based
retrieval-augmented language models (LMs). These methods, best exemplified by
the KNN-LM, interpolate the LM's predicted distribution of the next word with a
distribution formed from the most relevant retrievals for a given prefix. While
the KNN-LM and related methods yield impressive decreases in perplexity, we
discover that they do not exhibit corresponding improvements in open-ended
generation quality, as measured by both automatic evaluation metrics (e.g.,
MAUVE) and human evaluations. Digging deeper, we find that interpolating with a
retrieval distribution actually increases perplexity compared to a baseline
Transformer LM for the majority of tokens in the WikiText-103 test set, even
though the overall perplexity is lower due to a smaller number of tokens for
which perplexity dramatically decreases after interpolation. However, when
decoding a long sequence at inference time, significant improvements on this
smaller subset of tokens are washed out by slightly worse predictions on most
tokens. Furthermore, we discover that the entropy of the retrieval distribution
increases faster than that of the base LM as the generated sequence becomes
longer, which indicates that retrieval is less reliable when using
model-generated text as queries (i.e., is subject to exposure bias). We hope
that our analysis spurs future work on improved decoding algorithms and
interpolation strategies for retrieval-augmented language models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:48:33 GMT""}]","2023-05-25"
"2305.14626","Alexis Virelizier","Francesco Costantino, Nathan Geer, Bertrand Patureau-Mirand, Alexis
  Virelizier","Chromatic maps for finite tensor categories","14 pages",,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chromatic maps for spherical tensor categories are instrumental tools to
construct (non semisimple) invariants of 3-manifolds and their extension to
(non compact) (2+1)-TQFTs. In this paper, we introduce left and right chromatic
maps for finite tensor categories and prove that such maps always exist. As a
corollary, we obtain that any spherical finite tensor category has a chromatic
map.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:53:26 GMT""}]","2023-05-25"
"2305.14627","Tianyu Gao","Tianyu Gao, Howard Yen, Jiatong Yu, Danqi Chen","Enabling Large Language Models to Generate Text with Citations","Code and data are available at https://github.com/princeton-nlp/ALCE",,,,"cs.CL cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have emerged as a widely-used tool for
information seeking, but their generated outputs are prone to hallucination. In
this work, we aim to enable LLMs to generate text with citations, improving
their factual correctness and verifiability. Existing work mainly relies on
commercial search engines and human evaluation, making it challenging to
reproduce and compare with different modeling approaches. We propose ALCE, the
first benchmark for Automatic LLMs' Citation Evaluation. ALCE collects a
diverse set of questions and retrieval corpora and requires building end-to-end
systems to retrieve supporting evidence and generate answers with citations. We
build automatic metrics along three dimensions -- fluency, correctness, and
citation quality -- and demonstrate their strong correlation with human
judgements. Our experiments with state-of-the-art LLMs and novel prompting
strategies show that current systems have considerable room for improvements --
for example, on the ELI5 dataset, even the best model has 49% of its
generations lacking complete citation support. Our extensive analyses further
highlight promising future directions, including developing better retrievers,
advancing long-context LLMs, and improving the ability to synthesize
information from multiple sources.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:53:49 GMT""}]","2023-05-25"
"2305.14628","Chenglei Si","Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer, Jordan
  Boyd-Graber","Mixture of Prompt Experts for Generalizable and Interpretable Question
  Answering",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  One of the ultimate quests of question answering (QA) is to deploy a system
that can answer any type of question from the users, and refrain from answering
when it does not know the answer. While recent advancements in scaling large
language models (LLMs) brought significant improvements on various QA datasets,
it remains difficult for a single model to generalize across question types
that require distinct reasoning abilities. In this paper, we first provide
empirical evidence that state-of-the-art LLMs such as Codex suffer from poor
generalizability on question types beyond those seen in the prompt. To address
this, we propose a Mixture-of-Prompt-Experts (MOPE) system that ensembles
multiple specialized LLMs. We first implement each specialized model based on
the same backbone model (Codex) but with prompts optimized for different
reasoning categories including factual, multihop, mathematical, and commonsense
reasoning. By strategically selecting the best specialized model for each given
question, our MOPE system significantly outperforms any single specialized
model on a collection of 12 QA datasets from four reasoning types. Moreover,
the attribution and agreement among specialized expert models offer greater
interpretability, allowing for better selective question answering. Our human
study further confirms that presenting the expert predictions and answer
selection process helps annotators more accurately decide when to trust the
system's output. We release all code and data to facilitate future work.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:00:51 GMT""}]","2023-05-25"
"2305.14629","Zhesi Shen","Zhesi Shen, Liying Yang, Jinshan Wu","Two indicators rule them all: Mean and standard deviation used to
  calculate other journal indicators based on log-normal distribution of
  citation counts",,,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two journal-level indicators, respectively the mean ($m^i$) and the standard
deviation ($v^i$) are proposed to be the core indicators of each journal and we
show that quite several other indicators can be calculated from those two core
indicators, assuming that yearly citation counts of papers in each journal
follows more or less a log-normal distribution. Those other journal-level
indicators include journal h index, journal one-by-one-sample comparison
citation success index $S_j^i$, journal multiple-sample $K^i-K^j$ comparison
success rate $S_{j,K^j}^{i,K^i }$, and minimum representative sizes
$\kappa_j^i$ and $\kappa_i^j$, the average ranking of all papers in a journal
in a set of journals($R^t$). We find that those indicators are consistent with
those calculated directly using the raw citation data
($C^i=\{c_1^i,c_2^i,\dots,c_{N^i}^i \},\forall i$) of journals. In addition to
its theoretical significance, the ability to estimate other indicators from
core indicators has practical implications. This feature enables individuals
who lack access to raw citation count data to utilize other indicators by
simply using core indicators, which are typically easily accessible.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:02:05 GMT""}]","2023-05-25"
"2305.14630","Sam Musker","Sam Musker, Ellie Pavlick","Testing Causal Models of Word Meaning in GPT-3 and -4","Unabridged version. Code available at
  https://github.com/smusker/Causal_Models_Of_Word_Meaning",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Language Models (LLMs) have driven extraordinary improvements in NLP.
However, it is unclear how such models represent lexical concepts-i.e., the
meanings of the words they use. This paper evaluates the lexical
representations of GPT-3 and GPT-4 through the lens of HIPE theory, a theory of
concept representations which focuses on representations of words describing
artifacts (such as ""mop"", ""pencil"", and ""whistle""). The theory posits a causal
graph that relates the meanings of such words to the form, use, and history of
the objects to which they refer. We test LLMs using the same stimuli originally
used by Chaigneau et al. (2004) to evaluate the theory in humans, and consider
a variety of prompt designs. Our experiments concern judgements about causal
outcomes, object function, and object naming. We find no evidence that GPT-3
encodes the causal structure hypothesized by HIPE, but do find evidence that
GPT-4 encodes such structure. The results contribute to a growing body of
research characterizing the representational capacity of large language models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:03:23 GMT""}]","2023-05-25"
"2305.14631","Ying Liu","BESIII Collaboration: M. Ablikim, M. N. Achasov, P. Adlarson, R.
  Aliberti, A. Amoroso, M. R. An, Q. An, Y. Bai, O. Bakina, I. Balossino, Y.
  Ban, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D.
  Bettoni, F. Bianchi, E. Bianco, J. Bloms, A. Bortone, I. Boyko, R. A. Briere,
  A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A.
  Cetin, J. F. Chang, T. T. Chang, W. L. Chang, G. R. Che, G. Chelkov, C. Chen,
  Chao Chen, G. Chen, H. S. Chen, M. L. Chen, S. J. Chen, S. M. Chen, T. Chen,
  X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, W. S. Cheng, S.
  K. Choi, X. Chu, G. Cibinetto, S. C. Coen, F. Cossio, J. J. Cui, H. L. Dai,
  J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, Z. Y. Deng, A. Denig, I.
  Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding,
  J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, S. X. Du, Z. H. Duan, P. Egorov,
  Y.H. Y. Fan, Y. L. Fan, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, R.
  Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, K
  Fischer, M. Fritsch, C. Fritzsch, C. D. Fu, Y. W. Fu, H. Gao, Y. N. Gao, Yang
  Gao, S. Garbolino, I. Garzia, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A
  Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M.
  H. Gu, Y. T. Gu, C. Y Guan, Z. L. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R.
  P. Guo, Y. P. Guo, A. Guskov, T. T. Han, W. Y. Han, X. Q. Hao, F. A. Harris,
  K. K. He, K. L. He, F. H. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T.
  Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, H. M. Hu,
  J. F. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang,
  Y. P. Huang, T. Hussain, N H\""usken, W. Imoehl, J. Jackson, S. Jaeger, S.
  Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q.
  Jia, Z. K. Jia, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang,
  J. B. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, T. Johansson, X. K., S.
  Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, R. Kappert, M.
  Kavatsyuk, B. C. Ke, A. Khoukaz, R. Kiuchi, R. Kliemt, O. B. Kolcu, B. Kopf,
  M. Kuessner, A. Kupsc, W. K\""uhn, J. J. Lane, P. Larin, A. Lavania, L.
  Lavezzi, T. T. Lei, Z. H. Lei, H. Leithoff, M. Lellmann, T. Lenz, C. Li, C.
  Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. Li, H. B. Li, H. J. Li, H.
  N. Li, Hui Li, J. R. Li, J. S. Li, J. W. Li, K. L. Li, Ke Li, L. J Li, L. K.
  Li, Lei Li, M. H. Li, P. R. Li, Q. X. Li, S. X. Li, T. Li, W. D. Li, W. G.
  Li, X. H. Li, X. L. Li, Xiaoyu Li, Y. G. Li, Z. J. Li, Z. X. Li, Z. Y. Li, C.
  Liang, H. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L.
  Z. Liao, J. Libby, A. Limphirat, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C.
  Liu, C. X. Liu, D. Liu, F. H. Liu, Fang Liu, Feng Liu, G. M. Liu, H. Liu, H.
  B. Liu, H. M. Liu, Huanhuan Liu, Huihui Liu, J. B. Liu, J. L. Liu, J. Y. Liu,
  K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu,
  Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, Y. Liu, Y. B. Liu,
  Z. A. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y.
  Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu,
  Y. F. Lyu, F. C. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q.
  Ma, R. T. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S.
  Maldaner, S. Malde, Q. A. Malik, A. Mangoni, Y. J. Mao, Z. P. Mao, S.
  Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R.
  E. Mitchell, X. H. Mo, N. Yu. Muchnoi, Y. Nefedov, F. Nerling, I. B.
  Nikolaev, Z. Ning, S. Nisar, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X.
  Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, K.
  Peters, J. L. Ping, R. G. Ping, S. Plura, S. Pogodin, V. Prasad, F. Z. Qi, H.
  Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, J. J. Qin, L.
  Q. Qin, X. P. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, S. Q. Qu, C. F. Redmer,
  K. J. Ren, A. Rivetti, V. Rodin, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N.
  Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan,
  W. Shan, X. Y. Shan, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F.
  Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q.
  Q. Shi, R. S. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y.
  X. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H.
  Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y.
  Sun, Y. J. Sun, Y. Z. Sun, Z. T. Sun, Y. X. Tan, C. J. Tang, G. Y. Tang, J.
  Tang, Y. A. Tang, L. Y Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H.
  Tian, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, S. J. Wang, B. Wang, B. L.
  Wang, Bo Wang, C. W. Wang, D. Y. Wang, F. Wang, H. J. Wang, H. P. Wang, J. P.
  Wang, K. Wang, L. L. Wang, M. Wang, Meng Wang, S. Wang, S. Wang, T. Wang, T.
  J. Wang, W. Wang, W. Wang, W. H. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J.
  Wang, X. L. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. H. Wang, Y. N. Wang, Y.
  Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D.
  Wei, D. H. Wei, F. Weidner, S. P. Wen, C. W. Wenzel, U. Wiedner, G.
  Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X.
  Wu, X. H. Wu, Y. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, T. Xiang, D. Xiao,
  G. Y. Xiao, H. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie,
  Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G.
  F. Xu, H. Y. Xu, Q. J. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z.
  S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L.
  Yang, H. X. Yang, Tao Yang, Y. Yang, Y. F. Yang, Y. X. Yang, Yifan Yang, Z.
  W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X.
  Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, C. Z. Yuan, L. Yuan, S. C. Yuan, X. Q.
  Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, X. Zeng, Y.
  Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L.
  Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. H. Zhang, H. H.
  Zhang, H. Q. Zhang, H. Y. Zhang, J. Zhang, J. J. Zhang, J. Q. Zhang, J. W.
  Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, Jiawei Zhang, L.
  M. Zhang, L. Q. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, Shuihan Zhang,
  Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Xuyan Zhang, Y. Zhang,
  Y. T. Zhang, Y. H. Zhang, Yan Zhang, Yao Zhang, Z. H. Zhang, Z. L. Zhang, Z.
  Y. Zhang, Z. Y. Zhang, G. Zhao, J. Zhao, J. Y. Zhao, J. Z. Zhao, Lei Zhao,
  Ling Zhao, M. G. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A.
  Zhemchugov, B. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X.
  Zhong, H. Zhou, L. P. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y.
  Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu,
  T. J. Zhu, W. J. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu","Determination of spin and parity of $D^{*}_{(s)}$ mesons",,,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spin and parity of the charmed mesons $D_{s}^{*+}$, $D^{*0}$ and $D^{*+}$
are determined for the first time to be $J^P=1^{-}$ with significances greater
than 10$\sigma$ over other hypotheses of $2^{+}$ and $3^{-}$, using an $e^+e^-$
collision data sample with an integrated luminosity of 3.19 fb$^{-1}$ collected
by the BESIII detector at a center-of-mass energy of 4.178 GeV. Different
spin-parity hypotheses for $D_{s}^{*+}$, $D^{*0}$, and $D^{*+}$ mesons are
tested via a helicity amplitude analysis of the processes $e^+e^-\to
D^{*+}_{s}D^{-}_{s}$, $D^{*0}D^{0}$ and $D^{*+}D^{-}$, with $D^{*+}_{s}\to
D^{+}_{s} \gamma$, $D^{*0}\to D^{0}\pi^{0}$, and $D^{*+}\to D^{+}\pi^{0}$. The
results confirm the quark model predictions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:05:34 GMT""}]","2023-05-25"
"2305.14632","Rishi Sonthalia","Rishi Sonthalia and Anna Seigal and Guido Montufar","Supermodular Rank: Set Function Decomposition and Optimization",,,,,"math.CO cs.CC cs.DM cs.LG math.OC","http://creativecommons.org/licenses/by/4.0/","  We define the supermodular rank of a function on a lattice. This is the
smallest number of terms needed to decompose it into a sum of supermodular
functions. The supermodular summands are defined with respect to different
partial orders. We characterize the maximum possible value of the supermodular
rank and describe the functions with fixed supermodular rank. We analogously
define the submodular rank. We use submodular decompositions to optimize set
functions. Given a bound on the submodular rank of a set function, we formulate
an algorithm that splits an optimization problem into submodular subproblems.
We show that this method improves the approximation ratio guarantees of several
algorithms for monotone set function maximization and ratio of set functions
minimization, at a computation overhead that depends on the submodular rank.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:09:28 GMT""}]","2023-05-25"
"2305.14633","Li Luo","Weideng Cui, Li Luo and Zheming Xu","Asymptotic Schur algebras and cellularity of q-Schur algebras","28 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the q-Schur algebras of finite type introduced in [LW22] are
cellular in the sense of Graham and Lehrer, which is a generalization of Geck's
theorem on the cellularity of Hecke algebras of finite type. Moreover, we study
special modules of the associated asymptotic Schur algebras and left cell
representations of Schur algebras, which generalize Lusztig's work about
special modules of asymptotic Hecke algebras and left cell representations of
Weyl groups, respectively.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:12:31 GMT""}]","2023-05-25"
"2305.14634","Prashant Singh Dr","Prashant Singh, Manoj K Harbola","Density Functional Theory of Material Design: Fundamentals and
  Applications -- I","44 pages, 3 figures, 5 tables","Oxford Open Materials Science, Volume 1, Issue 1, 2021, itab018","10.1093/oxfmat/itab018",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article is part-I of a review of density-functional theory (DFT) that is
the most widely used method for calculating electronic structure of materials.
The accuracy and ease of numerical implementation of DFT methods has resulted
in its extensive use for materials design and discovery and has thus ushered in
the new field of computational material science. In this article we start with
an introduction to Schr\""odinger equation and methods of its solutions. After
presenting exact results for some well-known systems, difficulties encountered
in solving the equation for interacting electrons are described. How these
difficulties are handled using the variational principle for the energy to
obtain approximate solutions of the Schr\""odinger equation is discussed. The
resulting Hartree and Hartree-Fock theories are presented along with results
they give for atomic and solid-state systems. We then describe Thomas-Fermi
theory and its extensions which were the initial attempts to formulate
many-electron problem in terms of electronic density of a system. Having
described these theories, we introduce modern density functional theory by
discussing Hohenberg-Kohn theorems that form its foundations. We then go on to
discuss Kohn-Sham formulation of density-functional theory in its exact form.
Next, local density approximation is introduced and solutions of Kohn-Sham
equation for some representative systems, obtained using the local density
approximation, are presented. We end part-I of the review describing the
contents of part-II.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:12:55 GMT""}]","2023-05-25"
"2305.14635","Yan Zhou","Yan Zhou, Qingkai Fang, Yang Feng","CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation","ACL 2023 main conference",,,,"cs.CL cs.AI cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  End-to-end speech translation (ST) is the task of translating speech signals
in the source language into text in the target language. As a cross-modal task,
end-to-end ST is difficult to train with limited data. Existing methods often
try to transfer knowledge from machine translation (MT), but their performances
are restricted by the modality gap between speech and text. In this paper, we
propose Cross-modal Mixup via Optimal Transport CMOT to overcome the modality
gap. We find the alignment between speech and text sequences via optimal
transport and then mix up the sequences from different modalities at a token
level using the alignment. Experiments on the MuST-C ST benchmark demonstrate
that CMOT achieves an average BLEU of 30.0 in 8 translation directions,
outperforming previous methods. Further analysis shows CMOT can adaptively find
the alignment between modalities, which helps alleviate the modality gap
between speech and text. Code is publicly available at
https://github.com/ictnlp/CMOT.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:13:48 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 08:55:41 GMT""}]","2023-05-26"
"2305.14636","Sakander Hayat","Jack H. Koolen, Mamoon Abdullah, Brhane Gebremichel, Sakander Hayat","Distance-regular graphs with exactly one positive $q$-distance
  eigenvalue","19 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the $q$-distance matrix for a distance-regular graph
and show that the $q$-distance matrix of a distance-regular graph with
classical parameters ($D, q, \alpha, \beta$) has exactly three distinct
eigenvalues, of which one is zero. Moreover, we study distance-regular graphs
whose $q$-distance matrix has exactly one positive eigenvalue.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:16:19 GMT""}]","2023-05-25"
"2305.14637","Davit Soselia","Davit Soselia, Khalid Saifullah, and Tianyi Zhou","Reinforcement Learning finetuned Vision-Code Transformer for UI-to-Code
  Generation",,,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated HTML/CSS code generation from screenshots is an important yet
challenging problem with broad applications in website development and design.
In this paper, we present a novel vision-code transformer approach that
leverages an Encoder-Decoder architecture as well as explore actor-critic
fine-tuning as a method for improving upon the baseline. For this purpose, two
image encoders are compared: Vision Transformer (ViT) and Document Image
Transformer (DiT).
  We propose an end-to-end pipeline that can generate high-quality code
snippets directly from screenshots, streamlining the website creation process
for developers. To train and evaluate our models, we created a synthetic
dataset of 30,000 unique pairs of code and corresponding screenshots.
  We evaluate the performance of our approach using a combination of automated
metrics such as MSE, BLEU, IoU, and a novel htmlBLEU score, where our models
demonstrated strong performance. We establish a strong baseline with the
DiT-GPT2 model and show that actor-critic can be used to improve IoU score from
the baseline of 0.64 to 0.79 and lower MSE from 12.25 to 9.02. We achieved
similar performance as when using larger models, with much lower computational
cost.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:17:32 GMT""}]","2023-05-25"
"2305.14638","Nikolay Yegovtsev","Nikolay Yegovtsev and Victor Gurarie","Effective mass and interaction energy of heavy Bose polarons at
  unitarity","5 pages, 0 figures",,,,"cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We study the motion of a heavy impurity immersed in a weakly interacting BEC
using the Gross-Pitaevskii equation (GPe). We construct a perturbative solution
to the GPe in powers of impurity velocity in the case when the boson-impurity
potential is tuned to unitarity and calculate the effective mass of the
polaron. In addition, we calculate the interaction energy of two unitary
polarons which are sufficiently far apart. Our formalism also reproduces the
results for both the mass and interaction energy obtained at weak
boson-impurity coupling.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:17:44 GMT""}]","2023-05-25"
"2305.14639","Ruizhe Chen","Ruizhe Chen (1), Sanjib Basu (2), Qian Shi (3) ((1) Johns Hopkins
  University, (2) University of Illinois Chicago, (3) Mayo Clinic)","Restricted Mean Survival Time Estimation Using Bayesian Nonparametric
  Dependent Mixture Models",,,,,"stat.ME stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Restricted mean survival time (RMST) is an intuitive summary statistic for
time-to-event random variables, and can be used for measuring treatment
effects. Compared to hazard ratio, its estimation procedure is robust against
the non-proportional hazards assumption. We propose nonparametric Bayeisan
(BNP) estimators for RMST using a dependent stick-breaking process prior
mixture model that adjusts for mixed-type covariates. The proposed Bayesian
estimators can yield both group-level causal estimate and subject-level
predictions. Besides, we propose a novel dependent stick-breaking process prior
that on average results in narrower credible intervals while maintaining
similar coverage probability compared to a dependent probit stick-breaking
process prior. We conduct simulation studies to investigate the performance of
the proposed BNP RMST estimators compared to existing frequentist approaches
and under different Bayesian modeling choices. The proposed framework is
applied to estimate the treatment effect of an immuno therapy among KRAS
wild-type colorectal cancer patients.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:18:14 GMT""}]","2023-05-25"
"2305.14640","Simin Keykhosravi","Simin Keykhosravi and Ebrahim Bedeer","Pilot Design and Doubly-Selective Channel Estimation for
  Faster-than-Nyquist Signaling","In preparation to submit to a Journal",,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  Being capable of enhancing the spectral efficiency (SE), faster-than-Nyquist
(FTN) signaling is a promising approach for wireless communication systems.
This paper investigates the doubly-selective (i.e., time- and
frequency-selective) channel estimation and data detection of FTN signaling. We
consider the intersymbol interference (ISI) resulting from both the FTN
signaling and the frequency-selective channel and adopt an efficient frame
structure with reduced overhead. We propose a novel channel estimation
technique of FTN signaling based on the least sum of squared errors (LSSE)
approach to estimate the complex channel coefficients at the pilot locations
within the frame. In particular, we find the optimal pilot sequence that
minimizes the mean square error (MSE) of the channel estimation. To address the
time-selective nature of the channel, we use a low-complexity linear
interpolation to track the complex channel coefficients at the data symbols
locations within the frame. To detect the data symbols of FTN signaling, we
adopt a turbo equalization technique based on a linear soft-input soft-output
(SISO) minimum mean square error (MMSE) equalizer. Simulation results show that
the MSE of the proposed FTN signaling channel estimation employing the designed
optimal pilot sequence is lower than its counterpart designed for conventional
Nyquist transmission. The bit error rate (BER) of the FTN signaling employing
the proposed optimal pilot sequence shows improvement compared to the FTN
signaling employing the conventional Nyquist pilot sequence. Additionally, for
the same SE, the proposed FTN signaling channel estimation employing the
designed optimal pilot sequence shows better performance when compared to
competing techniques from the literature.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:18:32 GMT""}]","2023-05-25"
"2305.14641","Zhe Wang","Zhe Wang, ZhiJie He, Ding Liu","Graph Analysis Using a GPU-based Parallel Algorithm: Quantum Clustering",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article introduces a new method for applying Quantum Clustering to graph
structures. Quantum Clustering (QC) is a novel density-based unsupervised
learning method that determines cluster centers by constructing a potential
function. In this method, we use the Graph Gradient Descent algorithm to find
the centers of clusters. GPU parallelization is utilized for computing
potential values. We also conducted experiments on five widely used datasets
and evaluated using four indicators. The results show superior performance of
the method. Finally, we discuss the influence of $\sigma$ on the experimental
results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:22:00 GMT""},{""version"":""v2"",""created"":""Sun, 28 May 2023 10:20:47 GMT""}]","2023-05-30"
"2305.14642","Lingbing Guo","Lingbing Guo, Weiqing Wang, Zhuo Chen, Ningyu Zhang, Zequn Sun, Yixuan
  Lai, Qiang Zhang, and Huajun Chen","Newton-Cotes Graph Neural Networks: On the Time Evolution of Dynamic
  Systems","Under review",,,,"cs.LG cs.CE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reasoning system dynamics is one of the most important analytical approaches
for many scientific studies. With the initial state of a system as input, the
recent graph neural networks (GNNs)-based methods are capable of predicting the
future state distant in time with high accuracy. Although these methods have
diverse designs in modeling the coordinates and interacting forces of the
system, we show that they actually share a common paradigm that learns the
integration of the velocity over the interval between the initial and terminal
coordinates. However, their integrand is constant w.r.t. time. Inspired by this
observation, we propose a new approach to predict the integration based on
several velocity estimations with Newton-Cotes formulas and prove its
effectiveness theoretically. Extensive experiments on several benchmarks
empirically demonstrate consistent and significant improvement compared with
the state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:23:00 GMT""}]","2023-05-25"
"2305.14643","Manabu Tsujimoto","Manabu Tsujimoto, Kaveh Delfanazari, Takanari Kashiwagi, Toshiaki
  Hattori, and Kazuo Kadowaki","Terahertz imaging system with on-chip superconducting Josephson plasma
  emitters for nondestructive testing","6 pages, 8 figures, 1 table",,,,"cond-mat.supr-con physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compared with adjacent microwaves and infrared frequencies, terahertz (THz)
frequency offers numerous advantages for imaging applications. The unique THz
spectral signatures of chemicals allow the development of THz imaging systems
for nondestructive tests and the evaluation of biological objects, materials,
components, circuits, and systems, which are especially useful in the security,
medical, material, pharmaceutical, aeronautical, and electronics industries.
However, technological advancements have been hindered owing to the lack of
power-efficient and compact THz sources. Here, we use high-temperature
superconducting monolithic sources known as Josephson plasma emitters
(JPEs)-which are compact, chip-integrated coherent and monochromatic sources of
broadly tunable THz waves-and report the art of non-destructive imaging of
concealed metallic surgical blades, floppy disks, dandelion leaves, and slices
of pork meat in the THz spectral range. The quality of the images, exhibiting
high-contrast differentiation between metallic and non-metallic parts, making
different features of objects visible, and targeting different powders,
demonstrates the viability of this THz imaging system for nondestructive,
contactless, quick, and accurate environmental monitoring, security, medicine,
materials, and quantum science and technology applications.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:23:33 GMT""}]","2023-05-25"
"2305.14644","Hemanth Manjunatha","Hemanth Manjunatha, Andrey Pak, Dimitar Filev, Panagiotis Tsiotras","KARNet: Kalman Filter Augmented Recurrent Neural Network for Learning
  World Models in Autonomous Driving Tasks","arXiv admin note: substantial text overlap with arXiv:2205.08712",,,,"cs.LG cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Autonomous driving has received a great deal of attention in the automotive
industry and is often seen as the future of transportation. The development of
autonomous driving technology has been greatly accelerated by the growth of
end-to-end machine learning techniques that have been successfully used for
perception, planning, and control tasks. An important aspect of autonomous
driving planning is knowing how the environment evolves in the immediate future
and taking appropriate actions. An autonomous driving system should effectively
use the information collected from the various sensors to form an abstract
representation of the world to maintain situational awareness. For this
purpose, deep learning models can be used to learn compact latent
representations from a stream of incoming data. However, most deep learning
models are trained end-to-end and do not incorporate any prior knowledge (e.g.,
from physics) of the vehicle in the architecture. In this direction, many works
have explored physics-infused neural network (PINN) architectures to infuse
physics models during training. Inspired by this observation, we present a
Kalman filter augmented recurrent neural network architecture to learn the
latent representation of the traffic flow using front camera images only. We
demonstrate the efficacy of the proposed model in both imitation and
reinforcement learning settings using both simulated and real-world datasets.
The results show that incorporating an explicit model of the vehicle (states
estimated using Kalman filtering) in the end-to-end learning significantly
increases performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:27:34 GMT""}]","2023-05-25"
"2305.14645","Minqian Liu","Xiaochu Li, Minqian Liu, Zhiyang Xu, Lifu Huang","Iteratively Improving Biomedical Entity Linking and Event Extraction via
  Hard Expectation-Maximization","15 pages, 3 figures, 10 tables",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Biomedical entity linking and event extraction are two crucial tasks to
support text understanding and retrieval in the biomedical domain. These two
tasks intrinsically benefit each other: entity linking disambiguates the
biomedical concepts by referring to external knowledge bases and the domain
knowledge further provides additional clues to understand and extract the
biological processes, while event extraction identifies a key trigger and
entities involved to describe each biological process which also captures the
structural context to better disambiguate the biomedical entities. However,
previous research typically solves these two tasks separately or in a pipeline,
leading to error propagation. What's more, it's even more challenging to solve
these two tasks together as there is no existing dataset that contains
annotations for both tasks. To solve these challenges, we propose joint
biomedical entity linking and event extraction by regarding the event
structures and entity references in knowledge bases as latent variables and
updating the two task-specific models in a hard Expectation-Maximization (EM)
fashion: (1) predicting the missing variables for each partially annotated
dataset based on the current two task-specific models, and (2) updating the
parameters of each model on the corresponding pseudo completed dataset.
Experimental results on two benchmark datasets: Genia 2011 for event extraction
and BC4GO for entity linking, show that our joint framework significantly
improves the model for each individual task and outperforms the strong
baselines for both tasks. We will make the code and model checkpoints publicly
available once the paper is accepted.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:30:31 GMT""}]","2023-05-25"
"2305.14646","Wuhyun Sohn","Wuhyun Sohn, James R. Fergusson, E. P. S. Shellard","High-resolution CMB bispectrum estimator with flexible modal basis","35 pages, 12 figures, public codes at
  https://github.com/Wuhyun/CMB-BEST and https://github.com/Wuhyun/Tetraquad",,,,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a new independent pipeline for the CMB bispectrum estimation of
primordial non-Gaussianity and release a public code for constraining
bispectrum shapes of interest based on the Planck 2018 temperature and
polarization data. The estimator combines the strengths of the conventional KSW
and Modal estimators at the cost of increased computational complexity, which
has been made manageable through intensive algorithmic and implementation
optimization. We also detail some methodological advances in numerical
integration over a tetrapyd - domain where the bispectrum is defined on - via
new quadrature rules. The pipeline has been validated both internally and
against Planck. As a proof-of-concept example, we constrain some highly
oscillatory models that were out of reach in conventional analyses using a
targeted basis with a fixed oscillation frequency, and no significant evidence
for primordial non-Gaussianity of these shapes is found. The methodology and
code developed in this work will be directly applicable to future surveys where
we expect a notable boost in sensitivity.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:33:34 GMT""}]","2023-05-25"
"2305.14647","Qi Zeng","Qi Zeng, Mankeerat Sidhu, Hou Pong Chan, Lu Wang, Heng Ji","Meta-review Generation with Checklist-guided Iterative Introspection",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Opinions in the scientific domain can be divergent, leading to controversy or
consensus among reviewers. However, current opinion summarization datasets
mostly focus on product review domains, which do not account for this
variability under the assumption that the input opinions are non-controversial.
To address this gap, we propose the task of scientific opinion summarization,
where research paper reviews are synthesized into meta-reviews. To facilitate
this task, we introduce a new ORSUM dataset covering 10,989 paper meta-reviews
and 40,903 paper reviews from 39 conferences. Furthermore, we propose the
Checklist-guided Iterative Introspection (CGI$^2$) approach, which breaks down
the task into several stages and iteratively refines the summary under the
guidance of questions from a checklist. We conclude that (1) human-written
summaries are not always reliable since many do not follow the guideline, and
(2) the combination of task decomposition and iterative self-refinement shows
promising discussion involvement ability and can be applied to other complex
text generation using black-box LLM.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:33:35 GMT""}]","2023-05-25"
"2305.14648","Paul Crowell","James M. Etheridge, Joseph Dill, Connor P. Dempsey, Mihir Pendharkar,
  Javier Garcia-Barriocanal, Guichuan Yu, Vlad S. Pribiag, Paul A. Crowell,
  Chris J. Palmstr{\o}m","Competing Uniaxial Anisotropies in Epitaxial Fe Thin Films Grown on
  InAs(001)","5 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We report on the interplay of two uniaxial magnetic anisotropies in epitaxial
Fe thin films of varying thickness grown on InAs(001) as observed in
ferromagnetic resonance experiments. One anisotropy originates from the Fe/InAs
interface while the other originates from in-plane shear strain resulting from
the anisotropic relaxation of the Fe film. X-ray diffraction was used to
measure the in-plane lattice constants of the Fe films, confirming the
correlation between the onset of film relaxation and the corresponding shear
strain inferred from ferromagnetic resonance data. These results are relevant
for ongoing efforts to develop spintronic and quantum devices utilizing large
spin-orbit coupling in III-V semiconductors.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:34:41 GMT""}]","2023-05-25"
"2305.14649","Yushu Chen","Yushu Chen, Shengzhuo Liu, Jinzhe Yang, Hao Jing, Wenlai Zhao, and
  Guangwen Yang","A Joint Time-frequency Domain Transformer for Multivariate Time Series
  Forecasting",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To enhance predicting performance while minimizing computational demands,
this paper introduces a joint time-frequency domain Transformer (JTFT) for
multivariate forecasting. The method exploits the sparsity of time series in
the frequency domain using a small number of learnable frequencies to extract
temporal dependencies effectively. Alongside the frequency domain
representation, a fixed number of the most recent data points are directly
encoded in the time domain, bolstering the learning of local relationships and
mitigating the adverse effects of non-stationarity. JTFT achieves linear
complexity since the length of the internal representation remains independent
of the input sequence length. Additionally, a low-rank attention layer is
proposed to efficiently capture cross-dimensional dependencies and prevent
performance degradation due to the entanglement of temporal and channel-wise
modeling. Experiments conducted on six real-world datasets demonstrate that
JTFT outperforms state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:37:23 GMT""}]","2023-05-25"
"2305.14650","Yuri Sales","Yuri S. Ribeiro, Fazal E-Asim, Andr\'e L.F de Almeida, Behrooz Makki,
  Gabor Fodor","Low-Complexity Joint Active and Passive Beamforming Design for
  IRS-Assisted MIMO","5 pages, 3 figures, submited to wireless communication letters (under
  review)",,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  In this letter, we consider an intelligent reflecting surface (IRS)-assisted
multiple input multiple output (MIMO) communication and we optimize the joint
active and passive beamforming by exploiting the geometrical structure of the
propagation channels. Due to the inherent Kronecker product structure of the
channel matrix, the global beamforming optimization problem is split into lower
dimensional horizontal and vertical sub-problems. Based on this factorization
property, we propose two closed-form methods for passive and active beamforming
designs, at the IRS, the base station, and user equipment, respectively. The
first solution is a singular value decomposition (SVD)-based algorithm
independently applied on the factorized channels, while the second method
resorts to a third-order rank-one tensor approximation along each domain.
Simulation results show that exploiting the channel Kronecker structures yields
a significant improvement in terms of computational complexity at the expense
of negligible spectral efficiency (SE) loss. We also show that under imperfect
channel estimation, the tensor-based solution shows better SE than the
benchmark and proposed SVD-based solutions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:39:15 GMT""}]","2023-05-25"
"2305.14651","Lingbing Guo","Lingbing Guo, Zhuo Chen, Jiaoyan Chen, and Huajun Chen","Revisit and Outstrip Entity Alignment: A Perspective of Generative
  Models","Under review",,,,"cs.CL cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent embedding-based methods have achieved great successes on exploiting
entity alignment from knowledge graph (KG) embeddings of multiple modals. In
this paper, we study embedding-based entity alignment (EEA) from a perspective
of generative models. We show that EEA is a special problem where the main
objective is analogous to that in a typical generative model, based on which we
theoretically prove the effectiveness of the recently developed generative
adversarial network (GAN)-based EEA methods. We then reveal that their
incomplete objective limits the capacity on both entity alignment and entity
synthesis (i.e., generating new entities). We mitigate this problem by
introducing a generative EEA (abbr., GEEA) framework with the proposed mutual
variational autoencoder (M-VAE) as the generative model. M-VAE can convert an
entity from one KG to another and generate new entities from random noise
vectors. We demonstrate the power of GEEA with theoretical analysis and
empirical experiments on both entity alignment and entity synthesis tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:39:20 GMT""}]","2023-05-25"
"2305.14652","Shaoxiang Wu","Shaoxiang Wu, Damai Dai, Ziwei Qin, Tianyu Liu, Binghuai Lin, Yunbo
  Cao, Zhifang Sui","Denoising Bottleneck with Mutual Information Maximization for Video
  Multimodal Fusion","Accept at ACL2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Video multimodal fusion aims to integrate multimodal signals in videos, such
as visual, audio and text, to make a complementary prediction with multiple
modalities contents. However, unlike other image-text multimodal tasks, video
has longer multimodal sequences with more redundancy and noise in both visual
and audio modalities. Prior denoising methods like forget gate are coarse in
the granularity of noise filtering. They often suppress the redundant and noisy
information at the risk of losing critical information. Therefore, we propose a
denoising bottleneck fusion (DBF) model for fine-grained video multimodal
fusion. On the one hand, we employ a bottleneck mechanism to filter out noise
and redundancy with a restrained receptive field. On the other hand, we use a
mutual information maximization module to regulate the filter-out module to
preserve key information within different modalities. Our DBF model achieves
significant improvement over current state-of-the-art baselines on multiple
benchmarks covering multimodal sentiment analysis and multimodal summarization
tasks. It proves that our model can effectively capture salient features from
noisy and redundant video, audio, and text inputs. The code for this paper is
publicly available at https://github.com/WSXRHFG/DBF.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:39:43 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 02:48:40 GMT""},{""version"":""v3"",""created"":""Wed, 31 May 2023 08:20:33 GMT""}]","2023-06-01"
"2305.14653","Jo\~ao Souto-Maior","Jo\~ao M. Souto-Maior","Hoarding without hoarders: unpacking the emergence of opportunity
  hoarding within schools",,,,,"physics.soc-ph cs.MA econ.TH","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Sociologists of education increasingly highlight the role of opportunity
hoarding in the formation of Black-White educational inequalities. Informed by
this literature, this article unpacks the necessary and sufficient conditions
under which the hoarding of educational resources emerges within schools. It
develops a qualitatively informed agent-based model which captures Black and
White students' competition for a valuable school resource: advanced
coursework. In contrast to traditional accounts -- which explain the emergence
of hoarding through the actions of Whites that keep valuable resources within
White communities -- simulations, perhaps surprisingly, show hoarding to arise
even when Whites do not play the role of hoarders of resources. Behind this
result is the fact that a structural inequality (i.e., racial differences in
social class) -- and not action-driven hoarding -- is the necessary condition
for hoarding to emerge. Findings, therefore, illustrate that common
action-driven understandings of opportunity hoarding can overlook the
structural foundations behind this important phenomenon. Policy implications
are discussed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:49:38 GMT""}]","2023-05-25"
"2305.14654","Atil Iscen","Ken Caluwaerts, Atil Iscen, J. Chase Kew, Wenhao Yu, Tingnan Zhang,
  Daniel Freeman, Kuang-Huei Lee, Lisa Lee, Stefano Saliceti, Vincent Zhuang,
  Nathan Batchelor, Steven Bohez, Federico Casarini, Jose Enrique Chen, Omar
  Cortes, Erwin Coumans, Adil Dostmohamed, Gabriel Dulac-Arnold, Alejandro
  Escontrela, Erik Frey, Roland Hafner, Deepali Jain, Bauyrjan Jyenis, Yuheng
  Kuang, Edward Lee, Linda Luu, Ofir Nachum, Ken Oslund, Jason Powell, Diego
  Reyes, Francesco Romano, Feresteh Sadeghi, Ron Sloat, Baruch Tabanpour,
  Daniel Zheng, Michael Neunert, Raia Hadsell, Nicolas Heess, Francesco Nori,
  Jeff Seto, Carolina Parada, Vikas Sindhwani, Vincent Vanhoucke, and Jie Tan","Barkour: Benchmarking Animal-level Agility with Quadruped Robots","17 pages, 19 figures",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  Animals have evolved various agile locomotion strategies, such as sprinting,
leaping, and jumping. There is a growing interest in developing legged robots
that move like their biological counterparts and show various agile skills to
navigate complex environments quickly. Despite the interest, the field lacks
systematic benchmarks to measure the performance of control policies and
hardware in agility. We introduce the Barkour benchmark, an obstacle course to
quantify agility for legged robots. Inspired by dog agility competitions, it
consists of diverse obstacles and a time based scoring mechanism. This
encourages researchers to develop controllers that not only move fast, but do
so in a controllable and versatile way. To set strong baselines, we present two
methods for tackling the benchmark. In the first approach, we train specialist
locomotion skills using on-policy reinforcement learning methods and combine
them with a high-level navigation controller. In the second approach, we
distill the specialist skills into a Transformer-based generalist locomotion
policy, named Locomotion-Transformer, that can handle various terrains and
adjust the robot's gait based on the perceived environment and robot states.
Using a custom-built quadruped robot, we demonstrate that our method can
complete the course at half the speed of a dog. We hope that our work
represents a step towards creating controllers that enable robots to reach
animal-level agility.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:49:43 GMT""}]","2023-05-25"
"2305.14655","Yu Ling","Yu Ling, Weimin Tan and Bo Yan","Learning Survival Distribution with Implicit Survival Function",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Survival analysis aims at modeling the relationship between covariates and
event occurrence with some untracked (censored) samples. In implementation,
existing methods model the survival distribution with strong assumptions or in
a discrete time space for likelihood estimation with censorship, which leads to
weak generalization. In this paper, we propose Implicit Survival Function (ISF)
based on Implicit Neural Representation for survival distribution estimation
without strong assumptions,and employ numerical integration to approximate the
cumulative distribution function for prediction and optimization. Experimental
results show that ISF outperforms the state-of-the-art methods in three public
datasets and has robustness to the hyperparameter controlling estimation
precision.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:51:29 GMT""}]","2023-05-25"
"2305.14656","Hao Sun","Yilong Xu, Yang Liu, Hao Sun","RSRM: Reinforcement Symbolic Regression Machine","18 pages",,,,"cs.LG cs.AI cs.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In nature, the behaviors of many complex systems can be described by
parsimonious math equations. Automatically distilling these equations from
limited data is cast as a symbolic regression process which hitherto remains a
grand challenge. Keen efforts in recent years have been placed on tackling this
issue and demonstrated success in symbolic regression. However, there still
exist bottlenecks that current methods struggle to break when the discrete
search space tends toward infinity and especially when the underlying math
formula is intricate. To this end, we propose a novel Reinforcement Symbolic
Regression Machine (RSRM) that masters the capability of uncovering complex
math equations from only scarce data. The RSRM model is composed of three key
modules: (1) a Monte Carlo tree search (MCTS) agent that explores optimal math
expression trees consisting of pre-defined math operators and variables, (2) a
Double Q-learning block that helps reduce the feasible search space of MCTS via
properly understanding the distribution of reward, and (3) a modulated sub-tree
discovery block that heuristically learns and defines new math operators to
improve representation ability of math expression trees. Biding of these
modules yields the state-of-the-art performance of RSRM in symbolic regression
as demonstrated by multiple sets of benchmark examples. The RSRM model shows
clear superiority over several representative baseline models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:51:45 GMT""}]","2023-05-25"
"2305.14657","Yiduo Guo","Yiduo Guo, Bing Liu, Dongyan Zhao","Dealing with Cross-Task Class Discrimination in Online Continual
  Learning","Accepted by CVPR2023",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Existing continual learning (CL) research regards catastrophic forgetting
(CF) as almost the only challenge. This paper argues for another challenge in
class-incremental learning (CIL), which we call cross-task class discrimination
(CTCD),~i.e., how to establish decision boundaries between the classes of the
new task and old tasks with no (or limited) access to the old task data. CTCD
is implicitly and partially dealt with by replay-based methods. A replay method
saves a small amount of data (replay data) from previous tasks. When a batch of
current task data arrives, the system jointly trains the new data and some
sampled replay data. The replay data enables the system to partially learn the
decision boundaries between the new classes and the old classes as the amount
of the saved data is small. However, this paper argues that the replay approach
also has a dynamic training bias issue which reduces the effectiveness of the
replay data in solving the CTCD problem. A novel optimization objective with a
gradient-based adaptive method is proposed to dynamically deal with the problem
in the online CL process. Experimental results show that the new method
achieves much better results in online CL.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:52:30 GMT""}]","2023-05-25"
"2305.14658","Yongkang Liu","Yongkang Liu and Shi Feng and Daling Wang and Yifei Zhang and Hinrich
  Sch\""utze","Evaluate What You Can't Evaluate: Unassessable Generated Responses
  Quality","preprint",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LLMs (large language models) such as ChatGPT have shown remarkable language
understanding and generation capabilities. Although reference-free evaluators
based on LLMs show better human alignment than traditional reference-based
evaluators, there are many challenges in using reference-free evaluators based
on LLMs. Reference-free evaluators are more suitable for open-ended examples
with different semantics responses. But not all examples are open-ended. For
closed-ended examples with unique correct semantic response, reference-free
evaluators will still consider it high quality when giving a response that is
inconsistent with the facts and the semantic of reference. In order to
comprehensively evaluate the reliability of evaluators based on LLMs, we
construct two adversarial meta-evaluation dialogue generation datasets
KdConv-ADV and DSTC7-ADV based on KdConv and DSTC7-AVSD, respectively. Compared
to previous meta-evaluation benchmarks, KdConv-ADV and DSTC7-ADV are much more
challenging since they requires evaluators to be able to reasonably evaluate
closed-ended examples with the help of external knowledge or even its own
knowledge. Empirical results show that the ability of LLMs to identify
unreasonable responses is insufficient. There are risks in using eference-free
evaluators based on LLMs to evaluate the quality of dialogue responses.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:52:48 GMT""}]","2023-05-25"
"2305.14659","Ishani Mondal","Ishani Mondal, Michelle Yuan, Anandhavelu N, Aparna Garimella, Francis
  Ferraro, Andrew Blair-Stanek, Benjamin Van Durme, Jordan Boyd-Graber","InteractiveIE: Towards Assessing the Strength of Human-AI Collaboration
  in Improving the Performance of Information Extraction",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Learning template based information extraction from documents is a crucial
yet difficult task. Prior template-based IE approaches assume foreknowledge of
the domain templates; however, real-world IE do not have pre-defined schemas
and it is a figure-out-as you go phenomena. To quickly bootstrap templates in a
real-world setting, we need to induce template slots from documents with zero
or minimal supervision. Since the purpose of question answering intersect with
the goal of information extraction, we use automatic question generation to
induce template slots from the documents and investigate how a tiny amount of a
proxy human-supervision on-the-fly (termed as InteractiveIE) can further boost
the performance. Extensive experiments on biomedical and legal documents, where
obtaining training data is expensive, reveal encouraging trends of performance
improvement using InteractiveIE over AI-only baseline.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:53:22 GMT""}]","2023-05-25"
"2305.14660","Anna Martin-Boyle","Anna Martin-Boyle, Andrew Head, Kyle Lo, Risham Sidhu, Marti A.
  Hearst, and Dongyeop Kang","Complex Mathematical Symbol Definition Structures: A Dataset and Model
  for Coordination Resolution in Definition Extraction","9 pages, 4 figures",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Mathematical symbol definition extraction is important for improving
scholarly reading interfaces and scholarly information extraction (IE).
However, the task poses several challenges: math symbols are difficult to
process as they are not composed of natural language morphemes; and scholarly
papers often contain sentences that require resolving complex coordinate
structures. We present SymDef, an English language dataset of 5,927 sentences
from full-text scientific papers where each sentence is annotated with all
mathematical symbols linked with their corresponding definitions. This dataset
focuses specifically on complex coordination structures such as ""respectively""
constructions, which often contain overlapping definition spans. We also
introduce a new definition extraction method that masks mathematical symbols,
creates a copy of each sentence for each symbol, specifies a target symbol, and
predicts its corresponding definition spans using slot filling. Our experiments
show that our definition extraction model significantly outperforms RoBERTa and
other strong IE baseline systems by 10.9 points with a macro F1 score of 84.82.
With our dataset and model, we can detect complex definitions in scholarly
documents to make scientific writing more readable.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:53:48 GMT""}]","2023-05-25"
"2305.14661","Zhedong Zhang Dr","Joel Jiahao Fan, Zhe-Yu Jeff Ou, Zhedong Zhang","Entangled Photons Enabled Ultrafast Stimulated Raman Spectroscopy for
  Molecular Dynamics","7 pages, 4 figures",,,,"quant-ph physics.chem-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Quantum entanglement has emerged as a great resource for interactions between
molecules and radiation. We propose a new paradigm of stimulated Raman
scattering with entangled photons. A quantum ultrafast Raman spectroscopy is
developed for condensed-phase molecules, to monitor the exciton populations and
coherences. Analytic results are obtained, showing a time-frequency scale not
attainable by classical light. The Raman signal presents an unprecedented
selectivity of molecular correlation functions, as a result of the
Hong-Ou-Mandel interference. This is a typical quantum nature, advancing the
spectroscopy for clarity. Our work suggests a new scheme of optical signals and
spectroscopy, with potential to unveil advanced information about complex
materials.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:57:43 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 03:15:28 GMT""}]","2023-05-26"
"2305.14662","Honglin Wen","Honglin Wen","Probabilistic Wind Power Forecasting with Missing Values via Adaptive
  Quantile Regression","submitted to IEEE Transactions on Sustainable Energy",,,,"stat.AP cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Missing values challenge the probabilistic wind power forecasting at both
parameter estimation and operational forecasting stages. In this paper, we
illustrate that we are allowed to estimate forecasting functions for each
missing patterns conveniently, and propose an adaptive quantile regression
model whose parameters can adapt to missing patterns. For that, we particularly
design a feature extraction block within the quantile regression model, where
parameters are set as a function of missingness pattern and only account for
observed values. To avoidthe quantile-crossing phenomena, we design a
multi-task model to ensure the monotonicity of quantiles, where higher
quantiles are derived by the addition between lower quantiles and non-negative
increments modeled by neural networks. The proposed approach is
distribution-free and applicable to both missing-at-random and
missing-not-at-random cases. Case studies demonstrate that the proposed
approach achieves the state-of-the-art in terms of the continuous ranked
probability score.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:58:32 GMT""}]","2023-05-25"
"2305.14663","Naihao Deng","Naihao Deng, Siyang Liu, Xinliang Frederick Zhang, Winston Wu, Lu
  Wang, Rada Mihalcea","You Are What You Annotate: Towards Better Models through Annotator
  Representations","19 pages",,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Annotator disagreement is ubiquitous in natural language processing (NLP)
tasks. There are multiple reasons for such disagreements, including the
subjectivity of the task, difficult cases, unclear guidelines, and so on.
Rather than simply aggregating labels to obtain data annotations, we instead
propose to explicitly account for the annotator idiosyncrasies and leverage
them in the modeling process. We create representations for the annotators
(annotator embeddings) and their annotations (annotation embeddings) with
learnable matrices associated with each. Our approach significantly improves
model performance on various NLP benchmarks by adding fewer than 1% model
parameters. By capturing the unique tendencies and subjectivity of individual
annotators, our embeddings help democratize AI and ensure that AI models are
inclusive of diverse viewpoints.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:06:13 GMT""}]","2023-05-25"
"2305.14664","Michael McGuigan","Michael McGuigan","Two Matrix Model, the Riemann Hypothesis and Master Matrix Obstruction",,,,,"math.NT hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We identify the Riemann Xi function as the Baker-Akhiezer function for a
(p,1) two matrix model as p goes to infinity. We solve the two matrix model
using biorthogonal polynomials and study the zeros of the polynomials in the
double scaling limit as N goes to infinity. We find zeros off the critical line
at finite N which possibly go to infinity as N goes to infinity. We study other
Baker-Akhiezer functions whose zeros are known to be on a critical line using
the two matrix model technique and find the zeros on the critical line in those
cases. We study other L-functions using the two matrix model and compare the
biorthogonal method with other approaches to the two matrix model such as the
master matrix approach and saddle point method. In cases where there are zeros
off the critical line the master matrix approach encounters an obstruction to
the solution to a quenched master matrix.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:09:32 GMT""}]","2023-05-25"
"2305.14665","Kuan-Ming Hung","Kuan-Ming Hung and Tung-Ho Shieh","Pairing interactions induce antiferromagnetism in cuprate
  superconductors","31 pages, 8 figures",,,,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  In cuprate superconductors, superconductivity is consistently accompanied by
antiferromagnetism. This raises the question of a potential causal link between
superconductivity and antiferromagnetic mechanisms. In this study, we consider
the non-local Coulomb interaction and solve the single-particle Green function
exactly. The exact solution shows the existence of strong inter-spin
correlations in the absence of superexchange, eliminating the directional
degrees of freedom for spin quantization in the Hatsugai-Kohmoto (HK) model.
Strong Coulomb interactions force the energy band splitting into infinitely
equidistant sub-bands weighted by a Poisson distribution, exhibiting boson
properties (incoherent pairs of fermions) and non-Fermi liquids. Attractive
pairing interactions caused by electron-phonon coupling open a pairing gap at
the Fermi surface. Based on the Pauli exclusion principle, paired particles
with the same spin quantization direction completely occupy the state below the
gap, resulting in pairing insulators, superconducting instability, and
especially antiferromagnetism. A pseudogap occurs when the higher split
sub-band overlaps in energy with the lowest sub-band. The critical temperature
Tc of superconductivity exhibits a multi-dome structure and peaks around the
maximum density of states. The maximum Tc depends on splitting sub-bands and
particle occupancy, consistent with experiments. This study concludes that the
non-local effect preserves the Hubbard and HK models' characteristics while
renormalizing the system to antiferromagnetism in pairing insulators and Pauli
paramagnetism in weak semimetals.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:15:35 GMT""}]","2023-05-25"
"2305.14666","Tian Xia","Tian Xia and Luca Scardovi","An input-output framework for stability and synchronization analysis of
  networks of infinite-dimensional linear systems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper extends a synchronization criterion established for networks of
finite-dimensional linear systems to the infinite-dimensional setting. Our
result, established in the general framework of input-output relations,
requires an additional input-output stability property, compared to the
finite-dimensional counterpart. We establish conditions for this property to
hold for a large class of infinite-dimensional systems including Abstract
Cauchy Problems, parabolic PDEs, and time-delay ordinary differential
equations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:17:06 GMT""}]","2023-05-25"
"2305.14667","Feng Wang","Feng Wang and Chuan-Fu Yang","Ambarzumyan-type theorem for vectorial Sturm-Liouville operator with
  impulses",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the vector-impulsive Sturm-Liouville problem with Neumann
conditions. The Ambarzumyan$^{\textbf{,}}$s theorem for the problem is proved,
which states that if the eigenvalues of the problem coincide with those of the
zero potential, then the potential is zero.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:19:02 GMT""}]","2023-05-25"
"2305.14668","Guofeng Zhang","Artur Jesslen, Guofeng Zhang, Angtian Wang, Alan Yuille, Adam
  Kortylewski","Robust 3D-aware Object Classification via Discriminative
  Render-and-Compare",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In real-world applications, it is essential to jointly estimate the 3D object
pose and class label of objects, i.e., to perform 3D-aware classification.While
current approaches for either image classification or pose estimation can be
extended to 3D-aware classification, we observe that they are inherently
limited: 1) Their performance is much lower compared to the respective
single-task models, and 2) they are not robust in out-of-distribution (OOD)
scenarios. Our main contribution is a novel architecture for 3D-aware
classification, which builds upon a recent work and performs comparably to
single-task models while being highly robust. In our method, an object category
is represented as a 3D cuboid mesh composed of feature vectors at each mesh
vertex. Using differentiable rendering, we estimate the 3D object pose by
minimizing the reconstruction error between the mesh and the feature
representation of the target image. Object classification is then performed by
comparing the reconstruction losses across object categories. Notably, the
neural texture of the mesh is trained in a discriminative manner to enhance the
classification performance while also avoiding local optima in the
reconstruction loss. Furthermore, we show how our method and feed-forward
neural networks can be combined to scale the render-and-compare approach to
larger numbers of categories. Our experiments on PASCAL3D+, occluded-PASCAL3D+,
and OOD-CV show that our method outperforms all baselines at 3D-aware
classification by a wide margin in terms of performance and robustness.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:20:09 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 17:39:03 GMT""}]","2023-06-06"
"2305.14669","Yexing Song","Yexing Song, Meilin Wang, Xiaoyu Xian, Zhijing Yang, Yuming Fan, Yukai
  Shi","NegVSR: Augmenting Negatives for Generalized Noise Modeling in
  Real-World Video Super-Resolution",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The capability of video super-resolution (VSR) to synthesize high-resolution
(HR) video from ideal datasets has been demonstrated in many works. However,
applying the VSR model to real-world video with unknown and complex degradation
remains a challenging task. First, existing degradation metrics in most VSR
methods are not able to effectively simulate real-world noise and blur. On the
contrary, simple combinations of classical degradation are used for real-world
noise modeling, which led to the VSR model often being violated by
out-of-distribution noise. Second, many SR models focus on noise simulation and
transfer. Nevertheless, the sampled noise is monotonous and limited. To address
the aforementioned problems, we propose a Negatives augmentation strategy for
generalized noise modeling in Video Super-Resolution (NegVSR) task.
Specifically, we first propose sequential noise generation toward real-world
data to extract practical noise sequences. Then, the degeneration domain is
widely expanded by negative augmentation to build up various yet challenging
real-world noise sets. We further propose the augmented negative guidance loss
to learn robust features among augmented negatives effectively. Extensive
experiments on real-world datasets (e.g., VideoLQ and FLIR) show that our
method outperforms state-of-the-art methods with clear margins, especially in
visual quality.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:23:35 GMT""}]","2023-05-25"
"2305.14670","Ben Kane","Ben Kane and Zichen Yang","On finiteness theorems for sums of generalized polygonal numbers",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider mixed sums of generalized polygonal numbers.
Specifically, we obtain a finiteness condition for universality of such sums;
this means that it suffices to check representability of a finite subset of the
positive integers in order to conclude that the sum of generalized polygonal
numbers represents every positive integer. The sub-class of sums of generalized
polygonal numbers which we consider is those sums of $m_j$-gonal numbers for
which $\operatorname{lcm}(m_1-2,\dots,m_{r}-2)\leq \mathfrak{M}$ and we obtain
a bound on the asymptotic growth of a constant $\Gamma_{\mathfrak{M}}$ such
that it suffices to check the representability condition for $n\leq
\Gamma_{\mathfrak{M}}$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:24:48 GMT""}]","2023-05-25"
"2305.14671","Hao Zou","Hao Zou, Zae Myung Kim, Dongyeop Kang","Diffusion Models in NLP: A Survey",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This survey paper provides a comprehensive review of the use of diffusion
models in natural language processing (NLP). Diffusion models are a class of
mathematical models that aim to capture the diffusion of information or signals
across a network or manifold. In NLP, diffusion models have been used in a
variety of applications, such as natural language generation, sentiment
analysis, topic modeling, and machine translation. This paper discusses the
different formulations of diffusion models used in NLP, their strengths and
limitations, and their applications. We also perform a thorough comparison
between diffusion models and alternative generative models, specifically
highlighting the autoregressive (AR) models, while also examining how diverse
architectures incorporate the Transformer in conjunction with diffusion models.
Compared to AR models, diffusion models have significant advantages for
parallel generation, text interpolation, token-level controls such as syntactic
structures and semantic contents, and robustness. Exploring further
permutations of integrating Transformers into diffusion models would be a
valuable pursuit. Also, the development of multimodal diffusion models and
large-scale diffusion language models with notable capabilities for few-shot
learning would be important directions for the future advance of diffusion
models in NLP.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:25:32 GMT""}]","2023-05-25"
"2305.14672","Melissa Dell","Xinmei Yang and Abhishek Arora and Shao-Yu Jheng and Melissa Dell","Quantifying Character Similarity with Vision Transformers",,,,,"cs.CL cs.CV econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Record linkage is a bedrock of quantitative social science, as analyses often
require linking data from multiple, noisy sources. Off-the-shelf string
matching methods are widely used, as they are straightforward and cheap to
implement and scale. Not all character substitutions are equally probable, and
for some settings there are widely used handcrafted lists denoting which string
substitutions are more likely, that improve the accuracy of string matching.
However, such lists do not exist for many settings, skewing research with
linked datasets towards a few high-resource contexts that are not
representative of the diversity of human societies. This study develops an
extensible way to measure character substitution costs for OCR'ed documents, by
employing large-scale self-supervised training of vision transformers (ViT)
with augmented digital fonts. For each language written with the CJK script, we
contrastively learn a metric space where different augmentations of the same
character are represented nearby. In this space, homoglyphic characters - those
with similar appearance such as ``O'' and ``0'' - have similar vector
representations. Using the cosine distance between characters' representations
as the substitution cost in an edit distance matching algorithm significantly
improves record linkage compared to other widely used string matching methods,
as OCR errors tend to be homoglyphic in nature. Homoglyphs can plausibly
capture character visual similarity across any script, including low-resource
settings. We illustrate this by creating homoglyph sets for 3,000 year old
ancient Chinese characters, which are highly pictorial. Fascinatingly, a ViT is
able to capture relationships in how different abstract concepts were
conceptualized by ancient societies, that have been noted in the archaeological
literature.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:25:33 GMT""}]","2023-05-25"
"2305.14673","Xiao Liang","Xiao Liang, Shan Lin, Fei Liu, Dimitri Schreiber, and Michael Yip","ORRN: An ODE-based Recursive Registration Network for Deformable
  Respiratory Motion Estimation with Lung 4DCT Images","Accepted by IEEE Transactions on Biomedical Engineering",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deformable Image Registration (DIR) plays a significant role in quantifying
deformation in medical data. Recent Deep Learning methods have shown promising
accuracy and speedup for registering a pair of medical images. However, in 4D
(3D + time) medical data, organ motion, such as respiratory motion and heart
beating, can not be effectively modeled by pair-wise methods as they were
optimized for image pairs but did not consider the organ motion patterns
necessary when considering 4D data. This paper presents ORRN, an Ordinary
Differential Equations (ODE)-based recursive image registration network. Our
network learns to estimate time-varying voxel velocities for an ODE that models
deformation in 4D image data. It adopts a recursive registration strategy to
progressively estimate a deformation field through ODE integration of voxel
velocities. We evaluate the proposed method on two publicly available lung 4DCT
datasets, DIRLab and CREATIS, for two tasks: 1) registering all images to the
extreme inhale image for 3D+t deformation tracking and 2) registering extreme
exhale to inhale phase images. Our method outperforms other learning-based
methods in both tasks, producing the smallest Target Registration Error of
1.24mm and 1.26mm, respectively. Additionally, it produces less than 0.001\%
unrealistic image folding, and the computation speed is less than 1 second for
each CT volume. ORRN demonstrates promising registration accuracy, deformation
plausibility, and computation efficiency on group-wise and pair-wise
registration tasks. It has significant implications in enabling fast and
accurate respiratory motion estimation for treatment planning in radiation
therapy or robot motion planning in thoracic needle insertion.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:26:26 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 04:56:19 GMT""}]","2023-05-26"
"2305.14674","Kangfu Mei","Kangfu Mei and Mo Zhou and Vishal M. Patel","T1: Scaling Diffusion Probabilistic Fields to High-Resolution on Unified
  Visual Modalities","for project page, see https://t1-diffusion-model.github.io",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion Probabilistic Field (DPF) models the distribution of continuous
functions defined over metric spaces. While DPF shows great potential for
unifying data generation of various modalities including images, videos, and 3D
geometry, it does not scale to a higher data resolution. This can be attributed
to the ``scaling property'', where it is difficult for the model to capture
local structures through uniform sampling. To this end, we propose a new model
comprising of a view-wise sampling algorithm to focus on local structure
learning, and incorporating additional guidance, e.g., text description, to
complement the global geometry. The model can be scaled to generate
high-resolution data while unifying multiple modalities. Experimental results
on data generation in various modalities demonstrate the effectiveness of our
model, as well as its potential as a foundation framework for scalable
modality-unified visual content generation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:32:03 GMT""}]","2023-05-25"
"2305.14675","Yiheng Jiang","Yiheng Jiang and Yuanbo Xu","Revenge of MLP in Sequential Recommendation",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequential recommendation models sequences of historical user-item
interactive behaviors (or referred as token) to better infer dynamic
preferences. Fueled by the improved neural network architectures such as RNN,
CNN and Transformer, this field has enjoyed rapid performance boost in the past
years. Recent progress on all-MLP models lights on an efficient method with
less intensive computation, token-mixing MLP, to learn the transformation
patterns among historical behaviors. However, due to the inherent
fully-connection design that allows the unrestricted cross-token communication
and ignores the chronological order, we find that directly applying
token-mixing MLP into sequential recommendation leads to subpar performance. In
this paper, we present a purely MLP-based sequential recommendation
architecture TriMLP with a novel \underline{Tri}angular Mixer where the
modified \underline{MLP} endows tokens with ordered interactions. As the
cross-token interaction in MLP is actually matrix multiplication, Triangular
Mixer drops the lower-triangle neurons in the weight matrix and thus blocks the
connections from future tokens, which prevents information leakage and improves
prediction capability under the standard auto-regressive training fashion. To
further model long and short-term preferences on fine-grained level, the mixer
adopts a dual-branch structure based on the delicate MLP described above,
namely global and local mixing, to separately capture the sequential long-range
dependencies and local patterns. Empirical study on 9 different scale datasets
(contain 50K\textasciitilde20M behaviors) of various benchmarks, including
MovieLens, Amazon and Tenrec, demonstrates that TriMLP attains promising and
stable accuracy/efficiency trade-off, i.e., averagely surpasses several
state-of-the-art baselines by 5.32\% and saves 8.44\% inference time cost.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:32:31 GMT""}]","2023-05-25"
"2305.14676","Woojeong Jin","Woojeong Jin, Subhabrata Mukherjee, Yu Cheng, Yelong Shen, Weizhu
  Chen, Ahmed Hassan Awadallah, Damien Jose, Xiang Ren","GRILL: Grounded Vision-language Pre-training via Aligning Text and Image
  Regions","Preprint",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalization to unseen tasks is an important ability for few-shot learners
to achieve better zero-/few-shot performance on diverse tasks. However, such
generalization to vision-language tasks including grounding and generation
tasks has been under-explored; existing few-shot VL models struggle to handle
tasks that involve object grounding and multiple images such as visual
commonsense reasoning or NLVR2. In this paper, we introduce GRILL, GRounded
vIsion Language aLigning, a novel VL model that can be generalized to diverse
tasks including visual question answering, captioning, and grounding tasks with
no or very few training instances. Specifically, GRILL learns object grounding
and localization by exploiting object-text alignments, which enables it to
transfer to grounding tasks in a zero-/few-shot fashion. We evaluate our model
on various zero-/few-shot VL tasks and show that it consistently surpasses the
state-of-the-art few-shot methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:33:21 GMT""}]","2023-05-25"
"2305.14677","Zhongjie Duan","Zhongjie Duan, Chengyu Wang, Cen Chen, Jun Huang and Weining Qian","Optimal Linear Subspace Search: Learning to Construct Fast and
  High-Quality Schedulers for Diffusion Models","13 pages, 5 figures",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In recent years, diffusion models have become the most popular and powerful
methods in the field of image synthesis, even rivaling human artists in
artistic creativity. However, the key issue currently limiting the application
of diffusion models is its extremely slow generation process. Although several
methods were proposed to speed up the generation process, there still exists a
trade-off between efficiency and quality. In this paper, we first provide a
detailed theoretical and empirical analysis of the generation process of the
diffusion models based on schedulers. We transform the designing problem of
schedulers into the determination of several parameters, and further transform
the accelerated generation process into an expansion process of the linear
subspace. Based on these analyses, we consequently propose a novel method
called Optimal Linear Subspace Search (OLSS), which accelerates the generation
process by searching for the optimal approximation process of the complete
generation process in the linear subspaces spanned by latent variables. OLSS is
able to generate high-quality images with a very small number of steps. To
demonstrate the effectiveness of our method, we conduct extensive comparative
experiments on open-source diffusion models. Experimental results show that
with a given number of steps, OLSS can significantly improve the quality of
generated images. Using an NVIDIA A100 GPU, we make it possible to generate a
high-quality image by Stable Diffusion within only one second without other
optimization techniques.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:33:30 GMT""}]","2023-05-25"
"2305.14678","Zhonghai Zhao","Zhonghai Zhao, Yang Xu, Jia Liu, Li Zhao, Yulong Shen and Norio
  Shiratori","Marriage Matching-based Instant Parking Spot Sharing in Internet of
  Vehicles",,,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rapid development and integration of automotive manufacturing, sensor,
and communication technologies have facilitated the emergence of the Internet
of Vehicles (IoV). However, the explosive growing demand for parking spots has
become a challenging issue to be addressed in IoV. In this paper, we propose a
novel Smart Parking System (SPS) for IoV by applying the matching game
approach. Specifically, the proposed SPS consists of three types of entities:
drivers, parking spot owners (PSOs), and a certificate authority (CA). Drivers
and PSOs send parking requests and parking spot information to the CA,
respectively. The CA is responsible for identifying legitimate system users,
matching drivers with PSOs, and recording their transaction information. We
first design rational utility functions for drivers and PSOs, and then
establish preference lists for them based on real-time conditions. With these
information, we further develop an improved marriage matching (MM) algorithm to
achieve stable matching results for drivers' requests and parking spot
allocation. Simulation results demonstrate that the proposed MM-based SPS not
only ensures stable matching results with the objective of distance
minimization but also achieves an overall utility close to that of the optimal
algorithm.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:37:25 GMT""}]","2023-05-25"
"2305.14679","Masahiro Kojima","Masahiro Kojima","Dynamic Borrowing Method for Historical Information Using a Frequentist
  Approach for Hybrid Control Design",,,,,"stat.ME stat.ML","http://creativecommons.org/licenses/by/4.0/","  Information borrowing from historical data is gaining attention in clinical
trials of rare and pediatric diseases, where statistical power may be
insufficient for confirmation of efficacy if the sample size is small. Although
Bayesian information borrowing methods are well established, test-then-pool and
equivalence-based test-then-pool methods have recently been proposed as
frequentist methods to determine whether historical data should be used for
statistical hypothesis testing. Depending on the results of the hypothesis
testing, historical data may not be usable. This paper proposes a dynamic
borrowing method for historical information based on the similarity between
current and historical data. In our proposed method of dynamic information
borrowing, as in Bayesian dynamic borrowing, the amount of borrowing ranges
from 0% to 100%. We propose two methods using the density function of the
t-distribution and a logistic function as a similarity measure. We evaluate the
performance of the proposed methods through Monte Carlo simulations. We
demonstrate the usefulness of borrowing information by reanalyzing actual
clinical trial data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:38:26 GMT""}]","2023-05-25"
"2305.14680","Zhichao Liu","Zhichao Liu, Zhouyu Lu, Ali-akbar Agha-mohammadi and Konstantinos
  Karydis","Contact-Prioritized Planning of Impact-Resilient Aerial Robots with an
  Integrated Compliant Arm","To appear in TMECH/AIM FS. Video https://youtu.be/Ks1tMMtjfGg",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article develops an impact-resilient aerial robot (s-ARQ) equipped with a
compliant arm to sense contacts and reduce collision impact and featuring a
real-time contact force estimator and a non-linear motion controller to handle
collisions while performing aggressive maneuvers and stabilize from high-speed
wall collisions. Further, a new collision-inclusive planning method that aims
to prioritize contacts to facilitate aerial robot navigation in cluttered
environments is proposed. A range of simulated and physical experiments
demonstrate key benefits of the robot and the contact-prioritized (CP) planner.
Experimental results show that the compliant robot has only a $4\%$ weight
increase but around $40\%$ impact reduction in drop tests and wall collision
tests. s-ARQ can handle collisions while performing aggressive maneuvers and
stabilize from high-speed wall collisions at $3.0$ m/s with a success rate of
$100\%$. Our proposed compliant robot and contact-prioritized planning method
can accelerate computation time while having shorter trajectory time and larger
clearances compared to A$^\ast$ and RRT$^\ast$ planners with velocity
constraints. Online planning tests in partially-known environments further
demonstrate the preliminary feasibility of our method to apply in practical use
cases.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:41:10 GMT""}]","2023-05-25"
"2305.14681","James Michaelov","James A. Michaelov, Benjamin K. Bergen","Emergent inabilities? Inverse scaling over the course of pretraining",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Does inverse scaling only occur as a function of model parameter size, or can
it also occur over the course of training? We carry out an exploratory study
investigating whether, over the course of training on the language modeling
task, the performance of language models at specific tasks can decrease while
general performance remains high. We find that for two tasks from the Inverse
Scaling Challenge - quote-repetition and redefine-math - this is indeed the
case. Specifically, we find that for Pythia (Biderman et al., 2023) models with
a higher number of parameters, performance decreases over the course of
training at these two tasks, despite these models showing standard (positive)
scaling overall. This highlights the importance of testing model performance at
all relevant benchmarks any time they are trained on additional data, even if
their overall performance improves.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:42:43 GMT""}]","2023-05-25"
"2305.14682","Jian Wu","Jian Wu, Yicheng Xu, Yan Gao, Jian-Guang Lou, B\""orje F. Karlsson,
  Manabu Okumura","TACR: A Table-alignment-based Cell-selection and Reasoning Model for
  Hybrid Question-Answering","Accepted at Findings of ACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Hybrid Question-Answering (HQA), which targets reasoning over tables and
passages linked from table cells, has witnessed significant research in recent
years. A common challenge in HQA and other passage-table QA datasets is that it
is generally unrealistic to iterate over all table rows, columns, and linked
passages to retrieve evidence. Such a challenge made it difficult for previous
studies to show their reasoning ability in retrieving answers. To bridge this
gap, we propose a novel Table-alignment-based Cell-selection and Reasoning
model (TACR) for hybrid text and table QA, evaluated on the HybridQA and
WikiTableQuestions datasets. In evidence retrieval, we design a
table-question-alignment enhanced cell-selection method to retrieve
fine-grained evidence. In answer reasoning, we incorporate a QA module that
treats the row containing selected cells as context. Experimental results over
the HybridQA and WikiTableQuestions (WTQ) datasets show that TACR achieves
state-of-the-art results on cell selection and outperforms fine-grained
evidence retrieval baselines on HybridQA, while achieving competitive
performance on WTQ. We also conducted a detailed analysis to demonstrate that
being able to align questions to tables in the cell-selection stage can result
in important gains from experiments of over 90\% table row and column selection
accuracy, meanwhile also improving output explainability.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:42:44 GMT""}]","2023-05-25"
"2305.14683","Lachlan MacDonald","Lachlan Ewen MacDonald and Jack Valmadre and Simon Lucey","On progressive sharpening, flat minima and generalisation",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new approach to understanding the relationship between loss
curvature and generalisation in deep learning. Specifically, we use existing
empirical analyses of the spectrum of deep network loss Hessians to ground an
ansatz tying together the loss Hessian and the input-output Jacobian of a deep
neural network. We then prove a series of theoretical results which quantify
the degree to which the input-output Jacobian of a model approximates its
Lipschitz norm over a data distribution, and deduce a novel generalisation
bound in terms of the empirical Jacobian. We use our ansatz, together with our
theoretical results, to give a new account of the recently observed progressive
sharpening phenomenon, as well as the generalisation properties of flat minima.
Experimental evidence is provided to validate our claims.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:44:50 GMT""}]","2023-05-25"
"2305.14684","Zehong Zhou","Zehong Zhou, Fei Zhou, Guoping Qiu","Collaborative Auto-encoding for Blind Image Quality Assessment",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Blind image quality assessment (BIQA) is a challenging problem with important
real-world applications. Recent efforts attempting to exploit powerful
representations by deep neural networks (DNN) are hindered by the lack of
subjectively annotated data. This paper presents a novel BIQA method which
overcomes this fundamental obstacle. Specifically, we design a pair of
collaborative autoencoders (COAE) consisting of a content autoencoder (CAE) and
a distortion autoencoder (DAE) that work together to extract content and
distortion representations, which are shown to be highly descriptive of image
quality. While the CAE follows a standard codec procedure, we introduce the
CAE-encoded feature as an extra input to the DAE's decoder for reconstructing
distorted images, thus effectively forcing DAE's encoder to extract distortion
representations. The self-supervised learning framework allows the COAE
including two feature extractors to be trained by almost unlimited amount of
data, thus leaving limited samples with annotations to finetune a BIQA model.
We will show that the proposed BIQA method achieves state-of-the-art
performance and has superior generalization capability over other learning
based models. The codes are available at:
https://github.com/Macro-Zhou/NRIQA-VISOR/.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:45:03 GMT""}]","2023-05-25"
"2305.14685","Shi Yu","Shi Yu (1), Chenghao Fan (2), Chenyan Xiong (3), David Jin (4),
  Zhiyuan Liu (1), Zhenghao Liu (5) ((1) Tsinghua University, (2) Huazhong
  University of Science and Technology, (3) Microsoft Research, (4)
  Massachusetts Institute of Technology, (5) Northeastern University)","Fusion-in-T5: Unifying Document Ranking Signals for Improved Information
  Retrieval",,,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Common IR pipelines are typically cascade systems that may involve multiple
rankers and/or fusion models to integrate different information step-by-step.
In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which
integrates document text information, retrieval features, and global document
information into a single unified model using templated-based input and global
attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show
that FiT5 significantly improves ranking performance over prior pipelines.
Analyses find that through global attention, FiT5 is able to jointly utilize
the ranking features via gradually attending to related documents, and thus
improve the detection of subtle nuances between them. Our code will be
open-sourced.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:45:35 GMT""}]","2023-05-25"
"2305.14686","Yu Chen","Yu Chen, Jin Cheng, Shuai Lu, Masahiro Yamamoto","Harmonic Measures and Numerical Computation of Cauchy Problems for
  Laplace Equations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that Cauchy problem for Laplace equations is an ill-posed
problem in Hadamard's sense. Small deviations in Cauchy data may lead to large
errors in the solutions. It is observed that if a bound is imposed on the
solution, there exists a conditional stability estimate. This gives a
reasonable way to construct stable algorithms. However, it is impossible to
have good results at all points in the domain. Although numerical methods for
Cauchy problems for Laplace equations have been widely studied for quite a long
time, there are still some unclear points, for example, how to evaluate the
numerical solutions, which means whether we can approximate the Cauchy data
well and keep the bound of the solution, and at which points the numerical
results are reliable? In this paper, we will prove the conditional stability
estimate which is quantitatively related to harmonic measures. The harmonic
measure can be used as an indicate function to pointwisely evaluate the
numerical result, which further enables us to find a reliable subdomain where
the local convergence rate is higher than a certain order.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:46:38 GMT""}]","2023-05-25"
"2305.14687","Yuqing Fu","Bocong Chen, Yuqing Fu and Hongwei Liu","Improved upper bounds on the number of non-zero weights of cyclic codes",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let C be an arbitrary simple-root cyclic code and let G be the subgroup of
Aut(C) (the automorphism group of C) generated by the multiplier, the cyclic
shift and the scalar multiplications. To the best of our knowledge, the
subgroup G is the largest subgroup of Aut(C). In this paper, an explicit
formula, in some cases an upper bound, for the number of orbits of G on C\{0}
is established. An explicit upper bound on the number of non-zero weights of C
is consequently derived and a necessary and sufficient condition for the code C
meeting the bound is exhibited. Many examples are presented to show that our
new upper bounds are tight and are strictly less than the upper bounds in [Chen
and Zhang, IEEE-TIT, 2023]. In addition, for two special classes of cyclic
codes, smaller upper bounds on the number of non-zero weights of such codes are
obtained by replacing G with larger subgroups of the automorphism groups of
these codes. As a byproduct, our main results suggest a new way to find
few-weight cyclic codes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:50:11 GMT""}]","2023-05-25"
"2305.14688","Benfeng Xu","Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong
  Zhang, Zhendong Mao","ExpertPrompting: Instructing Large Language Models to be Distinguished
  Experts",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The answering quality of an aligned large language model (LLM) can be
drastically improved if treated with proper crafting of prompts. In this paper,
we propose ExpertPrompting to elicit the potential of LLMs to answer as
distinguished experts. We first utilize In-Context Learning to automatically
synthesize detailed and customized descriptions of the expert identity for each
specific instruction, and then ask LLMs to provide answer conditioned on such
agent background. Based on this augmented prompting strategy, we produce a new
set of instruction-following data using GPT-3.5, and train a competitive
open-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation
to show that 1) the expert data is of significantly higher quality than vanilla
answers, and 2) ExpertLLaMA outperforms existing open-source opponents and
achieves 96\% of the original ChatGPT's capability. All data and the
ExpertLLaMA model will be made publicly available at
\url{https://github.com/OFA-Sys/ExpertLLaMA}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:51:31 GMT""}]","2023-05-25"
"2305.14689","Rishi Sonthalia","Rishi Sonthalia and Xinyue Li and Bochao Gu","Under-Parameterized Double Descent for Ridge Regularized Least Squares
  Denoising of Data on a Line",,,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  The relationship between the number of training data points, the number of
parameters in a statistical model, and the generalization capabilities of the
model has been widely studied. Previous work has shown that double descent can
occur in the over-parameterized regime, and believe that the standard
bias-variance trade-off holds in the under-parameterized regime. In this paper,
we present a simple example that provably exhibits double descent in the
under-parameterized regime. For simplicity, we look at the ridge regularized
least squares denoising problem with data on a line embedded in high-dimension
space. By deriving an asymptotically accurate formula for the generalization
error, we observe sample-wise and parameter-wise double descent with the peak
in the under-parameterized regime rather than at the interpolation point or in
the over-parameterized regime.
  Further, the peak of the sample-wise double descent curve corresponds to a
peak in the curve for the norm of the estimator, and adjusting $\mu$, the
strength of the ridge regularization, shifts the location of the peak. We
observe that parameter-wise double descent occurs for this model for small
$\mu$. For larger values of $\mu$, we observe that the curve for the norm of
the estimator has a peak but that this no longer translates to a peak in the
generalization error. Moreover, we study the training error for this problem.
The considered problem setup allows for studying the interaction between two
regularizers. We provide empirical evidence that the model implicitly favors
using the ridge regularizer over the input data noise regularizer. Thus, we
show that even though both regularizers regularize the same quantity, i.e., the
norm of the estimator, they are not equivalent.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:52:48 GMT""}]","2023-05-25"
"2305.14690","Tongtong Fang","Tongtong Fang, Nan Lu, Gang Niu, Masashi Sugiyama","Generalizing Importance Weighting to A Universal Solver for Distribution
  Shift Problems",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distribution shift (DS) may have two levels: the distribution itself changes,
and the support (i.e., the set where the probability density is non-zero) also
changes. When considering the support change between the training and test
distributions, there can be four cases: (i) they exactly match; (ii) the
training support is wider (and thus covers the test support); (iii) the test
support is wider; (iv) they partially overlap. Existing methods are good at
cases (i) and (ii), while cases (iii) and (iv) are more common nowadays but
still under-explored. In this paper, we generalize importance weighting (IW), a
golden solver for cases (i) and (ii), to a universal solver for all cases.
Specifically, we first investigate why IW may fail in cases (iii) and (iv);
based on the findings, we propose generalized IW (GIW) that could handle cases
(iii) and (iv) and would reduce to IW in cases (i) and (ii). In GIW, the test
support is split into an in-training (IT) part and an out-of-training (OOT)
part, and the expected risk is decomposed into a weighted classification term
over the IT part and a standard classification term over the OOT part, which
guarantees the risk consistency of GIW. Then, the implementation of GIW
consists of three components: (a) the split of validation data is carried out
by the one-class support vector machine, (b) the first term of the empirical
risk can be handled by any IW algorithm given training data and IT validation
data, and (c) the second term just involves OOT validation data. Experiments
demonstrate that GIW is a universal solver for DS problems, outperforming IW
methods in cases (iii) and (iv).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:53:15 GMT""}]","2023-05-25"
"2305.14691","Jiajia Li","Jiajia Li, Dong Chen, Xinda Qi, Zhaojian Li, Yanbo Huang, Daniel
  Morris, Xiaobo Tan","Label-Efficient Learning in Agriculture: A Comprehensive Review","34 pages, 23 figures",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The past decade has witnessed many great successes of machine learning (ML)
and deep learning (DL) applications in agricultural systems, including weed
control, plant disease diagnosis, agricultural robotics, and precision
livestock management. Despite tremendous progresses, one downside of such ML/DL
models is that they generally rely on large-scale labeled datasets for
training, and the performance of such models is strongly influenced by the size
and quality of available labeled data samples. In addition, collecting,
processing, and labeling such large-scale datasets is extremely costly and
time-consuming, partially due to the rising cost in human labor. Therefore,
developing label-efficient ML/DL methods for agricultural applications has
received significant interests among researchers and practitioners. In fact,
there are more than 50 papers on developing and applying deep-learning-based
label-efficient techniques to address various agricultural problems since 2016,
which motivates the authors to provide a timely and comprehensive review of
recent label-efficient ML/DL methods in agricultural applications. To this end,
we first develop a principled taxonomy to organize these methods according to
the degree of supervision, including weak supervision (i.e., active learning
and semi-/weakly- supervised learning), and no supervision (i.e., un-/self-
supervised learning), supplemented by representative state-of-the-art
label-efficient ML/DL methods. In addition, a systematic review of various
agricultural applications exploiting these label-efficient algorithms, such as
precision agriculture, plant phenotyping, and postharvest quality assessment,
is presented. Finally, we discuss the current problems and challenges, as well
as future research directions. A well-classified paper list can be accessed at
https://github.com/DongChen06/Label-efficient-in-Agriculture.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:53:20 GMT""}]","2023-05-25"
"2305.14692","Rahul Krishna Yandrapally","Rahulkrishna Yandrapally, Saurabh Sinha, Rachel Tzoref-Brill, Ali
  Mesbah","Carving UI Tests to Generate API Tests and API Specification",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  Modern web applications make extensive use of API calls to update the UI
state in response to user events or server-side changes. For such applications,
API-level testing can play an important role, in-between unit-level testing and
UI-level (or end-to-end) testing. Existing API testing tools require API
specifications (e.g., OpenAPI), which often may not be available or, when
available, be inconsistent with the API implementation, thus limiting the
applicability of automated API testing to web applications. In this paper, we
present an approach that leverages UI testing to enable API-level testing for
web applications. Our technique navigates the web application under test and
automatically generates an API-level test suite, along with an OpenAPI
specification that describes the application's server-side APIs (for REST-based
web applications). A key element of our solution is a dynamic approach for
inferring API endpoints with path parameters via UI navigation and directed API
probing. We evaluated the technique for its accuracy in inferring API
specifications and the effectiveness of the ""carved"" API tests. Our results on
seven open-source web applications show that the technique achieves 98%
precision and 56% recall in inferring endpoints. The carved API tests, when
added to test suites generated by two automated REST API testing tools,
increase statement coverage by 52% and 29% and branch coverage by 99% and 75%,
on average. The main benefits of our technique are: (1) it enables API-level
testing of web applications in cases where existing API testing tools are
inapplicable and (2) it creates API-level test suites that cover server-side
code efficiently while exercising APIs as they would be invoked from an
application's web UI, and that can augment existing API test suites.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:53:34 GMT""}]","2023-05-25"
"2305.14693","Xiaoyang Song","Xiaoyang Song, Akshat Gupta, Kiyan Mohebbizadeh, Shujie Hu, Anant
  Singh","Have Large Language Models Developed a Personality?: Applicability of
  Self-Assessment Tests in Measuring Personality in LLMs",,,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Have Large Language Models (LLMs) developed a personality? The short answer
is a resounding ""We Don't Know!"". In this paper, we show that we do not yet
have the right tools to measure personality in language models. Personality is
an important characteristic that influences behavior. As LLMs emulate
human-like intelligence and performance in various tasks, a natural question to
ask is whether these models have developed a personality. Previous works have
evaluated machine personality through self-assessment personality tests, which
are a set of multiple-choice questions created to evaluate personality in
humans. A fundamental assumption here is that human personality tests can
accurately measure personality in machines. In this paper, we investigate the
emergence of personality in five LLMs of different sizes ranging from 1.5B to
30B. We propose the Option-Order Symmetry property as a necessary condition for
the reliability of these self-assessment tests. Under this condition, the
answer to self-assessment questions is invariant to the order in which the
options are presented. We find that many LLMs personality test responses do not
preserve option-order symmetry. We take a deeper look at LLMs test responses
where option-order symmetry is preserved to find that in these cases, LLMs do
not take into account the situational statement being tested and produce the
exact same answer irrespective of the situation being tested. We also identify
the existence of inherent biases in these LLMs which is the root cause of the
aforementioned phenomenon and makes self-assessment tests unreliable. These
observations indicate that self-assessment tests are not the correct tools to
measure personality in LLMs. Through this paper, we hope to draw attention to
the shortcomings of current literature in measuring personality in LLMs and
call for developing tools for machine personality measurement.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:53:43 GMT""}]","2023-05-25"
"2305.14694","Keith Paarporn","Keith Paarporn, Shouhuai Xu","Analysis of Contagion Dynamics with Active Cyber Defenders","3 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In this paper, we analyze the infection spreading dynamics of malware in a
population of cyber nodes (i.e., computers or devices). Unlike most prior
studies where nodes are reactive to infections, in our setting some nodes are
active defenders meaning that they are able to clean up malware infections of
their neighboring nodes, much like how spreading malware exploits the network
connectivity properties in order to propagate. We formulate these dynamics as
an Active Susceptible-Infected-Susceptible (A-SIS) compartmental model of
contagion. We completely characterize the system's asymptotic behavior by
establishing conditions for the global asymptotic stability of the
infection-free equilibrium and for an endemic equilibrium state. We show that
the presence of active defenders counter-acts infectious spreading, effectively
increasing the epidemic threshold on parameters for which an endemic state
prevails. Leveraging this characterization, we investigate a general class of
problems for finding optimal investments in active cyber defense capabilities
given limited resources. We show that this class of problems has unique
solutions under mild assumptions. We then analyze an Active
Susceptible-Infected-Recovered (A-SIR) compartmental model, where the peak
infection level of any trajectory is explicitly derived.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:57:15 GMT""}]","2023-05-25"
"2305.14695","Fei Wang","Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen","A Causal View of Entity Bias in (Large) Language Models","Work in progress",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entity bias widely affects pretrained (large) language models, causing them
to excessively rely on (biased) parametric knowledge to make unfaithful
predictions. Although causality-inspired methods have shown great potential to
mitigate entity bias, it is hard to precisely estimate the parameters of
underlying causal models in practice. The rise of black-box LLMs also makes the
situation even worse, because of their inaccessible parameters and uncalibrated
logits. To address these problems, we propose a specific structured causal
model (SCM) whose parameters are comparatively easier to estimate. Building
upon this SCM, we propose causal intervention techniques to mitigate entity
bias for both white-box and black-box settings. The proposed causal
intervention perturbs the original entity with neighboring entities. This
intervention reduces specific biasing information pertaining to the original
entity while still preserving sufficient common predictive information from
similar entities. When evaluated on the relation extraction task, our
training-time intervention significantly improves the F1 score of RoBERTa by
5.7 points on EntRED, in which spurious shortcuts between entities and labels
are removed. Meanwhile, our in-context intervention effectively reduces the
knowledge conflicts between parametric knowledge and contextual knowledge in
GPT-3.5 and improves the F1 score by 9.14 points on a challenging test set
derived from Re-TACRED.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:59:18 GMT""}]","2023-05-25"
"2305.14696","Dheeraj Mekala","Dheeraj Mekala, Adithya Samavedhi, Chengyu Dong, Jingbo Shang","SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to
  Rank",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Deep neural classifiers trained with cross-entropy loss (CE loss) often
suffer from poor calibration, necessitating the task of out-of-distribution
(OOD) detection. Traditional supervised OOD detection methods require expensive
manual annotation of in-distribution and OOD samples. To address the annotation
bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that
requires only in-distribution samples as supervision. We cast OOD detection as
an inter-document intra-label (IDIL) ranking problem and train the classifier
with our pairwise ranking loss, referred to as IDIL loss. Specifically, given a
set of in-distribution documents and their labels, for each label, we train the
classifier to rank the softmax scores of documents belonging to that label to
be higher than the scores of documents that belong to other labels. Unlike CE
loss, our IDIL loss function reaches zero when the desired confidence ranking
is achieved and gradients are backpropagated to decrease probabilities
associated with incorrect labels rather than continuously increasing the
probability of the correct label. Extensive experiments with several
classifiers on multiple classification datasets demonstrate the effectiveness
of our method in both coarse- and fine-grained settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:01:27 GMT""}]","2023-05-25"
"2305.14697","Heyi Liang","Yan Fang, Artem M. Rumyantsev, Angelika E. Neitzel, Heyi Liang,
  William T. Heller, Paul F. Nealey, Matthew V. Tirrel, Juan J. de Pablo","Scattering Evidence of Positional Charge Correlations in Polyelectrolyte
  Complexes",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Polyelectrolyte complexation plays an important role in materials science and
biology. The internal structure of the resultant polyelectrolyte complex (PEC)
phase dictates properties such as physical state, response to external stimuli,
and dynamics. Small-angle scattering experiments with X-rays and neutrons have
revealed structural similarities between PECs and semidilute solutions of
neutral polymers, where the total scattering function exhibits an
Ornstein-Zernike form. In spite of consensus among different theoretical
predictions, the existence of positional correlations between polyanion and
polycation charges has not been confirmed experimentally. Here, we present
small-angle neutron scattering profiles where the polycation scattering length
density is matched to that of the solvent to extract positional correlations
among anionic monomers. The polyanion scattering functions exhibit a peak at
the inverse polymer screening radius of Coulomb interactions, $q^{*} \approx
0.2 {\AA}^{-1}$. This peak, attributed to Coulomb repulsions between the
fragments of polyanions and their attractions to polycations, is even more
pronounced in the calculated charge scattering function that quantifies
positional correlations of all polymer charges within the PEC. Screening of
electrostatic interactions by adding salt leads to the gradual disappearance of
this correlation peak, and the scattering functions regain an Ornstein-Zernike
form. Experimental scattering results are consistent with those calculated from
the random phase approximation, a scaling analysis, and molecular simulations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:05:09 GMT""}]","2023-05-25"
"2305.14698","Francisco Rodriguez","Dorothy Kronick and Francisco Rodr\'iguez","Political Conflict and Economic Growth in Post-Independence Venezuela","28 pages, 3 figures",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Venezuela has suffered three economic catastrophes since independence: one
each in the nineteenth, twentieth, and twenty-first centuries. Prominent
explanations for this trilogy point to the interaction of class conflict and
resource dependence. We turn attention to intra-class conflict, arguing that
the most destructive policy choices stemmed not from the rich defending
themselves against the masses but rather from pitched battles among elites.
Others posit that Venezuelan political institutions failed to sustain growth
because they were insufficiently inclusive; we suggest in addition that they
inadequately mediated intra-elite conflict.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:05:56 GMT""}]","2023-05-25"
"2305.14699","Dylan Zhang","Shizhuo Dylan Zhang, Curt Tigges, Stella Biderman, Maxim Raginsky,
  Talia Ringer","Can Transformers Learn to Solve Problems Recursively?",,,,,"cs.LG cs.AI cs.LO cs.PL","http://creativecommons.org/licenses/by/4.0/","  Neural networks have in recent years shown promise for helping software
engineers write programs and even formally verify them. While semantic
information plays a crucial part in these processes, it remains unclear to what
degree popular neural architectures like transformers are capable of modeling
that information. This paper examines the behavior of neural networks learning
algorithms relevant to programs and formal verification proofs through the lens
of mechanistic interpretability, focusing in particular on structural
recursion. Structural recursion is at the heart of tasks on which symbolic
tools currently outperform neural models, like inferring semantic relations
between datatypes and emulating program behavior. We evaluate the ability of
transformer models to learn to emulate the behavior of structurally recursive
functions from input-output examples. Our evaluation includes empirical and
conceptual analyses of the limitations and capabilities of transformer models
in approximating these functions, as well as reconstructions of the ``shortcut""
algorithms the model learns. By reconstructing these algorithms, we are able to
correctly predict 91 percent of failure cases for one of the approximated
functions. Our work provides a new foundation for understanding the behavior of
neural networks that fail to solve the very tasks they are trained for.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:08:37 GMT""}]","2023-05-25"
"2305.14700","Zihui Wu","Zihui Wu, Haichang Gao, Bingqian Zhou, Ping Wang","AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  \emph{Consistent teaching} is an effective paradigm for implementing
knowledge distillation (KD), where both student and teacher models receive
identical inputs, and KD is treated as a function matching task (FunMatch).
However, one limitation of FunMatch is that it does not account for the
transfer of adversarial robustness, a model's resistance to adversarial
attacks. To tackle this problem, we propose a simple but effective strategy
called Adversarial Function Matching (AdvFunMatch), which aims to match
distributions for all data points within the $\ell_p$-norm ball of the training
data, in accordance with consistent teaching. Formulated as a min-max
optimization problem, AdvFunMatch identifies the worst-case instances that
maximizes the KL-divergence between teacher and student model outputs, which we
refer to as ""mismatched examples,"" and then matches the outputs on these
mismatched examples. Our experimental results show that AdvFunMatch effectively
produces student models with both high clean accuracy and robustness.
Furthermore, we reveal that strong data augmentations (\emph{e.g.},
AutoAugment) are beneficial in AdvFunMatch, whereas prior works have found them
less effective in adversarial training. Code is available at
\url{https://gitee.com/zihui998/adv-fun-match}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:09:08 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 02:46:26 GMT""}]","2023-05-26"
"2305.14701","Tom McCoy","R. Thomas McCoy and Thomas L. Griffiths","Modeling rapid language learning by distilling Bayesian priors into
  artificial neural networks","21 pages plus references; 4 figures",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Humans can learn languages from remarkably little experience. Developing
computational models that explain this ability has been a major challenge in
cognitive science. Bayesian models that build in strong inductive biases -
factors that guide generalization - have been successful at explaining how
humans might generalize from few examples in controlled settings but are
usually too restrictive to be tractably applied to more naturalistic data. By
contrast, neural networks have flexible representations that allow them to
learn well from naturalistic data but require many more examples than humans
receive. We show that learning from limited naturalistic data is possible with
an approach that combines the strong inductive biases of a Bayesian model with
the flexible representations of a neural network. This approach works by
distilling a Bayesian model's biases into a neural network. Like a Bayesian
model, the resulting system can learn formal linguistic patterns from a small
number of examples. Like a neural network, it can also learn aspects of English
syntax from a corpus of natural language - and it outperforms a standard neural
network at acquiring the linguistic phenomena of recursion and priming.
Bridging the divide between Bayesian models and neural networks makes it
possible to handle a broader range of learning scenarios than either approach
can handle on its own.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:11:59 GMT""}]","2023-05-25"
"2305.14702","Kaiqiang Song","Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh,
  Fei Liu","Analyzing Influential Factors in Human Preference Judgments via GPT-4",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pairwise human judgments are pivotal in guiding large language models (LLMs)
to generate outputs that align with human preferences. They are also often used
in summarization evaluation, complementing existing automatic metrics. Despite
their significance, however, there has been limited research probing these
pairwise human judgments. The collective impact and respective weights of
factors such as informativeness, coherence, fluency, and factual consistency
remain elusive. The impact of hidden factors on the final judgment is also
unclear. In this paper, we conduct an in-depth examination of a dataset of
pairwise human judgments released by OpenAI. Utilizing the Bradley-Terry-Luce
model, we identify key factors that could potentially influence human
judgments. Our research uncovers the inherent preferences embedded in human
judgments and suggests strategies to boost sample efficiency. Finally, we
provide insights on the construction of balanced datasets for human judgment
evaluations, a crucial step in shaping the behaviors of future LLMs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:13:15 GMT""}]","2023-05-25"
"2305.14703","Ting Wang","Ting Wang, Petr Plechac, Jaroslaw Knap","Generative diffusion learning for parametric partial differential
  equations",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We develop a class of data-driven generative models that approximate the
solution operator for parameter-dependent partial differential equations (PDE).
We propose a novel probabilistic formulation of the operator learning problem
based on recently developed generative denoising diffusion probabilistic models
(DDPM) in order to learn the input-to-output mapping between problem parameters
and solutions of the PDE. To achieve this goal we modify DDPM to supervised
learning in which the solution operator for the PDE is represented by a class
of conditional distributions. The probabilistic formulation combined with DDPM
allows for an automatic quantification of confidence intervals for the learned
solutions. Furthermore, the framework is directly applicable for learning from
a noisy data set. We compare computational performance of the developed method
with the Fourier Network Operators (FNO). Our results show that our method
achieves comparable accuracy and recovers the noise magnitude when applied to
data sets with outputs corrupted by additive noise.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:15:34 GMT""}]","2023-05-25"
"2305.14704","Zezhong Zhang","Zezhong Zhang and Ted Yuan","An Evaluation on Practical Batch Bayesian Sampling Algorithms for Online
  Adaptive Traffic Experimentation",,,,,"cs.LG stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To speed up online testing, adaptive traffic experimentation through
multi-armed bandit algorithms is rising as an essential complementary
alternative to the fixed horizon A/B testing. Based on recent research on best
arm identification and statistical inference with adaptively collected data,
this paper derives and evaluates four Bayesian batch bandit algorithms (NB-TS,
WB-TS, NB-TTTS, WB-TTTS), which are combinations of two ways of weighting
batches (Naive Batch and Weighted Batch) and two Bayesian sampling strategies
(Thompson Sampling and Top-Two Thompson Sampling) to adaptively determine
traffic allocation. These derived Bayesian sampling algorithms are practically
based on summary batch statistics of a reward metric for pilot experiments,
where one of the combination WB-TTTS in this paper seems to be newly discussed.
The comprehensive evaluation on the four Bayesian sampling algorithms covers
trustworthiness, sensitivity and regret of a testing methodology. Moreover, the
evaluation includes 4 real-world eBay experiments and 40 reproducible synthetic
experiments to reveal the learnings, which covers both stationary and
non-stationary situations. Our evaluation reveals that, (a) There exist false
positives inflation with equivalent best arms, while seldom discussed in
literatures; (b) To control false positives, connections between convergence of
posterior optimal probabilities and neutral posterior reshaping are discovered;
(c) WB-TTTS shows competitive recall, higher precision, and robustness against
non-stationary trend; (d) NB-TS outperforms on minimizing regret trials except
on precision and robustness; (e) WB-TTTS is a promising alternative if regret
of A/B Testing is affordable, otherwise NB-TS is still a powerful choice with
regret consideration for pilot experiments.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:16:56 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 21:38:01 GMT""}]","2023-05-29"
"2305.14705","Sheng Shen","Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei,
  Hyung Won Chung, Barret Zoph, William Fedus, Xinyun Chen, Tu Vu, Yuexin Wu,
  Wuyang Chen, Albert Webson, Yunxuan Li, Vincent Zhao, Hongkun Yu, Kurt
  Keutzer, Trevor Darrell, Denny Zhou","Flan-MoE: Scaling Instruction-Finetuned Language Models with Sparse
  Mixture of Experts","Preprint",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The explosive growth of language models and their applications have led to an
increased demand for efficient and scalable methods. In this paper, we
introduce Flan-MoE, a set of Instruction-Finetuned Sparse Mixture-of-Expert
(MoE) models. We show that naively finetuning MoE models on a task-specific
dataset (in other words, no instruction-finetuning) often yield worse
performance compared to dense models of the same computational complexity.
However, our Flan-MoE outperforms dense models under multiple experiment
settings: instruction-finetuning only and instruction-finetuning followed by
task-specific finetuning. This shows that instruction-finetuning is an
essential stage for MoE models. Specifically, our largest model, Flan-MoE-32B,
surpasses the performance of Flan-PaLM-62B on four benchmarks, while utilizing
only one-third of the FLOPs. The success of Flan-MoE encourages rethinking the
design of large-scale, high-performance language models, under the setting of
task-agnostic learning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:22:26 GMT""}]","2023-05-25"
"2305.14706","Yushan Su","Yushan Su, Vishvak Murahari, Karthik Narasimhan, Kai Li","PruMUX: Augmenting Data Multiplexing with Model Compression","Findings of the Association for Computational Linguistics (ACL 2023)",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  As language models increase in size by the day, methods for efficient
inference are critical to leveraging their capabilities for various
applications. Prior work has investigated techniques like model pruning,
knowledge distillation, and data multiplexing to increase model throughput
without sacrificing accuracy. In this paper, we combine two such methods --
structured pruning and data multiplexing -- to compound the speedup gains
obtained by either method. Our approach, PruMUX, obtains up to 7.5-29.5X
throughput improvement over BERT-base model with accuracy threshold from 80% to
74%. We further study various combinations of parameters (such as sparsity and
multiplexing factor) in the two techniques to provide a comprehensive analysis
of the tradeoff between accuracy and throughput in the resulting models. We
then propose Auto-PruMUX, a meta-level model that can predict the
high-performance parameters for pruning and multiplexing given a desired
accuracy loss budget, providing a practical method to leverage the combination
effectively.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:22:38 GMT""}]","2023-05-25"
"2305.14707","Dhananjay Ashok","Dhananjay Ashok, Atharva Kulkarni, Hai Pham, Barnab\'as P\'oczos","The student becomes the master: Matching GPT3 on Scientific Factual
  Error Correction",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Due to the prohibitively high cost of creating error correction datasets,
most Factual Claim Correction methods rely on a powerful verification model to
guide the correction process. This leads to a significant drop in performance
in domains like Scientific Claim Correction, where good verification models do
not always exist. In this work, we introduce a claim correction system that
makes no domain assumptions and does not require a verifier but is able to
outperform existing methods by an order of magnitude -- achieving 94%
correction accuracy on the SciFact dataset, and 62.5% on the SciFact-Open
dataset, compared to the next best methods 0.5% and 1.50% respectively. Our
method leverages the power of prompting with LLMs during training to create a
richly annotated dataset that can be used for fully supervised training and
regularization. We additionally use a claim-aware decoding procedure to improve
the quality of corrected claims. Our method is competitive with the very LLM
that was used to generate the annotated dataset -- with GPT3.5 achieving 89.5%
and 60% correction accuracy on SciFact and SciFact-Open, despite using 1250
times as many parameters as our model.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:24:16 GMT""}]","2023-05-25"
"2305.14708","Yichen Chi","Yichen Chi, Junhao Gu, Jiamiao Zhang, Wenming Yang, Yapeng Tian","EgoVSR: Towards High-Quality Egocentric Video Super-Resolution",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the limitations of capture devices and scenarios, egocentric videos
frequently have low visual quality, mainly caused by high compression and
severe motion blur. With the increasing application of egocentric videos, there
is an urgent need to enhance the quality of these videos through
super-resolution. However, existing Video Super-Resolution (VSR) works,
focusing on third-person view videos, are actually unsuitable for handling
blurring artifacts caused by rapid ego-motion and object motion in egocentric
videos. To this end, we propose EgoVSR, a VSR framework specifically designed
for egocentric videos. We explicitly tackle motion blurs in egocentric videos
using a Dual Branch Deblur Network (DB$^2$Net) in the VSR framework. Meanwhile,
a blurring mask is introduced to guide the DB$^2$Net learning, and can be used
to localize blurred areas in video frames. We also design a MaskNet to predict
the mask, as well as a mask loss to optimize the mask estimation. Additionally,
an online motion blur synthesis model for common VSR training data is proposed
to simulate motion blurs as in egocentric videos. In order to validate the
effectiveness of our proposed method, we introduce an EgoVSR dataset containing
a large amount of fast-motion egocentric video sequences. Extensive experiments
demonstrate that our EgoVSR model can efficiently super-resolve low-quality
egocentric videos and outperform strong comparison baselines. Our code,
pre-trained models, and data will be released.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:25:51 GMT""}]","2023-05-25"
"2305.14709","Gabriele Farina","Gabriele Farina and Julien Grand-Cl\'ement and Christian Kroer and
  Chung-Wei Lee and Haipeng Luo","Regret Matching+: (In)Stability and Fast Convergence in Games",,,,,"cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regret Matching+ (RM+) and its variants are important algorithms for solving
large-scale games. However, a theoretical understanding of their success in
practice is still a mystery. Moreover, recent advances on fast convergence in
games are limited to no-regret algorithms such as online mirror descent, which
satisfy stability. In this paper, we first give counterexamples showing that
RM+ and its predictive version can be unstable, which might cause other players
to suffer large regret. We then provide two fixes: restarting and chopping off
the positive orthant that RM+ works in. We show that these fixes are sufficient
to get $O(T^{1/4})$ individual regret and $O(1)$ social regret in normal-form
games via RM+ with predictions. We also apply our stabilizing techniques to
clairvoyant updates in the uncoupled learning setting for RM+ and prove
desirable results akin to recent works for Clairvoyant online mirror descent.
Our experiments show the advantages of our algorithms over vanilla RM+-based
algorithms in matrix and extensive-form games.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:26:21 GMT""}]","2023-05-25"
"2305.14710","Muhao Chen","Jiashu Xu, Mingyu Derek Ma, Fei Wang, Chaowei Xiao, Muhao Chen","Instructions as Backdoors: Backdoor Vulnerabilities of Instruction
  Tuning for Large Language Models",,,,,"cs.CL cs.AI cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Instruction-tuned models are trained on crowdsourcing datasets with task
instructions to achieve superior performance. However, in this work we raise
security concerns about this training paradigm. Our studies demonstrate that an
attacker can inject backdoors by issuing very few malicious instructions among
thousands of gathered data and control model behavior through data poisoning,
without even the need of modifying data instances or labels themselves. Through
such instruction attacks, the attacker can achieve over 90% attack success rate
across four commonly used NLP datasets, and cause persistent backdoors that are
easily transferred to 15 diverse datasets zero-shot. In this way, the attacker
can directly apply poisoned instructions designed for one dataset on many other
datasets. Moreover, the poisoned model cannot be cured by continual learning.
Lastly, instruction attacks show resistance to existing inference-time defense.
These findings highlight the need for more robust defenses against data
poisoning attacks in instructiontuning models and underscore the importance of
ensuring data quality in instruction crowdsourcing.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:27:21 GMT""}]","2023-05-25"
"2305.14711","Haoyi Qiu","Haoyi Qiu, Zi-Yi Dou, Tianlu Wang, Asli Celikyilmaz, Nanyun Peng","Gender Biases in Automatic Evaluation Metrics: A Case Study on Image
  Captioning",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pretrained model-based evaluation metrics have demonstrated strong
performance with high correlations with human judgments in various natural
language generation tasks such as image captioning. Despite the impressive
results, their impact on fairness is under-explored -- it is widely
acknowledged that pretrained models can encode societal biases, and utilizing
them for evaluation purposes may inadvertently manifest and potentially amplify
biases. In this paper, we conduct a systematic study in gender biases of
model-based evaluation metrics with a focus on image captioning tasks.
Specifically, we first identify and quantify gender biases in different
evaluation metrics regarding profession, activity, and object concepts. Then,
we demonstrate the negative consequences of using these biased metrics, such as
favoring biased generation models in deployment and propagating the biases to
generation models through reinforcement learning. We also present a simple but
effective alternative to reduce gender biases by combining n-gram
matching-based and pretrained model-based evaluation metrics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:27:40 GMT""}]","2023-05-25"
"2305.14712","Mingyang Yi","Mingyang Yi, Jiacheng Sun, Zhenguo Li","On the Generalization of Diffusion Model",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The diffusion probabilistic generative models are widely used to generate
high-quality data. Though they can synthetic data that does not exist in the
training set, the rationale behind such generalization is still unexplored. In
this paper, we formally define the generalization of the generative model,
which is measured by the mutual information between the generated data and the
training set. The definition originates from the intuition that the model which
generates data with less correlation to the training set exhibits better
generalization ability. Meanwhile, we show that for the empirical optimal
diffusion model, the data generated by a deterministic sampler are all highly
related to the training set, thus poor generalization. This result contradicts
the observation of the trained diffusion model's (approximating empirical
optima) extrapolation ability (generating unseen data). To understand this
contradiction, we empirically verify the difference between the sufficiently
trained diffusion model and the empirical optima. We found, though obtained
through sufficient training, there still exists a slight difference between
them, which is critical to making the diffusion model generalizable. Moreover,
we propose another training objective whose empirical optimal solution has no
potential generalization problem. We empirically show that the proposed
training objective returns a similar model to the original one, which further
verifies the generalization ability of the trained diffusion model.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:27:57 GMT""}]","2023-05-25"
"2305.14713","Yixiong Yan","Yixiong Yan, Liangzhu Cheng, Yongxu Li, Xinjuan Tuo","Streaming Object Detection on Fisheye Cameras for Automatic Parking",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fisheye cameras are widely employed in automatic parking, and the video
stream object detection (VSOD) of the fisheye camera is a fundamental
perception function to ensure the safe operation of vehicles. In past research
work, the difference between the output of the deep learning model and the
actual situation at the current moment due to the existence of delay of the
perception system is generally ignored. But the environment will inevitably
change within the delay time which may cause a potential safety hazard. In this
paper, we propose a real-time detection framework equipped with a dual-flow
perception module (dynamic and static flows) that can predict the future and
alleviate the time-lag problem. Meanwhile, we use a new scheme to evaluate
latency and accuracy. The standard bounding box is unsuitable for the object in
fisheye camera images due to the strong radial distortion of the fisheye camera
and the primary detection objects of parking perception are vehicles and
pedestrians, so we adopt the rotate bounding box and propose a new periodic
angle loss function to regress the angle of the box, which is the simple and
accurate representation method of objects. The instance segmentation ground
truth is used to supervise the training. Experiments demonstrate the
effectiveness of our approach. Code is released at:
https://gitee.com/hiyanyx/fisheye-streaming-perception.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:30:25 GMT""}]","2023-05-25"
"2305.14714","Ximo Gallud Cidoncha","Ximo Gallud and Paulo C. Lozano","The limited effect of electric conductivity on the ion current
  evaporated from electrospray sources",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electrohydrodynamic modeling and experimental observations indicate that the
ion evaporation current emitted by passively-fed electrospray sources is
independent of the electrical conductivity of the ionic liquid. This contrasts
with cone-jet electrosprays, in which current depends on conductivity at fixed
flow rates. The current in the pure ionic regime is controlled by the bias
voltage and flow impedance, where a low viscosity is key for its enhancement.
In addition to clarifying the role of electric conductivity in ionic liquid ion
sources, this observation provides guidance to the selection of liquid
properties for a particular application.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:32:49 GMT""}]","2023-05-25"
"2305.14715","Daehee Park","Daehee Park, Hobin Ryu, Yunseo Yang, Jegyeong Cho, Jiwon Kim, Kuk-Jin
  Yoon","Leveraging Future Relationship Reasoning for Vehicle Trajectory
  Prediction","ICLR 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the interaction between multiple agents is crucial for
realistic vehicle trajectory prediction. Existing methods have attempted to
infer the interaction from the observed past trajectories of agents using
pooling, attention, or graph-based methods, which rely on a deterministic
approach. However, these methods can fail under complex road structures, as
they cannot predict various interactions that may occur in the future. In this
paper, we propose a novel approach that uses lane information to predict a
stochastic future relationship among agents. To obtain a coarse future motion
of agents, our method first predicts the probability of lane-level waypoint
occupancy of vehicles. We then utilize the temporal probability of passing
adjacent lanes for each agent pair, assuming that agents passing adjacent lanes
will highly interact. We also model the interaction using a probabilistic
distribution, which allows for multiple possible future interactions. The
distribution is learned from the posterior distribution of interaction obtained
from ground truth future trajectories. We validate our method on popular
trajectory prediction datasets: nuScenes and Argoverse. The results show that
the proposed method brings remarkable performance gain in prediction accuracy,
and achieves state-of-the-art performance in long-term prediction benchmark
dataset.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:33:28 GMT""}]","2023-05-25"
"2305.14716","Yueqi Song","Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei Liu, Fahim Faisal,
  Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya,
  Yulia Tsvetkov, Antonios Anastasopoulos and Graham Neubig","GlobalBench: A Benchmark for Global Progress in Natural Language
  Processing","Preprint, 9 pages",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the major advances in NLP, significant disparities in NLP system
performance across languages still exist. Arguably, these are due to uneven
resource allocation and sub-optimal incentives to work on less resourced
languages. To track and further incentivize the global development of equitable
language technology, we introduce GlobalBench. Prior multilingual benchmarks
are static and have focused on a limited number of tasks and languages. In
contrast, GlobalBench is an ever-expanding collection that aims to dynamically
track progress on all NLP datasets in all languages. Rather than solely
measuring accuracy, GlobalBench also tracks the estimated per-speaker utility
and equity of technology across all languages, providing a multi-faceted view
of how language technology is serving people of the world. Furthermore,
GlobalBench is designed to identify the most under-served languages, and
rewards research efforts directed towards those languages. At present, the most
under-served languages are the ones with a relatively high population, but
nonetheless overlooked by composite multilingual benchmarks (like Punjabi,
Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190
languages, and has 1,128 system submissions spanning 62 languages.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:36:32 GMT""}]","2023-05-25"
"2305.14717","Linhan Zhang","Linhan Zhang, Qian Chen, Wen Wang, Yuxin Jiang, Bing Li, Wei Wang, Xin
  Cao","Exploiting Correlations Between Contexts and Definitions with Multiple
  Definition Modeling",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Definition modeling is an important task in advanced natural language
applications such as understanding and conversation. Since its introduction, it
focus on generating one definition for a target word or phrase in a given
context, which we refer to as Single Definition Modeling (SDM). However, this
approach does not adequately model the correlations and patterns among
different contexts and definitions of words. In addition, the creation of a
training dataset for SDM requires significant human expertise and effort. In
this paper, we carefully design a new task called Multiple Definition Modeling
(MDM) that pool together all contexts and definition of target words. We
demonstrate the ease of creating a model as well as multiple training sets
automatically. % In the experiments, we demonstrate and analyze the benefits of
MDM, including improving SDM's performance by using MDM as the pretraining task
and its comparable performance in the zero-shot setting.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:38:29 GMT""}]","2023-05-25"
"2305.14718","Ashutosh Baheti","Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap,
  Mark Riedl","Improving Language Models with Advantage-based Offline Policy Gradients",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Improving language model generations according to some user-defined quality
or style constraints is challenging. Typical approaches include learning on
additional human-written data, filtering ``low-quality'' data using heuristics
and/or using reinforcement learning with human feedback (RLHF). However,
filtering can remove valuable training signals, whereas data collection and
RLHF constantly require additional human-written or LM exploration data which
can be costly to obtain. A natural question to ask is ``Can we leverage RL to
optimize LM utility on existing crowd-sourced and internet data?''
  To this end, we present Left-over Lunch RL (LoL-RL), a simple training
algorithm that uses offline policy gradients for learning language generation
tasks as a 1-step RL game. LoL-RL can finetune LMs to optimize arbitrary
classifier-based or human-defined utility functions on any sequence-to-sequence
data. Experiments with five different language generation tasks using models of
varying sizes and multiple rewards show that models trained with LoL-RL can
consistently outperform the best supervised learning models. We also release
our experimental code. https://github.com/abaheti95/LoL-RL
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:42:17 GMT""}]","2023-05-25"
"2305.14719","Michael Kranzlein","Michael Kranzlein, Nathan Schneider, Kevin Tobia","CuRIAM: Corpus re Interpretation and Metalanguage in U.S. Supreme Court
  Opinions",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most judicial decisions involve the interpretation of legal texts; as such,
judicial opinion requires the use of language as a medium to comment on or draw
attention to other language. Language used this way is called metalanguage. We
develop an annotation schema for categorizing types of legal metalanguage and
apply our schema to a set of U.S. Supreme Court opinions, yielding a corpus
totaling 59k tokens. We remark on several patterns observed in the kinds of
metalanguage used by the justices.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:47:55 GMT""}]","2023-05-25"
"2305.14720","Dongxu Li","Dongxu Li, Junnan Li, Steven C.H. Hoi","BLIP-Diffusion: Pre-trained Subject Representation for Controllable
  Text-to-Image Generation and Editing",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Subject-driven text-to-image generation models create novel renditions of an
input subject based on text prompts. Existing models suffer from lengthy
fine-tuning and difficulties preserving the subject fidelity. To overcome these
limitations, we introduce BLIP-Diffusion, a new subject-driven image generation
model that supports multimodal control which consumes inputs of subject images
and text prompts. Unlike other subject-driven generation models, BLIP-Diffusion
introduces a new multimodal encoder which is pre-trained to provide subject
representation. We first pre-train the multimodal encoder following BLIP-2 to
produce visual representation aligned with the text. Then we design a subject
representation learning task which enables a diffusion model to leverage such
visual representation and generates new subject renditions. Compared with
previous methods such as DreamBooth, our model enables zero-shot subject-driven
generation, and efficient fine-tuning for customized subject with up to 20x
speedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with
existing techniques such as ControlNet and prompt-to-prompt to enable novel
subject-driven generation and editing applications. Code and models will be
released at
https://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project
page at https://dxli94.github.io/BLIP-Diffusion-website/.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:51:04 GMT""}]","2023-05-25"
"2305.14721","Manil T Mohan","Manil T. Mohan","Approximations of 2D and 3D Stochastic Convective Brinkman-Forchheimer
  Extended Darcy Equations",,,,,"math.PR","http://creativecommons.org/publicdomain/zero/1.0/","  In this article, we consider two- and three- dimensional stochastic
convective Brinkman-Forchheimer extended Darcy (CBFeD) equations
\begin{equation*} \frac{\partial \boldsymbol{u}}{\partial t}-\mu
\Delta\boldsymbol{u}+(\boldsymbol{u}\cdot\nabla)\boldsymbol{u}+\alpha|\boldsymbol{u}|^{q-1}\boldsymbol{u}+\beta|\boldsymbol{u}|^{r-1}\boldsymbol{u}+\nabla
p=\boldsymbol{f},\ \nabla\cdot\boldsymbol{u}=0, \end{equation*} on a torus,
where $\mu,\beta>0$, $\alpha\in\mathbb{R}$, $r\in[1,\infty)$ and $q\in[1,r)$.
The goal is to show that the solutions of 2D and 3D stochastic CBFeD equations
driven by Brownian motion can be approximated by 2D and 3D stochastic CBFeD
equations forced by pure jump noise/random kicks on on the state space
$\mathrm{D}([0,T];\mathbb{H})$. The results are established for
$d=2,r\in[1,\infty)$ and $d=3,r\in[3,\infty)$ with $2\beta\mu\geq 1$ for
$d=r=3,$ and by using less regular assumptions on the noise coefficient.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:53:53 GMT""}]","2023-05-25"
"2305.14722","Hao Chen","Hao Chen, Haotian Zhang, Keyan Chen, Chenyao Zhou, Song Chen, Zhengxia
  Zhou, Zhenwei Shi","Remote Sensing Image Change Detection Towards Continuous Bitemporal
  Resolution Differences","19 pages, 11 figures. Submitted to the IEEE for a possible
  publication",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most contemporary supervised Remote Sensing (RS) image Change Detection (CD)
approaches are customized for equal-resolution bitemporal images. Real-world
applications raise the need for cross-resolution change detection, aka, CD
based on bitemporal images with different spatial resolutions. Current
cross-resolution methods that are trained with samples of a fixed resolution
difference (resolution ratio between the high-resolution (HR) image and the
low-resolution (LR) one) may fit a certain ratio but lack adaptation to other
resolution differences. Toward continuous cross-resolution CD, we propose
scale-invariant learning to enforce the model consistently predicting HR
results given synthesized samples of varying bitemporal resolution differences.
Concretely, we synthesize blurred versions of the HR image by random
downsampled reconstructions to reduce the gap between HR and LR images. We
introduce coordinate-based representations to decode per-pixel predictions by
feeding the coordinate query and corresponding multi-level embedding features
into an MLP that implicitly learns the shape of land cover changes, therefore
benefiting recognizing blurred objects in the LR image. Moreover, considering
that spatial resolution mainly affects the local textures, we apply
local-window self-attention to align bitemporal features during the early
stages of the encoder. Extensive experiments on two synthesized and one
real-world different-resolution CD datasets verify the effectiveness of the
proposed method. Our method significantly outperforms several vanilla CD
methods and two cross-resolution CD methods on the three datasets both in
in-distribution and out-of-distribution settings. The empirical results suggest
that our method could yield relatively consistent HR change predictions
regardless of varying resolution difference ratios. Our code will be public.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:57:24 GMT""}]","2023-05-25"
"2305.14723","Hiroshi Sato","Hiroshi Sato, Ryo Masumura, Tsubasa Ochiai, Marc Delcroix, Takafumi
  Moriya, Takanori Ashihara, Kentaro Shinayama, Saki Mizuno, Mana Ihori,
  Tomohiro Tanaka, Nobukatsu Hojo","Downstream Task Agnostic Speech Enhancement with Self-Supervised
  Representation Loss","4 pages , 2 figures, Accepted to Interspeech 2023",,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Self-supervised learning (SSL) is the latest breakthrough in speech
processing, especially for label-scarce downstream tasks by leveraging massive
unlabeled audio data. The noise robustness of the SSL is one of the important
challenges to expanding its application. We can use speech enhancement (SE) to
tackle this issue. However, the mismatch between the SE model and SSL models
potentially limits its effect. In this work, we propose a new SE training
criterion that minimizes the distance between clean and enhanced signals in the
feature representation of the SSL model to alleviate the mismatch. We expect
that the loss in the SSL domain could guide SE training to preserve or enhance
various levels of characteristics of the speech signals that may be required
for high-level downstream tasks. Experiments show that our proposal improves
the performance of an SE and SSL pipeline on five downstream tasks with noisy
input while maintaining the SE performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:00:30 GMT""}]","2023-05-25"
"2305.14724","Tuhin Chakrabarty Mr","Tuhin Chakrabarty, Arkadiy Saakyan, Olivia Winn, Artemis Panagopoulou,
  Yue Yang, Marianna Apidianaki, Smaranda Muresan","I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create
  Visual Metaphors","ACL 2023 (Findings)",,,,"cs.CL cs.AI cs.CV cs.HC","http://creativecommons.org/licenses/by/4.0/","  Visual metaphors are powerful rhetorical devices used to persuade or
communicate creative ideas through images. Similar to linguistic metaphors,
they convey meaning implicitly through symbolism and juxtaposition of the
symbols. We propose a new task of generating visual metaphors from linguistic
metaphors. This is a challenging task for diffusion-based text-to-image models,
such as DALL$\cdot$E 2, since it requires the ability to model implicit meaning
and compositionality. We propose to solve the task through the collaboration
between Large Language Models (LLMs) and Diffusion Models: Instruct GPT-3
(davinci-002) with Chain-of-Thought prompting generates text that represents a
visual elaboration of the linguistic metaphor containing the implicit meaning
and relevant objects, which is then used as input to the diffusion-based
text-to-image models.Using a human-AI collaboration framework, where humans
interact both with the LLM and the top-performing diffusion model, we create a
high-quality dataset containing 6,476 visual metaphors for 1,540 linguistic
metaphors and their associated visual elaborations. Evaluation by professional
illustrators shows the promise of LLM-Diffusion Model collaboration for this
task.To evaluate the utility of our Human-AI collaboration framework and the
quality of our dataset, we perform both an intrinsic human-based evaluation and
an extrinsic evaluation using visual entailment as a downstream task.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:01:10 GMT""}]","2023-05-25"
"2305.14725","Barry Menglong Yao","Barry Menglong Yao, Yu Chen, Qifan Wang, Sijia Wang, Minqian Liu,
  Zhiyang Xu, Licheng Yu, Lifu Huang","AMELI: Enhancing Multimodal Entity Linking with Fine-Grained Attributes","12 pages, 4 figures",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We propose attribute-aware multimodal entity linking, where the input is a
mention described with a text and image, and the goal is to predict the
corresponding target entity from a multimodal knowledge base (KB) where each
entity is also described with a text description, a visual image and a set of
attributes and values. To support this research, we construct AMELI, a
large-scale dataset consisting of 18,472 reviews and 35,598 products. To
establish baseline performance on AMELI, we experiment with the current
state-of-the-art multimodal entity linking approaches and our enhanced
attribute-aware model and demonstrate the importance of incorporating the
attribute information into the entity linking process. To be best of our
knowledge, we are the first to build benchmark dataset and solutions for the
attribute-aware multimodal entity linking task. Datasets and codes will be made
publicly available.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:01:48 GMT""}]","2023-05-25"
"2305.14726","Dan Iter","Dan Iter, Reid Pryzant, Ruochen Xu, Shuohang Wang, Yang Liu, Yichong
  Xu, Chenguang Zhu","In-Context Demonstration Selection with Cross Entropy Difference",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LLMs) can use in-context demonstrations to improve
performance on zero-shot tasks. However, selecting the best in-context examples
is challenging because model performance can vary widely depending on the
selected examples. We present a cross-entropy difference (CED) method for
selecting in-context demonstrations. Our method is based on the observation
that the effectiveness of in-context demonstrations negatively correlates with
the perplexity of the test example by a language model that was finetuned on
that demonstration. We utilize parameter efficient finetuning to train small
models on training data that are used for computing the cross-entropy
difference between a test example and every candidate in-context demonstration.
This metric is used to rank and select in-context demonstrations independently
for each test input. We evaluate our method on a mix-domain dataset that
combines 8 benchmarks, representing 4 text generation tasks, showing that CED
for in-context demonstration selection can improve performance for a variety of
LLMs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:04:00 GMT""}]","2023-05-25"
"2305.14727","Pierre Senellart","Angelo Saadeh and Pierre Senellart and St\'ephane Bressan","Confidential Truth Finding with Multi-Party Computation (Extended
  Version)","15-page extended version of a paper published at DEXA 2023",,,,"cs.CR cs.DB","http://creativecommons.org/licenses/by/4.0/","  Federated knowledge discovery and data mining are challenged to assess the
trustworthiness of data originating from autonomous sources while protecting
confidentiality and privacy. Truth-finding algorithms help corroborate data
from disagreeing sources. For each query it receives, a truth-finding algorithm
predicts a truth value of the answer, possibly updating the trustworthiness
factor of each source. Few works, however, address the issues of
confidentiality and privacy. We devise and present a secure
secret-sharing-based multi-party computation protocol for pseudo-equality tests
that are used in truth-finding algorithms to compute additions depending on a
condition. The protocol guarantees confidentiality of the data and privacy of
the sources. We also present variants of truth-finding algorithms that would
make the computation faster when executed using secure multi-party computation.
We empirically evaluate the performance of the proposed protocol on two
state-of-the-art truth-finding algorithms, Cosine, and 3-Estimates, and compare
them with that of the baseline plain algorithms. The results confirm that the
secret-sharing-based secure multi-party algorithms are as accurate as the
corresponding baselines but for proposed numerical approximations that
significantly reduce the efficiency loss incurred.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:06:03 GMT""}]","2023-05-25"
"2305.14728","Victoria Lin","Victoria Lin, Louis-Philippe Morency","SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language
  Representations","Accepted to Findings of ACL 2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although deep language representations have become the dominant form of
language featurization in recent years, in many settings it is important to
understand a model's decision-making process. This necessitates not only an
interpretable model but also interpretable features. In particular, language
must be featurized in a way that is interpretable while still characterizing
the original text well. We present SenteCon, a method for introducing human
interpretability in deep language representations. Given a passage of text,
SenteCon encodes the text as a layer of interpretable categories in which each
dimension corresponds to the relevance of a specific category. Our empirical
evaluations indicate that encoding language with SenteCon provides high-level
interpretability at little to no cost to predictive performance on downstream
tasks. Moreover, we find that SenteCon outperforms existing interpretable
language representations with respect to both its downstream performance and
its agreement with human characterizations of the text.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:06:28 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 20:55:25 GMT""}]","2023-06-05"
"2305.14729","Yuto Sano","Nobuyuki Shukuno, Yuto Sano, Makoto Tsubota","Faraday Waves in Bose-Einstein Condensates -- The Excitation by the
  Modulation of the Interaction and the Potential","7 pages, 14 figures","J. Phys. Soc. Jpn. 92, 064602 (2023)","10.7566/JPSJ.92.064602",,"cond-mat.quant-gas physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We numerically study the dynamics of Faraday waves for Bose-Einstein
condensates(BECs) trapped by anisotropic potentials using the three-dimensional
Gross-Pitaevskii equation. In previous studies, Faraday waves were excited by
periodic modulation of the interaction or potential; in contrast, this study
systematically addresses the excitations of the two methods. When the
interaction is modulated with a modulation frequency resonant with Faraday
waves, the breathing mode along the tight confinement direction is excited, and
the Faraday waves appear in the direction of weak confinement. A modulation
frequency that is not resonant with Faraday waves does not excite Faraday
waves. Thus, the dynamics depend on modulation frequencies. The behavior of the
total energy and its decomposition characterize the dynamics. The excitation of
Faraday waves depends on the anisotropy of the potentials as well; Faraday
waves are excited only for elongated BECs. We compare the differences of the
dynamics in modulation methods. There are no qualitative differences between
the modulation of the interaction and potential. When the interaction and
potential are simultaneously modulated, Faraday waves are excited but they do
not necessarily work additively. To understand this phenomenon as a dynamical
system, we choose a few dynamical variables and follow their trajectory in a
phase space. The trajectory characteristics of Faraday waves and the breathing
mode show that the methods of modulation are not very relevant; determining the
target mode to excite is important.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:06:28 GMT""}]","2023-05-25"
"2305.14730","Junrui Xiao","Junrui Xiao, Zhikai Li, Lianwei Yang, Qingyi Gu","BinaryViT: Towards Efficient and Accurate Binary Vision Transformers",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vision Transformers (ViTs) have emerged as the fundamental architecture for
most computer vision fields, but the considerable memory and computation costs
hinders their application on resource-limited devices. As one of the most
powerful compression methods, binarization reduces the computation of the
neural network by quantizing the weights and activation values as $\pm$1.
Although existing binarization methods have demonstrated excellent performance
on Convolutional Neural Networks (CNNs), the full binarization of ViTs is still
under-studied and suffering a significant performance drop. In this paper, we
first argue empirically that the severe performance degradation is mainly
caused by the weight oscillation in the binarization training and the
information distortion in the activation of ViTs. Based on these analyses, we
propose $\textbf{BinaryViT}$, an accurate full binarization scheme for ViTs,
which pushes the quantization of ViTs to the limit. Specifically, we propose a
novel gradient regularization scheme (GRS) for driving a bimodal distribution
of the weights to reduce oscillation in binarization training. Moreover, we
design an activation shift module (ASM) to adaptively tune the activation
distribution to reduce the information distortion caused by binarization.
Extensive experiments on ImageNet dataset show that our BinaryViT consistently
surpasses the strong baseline by 2.05% and improve the accuracy of fully
binarized ViTs to a usable level. Furthermore, our method achieves impressive
savings of 16.2$\times$ and 17.7$\times$ in model size and OPs compared to the
full-precision DeiT-S. The codes and models will be released on github.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:06:59 GMT""}]","2023-05-25"
"2305.14731","Peyman Gholami","Peyman Gholami and Robert Xiao","AutoDepthNet: High Frame Rate Depth Map Reconstruction using Commodity
  Depth and RGB Cameras",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depth cameras have found applications in diverse fields, such as computer
vision, artificial intelligence, and video gaming. However, the high latency
and low frame rate of existing commodity depth cameras impose limitations on
their applications. We propose a fast and accurate depth map reconstruction
technique to reduce latency and increase the frame rate in depth cameras. Our
approach uses only a commodity depth camera and color camera in a hybrid camera
setup; our prototype is implemented using a Kinect Azure depth camera at 30 fps
and a high-speed RGB iPhone 11 Pro camera captured at 240 fps. The proposed
network, AutoDepthNet, is an encoder-decoder model that captures frames from
the high-speed RGB camera and combines them with previous depth frames to
reconstruct a stream of high frame rate depth maps. On GPU, with a 480 x 270
output resolution, our system achieves an inference time of 8 ms, enabling
real-time use at up to 200 fps with parallel processing. AutoDepthNet can
estimate depth values with an average RMS error of 0.076, a 44.5% improvement
compared to an optical flow-based comparison method. Our method can also
improve depth map quality by estimating depth values for missing and
invalidated pixels. The proposed method can be easily applied to existing depth
cameras and facilitates the use of depth cameras in applications that require
high-speed depth estimation. We also showcase the effectiveness of the
framework in upsampling different sparse datasets e.g. video object
segmentation. As a demonstration of our method, we integrated our framework
into existing body tracking systems and demonstrated the robustness of the
proposed method in such applications.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:09:43 GMT""}]","2023-05-25"
"2305.14732","Xu Shen","Jacopo Guanetti, Yeojun Kim, Xu Shen, Joel Donham, Santosh Alexander,
  Bruce Wootton, Francesco Borrelli","Increasing Electric Vehicles Utilization in Transit Fleets using
  Learning, Predictions, Optimization, and Automation","Accepted at the 35th IEEE Intelligent Vehicles Symposium (IV 2023)",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents a novel hierarchical approach to increase Battery Electric
Buses (BEBs) utilization in transit fleets. The proposed approach relies on
three key components. A learning-based BEB digital twin cloud platform is used
to accurately predict BEB charge consumption on a per vehicle, per driver, and
per route basis, and accurately predict the time-to-charge BEB batteries to any
level. These predictions are then used by a Predictive Block Assignment module
to maximize the BEB fleet utilization. This module computes the optimal BEB
daily assignment and charge management strategy. A Depot Parking and Charging
Queue Management module is used to autonomously park and charge the vehicles
based on their charging demands. The paper discusses the technical approach and
benefits of each level in architecture and concludes with a realistic
simulations study. The study shows that if our approach is employed, BEB fleet
utilization can increase by 50% compared to state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:10:13 GMT""}]","2023-05-25"
"2305.14733","Andrew Cameron","A. D. Cameron, M. Bailes, D. J. Champion, P. C. C. Freire, M. Kramer,
  M. A. McLaughlin, C. Ng, A. Possenti, A. Ridolfi, T. M. Tauris, H. M. Wahl,
  N. Wex","New constraints on the kinematic, relativistic and evolutionary
  properties of the PSR J1757$-$1854 double neutron star system","23 pages, 16 figures, 7 tables",,,,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  PSR J1757$-$1854 is one of the most relativistic double neutron star binary
systems known in our Galaxy, with an orbital period of
$P_\text{b}=4.4\,\text{hr}$ and an orbital eccentricity of $e=0.61$. As such,
it has promised to be an outstanding laboratory for conducting tests of
relativistic gravity. We present the results of a 6-yr campaign with the 100-m
Green Bank and 64-m Parkes radio telescopes, designed to capitalise on this
potential. We identify secular changes in the profile morphology and
polarisation of PSR J1757$-$1854, confirming the presence of geodetic
precession and allowing the constraint of viewing geometry solutions consistent
with General Relativity. We also update PSR J1757$-$1854's timing, including
new constraints of the pulsar's proper motion, post-Keplerian parameters and
component masses. We conclude that the radiative test of gravity provided by
PSR J1757$-$1854 is fundamentally limited to a precision of 0.3 per cent due to
the pulsar's unknown distance. A search for pulsations from the companion
neutron star is also described, with negative results. We provide an updated
evaluation of the system's evolutionary history, finding strong support for a
large kick velocity of $w\ge280\,\text{km s}^{-1}$ following the second
progenitor supernova. Finally, we reassess PSR J1757$-$1854's potential to
provide new relativistic tests of gravity. We conclude that a 3-$\sigma$
constraint of the change in the projected semi-major axis ($\dot{x}$)
associated with Lense-Thirring precession is expected no earlier than 2031.
Meanwhile, we anticipate a 3-$\sigma$ measurement of the relativistic orbital
deformation parameter $\delta_\theta$ as soon as 2026.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:12:49 GMT""}]","2023-05-25"
"2305.14734","Bashar Alhafni","Bashar Alhafni, Go Inoue, Christian Khairallah, Nizar Habash","Advancements in Arabic Grammatical Error Detection and Correction: An
  Empirical Investigation",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Grammatical error correction (GEC) is a well-explored problem in English with
many existing models and datasets. However, research on GEC in morphologically
rich languages has been limited due to challenges such as data scarcity and
language complexity. In this paper, we present the first results on Arabic GEC
by using two newly developed Transformer-based pretrained sequence-to-sequence
models. We address the task of multi-class Arabic grammatical error detection
(GED) and present the first results on multi-class Arabic GED. We show that
using GED information as auxiliary input in GEC models improves GEC performance
across three datasets spanning different genres. Moreover, we also investigate
the use of contextual morphological preprocessing in aiding GEC systems. Our
models achieve state-of-the-art results on two Arabic GEC shared tasks datasets
and establish a strong benchmark on a newly created dataset.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:12:58 GMT""}]","2023-05-25"
"2305.14735","Vyoma Raman","Vyoma Raman, Eve Fleisig, Dan Klein","Centering the Margins: Outlier-Based Identification of Harmed
  Populations in Toxicity Detection",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  A standard method for measuring the impacts of AI on marginalized communities
is to determine performance discrepancies between specified demographic groups.
These approaches aim to address harms toward vulnerable groups, but they
obscure harm patterns faced by intersectional subgroups or shared across
demographic groups. We instead operationalize ""the margins"" as data points that
are statistical outliers due to having demographic attributes distant from the
""norm"" and measure harms toward these outliers. We propose a Group-Based
Performance Disparity Index (GPDI) that measures the extent to which a
subdivision of a dataset into subgroups identifies those facing increased
harms. We apply our approach to detecting disparities in toxicity detection and
find that text targeting outliers is 28% to 86% more toxic for all types of
toxicity examined. We also discover that model performance is consistently
worse for demographic outliers, with disparities in error between outliers and
non-outliers ranging from 28% to 71% across toxicity types. Our outlier-based
analysis has comparable or higher GPDI than traditional subgroup-based
analyses, suggesting that outlier analysis enhances identification of subgroups
facing greater harms. Finally, we find that minoritized racial and religious
groups are most associated with outliers, which suggests that outlier analysis
is particularly beneficial for identifying harms against those groups.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:15:36 GMT""}]","2023-05-25"
"2305.14736","Krishna Chaitanya Kalagarla","Krishna C. Kalagarla, Dhruva Kartik, Dongming Shen, Rahul Jain,
  Ashutosh Nayyar and Pierluigi Nuzzo","Optimal Control of Logically Constrained Partially Observable and
  Multi-Agent Markov Decision Processes","arXiv admin note: substantial text overlap with arXiv:2203.09038",,,,"cs.AI cs.FL cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Autonomous systems often have logical constraints arising, for example, from
safety, operational, or regulatory requirements. Such constraints can be
expressed using temporal logic specifications. The system state is often
partially observable. Moreover, it could encompass a team of multiple agents
with a common objective but disparate information structures and constraints.
In this paper, we first introduce an optimal control theory for partially
observable Markov decision processes (POMDPs) with finite linear temporal logic
constraints. We provide a structured methodology for synthesizing policies that
maximize a cumulative reward while ensuring that the probability of satisfying
a temporal logic constraint is sufficiently high. Our approach comes with
guarantees on approximate reward optimality and constraint satisfaction. We
then build on this approach to design an optimal control framework for
logically constrained multi-agent settings with information asymmetry. We
illustrate the effectiveness of our approach by implementing it on several case
studies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:15:36 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 21:40:54 GMT""}]","2023-05-30"
"2305.14737","Valentin Vergara Hidd","Valent\'in Vergara Hidd, Mailun Zhang, Simone Centellegher, Sam G. B.
  Roberts, Bruno Lepri, Eduardo L\'opez","The Rhythms of Transient Relationships: Allocating time between weekdays
  and weekends","15 pages, 4 figures. Submitted for review at EPJ Data Science",,,,"physics.soc-ph cs.SI","http://creativecommons.org/licenses/by/4.0/","  People maintain a variety of different types of social relationships with
others. Among them, transient relationships constitute a substantial portion of
communication, yet receive little attention in the literature. They are
characterized by a limited lifetime, which recent research has found can be
effectively predicted by call volume, suggesting that available personal time
for communication is a key driver for maintaining these relationships. Whilst
there are examples of research on the circadian rhythms of communication over a
24-hour period, little is known about patterns of communication during
different days of the week. In this study, we use mobile phone datasets in the
UK and Italy to analyze the allocation of time to transient relationships at
distinct parts of the week focusing on the differences between relationships
with more contact during weekdays (Monday to Friday) or weekends. We find more
relationships are created during weekdays, with an overall greater proportion
of them receiving more contact during these days of the week in the long term.
However, the smaller group of relationships that receive more phone calls
during the weekend tend to remain longer in their corresponding ego network
(have a longer relationship lifetime). We uncover a sorting process by which
some ties are moved from weekdays to weekends and vice versa, mostly in the
first half of the relationship. This process also leads to higher mutual
information between lifetime and the part of the week in which the relationship
is pursued. This suggests that there is an evaluation process early in the
relationship that leads to a decision on how to allocate time to different
types of transient ties. Overall, these results demonstrate that the part of
the week that concentrates the bulk of mobile communication provides
information about key aspects of the ego-alter relationship.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:17:07 GMT""}]","2023-05-25"
"2305.14738","Jaekwan Jeon","Jaekwan Jeon, Dongsoo Shin","Deformations of weighted homogeneous surface singularities with big
  central node","We welcome any comments",,,,"math.AG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We prove Koll\'{a}r conjecture for weighted homogeneous surface singularities
with big central node. More precisely, we show that every irreducible component
of the deformation space of the singularity is parametrized by a certain
partial resolution which is known as a $P$-resolution.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:18:21 GMT""}]","2023-05-25"
"2305.14739","Weijia Shi","Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia Tsvetkov, Luke
  Zettlemoyer, Scott Wen-tau Yih","Trusting Your Evidence: Hallucinate Less with Context-aware Decoding",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Language models (LMs) often struggle to pay enough attention to the input
context, and generate texts that are unfaithful or contain hallucinations. To
mitigate this issue, we present context-aware decoding (CAD), which follows a
contrastive output distribution that amplifies the difference between the
output probabilities when a model is used with and without context. Our
experiments show that CAD, without additional training, significantly improves
the faithfulness of different LM families, including OPT, GPT, LLaMA and
FLAN-T5 for summarization tasks (e.g., 14.3% gain for LLaMA in factuality
metrics). Furthermore, CAD is particularly effective in overriding a model's
prior knowledge when it contradicts the provided context, leading to
substantial improvements in tasks where resolving the knowledge conflict is
essential.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:19:15 GMT""}]","2023-05-25"
"2305.14740","Yuxi Xie","Yuxi Xie and Guanzhen Li and Min-Yen Kan","ECHo: Event Causality Inference via Human-centric Reasoning","Please find data and code at https://github.com/YuxiXie/ECHo",,,,"cs.AI cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce ECHo, a diagnostic dataset of event causality inference grounded
in visual-and-linguistic social scenarios. ECHo employs real-world
human-centric deductive information collected from crime drama, bridging the
gap in multimodal reasoning towards higher social intelligence through the
elicitation of intermediate Theory-of-Mind (ToM). We propose a unified
framework aligned with the Chain-of-Thought (CoT) paradigm to assess the
reasoning capability of current AI systems. This ToM-enhanced CoT pipeline can
accommodate and integrate various large foundation models in zero-shot
visual-and-linguistic understanding. With this framework, we scrutinize the
advanced large language and multimodal models via three complementary
human-centric ECHo tasks. Further analysis demonstrates ECHo as a challenging
dataset to expose imperfections and inconsistencies in reasoning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:21:13 GMT""}]","2023-05-25"
"2305.14741","Naoya Ando","Naoya Ando","Sections of time-like twistor spaces with light-like or zero covariant
  derivatives",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conformal Gauss maps of time-like minimal surfaces in $E^3_1$ give
sections of the time-like twistor spaces associated with the pull-back bundles
such that the covariant derivatives are fully light-like, that is, these are
either light-like or zero, and do not vanish at any point. For an oriented
neutral $4n$-manifold $(M, h)$, if $J$ is an $h$-reversing almost paracomplex
structure of $M$ such that $\nabla J$ is locally given by the tensor product of
a nowhere zero 1-form and an almost nilpotent structure related to $J$, then we
will see that $\nabla J$ is valued in a light-like $2n$-dimensional
distribution $\mathcal{D}$ such that $(M , h, \mathcal{D} )$ is a Walker
manifold and that the square norm $\parallel\!\nabla J\!\parallel^2$ of $\nabla
J$ vanishes. We will obtain examples of $h$-reversing almost paracomplex
structures of $E^{4n}_{2n}$ as above. In addition, we will obtain all the pairs
of $h$-reversing almost paracomplex structures of $E^4_2$ such that each pair
gives sections of the two time-like twistor spaces with fully light-like
covariant derivatives.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:25:30 GMT""}]","2023-05-25"
"2305.14742","Dongxu Yue","Dongxu Yue, Qin Guo, Munan Ning, Jiaxi Cui, Yuesheng Zhu, Li Yuan","ChatFace: Chat-Guided Real Face Editing via Diffusion Latent Space
  Manipulation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Editing real facial images is a crucial task in computer vision with
significant demand in various real-world applications. While GAN-based methods
have showed potential in manipulating images especially when combined with
CLIP, these methods are limited in their ability to reconstruct real images due
to challenging GAN inversion capability. Despite the successful image
reconstruction achieved by diffusion-based methods, there are still challenges
in effectively manipulating fine-gained facial attributes with textual
instructions.To address these issues and facilitate convenient manipulation of
real facial images, we propose a novel approach that conduct text-driven image
editing in the semantic latent space of diffusion model. By aligning the
temporal feature of the diffusion model with the semantic condition at
generative process, we introduce a stable manipulation strategy, which perform
precise zero-shot manipulation effectively. Furthermore, we develop an
interactive system named ChatFace, which combines the zero-shot reasoning
ability of large language models to perform efficient manipulations in
diffusion semantic latent space. This system enables users to perform complex
multi-attribute manipulations through dialogue, opening up new possibilities
for interactive image editing. Extensive experiments confirmed that our
approach outperforms previous methods and enables precise editing of real
facial images, making it a promising candidate for real-world applications.
Project page: https://dongxuyue.github.io/chatface/
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:28:37 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 10:34:05 GMT""}]","2023-06-06"
"2305.14743","Hanming Ma","Hanming Ma, Dilip Bhoi, Jun Gouchi, Hiroyasu Sato, Toru Shigeoka,
  J.-G. Cheng, and Yoshiya Uwatoko","Investigation of the atomic coordinates of CeNiC$_2$ under pressure:
  switching of the Ce-Ce first nearest neighbor direction","13 pages, 4 figures",,,,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.other cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  When pressurized, the heavy fermion compound CeNiC$_2$ reveals a rich
electronic phase diagram and shows unconventional superconductivity with a
transition temperature $T_c$ $\sim$ 3.7 K, the highest among Ce-based heavy
fermion superconductors [S. Katano et al., Phys. Rev. B. 99, 100501(R) (2019)].
Understanding of this appearance of superconductivity in the vicinity of
magnetic quantum critical point is still lacking. Given that physical
properties of CeNiC$_2$ are sensitive to subtle changes in the interatomic
distances, information on atomic coordinates may offer essential insights into
the local lattice arrangements, thus the mechanisms behind the exotic phases
and phase transitions. However, extraction of precise information on the atomic
coordinates under pressure remains a challenge. To find a correlation between
the local lattice environments and exotic physical properties in CeNiC$_2$, we
investigate its crystal structure from ambient pressure to 18.6 GPa via single
crystal X-ray diffraction. The pressure dependence of lattice parameters
reveals anisotropic linear compressibility, $|\kappa|$, following the
relationship $|\kappa_{a}|$ (3.70$\times$10$^{-3}$ GPa$^{-1}$) $>$
$|\kappa_{c}|$ (1.97$\times$10$^{-3}$ GPa$^{-1}$) $>$ $|\kappa_{b}|$
(1.39$\times$10$^{-3}$ GPa$^{-1}$), and a large bulk modulus, B$_0$ $\sim$ 134
GPa. Although the atomic coordinates between Ce and Ni remain unchanged under
applied pressure, direction of the first nearest and the second nearest
neighbors between both the Ce-Ce and Ni-Ni atoms switch $\sim$ 7 GPa. Notably,
this is the same pressure that antiferromagnetic ordering temperature reaches
maximum in the pressure temperature phase diagram of CeNiC$_2$. Our results
suggest that the direction of nearest neighbors interchange might play a key
role in the suppression of magnetic order and the enhancement of Kondo effect.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:29:27 GMT""}]","2023-05-25"
"2305.14744","Liangzu Peng","Liangzu Peng and Ren\'e Vidal","Block Coordinate Descent on Smooth Manifolds",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Block coordinate descent is an optimization paradigm that iteratively updates
one block of variables at a time, making it quite amenable to big data
applications due to its scalability and performance. Its convergence behavior
has been extensively studied in the (block-wise) convex case, but it is much
less explored in the non-convex case. In this paper we analyze the convergence
of block coordinate methods on non-convex sets and derive convergence rates on
smooth manifolds under natural or weaker assumptions than prior work. Our
analysis applies to many non-convex problems (e.g., generalized PCA, optimal
transport, matrix factorization, Burer-Monteiro factorization, outlier-robust
estimation, alternating projection, maximal coding rate reduction, neural
collapse, adversarial attacks, homomorphic sensing), either yielding novel
corollaries or recovering previously known results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:32:49 GMT""}]","2023-05-25"
"2305.14745","Ziaullah Momand","Hamida Ashna, Ziaullah Momand","Applications of Machine Learning in Detecting Afghan Fake Banknotes",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Fake currency, unauthorized imitation money lacking government approval,
constitutes a form of fraud. Particularly in Afghanistan, the prevalence of
fake currency poses significant challenges and detrimentally impacts the
economy. While banks and commercial establishments employ authentication
machines, the public lacks access to such systems, necessitating a program that
can detect counterfeit banknotes accessible to all. This paper introduces a
method using image processing to identify counterfeit Afghan banknotes by
analyzing specific security features. Extracting first and second order
statistical features from input images, the WEKA machine learning tool was
employed to construct models and perform classification with Random Forest,
PART, and Na\""ive Bayes algorithms. The Random Forest algorithm achieved
exceptional accuracy of 99% in detecting fake Afghan banknotes, indicating the
efficacy of the proposed method as a solution for identifying counterfeit
currency.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:39:46 GMT""}]","2023-05-25"
"2305.14746","Minh-Ngoc Tran","Nhat-Minh Nguyen and Minh-Ngoc Tran and Christopher Drovandi and David
  Nott","Wasserstein Gaussianization and Efficient Variational Bayes for Robust
  Bayesian Synthetic Likelihood",,,,,"stat.CO stat.ML","http://creativecommons.org/licenses/by/4.0/","  The Bayesian Synthetic Likelihood (BSL) method is a widely-used tool for
likelihood-free Bayesian inference. This method assumes that some summary
statistics are normally distributed, which can be incorrect in many
applications. We propose a transformation, called the Wasserstein
Gaussianization transformation, that uses a Wasserstein gradient flow to
approximately transform the distribution of the summary statistics into a
Gaussian distribution. BSL also implicitly requires compatibility between
simulated summary statistics under the working model and the observed summary
statistics. A robust BSL variant which achieves this has been developed in the
recent literature. We combine the Wasserstein Gaussianization transformation
with robust BSL, and an efficient Variational Bayes procedure for posterior
approximation, to develop a highly efficient and reliable approximate Bayesian
inference method for likelihood-free problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:42:56 GMT""}]","2023-05-25"
"2305.14747","Peter Hamm","Jan Helbing and Peter Hamm","Versatile Femtosecond Laser Synchronization for Multiple-Timescale
  Transient IR Spectroscopy",,,,,"physics.optics physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Several ways to electronically synchronize different types of amplified
femtosecond laser systems are presented, based on a single freely programmable
electronics hardware: Arbitrary-detuning asynchronous optical sampling, as well
as actively locking two femtosecond laser oscillators, albeit not necessarily
to the same round-trip frequency. They allow us to rapidly probe a very wide
range of timescales, from picoseconds to potentially seconds, in a single
transient absorption experiment without the need to move any delay stage.
Experiments become possible that address a largely unexplored aspect of many
photochemical reactions, in particular in the context of photo-catalysis as
well as photoactive proteins, where an initial femtosecond trigger very often
initiates a long-lasting cascade of follow-up processes. The approach is very
versatile, and allows us to synchronize very different lasers, such as a Ti:Sa
amplifier and a 100~kHz Yb-laser system. The jitter of the synchronisation, and
therewith the time-resolution in the transient experiment, lies in the range
from 1~ps to 3~ps, depending on the method. For illustration, transient IR
measurements of the excited state solvation and decay of a metal carbonyl
complex as well as the full reaction cycle of bacteriorhodopsin are shown. The
pros and cons of the various methods are discussed, with regard to the
scientific question one might want to address, and also with regard to the
laser systems that might be already existent in a laser lab.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:46:00 GMT""}]","2023-05-25"
"2305.14748","Dan Lin","Dan Lin, Jiajing Wu, Qishuang Fu, Yunmei Yu, Kaixin Lin, Zibin Zheng,
  Shuo Yang","Towards Understanding Crypto Money Laundering in Web3 Through the Lenses
  of Ethereum Heists",,,,,"cs.CR cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the overall momentum of the blockchain industry, crypto-based crimes are
becoming more and more prevalent. After committing a crime, the main goal of
cybercriminals is to obfuscate the source of the illicit funds in order to
convert them into cash and get away with it. Many studies have analyzed money
laundering in the field of the traditional financial sector and
blockchain-based Bitcoin. But so far, little is known about the characteristics
of crypto money laundering in the blockchain-based Web3 ecosystem. To fill this
gap, and considering that Ethereum is the largest platform on Web3, in this
paper, we systematically study the behavioral characteristics and economic
impact of money laundering accounts through the lenses of Ethereum heists.
Based on a very small number of tagged accounts of exchange hackers, DeFi
exploiters, and scammers, we mine untagged money laundering groups through
heuristic transaction tracking methods, to carve out a full picture of security
incidents. By analyzing account characteristics and transaction networks, we
obtain many interesting findings about crypto money laundering in Web3,
observing the escalating money laundering methods such as creating counterfeit
tokens and masquerading as speculators. Finally, based on these findings we
provide inspiration for anti-money laundering to promote the healthy
development of the Web3 ecosystem.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:46:42 GMT""}]","2023-05-25"
"2305.14749","Chaitanya K. Joshi","Chaitanya K. Joshi, Arian R. Jamasb, Ramon Vi\~nas, Charles Harris,
  Simon Mathis, Pietro Li\`o","Multi-State RNA Design with Geometric Multi-Graph Neural Networks",,,,,"cs.LG q-bio.BM q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational RNA design has broad applications across synthetic biology and
therapeutic development. Fundamental to the diverse biological functions of RNA
is its conformational flexibility, enabling single sequences to adopt a variety
of distinct 3D states. Currently, computational biomolecule design tasks are
often posed as inverse problems, where sequences are designed based on adopting
a single desired structural conformation. In this work, we propose gRNAde, a
geometric RNA design pipeline that operates on sets of 3D RNA backbone
structures to explicitly account for and reflect RNA conformational diversity
in its designs. We demonstrate the utility of gRNAde for improving native
sequence recovery over single-state approaches on a new large-scale 3D RNA
design dataset, especially for multi-state and structurally diverse RNAs. Our
code is available at https://github.com/chaitjo/geometric-rna-design
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:46:56 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 14:53:11 GMT""},{""version"":""v3"",""created"":""Sun, 28 May 2023 22:44:27 GMT""}]","2023-05-30"
"2305.14750","Nishant Balepur","Nishant Balepur, Jie Huang, Samraj Moorjani, Hari Sundaram, Kevin
  Chen-Chuan Chang","Mastering the ABCDs of Complex Questions: Answer-Based Claim
  Decomposition for Fine-grained Self-Evaluation","In progress preprint",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  When answering complex questions, large language models (LLMs) may produce
answers that do not satisfy all criteria of the question. While existing
self-evaluation techniques aim to detect if such answers are correct, these
techniques are unable to determine which criteria of the question are satisfied
by the generated answers. To address this issue, we propose answer-based claim
decomposition (ABCD), a prompting strategy that decomposes questions into a
series of true/false claims that can be used to verify which criteria of the
input question an answer satisfies. Using the decomposed ABCD claims, we
perform fine-grained self-evaluation. Through preliminary experiments on three
datasets, including a newly-collected challenge dataset ObscureQA, we find that
GPT-3.5 has some ability to determine to what extent its answer satisfies the
criteria of the input question, and can give insights into the errors and
knowledge gaps of the model.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:53:11 GMT""}]","2023-05-25"
"2305.14751","Tianyu Liu","Zefan Cai, Xin Zheng, Tianyu Liu, Xu Wang, Haoran Meng, Jiaqi Han,
  Gang Yuan, Binghuai Lin, Baobao Chang and Yunbo Cao","DialogVCS: Robust Natural Language Understanding in Dialogue System
  Upgrade","work in progress. The first three authors contribute equally",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  In the constant updates of the product dialogue systems, we need to retrain
the natural language understanding (NLU) model as new data from the real users
would be merged into the existent data accumulated in the last updates. Within
the newly added data, new intents would emerge and might have semantic
entanglement with the existing intents, e.g. new intents that are semantically
too specific or generic are actually subset or superset of some existing
intents in the semantic space, thus impairing the robustness of the NLU model.
As the first attempt to solve this problem, we setup a new benchmark consisting
of 4 Dialogue Version Control dataSets (DialogVCS). We formulate the intent
detection with imperfect data in the system update as a multi-label
classification task with positive but unlabeled intents, which asks the models
to recognize all the proper intents, including the ones with semantic
entanglement, in the inference. We also propose comprehensive baseline models
and conduct in-depth analyses for the benchmark, showing that the semantically
entangled intents can be effectively recognized with an automatic workflow.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:53:38 GMT""}]","2023-05-25"
"2305.14752","Norbert Tihanyi Dr.","Yiannis Charalambous, Norbert Tihanyi, Ridhi Jain, Youcheng Sun,
  Mohamed Amine Ferrag, Lucas C. Cordeiro","A New Era in Software Security: Towards Self-Healing Software via Large
  Language Models and Formal Verification",,,,,"cs.SE cs.AI cs.FL cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we present a novel solution that combines the capabilities of
Large Language Models (LLMs) with Formal Verification strategies to verify and
automatically repair software vulnerabilities. Initially, we employ Bounded
Model Checking (BMC) to locate the software vulnerability and derive a
counterexample. The counterexample provides evidence that the system behaves
incorrectly or contains a vulnerability. The counterexample that has been
detected, along with the source code, are provided to the LLM engine. Our
approach involves establishing a specialized prompt language for conducting
code debugging and generation to understand the vulnerability's root cause and
repair the code. Finally, we use BMC to verify the corrected version of the
code generated by the LLM. As a proof of concept, we create ESBMC-AI based on
the Efficient SMT-based Context-Bounded Model Checker (ESBMC) and a pre-trained
Transformer model, specifically gpt-3.5-turbo, to detect and fix errors in C
programs. Our experimentation involved generating a dataset comprising 1000 C
code samples, each consisting of 20 to 50 lines of code. Notably, our proposed
method achieved an impressive success rate of up to 80% in repairing vulnerable
code encompassing buffer overflow and pointer dereference failures. We assert
that this automated approach can effectively incorporate into the software
development lifecycle's continuous integration and deployment (CI/CD) process.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:54:10 GMT""}]","2023-05-25"
"2305.14753","Barbara Dietz","Weihua Zhang, Xiaodong Zhang, and Barbara Dietz","Time-reversal Invariance Violation and Quantum Chaos Induced by
  Magnetization in Ferrite-Loaded Resonators",,,,,"nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the fluctuation properties in the eigenfrequency spectra of
flat cylindrical microwave cavities that are homogeneously filled with
magnetized ferrite. These studies are motivated by experiments in which only
small pieces of ferrite were embedded in the cavity and magnetized with an
external static magnetic field to induce partial time-reversal (T ) invariance
violation. We use two different shapes of the cavity, one exhibiting an
integrable wave dynamics, the other one a chaotic one. We demonstrate that in
the frequency region where only transverse-magnetic modes exist, the
magnetization of the ferrites has no effect on the wave dynamics and does not
induce T -invariance violation whereas it is fully violated above the cutoff
frequency of the first transverse-electric mode. Above all, independently of
the shape of the resonator, it induces a chaotic wave dynamics in that
frequency range in the sense that for both resonator geometries the spectral
properties coincide with those of quantum systems with a chaotic classical
dynamics and same invariance properties under application of the generalized T
operator associated with the resonator geometry.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:55:44 GMT""}]","2023-05-25"
"2305.14754","Cheng-Te Li","Yi-Zhan Xu, Chih-Yao Chen, Cheng-Te Li","SUVR: A Search-based Approach to Unsupervised Visual Representation
  Learning","ICASSP 2023",,"10.1109/ICASSP49357.2023.10096936",,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised learning has grown in popularity because of the difficulty of
collecting annotated data and the development of modern frameworks that allow
us to learn from unlabeled data. Existing studies, however, either disregard
variations at different levels of similarity or only consider negative samples
from one batch. We argue that image pairs should have varying degrees of
similarity, and the negative samples should be allowed to be drawn from the
entire dataset. In this work, we propose Search-based Unsupervised Visual
Representation Learning (SUVR) to learn better image representations in an
unsupervised manner. We first construct a graph from the image dataset by the
similarity between images, and adopt the concept of graph traversal to explore
positive samples. In the meantime, we make sure that negative samples can be
drawn from the full dataset. Quantitative experiments on five benchmark image
classification datasets demonstrate that SUVR can significantly outperform
strong competing methods on unsupervised embedding learning. Qualitative
experiments also show that SUVR can produce better representations in which
similar images are clustered closer together than unrelated images in the
latent space.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:57:58 GMT""}]","2023-05-25"
"2305.14755","Akhila Yerukola","Akhila Yerukola, Xuhui Zhou, Maarten Sap","Don't Take This Out of Context! On the Need for Contextual Models and
  Evaluations for Stylistic Rewriting","may 24 submission",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most existing stylistic text rewriting methods operate on a sentence level,
but ignoring the broader context of the text can lead to generic, ambiguous,
and incoherent rewrites. In this paper, we propose the integration of preceding
textual context into both the rewriting and evaluation stages of stylistic text
rewriting, focusing on formality, toxicity, and sentiment transfer tasks. We
conduct a comparative evaluation of rewriting through few-shot prompting of
GPT-3.5 and GPT NeoX, comparing non-contextual rewrites to contextual rewrites.
Our experiments show that humans often prefer contextual rewrites over
non-contextual ones, but automatic metrics (e.g., BLEU, sBERT) do not. To
bridge this gap, we propose context-infused versions of common automatic
metrics, and show that these better reflect human preferences. Overall, our
paper highlights the importance of integrating preceding textual context into
both the rewriting and evaluation stages of stylistic text rewriting.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:58:17 GMT""}]","2023-05-25"
"2305.14756","Aditya Lahiri","Aditya Lahiri, Naigam Shah, Shivaank Agarwal, Vignesh Nandakumar","Deterministic Algorithmic Approaches to Solve Generalised Wordle",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Wordle is a single-player word-based game where the objective is to guess the
5-letter word in a maximum of 6 tries. The game was released to the public in
October 2021 and has since gained popularity with people competing against each
other to maintain daily streaks and guess the word in a minimum number of
tries. There have been works using probabilistic and reinforcement learning
based approaches to solve the game. Our work aims to formulate and analyze
deterministic algorithms that can solve the game and minimize the number of
turns required to guess the word and do so for any generalized setting of the
game. As a simplifying assumption, for our analysis of all the algorithms we
present, we assume that all letters will be unique in any word which is part of
our vocabulary. We propose two algorithms to play Wordle - one a greedy based
approach, and other based on Cliques. The Greedy approach is applicable for
both hard and easy modes of Wordle, while the Clique formation based approach
only works on the Easy mode. We present our analysis on both approaches one by
one, next.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:58:31 GMT""}]","2023-05-25"
"2305.14757","Salvatore Giorgi","Salvatore Giorgi, Shreya Havaldar, Farhan Ahmed, Zuhaib Akhtar,
  Shalaka Vaidya, Gary Pan, Lyle H. Ungar, H. Andrew Schwartz, Joao Sedoc","Human-Centered Metrics for Dialog System Evaluation",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present metrics for evaluating dialog systems through a
psychologically-grounded ""human"" lens: conversational agents express a
diversity of both states (short-term factors like emotions) and traits
(longer-term factors like personality) just as people do. These interpretable
metrics consist of five measures from established psychology constructs that
can be applied both across dialogs and on turns within dialogs: emotional
entropy, linguistic style and emotion matching, as well as agreeableness and
empathy. We compare these human metrics against 6 state-of-the-art automatic
metrics (e.g. BARTScore and BLEURT) on 7 standard dialog system data sets. We
also introduce a novel data set, the Three Bot Dialog Evaluation Corpus, which
consists of annotated conversations from ChatGPT, GPT-3, and BlenderBot. We
demonstrate the proposed human metrics offer novel information, are
uncorrelated with automatic metrics, and lead to increased accuracy beyond
existing automatic metrics for predicting crowd-sourced dialog judgements. The
interpretability and unique signal of our proposed human-centered framework
make it a valuable tool for evaluating and improving dialog systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:02:32 GMT""}]","2023-05-25"
"2305.14758","Tianlun Zheng","Tianlun Zheng, Zhineng Chen, BingChen Huang, Wei Zhang and Yu-Gang
  Jiang","MRN: Multiplexed Routing Network for Incremental Multilingual Text
  Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional Multilingual Text Recognition (MLTR) usually targets a fixed set
of languages and thus struggles to handle newly added languages or adapt to
ever-changing class distributions. In this paper, we introduce the Incremental
Multilingual Text Recognition (IMLTR) task in the incremental learning setting,
where new language data comes in batches. Compared to generic incremental
learning, IMLTR is even more challenging as it suffers from rehearsal-imbalance
(uneven distribution of sample characters in the rehearsal set). To address
this issue, we propose a Multiplexed Routing Network (MRN), where a series of
recognizers is trained for each language. Subsequently, a language predictor is
adopted to weigh the recognizers for voting. Since the recognizers are derived
from the original model, MRN effectively reduces the reliance on older data and
is better suited for rehearsal-imbalance. We extensively evaluate MRN on MLT17
and MLT19 datasets, outperforming existing state-of-the-art methods by a large
margin, i.e., accuracy improvement ranging from 10.3% to 27.4% under different
settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:03:34 GMT""}]","2023-05-25"
"2305.14759","Xinlei Zhang","Xin-Lei Zhang, Heng Xiao, Xiaodong Luo, Guowei He","Combining direct and indirect sparse data for learning generalizable
  turbulence models","42 pages, 16 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning turbulence models from observation data is of significant interest
in discovering a unified model for a broad range of practical flow
applications. Either the direct observation of Reynolds stress or the indirect
observation of velocity has been used to improve the predictive capacity of
turbulence models. In this work, we propose combining the direct and indirect
sparse data to train neural network-based turbulence models. The
backpropagation technique and the observation augmentation approach are used to
train turbulence models with different observation data in a unified
ensemble-based framework. These two types of observation data can explore
synergy to constrain the model training in different observation spaces, which
enables learning generalizable models from very sparse data. The present method
is tested in secondary flows in a square duct and separated flows over periodic
hills. Both cases demonstrate that combining direct and indirect observations
is able to improve the generalizability of the learned model in similar flow
configurations, compared to using only indirect data. The ensemble-based method
can serve as a practical tool for model learning from different types of
observations due to its non-intrusive and derivative-free nature.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:07:45 GMT""}]","2023-05-25"
"2305.14760","Heming Xia","Shoujie Tong, Heming Xia, Damai Dai, Tianyu Liu, Binghuai Lin, Yunbo
  Cao, Zhifang Sui","Bi-Drop: Generalizable Fine-tuning for Pre-trained Language Models via
  Adaptive Subnetwork Optimization","Work in progress. Co-first authors with equal contributions",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pretrained language models have achieved remarkable success in a variety of
natural language understanding tasks. Nevertheless, finetuning large pretrained
models on downstream tasks is susceptible to overfitting if the training set is
limited, which will lead to diminished performance. In this work, we propose a
dynamic fine-tuning strategy for pretrained language models called Bi-Drop. It
utilizes the gradient information of various sub-models generated by dropout to
update the model parameters selectively. Experiments on the GLUE benchmark show
that Bi-Drop outperforms previous fine-tuning methods by a considerable margin,
and exhibits consistent superiority over vanilla fine-tuning across various
pretrained models. Furthermore, empirical results indicate that Bi-Drop yields
substantial improvements in the multiple task or domain transfer, data
imbalance, and low-resource scenarios, demonstrating superb generalization
ability and robustness.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:09:26 GMT""}]","2023-05-25"
"2305.14761","Parsa Kavehzadeh","Ahmed Masry, Parsa Kavehzadeh, Xuan Long Do, Enamul Hoque, Shafiq Joty","UniChart: A Universal Vision-language Pretrained Model for Chart
  Comprehension and Reasoning",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Charts are very popular for analyzing data, visualizing key insights and
answering complex reasoning questions about data. To facilitate chart-based
data analysis using natural language, several downstream tasks have been
introduced recently such as chart question answering and chart summarization.
However, most of the methods that solve these tasks use pretraining on language
or vision-language tasks that do not attempt to explicitly model the structure
of the charts (e.g., how data is visually encoded and how chart elements are
related to each other). To address this, we first build a large corpus of
charts covering a wide variety of topics and visual styles. We then present
UniChart, a pretrained model for chart comprehension and reasoning. UniChart
encodes the relevant text, data, and visual elements of charts and then uses a
chart-grounded text decoder to generate the expected output in natural
language. We propose several chart-specific pretraining tasks that include: (i)
low-level tasks to extract the visual elements (e.g., bars, lines) and data
from charts, and (ii) high-level tasks to acquire chart understanding and
reasoning skills. We find that pretraining the model on a large corpus with
chart-specific low- and high-level tasks followed by finetuning on three
down-streaming tasks results in state-of-the-art performance on three
downstream tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:11:17 GMT""}]","2023-05-25"
"2305.14762","Taishi Kurahashi","Taishi Kurahashi and Yuta Sato","The finite frame property of some extensions of the pure logic of
  necessitation","16 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the finite frame property of some extensions of Fitting, Marek, and
Truszczy\'nski's pure logic of necessitation $\mathbf{N}$. For any natural
numbers $m, n$, we introduce the logic $\mathbf{N}^+\mathbf{A}_{m, n}$ by
adding the single axiom scheme $\Box^n \varphi \to \Box^m \varphi$ and the rule
$\dfrac{\neg \Box \varphi}{\neg \Box \Box \varphi}$ (Ros$^\Box$) into
$\mathbf{N}$. We prove the finite frame property of $\mathbf{N}^+\mathbf{A}_{m,
n}$ with respect to Fitting, Marek, and Truszczy\'nski's relational semantics.
We also prove that the Ros$^\Box$ rule is necessary for the completeness of
$\mathbf{N}^+\mathbf{A}_{0, n}$ for $n \ge 2$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:12:02 GMT""}]","2023-05-25"
"2305.14763","Vered Shwartz","Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin
  Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz","Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in
  Large Language Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The escalating debate on AI's capabilities warrants developing reliable
metrics to assess machine ""intelligence"". Recently, many anecdotal examples
were used to suggest that newer large language models (LLMs) like ChatGPT and
GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached
conflicting conclusions regarding those abilities. We investigate the extent of
LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs
exhibit certain N-ToM abilities, this behavior is far from being robust. We
further examine the factors impacting performance on N-ToM tasks and discover
that LLMs struggle with adversarial examples, indicating reliance on shallow
heuristics rather than robust ToM abilities. We caution against drawing
conclusions from anecdotal examples, limited benchmark testing, and using
human-designed psychological tests to evaluate models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:14:31 GMT""}]","2023-05-25"
"2305.14764","Naoya Mamada","Naoya Mamada, Masaichiro Mizumaki, Ichiro Akai, and Toru Aonishi","Detection of Non-uniformity in Parameters for Magnetic Domain Pattern
  Generation by Machine Learning","27 pages, 11 figures",,,,"cond-mat.mtrl-sci cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We attempt to estimate the spatial distribution of heterogeneous physical
parameters involved in the formation of magnetic domain patterns of
polycrystalline thin films by using convolutional neural networks. We propose a
method to obtain a spatial map of physical parameters by estimating the
parameters from patterns within a small subregion window of the full magnetic
domain and subsequently shifting this window. To enhance the accuracy of
parameter estimation in such subregions, we employ employ large-scale models
utilized for natural image classification and exploit the benefits of
pretraining. Using a model with high estimation accuracy on these subregions,
we conduct inference on simulation data featuring spatially varying parameters
and demonstrate the capability to detect such parameter variations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:15:27 GMT""}]","2023-05-25"
"2305.14765","Insung Kong","Insung Kong, Dongyoon Yang, Jongjin Lee, Ilsang Ohn, Gyuseung Baek,
  Yongdai Kim","Masked Bayesian Neural Networks : Theoretical Guarantee and its
  Posterior Inference","30 pages, ICML 2023 proceedings. arXiv admin note: substantial text
  overlap with arXiv:2206.00853",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian approaches for learning deep neural networks (BNN) have been
received much attention and successfully applied to various applications.
Particularly, BNNs have the merit of having better generalization ability as
well as better uncertainty quantification. For the success of BNN, search an
appropriate architecture of the neural networks is an important task, and
various algorithms to find good sparse neural networks have been proposed. In
this paper, we propose a new node-sparse BNN model which has good theoretical
properties and is computationally feasible. We prove that the posterior
concentration rate to the true model is near minimax optimal and adaptive to
the smoothness of the true model. In particular the adaptiveness is the first
of its kind for node-sparse BNNs. In addition, we develop a novel MCMC
algorithm which makes the Bayesian inference of the node-sparse BNN model
feasible in practice.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:16:11 GMT""}]","2023-05-25"
"2305.14766","Xiao Liu","Hao Sun, Xiao Liu, Yeyun Gong, Anlei Dong, Jingwen Lu, Yan Zhang,
  Daxin Jiang, Linjun Yang, Rangan Majumder, Nan Duan","BeamSearchQA: Large Language Models are Strong Zero-Shot QA Solver","Work in progress",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Open-domain question answering is a crucial task that often requires
accessing external information. Existing methods typically adopt a single-turn
retrieve-then-read approach, where relevant documents are first retrieved, and
questions are then answered based on the retrieved information. However, there
are cases where answering a question requires implicit knowledge that is not
directly retrievable from the question itself. In this work, we propose a novel
question-answering pipeline called BeamSearchQA. Our approach leverages large
language models to iteratively generate new questions about the original
question, enabling an iterative reasoning process. By iteratively refining and
expanding the scope of the question, our method aims to capture and utilize
hidden knowledge that may not be directly obtainable through retrieval. We
evaluate our approach on the widely-used open-domain NQ and WebQ datasets. The
experimental results demonstrate that BeamSearchQA significantly outperforms
other zero-shot baselines, indicating its effectiveness in tackling the
challenges of open-domain question answering.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:16:44 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 07:53:11 GMT""}]","2023-06-02"
"2305.14767","Andi Wang","Andi Wang, Hao Yan, and Juan Du","Interpretation and visualization of distance covariance through additive
  decomposition of correlations formula",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distance covariance is a widely used statistical methodology for testing the
dependency between two groups of variables. Despite the appealing properties of
consistency and superior testing power, the testing results of distance
covariance are often hard to be interpreted. This paper presents an elementary
interpretation of the mechanism of distance covariance through an additive
decomposition of correlations formula. Based on this formula, a visualization
method is developed to provide practitioners with a more intuitive explanation
of the distance covariance score.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:17:38 GMT""}]","2023-05-25"
"2305.14768","Zhengkai Jiang","Zhengkai Jiang and Liang Liu and Jiangning Zhang and Yabiao Wang and
  Mingang Chen and Chengjie Wang","Dual Path Transformer with Partition Attention",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a novel attention mechanism, called dual attention,
which is both efficient and effective. The dual attention mechanism consists of
two parallel components: local attention generated by Convolutional Neural
Networks (CNNs) and long-range attention generated by Vision Transformers
(ViTs). To address the high computational complexity and memory footprint of
vanilla Multi-Head Self-Attention (MHSA), we introduce a novel Multi-Head
Partition-wise Attention (MHPA) mechanism. The partition-wise attention
approach models both intra-partition and inter-partition attention
simultaneously. Building on the dual attention block and partition-wise
attention mechanism, we present a hierarchical vision backbone called
DualFormer. We evaluate the effectiveness of our model on several computer
vision tasks, including image classification on ImageNet, object detection on
COCO, and semantic segmentation on Cityscapes. Specifically, the proposed
DualFormer-XS achieves 81.5\% top-1 accuracy on ImageNet, outperforming the
recent state-of-the-art MPViT-XS by 0.6\% top-1 accuracy with much higher
throughput.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:17:53 GMT""}]","2023-05-25"
"2305.14769","Raul Fuentes-Azcatl Dr.","Ra\'ul Fuentes-Azcatl, Minerva Gonz\'alez-Melchor","Novel force field of [Bmim][Nf$_2$T] and its tranferability in a mixture
  with water",,,,,"cond-mat.soft physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, a new force field is presented for the ionic liquid
1-butyl-3-methylimidazolium-bis(trifluoromethylsulfonyl)imide, [Bmim][Nf$_2$T].
As a part of the \epsilon force field, the acronym IL/\epsilon is used to refer
to this ionic liquid. This new force field reproduces the dielectric constant,
the density, and the entalphy of vaporization, with an error of less than 3%,
being posible to generate new force fields for ionic liquids, based on the
flexibility of the molecule. In addition, a study of the [Bmim][Nf$_2$T]-H$_2$O
mixture is performed from pure IL to pure water, passing through various
concentrations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:18:57 GMT""}]","2023-05-25"
"2305.14770","Manya Wadhwa","Manya Wadhwa, Jifan Chen, Junyi Jessy Li, Greg Durrett","Using Natural Language Explanations to Rescale Human Judgments","Data available at
  https://github.com/ManyaWadhwa/explanation_based_rescaling",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The rise of large language models (LLMs) has brought a critical need for
high-quality human-labeled data, particularly for processes like human feedback
and evaluation. A common practice is to label data via consensus annotation
over the judgments of multiple crowdworkers. However, different annotators may
have different interpretations of labeling schemes unless given extensive
training, and for subjective NLP tasks, even trained expert annotators can
diverge heavily. We show that these nuances can be captured by high quality
natural language explanations, and propose a method to rescale ordinal
annotation in the presence of disagreement using LLMs. Specifically, we feed
Likert ratings and corresponding natural language explanations into an LLM and
prompt it to produce a numeric score. This score should reflect the underlying
assessment of the example by the annotator. The presence of explanations allows
the LLM to homogenize ratings across annotators in spite of scale usage
differences. We explore our technique in the context of a document-grounded
question answering task on which large language models achieve near-human
performance. Among questions where annotators identify incompleteness in the
answers, our rescaling improves correlation between nearly all annotator pairs,
improving pairwise correlation on these examples by an average of 0.2 Kendall's
tau.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:19:14 GMT""}]","2023-05-25"
"2305.14771","Xiaochuang Han","Xiaochuang Han, Sachin Kumar, Yulia Tsvetkov, Marjan Ghazvininejad","SSD-2: Scaling and Inference-time Fusion of Diffusion Language Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion-based language models (LMs) have been shown to be competent
generative models that are easy to control at inference and are a promising
alternative to autoregressive LMs. While autoregressive LMs have benefited
immensely from scaling and instruction-based learning, existing studies on
diffusion LMs have been conducted on a relatively smaller scale. Starting with
a recently proposed diffusion model SSD-LM, in this work we explore methods to
scale it from 0.4B to 13B parameters, proposing several techniques to improve
its training and inference efficiency. We call the new model SSD-2. We further
show that this model can be easily finetuned to follow instructions. Finally,
leveraging diffusion models' capability at inference-time control, we show that
SSD-2 facilitates novel ensembles with 100x smaller models that can be
customized and deployed by individual users. We find that compared to
autoregressive models, the collaboration between diffusion models is more
effective, leading to higher-quality and more relevant model responses due to
their ability to incorporate bi-directional contexts.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:22:14 GMT""}]","2023-05-25"
"2305.14772","Benjamin Newman","Benjamin Newman, Luca Soldaini, Raymond Fok, Arman Cohan, Kyle Lo","A Controllable QA-based Framework for Decontextualization","11 pages, 3 figures, 6 tables",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Many real-world applications require surfacing extracted snippets to users,
whether motivated by assistive tools for literature surveys or document
cross-referencing, or needs to mitigate and recover from model generated
inaccuracies., Yet, these passages can be difficult to consume when divorced
from their original document context. In this work, we explore the limits of
LLMs to perform decontextualization of document snippets in user-facing
scenarios, focusing on two real-world settings - question answering and
citation context previews for scientific documents. We propose a
question-answering framework for decontextualization that allows for better
handling of user information needs and preferences when determining the scope
of rewriting. We present results showing state-of-the-art LLMs under our
framework remain competitive with end-to-end approaches. We also explore
incorporating user preferences into the system, finding our framework allows
for controllability.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:23:02 GMT""}]","2023-05-25"
"2305.14773","Hogyun Kim","Hogyun Kim, Gilhwan Kang, Seokhwan Jeong, Seungjun Ma and Younggun Cho","Robust Imaging Sonar-based Place Recognition and Localization in
  Underwater Environments","7 pages, 8 figures",,,,"cs.RO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Place recognition using SOund Navigation and Ranging (SONAR) images is an
important task for simultaneous localization and mapping(SLAM) in underwater
environments. This paper proposes a robust and efficient imaging SONAR based
place recognition, SONAR context, and loop closure method. Unlike previous
methods, our approach encodes geometric information based on the
characteristics of raw SONAR measurements without prior knowledge or training.
We also design a hierarchical searching procedure for fast retrieval of
candidate SONAR frames and apply adaptive shifting and padding to achieve
robust matching on rotation and translation changes. In addition, we can derive
the initial pose through adaptive shifting and apply it to the iterative
closest point (ICP) based loop closure factor. We evaluate the performance of
SONAR context in the various underwater sequences such as simulated open water,
real water tank, and real underwater environments. The proposed approach shows
the robustness and improvements of place recognition on various datasets and
evaluation metrics. Supplementary materials are available at
https://github.com/sparolab/sonar_context.git.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:23:33 GMT""}]","2023-05-25"
"2305.14774","Jordi Boronat","M. C. Gordillo and J. Boronat","Phases of $^4$He and H$_2$ adsorbed on a single carbon nanotube",,"Phys. Rev. B 107, 174518 (2023)","10.1103/PhysRevB.107.174518",,"cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Using a diffusion Monte Carlo (DMC) technique, we calculated the phase
diagrams of $^4$He and H$_2$ adsorbed on a single (5,5) carbon nanotube, one of
the narrowest that can be obtained experimentally. For a single monolayer, when
the adsorbate density increases, both species undergo a series of first order
solid-solid phase transitions between incommensurate arrangements. Remarkably,
the $^4$He lowest-density solid phase shows supersolid behavior in contrast
with the normal solid that we found for H$_2$. The nature of the second-layer
is also different for both adsorbates. Contrarily to what happens on graphite,
the second-layer of $^4$He on that tube is a liquid, at least up to the density
corresponding to a third-layer promotion on a flat substrate. However, the
second-layer of H$_2$ is a solid that, at its lowest stable density, has a
small but observable superfluid fraction.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:24:01 GMT""}]","2023-05-31"
"2305.14775","Amirhossein Kazemnejad","Amirhossein Kazemnejad, Mehdi Rezagholizadeh, Prasanna Parthasarathi,
  Sarath Chandar","Measuring the Knowledge Acquisition-Utilization Gap in Pretrained
  Language Models",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  While pre-trained language models (PLMs) have shown evidence of acquiring
vast amounts of knowledge, it remains unclear how much of this parametric
knowledge is actually usable in performing downstream tasks. We propose a
systematic framework to measure parametric knowledge utilization in PLMs. Our
framework first extracts knowledge from a PLM's parameters and subsequently
constructs a downstream task around this extracted knowledge. Performance on
this task thus depends exclusively on utilizing the model's possessed
knowledge, avoiding confounding factors like insufficient signal. As an
instantiation, we study factual knowledge of PLMs and measure utilization
across 125M to 13B parameter PLMs. We observe that: (1) PLMs exhibit two gaps -
in acquired vs. utilized knowledge, (2) they show limited robustness in
utilizing knowledge under distribution shifts, and (3) larger models close the
acquired knowledge gap but the utilized knowledge gap remains. Overall, our
study provides insights into PLMs' capabilities beyond their acquired
knowledge.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:26:11 GMT""}]","2023-05-25"
"2305.14776","Yuchen Ding","Yuchen Ding and Lilu Zhao","Solution to a problem of Luca, Menares and Pizarro-Madariaga","some minor typos are corrected",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $k\ge 2$ be a positive integer and $P^+(n)$ the greatest prime factor of
a positive integer $n$ with convention $P^+(1)=1$. For any $\theta\in
\left[\frac 1{2k},\frac{17}{32k}\right)$, set
$$T_{k,\theta}(x)=\sum_{\substack{p_1\cdot\cdot\cdot p_k\le x\\
P^+(\gcd(p_1-1,...,p_k-1))\ge (p_1\cdot\cdot\cdot p_k)^\theta}}1,$$ where the
$p'$s are primes. It is proved that
$$T_{k,\theta}(x)\ll_{k}\frac{x^{1-\theta(k-1)}}{(\log x)^2},$$ which, together
with the lower bound $$T_{k,\theta}(x)\gg_{k}\frac{x^{1-\theta(k-1)}}{(\log
x)^2}$$ obtained by Wu in 2019, answer a 2015 problem of Luca, Menares and
Pizarro-Madariaga on the exact order of magnitude of $T_{k,\theta}(x)$.
  A main novelty in the proof is that, instead of using the Brun--Titchmarsh
theorem to estimate the $k^{th}$ movement of primes in arithmetic progressions,
we transform the movement to an estimation involving taking primes
simultaneously by linear shifts of primes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:29:29 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 06:42:01 GMT""}]","2023-06-06"
"2305.14777","Jaemoo Choi","Jaemoo Choi, Jaewoong Choi, Myungjoo Kang","Generative Modeling through the Semi-dual Formulation of Unbalanced
  Optimal Transport","23 pages, 15 figures",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optimal Transport (OT) problem investigates a transport map that bridges two
distributions while minimizing a given cost function. In this regard, OT
between tractable prior distribution and data has been utilized for generative
modeling tasks. However, OT-based methods are susceptible to outliers and face
optimization challenges during training. In this paper, we propose a novel
generative model based on the semi-dual formulation of Unbalanced Optimal
Transport (UOT). Unlike OT, UOT relaxes the hard constraint on distribution
matching. This approach provides better robustness against outliers, stability
during training, and faster convergence. We validate these properties
empirically through experiments. Moreover, we study the theoretical upper-bound
of divergence between distributions in UOT. Our model outperforms existing
OT-based generative models, achieving FID scores of 2.97 on CIFAR-10 and 5.80
on CelebA-HQ-256.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:31:05 GMT""}]","2023-05-25"
"2305.14778","Xiyuan Wang","Xiyuan Wang, Fangyuan Wang, Bo Xu, Liang Xu, Jing Xiao","P-vectors: A Parallel-Coupled TDNN/Transformer Network for Speaker
  Verification","Accepted by INTERSPEECH 2023",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Typically, the Time-Delay Neural Network (TDNN) and Transformer can serve as
a backbone for Speaker Verification (SV). Both of them have advantages and
disadvantages from the perspective of global and local feature modeling. How to
effectively integrate these two style features is still an open issue. In this
paper, we explore a Parallel-coupled TDNN/Transformer Network (p-vectors) to
replace the serial hybrid networks. The p-vectors allows TDNN and Transformer
to learn the complementary information from each other through Soft Feature
Alignment Interaction (SFAI) under the premise of preserving local and global
features. Also, p-vectors uses the Spatial Frequency-channel Attention (SFA) to
enhance the spatial interdependence modeling for input features. Finally, the
outputs of dual branches of p-vectors are combined by Embedding Aggregation
Layer (EAL). Experiments show that p-vectors outperforms MACCIF-TDNN and
MFA-Conformer with relative improvements of 11.5% and 13.9% in EER on
VoxCeleb1-O.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:33:38 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 07:40:15 GMT""}]","2023-05-26"
"2305.14779","Nikita Srivatsan","Nikita Srivatsan, Sofia Samaniego, Omar Florez, Taylor
  Berg-Kirkpatrick","Text Conditional Alt-Text Generation for Twitter Images",,,,,"cs.CV cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this work we present an approach for generating alternative text (or
alt-text) descriptions for images shared on social media, specifically Twitter.
This task is more than just a special case of image captioning, as alt-text is
both more literally descriptive and context-specific. Also critically, images
posted to Twitter are often accompanied by user-written text that despite not
necessarily describing the image may provide useful context that if properly
leveraged can be informative -- e.g. the tweet may name an uncommon object in
the image that the model has not previously seen. We address this with a CLIP
prefix model that extracts an embedding of the image and passes it to a mapping
network that outputs a short sequence in word embedding space, or a ``prefix'',
to which we also concatenate the text from the tweet itself. This lets the
model condition on both visual and textual information from the post. The
combined multimodal prefix is then fed as a prompt to a pretrained language
model which autoregressively completes the sequence to generate the alt-text.
While prior work has used similar methods for captioning, ours is the first to
our knowledge that incorporates textual information from the associated social
media post into the prefix as well, and we further demonstrate through
ablations that utility of these two information sources stacks. We put forward
a new dataset scraped from Twitter and evaluate on it across a variety of
automated metrics as well as human evaluation, and show that our approach of
conditioning on both tweet text and visual information significantly
outperforms prior work.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:35:26 GMT""}]","2023-05-25"
"2305.14780","Bo Xue","Bo Xue, Kayode Adedotun Oyesina and Alex M. H. Wong","Electromagnetic Near-Field Mutual Coupling Suppression with Active Janus
  Sources","21 pages, 6 figures, 1 table",,,,"physics.app-ph physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electric dipoles and magnetic dipoles are the most fundamental particles in
electromagnetic theory. Huygens and Janus sources, formed by the orthogonal
combination of electric and magnetic dipoles, both show good directionality in
the near field. Although the Huygens source has been widely used in antennas
and metasurfaces, the applications of Janus source are heretofore limited. In
this paper we report the first physical construction of an active Janus source.
Through full-wave simulations within the PPW environment, we show that our
source achieves the directional electromagnetic near-field and quasi-isotropic
far-field requisite of the Janus source. Using this fact, we demonstrate that
two active Janus sources in close proximity (about 0.10 to 0.25 wavelengths)
achieve a near 1000-fold reduced mutual coupling compared to electric dipole
sources. The achievement of strong mutual coupling suppression and
quasi-isotropic radiation make the Janus source an ideal candidate for
consideration in future compact MIMO communication systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:37:12 GMT""}]","2023-05-29"
"2305.14781","Qingyuan Liu","Qingyuan Liu, Zhengchao Huang, Hao Ye, Dexian Huang, Chao Shang","Accelerated Nonconvex ADMM with Self-Adaptive Penalty for
  Rank-Constrained Model Identification","7 pages, 4 figures. Submitted to 62nd IEEE Conference on Decision and
  Control (CDC 2023)",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The alternating direction method of multipliers (ADMM) has been widely
adopted in low-rank approximation and low-order model identification tasks;
however, the performance of nonconvex ADMM is highly reliant on the choice of
penalty parameter. To accelerate ADMM for solving rankconstrained
identification problems, this paper proposes a new self-adaptive strategy for
automatic penalty update. Guided by first-order analysis of the increment of
the augmented Lagrangian, the self-adaptive penalty updating enables effective
and balanced minimization of both primal and dual residuals and thus ensures a
stable convergence. Moreover, improved efficiency can be obtained within the
Anderson acceleration scheme. Numerical examples show that the proposed
strategy significantly accelerates the convergence of nonconvex ADMM while
alleviating the critical reliance on tedious tuning of penalty parameters.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:38:36 GMT""}]","2023-05-25"
"2305.14782","Pengyuan Lu","Pengyuan Lu and Michele Caprio and Eric Eaton and Insup Lee","Zero-shot Task Preference Addressing Enabled by Imprecise Bayesian
  Continual Learning",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Like generic multi-task learning, continual learning has the nature of
multi-objective optimization, and therefore faces a trade-off between the
performance of different tasks. That is, to optimize for the current task
distribution, it may need to compromise performance on some tasks to improve on
others. This means there exist multiple models that are each optimal at
different times, each addressing a distinct task-performance trade-off.
Researchers have discussed how to train particular models to address specific
preferences on these trade-offs. However, existing algorithms require
additional sample overheads -- a large burden when there are multiple, possibly
infinitely many, preferences. As a response, we propose Imprecise Bayesian
Continual Learning (IBCL). Upon a new task, IBCL (1) updates a knowledge base
in the form of a convex hull of model parameter distributions and (2) obtains
particular models to address preferences with zero-shot. That is, IBCL does not
require any additional training overhead to construct preference-addressing
models from its knowledge base. We show that models obtained by IBCL have
guarantees in identifying the preferred parameters. Moreover, experiments show
that IBCL is able to locate the Pareto set of parameters given a preference,
maintain similar to better performance than baseline methods, and significantly
reduce training overhead via zero-shot preference addressing.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:39:00 GMT""}]","2023-05-25"
"2305.14783","Zihong Liang","Zihong Liang, Xiaojun Quan, Qifan Wang","Disentangled Phonetic Representation for Chinese Spelling Correction","Accepted to ACL 2023 Main Conference",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chinese Spelling Correction (CSC) aims to detect and correct erroneous
characters in Chinese texts. Although efforts have been made to introduce
phonetic information (Hanyu Pinyin) in this task, they typically merge phonetic
representations with character representations, which tends to weaken the
representation effect of normal texts. In this work, we propose to disentangle
the two types of features to allow for direct interaction between textual and
phonetic information. To learn useful phonetic representations, we introduce a
pinyin-to-character objective to ask the model to predict the correct
characters based solely on phonetic information, where a separation mask is
imposed to disable attention from phonetic input to text. To avoid overfitting
the phonetics, we further design a self-distillation module to ensure that
semantic information plays a major role in the prediction. Extensive
experiments on three CSC benchmarks demonstrate the superiority of our method
in using phonetic information.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:39:12 GMT""}]","2023-05-25"
"2305.14784","Ameet Deshpande","Ameet Deshpande, Tanmay Rajpurohit, Karthik Narasimhan, Ashwin Kalyan","Anthropomorphization of AI: Opportunities and Risks",,,,,"cs.AI cs.CL cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anthropomorphization is the tendency to attribute human-like traits to
non-human entities. It is prevalent in many social contexts -- children
anthropomorphize toys, adults do so with brands, and it is a literary device.
It is also a versatile tool in science, with behavioral psychology and
evolutionary biology meticulously documenting its consequences. With widespread
adoption of AI systems, and the push from stakeholders to make it human-like
through alignment techniques, human voice, and pictorial avatars, the tendency
for users to anthropomorphize it increases significantly. We take a dyadic
approach to understanding this phenomenon with large language models (LLMs) by
studying (1) the objective legal implications, as analyzed through the lens of
the recent blueprint of AI bill of rights and the (2) subtle psychological
aspects customization and anthropomorphization. We find that anthropomorphized
LLMs customized for different user bases violate multiple provisions in the
legislative blueprint. In addition, we point out that anthropomorphization of
LLMs affects the influence they can have on their users, thus having the
potential to fundamentally change the nature of human-AI interaction, with
potential for manipulation and negative influence. With LLMs being
hyper-personalized for vulnerable groups like children and patients among
others, our work is a timely and important contribution. We propose a
conservative strategy for the cautious use of anthropomorphization to improve
trustworthiness of AI systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:39:45 GMT""}]","2023-05-25"
"2305.14785","Yoav Goldberg","Victoria Basmov, Yoav Goldberg, Reut Tsarfaty","ChatGPT and Simple Linguistic Inferences: Blind Spots and Blinds",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper sheds light on the limitations of ChatGPT's understanding
capabilities, focusing on simple inference tasks that are typically easy for
humans but appear to be challenging for the model. Specifically, we target (i)
grammatically-specified entailments, (ii) premises with evidential adverbs of
uncertainty, and (iii) monotonicity entailments. We present expert-designed
evaluation sets for these inference types and conduct experiments in a
zero-shot setup. Our results show that the model struggles with these types of
inferences, exhibiting moderate to low accuracy. Moreover, while ChatGPT
demonstrates knowledge of the underlying linguistic concepts when prompted
directly, it often fails to incorporate this knowledge to make correct
inferences. Even more strikingly, further experiments show that embedding the
premise under presupposition triggers or non-factive verbs causes the model to
predict entailment more frequently {regardless} of the correct semantic label.
Overall these results suggest that, despite GPT's celebrated language
understanding capacity, ChatGPT has blindspots with respect to certain types of
entailment, and that certain entailment-cancelling features act as ``blinds''
overshadowing the semantics of the embedded premise. Our analyses emphasize the
need for further research into the linguistic comprehension and reasoning
capabilities of LLMs, in order to improve their reliability, and establish
their trustworthiness for real-world applications.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:41:09 GMT""}]","2023-05-25"
"2305.14786","Takuya Aoyama","Takuya Aoyama, Kenya Ohgushi","Piezomagnetic Properties in Altermagnetic MnTe",,,,,"cond-mat.mtrl-sci cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We examined the piezomagnetic effect in an antiferromagnet composed of MnTe,
which is a candidate material for altermagnetism with a high critical
temperature. We observed that the magnetization develops with the application
of stress and revealed that the piezomagnetic coefficient Q is
1.38$\times10^{-8}$ ${\mu}$B/MPa at 300 K. The poling-field dependence of
magnetization indicates that the antiferromagnetic domain can be controlled
using the piezomagnetic effect. We demonstrate that the piezomagnetic effect is
suitable for detecting and controlling the broken time reversal symmetry in
altermagnets.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:41:53 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 01:16:44 GMT""}]","2023-06-02"
"2305.14787","Michael Baltaxe","Michael Baltaxe, Tomer Pe'er, Dan Levi","Polarimetric Imaging for Perception",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Autonomous driving and advanced driver-assistance systems rely on a set of
sensors and algorithms to perform the appropriate actions and provide alerts as
a function of the driving scene. Typically, the sensors include color cameras,
radar, lidar and ultrasonic sensors. Strikingly however, although light
polarization is a fundamental property of light, it is seldom harnessed for
perception tasks. In this work we analyze the potential for improvement in
perception tasks when using an RGB-polarimetric camera, as compared to an RGB
camera. We examine monocular depth estimation and free space detection during
the middle of the day, when polarization is independent of subject heading, and
show that a quantifiable improvement can be achieved for both of them using
state-of-the-art deep neural networks, with a minimum of architectural changes.
We also present a new dataset composed of RGB-polarimetric images, lidar scans,
GNSS / IMU readings and free space segmentations that further supports
developing perception algorithms that take advantage of light polarization.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:42:27 GMT""}]","2023-05-25"
"2305.14788","Alexander Wettig","Alexis Chevalier, Alexander Wettig, Anirudh Ajith, Danqi Chen","Adapting Language Models to Compress Contexts",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer-based language models (LMs) are powerful and widely-applicable
tools, but their usefulness is constrained by a finite context window and the
expensive computational cost of processing long text documents. We propose to
adapt pre-trained LMs into AutoCompressors. These models are capable of
compressing long contexts into compact summary vectors, which are then
accessible to the model as soft prompts. Summary vectors are trained with an
unsupervised objective, whereby long documents are processed in segments and
summary vectors from all previous segments are used in language modeling. We
fine-tune OPT models on sequences of up to 30,720 tokens and show that
AutoCompressors can utilize long contexts to improve perplexity. We evaluate
AutoCompressors on in-context learning by compressing task demonstrations. We
find that summary vectors are good substitutes for plain-text demonstrations,
increasing accuracy while reducing inference cost. Finally, we explore the
benefits of pre-computing summary vectors for large corpora by applying summary
vectors to retrieval-augmented language modeling. Overall, AutoCompressors
emerge as a simple and inexpensive solution for extending the context window of
LMs while speeding up inference over long contexts.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:42:44 GMT""}]","2023-05-25"
"2305.14789","Xinyi Yuan","Junyi Xie, Xinyi Yuan","Partial Heights and the Geometric Bombieri-Lang Conjecture","61 pages",,,,"math.NT math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We prove the geometric Bombieri-Lang conjecture for projective varieties
which have finite morphisms to abelian varieties over function fields of
characteristic 0. Our proof is complex analytic, which applies the classical
Brody lemma to construct entire curves on complex varieties. Our key
ingredients includes a new notion of partial height and its non-degeneracy in a
suitable sense. The non-degeneracy is required in the application of the Brody
lemma.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:43:05 GMT""}]","2023-05-25"
"2305.14790","Feng Jiang","Feng Jiang, Weihao Liu, Xiaomin Chu, Peifeng Li, Qiaoming Zhu, Haizhou
  Li","Advancing Topic Segmentation and Outline Generation in Chinese Texts:
  The Paragraph-level Topic Representation, Corpus, and Benchmark",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Topic segmentation and outline generation strive to divide a document into
coherent topic sections and generate corresponding subheadings. Such a process
unveils the discourse topic structure of a document that benefits quickly
grasping and understanding the overall context of the document from a higher
level. However, research and applications in this field have been restrained
due to the lack of proper paragraph-level topic representations and
large-scale, high-quality corpora in Chinese compared to the success achieved
in English. Addressing these issues, we introduce a hierarchical
paragraph-level topic structure representation with title, subheading, and
paragraph that comprehensively models the document discourse topic structure.
In addition, we ensure a more holistic representation of topic distribution
within the document by using sentences instead of keywords to represent
sub-topics. Following this representation, we construct the largest Chinese
Paragraph-level Topic Structure corpus (CPTS), four times larger than the
previously largest one. We also employ a two-stage man-machine collaborative
annotation method to ensure the high quality of the corpus both in form and
semantics. Finally, we validate the computability of CPTS on two fundamental
tasks (topic segmentation and outline generation) by several strong baselines,
and its efficacy has been preliminarily confirmed on the downstream task:
discourse parsing. The representation, corpus, and benchmark we established
will provide a solid foundation for future studies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:43:23 GMT""}]","2023-05-25"
"2305.14791","Yongqi Li","Yongqi Li, Mayi Xu, Xin Miao, Shen Zhou, Tieyun Qian","Large Language Models as Counterfactual Generator: Strengths and
  Weaknesses",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LLMs) have demonstrated remarkable performance in a
range of natural language understanding and generation tasks. Yet, their
ability to generate counterfactuals, which can be used for areas like data
augmentation, remains under-explored. This study aims to investigate the
counterfactual generation capabilities of LLMs and analysis factors that
influence this ability. First, we evaluate how effective are LLMs in
counterfactual generation through data augmentation experiments for small
language models (SLMs) across four tasks: sentiment analysis, natural language
inference, named entity recognition, and relation extraction. While LLMs show
promising enhancements in various settings, they struggle in complex tasks due
to their self-limitations and the lack of logical guidance to produce
counterfactuals that align with commonsense. Second, our analysis reveals the
pivotal role of providing accurate task definitions and detailed step-by-step
instructions to LLMs in generating counterfactuals. Interestingly, we also find
that LLMs can generate reasonable counterfactuals even with unreasonable
demonstrations, which illustrates that demonstrations are primarily to regulate
the output format.This study provides the first comprehensive insight into
counterfactual generation abilities of LLMs, and offers a novel perspective on
utilizing LLMs for data augmentation to enhance SLMs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:44:32 GMT""}]","2023-05-25"
"2305.14792","Tianyu Li","Tianyu Li, Jungdam Won, Alexander Clegg, Jeonghwan Kim, Akshara Rai,
  Sehoon Ha","ACE: Adversarial Correspondence Embedding for Cross Morphology Motion
  Retargeting from Human to Nonhuman Characters",,,,,"cs.RO cs.GR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Motion retargeting is a promising approach for generating natural and
compelling animations for nonhuman characters. However, it is challenging to
translate human movements into semantically equivalent motions for target
characters with different morphologies due to the ambiguous nature of the
problem. This work presents a novel learning-based motion retargeting
framework, Adversarial Correspondence Embedding (ACE), to retarget human
motions onto target characters with different body dimensions and structures.
Our framework is designed to produce natural and feasible robot motions by
leveraging generative-adversarial networks (GANs) while preserving high-level
motion semantics by introducing an additional feature loss. In addition, we
pretrain a robot motion prior that can be controlled in a latent embedding
space and seek to establish a compact correspondence. We demonstrate that the
proposed framework can produce retargeted motions for three different
characters -- a quadrupedal robot with a manipulator, a crab character, and a
wheeled manipulator. We further validate the design choices of our framework by
conducting baseline comparisons and a user study. We also showcase sim-to-real
transfer of the retargeted motions by transferring them to a real Spot robot.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:44:32 GMT""}]","2023-05-25"
"2305.14793","Nikhita Vedula","Zhuoer Wang, Marcus Collins, Nikhita Vedula, Simone Filice, Shervin
  Malmasi, Oleg Rokhlenko","Faithful Low-Resource Data-to-Text Generation through Cycle Training","19 pages, 4 figures, ACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Methods to generate text from structured data have advanced significantly in
recent years, primarily due to fine-tuning of pre-trained language models on
large datasets. However, such models can fail to produce output faithful to the
input data, particularly on out-of-domain data. Sufficient annotated data is
often not available for specific domains, leading us to seek an unsupervised
approach to improve the faithfulness of output text. Since the problem is
fundamentally one of consistency between the representations of the structured
data and text, we evaluate the effectiveness of cycle training in this work.
Cycle training uses two models which are inverses of each other: one that
generates text from structured data, and one which generates the structured
data from natural language text. We show that cycle training, when initialized
with a small amount of supervised data (100 samples in our case), achieves
nearly the same performance as fully supervised approaches for the data-to-text
generation task on the WebNLG, E2E, WTQ, and WSQL datasets. We perform
extensive empirical analysis with automated evaluation metrics and a newly
designed human evaluation schema to reveal different cycle training strategies'
effectiveness of reducing various types of generation errors. Our code is
publicly available at https://github.com/Edillower/CycleNLG.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:44:42 GMT""}]","2023-05-25"
"2305.14794","Chengyu Dong","Chengyu Dong, Zihan Wang, Jingbo Shang","Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak
  Supervision for Text Classification",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in weakly supervised text classification mostly focus on
designing sophisticated methods to turn high-level human heuristics into
quality pseudo-labels. In this paper, we revisit the seed matching-based
method, which is arguably the simplest way to generate pseudo-labels, and show
that its power was greatly underestimated. We show that the limited performance
of seed matching is largely due to the label bias injected by the simple
seed-match rule, which prevents the classifier from learning reliable
confidence for selecting high-quality pseudo-labels. Interestingly, simply
deleting the seed words present in the matched input texts can mitigate the
label bias and help learn better confidence. Subsequently, the performance
achieved by seed matching can be improved significantly, making it on par with
or even better than the state-of-the-art. Furthermore, to handle the case when
the seed words are not made known, we propose to simply delete the word tokens
in the input text randomly with a high deletion ratio. Remarkably, seed
matching equipped with this random deletion method can often achieve even
better performance than that with seed deletion.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:45:33 GMT""}]","2023-05-25"
"2305.14795","Zexuan Zhong","Zexuan Zhong, Zhengxuan Wu, Christopher D. Manning, Christopher Potts,
  Danqi Chen","MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop
  Questions","Our code and datasets are available at
  https://github.com/princeton-nlp/MQuAKE",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The information stored in large language models (LLMs) falls out of date
quickly, and retraining from scratch is often not an option. This has recently
given rise to a range of techniques for injecting new facts through updating
model weights. Current evaluation paradigms are extremely limited, mainly
validating the recall of edited facts, but changing one fact should cause
rippling changes to the model's related beliefs. If we edit the UK Prime
Minister to now be Rishi Sunak, then we should get a different answer to Who is
married to the British Prime Minister? In this work, we present a benchmark
MQuAKE (Multi-hop Question Answering for Knowledge Editing) comprising
multi-hop questions that assess whether edited models correctly answer
questions where the answer should change as an entailed consequence of edited
facts. While we find that current knowledge-editing approaches can recall
edited facts accurately, they fail catastrophically on the constructed
multi-hop questions. We thus propose a simple memory-based approach, MeLLo,
which stores all edited facts externally while prompting the language model
iteratively to generate answers that are consistent with the edited facts.
While MQuAKE remains challenging, we show that MeLLo scales well with LLMs (up
to 175B) and outperforms previous model editors by a large margin.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:48:41 GMT""}]","2023-05-25"
"2305.14796","J. C. J. Koelemeij","J. C. J. Koelemeij, H. Dun, C. E. V. Diouf, E. F. Dierikx, G. J. M.
  Janssen and C. C. J. M. Tiberius","A hybrid optical-wireless network for decimetre-level terrestrial
  positioning","38 pages, 9 figures, 3 tables","Nature 611 (2022) 473-478","10.1038/s41586-022-05315-7",,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Global navigation satellite systems (GNSS) are widely used for navigation and
time distribution, features indispensable for critical infrastructure such as
mobile communication networks, as well as emerging technologies like automated
driving and sustainable energy grids. While GNSS can provide centimetre-level
precision, GNSS receivers are prone to many-metre errors due to multipath
propagation and obstructed view of the sky, which occur especially in urban
areas where accurate positioning is needed most. Moreover, the vulnerabilities
of GNSS, combined with the lack of a back-up system, pose a severe risk to
GNSS-dependent technologies. Here, we demonstrate a terrestrial positioning
system which is independent of GNSS and offers superior performance through a
constellation of radio transmitters, connected and time-synchronised at the
sub-nanosecond level through a fibre-optic Ethernet network. Employing optical
and wireless transmission schemes similar to those encountered in mobile
communication networks, and exploiting spectrally efficient virtual wideband
signals, the detrimental effects of multipath propagation are mitigated, thus
enabling robust decimetre-level positioning and sub-nanosecond timing in a
multipath-prone outdoor environment. This work provides a glimpse of a future
in which telecommunication networks provide not only connectivity, but also
GNSS-independent timing and positioning services with unprecedented accuracy
and reliability.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:50:46 GMT""}]","2023-05-25"
"2305.14797","Xiao Li","Xiao Li, Igor Gilitschenski, Guy Rosman, Sertac Karaman, Daniela Rus","Multi-Abstractive Neural Controller: An Efficient Hierarchical Control
  Architecture for Interactive Driving",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  As learning-based methods make their way from perception systems to
planning/control stacks, robot control systems have started to enjoy the
benefits that data-driven methods provide. Because control systems directly
affect the motion of the robot, data-driven methods, especially black box
approaches, need to be used with caution considering aspects such as stability
and interpretability. In this paper, we describe a differentiable and
hierarchical control architecture. The proposed representation, called
\textit{multi-abstractive neural controller}, uses the input image to control
the transitions within a novel discrete behavior planner (referred to as the
visual automaton generative network, or \textit{vAGN}). The output of a vAGN
controls the parameters of a set of dynamic movement primitives which provides
the system controls. We train this neural controller with real-world driving
data via behavior cloning and show improved explainability, sample efficiency,
and similarity to human driving.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:51:55 GMT""}]","2023-05-25"
"2305.14798","Junyi Liu","Ying Cui, Junyi Liu, Jong-Shi Pang","The Minimization of Piecewise Functions: Pseudo Stationarity",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  There are many significant applied contexts that require the solution of
discontinuous optimization problems in finite dimensions. Yet these problems
are very difficult, both computationally and analytically. With the functions
being discontinuous and a minimizer (local or global) of the problems, even if
it exists, being impossible to verifiably compute, a foremost question is what
kind of ''stationary solutions'' one can expect to obtain; these solutions
provide promising candidates for minimizers; i.e., their defining conditions
are necessary for optimality. Motivated by recent results on sparse
optimization, we introduce in this paper such a kind of solution, termed
''pseudo B- (for Bouligand) stationary solution'', for a broad class of
discontinuous piecewise continuous optimization problems with objective and
constraint defined by indicator functions of the positive real axis composite
with functions that are possibly nonsmooth. We present two approaches for
computing such a solution. One approach is based on lifting the problem to a
higher dimension via the epigraphical formulation of the indicator functions;
this requires the addition of some auxiliary variables. The other approach is
based on certain continuous (albeit not necessarily differentiable) piecewise
approximations of the indicator functions and the convergence to a pseudo
B-stationary solution of the original problem is established. The conditions
for convergence are discussed and illustrated by an example.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:52:21 GMT""}]","2023-05-25"
"2305.14799","Hoang Nguyen","Hoang Tien Nguyen, Young-Jin Kim, and Dae-Hyun Choi","Sample-Efficient Learning for a Surrogate Model of Three-Phase
  Distribution System","Under review in IEEE PES Letter",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A surrogate model that accurately predicts distribution system voltages is
crucial for reliable smart grid planning and operation. This letter proposes a
fixed-point data-driven surrogate modeling method that employs a limited
dataset to learn the power-voltage relationship of an unbalanced three-phase
distribution system. The proposed surrogate model is designed using a
fixed-point load-flow equation, and the stochastic gradient descent method with
an automatic differentiation technique is employed to update the parameters of
the surrogate model using complex power and voltage samples. Numerical examples
in IEEE 13-bus, 37-bus, and 123-bus systems demonstrate that the proposed
surrogate model can outperform surrogate models based on the deep neural
network and Gaussian process regarding prediction accuracy and sample
efficiency
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:52:25 GMT""}]","2023-05-25"
"2305.14800","Yongliang Wu","Xu Yang, Yongliang Wu, Mingzhuo Yang, Haokun Chen, Xin Geng","Exploring Diverse In-Context Configurations for Image Captioning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  After discovering that Language Models (LMs) can be good in-context few-shot
learners, numerous strategies have been proposed to optimize in-context
sequence configurations. Recently, researchers in Vision-Language (VL) domains
also develop their few-shot learners, while they only use the simplest way,
i.e., randomly sampling, to configure in-context image-text pairs. In order to
explore the effects of varying configurations on VL in-context learning, we
devised four strategies for image selection and four for caption assignment to
configure in-context image-text pairs for image captioning. Here Image
Captioning is used as the case study since it can be seen as the
visually-conditioned LM. Our comprehensive experiments yield two
counter-intuitive but valuable insights, highlighting the distinct
characteristics of VL in-context learning due to multi-modal synergy, as
compared to the NLP case.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:52:47 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 13:17:45 GMT""}]","2023-05-29"
"2305.14801","Elvira Zappale","Giuliano Gargiulo and Elvira Zappale","A sufficient condition for the lower semicontinuity of nonlocal supremal
  functionals in the vectorial case","to appear in European Journal of Mathematics",,,,"math.AP math.OC","http://creativecommons.org/licenses/by/4.0/","  In this note we present a sufficient condition ensuring lower semicontinuity
for nonlocal supremal functionals of the type $$W^{1,\infty}(\Omega;\mathbb
R^d)\ni u \mapsto \sup{\rm ess}_{(x,y)\in \Omega} W(x,y, \nabla u(x),\nabla
u(y)),$$ where $\Omega$ is a bounded open subset of $\mathbb R^N$ and $W:\Omega
\times \Omega \times \mathbb R^{d \times N}\times \mathbb R^{d \times N} \to
\mathbb R$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:54:39 GMT""}]","2023-05-25"
"2305.14802","Harvey Yiyun Fu","Harvey Yiyun Fu, Qinyuan Ye, Albert Xu, Xiang Ren, Robin Jia","Estimating Large Language Model Capabilities without Labeled Test Data","14 pages, 4 figures",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Language Models (LLMs) have exhibited an impressive ability to perform
in-context learning (ICL) from only a few examples, but the success of ICL
varies widely from task to task. Thus, it is important to quickly determine
whether ICL is applicable to a new task, but directly evaluating ICL accuracy
can be expensive in situations where test data is expensive to annotate -- the
exact situations where ICL is most appealing. In this paper, we propose the
task of ICL accuracy estimation, in which we predict the accuracy of an LLM
when doing in-context learning on a new task given only unlabeled data for that
task. To perform ICL accuracy estimation, we propose a method that trains a
meta-model using LLM confidence scores as features. We compare our method to
several strong accuracy estimation baselines on a new benchmark that covers 4
LLMs and 3 task collections. On average, the meta-model improves over all
baselines and achieves the same estimation performance as directly evaluating
on 40 labeled test examples per task, across the total 12 settings. We
encourage future work to improve on our methods and evaluate on our ICL
accuracy estimation benchmark to deepen our understanding of when ICL works.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:55:09 GMT""}]","2023-05-25"
"2305.14803","Gilles Dowek","Gilles Dowek (LOGICAL)","Preliminary investigations on induction over real numbers",,,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The induction principle for natural numbers expresses that when a property
holds for some natural number a and is hereditary, then it holds for all
numbers greater than or equal to a. We present a similar principle for real
numbers.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:58:16 GMT""}]","2023-05-25"
"2305.14804","Jean-Marie MALHERBE","Jean-Marie Malherbe, Florence Cornu, Isabelle Bual\'e","Solex observations for the BASS2000 database, a collaboration PRO-AM","arXiv admin note: text overlap with arXiv:2301.11105",,,,"astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Systematic observations of the chromosphere and the photosphere started in
Meudon Observatory 115 years ago with Deslandres spectroheliograph. An
exceptional collection of more than 100 000 monochromatic images in CaII K and
H$\alpha$ spanning more than 10 solar cycles is proposed to the international
community by the BASS2000 solar database. We started in 2023 a ''PRO-AM''
collaboration between professional and amateur astronomers with the Solar
Explorer (SOLEX), a compact and high quality spectroheliograph designed by
Christian Buil, in order to record images every day, and several times per day,
owing to tens of observing stations in various places. This paper summarizes
the scientific objectives and provides practical and technical information to
amateurs willing to join the observing network.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:59:47 GMT""}]","2023-05-25"
"2305.14805","Kailiang Wu","Chaoyi Cai, Jianxian Qiu, Kailiang Wu","Provably convergent Newton-Raphson methods for recovering primitive
  variables with applications to physical-constraint-preserving Hermite WENO
  schemes for relativistic hydrodynamics","49 pages",,,,"math.NA astro-ph.IM cs.NA physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relativistic hydrodynamics (RHD) equations have three crucial intrinsic
physical constraints on the primitive variables: positivity of pressure and
density, and subluminal fluid velocity. However, numerical simulations can
violate these constraints, leading to nonphysical results or even simulation
failure. Designing genuinely physical-constraint-preserving (PCP) schemes is
very difficult, as the primitive variables cannot be explicitly reformulated
using conservative variables due to relativistic effects. In this paper, we
propose three efficient Newton--Raphson (NR) methods for robustly recovering
primitive variables from conservative variables. Importantly, we rigorously
prove that these NR methods are always convergent and PCP, meaning they
preserve the physical constraints throughout the NR iterations. The discovery
of these robust NR methods and their PCP convergence analyses are highly
nontrivial and technical. As an application, we apply the proposed NR methods
to design PCP finite volume Hermite weighted essentially non-oscillatory
(HWENO) schemes for solving the RHD equations. Our PCP HWENO schemes
incorporate high-order HWENO reconstruction, a PCP limiter, and
strong-stability-preserving time discretization. We rigorously prove the PCP
property of the fully discrete schemes using convex decomposition techniques.
Moreover, we suggest the characteristic decomposition with rescaled
eigenvectors and scale-invariant nonlinear weights to enhance the performance
of the HWENO schemes in simulating large-scale RHD problems. Several demanding
numerical tests are conducted to demonstrate the robustness, accuracy, and high
resolution of the proposed PCP HWENO schemes and to validate the efficiency of
our NR methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:59:54 GMT""}]","2023-05-25"
"2305.14806","Shuyang Cao","Shuyang Cao and Lu Wang","AWESOME: GPU Memory-constrained Long Document Summarization using Memory
  Mechanism and Global Salient Content",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Long document summarization systems are critical for domains with lengthy and
jargonladen text, yet they present significant challenges to researchers and
developers with limited computing resources. Existing solutions mainly focus on
efficient attentions or divide-and-conquer strategies. The former reduces
theoretical time complexity, but is still memory-heavy. The latter methods
sacrifice global context, leading to uninformative and incoherent summaries.
This work aims to leverage the memory-efficient nature of divide-and-conquer
methods while preserving global context. Concretely, our framework AWESOME uses
two novel mechanisms: (1) External memory mechanisms track previously encoded
document segments and their corresponding summaries, to enhance global document
understanding and summary coherence. (2) Global salient content is further
identified beforehand to augment each document segment to support its
summarization. Extensive experiments on diverse genres of text, including
government reports, transcripts, scientific papers, and novels, show that
AWESOME produces summaries with improved informativeness, faithfulness, and
coherence than competitive baselines on longer documents, while having a
similar or smaller GPU memory footprint.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:00:00 GMT""}]","2023-05-25"
"2305.14807","Gil Weinberg","Gil Weinberg, Uri Weiss, Ori Katz","Image scanning lensless fiber-bundle endomicroscopy",,,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fiber-based confocal endomicroscopy has shown great promise for
minimally-invasive deep-tissue imaging. Despite its advantages, confocal
fiber-bundle endoscopy inherently suffers from undersampling due to the spacing
between fiber cores, and low collection efficiency when the target is not in
proximity to the distal fiber facet. Here, we demonstrate an adaptation of
image-scanning microscopy (ISM) to lensless fiber bundle endoscopy, doubling
the spatial sampling frequency and significantly improving collection
efficiency. Our approach only requires replacing the confocal detector with a
camera. It improves the spatial resolution for targets placed at a distance
from the fiber tip, and addresses the fundamental challenge of
aliasing/pixelization artifacts.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:01:22 GMT""}]","2023-05-25"
"2305.14808","Yuwei Zhang","Yuwei Zhang and Zhi Jin and Zejun Wang and Ying Xing and Ge Li","SAGA: Summarization-Guided Assert Statement Generation","Preprint, to appear in the Journal of Computer Science and Technology
  (JCST)",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generating meaningful assert statements is one of the key challenges in
automated test case generation, which requires understanding the intended
functionality of the tested code. Recently, deep learning-based models have
shown promise in improving the performance of assert statement generation.
However, existing models only rely on the test prefixes along with their
corresponding focal methods, yet ignore the developer-written summarization.
Based on our observations, the summarization contents usually express the
intended program behavior or contain parameters that will appear directly in
the assert statement. Such information will help existing models address their
current inability to accurately predict assert statements. This paper presents
a novel summarization-guided approach for automatically generating assert
statements. To derive generic representations for natural language (i.e.,
summarization) and programming language (i.e., test prefixes and focal
methods), we leverage a pre-trained language model as the reference
architecture and fine-tune it on the task of assert statement generation. To
the best of our knowledge, the proposed approach makes the first attempt to
leverage the summarization of focal methods as the guidance for making the
generated assert statements more accurate. We demonstrate the effectiveness of
our approach on two real-world datasets when compared with state-of-the-art
models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:03:21 GMT""}]","2023-05-25"
"2305.14809","Khondokar Fida Hasan","Keyvan Ansari and Khondokar Fida Hasan","Proposition of Augmenting V2X Roadside Unit to Enhance Cooperative
  Awareness of Heterogeneously Connected Road Users","13 pages",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  Intelligent transportation and autonomous mobility solutions rely on
cooperative awareness developed by exchanging proximity and mobility data among
road users. To maintain pervasive awareness on roads, all vehicles and
vulnerable road users must be identified, either cooperatively, where road
users equipped with wireless capabilities of Vehicle-to-Everything (V2X) radios
can communicate with one another, or passively, where users without V2X
capabilities are detected by means other than V2X communications. This
necessitates the establishment of a communications channel among all
V2X-enabled road users, regardless of whether their underlying V2X technology
is compatible or not. At the same time, for cooperative awareness to realize
its full potential, non-V2X-enabled road users must also be communicated with
where possible or, leastwise, be identified passively. However, the question is
whether current V2X technologies can provide such a welcoming heterogeneous
road environment for all parties, including varying V2X-enabled and
non-V2X-enabled road users? This paper investigates the roles of a
propositional concept named Augmenting V2X Roadside Unit (A-RSU) in enabling
heterogeneous vehicular networks to support and benefit from pervasive
cooperative awareness. To this end, this paper explores the efficacy of A-RSU
in establishing pervasive cooperative awareness and investigates the
capabilities of the available communication networks using secondary data. The
primary findings suggest that A-RSU is a viable solution for accommodating all
types of road users regardless of their V2X capabilities.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:03:32 GMT""}]","2023-05-25"
"2305.14810","Jiongnan Liu","Jiongnan Liu, Zhicheng Dou, Guoyu Tang, Sulong Xu","JDsearch: A Personalized Product Search Dataset with Real Queries and
  Full Interactions","Accepted to SIGIR 2023",,,,"cs.IR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, personalized product search attracts great attention and many
models have been proposed. To evaluate the effectiveness of these models,
previous studies mainly utilize the simulated Amazon recommendation dataset,
which contains automatically generated queries and excludes cold users and tail
products. We argue that evaluating with such a dataset may yield unreliable
results and conclusions, and deviate from real user satisfaction. To overcome
these problems, in this paper, we release a personalized product search dataset
comprised of real user queries and diverse user-product interaction types
(clicking, adding to cart, following, and purchasing) collected from JD.com, a
popular Chinese online shopping platform. More specifically, we sample about
170,000 active users on a specific date, then record all their interacted
products and issued queries in one year, without removing any tail users and
products. This finally results in roughly 12,000,000 products, 9,400,000 real
searches, and 26,000,000 user-product interactions. We study the
characteristics of this dataset from various perspectives and evaluate
representative personalization models to verify its feasibility. The dataset
can be publicly accessed at Github: https://github.com/rucliujn/JDsearch.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:06:21 GMT""}]","2023-05-25"
"2305.14811","Magali Hersant","Magali Hersant (CREN)","Doing mathematics in kindergarten: Under what conditions?","in French language","Grand N, Revue de math{\'e}matiques, de sciences et technologie
  pour les ma{\^i}tres de l'enseignement primaire, 2022, 110, pp.4-16",,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we identify the didactic conditions for learning mathematics
in kindergarten. To do so, we rely on the framework of the theory of didactic
situations (Brousseau, 1998) and the notion of problem-situation (Douady,
1984). We first explain what constitutes for us the stakes of teaching
mathematics in kindergarten and then, based on examples, we highlight the
conditions related to the stakes of the pupils' activity, to the
characteristics of the situations proposed to the pupils and to the teacher's
interventions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:08:17 GMT""}]","2023-05-25"
"2305.14812","Hyun-Chul Kim","Samson Clymton and Hyun-Chul Kim","Two-pole structure of the $b_1$(1235) axial-vector meson","10 pages and 6 figures. The version submitted to PRD",,,"INHA-NTG-03/2023","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the dynamical generation of the $b_1$ meson in the $\pi\omega$
interaction, using the fully off-mass-shell coupled-channel formalism with the
$\pi\omega$, $\eta\rho$, $\pi\phi$, and $K\bar{K}^*$ channels included. We
first construct the Feynman amplitudes for the sixteen different kernel
amplitudes, considering only the $t$ and $u$ channels. Solving the coupled
integral equation, we obtain the transition amplitude for the $\pi\omega$
interaction. We select the axial-vector and isovector channels from the
partial-wave expansion and single out the two poles corresponding to the $b_1$
mesons: $(1306-i70)$ MeV and $(1356-i65)$ MeV. They are located below the
$K\bar{K}^*$ threshold. The first pole lies below the $\eta\rho$ threshold by
about 10 MeV, whereas the second one emerges above it by about 40 MeV. We
analyze the effects of the two poles and background contributions to the
$\pi\omega$ total cross section by using a toy model.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:08:29 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 08:16:23 GMT""}]","2023-05-29"
"2305.14813","Yuhang Zang","Yuhang Zang, Kaiyang Zhou, Chen Huang, Chen Change Loy","Semi-Supervised and Long-Tailed Object Detection with CascadeMatch","International Journal of Computer Vision (IJCV), 2023",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper focuses on long-tailed object detection in the semi-supervised
learning setting, which poses realistic challenges, but has rarely been studied
in the literature. We propose a novel pseudo-labeling-based detector called
CascadeMatch. Our detector features a cascade network architecture, which has
multi-stage detection heads with progressive confidence thresholds. To avoid
manually tuning the thresholds, we design a new adaptive pseudo-label mining
mechanism to automatically identify suitable values from data. To mitigate
confirmation bias, where a model is negatively reinforced by incorrect
pseudo-labels produced by itself, each detection head is trained by the
ensemble pseudo-labels of all detection heads. Experiments on two long-tailed
datasets, i.e., LVIS and COCO-LT, demonstrate that CascadeMatch surpasses
existing state-of-the-art semi-supervised approaches -- across a wide range of
detection architectures -- in handling long-tailed object detection. For
instance, CascadeMatch outperforms Unbiased Teacher by 1.9 AP Fix on LVIS when
using a ResNet50-based Cascade R-CNN structure, and by 1.7 AP Fix when using
Sparse R-CNN with a Transformer encoder. We also show that CascadeMatch can
even handle the challenging sparsely annotated object detection problem.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:09:25 GMT""}]","2023-05-25"
"2305.14814","Samuel Vaiter","Nicolas Keriven (CNRS, IRISA), Samuel Vaiter (CNRS, LJAD)","What functions can Graph Neural Networks compute on random graphs? The
  role of Positional Encoding",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We aim to deepen the theoretical understanding of Graph Neural Networks
(GNNs) on large graphs, with a focus on their expressive power. Existing
analyses relate this notion to the graph isomorphism problem, which is mostly
relevant for graphs of small sizes, or studied graph classification or
regression tasks, while prediction tasks on nodes are far more relevant on
large graphs. Recently, several works showed that, on very general random
graphs models, GNNs converge to certains functions as the number of nodes
grows. In this paper, we provide a more complete and intuitive description of
the function space generated by equivariant GNNs for node-tasks, through
general notions of convergence that encompass several previous examples. We
emphasize the role of input node features, and study the impact of node
Positional Encodings (PEs), a recent line of work that has been shown to yield
state-of-the-art results in practice. Through the study of several examples of
PEs on large random graphs, we extend previously known universality results to
significantly more general models. Our theoretical results hint at some
normalization tricks, which is shown numerically to have a positive impact on
GNN generalization on synthetic and real data. Our proofs contain new
concentration inequalities of independent interest.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:09:53 GMT""}]","2023-05-25"
"2305.14815","Dung Thai","Dung Thai, Dhruv Agarwal, Mudit Chaudhary, Rajarshi Das, Manzil
  Zaheer, Jay-Yoon Lee, Hannaneh Hajishirzi, Andrew McCallum","Machine Reading Comprehension using Case-based Reasoning","9 pages, 2 figures",,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  We present an accurate and interpretable method for answer extraction in
machine reading comprehension that is reminiscent of case-based reasoning (CBR)
from classical AI. Our method (CBR-MRC) builds on the hypothesis that
contextualized answers to similar questions share semantic similarities with
each other. Given a target question, CBR-MRC retrieves a set of similar
questions from a memory of observed cases and predicts an answer by selecting
the span in the target context that is most similar to the contextualized
representations of answers in the retrieved cases. The semi-parametric nature
of our approach allows CBR-MRC to attribute a prediction to the specific set of
cases used during inference, making it a desirable choice for building reliable
and debuggable QA systems. We show that CBR-MRC achieves high test accuracy
comparable with large reader models, outperforming baselines by 11.5 and 8.4 EM
on NaturalQuestions and NewsQA, respectively. Further, we also demonstrate the
ability of CBR-MRC in identifying not just the correct answer tokens but also
the span with the most relevant supporting evidence. Lastly, we observe that
contexts for certain question types show higher lexical diversity than others
and find CBR-MRC to be robust to these variations while performance using
fully-parametric methods drops.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:09:56 GMT""}]","2023-05-25"
"2305.14816","Wenhao Zhan","Wenhao Zhan, Masatoshi Uehara, Nathan Kallus, Jason D. Lee, Wen Sun","Provable Offline Reinforcement Learning with Human Feedback",,,,,"cs.LG math.ST stat.ML stat.TH","http://creativecommons.org/publicdomain/zero/1.0/","  In this paper, we investigate the problem of offline reinforcement learning
with human feedback where feedback is available in the form of preference
between trajectory pairs rather than explicit rewards. Our proposed algorithm
consists of two main steps: (1) estimate the implicit reward using Maximum
Likelihood Estimation (MLE) with general function approximation from offline
data and (2) solve a distributionally robust planning problem over a confidence
set around the MLE. We consider the general reward setting where the reward can
be defined over the whole trajectory and provide a novel guarantee that allows
us to learn any target policy with a polynomial number of samples, as long as
the target policy is covered by the offline data. This guarantee is the first
of its kind with general function approximation. To measure the coverage of the
target policy, we introduce a new single-policy concentrability coefficient,
which can be upper bounded by the per-trajectory concentrability coefficient.
We also establish lower bounds that highlight the necessity of such
concentrability and the difference from standard RL, where state-action-wise
rewards are directly observed. We further extend and analyze our algorithm when
the feedback is given over action pairs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:11:26 GMT""}]","2023-05-25"
"2305.14817","Subhadeep Gupta","Jun Hui See Toh, Mengxin Du, Xinxin Tang, Ying Su, Tristan Rojo,
  Carson O. Patterson, Nicolas R. Williams, Chuanwei Zhang and Subhadeep Gupta","Evidence for a Many-Body Anderson Metal-Insulator Transition using
  Kicked Quantum Gases","15 pages, 11 figures, 2 tables, including supplementary materials",,,,"cond-mat.quant-gas physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding the interplay of interactions and disorder in quantum transport
poses long-standing fundamental challenges for theory and experiment. Despite
remarkable advances using ultracold atomic platforms combining atomic
interactions with spatially disordered lattices, many-body effects on quantum
transport phenomena in high-dimensional disordered systems, such as the
three-dimensional (d = 3) Anderson metal-insulator transition (MIT), have
largely remained unexplored. Here we utilize a momentum space lattice platform
using quasi-periodically kicked ultracold atomic gases as a quantum simulator
to experimentally investigate the role of many-body interactions in the d = 3
Anderson MIT. We observe interaction-driven sub-diffusive delocalization and
find a divergence of the delocalization onset time as kick strength approaches
the many-body phase boundary. By modifying the kick quasi-periodicity, we
demonstrate interaction-driven sub-diffusion in d = 2 and d = 4. Our numerical
simulations using a mean-field treatment exhibit an interaction-induced shift
of the d = 3 transition boundary and many-body delocalization dynamics, that
are both in qualitative agreement with experimental observations. However,
there are significant quantitative deviations between experiment and mean-field
theory which increase with higher interaction strengths, calling for further
study of the underlying many-body physics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:12:11 GMT""}]","2023-05-25"
"2305.14818","Raunak Shah","Koyel Mukherjee, Raunak Shah, Shiv Kumar Saini, Karanpreet Singh,
  Khushi, Harsh Kesarwani, Kavya Barnwal, Ayush Chauhan","Towards Optimizing Storage Costs on the Cloud","The first two authors contributed equally. 12 pages, Accepted to the
  International Conference on Data Engineering (ICDE) 2023",,,,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of optimizing data storage and access costs on the cloud
while ensuring that the desired performance or latency is unaffected. We first
propose an optimizer that optimizes the data placement tier (on the cloud) and
the choice of compression schemes to apply, for given data partitions with
temporal access predictions. Secondly, we propose a model to learn the
compression performance of multiple algorithms across data partitions in
different formats to generate compression performance predictions on the fly,
as inputs to the optimizer. Thirdly, we propose to approach the data
partitioning problem fundamentally differently than the current default in most
data lakes where partitioning is in the form of ingestion batches. We propose
access pattern aware data partitioning and formulate an optimization problem
that optimizes the size and reading costs of partitions subject to access
patterns.
  We study the various optimization problems theoretically as well as
empirically, and provide theoretical bounds as well as hardness results. We
propose a unified pipeline of cost minimization, called SCOPe that combines the
different modules. We extensively compare the performance of our methods with
related baselines from the literature on TPC-H data as well as enterprise
datasets (ranging from GB to PB in volume) and show that SCOPe substantially
improves over the baselines. We show significant cost savings compared to
platform baselines, of the order of 50% to 83% on enterprise Data Lake datasets
that range from terabytes to petabytes in volume.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:12:25 GMT""}]","2023-05-25"
"2305.14819","gong chen","Chen Gong (LJLL), Yvon Maday (LJLL, IUF)","Directed Message Passing Based on Attention for Prediction of Molecular
  Properties","Computational Materials Science, In press",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Molecular representation learning (MRL) has long been crucial in the fields
of drug discovery and materials science, and it has made significant progress
due to the development of natural language processing (NLP) and graph neural
networks (GNNs). NLP treats the molecules as one dimensional sequential tokens
while GNNs treat them as two dimensional topology graphs. Based on different
message passing algorithms, GNNs have various performance on detecting chemical
environments and predicting molecular properties. Herein, we propose Directed
Graph Attention Networks (D-GATs): the expressive GNNs with directed bonds. The
key to the success of our strategy is to treat the molecular graph as directed
graph and update the bond states and atom states by scaled dot-product
attention mechanism. This allows the model to better capture the sub-structure
of molecular graph, i.e., functional groups. Compared to other GNNs or Message
Passing Neural Networks (MPNNs), D-GATs outperform the state-of-the-art on 13
out of 15 important molecular property prediction benchmarks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:13:30 GMT""}]","2023-05-25"
"2305.14820","Kailiang Wu","Shengrong Ding, Kailiang Wu","A new discretely divergence-free positivity-preserving high-order finite
  volume method for ideal MHD equations","26 pages",,,,"math.NA astro-ph.IM cs.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes and analyzes a novel efficient high-order finite volume
method for the ideal magnetohydrodynamics (MHD). As a distinctive feature, the
method simultaneously preserves a discretely divergence-free (DDF) constraint
on the magnetic field and the positivity-preserving (PP) property, which
ensures the positivity of density, pressure, and internal energy. To enforce
the DDF condition, we design a new discrete projection approach that projects
the reconstructed point values at the cell interface into a DDF space, without
using any approximation polynomials. This projection method is highly
efficient, easy to implement, and particularly suitable for standard high-order
finite volume WENO methods, which typically return only the point values in the
reconstruction. Moreover, we also develop a new finite volume framework for
constructing provably PP schemes for the ideal MHD system. The framework
comprises the discrete projection technique, a suitable approximation to the
Godunov--Powell source terms, and a simple PP limiter. We provide rigorous
analysis of the PP property of the proposed finite volume method, demonstrating
that the DDF condition and the proper approximation to the source terms
eliminate the impact of magnetic divergence terms on the PP property. The
analysis is challenging due to the internal energy function's nonlinearity and
the intricate relationship between the DDF and PP properties. To address these
challenges, the recently developed geometric quasilinearization approach is
adopted, which transforms a nonlinear constraint into a family of linear
constraints. Finally, we validate the effectiveness of the proposed method
through several benchmark and demanding numerical examples. The results
demonstrate that the proposed method is robust, accurate, and highly effective,
confirming the significance of the proposed DDF projection and PP techniques.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:18:29 GMT""}]","2023-05-25"
"2305.14821","Attila Szolnoki","Attila Szolnoki and Xiaojie Chen","Emerging solutions from the battle of defensive alliances","11 pages, 8 figures, accepted for publication in Scientific Reports",,,,"physics.soc-ph cond-mat.stat-mech cs.GT q-bio.PE","http://creativecommons.org/licenses/by/4.0/","  Competing strategies in an evolutionary game model, or species in a
biosystem, can easily form a larger unit which protects them from the invasion
of an external actor. Such a defensive alliance may have two, three, four or
even more members. But how effective can be such formation against an
alternative group composed by other competitors? To address this question we
study a minimal model where a two-member and a four-member alliances fight in a
symmetric and balanced way. By presenting representative phase diagrams, we
systematically explore the whole parameter range which characterizes the inner
dynamics of the alliances and the intensity of their interactions. The group
formed by a pair, who can exchange their neighboring positions, prevail in the
majority of the parameter region. The rival quartet can only win if their inner
cyclic invasion rate is significant while the mixing rate of the pair is
extremely low. At specific parameter values, when neither of the alliances is
strong enough, new four-member solutions emerge where a
rock-paper-scissors-like trio is extended by the other member of the pair.
These new solutions coexist hence all six competitors can survive. The
evolutionary process is accompanied by serious finite-size effects which can be
mitigated by appropriately chosen prepared initial states.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:21:30 GMT""}]","2023-05-25"
"2305.14822","Roi Livni","Niva Elkin-Koren and Uri Hacohen and Roi Livni and Shay Moran","Can Copyright be Reduced to Privacy?",,,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by-sa/4.0/","  There is an increasing concern that generative AI models may produce outputs
that are remarkably similar to the copyrighted input content on which they are
trained. This worry has escalated as the quality and complexity of generative
models have immensely improved, and the availability of large datasets
containing copyrighted material has increased. Researchers are actively
exploring strategies to mitigate the risk of producing infringing samples, and
a recent line of work suggests to employ techniques such as differential
privacy and other forms of algorithmic stability to safeguard copyrighted
content.
  In this work, we examine the question whether algorithmic stability
techniques such as differential privacy are suitable to ensure the responsible
use of generative models without inadvertently violating copyright laws. We
argue that there are fundamental differences between privacy and copyright that
should not be overlooked. In particular we highlight that although algorithmic
stability may be perceived as a practical tool to detect copying, it does not
necessarily equate to copyright protection. Therefore, if it is adopted as
standard for copyright infringement, it may undermine copyright law intended
purposes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:22:41 GMT""}]","2023-05-25"
"2305.14823","Ian Roberts","Ian D. Roberts and Toby Brown and Nikki Zabel and Christine D. Wilson
  and Aeree Chung and Laura C. Parker and Dhruv Bisaria and Alessandro Boselli
  and Barbara Catinella and Ryan Chown and Luca Cortese and Timothy A. Davis
  and Sara Ellison and Maria Jesus Jimenez-Donaire and Bumhyun Lee and Rory
  Smith and Kristine Spekkens and Adam R.H. Stevens and Mallory Thorp and
  Vincente Villanueva and Adam B. Watts and Charlotte Welker and Hyein Yoon","VERTICO VI: Cold-gas asymmetries in Virgo cluster galaxies","15 pages, 8 figures, 1 table, accepted for publication in A&A",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze cold-gas distributions in Virgo cluster galaxies using resolved
CO(2-1) (tracing molecular hydrogen, H2) and HI observations from the Virgo
Environment Traced In CO (VERTICO) and the VLA Imaging of Virgo in Atomic Gas
(VIVA) surveys. From a theoretical perspective, it is expected that
environmental processes in clusters will have a stronger influence on diffuse
atomic gas compared to the relatively dense molecular gas component, and that
these environmental perturbations can compress the cold interstellar medium in
cluster galaxies leading to elevated star formation. In this work we
observationally test these predictions for star-forming satellite galaxies
within the Virgo cluster. We divide our Virgo galaxy sample into HI-normal,
HI-tailed, and HI-truncated classes and show, unsurprisingly, that the
HI-tailed galaxies have the largest quantitative HI asymmetries. We also
compare to a control sample of non-cluster galaxies and find that Virgo
galaxies, on average, have HI asymmetries that are 40 +/- 10 per cent larger
than the control. There is less separation between control, HI-normal,
HI-tailed, and HI-truncated galaxies in terms of H2 asymmetries, and on
average, Virgo galaxies have H2 asymmetries that are only marginally (20 +/- 10
per cent) larger than the control sample. We find a weak correlation between HI
and H2 asymmetries over our entire sample, but a stronger correlation for those
specific galaxies being strongly impacted by environmental perturbations.
Finally, we divide the discs of the HI-tailed Virgo galaxies into a leading
half and trailing half according to the observed tail direction. We find
evidence for excess molecular gas mass on the leading halves of the disc. This
excess molecular gas on the leading half is accompanied by an excess in star
formation rate such that the depletion time is, on average, unchanged.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:27:21 GMT""}]","2023-05-25"
"2305.14824","Michael J.Q. Zhang","Michael J.Q. Zhang and Eunsol Choi","Mitigating Temporal Misalignment by Discarding Outdated Facts",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  While large language models are able to retain vast amounts of world
knowledge seen during pretraining, such knowledge is prone to going out of date
and is nontrivial to update. Furthermore, these models are often used under
temporal misalignment, tasked with answering questions about the present,
despite having only been trained on data collected in the past. To mitigate the
effects of temporal misalignment, we propose fact duration prediction: the task
of predicting how long a given fact will remain true. In our experiments, we
demonstrate how identifying facts that are prone to rapid change can help
models avoid from reciting outdated information and identify which predictions
require seeking out up-to-date knowledge sources. We also show how modeling
fact duration improves calibration for knowledge-intensive tasks, such as
open-retrieval question answering, under temporal misalignment by discarding
volatile facts. Our data and code will be released publicly at
https://github.com/mikejqzhang/mitigating_misalignment.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:30:08 GMT""}]","2023-05-25"
"2305.14825","Xiaojuan Tang","Xiaojuan Tang, Zilong Zheng, Jiaqi Li, Fanxu Meng, Song-Chun Zhu,
  Yitao Liang, Muhan Zhang","Large Language Models are In-Context Semantic Reasoners rather than
  Symbolic Reasoners",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  The emergent few-shot reasoning capabilities of Large Language Models (LLMs)
have excited the natural language and machine learning community over recent
years. Despite of numerous successful applications, the underlying mechanism of
such in-context capabilities still remains unclear. In this work, we
hypothesize that the learned \textit{semantics} of language tokens do the most
heavy lifting during the reasoning process. Different from human's symbolic
reasoning process, the semantic representations of LLMs could create strong
connections among tokens, thus composing a superficial logical chain. To test
our hypothesis, we decouple semantics from the language reasoning process and
evaluate three kinds of reasoning abilities, i.e., deduction, induction and
abduction. Our findings reveal that semantics play a vital role in LLMs'
in-context reasoning -- LLMs perform significantly better when semantics are
consistent with commonsense but struggle to solve symbolic or
counter-commonsense reasoning tasks by leveraging in-context new knowledge. The
surprising observations question whether modern LLMs have mastered the
inductive, deductive and abductive reasoning abilities as in human
intelligence, and motivate research on unveiling the magic existing within the
black-box LLMs. On the whole, our analysis provides a novel perspective on the
role of semantics in developing and evaluating language models' reasoning
abilities. Code is available at {\url{https://github.com/XiaojuanTang/ICSR}}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:33:34 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 16:38:51 GMT""}]","2023-06-09"
"2305.14826","Xuhong Wang","Xuhong Wang, Ding Wang, Liang Chen and Yilun Lin","Building Transportation Foundation Model via Generative Graph
  Transformer",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Efficient traffic management is crucial for maintaining urban mobility,
especially in densely populated areas where congestion, accidents, and delays
can lead to frustrating and expensive commutes. However, existing prediction
methods face challenges in terms of optimizing a single objective and
understanding the complex composition of the transportation system. Moreover,
they lack the ability to understand the macroscopic system and cannot
efficiently utilize big data. In this paper, we propose a novel approach,
Transportation Foundation Model (TFM), which integrates the principles of
traffic simulation into traffic prediction. TFM uses graph structures and
dynamic graph generation algorithms to capture the participatory behavior and
interaction of transportation system actors. This data-driven and model-free
simulation method addresses the challenges faced by traditional systems in
terms of structural complexity and model accuracy and provides a foundation for
solving complex transportation problems with real data. The proposed approach
shows promising results in accurately predicting traffic outcomes in an urban
transportation setting.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:34:15 GMT""}]","2023-05-25"
"2305.14827","Mujeen Sung","Mujeen Sung, James Gung, Elman Mansimov, Nikolaos Pappas, Raphael Shu,
  Salvatore Romeo, Yi Zhang, Vittorio Castelli","Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent
  Classification",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intent classification (IC) plays an important role in task-oriented dialogue
systems as it identifies user intents from given utterances. However, models
trained on limited annotations for IC often suffer from a lack of
generalization to unseen intent classes. We propose a novel pre-training method
for text encoders that uses contrastive learning with intent psuedo-labels to
produce embeddings that are well-suited for IC tasks. By applying this
pre-training strategy, we also introduce the pre-trained intent-aware encoder
(PIE). Specifically, we first train a tagger to identify key phrases within
utterances that are crucial for interpreting intents. We then use these
extracted phrases to create examples for pre-training a text encoder in a
contrastive manner. As a result, our PIE model achieves up to 5.4% and 4.0%
higher accuracy than the previous state-of-the-art pre-trained sentence encoder
for the N-way zero- and one-shot settings on four IC datasets.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:34:32 GMT""}]","2023-05-25"
"2305.14828","Prashant Krishnan","Prashant Krishnan, Zilong Wang, Yangkun Wang and Jingbo Shang","Towards Few-shot Entity Recognition in Document Images: A Graph Neural
  Network Approach Robust to Image Manipulation",,,,,"cs.CL cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Recent advances of incorporating layout information, typically bounding box
coordinates, into pre-trained language models have achieved significant
performance in entity recognition from document images. Using coordinates can
easily model the absolute position of each token, but they might be sensitive
to manipulations in document images (e.g., shifting, rotation or scaling),
especially when the training data is limited in few-shot settings. In this
paper, we propose to further introduce the topological adjacency relationship
among the tokens, emphasizing their relative position information.
Specifically, we consider the tokens in the documents as nodes and formulate
the edges based on the topological heuristics from the k-nearest bounding
boxes. Such adjacency graphs are invariant to affine transformations including
shifting, rotations and scaling. We incorporate these graphs into the
pre-trained language model by adding graph neural network layers on top of the
language model embeddings, leading to a novel model LAGER. Extensive
experiments on two benchmark datasets show that LAGER significantly outperforms
strong baselines under different few-shot settings and also demonstrate better
robustness to manipulations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:34:33 GMT""}]","2023-05-25"
"2305.14829","Jonathan Kua","Shiva Raj Pokhrel, Jonathan Kua, Deol Satish, Phil Williams, Arkady
  Zaslavsky, Seng W. Loke, Jinho Choi","On Correlated Knowledge Distillation for Monitoring Human Pose with
  Radios",,,,,"cs.CV eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we propose and develop a simple experimental testbed to study
the feasibility of a novel idea by coupling radio frequency (RF) sensing
technology with Correlated Knowledge Distillation (CKD) theory towards
designing lightweight, near real-time and precise human pose monitoring
systems. The proposed CKD framework transfers and fuses pose knowledge from a
robust ""Teacher"" model to a parameterized ""Student"" model, which can be a
promising technique for obtaining accurate yet lightweight pose estimates. To
assure its efficacy, we implemented CKD for distilling logits in our integrated
Software Defined Radio (SDR)-based experimental setup and investigated the
RF-visual signal correlation. Our CKD-RF sensing technique is characterized by
two modes -- a camera-fed Teacher Class Network (e.g., images, videos) with an
SDR-fed Student Class Network (e.g., RF signals). Specifically, our CKD model
trains a dual multi-branch teacher and student network by distilling and fusing
knowledge bases. The resulting CKD models are then subsequently used to
identify the multimodal correlation and teach the student branch in reverse.
Instead of simply aggregating their learnings, CKD training comprised multiple
parallel transformations with the two domains, i.e., visual images and RF
signals. Once trained, our CKD model can efficiently preserve privacy and
utilize the multimodal correlated logits from the two different neural networks
for estimating poses without using visual signals/video frames (by using only
the RF signals).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:34:49 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 13:14:05 GMT""}]","2023-05-31"
"2305.14830","Bin Chen","Bin Chen, Weidong Wang, Xia Zhao, Peibiao Zhao","An inverse Gauss curvature flow and its application to p-capacitary
  Orlicz-Minkowski problem",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In [Calc. Var., 57:5 (2018)], Hong-Ye-Zhang proposed the $p$-capacitary
Orlicz-Minkowski problem and proved the existence of convex solutions to this
problem by variational method for $p\in(1,n)$.
  However, the smoothness and uniqueness of solutions are still open.
  Notice that the $p$-capacitary Orlicz-Minkowski problem can be converted
equivalently to a Monge-Amp\`{e}re type equation in smooth case:
  \begin{align}\label{0.1}
  f\phi(h_K)|\nabla\Psi|^p=\tau G
  \end{align}
  for $p\in(1,n)$ and some constant $\tau>0$, where $f$ is a positive function
defined on the unit sphere $\mathcal{S}^{n-1}$, $\phi$ is a continuous positive
function defined in $(0,+\infty)$, and $G$ is the Gauss curvature.
  In this paper, we confirm the existence of smooth solutions to $p$-capacitary
Orlicz-Minkowski problem with $p\in(1,n)$ for the first time by a class of
inverse Gauss curvature flows, which converges smoothly to the solution of
Equation (\ref{0.1}).
  Furthermore, we prove the uniqueness result for Equation (\ref{0.1}) in a
special case.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:36:23 GMT""}]","2023-05-25"
"2305.14831","Zhiwen Yan","Zhiwen Yan, Chen Li, Gim Hee Lee","OD-NeRF: Efficient Training of On-the-Fly Dynamic Neural Radiance Fields",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic neural radiance fields (dynamic NeRFs) have demonstrated impressive
results in novel view synthesis on 3D dynamic scenes. However, they often
require complete video sequences for training followed by novel view synthesis,
which is similar to playing back the recording of a dynamic 3D scene. In
contrast, we propose OD-NeRF to efficiently train and render dynamic NeRFs
on-the-fly which instead is capable of streaming the dynamic scene. When
training on-the-fly, the training frames become available sequentially and the
model is trained and rendered frame-by-frame. The key challenge of efficient
on-the-fly training is how to utilize the radiance field estimated from the
previous frames effectively. To tackle this challenge, we propose: 1) a NeRF
model conditioned on the multi-view projected colors to implicitly track
correspondence between the current and previous frames, and 2) a transition and
update algorithm that leverages the occupancy grid from the last frame to
sample efficiently at the current frame. Our algorithm can achieve an
interactive speed of 6FPS training and rendering on synthetic dynamic scenes
on-the-fly, and a significant speed-up compared to the state-of-the-art on
real-world dynamic scenes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:36:47 GMT""}]","2023-05-25"
"2305.14832","Karol Capala","Karol Capa{\l}a, Bart{\l}omiej Dybiec","Optimization of escape kinetics by reflecting and resetting","7 pages",,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic restarting is a strategy of starting anew. Incorporation of the
resetting to the random walks can result in the decrease of the mean first
passage time, due to the ability to limit unfavorably meandering, sub-optimal
trajectories. In the following manuscript we examine how stochastic resetting
influences escape dynamics from the $(-\infty,1)$ interval in the presence of
the single-well power-law $|x|^\kappa$ potentials with $\kappa>0$. Examination
of the mean first passage time is complemented by the analysis of the
coefficient of variation, which provides a robust and reliable indicator
assessing efficiency of stochastic resetting. The restrictive nature of
resetting is compared to placing a reflective boundary in the system at hand.
In particular, for each potential, the position of the reflecting barrier
giving the same mean first passage time as the optimal resetting rate is
determined. Finally, in addition to reflecting, we compare effectiveness of
other resetting strategies with respect to optimization of the mean first
passage time.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:38:04 GMT""}]","2023-05-25"
"2305.14833","Jake Shipley","Jake O. Shipley","Stable photon orbits in stationary axisymmetric spacetimes with an
  electromagnetic field and a cosmological constant","6 pages, 1 figure",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stable light rings, which are associated with spacetime instabilities, are
known to exist in four-dimensional stationary axisymmetric spacetimes that
solve the Einstein$\unicode{x2013}$Maxwell equations (so-called electrovacuum
solutions, with Faraday tensor $F_{\mu \nu} \neq 0$); however, they are not
permitted in pure vacuum ($F_{\mu \nu} = 0$). In this work, we extend this
result to spacetimes with a non-zero cosmological constant $\Lambda$. In
particular, we demonstrate that stable light rings are permitted in
$\Lambda$-electrovacuum ($F_{\mu \nu} \neq 0$, $\Lambda \neq 0$), but ruled out
in $\Lambda$-vacuum ($F_{\mu \nu} = 0$, $\Lambda \neq 0$).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:38:08 GMT""}]","2023-05-25"
"2305.14834","Jeremy Smallwood","Jeremy L. Smallwood","Formation of the warped debris disc around $\beta$ Pictoris","10 pages, 8 figures, accepted for publication in MNRAS",,"10.1093/mnras/stad1586",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In light of the recent confirmation of an eccentric orbit giant planet,
$\beta$ Pic c, I revisit the formation and evolution of the warped debris disc
in the system. $\beta$ Pic c is interior to $\beta$ Pic b, and the debris disc
is exterior to both planets. Previous $N$-body simulations have shown that
$\beta$ Pic b is responsible for exciting the inclination of the debris disc.
With hydrodynamical simulations, I model a protoplanetary gas disc misaligned
with the planets. I find that the gas disc does not exhibit significant long
lasting inclination excitation from the planets even for the observed disc
size. The warp that is excited by the planets propagates through the entire
disc with a timescale much less than the gas disc lifetime. Therefore, the
observed warp in the debris disc must be produced after the gas disc has
dispersed. With analytical secular theory calculations, I show that two secular
resonances are exterior to $\beta$ Pic b, located at $\sim 20\, \rm au$ and
$\sim 25\, \rm au$. This agrees with my $N$-body simulations that show that
these secular resonances shape the inner edge of the $\beta$ Pic debris disc at
a radius that agrees with observations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:38:17 GMT""}]","2023-05-31"
"2305.14835","Haopeng Zhang","Haopeng Zhang, Xiao Liu, Jiawei Zhang","SummIt: Iterative Text Summarization via ChatGPT","work in progress",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing text summarization systems have made significant progress in recent
years but typically generates summaries in a single step. The one-shot
summarization setting is sometimes inadequate, however, as the generated
summary may contain hallucinations or overlook important details related to the
reader's interests. In this paper, we address this limitation by proposing
SummIt, an iterative text summarization framework based on large language
models like ChatGPT. Our framework enables the model to refine the generated
summary iteratively through self-evaluation and feedback, closely resembling
the iterative process humans undertake when drafting and revising summaries. We
also explore using in-context learning to guide the rationale generation and
summary refinement. Furthermore, we explore the potential benefits of
integrating knowledge and topic extractors into the framework to enhance
summary faithfulness and controllability. We evaluate the performance of our
framework on three benchmark summarization datasets through empirical and
qualitative analyses. We also conduct a human evaluation to validate the
effectiveness of the model's refinements and find a potential issue of
over-correction. Our code is available at
\url{https://github.com/hpzhang94/summ_it}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:40:06 GMT""}]","2023-05-25"
"2305.14836","Tianwen Qian","Tianwen Qian, Jingjing Chen, Linhai Zhuo, Yang Jiao, Yu-Gang Jiang","NuScenes-QA: A Multi-modal Visual Question Answering Benchmark for
  Autonomous Driving Scenario",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a novel visual question answering (VQA) task in the context of
autonomous driving, aiming to answer natural language questions based on
street-view clues. Compared to traditional VQA tasks, VQA in autonomous driving
scenario presents more challenges. Firstly, the raw visual data are
multi-modal, including images and point clouds captured by camera and LiDAR,
respectively. Secondly, the data are multi-frame due to the continuous,
real-time acquisition. Thirdly, the outdoor scenes exhibit both moving
foreground and static background. Existing VQA benchmarks fail to adequately
address these complexities. To bridge this gap, we propose NuScenes-QA, the
first benchmark for VQA in the autonomous driving scenario, encompassing 34K
visual scenes and 460K question-answer pairs. Specifically, we leverage
existing 3D detection annotations to generate scene graphs and design question
templates manually. Subsequently, the question-answer pairs are generated
programmatically based on these templates. Comprehensive statistics prove that
our NuScenes-QA is a balanced large-scale benchmark with diverse question
formats. Built upon it, we develop a series of baselines that employ advanced
3D detection and VQA techniques. Our extensive experiments highlight the
challenges posed by this new task. Codes and dataset are available at
https://github.com/qiantianwen/NuScenes-QA.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:40:50 GMT""}]","2023-05-25"
"2305.14837","Stefano Zacchiroli","Yiming Sun (UVIC), Daniel M. German (UVIC), Stefano Zacchiroli (IP
  Paris, LTCI)","Using the Uniqueness of Global Identifiers to Determine the Provenance
  of Python Software Source Code",,"Empirical Software Engineering, In press","10.1007/s10664-023-10317-8",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of identifying the provenance of free/open source
software (FOSS) and specifically the need of identifying where reused source
code has been copied from. We propose a lightweight approach to solve the
problem based on software identifiers-such as the names of variables, classes,
and functions chosen by programmers. The proposed approach is able to
efficiently narrow down to a small set of candidate origin products, to be
further analyzed with more expensive techniques to make a final provenance
determination.By analyzing the PyPI (Python Packaging Index) open source
ecosystem we find that globally defined identifiers are very distinct. Across
PyPI's 244 K packages we found 11.2 M different global identifiers (classes and
method/function names-with only 0.6% of identifiers shared among the two types
of entities); 76% of identifiers were used only in one package, and 93% in at
most 3. Randomly selecting 3 non-frequent global identifiers from an input
product is enough to narrow down its origins to a maximum of 3 products within
89% of the cases.We validate the proposed approach by mapping Debian source
packages implemented in Python to the corresponding PyPI packages; this
approach uses at most five trials, where each trial uses three randomly chosen
global identifiers from a randomly chosen python file of the subject software
package, then ranks results using a popularity index and requires to inspect
only the top result. In our experiments, this method is effective at finding
the true origin of a project with a recall of 0.9 and precision of 0.77.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:42:11 GMT""}]","2023-05-25"
"2305.14838","Chenyang Le","Chenyang Le, Yao Qian, Long Zhou, Shujie Liu, Michael Zeng, Xuedong
  Huang","ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text
  Translation",,,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Joint speech-language training is challenging due to the large demand for
training data and GPU consumption, as well as the modality gap between speech
and language. We present ComSL, a speech-language model built atop a composite
architecture of public pretrained speech-only and language-only models and
optimized data-efficiently for spoken language tasks. Particularly, we propose
to incorporate cross-modality learning into transfer learning and conduct them
simultaneously for downstream tasks in a multi-task learning manner. Our
approach has demonstrated effectiveness in end-to-end speech-to-text
translation tasks, achieving a new state-of-the-art average BLEU score of 31.5
on the multilingual speech to English text translation task for 21 languages,
as measured on the public CoVoST2 evaluation set.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:42:15 GMT""}]","2023-05-25"
"2305.14839","Yunshui Li","Yunshui Li, Binyuan Hui, ZhiChao Yin, Min Yang, Fei Huang and Yongbin
  Li","PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and
  Compositional Experts","ACL 2023",,,,"cs.CL cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Perceiving multi-modal information and fulfilling dialogues with humans is a
long-term goal of artificial intelligence. Pre-training is commonly regarded as
an effective approach for multi-modal dialogue. However, due to the limited
availability of multi-modal dialogue data, there is still scarce research on
multi-modal dialogue pre-training. Yet another intriguing challenge emerges
from the encompassing nature of multi-modal dialogue, which involves various
modalities and tasks. Moreover, new forms of tasks may arise at unpredictable
points in the future. Hence, it is essential for designed multi-modal dialogue
models to possess sufficient flexibility to adapt to such scenarios. This paper
proposes \textbf{PaCE}, a unified, structured, compositional multi-modal
dialogue pre-training framework. It utilizes a combination of several
fundamental experts to accommodate multiple dialogue-related tasks and can be
pre-trained using limited dialogue and extensive non-dialogue multi-modal data.
Furthermore, we propose a progressive training method where old experts from
the past can assist new experts, facilitating the expansion of their
capabilities. Experimental results demonstrate that PaCE achieves
state-of-the-art results on eight multi-modal dialog benchmarks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:43:29 GMT""}]","2023-05-25"
"2305.14840","Hong Wang","Hong Wang, Su Yang, Xiaoke Huang, Weishan Zhang","Predicting Token Impact Towards Efficient Vision Transformer","10 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Token filtering to reduce irrelevant tokens prior to self-attention is a
straightforward way to enable efficient vision Transformer. This is the first
work to view token filtering from a feature selection perspective, where we
weigh the importance of a token according to how much it can change the loss
once masked. If the loss changes greatly after masking a token of interest, it
means that such a token has a significant impact on the final decision and is
thus relevant. Otherwise, the token is less important for the final decision,
so it can be filtered out. After applying the token filtering module
generalized from the whole training data, the token number fed to the
self-attention module can be obviously reduced in the inference phase, leading
to much fewer computations in all the subsequent self-attention layers. The
token filter can be realized using a very simple network, where we utilize
multi-layer perceptron. Except for the uniqueness of performing token filtering
only once from the very beginning prior to self-attention, the other core
feature making our method different from the other token filters lies in the
predictability of token impact from a feature selection point of view. The
experiments show that the proposed method provides an efficient way to approach
a light weighted model after optimized with a backbone by means of fine tune,
which is easy to be deployed in comparison with the existing methods based on
training from scratch.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:44:16 GMT""}]","2023-05-25"
"2305.14841","Abouzar Ghavami","Nima Hassanpour and Abouzar Ghavami","Deep Learning-based Bio-Medical Image Segmentation using UNet
  Architecture and Transfer Learning",,,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image segmentation is a branch of computer vision that is widely used in real
world applications including biomedical image processing. With recent
advancement of deep learning, image segmentation has achieved at a very high
level performance. Recently, UNet architecture is found as the core of novel
deep learning segmentation methods. In this paper we implement UNet
architecture from scratch with using basic blocks in Pytorch and evaluate its
performance on multiple biomedical image datasets. We also use transfer
learning to apply novel modified UNet segmentation packages on the biomedical
image datasets. We fine tune the pre-trained transferred model with each
specific dataset. We compare its performance with our fundamental UNet
implementation. We show that transferred learning model has better performance
in image segmentation than UNet model that is implemented from scratch.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:45:54 GMT""}]","2023-05-25"
"2305.14842","Karthick Prasad Gunasekaran","Karthick Prasad Gunasekaran","Exploring Sentiment Analysis Techniques in Natural Language Processing:
  A Comprehensive Review",,"International Journal of Advanced Research in Computer And
  Communication Engineering Vol. 8, Issue 1, January 2019","10.17148/IJARCCE.2019.8126",,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Sentiment analysis (SA) is the automated process of detecting and
understanding the emotions conveyed through written text. Over the past decade,
SA has gained significant popularity in the field of Natural Language
Processing (NLP). With the widespread use of social media and online platforms,
SA has become crucial for companies to gather customer feedback and shape their
marketing strategies. Additionally, researchers rely on SA to analyze public
sentiment on various topics. In this particular research study, a comprehensive
survey was conducted to explore the latest trends and techniques in SA. The
survey encompassed a wide range of methods, including lexicon-based,
graph-based, network-based, machine learning, deep learning, ensemble-based,
rule-based, and hybrid techniques. The paper also addresses the challenges and
opportunities in SA, such as dealing with sarcasm and irony, analyzing
multi-lingual data, and addressing ethical concerns. To provide a practical
case study, Twitter was chosen as one of the largest online social media
platforms. Furthermore, the researchers shed light on the diverse application
areas of SA, including social media, healthcare, marketing, finance, and
politics. The paper also presents a comparative and comprehensive analysis of
existing trends and techniques, datasets, and evaluation metrics. The ultimate
goal is to offer researchers and practitioners a systematic review of SA
techniques, identify existing gaps, and suggest possible improvements. This
study aims to enhance the efficiency and accuracy of SA processes, leading to
smoother and error-free outcomes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:48:41 GMT""}]","2023-05-25"
"2305.14843","Hanxu Hu","Hanxu Hu, Frank Keller","Meta-Learning For Vision-and-Language Cross-lingual Transfer",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Current pre-trained vison-language models (PVLMs) achieve excellent
performance on a range of multi-modal datasets. Recent work has aimed at
building multilingual models, and a range of novel multilingual multi-modal
datasets have been proposed. Current PVLMs typically perform poorly on these
datasets when used for multi-modal zero-shot or few-shot cross-lingual
transfer, especially for low-resource languages. To alleviate this problem, we
propose a novel meta-learning fine-tuning framework. Our framework makes
current PVLMs rapidly adaptive to new languages in vision-language scenarios by
designing MAML in a cross-lingual multi-modal manner. Experiments show that our
method boosts the performance of current state-of-the-art PVLMs in both
zero-shot and few-shot cross-lingual transfer on a range of vision-language
understanding tasks and datasets (XVNLI, xGQA, MaRVL, xFlicker&Co
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:51:42 GMT""}]","2023-05-25"
"2305.14844","Bruno Ebner","Bruno Ebner and Norbert Henze and Simos Meintanis","A unified approach to goodness-of-fit testing for spherical and
  hyperspherical data","29 pages, 2 figures, 6 tables",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We propose a general and relatively simple method for the construction of
goodness-of-fit tests on the sphere and the hypersphere. The method is based on
the characterization of probability distributions via their characteristic
function, and it leads to test criteria that are convenient regarding
applications and consistent against arbitrary deviations from the model under
test. We emphasize goodness-of-fit tests for spherical distributions due to
their importance in applications and the relative scarcity of available
methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:53:52 GMT""}]","2023-05-25"
"2305.14845","Tiberiu Harko","Tiberiu Harko","Dissipative quintessence, and its cosmological implications","23 pages, 8 figures, accepted for publication in PRD",,,,"gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a generalization of the quintessence type scalar field
cosmological models, by adding a multiplicative dissipative term in the scalar
field Lagrangian, which is represented in an exponential form. The generalized
dissipative Klein-Gordon equation is obtained from the variational principle in
a covariant form. The energy-momentum tensor of the dissipative scalar field is
also obtained from the dissipative Lagrangian. The generalized Friedmann
equations in the presence of the dissipative scalar field are obtained for a
specific form of dissipation, with the dissipation exponent represented as the
time integral of the product of the Hubble function, and of a function
describing the dissipative properties of the scalar field. Several cosmological
models, corresponding to different choices of the dissipation function, and of
the scalar field potential, are considered in detail. The evolutions of the
basic cosmological parameters (Hubble function, deceleration parameter etc.)
are investigated by using both analytical and numerical techniques. A
comparison with the observational data for the Hubble function, and with the
predictions of the standard $\Lambda$CDM paradigm is also presented for each
dissipative scalar field model. In the large time limit the model describes an
accelerating Universe, with the effective negative pressure induced by the
dissipative effects associated to the scalar field. Accelerated expansion in
the absence of the scalar field potential is also possible, with the kinetic
term dominating the expansionary evolution. The dissipative scalar field models
describe well the observational data, with the free parameters of the model
obtained by a trial and error method. The obtained results show that the
dissipative scalar field model offers an effective dynamical possibility for
explaining the recent cosmological observational data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:54:24 GMT""}]","2023-05-25"
"2305.14846","Junyoung Byun","Junyoung Byun, Myung-Joon Kwon, Seungju Cho, Yoonji Kim, Changick Kim","Introducing Competition to Boost the Transferability of Targeted
  Adversarial Examples through Clean Feature Mixup","CVPR 2023 camera-ready",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks are widely known to be susceptible to adversarial
examples, which can cause incorrect predictions through subtle input
modifications. These adversarial examples tend to be transferable between
models, but targeted attacks still have lower attack success rates due to
significant variations in decision boundaries. To enhance the transferability
of targeted adversarial examples, we propose introducing competition into the
optimization process. Our idea is to craft adversarial perturbations in the
presence of two new types of competitor noises: adversarial perturbations
towards different target classes and friendly perturbations towards the correct
class. With these competitors, even if an adversarial example deceives a
network to extract specific features leading to the target class, this
disturbance can be suppressed by other competitors. Therefore, within this
competition, adversarial examples should take different attack strategies by
leveraging more diverse features to overwhelm their interference, leading to
improving their transferability to different models. Considering the
computational complexity, we efficiently simulate various interference from
these two types of competitors in feature space by randomly mixing up stored
clean features in the model inference and named this method Clean Feature Mixup
(CFM). Our extensive experimental results on the ImageNet-Compatible and
CIFAR-10 datasets show that the proposed method outperforms the existing
baselines with a clear margin. Our code is available at
https://github.com/dreamflake/CFM.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:54:44 GMT""}]","2023-05-25"
"2305.14847","Anisha Gunjal","Anisha Gunjal, Greg Durrett","Drafting Event Schemas using Language Models",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Past work has studied event prediction and event language modeling, sometimes
mediated through structured representations of knowledge in the form of event
schemas. Such schemas can lead to explainable predictions and forecasting of
unseen events given incomplete information. In this work, we look at the
process of creating such schemas to describe complex events. We use large
language models (LLMs) to draft schemas directly in natural language, which can
be further refined by human curators as necessary. Our focus is on whether we
can achieve sufficient diversity and recall of key events and whether we can
produce the schemas in a sufficiently descriptive style. We show that large
language models are able to achieve moderate recall against schemas taken from
two different datasets, with even better results when multiple prompts and
multiple samples are combined. Moreover, we show that textual entailment
methods can be used for both matching schemas to instances of events as well as
evaluating overlap between gold and predicted schemas. Our method paves the way
for easier distillation of event knowledge from large language model into
schemas.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:57:04 GMT""}]","2023-05-25"
"2305.14848","Moritz Schick","Mareike Dressler and Salma Kuhlmann and Moritz Schick","Geometrical Study of the Cone of Sums of Squares plus Sums of
  Nonnegative Circuits",,,,,"math.AG math.CO math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we combine sums of squares (SOS) and sums of nonnegative
circuit (SONC) forms, two independent nonnegativity certificates for real
homogeneous polynomials. We consider the convex cone SOS+SONC of forms that
decompose into a sum of an SOS and a SONC form and study it from a geometric
point of view. We show that the SOS+SONC cone is proper and neither closed
under multiplications nor under linear transformation of variables. Moreover,
we present an alternative proof of an analog of Hilbert's 1888 Theorem for the
SOS+SONC cone and prove that in the non-Hilbert cases it provides a proper
superset of both the SOS and the SONC cone. This follows by exploiting a new
necessary condition for membership in the SONC cone.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:59:18 GMT""}]","2023-05-25"
"2305.14849","Taesun Yeom","Taesun Yeom, Minhyeok Lee","DuDGAN: Improving Class-Conditional GANs via Dual-Diffusion","8 page, 3 figures, supplementary material included",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Class-conditional image generation using generative adversarial networks
(GANs) has been investigated through various techniques; however, it continues
to face challenges such as mode collapse, training instability, and low-quality
output in cases of datasets with high intra-class variation. Furthermore, most
GANs often converge in larger iterations, resulting in poor iteration efficacy
in training procedures. While Diffusion-GAN has shown potential in generating
realistic samples, it has a critical limitation in generating class-conditional
samples. To overcome these limitations, we propose a novel approach for
class-conditional image generation using GANs called DuDGAN, which incorporates
a dual diffusion-based noise injection process. Our method consists of three
unique networks: a discriminator, a generator, and a classifier. During the
training process, Gaussian-mixture noises are injected into the two noise-aware
networks, the discriminator and the classifier, in distinct ways. This noisy
data helps to prevent overfitting by gradually introducing more challenging
tasks, leading to improved model performance. As a result, our method
outperforms state-of-the-art conditional GAN models for image generation in
terms of performance. We evaluated our method using the AFHQ, Food-101, and
CIFAR-10 datasets and observed superior results across metrics such as FID,
KID, Precision, and Recall score compared with comparison models, highlighting
the effectiveness of our approach.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:59:44 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 06:35:25 GMT""}]","2023-06-07"
"2305.14850","Yan Rybalko","Kenneth Karlsen and Yan Rybalko","On the well-posedness of a nonlocal (two-place) FORQ equation via a
  two-component peakon system",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the Cauchy problem for a nonlocal (two-place) FORQ equation.
By interpreting this equation as a special case of a two-component peakon
system (exhibiting a cubic nonlinearity), we convert the Cauchy problem into a
system of ordinary differential equations in a Banach space. Using this
approach, we are able to demonstrate local well-posedness in the Sobolev space
$H^{s}$ where $s > 5/2$. We also establish the continuity properties for the
data-to-solution map for a range of Sobolev spaces. Finally, we briefly explore
the relationship between the two-component system and the bi-Hamiltonian AKNS
hierarchy.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:00:12 GMT""}]","2023-05-25"
"2305.14851","Pengfei He","Pengfei He, Han Xu, Jie Ren, Yingqian Cui, Hui Liu, Charu C. Aggarwal,
  Jiliang Tang","Sharpness-Aware Data Poisoning Attack",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Recent research has highlighted the vulnerability of Deep Neural Networks
(DNNs) against data poisoning attacks. These attacks aim to inject poisoning
samples into the models' training dataset such that the trained models have
inference failures. While previous studies have executed different types of
attacks, one major challenge that greatly limits their effectiveness is the
uncertainty of the re-training process after the injection of poisoning
samples, including the re-training initialization or algorithms. To address
this challenge, we propose a novel attack method called ''Sharpness-Aware Data
Poisoning Attack (SAPA)''. In particular, it leverages the concept of DNNs'
loss landscape sharpness to optimize the poisoning effect on the worst
re-trained model. It helps enhance the preservation of the poisoning effect,
regardless of the specific retraining procedure employed. Extensive experiments
demonstrate that SAPA offers a general and principled strategy that
significantly enhances various types of poisoning attacks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:00:21 GMT""}]","2023-05-25"
"2305.14852","Moonseok Choi","Moonseok Choi, Hyungi Lee, Giung Nam, Juho Lee","SWAMP: Sparse Weight Averaging with Multiple Particles for Iterative
  Magnitude Pruning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given the ever-increasing size of modern neural networks, the significance of
sparse architectures has surged due to their accelerated inference speeds and
minimal memory demands. When it comes to global pruning techniques, Iterative
Magnitude Pruning (IMP) still stands as a state-of-the-art algorithm despite
its simple nature, particularly in extremely sparse regimes. In light of the
recent finding that the two successive matching IMP solutions are linearly
connected without a loss barrier, we propose Sparse Weight Averaging with
Multiple Particles (SWAMP), a straightforward modification of IMP that achieves
performance comparable to an ensemble of two IMP solutions. For every
iteration, we concurrently train multiple sparse models, referred to as
particles, using different batch orders yet the same matching ticket, and then
weight average such models to produce a single mask. We demonstrate that our
method consistently outperforms existing baselines across different sparsities
through extensive experiments on various data and neural network structures.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:01:49 GMT""}]","2023-05-25"
"2305.14853","Chunjing  Xie","Kaijian Sha, Yun Wang, Chunjing Xie","Uniqueness and uniform structural stability of Poiseuille flows with
  large fluxes in two-dimensional strips","arXiv admin note: substantial text overlap with arXiv:2011.07467",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we prove the uniform nonlinear structural stability of
Poiseuille flows with suitably large flux for the steady Navier-Stokes system
in a two-dimensional strip with arbitrary period. Furthermore, the
well-posedness theory for the Navier-Stokes system is also proved even when the
$L^2$-norm of the external force is large. In particular, if the vertical
velocity is suitably small where the smallness is independent of the flux, then
Poiseuille flow is the unique solution of the steady Navier-Stokes system in
the periodic strip. The key point is to establish uniform a priori estimates
for the corresponding linearized problem via the boundary layer analysis, where
we explore the particular features of odd and even stream functions. The
analysis for the even stream function is new, which not only generalizes the
previous study for the symmetric flows in \cite{Rabier1}, but also provides an
explicit relation between the flux and period.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:03:01 GMT""}]","2023-05-25"
"2305.14854","Zhi-Peng Xing","Zhi-Peng Xing, Xiao-Gang He, Fei Huang, Chang Yang","A global analysis for determined and undetermined hadronic two body weak
  decays of anti-triplet charmed baryons","9pages, 2 figures, 3 tables",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A large amount of data on hadronic two body weak decays of anti-triplet
charmed baryons $T_{c\bar 3}$ to an octet baryon $T_8$ and an octet or singlet
pseudoscalar meson $P$, $T_{c \bar 3} \to T_8 P$, have been measured. The SU(3)
flavor symmetry has been applied to study these decays to obtain insights about
weak interactions for charm physics. However not all such decays needed to
determine the SU(3) irreducible amplitudes have been measured forbidding a
complete global analysis. Previously, it has been shown that data from measured
decays can be used to do a global fit to determine all except one parity
violating and one parity conserving amplitudes of the relevant SU(3)
irreducible amplitudes causing 8 hadronic two body weak decay channels
involving $\Xi^0_c$ to $\eta$ or $\eta'$ transitions undetermined. It is
important to obtain information about these decays in order to guide
experimental searches. In this work using newly measured decay modes by BESIII
and Belle in 2022, we carry out a global analysis and parameterize the unknown
amplitudes to provide the ranges for the branching ratios of the 8 undetermined
decays. Our results indicate that the SU(3) flavor symmetry can explain the
measured data exceptionally well, with a remarkable minimal $\chi^2/d.o.f.$ of
1.21 and predict 80 observables in 45 decays for future experimental data to
test. We then vary the unknown SU(3) amplitudes to obtain the allowed range of
branching ratios for the 8 undetermined decays. We find that some of them are
within reach of near future experimental capabilities. We urge our experimental
colleagues to carry out related searches.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:05:09 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 11:57:06 GMT""}]","2023-06-01"
"2305.14855","Tasneem Saleem","Tasneem Saleem, Salleh Ahmad, Jean-Baptiste Cizel, Christophe De La
  Taille, Maxime Morenas, Vanessa Nadig, Florent Perez, Volkmar Schulz, Stefan
  Gundacker and Julien Fleury","Study experimental time resolution limits of recent ASICs at Weeroc with
  different SiPMs and scintillators","Prepared for submission to JINST",,,,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Medical applications, such as positron emission tomography (PET), and space
application, such as Light Detection and Ranging (LIDAR), are in need for
highly specialized ASICs. Weeroc, in collaboration with different partners, is
highly involved in developing a new generation of front-end ASICs. In the
context of a joined LIDAR project among Weeroc, CNES, and Airbus, Weeroc is
working on the development of Liroc, an ASIC for space LIDAR application.
Weeroc is also working on advancing ASICs for medical applications, hence,
another ASIC, Radioroc, is under development and intended to be used for PET
applications.
  This study experimentally evaluates the time resolution limits of these ASICs
in different configurations, with some of the most recent silicon
photomultipliers (SiPMs) technologies available on the market coupled with
different scintillation crystals. The best single-photon time resolution (SPTR)
was achieved using FBK NUV-HD SiPMs with an FWHM of 79 ps with Liroc and 73 ps
with Radioroc. Furthermore, the best coincidence time resolution (CTR) of
Radioroc was determined to 83 ps (FWHM) with Broadcom Near UltraViolet - Metal
Trench (NUV-MT) SiPMs coupled to TAC LYSO:Ce,Ca (2x2x3 mm3).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:05:22 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 13:36:28 GMT""}]","2023-05-29"
"2305.14856","\v{Z}iga Babnik","\v{Z}iga Babnik, Naser Damer, Vitomir \v{S}truc","Optimization-Based Improvement of Face Image Quality Assessment
  Techniques","In proceedings of the International Workshop on Biometrics and
  Forensics (IWBF) 2023",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Contemporary face recognition (FR) models achieve near-ideal recognition
performance in constrained settings, yet do not fully translate the performance
to unconstrained (realworld) scenarios. To help improve the performance and
stability of FR systems in such unconstrained settings, face image quality
assessment (FIQA) techniques try to infer sample-quality information from the
input face images that can aid with the recognition process. While existing
FIQA techniques are able to efficiently capture the differences between high
and low quality images, they typically cannot fully distinguish between images
of similar quality, leading to lower performance in many scenarios. To address
this issue, we present in this paper a supervised quality-label optimization
approach, aimed at improving the performance of existing FIQA techniques. The
developed optimization procedure infuses additional information (computed with
a selected FR model) into the initial quality scores generated with a given
FIQA technique to produce better estimates of the ""actual"" image quality. We
evaluate the proposed approach in comprehensive experiments with six
state-of-the-art FIQA approaches (CR-FIQA, FaceQAN, SER-FIQ, PCNet, MagFace,
SDD-FIQA) on five commonly used benchmarks (LFW, CFPFP, CPLFW, CALFW, XQLFW)
using three targeted FR models (ArcFace, ElasticFace, CurricularFace) with
highly encouraging results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:06:12 GMT""}]","2023-05-25"
"2305.14857","Akari Asai","Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila
  Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, Hannaneh Hajishirzi","BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual
  Transfer","The data and code is available at https://buffetfs.github.io/",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Despite remarkable advancements in few-shot generalization in natural
language processing, most models are developed and evaluated primarily in
English. To facilitate research on few-shot cross-lingual transfer, we
introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across
54 languages in a sequence-to-sequence format and provides a fixed set of
few-shot examples and instructions. BUFFET is designed to establish a rigorous
and equitable evaluation framework for few-shot cross-lingual transfer across a
broad range of tasks and languages. Using BUFFET, we perform thorough
evaluations of state-of-the-art multilingual large language models with
different transfer methods, namely in-context learning and fine-tuning. Our
findings reveal significant room for improvement in few-shot in-context
cross-lingual transfer. In particular, ChatGPT with in-context learning often
performs worse than much smaller mT5-base models fine-tuned on English task
data and few-shot in-language examples. Our analysis suggests various avenues
for future research in few-shot cross-lingual transfer, such as improved
pretraining, understanding, and future evaluations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:06:33 GMT""}]","2023-05-25"
"2305.14858","Zixuan Jiang","Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, David Z. Pan","Pre-RMSNorm and Pre-CRMSNorm Transformers: Equivalent and Efficient
  Pre-LN Transformers","15 pages, 5 tables, code available at
  https://github.com/ZixuanJiang/pre-rmsnorm-transformer",,,,"cs.LG cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have achieved great success in machine learning applications.
Normalization techniques, such as Layer Normalization (LayerNorm, LN) and Root
Mean Square Normalization (RMSNorm), play a critical role in accelerating and
stabilizing the training of Transformers. While LayerNorm recenters and
rescales input vectors, RMSNorm only rescales the vectors by their RMS value.
Despite being more computationally efficient, RMSNorm may compromise the
representation ability of Transformers. There is currently no consensus
regarding the preferred normalization technique, as some models employ
LayerNorm while others utilize RMSNorm, especially in recent large language
models. It is challenging to convert Transformers with one normalization to the
other type. While there is an ongoing disagreement between the two
normalization types, we propose a solution to unify two mainstream Transformer
architectures, Pre-LN and Pre-RMSNorm Transformers. By removing the inherent
redundant mean information in the main branch of Pre-LN Transformers, we can
reduce LayerNorm to RMSNorm, achieving higher efficiency. We further propose
the Compressed RMSNorm (CRMSNorm) and Pre-CRMSNorm Transformer based on a
lossless compression of the zero-mean vectors. We formally establish the
equivalence of Pre-LN, Pre-RMSNorm, and Pre-CRMSNorm Transformer variants in
both training and inference. It implies that Pre-LN Transformers can be
substituted with Pre-(C)RMSNorm counterparts at almost no cost, offering the
same arithmetic functionality along with free efficiency improvement.
Experiments demonstrate that we can reduce the training and inference time of
Pre-LN Transformers by up to 10%.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:08:26 GMT""}]","2023-05-25"
"2305.14859","Bojun Huang","Huang Bojun, Fei Yuan","Utility-Probability Duality of Neural Networks",,,,,"cs.LG cs.CL cs.NE","http://creativecommons.org/licenses/by/4.0/","  It is typically understood that the training of modern neural networks is a
process of fitting the probability distribution of desired output. However,
recent paradoxical observations in a number of language generation tasks let
one wonder if this canonical probability-based explanation can really account
for the empirical success of deep learning. To resolve this issue, we propose
an alternative utility-based explanation to the standard supervised learning
procedure in deep learning. The basic idea is to interpret the learned neural
network not as a probability model but as an ordinal utility function that
encodes the preference revealed in training data. In this perspective, training
of the neural network corresponds to a utility learning process. Specifically,
we show that for all neural networks with softmax outputs, the SGD learning
dynamic of maximum likelihood estimation (MLE) can be seen as an iteration
process that optimizes the neural network toward an optimal utility function.
This utility-based interpretation can explain several otherwise-paradoxical
observations about the neural networks thus trained. Moreover, our
utility-based theory also entails an equation that can transform the learned
utility values back to a new kind of probability estimation with which
probability-compatible decision rules enjoy dramatic (double-digits)
performance improvements. These evidences collectively reveal a phenomenon of
utility-probability duality in terms of what modern neural networks are (truly)
modeling: We thought they are one thing (probabilities), until the
unexplainable showed up; changing mindset and treating them as another thing
(utility values) largely reconcile the theory, despite remaining subtleties
regarding its original (probabilistic) identity.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:09:07 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 09:25:24 GMT""}]","2023-05-31"
"2305.14860","Bogar D\'iaz","J. R. Alvarado Garc\'ia, D. Rosales Herrera, A. Fern\'andez T\'ellez,
  Bogar D\'iaz, and J. E. Ram\'irez","Structure of the medium formed in heavy ion collisions","15 pages, 8 figures",,,,"hep-ph nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the structure of the medium formed in heavy ion collisions
using three different models: the Color String Percolation Model (CSPM), the
Core-Shell-Color String Percolation Model (CSCSPM), and the Color Glass
Condensate (CGC) framework. We analyze the radial distribution function of the
transverse representation of color flux tubes in each model to determine the
medium's structure. Our results indicate that the CSPM behaves as an ideal gas,
while the CSCSPM exhibits a structural phase transition from a gas-like to a
liquid-like structure. Additionally, our analysis of the CGC framework suggests
that it produces systems that behave like interacting gases for AuAu central
collisions at RHIC energies and liquid-like structures for PbPb central
collisions at LHC energies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:13:46 GMT""}]","2023-05-25"
"2305.14861","Fengjun Zhuo","Fengjun Zhuo, Jian Kang, Aur\'elien Manchon, Zhenxiang Cheng","Topological Phases in Magnonics: A Review","17 pages, 12 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Magnonics or magnon spintronics is an emerging field focusing on generating,
detecting, and manipulating magnons. As charge-neutral quasi-particles, magnons
are promising information carriers because of their low energy dissipation and
long coherence length. In the past decade, topological phases in magnonics have
attracted intensive attention due to their fundamental importance in
condensed-matter physics and potential applications of spintronic devices. In
this review, we mainly focus on recent progress in topological magnonics, such
as the Hall effect of magnons, magnon Chern insulators, topological magnon
semimetals, etc. In addition, the evidence supporting topological phases in
magnonics and candidate materials are also discussed and summarized. The aim of
this review is to provide readers with a comprehensive and systematic
understanding of the recent developments in topological magnonics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:13:53 GMT""}]","2023-05-25"
"2305.14862","Miren Mu\~noz-Echeverr\'ia","M. Mu\~noz-Echeverr\'ia, J. F. Mac\'ias-P\'erez, E. Artis, W. Cui, D.
  de Andres, F. De Luca, M. De Petris, A. Ferragamo, C. Giocoli, C. Hanser, F.
  Mayet, M. Meneghetti, A. Moyer, A. Paliwal, L. Perotto, E. Rasia, and G.
  Yepes","Galaxy cluster mass bias from projected mass maps: The Three
  Hundred-NIKA2 LPSZ twin samples",,,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  The determination of the mass of galaxy clusters from observations is subject
to systematic uncertainties. Beyond the errors due to instrumental and
observational systematic effects, in this work we investigate the bias
introduced by modelling assumptions. In particular, we consider the
reconstruction of the mass of galaxy clusters from convergence maps employing
spherical mass density models. We make use of The Three Hundred simulations,
selecting clusters in the same redshift and mass range as the NIKA2
Sunyaev-Zel'dovich Large Program sample: $3 \leq M_{500}/ 10^{14}
\mathrm{M}_{\odot} \leq 10$ and $0.5 \leq z \leq 0.9$. We study different
modelling and intrinsic uncertainties that should be accounted for when using
the single cluster mass estimates for scaling relations. We confirm that the
orientation of clusters and the radial ranges considered for the fit have an
important impact on the mass bias. The effect of the projection adds
uncertainties to the order of $10\%$ to $14\%$ to the mass estimates. We also
find that the scatter from cluster to cluster in the mass bias when using
spherical mass models is less than $20\%$ of the true mass of the clusters.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:14:08 GMT""}]","2023-05-25"
"2305.14863","Marcin Glowacki","M. Glowacki, K. Lee-Waddell, A. T. Deller, N. Deg, A. C. Gordon, J. A.
  Grundy, L. Marnoch, A. X. Shen, S. D. Ryder, R. M. Shannon, O. I. Wong, H.
  D\'enes, B. S. Koribalski, C. Murugeshan, J. Rhee, T. Westmeier, S. Bhandari,
  A. Bosma, B. W. Holwerda, J. X. Prochaska","WALLABY Pilot Survey: HI in the host galaxy of a Fast Radio Burst","13 pages, 5 figures. Published in ApJ",,"10.3847/1538-4357/acc1e3",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We report on the commensal ASKAP detection of a fast radio burst (FRB),
FRB20211127I, and the detection of neutral hydrogen (HI) emission in the FRB
host galaxy, WALLABYJ131913-185018 (hereafter W13-18). This collaboration
between the CRAFT and WALLABY survey teams marks the fifth, and most distant,
FRB host galaxy detected in HI, not including the Milky Way. We find that
W13-18 has a HI mass of $M_{\rm HI}$ = 6.5 $\times$ 10$^{9}$ M$_{\odot}$, a
HI-to-stellar mass ratio of 2.17, and coincides with a continuum radio source
of flux density at 1.4 GHz of 1.3 mJy. The HI global spectrum of W13-18 appears
to be asymmetric, albeit the HI observation has a low S/N, and the galaxy
itself appears modestly undisturbed. These properties are compared to the early
literature of HI emission detected in other FRB hosts to date, where either the
HI global spectra were strongly asymmetric, or there were clearly disrupted HI
intensity map distributions. W13-18 lacks sufficient S/N to determine whether
it is significantly less asymmetric in its HI distribution than previous
examples of FRB host galaxies. However, there are no strong signs of a major
interaction in the HI or optical image of the host galaxy that would stimulate
a burst of star formation and hence the production of putative FRB progenitors
related to massive stars and their compact remnants.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:14:20 GMT""}]","2023-05-25"
"2305.14864","Ananya Harsh Jha","Ananya Harsh Jha, Dirk Groeneveld, Emma Strubell, Iz Beltagy","Large Language Model Distillation Doesn't Need a Teacher","10 pages, 3 figures, 5 tables",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Knowledge distillation trains a smaller student model to match the output
distribution of a larger teacher to maximize the end-task performance under
computational constraints. However, existing literature on language model
distillation primarily focuses on compressing encoder-only models that are then
specialized by task-specific supervised finetuning. We need to rethink this
setup for more recent large language models with tens to hundreds of billions
of parameters. Task-specific finetuning is impractical at this scale, and model
performance is often measured using zero/few-shot prompting. Thus, in this
work, we advocate for task-agnostic zero-shot evaluated distillation for large
language models without access to end-task finetuning data. We propose a
teacher-free task-agnostic distillation method, which uses a truncated version
of the larger model for initialization, and continues pretraining this model
using a language modeling objective. Our teacher-free method shines in a
distillation regime where it is infeasible to fit both the student and teacher
into the GPU memory. Despite its simplicity, our method can effectively reduce
the model size by 50\%, matching or outperforming the vanilla distillation
method on perplexity and accuracy on 13 zero-shot end-tasks while being 1.5x
computationally efficient.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:18:35 GMT""}]","2023-05-25"
"2305.14865","Na Zhang","Na Zhang, Kun Yue, Chao Fang","A Game-Theoretic Framework for AI Governance",,,,,"cs.GT cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a transformative general-purpose technology, AI has empowered various
industries and will continue to shape our lives through ubiquitous
applications. Despite the enormous benefits from wide-spread AI deployment, it
is crucial to address associated downside risks and therefore ensure AI
advances are safe, fair, responsible, and aligned with human values. To do so,
we need to establish effective AI governance. In this work, we show that the
strategic interaction between the regulatory agencies and AI firms has an
intrinsic structure reminiscent of a Stackelberg game, which motivates us to
propose a game-theoretic modeling framework for AI governance. In particular,
we formulate such interaction as a Stackelberg game composed of a leader and a
follower, which captures the underlying game structure compared to its
simultaneous play counterparts. Furthermore, the choice of the leader naturally
gives rise to two settings. And we demonstrate that our proposed model can
serves as a unified AI governance framework from two aspects: firstly we can
map one setting to the AI governance of civil domains and the other to the
safety-critical and military domains, secondly, the two settings of governance
could be chosen contingent on the capability of the intelligent systems. To the
best of our knowledge, this work is the first to use game theory for analyzing
and structuring AI governance. We also discuss promising directions and hope
this can help stimulate research interest in this interdisciplinary area. On a
high, we hope this work would contribute to develop a new paradigm for
technology policy: the quantitative and AI-driven methods for the technology
policy field, which holds significant promise for overcoming many shortcomings
of existing qualitative approaches.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:18:42 GMT""}]","2023-05-25"
"2305.14866","Douadi  Drihem","Douadi Drihem","Powers functions in Besov spaces of power weights. Necessary conditions",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to present some necessary conditions for the
boundedness of the mapping $f\mapsto |f|^{\mu },\mu >0$ on Besov spaces
equipped with power weights.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:19:13 GMT""}]","2023-05-25"
"2305.14867","Rodrigo Diaz","Rodrigo Diaz, Charalampos Saitis, Mark Sandler","Interactive Neural Resonators",,,,,"cs.SD cs.HC eess.AS","http://creativecommons.org/licenses/by/4.0/","  In this work, we propose a method for the controllable synthesis of real-time
contact sounds using neural resonators. Previous works have used physically
inspired statistical methods and physical modelling for object materials and
excitation signals. Our method incorporates differentiable second-order
resonators and estimates their coefficients using a neural network that is
conditioned on physical parameters. This allows for interactive dynamic control
and the generation of novel sounds in an intuitive manner. We demonstrate the
practical implementation of our method and explore its potential creative
applications.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:19:42 GMT""}]","2023-05-25"
"2305.14868","Ganghwi Kim","Ganghwi Kim, Dae-Han Jung, Hee-Sung Han and Ki-Suk Lee","Resonance of Domain Wall in a Ferromagnetic Nanostrip: Relation Between
  Distortion and Velocity","15 pages, 4 figures",,,,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The resonance of the magnetic domain wall under the applied field amplifies
its velocity compared to the one-dimensional model. To quantify the
amplification, we define the distortion variation rate of the domain wall that
can represent how fast and severely the wall shape is variated. Introducing
that rate gives a way to bring the resonance into the one-dimensional domain
wall dynamics model. We obtain the dissipated energy and domain wall velocity
amplification by calculating the distortion variation rate. The relationship
between velocity and distortion variation rate agrees well with micromagnetic
simulation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:21:26 GMT""}]","2023-05-25"
"2305.14869","Weiqi Wang Mr.","Weiqi Wang, Tianqing Fang, Wenxuan Ding, Baixuan Xu, Xin Liu, Yangqiu
  Song, Antoine Bosselut","CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense
  Question Answering",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of zero-shot commonsense question answering evaluates models on
their capacity to reason about general scenarios beyond those presented in
specific datasets. Existing approaches for tackling this task leverage external
knowledge from CommonSense Knowledge Bases (CSKBs) by pretraining the model on
synthetic QA pairs constructed from CSKBs. In these approaches, negative
examples (distractors) are formulated by randomly sampling from CSKBs using
fairly primitive keyword constraints. However, two bottlenecks limit these
approaches: the inherent incompleteness of CSKBs limits the semantic coverage
of synthetic QA pairs, and the lack of human annotations makes the sampled
negative examples potentially uninformative and contradictory. To tackle these
limitations above, we propose Conceptualization-Augmented Reasoner (CAR), a
zero-shot commonsense question-answering framework that fully leverages the
power of conceptualization. Specifically, CAR abstracts a commonsense knowledge
triple to many higher-level instances, which increases the coverage of CSKB and
expands the ground-truth answer space, reducing the likelihood of selecting
false-negative distractors. Extensive experiments demonstrate that CAR more
robustly generalizes to answering questions about zero-shot commonsense
scenarios than existing methods, including large language models, such as
GPT3.5 and ChatGPT. Our codes, data, and model checkpoints are available at
https://github.com/HKUST-KnowComp/CAR.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:21:31 GMT""}]","2023-05-25"
"2305.14870","Indrani Banerjee","Siddharth Kumar Sahoo, Neeraj Yadav and Indrani Banerjee","Imprints of Einstein-Maxwell dilaton-axion gravity in the observed
  shadows of Sgr A* and M87*","28 pages, 7 figures",,,,"gr-qc astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Einstein-Maxwell dilaton-axion (EMDA) gravity provides a simple framework to
investigate the signatures of string theory. The axion and the dilaton fields
arising in EMDA gravity have important implications in inflationary cosmology
and in addressing the late time acceleration of the universe. It is therefore
instructive to explore the implications of such a model in explaining the
astrophysical observations. In this work we explore the role of EMDA gravity in
explaining the observed shadows of black holes (M87* and Sgr A*) released by
the Event Horizon Telescope (EHT) collaboration. The Kerr-Sen metric represents
the exact, stationary and axisymmetric black hole solution of EMDA gravity.
Such a black hole is characterized by the angular momentum $a$ acquired from
the axionic field and the dilatonic charge $r_2$ arising from string
compactifications. We study the role of spin and the dilaton charge in
modifying the shape and size of the black hole shadow. We note that black holes
with larger dilaton charge cast a smaller shadow. We investigate the
consequences of such a result in addressing the EHT observations of M87* and
Sgr A*. Our analysis reveals that the shadow of M87* exhibits a preference
towards the Kerr scenario. However, when 10% offset in the shadow diameter is
considered, $0.1\lesssim r_2\lesssim 0.3$ is observationally favored within
1-$\sigma$. The shadow of Sgr A* on the other hand shows a preference towards
the Kerr-Sen scenario since the central value of its shadow can be better
explained by a non-zero dilaton charge $0.1 \lesssim r_2 \lesssim 0.4$.
However, when the 1-$\sigma$ interval is considered the Kerr scenario is
included. We discuss the implications of our results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:22:49 GMT""}]","2023-05-25"
"2305.14871","Yuwei Zhang","Yuwei Zhang, Zihan Wang, Jingbo Shang","ClusterLLM: Large Language Models as a Guide for Text Clustering",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We introduce ClusterLLM, a novel text clustering framework that leverages
feedback from an instruction-tuned large language model, such as ChatGPT.
Compared with traditional unsupervised methods that builds upon ""small""
embedders, ClusterLLM exhibits two intriguing advantages: (1) it enjoys the
emergent capability of LLM even if its embeddings are inaccessible; and (2) it
understands the user's preference on clustering through textual instruction
and/or a few annotated data. First, we prompt ChatGPT for insights on
clustering perspective by constructing hard triplet questions <does A better
correspond to B than C>, where A, B and C are similar data points that belong
to different clusters according to small embedder. We empirically show that
this strategy is both effective for fine-tuning small embedder and
cost-efficient to query ChatGPT. Second, we prompt ChatGPT for helps on
clustering granularity by carefully designed pairwise questions <do A and B
belong to the same category>, and tune the granularity from cluster hierarchies
that is the most consistent with the ChatGPT answers. Extensive experiments on
14 datasets show that ClusterLLM consistently improves clustering quality, at
an average cost of ~$0.6 per dataset.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:24:25 GMT""}]","2023-05-25"
"2305.14872","Janek Gro{\ss}","Janek Gro{\ss}, Michael Kl\""as, Lisa J\""ockel, Pascal Gerber","Timeseries-aware Uncertainty Wrappers for Uncertainty Quantification of
  Information-Fusion-Enhanced AI Models based on Machine Learning","8 pages, 7 figures, VERDI workshop collocated with the DSN conference
  2023",,,,"cs.LG cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the use of Artificial Intelligence (AI) components in cyber-physical
systems is becoming more common, the need for reliable system architectures
arises. While data-driven models excel at perception tasks, model outcomes are
usually not dependable enough for safety-critical applications. In this work,we
present a timeseries-aware uncertainty wrapper for dependable uncertainty
estimates on timeseries data. The uncertainty wrapper is applied in combination
with information fusion over successive model predictions in time. The
application of the uncertainty wrapper is demonstrated with a traffic sign
recognition use case. We show that it is possible to increase model accuracy
through information fusion and additionally increase the quality of uncertainty
estimates through timeseries-aware input quality features.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:24:54 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 07:58:04 GMT""}]","2023-06-01"
"2305.14873","Ming Ji","Ming Ji and Holger F. Hofmann","Quantitative Relations Between Different Measurement Contexts","10 pages and 4 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In quantum theory, a measurement context is defined by an orthogonal basis in
a Hilbert space, where each basis vector represents a specific measurement
outcome. The precise quantitative relation between two different measurement
contexts can thus be characterized by the inner products of nonorthogonal
states in that Hilbert space. Here, we use measurement outcomes that are shared
by different contexts to derive specific quantitative relations between the
inner products of the Hilbert space vectors that represent the different
contexts. It is shown that the probabilities that describe the paradoxes of
quantum contextuality can be derived from a very small number of inner
products, demonstrating that quantum contextuality is a necessary consequence
of the quantitative relations between Hilbert space vectors representing
different measurement contexts. The application of our analysis to a product
space of two systems reveals that the non-locality of quantum entanglement can
be traced back to a local inner product representing the relation between
measurement contexts in only one system. Our results thus indicate that the
essential non-classical features of quantum mechanics can all be derived
systematically from the quantitative relations between different measurement
contexts described by the Hilbert space formalism.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:26:09 GMT""}]","2023-05-25"
"2305.14874","Peter Jansen","Peter Jansen","From Words to Wires: Generating Functioning Electronic Devices from
  Natural Language Descriptions","13 pages, 4 figures",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  In this work, we show that contemporary language models have a previously
unknown skill -- the capacity for electronic circuit design from high-level
textual descriptions, akin to code generation. We introduce two benchmarks:
Pins100, assessing model knowledge of electrical components, and Micro25,
evaluating a model's capability to design common microcontroller circuits and
code in the Arduino ecosystem that involve input, output, sensors, motors,
protocols, and logic -- with models such as GPT-4 and Claude-V1 achieving
between 60% to 96% Pass@1 on generating full devices. We include six case
studies of using language models as a design assistant for moderately complex
devices, such as a radiation-powered random number generator, an emoji
keyboard, a visible spectrometer, and several assistive devices, while offering
a qualitative analysis performance, outlining evaluation challenges, and
suggesting areas of development to improve complex circuit design and practical
utility. With this work, we aim to spur research at the juncture of natural
language processing and electronic design.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:28:59 GMT""}]","2023-05-25"
"2305.14875","Alarith Uhde","Andreas F\""orster and Alarith Uhde and Mathias Komesker and Christina
  Komesker and Irina Schmidt","LoopBoxes -- Evaluation of a Collaborative Accessible Digital Musical
  Instrument","10 pages, 9 figures, to be published in the Proceedings of the
  International Conference on New Interfaces for Musical Expression (NIME'23)",,,,"cs.HC cs.CY cs.MM cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  LoopBoxes is an accessible digital musical instrument designed to create an
intuitive access to loop based music making for children with special
educational needs (SEN). This paper describes the evaluation of the instrument
in the form of a pilot study during a music festival in Berlin, Germany, as
well as a case study with children and music teachers in a SEN school setting.
We created a modular system composed of three modules that afford single user
as well as collaborative music making. The pilot study was evaluated using
informal observation and questionnaires (n = 39), and indicated that the
instrument affords music making for people with and without prior musical
knowledge across all age groups and fosters collaborative musical processes.
The case study was based on observation and a qualitative interview. It
confirmed that the instrument meets the needs of the school settings and
indicated how future versions could expand access to all students, especially
those experiencing complex disabilities. In addition, out-of-the-box
functionality seems to be crucial for the long-term implementation of the
instrument in a school setting.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:29:14 GMT""}]","2023-05-25"
"2305.14876","Yige Li","Yige Li, Xixiang Lyu, Xingjun Ma, Nodens Koren, Lingjuan Lyu, Bo Li,
  Yu-Gang Jiang","Reconstructive Neuron Pruning for Backdoor Defense","Accepted by ICML23",,,,"cs.LG cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) have been found to be vulnerable to backdoor
attacks, raising security concerns about their deployment in mission-critical
applications. While existing defense methods have demonstrated promising
results, it is still not clear how to effectively remove backdoor-associated
neurons in backdoored DNNs. In this paper, we propose a novel defense called
\emph{Reconstructive Neuron Pruning} (RNP) to expose and prune backdoor neurons
via an unlearning and then recovering process. Specifically, RNP first unlearns
the neurons by maximizing the model's error on a small subset of clean samples
and then recovers the neurons by minimizing the model's error on the same data.
In RNP, unlearning is operated at the neuron level while recovering is operated
at the filter level, forming an asymmetric reconstructive learning procedure.
We show that such an asymmetric process on only a few clean samples can
effectively expose and prune the backdoor neurons implanted by a wide range of
attacks, achieving a new state-of-the-art defense performance. Moreover, the
unlearned model at the intermediate step of our RNP can be directly used to
improve other backdoor defense tasks including backdoor removal, trigger
recovery, backdoor label detection, and backdoor sample detection. Code is
available at \url{https://github.com/bboylyg/RNP}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:29:30 GMT""}]","2023-05-25"
"2305.14877","Sohee Yang","Sohee Yang, Jonghyeon Kim, Joel Jang, Seonghyeon Ye, Hyunji Lee,
  Minjoon Seo","Improving Probability-based Prompt Selection Through Unified Evaluation
  and Analysis",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Language Models (LLMs) have demonstrated great capabilities in solving
a wide range of tasks in a resource-efficient manner through prompting, which
does not require task-specific training, but suffers from performance
fluctuation when there are multiple prompt candidates. Previous works have
introduced gradient-free probability-based prompt selection methods that aim to
choose the optimal prompt among the candidates for a given task but fail to
provide a comprehensive and fair comparison between each other. In this paper,
we propose a unified framework to interpret and evaluate the existing
probability-based prompt selection methods by performing extensive experiments
on 13 common NLP tasks. We find that all existing methods can be unified into
some variant of the method that maximizes the mutual information between the
input and the corresponding model output (denoted as MI). Using the finding, we
develop several variants of MI and increases the effectiveness of the best
prompt selection method from 87.79% to 94.98%, measured as the ratio of the
performance of the selected prompt to that of the optimal oracle prompt.
Furthermore, we propose a novel calibration method called Calibration by
Marginalization (CBM) that is orthogonal to existing methods and helps increase
the prompt selection effectiveness of the best method by 99.44%. The code and
datasets used in our work will be released at
https://github.com/soheeyang/unified-prompt-selection.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:29:50 GMT""}]","2023-05-25"
"2305.14878","Vikas Raunak","Vikas Raunak, Amr Sharaf, Hany Hassan Awadallah, Arul Menezes","Leveraging GPT-4 for Automatic Translation Post-Editing",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  While Neural Machine Translation (NMT) represents the leading approach to
Machine Translation (MT), the outputs of NMT models still require translation
post-editing to rectify errors and enhance quality, particularly under critical
settings. In this work, we formalize the task of translation post-editing with
Large Language Models (LLMs) and explore the use of GPT-4 to automatically
post-edit NMT outputs across several language pairs. Our results demonstrate
that GPT-4 is adept at translation post-editing and produces meaningful edits
even when the target language is not English. Notably, we achieve
state-of-the-art performance on WMT-22 English-Chinese, English-German,
Chinese-English and German-English language pairs using GPT-4 based
post-editing, as evaluated by state-of-the-art MT quality metrics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:30:05 GMT""}]","2023-05-25"
"2305.14879","Peter Jansen","Ruoyao Wang, Graham Todd, Eric Yuan, Ziang Xiao, Marc-Alexandre
  C\^ot\'e, Peter Jansen","ByteSized32: A Corpus and Challenge Task for Generating Task-Specific
  World Models Expressed as Text Games","10 pages",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  In this work we examine the ability of language models to generate explicit
world models of scientific and common-sense reasoning tasks by framing this as
a problem of generating text-based games. To support this, we introduce
ByteSized32, a corpus of 32 highly-templated text games written in Python
totaling 24k lines of code, each centered around a particular task, and paired
with a set of 16 unseen text game specifications for evaluation. We propose a
suite of automatic and manual metrics for assessing simulation validity,
compliance with task specifications, playability, winnability, and alignment
with the physical world. In a single-shot evaluation of GPT-4 on this
simulation-as-code-generation task, we find it capable of producing runnable
games in 27% of cases, highlighting the difficulty of this challenge task. We
discuss areas of future improvement, including GPT-4's apparent capacity to
perform well at simulating near canonical task solutions, with performance
dropping off as simulations include distractors or deviate from canonical
solutions in the action space.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:31:30 GMT""}]","2023-05-25"
"2305.14880","Shuting Yan","Shuting Yan, Pingping Chen, Honghui Chen, Huan Mao, Feng Chen and
  Zhijian Lin","Multiresolution Feature Guidance Based Transformer for Anomaly Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly detection is represented as an unsupervised learning to identify
deviated images from normal images. In general, there are two main challenges
of anomaly detection tasks, i.e., the class imbalance and the unexpectedness of
anomalies. In this paper, we propose a multiresolution feature guidance method
based on Transformer named GTrans for unsupervised anomaly detection and
localization. In GTrans, an Anomaly Guided Network (AGN) pre-trained on
ImageNet is developed to provide surrogate labels for features and tokens.
Under the tacit knowledge guidance of the AGN, the anomaly detection network
named Trans utilizes Transformer to effectively establish a relationship
between features with multiresolution, enhancing the ability of the Trans in
fitting the normal data manifold. Due to the strong generalization ability of
AGN, GTrans locates anomalies by comparing the differences in spatial distance
and direction of multi-scale features extracted from the AGN and the Trans. Our
experiments demonstrate that the proposed GTrans achieves state-of-the-art
performance in both detection and localization on the MVTec AD dataset. GTrans
achieves image-level and pixel-level anomaly detection AUROC scores of 99.0%
and 97.9% on the MVTec AD dataset, respectively.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:31:38 GMT""}]","2023-05-25"
"2305.14881","Santiago Oviedo-Casado","Nicolas Staudenmaier, Anjusha Vijayakumar-Sreeja, Genko Genov, Daniel
  Cohen, Christoph Findler, Johannes Lang, Alex Retzker, Fedor Jelezko,
  Santiago Oviedo-Casado","An optimal sensing protocol for statistically polarized nano-NMR with NV
  centers","17 pages and 7 figures. Comments very welcome",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion noise represents a major constraint to successful liquid state
nano-NMR spectroscopy. Using the Fisher information as a faithful measure, we
calculate theoretically and show experimentally that phase sensitive protocols
are superior in most experimental scenarios, as they maximize information
extraction from correlations in the sample. We derive the optimal experimental
parameters for quantum heterodyne detection and present the most accurate
statistically polarized nano-NMR Qdyne experiments to date, leading the way to
resolve chemical shifts and $J$-couplings at the nano-scale.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:32:28 GMT""}]","2023-05-25"
"2305.14882","Xingyu Fu","Xingyu Fu, Ben Zhou, Sihao Chen, Mark Yatskar, Dan Roth","Interpretable by Design Visual Question Answering","Multimodal, Vision and Language",,,,"cs.CL cs.AI cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Model interpretability has long been a hard problem for the AI community
especially in the multimodal setting, where vision and language need to be
aligned and reasoned at the same time. In this paper, we specifically focus on
the problem of Visual Question Answering (VQA). While previous researches try
to probe into the network structures of black-box multimodal models, we propose
to tackle the problem from a different angle -- to treat interpretability as an
explicit additional goal.
  Given an image and question, we argue that an interpretable VQA model should
be able to tell what conclusions it can get from which part of the image, and
show how each statement help to arrive at an answer. We introduce InterVQA:
Interpretable-by-design VQA, where we design an explicit intermediate dynamic
reasoning structure for VQA problems and enforce symbolic reasoning that only
use the structure for final answer prediction to take place. InterVQA produces
high-quality explicit intermediate reasoning steps, while maintaining similar
to the state-of-the-art (sota) end-task performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:33:15 GMT""}]","2023-05-25"
"2305.14883","Ricard Vilar","Ricard Vilar and Simeon Ball","Quantum cyclic redundancy check codes",,,,,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the idea of classical cyclic redundancy check codes to quantum
cyclic redundancy check codes. This allows us to construct codes quantum
stabiliser codes which can correct burst errors where the burst length attains
the quantum Reiger bound. We then consider a certain family of quantum cyclic
redundancy check codes for which we present a fast linear time decoding
algorithm.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:33:22 GMT""}]","2023-05-25"
"2305.14884","Campbell Wheeler","Stavros Garoufalidis, Matthias Storzer and Campbell Wheeler","Topological invariance of complex Chern-Simons and Teichm\""uller TQFT
  perturbation theory","48 pages, 2 figures",,,"MPIM-Bonn-2023","math.GT hep-th","http://creativecommons.org/licenses/by/4.0/","  We prove the topological invariance of a formal power series defined using an
ideal triangulation of a 3-manifold with torus boundary components (together
with some further choices). This formal power series is conjectured to agree to
all orders in perturbation theory with two important topological invariants of
hyperbolic knots, namely the Kashaev invariant and the Andersen--Kashaev
invariant (also known as the state-integral) of Teichm\""uller TQFT.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:33:29 GMT""}]","2023-05-26"
"2305.14885","Chuhao Liu","Chuhao Liu and Shaojie Shen","Towards View-invariant and Accurate Loop Detection Based on Scene Graph","Accepted by ICRA2023",,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Loop detection plays a key role in visual Simultaneous Localization and
Mapping (SLAM) by correcting the accumulated pose drift. In indoor scenarios,
the richly distributed semantic landmarks are view-point invariant and hold
strong descriptive power in loop detection. The current semantic-aided loop
detection embeds the topology between semantic instances to search a loop.
However, current semantic-aided loop detection methods face challenges in
dealing with ambiguous semantic instances and drastic viewpoint differences,
which are not fully addressed in the literature. This paper introduces a novel
loop detection method based on an incrementally created scene graph, targeting
the visual SLAM at indoor scenes. It jointly considers the macro-view topology,
micro-view topology, and occupancy of semantic instances to find correct
correspondences. Experiments using handheld RGB-D sequence show our method is
able to accurately detect loops in drastically changed viewpoints. It maintains
a high precision in observing objects with similar topology and appearance. Our
method also demonstrates that it is robust in changed indoor scenes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:34:43 GMT""}]","2023-05-25"
"2305.14886","Jiajia Chen","Jiajia Chen, Jiancan Wu, Jiawei Chen, Xin Xin, Yong Li, Xiangnan He","How Graph Convolutions Amplify Popularity Bias for Recommendation?","Accepted by Frontiers of Computer Science",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Graph convolutional networks (GCNs) have become prevalent in recommender
system (RS) due to their superiority in modeling collaborative patterns.
Although improving the overall accuracy, GCNs unfortunately amplify popularity
bias -- tail items are less likely to be recommended. This effect prevents the
GCN-based RS from making precise and fair recommendations, decreasing the
effectiveness of recommender systems in the long run.
  In this paper, we investigate how graph convolutions amplify the popularity
bias in RS. Through theoretical analyses, we identify two fundamental factors:
(1) with graph convolution (\textit{i.e.,} neighborhood aggregation), popular
items exert larger influence than tail items on neighbor users, making the
users move towards popular items in the representation space; (2) after
multiple times of graph convolution, popular items would affect more high-order
neighbors and become more influential. The two points make popular items get
closer to almost users and thus being recommended more frequently. To rectify
this, we propose to estimate the amplified effect of popular nodes on each
node's representation, and intervene the effect after each graph convolution.
Specifically, we adopt clustering to discover highly-influential nodes and
estimate the amplification effect of each node, then remove the effect from the
node embeddings at each graph convolution layer. Our method is simple and
generic -- it can be used in the inference stage to correct existing models
rather than training a new model from scratch, and can be applied to various
GCN models. We demonstrate our method on two representative GCN backbones
LightGCN and UltraGCN, verifying its ability in improving the recommendations
of tail items without sacrificing the performance of popular items. Codes are
open-sourced \footnote{https://github.com/MEICRS/DAP}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:35:43 GMT""}]","2023-05-25"
"2305.14887","Khalil Zakeri Lori","Khalil Zakeri and Christophe Berthod","Theory of spin-polarized high-resolution electron energy loss
  spectroscopy from nonmagnetic surfaces with a large spin-orbit coupling","8 pages, 1 figure","Phys. Rev. B 106, 235117 (2022)","10.1103/PhysRevB.106.235117",,"cond-mat.str-el cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  The scattering theory of low-energy (slow) electrons has been developed by
Evans and Mills [Phys. Rev. B 5, 4126 (1972)]. The formalism is merely based on
the electrostatic Coulomb interaction of the scattering electrons with the
charge-density fluctuations above the surface and can describe most of the
interesting features observed in the high-resolution electron energy-loss
spectroscopy experiments. Here we extend this theory by including the
spin-orbit coupling in the scattering process. We discuss the impact of this
interaction on the scattering cross section. In particular, we discuss cases in
which a spin-polarized electron beam is scattered from nonmagnetic surfaces
with a strong spin-orbit coupling. We show that under some assumptions one can
derive an expression for the scattering cross section, which can be used for
numerical calculations of the spin-polarized spectra recorded by spin-polarized
high-resolution electron energy-loss spectroscopy experiments.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:37:25 GMT""}]","2023-05-25"
"2305.14888","Yangsibo Huang","Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen","Privacy Implications of Retrieval-Based Language Models",,,,,"cs.CL cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Retrieval-based language models (LMs) have demonstrated improved
interpretability, factuality, and adaptability compared to their parametric
counterparts, by incorporating retrieved text from external datastores. While
it is well known that parametric models are prone to leaking private data, it
remains unclear how the addition of a retrieval datastore impacts model
privacy. In this work, we present the first study of privacy risks in
retrieval-based LMs, particularly $k$NN-LMs. Our goal is to explore the optimal
design and training procedure in domains where privacy is of concern, aiming to
strike a balance between utility and privacy. Crucially, we find that $k$NN-LMs
are more susceptible to leaking private information from their private
datastore than parametric models. We further explore mitigations of privacy
risks. When privacy information is targeted and readily detected in the text,
we find that a simple sanitization step would completely eliminate the risks,
while decoupling query and key encoders achieves an even better utility-privacy
trade-off. Otherwise, we consider strategies of mixing public and private data
in both datastore and encoder training. While these methods offer modest
improvements, they leave considerable room for future work. Together, our
findings provide insights for practitioners to better understand and mitigate
privacy risks in retrieval-based LMs. Our code is available at:
https://github.com/Princeton-SysML/kNNLM_privacy .
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:37:27 GMT""}]","2023-05-25"
"2305.14889","Ziang Xiao","Ziang Xiao, Susu Zhang, Vivian Lai, Q. Vera Liao","Evaluating NLG Evaluation Metrics: A Measurement Theory Perspective",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  We address the fundamental challenge in Natural Language Generation (NLG)
model evaluation, the design and validation of evaluation metrics. Recognizing
the limitations of existing metrics and issues with human judgment, we propose
using measurement theory, the foundation of test design, as a framework for
conceptualizing and evaluating the validity and reliability of NLG evaluation
metrics. This approach offers a systematic method for defining ""good"" metrics,
developing robust metrics, and assessing metric performance. In this paper, we
introduce core concepts in measurement theory in the context of NLG evaluation
and key methods to evaluate the performance of NLG metrics. Through this
framework, we aim to promote the design, evaluation, and interpretation of
valid and reliable metrics, ultimately contributing to the advancement of
robust and effective NLG models in real-world settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:38:23 GMT""}]","2023-05-25"
"2305.14890","Arne Nix","Arne F. Nix, Max F. Burg, Fabian H. Sinz","HARD: Hard Augmentations for Robust Distillation",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Knowledge distillation (KD) is a simple and successful method to transfer
knowledge from a teacher to a student model solely based on functional
activity. However, current KD has a few shortcomings: it has recently been
shown that this method is unsuitable to transfer simple inductive biases like
shift equivariance, struggles to transfer out of domain generalization, and
optimization time is magnitudes longer compared to default non-KD model
training. To improve these aspects of KD, we propose Hard Augmentations for
Robust Distillation (HARD), a generally applicable data augmentation framework,
that generates synthetic data points for which the teacher and the student
disagree. We show in a simple toy example that our augmentation framework
solves the problem of transferring simple equivariances with KD. We then apply
our framework in real-world tasks for a variety of augmentation models, ranging
from simple spatial transformations to unconstrained image manipulations with a
pretrained variational autoencoder. We find that our learned augmentations
significantly improve KD performance on in-domain and out-of-domain evaluation.
Moreover, our method outperforms even state-of-the-art data augmentations and
since the augmented training inputs can be visualized, they offer a qualitative
insight into the properties that are transferred from the teacher to the
student. Thus HARD represents a generally applicable, dynamically optimized
data augmentation technique tailored to improve the generalization and
convergence speed of models trained with KD.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:38:44 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 10:57:46 GMT""}]","2023-05-26"
"2305.14891","Luka Pavlovi\'c","Luka Pavlovi\'c","Extracting Psychological Indicators Using Question Answering","4 pages, 0 figures",,,,"cs.CL cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a method for extracting text spans that may indicate
one of the BIG5 psychological traits using a question-answering task with
examples that have no answer for the asked question. We utilized the RoBERTa
model fine-tuned on SQuAD 2.0 dataset. The model was further fine-tuned
utilizing comments from Reddit. We examined the effect of the percentage of
examples with no answer in the training dataset on the overall performance. The
results obtained in this study are in line with the SQuAD 2.0 benchmark and
present a good baseline for further research.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:41:23 GMT""}]","2023-05-25"
"2305.14892","Mohammad Rowshan","Mohammad Rowshan and Jinhong Yuan","Segmented GRAND: Combining Sub-patterns in Near-ML Order",,,,,"cs.IT eess.SP math.IT","http://creativecommons.org/licenses/by/4.0/","  The recently introduced maximum-likelihood (ML) decoding scheme called
guessing random additive noise decoding (GRAND) has demonstrated a remarkably
low time complexity in high signal-to-noise ratio (SNR) regimes. However, the
complexity is not as low at low SNR regimes and low code rates. To mitigate
this concern, we propose a scheme for a near-ML variant of GRAND called ordered
reliability bits GRAND (or ORBGRAND), which divides codewords into segments
based on the properties of the underlying code, generates sub-patterns for each
segment consistent with the syndrome (thus reducing the number of inconsistent
error patterns generated), and combines them in a near-ML order using two-level
integer partitions of logistic weight. The numerical evaluation demonstrates
that the proposed scheme, called segmented ORBGRAND, significantly reduces the
average number of queries at any SNR regime. Moreover, the segmented ORBGRAND
with abandonment also improves the error correction performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:43:07 GMT""}]","2023-05-25"
"2305.14893","Najmeh Sadat Mirian","Najmeh Sadat Mirian, Elham Salehi, Frank Zimmermann","Using the LHeC ERL to generate high-energy photons","4",,,,"physics.acc-ph","http://creativecommons.org/licenses/by/4.0/","  The Large Hadron electron Collider (LHeC) is a proposed future particle
physics project colliding 60 GeV electrons from a six-pass recirculating
energy-recovery linac (ERL) with 7 TeV protons stored in the LHC. The ERL
technology allows for much higher beam current and, therefore, higher
luminosity than a traditional linac. The high-current, high-energy electron
beam can also be used to drive a free electron laser (FEL). In this
contribution, we examine how the LHeC ERL can serve as a source of high-energy
photons for studies in nuclear physics, high-energy physics, Axion detection,
dark energy, and protein crystallography. In the first section, we discuss the
performance of the LHeC-based FEL, operated in the SASE mode for generating
photon pulses at wavelengths ranging from 200 keV to 600 keV. In the second
section, we investigate photon production via Laser Compton scattering (LCS).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:44:41 GMT""}]","2023-05-25"
"2305.14894","Bosiljka Tadic","Samir Sahoo, Bosiljka Tadic, Malayaja Chutani and Neelima Gupte","Effect of hidden geometry and higher-order interactions on the
  synchronization and hysteresis behaviour of phase oscillators on 5-cliques
  simplicial assemblies","9 pages, 7 figures; regular article, submitted",,,,"cond-mat.stat-mech nlin.AO","http://creativecommons.org/licenses/by/4.0/","  The hidden geometry of simplicial complexes can influence the collective
dynamics of nodes in different ways depending on the simplex-based interactions
of various orders and competition between local and global structural features.
We study a system of phase oscillators attached to nodes of 4-dimensional
simplicial complexes and interacting via positive/negative edges-based pairwise
$K_1$ and triangle-based triple $K_2\geq 0$ couplings. Three prototypal
simplicial complexes are grown by aggregation of 5-cliques, controlled by the
chemical affinity parameter $\nu$, resulting in sparse, mixed, and compact
architecture, all of which have 1-hyperbolic graphs but different spectral
dimensions. By changing the interaction strength $K_1\in[-4,2]$ along the
forward and backward sweeps, we numerically determine individual phases of each
oscillator and a global order parameter to measure the level of
synchronisation. Our results reveal how different architectures of simplicial
complexes, in conjunction with the interactions and internal-frequency
distributions, impact the shape of the hysteresis loop and lead to patterns of
locally synchronised groups that hinder global network synchronisation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:45:19 GMT""}]","2023-05-25"
"2305.14895","Zhixing Ling Dr","Z.X. Ling, X.J. Sun, C. Zhang, S.L. Sun, G. Jin, S.N. Zhang, X.F.
  Zhang, J.B. Chang, F.S. Chen, Y.F. Chen, Z.W. Cheng, W. Fu, Y.X. Han, H. Li,
  J.F. Li, Y. Li, Z.D. Li, P.R. Liu, Y.H. Lv, X.H. Ma, Y.J. Tang, C.B. Wang,
  R.J. Xie, Y.L. Xue, A.L. Yan, Q. Zhang, C.Y. Bao, H.B. Cai, H.Q. Cheng, C.Z.
  Cui, Y.F. Dai, D.W. Fan, H.B. Hu, J.W. Hu, M.H. Huang, Z.Q. Jia, C.C. Jin,
  D.Y. Li, J.Q. Li, H.Y. Liu, M.J. Liu, Y. Liu, H.W. Pan, Y.L. Qiu, M.
  Sugizaki, H. Sun, W.X. Wang, Y.L. Wang, Q.Y. Wu, X.P. Xu, Y.F. Xu, H.N. Yang,
  X. Yang, B. Zhang, M. Zhang, W.D. Zhang, Z. Zhang, D.H. Zhao, X.Q. Cong, B.W.
  Jiang, L.H. Li, X.B. Qiu, J.N. Sun, D.T. Su, J. Wang, C. Wu, Z. Xu, X.M.
  Yang, S.K. Zhang, Z. Zhang, N. Zhang, Y.F. Zhu, H.Y. Ban, X.Z. Bi, Z.M. Cai,
  W. Chen, X. Chen, Y.H. Chen, Y. Cui, X.L. Duan, Z.G Feng, Y. Gao, J.W. He, T.
  He, J.J. Huang, F. Li, J.S. Li, T.J. Li, T.T. Li, H.Q. Liu, L. Liu, R. Liu,
  S. Liu, N. Meng, Q. Shi, A.T. Sun, Y.M. Wang, Y.B. Wang, H.C. Wu, D.X Xu, Y.Q
  Yang, Y. Yang, X.S. Yu, K.X. Zhang, Y.L. Zhang, Y.H. Zhang, Y.T. Zhang, H.
  Zhou, X.C. Zhu, J.S. Cheng, L. Qin, L. Wang, Q.L. Wang, M. Bai, R.L. Gao, Z.
  Ji, Y.R. Liu, F.L. Ma, Y.J. Shi, J. Su, Y.Y. Tan, J.Z. Tong, H.T. Xu, C.B.
  Xue, G.F. Xue, W. Yuan","The Lobster Eye Imager for Astronomy Onboard the SATech-01 Satellite","Accepted by RAA",,,,"astro-ph.IM hep-ex physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Lobster Eye Imager for Astronomy (LEIA), a pathfinder of the Wide-field
X-ray Telescope of the Einstein Probe (EP) mission, was successfully launched
onboard the SATech-01 satellite of the Chinese Academy of Sciences on 27 July
2022. In this paper, we introduce the design and on-ground test results of the
LEIA instrument. Using state-of-the-art Micro-Pore Optics (MPO), a wide
field-of-view (FoV) of 346 square degrees (18.6 degrees * 18.6 degrees) of the
X-ray imager is realized. An optical assembly composed of 36 MPO chips is used
to focus incident X-ray photons, and four large-format complementary
metal-oxide semiconductor (CMOS) sensors, each of 6 cm * 6 cm, are used as the
focal plane detectors. The instrument has an angular resolution of 4 - 8 arcmin
(in FWHM) for the central focal spot of the point spread function, and an
effective area of 2 - 3 cm2 at 1 keV in essentially all the directions within
the field of view. The detection passband is 0.5 - 4 keV in the soft X-rays and
the sensitivity is 2 - 3 * 10-11 erg s-1 cm-2 (about 1 mini-Crab) at 1,000
second observation. The total weight of LEIA is 56 kg and the power is 85 W.
The satellite, with a design lifetime of 2 years, operates in a Sun-synchronous
orbit of 500 km with an orbital period of 95 minutes. LEIA is paving the way
for future missions by verifying in flight the technologies of both novel
focusing imaging optics and CMOS sensors for X-ray observation, and by
optimizing the working setups of the instrumental parameters. In addition, LEIA
is able to carry out scientific observations to find new transients and to
monitor known sources in the soft X-ray band, albeit limited useful observing
time available.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:47:05 GMT""}]","2023-05-25"
"2305.14896","Krzysztof Oleszkiewicz","Krzysztof Oleszkiewicz","Boolean functions with small second order influences on the discrete
  cube",,,,,"math.PR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Motivated by a recent paper of Kevin Tanguy, in which the concept of second
order influences on the discrete cube and Gauss space has been investigated in
detail, the present note studies it in a more specific context of Boolean
functions on the discrete cube. Some bounds which Tanguy obtained as
applications of his more general approach are extended and complemented.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:48:19 GMT""}]","2023-05-25"
"2305.14897","Amita Kamath","Amita Kamath, Jack Hessel, Kai-Wei Chang","Text encoders are performance bottlenecks in contrastive vision-language
  models",,,,,"cs.CL cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Performant vision-language (VL) models like CLIP represent captions using a
single vector. How much information about language is lost in this bottleneck?
We first curate CompPrompts, a set of increasingly compositional image captions
that VL models should be able to capture (e.g., single object, to
object+property, to multiple interacting objects). Then, we train text-only
recovery probes that aim to reconstruct captions from single-vector text
representations produced by several VL models. This approach doesn't require
images, allowing us to test on a broader range of scenes compared to prior
work. We find that: 1) CLIP's text encoder falls short on object relationships,
attribute-object association, counting, and negations; 2) some text encoders
work significantly better than others; and 3) text-only recovery performance
predicts multi-modal matching performance on ControlledImCaps: a new evaluation
benchmark we collect+release consisting of fine-grained compositional
images+captions. Specifically -- our results suggest text-only recoverability
is a necessary (but not sufficient) condition for modeling compositional
factors in contrastive vision+language models. We release data+code.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:48:44 GMT""}]","2023-05-25"
"2305.14898","Keming Lu","Keming Lu, Xiaoman Pan, Kaiqiang Song, Hongming Zhang, Dong Yu,
  Jianshu Chen","PIVOINE: Instruction Tuning for Open-world Information Extraction",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of Open-world Information Extraction (Open-world IE),
which extracts comprehensive entity profiles from unstructured texts. Different
from the conventional closed-world setting of Information Extraction (IE),
Open-world IE considers a more general situation where entities and relations
could be beyond a predefined ontology. More importantly, we seek to develop a
large language model (LLM) that is able to perform Open-world IE to extract
desirable entity profiles characterized by (possibly fine-grained) natural
language instructions. We achieve this by finetuning LLMs using instruction
tuning. In particular, we construct INSTRUCTOPENWIKI, a substantial instruction
tuning dataset for Open-world IE enriched with a comprehensive corpus,
extensive annotations, and diverse instructions. We finetune the pretrained
BLOOM models on INSTRUCTOPENWIKI and obtain PIVOINE, an LLM for Open-world IE
with strong instruction-following capabilities. Our experiments demonstrate
that PIVOINE significantly outperforms traditional closed-world methods and
other LLM baselines, displaying impressive generalization capabilities on both
unseen instructions and out-of-ontology cases. Consequently, PIVOINE emerges as
a promising solution to tackle the open-world challenge in IE effectively.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:52:08 GMT""}]","2023-05-25"
"2305.14899","Emilio Martinez-Nunez","Luis Guerrero-Mendez, Anxo Lema-Saavedra, Elena Jimenez, Antonio
  Fernandez-Ramos, Emilio Martinez-Nunez","Gas-phase formation of glycolonitrile in the interstellar medium",,,,,"astro-ph.GA physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Our automated reaction discovery program, AutoMeKin, has been utilized to
investigate the formation of glycolonitrile (HOCH$_{2}$CN) in the gas phase
under the low temperatures of the interstellar medium (ISM). The feasibility of
a proposed pathway depends on the absence of barriers above the energy of
reactants and the availability of the suggested precursors in the ISM. Based on
these criteria, several radical-radical reactions and a radical-molecule
reaction have been identified as viable formation routes in the ISM. Among the
radical-radical reactions, OH+CH$_{2}$CN appears to be the most relevant,
considering the energy of the radicals and its ability to produce
glycolonitrile in a single step. However, our analysis reveals that this
reaction produces hydrogen isocyanide (HNC) and formaldehyde (CH$_{2}$O), with
rate coefficients ranging from (7.3-11.5)$\times$10$^{-10}$ cm$^3$
molecule$^{-1}$ s$^{-1}$ across the temperature range of 10-150 K. This finding
is particularly interesing given the persistently unexplained overabundance of
hydrogen isocyanide in the ISM. Among the radical-molecule reactions
investigated, the most promising one is OH+CH$_{2}$CNH, which forms
glycolonitrile and atomic hydrogen with rate coefficients in the range
(0.3-6.6)$\times$10$^{-10}$ cm$^3$ molecule$^{-1}$ s$^{-1}$ within the 10-150 K
temperature range. Our calculations indicate that the formation of both
hydrogen isocyanide and glycolonitrile is efficient under the harsh conditions
of the ISM.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:54:10 GMT""}]","2023-05-25"
"2305.14900","Jasper Ischebeck","Jasper Ischebeck","Central limit theorems for fringe trees in patricia tries",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give theorems about asymptotic normality of general additive functionals
on patricia tries in an i.i.d. setting, derived from results on tries by Janson
(2022). These theorems are applied to show asymptotic normality of the
distribution of random fringe trees in patricia tries. Formulas for asymptotic
mean and variance are given. The proportion of fringe trees with $k$ keys is
asymptotically, ignoring oscillations, given by $(1-\rho(k))/(H+J)k(k-1)$ with
the source entropy $H$, an entropy-like constant $J$, that is $H$ in the binary
case, and an exponentially decreasing function $\rho(k)$. Another application
gives asymptotic normality of the independence number.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:54:46 GMT""}]","2023-05-25"
"2305.14901","Wang Zhu","Wang Zhu, Jesse Thomason, Robin Jia","Chain-of-Questions Training with Latent Answers for Robust Multistep
  Question Answering","12 pages, 2 figures",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  We train a language model (LM) to robustly answer multistep questions by
generating and answering sub-questions. We propose Chain-of-Questions, a
framework that trains a model to generate sub-questions and sub-answers one at
a time by leveraging human annotated question decomposition meaning
representation (QDMR). The key technical challenge is that QDMR only contains
sub-questions but not answers to those sub-questions, so we treat sub-answers
as latent variables and optimize them using a novel dynamic mixture of Hard-EM
and MAPO. Chain-of-Questions greatly outperforms strong neuro-symbolic methods
by 9.0 F1 on DROP contrast set, and outperforms GPT-3.5 by 24.3 F1 on HOTPOTQA
adversarial set, thus demonstrating the effectiveness and robustness of our
framework.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:55:08 GMT""}]","2023-05-25"
"2305.14902","Yuxia Wang","Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem
  Shelmanov, Akim Tsvigun, Chenxi Whitehouse, Osama Mohammed Afzal, Tarek
  Mahmoud, Alham Fikri Aji, Preslav Nakov","M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box
  Machine-Generated Text Detection","11 pages",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have demonstrated remarkable capability to
generate fluent responses to a wide variety of user queries, but this has also
resulted in concerns regarding the potential misuse of such texts in
journalism, educational, and academic context. In this work, we aim to develop
automatic systems to identify machine-generated text and to detect potential
misuse. We first introduce a large-scale benchmark M4, which is
multi-generator, multi-domain, and multi-lingual corpus for machine-generated
text detection. Using the dataset, we experiment with a number of methods and
we show that it is challenging for detectors to generalize well on unseen
examples if they are either from different domains or are generated by
different large language models. In such cases, detectors tend to misclassify
machine-generated text as human-written. These results show that the problem is
far from solved and there is a lot of room for improvement. We believe that our
dataset M4, which covers different generators, domains and languages, will
enable future research towards more robust approaches for this pressing
societal problem. The M4 dataset is available at
https://github.com/mbzuai-nlp/M4.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:55:11 GMT""}]","2023-05-25"
"2305.14903","Francesco Marin","P. Vezio, M. Bonaldi, A. Borrielli, F. Marino, B. Morana, P.M. Sarro,
  E. Serra, and F. Marin","Optical self-cooling of a membrane oscillator in a cavity optomechanical
  experiment at room temperature",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal noise is a major obstacle to observing quantum behavior in
macroscopic systems. To mitigate its effect, quantum optomechanical experiments
are typically performed in a cryogenic environment. However, this condition
represents a considerable complication in the transition from fundamental
research to quantum technology applications. It is therefore interesting to
explore the possibility of achieving the quantum regime in room temperature
experiments. In this work we test the limits of sideband cooling vibration
modes of a SiN membrane in a cavity optomechanical experiment. We obtain an
effective temperature of a few mK, corresponding to a phononic occupation
number of around 100. We show that further cooling is prevented by the excess
classical noise of our laser source, and we outline the road toward the
achievement of ground state cooling
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:56:23 GMT""}]","2023-05-25"
"2305.14904","Alexander Spangher","Alexander Spangher, Nanyun Peng, Jonathan May, Emilio Ferrara","Identifying Informational Sources in News Articles","13 pages",,,,"cs.CL cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  News articles are driven by the informational sources journalists use in
reporting. Modeling when, how and why sources get used together in stories can
help us better understand the information we consume and even help journalists
with the task of producing it. In this work, we take steps toward this goal by
constructing the largest and widest-ranging annotated dataset, to date, of
informational sources used in news writing. We show that our dataset can be
used to train high-performing models for information detection and source
attribution. We further introduce a novel task, source prediction, to study the
compositionality of sources in news articles. We show good performance on this
task, which we argue is an important proof for narrative science exploring the
internal structure of news articles and aiding in planning-based language
generation, and an important step towards a source-recommendation system to aid
journalists.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:56:35 GMT""}]","2023-05-25"
"2305.14905","Tinatin Baratashvili","Tinatin Baratashvili, Christine Verbeke, Rony Keppens, Stefaan Poedts","Exploring the effects of numerical methods and slope limiters in
  heliospheric modeling","17 pages, 9 figures, 4 tables, to appear in Sun and Geosphere",,,,"astro-ph.SR physics.comp-ph physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coronal mass ejections (CMEs) are large eruptions close to the solar surface,
where plasma is ejected outwards into space at large speeds. When directed
towards Earth, they interfere with Earth's magnetic fields and cause strong
geo-effective storms. In order to mitigate the potential damage, forecasting
tools are implemented. Recently, a novel heliospheric modelling tool, Icarus,
has been implemented, which exploits the open-source framework MPI-AMRVAC as
its core MHD solver. This new model efficiently performs 3D MHD simulations of
the solar wind and the evolution of interplanetary CMEs with the help of
advanced techniques, such as adaptive mesh refinement and gradual radial grid
stretching. The numerical methods applied in the simulations can have
significant effects on the simulation results and on the efficiency of the
model. In this study, the effect of different combinations of numerical schemes
and slope limiters, for reconstructing edge-based variabes used in fluxes, is
considered. We explore frequently exploited combinations from the available
numerical schemes in MPI-AMRVAC: TVDLF, HLL and HLLC along with the slope
limiters 'woodward', 'minmod', 'vanleer', and 'koren'. For analysis purposes,
we selected one particular solar wind configuration and studied the influence
on variables at 1 AU in the equatorial plane. The goal is to find the optimal
combination to produce accurate results fast and in a robust way so that the
model can be reliable for day-to-day use by space weather scientists. As a
conclusion, the best result assessed with these two criteria is the combination
of the TVDLF scheme with the 'woodward' limiter.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:56:35 GMT""}]","2023-05-25"
"2305.14906","Alba Garc\'ia-Ruiz","Alba Garc\'ia-Ruiz","A relation between two different formulations of the Berry's conjecture","19 pages",,,,"math.SP math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Random Wave Conjecture of M. V. Berry is the heuristic that
eigenfunctions of a classically chaotic system should behave like Gaussian
random fields, in the large eigenvalue limit. In this work we collect some
definitions and properties of Gaussian random fields, and show that the
formulation of the Berry's conjecture proposed using local weak limits is
equivalent to the one that is based on the Benjamini-Schramm convergence.
Finally, we see that both these formulations of the Berry's property imply
another property known as inverse localization that relates high energy
eigenfunctions and solutions to the Euclidean Helmholtz equation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:56:38 GMT""}]","2023-05-25"
"2305.14907","Shivanshu Gupta","Shivanshu Gupta, Matt Gardner, Sameer Singh","Coverage-based Example Selection for In-Context Learning",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In-context learning (ICL), the ability of large language models to perform
novel tasks by conditioning on a prompt with a few task examples, requires
demonstrations that are informative about the test instance. The standard
approach of independently selecting the most similar examples selects redundant
demonstrations while overlooking important information. This work proposes a
framework for assessing the informativeness of demonstrations based on their
coverage of salient aspects (e.g., reasoning patterns) of the test input. Using
this framework, we show that contextual token embeddings effectively capture
these salient aspects, and their recall measured using BERTScore-Recall (BSR)
yields a reliable measure of informativeness. Further, we extend recall metrics
like BSR to propose their set versions to find maximally informative sets of
demonstrations. On 6 complex compositional generation tasks and 7 diverse LLMs,
we show that Set-BSR outperforms the standard similarity-based approach by up
to 16% on average and, despite being learning-free, often surpasses methods
that leverage task or LLM-specific training.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:58:28 GMT""}]","2023-05-25"
"2305.14908","Anthony Chen","Anthony Chen, Panupong Pasupat, Sameer Singh, Hongrae Lee and Kelvin
  Guu","PURR: Efficiently Editing Language Model Hallucinations by Denoising
  Language Model Corruptions",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The remarkable capabilities of large language models have been accompanied by
a persistent drawback: the generation of false and unsubstantiated claims
commonly known as ""hallucinations"". To combat this issue, recent research has
introduced approaches that involve editing and attributing the outputs of
language models, particularly through prompt-based editing. However, the
inference cost and speed of using large language models for editing currently
bottleneck prompt-based methods. These bottlenecks motivate the training of
compact editors, which is challenging due to the scarcity of training data for
this purpose. To overcome these challenges, we exploit the power of large
language models to introduce corruptions (i.e., noise) into text and
subsequently fine-tune compact editors to denoise the corruptions by
incorporating relevant evidence. Our methodology is entirely unsupervised and
provides us with faux hallucinations for training in any domain. Our Petite
Unsupervised Research and Revision model, PURR, not only improves attribution
over existing editing methods based on fine-tuning and prompting, but also
achieves faster execution times by orders of magnitude.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:59:00 GMT""}]","2023-05-25"
"2305.14909","Lin Guan","Lin Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati","Leveraging Pre-trained Large Language Models to Construct and Utilize
  World Models for Model-based Task Planning",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a growing interest in applying pre-trained large language models
(LLMs) to planning problems. However, methods that use LLMs directly as
planners are currently impractical due to several factors, including limited
correctness of plans, strong reliance on feedback from interactions with
simulators or even the actual environment, and the inefficiency in utilizing
human feedback. In this work, we introduce a novel alternative paradigm that
constructs an explicit world (domain) model in planning domain definition
language (PDDL) and then uses it to plan with sound domain-independent
planners. To address the fact that LLMs may not generate a fully functional
PDDL model initially, we employ LLMs as an interface between PDDL and sources
of corrective feedback, such as PDDL validators and humans. For users who lack
a background in PDDL, we show that LLMs can translate PDDL into natural
language and effectively encode corrective feedback back to the underlying
domain model. Our framework not only enjoys the correctness guarantee offered
by the external planners but also reduces human involvement by allowing users
to correct domain models at the beginning, rather than inspecting and
correcting (through interactive prompting) every generated plan as in previous
work. On two IPC domains and a Household domain that is more complicated than
commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be
leveraged to produce high-quality PDDL models for over 40 actions, and the
corrected PDDL models are then used to successfully solve 48 challenging
planning tasks. Resources including the source code will be released at:
https://guansuns.github.io/pages/llm-dm.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:59:15 GMT""}]","2023-05-25"
"2305.14910","Muhao Chen","Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen","From Shortcuts to Triggers: Backdoor Defense with Denoised PoE","Work in Progress",,,,"cs.CL cs.AI cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Language models are often at risk of diverse backdoor attacks, especially
data poisoning. Thus, it is important to investigate defense solutions for
addressing them. Existing backdoor defense methods mainly focus on backdoor
attacks with explicit triggers, leaving a universal defense against various
backdoor attacks with diverse triggers largely unexplored. In this paper, we
propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised
Product-of-Experts), which is inspired by the shortcut nature of backdoor
attacks, to defend various backdoor attacks. DPoE consists of two models: a
shallow model that captures the backdoor shortcuts and a main model that is
prevented from learning the backdoor shortcuts. To address the label flip
caused by backdoor attackers, DPoE incorporates a denoising design. Experiments
on SST-2 dataset show that DPoE significantly improves the defense performance
against various types of backdoor triggers including word-level,
sentence-level, and syntactic triggers. Furthermore, DPoE is also effective
under a more challenging but practical setting that mixes multiple types of
trigger.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:59:25 GMT""}]","2023-05-25"
"2305.14911","Qian Zhang","Jianqing Chen and Qian Zhang","Ground states solution of Nehari-Poho\v{z}aev type for periodic
  quasilinear Schr\""{o}dinger system",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with a quasilinear Schr\""{o}dinger system in $\mathbb
R^{N}$ $$\left\{\aligned &-\Delta
u+A(x)u-\frac{1}{2}\triangle(u^{2})u=\frac{2\alpha}{\alpha+\beta}|u|^{\alpha-2}u|v|^{\beta},\\
&-\Delta
v+B(x)v-\frac{1}{2}\triangle(v^{2})v=\frac{2\beta}{\alpha+\beta}|u|^{\alpha}|v|^{\beta-2}v,\\
& u(x)\to 0\ \hbox{and}\quad v(x)\to 0\ \hbox{as}\ |x|\to
\infty,\endaligned\right. $$ where $\alpha,\beta>1$ and
$2<\alpha+\beta<\frac{4N}{N-2}$ ($N \geq 3$). $A(x)$ and $B(x)$ are two
periodic functions. By minimization under a convenient constraint and
concentration-compactness lemma, we prove the existence of ground states
solution. Our result covers the case of $\alpha+\beta\in(2,4)$ which seems to
be the first result for coupled quasilinear Schr\""{o}dinger system in the
periodic situation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:01:23 GMT""}]","2023-05-25"
"2305.14912","Yu-Bang Zheng","Yu-Bang Zheng, Xi-Le Zhao, Junhua Zeng, Chao Li, Qibin Zhao, Heng-Chao
  Li, Ting-Zhu Huang","SVDinsTN: An Integrated Method for Tensor Network Representation with
  Efficient Structure Search",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor network (TN) representation is a powerful technique for data analysis
and machine learning. It practically involves a challenging TN structure search
(TN-SS) problem, which aims to search for the optimal structure to achieve a
compact representation. Existing TN-SS methods mainly adopt a bi-level
optimization method that leads to excessive computational costs due to repeated
structure evaluations. To address this issue, we propose an efficient
integrated (single-level) method named SVD-inspired TN decomposition
(SVDinsTN), eliminating the need for repeated tedious structure evaluation. By
inserting a diagonal factor for each edge of the fully-connected TN, we
calculate TN cores and diagonal factors simultaneously, with factor sparsity
revealing the most compact TN structure. Experimental results on real-world
data demonstrate that SVDinsTN achieves approximately $10^2\sim{}10^3$ times
acceleration in runtime compared to the existing TN-SS methods while
maintaining a comparable level of representation ability.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:02:01 GMT""}]","2023-05-25"
"2305.14913","Qianhui Wu","Tingting Ma, Qianhui Wu, Huiqiang Jiang, B\""orje F. Karlsson, Tiejun
  Zhao, Chin-Yew Lin","CoLaDa: A Collaborative Label Denoising Framework for Cross-lingual
  Named Entity Recognition","ACL 2023. Our code is available at
  https://github.com/microsoft/vert-papers/tree/master/papers/CoLaDa",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-lingual named entity recognition (NER) aims to train an NER system that
generalizes well to a target language by leveraging labeled data in a given
source language. Previous work alleviates the data scarcity problem by
translating source-language labeled data or performing knowledge distillation
on target-language unlabeled data. However, these methods may suffer from label
noise due to the automatic labeling process. In this paper, we propose CoLaDa,
a Collaborative Label Denoising Framework, to address this problem.
Specifically, we first explore a model-collaboration-based denoising scheme
that enables models trained on different data sources to collaboratively
denoise pseudo labels used by each other. We then present an
instance-collaboration-based strategy that considers the label consistency of
each token's neighborhood in the representation space for denoising.
Experiments on different benchmark datasets show that the proposed CoLaDa
achieves superior results compared to previous methods, especially when
generalizing to distant languages.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:03:01 GMT""}]","2023-05-25"
"2305.14914","Zhitong Xiong","Zhitong Xiong, Sining Chen, Yi Wang, Lichao Mou, Xiao Xiang Zhu","GAMUS: A Geometry-aware Multi-modal Semantic Segmentation Benchmark for
  Remote Sensing Data","13 pages",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Geometric information in the normalized digital surface models (nDSM) is
highly correlated with the semantic class of the land cover. Exploiting two
modalities (RGB and nDSM (height)) jointly has great potential to improve the
segmentation performance. However, it is still an under-explored field in
remote sensing due to the following challenges. First, the scales of existing
datasets are relatively small and the diversity of existing datasets is
limited, which restricts the ability of validation. Second, there is a lack of
unified benchmarks for performance assessment, which leads to difficulties in
comparing the effectiveness of different models. Last, sophisticated
multi-modal semantic segmentation methods have not been deeply explored for
remote sensing data. To cope with these challenges, in this paper, we introduce
a new remote-sensing benchmark dataset for multi-modal semantic segmentation
based on RGB-Height (RGB-H) data. Towards a fair and comprehensive analysis of
existing methods, the proposed benchmark consists of 1) a large-scale dataset
including co-registered RGB and nDSM pairs and pixel-wise semantic labels; 2) a
comprehensive evaluation and analysis of existing multi-modal fusion strategies
for both convolutional and Transformer-based networks on remote sensing data.
Furthermore, we propose a novel and effective Transformer-based intermediary
multi-modal fusion (TIMF) module to improve the semantic segmentation
performance through adaptive token-level multi-modal fusion.The designed
benchmark can foster future research on developing new methods for multi-modal
learning on remote sensing data. Extensive analyses of those methods are
conducted and valuable insights are provided through the experimental results.
Code for the benchmark and baselines can be accessed at
\url{https://github.com/EarthNets/RSI-MMSegmentation}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:03:18 GMT""}]","2023-05-25"
"2305.14915","Dennis Trautwein","Harald Garcke and Dennis Trautwein","Approximation and existence of a viscoelastic phase-field model for
  tumour growth in two and three dimensions",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, we present a phase-field model for tumour growth, where a
diffuse interface separates a tumour from the surrounding host tissue. In our
model, we consider transport processes by an internal, non-solenoidal velocity
field. We include viscoelastic effects with the help of a general Oldroyd-B
type description with relaxation and possible stress generation by growth. The
elastic energy density is coupled to the phase-field variable which allows to
model invasive growth towards areas with less mechanical resistance. The main
analytical result is the existence of weak solutions in two and three space
dimensions in the case of additional stress diffusion. The idea behind the
proof is to use a numerical approximation with a fully-practical, stable and
(subsequence) converging finite element scheme. The physical properties of the
model are preserved with the help of a regularization technique, uniform
estimates and a limit passage on the fully-discrete level. Finally, we
illustrate the practicability of the discrete scheme with the help of numerical
simulations in two and three dimensions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:03:28 GMT""}]","2023-05-25"
"2305.14916","Louis Sharrock","Louis Sharrock, Daniel Dodd, Christopher Nemeth","CoinEM: Tuning-Free Particle-Based Variational Inference for Latent
  Variable Models",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce two new particle-based algorithms for learning latent variable
models via marginal maximum likelihood estimation, including one which is
entirely tuning-free. Our methods are based on the perspective of marginal
maximum likelihood estimation as an optimization problem: namely, as the
minimization of a free energy functional. One way to solve this problem is to
consider the discretization of a gradient flow associated with the free energy.
We study one such approach, which resembles an extension of the popular Stein
variational gradient descent algorithm. In particular, we establish a descent
lemma for this algorithm, which guarantees that the free energy decreases at
each iteration. This method, and any other obtained as the discretization of
the gradient flow, will necessarily depend on a learning rate which must be
carefully tuned by the practitioner in order to ensure convergence at a
suitable rate. With this in mind, we also propose another algorithm for
optimizing the free energy which is entirely learning rate free, based on coin
betting techniques from convex optimization. We validate the performance of our
algorithms across a broad range of numerical experiments, including several
high-dimensional settings. Our results are competitive with existing
particle-based methods, without the need for any hyperparameter tuning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:03:55 GMT""}]","2023-05-25"
"2305.14917","Gijs Wijnholds","Gijs Wijnholds and Michael Moortgat","Structural Ambiguity and its Disambiguation in Language Model Based
  Parsers: the Case of Dutch Clause Relativization",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  This paper addresses structural ambiguity in Dutch relative clauses. By
investigating the task of disambiguation by grounding, we study how the
presence of a prior sentence can resolve relative clause ambiguities. We apply
this method to two parsing architectures in an attempt to demystify the parsing
and language model components of two present-day neural parsers. Results show
that a neurosymbolic parser, based on proof nets, is more open to data bias
correction than an approach based on universal dependencies, although both
setups suffer from a comparable initial data bias.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:04:18 GMT""}]","2023-05-25"
"2305.14918","Xingxing Zuo","Xingxing Zuo, Nan Yang, Nathaniel Merrill, Binbin Xu, Stefan
  Leutenegger","Incremental Dense Reconstruction from Monocular Video with Guided Sparse
  Feature Volume Fusion","8 pages, 5 figures, RA-L 2023",,"10.1109/LRA.2023.3273509",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Incrementally recovering 3D dense structures from monocular videos is of
paramount importance since it enables various robotics and AR applications.
Feature volumes have recently been shown to enable efficient and accurate
incremental dense reconstruction without the need to first estimate depth, but
they are not able to achieve as high of a resolution as depth-based methods due
to the large memory consumption of high-resolution feature volumes. This letter
proposes a real-time feature volume-based dense reconstruction method that
predicts TSDF (Truncated Signed Distance Function) values from a novel
sparsified deep feature volume, which is able to achieve higher resolutions
than previous feature volume-based methods, and is favorable in large-scale
outdoor scenarios where the majority of voxels are empty. An uncertainty-aware
multi-view stereo (MVS) network is leveraged to infer initial voxel locations
of the physical surface in a sparse feature volume. Then for refining the
recovered 3D geometry, deep features are attentively aggregated from multiview
images at potential surface locations, and temporally fused. Besides achieving
higher resolutions than before, our method is shown to produce more complete
reconstructions with finer detail in many cases. Extensive evaluations on both
public and self-collected datasets demonstrate a very competitive real-time
reconstruction result for our method compared to state-of-the-art
reconstruction methods in both indoor and outdoor settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:06:01 GMT""}]","2023-05-25"
"2305.14919","Pawan Goyal","Bishal Santra, Sakya Basak, Abhinandan De, Manish Gupta, Pawan Goyal","Frugal Prompting for Dialog Models","First two authors have equal contribution",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The use of large language models (LLMs) in natural language processing (NLP)
tasks is rapidly increasing, leading to changes in how researchers approach
problems in the field. To fully utilize these models' abilities, a better
understanding of their behavior for different input protocols is required. With
LLMs, users can directly interact with the models through a text-based
interface to define and solve various tasks. Hence, understanding the
conversational abilities of these LLMs, which may not have been specifically
trained for dialog modeling, is also important. This study examines different
approaches for building dialog systems using LLMs by considering various
aspects of the prompt. As part of prompt tuning, we experiment with various
ways of providing instructions, exemplars, current query and additional
context. The research also analyzes the representations of dialog history that
have the optimal usable-information density. Based on the findings, the paper
suggests more compact ways of providing dialog history information while
ensuring good performance and reducing model's inference-API costs. The
research contributes to a better understanding of how LLMs can be effectively
used for building interactive systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:06:49 GMT""}]","2023-05-25"
"2305.14920","Andreas D\""opp","Andreas D\""opp, Igor Andriyash, and Kim Ta Phuoc","All-optical Compton scattering at shallow interaction angles",,,,,"physics.acc-ph physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  All-optical Compton sources combine laser wakefield accelerators and intense
scattering pulses to generate ultrashort bursts of backscattered radiation. The
scattering pulse plays the role of a short-period undulator in which
relativistic electrons oscillate and emit x-ray radiation. To date, most of the
working laser-plasma accelerators operate preferably at energies of a few
hundreds of MeV and the Compton sources developed so far produce radiation in
the range from hundreds of keV to a few MeV. However, for such applications as
medical imaging and tomography the relevant energy range is 10-100 keV. In this
article, we discuss different scattering geometries for the generation of
X-rays in this range. Through numerical simulations, we study the influence of
electron beam parameters on the backscattered photons. We find that the
spectral bandwidth remains constant for beams of the same emittance regardless
of the scattering geometry. A shallow interaction angle of 30 degrees or less
seems particularly promising for imaging applications given parameters of
existing laser-plasma accelerators. Finally, we discuss the influence of the
radiation properties for potential applications in medical imaging and
non-destructive testing.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:07:30 GMT""}]","2023-05-25"
"2305.14921","Juanjuan Xu","Juanjuan Xu and Huanshui Zhang","Decentralized Control of Linear Systems with Private Input and
  Measurement Information",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the linear quadratic (LQ) optimal control problem of
linear systems with private input and measurement information. The main
challenging lies in the unavailability of other regulators' historical input
information. To overcome this difficulty, we introduce a kind of novel
observers by using the private input and measurement information and
accordingly design a kind of new decentralized controllers. In particular, it
is verified that the corresponding cost function under the proposed
decentralized controllers are asymptotically optimal as comparison with the
optimal cost under optimal state-feedback controller. The presented results in
this paper are new to the best of our knowledge, which represent the
fundamental contribution to classical decentralized control.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:07:38 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 03:29:04 GMT""}]","2023-05-29"
"2305.14922","Antonio Di Francesco","Matteo Colangeli, Antonio Di Francesco, Lamberto Rondoni","Finite reservoirs and irreversibility corrections to Hamiltonian systems
  statistics",,,,,"cond-mat.stat-mech math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We consider several Hamiltonian systems perturbed by external agents, that
preserve their Hamiltonian structure. We investigate the corrections to the
canonical statistics resulting from coupling such systems with possibly large
but finite reservoirs, and from the onset of processes breaking the time
reversal symmetry. We analyze exactly solvable oscillators systems, and perform
simulations of relatively more complex ones. This indicates that the standard
statistical mechanical formalism needs to be adjusted, in the ever more
investigated nano-scale science and technology. In particular, the hypothesis
that heat reservoirs be considered infinite and be described by the classical
ensembles is found to be critical when exponential quantities are considered,
since the large size limit may not coincide with the infinite size canonical
result. Furthermore, process-dependent emergent irreversibility affects
ensemble averages, effectively frustrating, on a statistical level, the time
reversal invariance of Hamiltonian dynamics, that is used to obtain numerous
results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:09:13 GMT""}]","2023-05-25"
"2305.14923","Alberto Mayorgas","M. Calixto, A. Mayorgas, N. A. Cordero, E. Romera, O. Casta\~nos","Faraday rotation and transmittance as markers of topological phase
  transitions in 2D materials","15 pages, 11 figures, including supplemental material with 5 pages
  and 4 figures, 3 animated gifs",,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We analyze the magneto-optical conductivity (and related magnitudes like
transmittance and Faraday rotation of the irradiated polarized light) of some
elemental two-dimensional Dirac materials of group IV (graphene analogues,
buckled honeycomb lattices, like silicene, germanene, stannane, etc.), group V
(phosphorene), and zincblende heterostructures (like HgTe/CdTe quantum wells)
near the Dirac and gamma points, under out-of-plane magnetic and electric
fields, to characterize topological-band insulator phase transitions and their
critical points. We provide plots of the Faraday angle and transmittance as a
function of the polarized light frequency, for different external electric and
magnetic fields, chemical potential, HgTe layer thickness and temperature, to
tune the material magneto-optical properties. We have shown that
absortance/transmittance acquires extremal values at the critical point, where
the Faraday angle changes sign, thus providing fine markers of the topological
phase transition.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:09:33 GMT""}]","2023-05-25"
"2305.14924","Zhenyu Zhang","Zhenyu Zhang, Yehui Hou, Minyong Guo, Bin Chen","Light rings and shadows of rotating black holes in the semiclassical
  gravity with trace anomaly","14 pages, 7 figures",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  In a recent work by Fernandes [arXiv:2305.10382], an exact stationary and
axisymmetric solution was discovered in semiclassical gravity with type-A trace
anomaly, identified as a quantum-corrected version of the Kerr black hole. This
discovery presents exciting research opportunities for observing non-circular
spacetimes. In this study, we explore the light rings and shadow of this black
hole solution. Our investigation reveals that there exist prograde and
retrograde normal light rings, whose radii increase monotonically with the
coupling parameter $\alpha$. We also observe that when $\alpha$ is negative,
the shadow area for the quantum-corrected black hole is smaller than that of
the Kerr black hole, whereas when $\alpha$ is positive, the area is larger.
Furthermore, the NHEKline for nearly extreme black hole disappears when
$\alpha$ is greater than zero, while it appears for negative $\alpha$, even if
the spin is not too high. Such line sinks in the middle part when $|\alpha|$ is
relatively large if $\alpha$ is less than zero.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:09:38 GMT""}]","2023-05-25"
"2305.14925","Dnyaneshwar Tadas","S. D. Katore, S. P. Hatkar, D. P. Tadas","Accelerating Kaluza-Klein Universe in Modified Theory of Gravitation","20 Pages, 08 Figures","Astrophysics 66 98-113 (2023)","10.1007/s10511-023-09773-3",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this paper is to study the Kaluza-Klein universe in the
context of the $f(R,T)$ gravity theory using magnetized strange quark matter
(MSQM). To obtain exact solutions of field equations, we assume two types of
volumetric expansion: power law and exponential law volumetric expansions. The
violation of energy conditions has been studied. The physical and geometrical
properties of the examined model have also been investigated thoroughly.
Keywords: Kaluza-Klein metric, Magnetized Strange Quark Matter, Power and
Exponential law, $f(R,T)$ gravity.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:09:44 GMT""}]","2023-05-25"
"2305.14926","Xingchen Wan","Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Hanjun Dai, Julian Martin
  Eisenschlos, Sercan O. Arik, Tomas Pfister","Universal Self-adaptive Prompting","10 pages, 3 figures, 4 tables (19 pages, 5 figures and 9 tables
  including references and appendices)",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hallmark of modern large language models (LLMs) is their impressive general
zero-shot and few-shot abilities, often elicited through prompt-based and/or
in-context learning. However, while highly coveted and being the most general,
zero-shot performances in LLMs are still typically weaker due to the lack of
guidance and the difficulty of applying existing automatic prompt design
methods in general tasks when ground-truth labels are unavailable. In this
study, we address this by presenting Universal Self-adaptive Prompting (USP),
an automatic prompt design approach specifically tailored for zero-shot
learning (while compatible with few-shot). Requiring only a small amount of
unlabeled data & an inference-only LLM, USP is highly versatile: to achieve
universal prompting, USP categorizes a possible NLP task into one of the three
possible task types, and then uses a corresponding selector to select the most
suitable queries & zero-shot model-generated responses as
pseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a
fully automated way. We evaluate zero-shot USP with two PaLM models, and
demonstrate performances that are considerably stronger than standard zero-shot
baselines and are comparable to or even superior than few-shot baselines across
more than 20 natural language understanding (NLU) and natural language
generation (NLG) tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:09:48 GMT""}]","2023-05-25"
"2305.14927","Cheng Wang","Rui-Qian Li and Yi-Wei Shen and Bao-De Lin and Jingyi Yu and Xuming He
  and Cheng Wang","Scalable wavelength-multiplexing photonic reservoir computing",,,,,"physics.optics eess.SP","http://creativecommons.org/licenses/by/4.0/","  Photonic reservoir computing (PRC) is a special hardware recurrent neural
network, which is featured with fast training speed and low training cost. This
work shows a wavelength-multiplexing PRC architecture, taking advantage of the
numerous longitudinal modes in a Fabry-Perot semiconductor laser. These modes
construct connected physical neurons in parallel, while an optical feedback
loop provides interactive virtual neurons in series. We experimentally
demonstrate a four-channel wavelength-multiplexing PRC, which runs four times
faster than the single-channel case. It is proved that the multiplexing PRC
exhibits superior performance on the task of signal equalization in an optical
fiber communication link. Particularly, this scheme is highly scalable owing to
the rich mode resources in Fabry-Perot lasers.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:10:06 GMT""}]","2023-05-25"
"2305.14928","Kellin Pelrine","Kellin Pelrine, Meilina Reksoprodjo, Caleb Gupta, Joel Christoph,
  Reihaneh Rabbany","Towards Reliable Misinformation Mitigation: Generalization, Uncertainty,
  and GPT-4",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Misinformation poses a critical societal challenge, and current approaches
have yet to produce an effective solution. We propose focusing on
generalization, soft classification, and leveraging recent large language
models to create more practical tools in contexts where perfect predictions
remain unattainable. We begin by demonstrating that GPT-4 and other language
models can outperform existing methods in the literature. Next, we explore
their generalization, revealing that GPT-4 and RoBERTa-large exhibit critical
differences in failure modes, which offer potential for significant performance
improvements. Finally, we show that these models can be employed in soft
classification frameworks to better quantify uncertainty. We find that models
with inferior hard classification results can achieve superior soft
classification performance. Overall, this research lays groundwork for future
tools that can drive real-world progress on misinformation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:10:20 GMT""}]","2023-05-25"
"2305.14929","Bodhisattwa Prasad Majumder","EunJeong Hwang, Bodhisattwa Prasad Majumder, Niket Tandon","Aligning Language Models to User Opinions",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  An important aspect of developing LLMs that interact with humans is to align
models' behavior to their users. It is possible to prompt an LLM into behaving
as a certain persona, especially a user group or ideological persona the model
captured during its pertaining stage. But, how to best align an LLM with a
specific user and not a demographic or ideological group remains an open
question. Mining public opinion surveys (by Pew Research), we find that the
opinions of a user and their demographics and ideologies are not mutual
predictors. We use this insight to align LLMs by modeling both user opinions as
well as user demographics and ideology, achieving up to 7 points accuracy gains
in predicting public opinions from survey questions across a broad set of
topics. In addition to the typical approach of prompting LLMs with demographics
and ideology, we discover that utilizing the most relevant past opinions from
individual users enables the model to predict user opinions more accurately.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:11:11 GMT""}]","2023-05-25"
"2305.14930","Leonard Salewski","Leonard Salewski, Stephan Alaniz, Isabel Rio-Torto, Eric Schulz,
  Zeynep Akata","In-Context Impersonation Reveals Large Language Models' Strengths and
  Biases",,,,,"cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In everyday conversations, humans can take on different roles and adapt their
vocabulary to their chosen roles. We explore whether LLMs can take on, that is
impersonate, different roles when they generate text in-context. We ask LLMs to
assume different personas before solving vision and language tasks. We do this
by prefixing the prompt with a persona that is associated either with a social
identity or domain expertise. In a multi-armed bandit task, we find that LLMs
pretending to be children of different ages recover human-like developmental
stages of exploration. In a language-based reasoning task, we find that LLMs
impersonating domain experts perform better than LLMs impersonating non-domain
experts. Finally, we test whether LLMs' impersonations are complementary to
visual information when describing different categories. We find that
impersonation can improve performance: an LLM prompted to be a bird expert
describes birds better than one prompted to be a car expert. However,
impersonation can also uncover LLMs' biases: an LLM prompted to be a man
describes cars better than one prompted to be a woman. These findings
demonstrate that LLMs are capable of taking on diverse roles and that this
in-context impersonation can be used to uncover their hidden strengths and
biases.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:13:15 GMT""}]","2023-05-25"
"2305.14931","The ATLAS Collaboration","ATLAS Collaboration","Search for Majorana neutrinos in same-sign $WW$ scattering events from
  $pp$ collisions at $\sqrt{s}=13$ TeV","36 pages in total, author list starting page 19, 3 figures, 1 table,
  submitted to EPJC. All figures including auxiliary figures are available at
  https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/EXOT-2020-06/",,,"CERN-EP-2023-099","hep-ex","http://creativecommons.org/licenses/by/4.0/","  A search for Majorana neutrinos in same-sign $WW$ scattering events is
presented. The analysis uses $\sqrt{s}= 13$ TeV proton-proton collision data
with an integrated luminosity of 140 fb$^{-1}$ recorded during 2015-2018 by the
ATLAS detector at the Large Hadron Collider. The analysis targets final states
including exactly two same-sign muons and at least two hadronic jets well
separated in rapidity. The modelling of the main backgrounds, from Standard
Model same-sign $WW$ scattering and $WZ$ production, is constrained with data
in dedicated signal-depleted control regions. The distribution of the
transverse momentum of the second-hardest muon is used to search for signals
originating from a heavy Majorana neutrino with a mass between 50 GeV and 20
TeV. No significant excess is observed over the background expectation. The
results are interpreted in a benchmark scenario of the Phenomenological Type-I
Seesaw model. In addition, the sensitivity to the Weinberg operator is
investigated. Upper limits at the 95% confidence level are placed on the
squared muon-neutrino-heavy-neutrino mass-mixing matrix element $\vert V_{\mu
N} \vert^{2}$ as a function of the heavy Majorana neutrino's mass $m_N$, and on
the effective $\mu\mu$ Majorana neutrino mass $|m_{\mu\mu}|$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:13:37 GMT""}]","2023-05-25"
"2305.14932","Fani Derveni Dr.","Fani Derveni, Arefeh Abbasi, Pedro M. Reis","Defect-Defect Interactions in the Buckling of Imperfect Spherical Shells",,,,,"cond-mat.soft","http://creativecommons.org/publicdomain/zero/1.0/","  We perform finite element simulations to study the impact of defect-defect
interactions on the pressure-induced buckling of thin, elastic, spherical
shells containing two dimpled imperfections. Throughout, we quantify the
critical buckling pressure of these shells using their knockdown factor. We
examine cases featuring either identical or different geometric defects and
systematically explore the parameter space, including the angular separation
between the defects, their widths and amplitudes, and the radius-to-thickness
ratio of the shell. As the angular separation between the defects is increased,
the buckling strength initially decreases, then increases before reaching a
plateau. Our primary finding is that the onset of defect-defect interactions,
as quantified by a characteristic length scale associated with the onset of the
plateau, is set by the critical buckling wavelength reported in the classic
shell-buckling literature. Beyond this threshold, within the plateau regime,
the buckling behavior of the shell is dictated by the largest defect.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:14:47 GMT""}]","2023-05-25"
"2305.14933","Rui-Chen Zheng","Rui-Chen Zheng, Yang Ai, Zhen-Hua Ling","Incorporating Ultrasound Tongue Images for Audio-Visual Speech
  Enhancement through Knowledge Distillation","To be published in InterSpeech 2023",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Audio-visual speech enhancement (AV-SE) aims to enhance degraded speech along
with extra visual information such as lip videos, and has been shown to be more
effective than audio-only speech enhancement. This paper proposes further
incorporating ultrasound tongue images to improve lip-based AV-SE systems'
performance. Knowledge distillation is employed at the training stage to
address the challenge of acquiring ultrasound tongue images during inference,
enabling an audio-lip speech enhancement student model to learn from a
pre-trained audio-lip-tongue speech enhancement teacher model. Experimental
results demonstrate significant improvements in the quality and intelligibility
of the speech enhanced by the proposed method compared to the traditional
audio-lip speech enhancement baselines. Further analysis using phone error
rates (PER) of automatic speech recognition (ASR) shows that palatal and velar
consonants benefit most from the introduction of ultrasound tongue images.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:15:53 GMT""}]","2023-05-25"
"2305.14934","Muhammad Khalifa","Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu
  Wang","Discriminator-Guided Multi-step Reasoning with Language Models","19 pages, 7 figures, and 8 tables",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  In the context of multi-step reasoning, language models (LMs) probabilities
are often miscalibrated -- solutions with high probabilities are not always
correct. Therefore, greedy decoding, which is the standard decoding method for
reasoning tasks, often yields incorrect solutions. In addition, methods such as
self-consistency and verifiers rely on sampling from the LM distribution and do
not tackle the underlying issue. To address this, we introduce Guiding
Multi-step ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise
decoding approach that nudges the model towards producing correct reasoning
steps. GRACE employs a discriminator model, which is trained to differentiate
correct steps from invalid ones, to adjust decoding preferences based on the
correctness of each reasoning step. Importantly, GRACE does not require
fine-tuning or re-training the LMs. When compared with conventional decoding
strategies over four popular math reasoning benchmarks, GRACE exhibits
significant improvements in both final answer accuracy and step correctness,
outperforming both greedy decoding and self-consistency.\footnote{Our code can
be found at \url{https://github.com/mukhal/grace.}}
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:16:51 GMT""}]","2023-05-25"
"2305.14935","Timon Ziegenbein","Timon Ziegenbein, Shahbaz Syed, Felix Lange, Martin Potthast and
  Henning Wachsmuth","Modeling Appropriate Language in Argumentation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Online discussion moderators must make ad-hoc decisions about whether the
contributions of discussion participants are appropriate or should be removed
to maintain civility. Existing research on offensive language and the resulting
tools cover only one aspect among many involved in such decisions. The question
of what is considered appropriate in a controversial discussion has not yet
been systematically addressed. In this paper, we operationalize appropriate
language in argumentation for the first time. In particular, we model
appropriateness through the absence of flaws, grounded in research on argument
quality assessment, especially in aspects from rhetoric. From these, we derive
a new taxonomy of 14 dimensions that determine inappropriate language in online
discussions. Building on three argument quality corpora, we then create a
corpus of 2191 arguments annotated for the 14 dimensions. Empirical analyses
support that the taxonomy covers the concept of appropriateness
comprehensively, showing several plausible correlations with argument quality
dimensions. Moreover, results of baseline approaches to assessing
appropriateness suggest that all dimensions can be modeled computationally on
the corpus.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:17:05 GMT""}]","2023-05-25"
"2305.14936","Ivan Habernal","Cleo Matzken, Steffen Eger, Ivan Habernal","Trade-Offs Between Fairness and Privacy in Language Modeling","Findings of ACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Protecting privacy in contemporary NLP models is gaining in importance. So
does the need to mitigate social biases of such models. But can we have both at
the same time? Existing research suggests that privacy preservation comes at
the price of worsening biases in classification tasks. In this paper, we
explore the extent to which this tradeoff really holds when we incorporate both
privacy preservation and de-biasing techniques into training text generation
models. How does improving the model along one dimension affect the other
dimension as well as the utility of the model? We conduct an extensive set of
experiments that include bias detection, privacy attacks, language modeling,
and performance on downstream tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:18:28 GMT""}]","2023-05-25"
"2305.14937","Natalie Prange","Hannah Bast and Matthias Hertel and Natalie Prange","A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking
  Systems",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing evaluations of entity linking systems often say little about how the
system is going to perform for a particular application. There are four
fundamental reasons for this: many benchmarks focus on named entities; it is
hard to define which other entities to include; there are ambiguities in entity
recognition and entity linking; many benchmarks have errors or artifacts that
invite overfitting or lead to evaluation results of limited meaningfulness.
  We provide a more meaningful and fair in-depth evaluation of a variety of
existing end-to-end entity linkers. We characterize the strengths and
weaknesses of these linkers and how well the results from the respective
publications can be reproduced. Our evaluation is based on several widely used
benchmarks, which exhibit the problems mentioned above to various degrees, as
well as on two new benchmarks, which address these problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:20:15 GMT""}]","2023-05-25"
"2305.14938","Minje Choi","Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu and David Jurgens","Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large
  Language Models with SocKET Benchmark","24 pages, 7 tables, 5 figures",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have been shown to perform well at a variety of
syntactic, discourse, and reasoning tasks. While LLMs are increasingly deployed
in many forms including conversational agents that interact with humans, we
lack a grounded benchmark to measure how well LLMs understand \textit{social}
language. Here, we introduce a new theory-driven benchmark, SocKET, that
contains 58 NLP tasks testing social knowledge which we group into five
categories: humor & sarcasm, offensiveness, sentiment & emotion, and
trustworthiness. In tests on the benchmark, we demonstrate that current models
attain only moderate performance but reveal significant potential for task
transfer among different types and categories of tasks, which were predicted
from theory. Through zero-shot evaluations, we show that pretrained models
already possess some innate but limited capabilities of social language
understanding and training on one category of tasks can improve zero-shot
testing on others. Our benchmark provides a systematic way to analyze model
performance on an important dimension of language and points to clear room for
improvement to build more socially-aware LLMs. The associated resources are
released at https://github.com/minjechoi/SOCKET.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:21:06 GMT""}]","2023-05-25"
"2305.14939","Ke Wei","Jianzhou Luo, Dingchuan Yang, and Ke Wei","Improved Complexity Analysis of the Sinkhorn and Greenkhorn Algorithms
  for Optimal Transport",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  The Sinkhorn algorithm is a widely used method for solving the optimal
transport problem, and the Greenkhorn algorithm is one of its variants. While
there are modified versions of these two algorithms whose computational
complexities are $O({n^2\|C\|_\infty^2\log n}/{\varepsilon^2})$ to achieve an
$\varepsilon$-accuracy, the best known complexities for the vanilla versions
are $O({n^2\|C\|_\infty^3\log n}/{\varepsilon^3})$. In this paper we fill this
gap and show that the complexities of the vanilla Sinkhorn and Greenkhorn
algorithms are indeed $O({n^2\|C\|_\infty^2\log n}/{\varepsilon^2})$. The
analysis relies on the equicontinuity of the dual variables of the entropic
regularized optimal transport problem, which is of independent interest.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:23:33 GMT""}]","2023-05-25"
"2305.14940","Siddhartha Ganguly","Siddhartha Ganguly and Souvik Das and Debasish Chatterjee and Ravi
  Banavar","A discrete-time Pontryagin maximum principle under rate constraints",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Limited bandwidth and limited saturation in actuators are practical concerns
in control systems. Mathematically, these limitations manifest as constraints
being imposed on the control actions, their rates of change, and more
generally, the global behavior of their paths. While the problem of actuator
saturation has been studied extensively, little attention has been devoted to
the problem of actuators having limited bandwidth. While attempts have been
made in the direction of incorporating frequency constraints on state-action
trajectories before, rate constraints on the control at the design stage have
not been studied extensively in the discrete-time regime. This article
contributes toward filling this lacuna. In particular, we establish a new
discrete-time Pontryagin maximum principle with rate constraints being imposed
on the control trajectories, and derive first-order necessary conditions for
optimality. A brief discussion on the existence of optimal control is included,
and numerical examples are provided to illustrate the results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:23:48 GMT""}]","2023-05-25"
"2305.14941","Michael Seifert","Michael Seifert (1), Tom\'a\v{s} Rauch (1), Miguel A. L. Marques (2)
  and Silvana Botti (1 and 3) ((1) Institut f\""ur Festk\""orpertheorie und
  -optik, Friedrich-Schiller-Universit\""at Jena and European Theoretical
  Spectroscopy Facility, (2) Research Center Future Energy Materials and
  Systems of the University Alliance Ruhr, Faculty of Mechanical Engineering,
  Ruhr University Bochum, (3) Research Center Future Energy Materials and
  Systems, Faculty of Physics and Astronomy, Ruhr Universit\""at Bochum)","Structure prediction and characterization of CuI-based ternary $p$-type
  transparent conductors",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Zincblende copper iodide has attracted significant interest as a potential
material for transparent electronics, thanks to its exceptional light
transmission capabilities in the visible range and remarkable hole
conductivity. However, remaining challenges hinder the utilization of copper
iodide's unique properties in real-world applications. To address this,
chalcogen doping has emerged as a viable approach to enhance the hole
concentration in copper iodide. In search of further strategies to improve and
tune the electronic properties of this transparent semiconductor, we
investigate the ternary phase diagram of copper and iodine with sulphur or
selenium by performing structure prediction calculations using the minima
hopping method. As a result, we find 11 structures located on or near the
convex hull, 9 of which are unreported. Based on our band structure
calculations, it appears that sulphur and selenium are promising candidates for
achieving ternary semiconductors suitable as $p$-type transparent conducting
materials. Additionally, our study reveals the presence of unreported phases
that exhibit intriguing topological properties. These findings broaden the
scope of potential applications for these ternary systems, highlighting the
possibility of harnessing their unique electronic characteristics in diverse
electronic devices and systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:27:11 GMT""}]","2023-05-25"
"2305.14942","Tomi K Baikie","Tomi K. Baikie, Philip Calado, Krzysztof Galkowski, Zahra
  Andaji-Garmaroudi, Yi-Chun Chin, Joel Luke, Charlie Henderson, Tom Dunlop,
  James McGettrick, Ji-Seon Kim, Akshay Rao, Jenny Nelson, Samuel D. Stranks,
  Piers R. B. Barnes","Generalised Framework for Controlling and Understanding Ion Dynamics
  with Passivated Lead Halide Perovskites",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Metal halide perovskite solar cells have gained widespread attention due to
their high efficiency and high defect tolerance. The absorbing perovskite layer
is as a mixed electron-ion conductor that supports high rates of ion and charge
transport at room temperature, but the migration of mobile defects can lead to
degradation pathways. We combine experimental observations and drift-diffusion
modelling to demonstrate a new framework to interpret surface photovoltage
(SPV) measurements in perovskite systems and mixed electronic ionic conductors
more generally. We conclude that the SPV in mixed electronic ionic conductors
can be understood in terms of the change in electric potential at the surface
associated with changes in the net charge within the semiconductor system. We
show that by modifying the interfaces of perovskite bilayers, we may control
defect migration behaviour throughout the perovskite bulk. Our new framework
for SPV has broad implications for developing strategies to improve the
stability of perovskite devices by controlling defect accumulation at
interfaces. More generally, in mixed electronic conductors our framework
provides new insights into the behaviour of mobile defects and their
interaction with photoinduced charges, which are foundational to physical
mechanisms in memristivity, logic, impedance, sensors and energy storage.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:28:07 GMT""}]","2023-05-25"
"2305.14943","Louis Sharrock","Louis Sharrock, Lester Mackey, Christopher Nemeth","Learning Rate Free Bayesian Inference in Constrained Domains",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a suite of new particle-based algorithms for sampling on
constrained domains which are entirely learning rate free. Our approach
leverages coin betting ideas from convex optimisation, and the viewpoint of
constrained sampling as a mirrored optimisation problem on the space of
probability measures. Based on this viewpoint, we also introduce a unifying
framework for several existing constrained sampling algorithms, including
mirrored Langevin dynamics and mirrored Stein variational gradient descent. We
demonstrate the performance of our algorithms on a range of numerical examples,
including sampling from targets on the simplex, sampling with fairness
constraints, and constrained sampling problems in post-selection inference. Our
results indicate that our algorithms achieve competitive performance with
existing constrained sampling methods, without the need to tune any
hyperparameters.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:31:18 GMT""}]","2023-05-25"
"2305.14944","Lucas Slot","Sander Gribling, Sven Polak, Lucas Slot","A note on the computational complexity of the moment-SOS hierarchy for
  polynomial optimization","10 pages",,,,"math.OC cs.CC","http://creativecommons.org/licenses/by/4.0/","  The moment-sum-of-squares (moment-SOS) hierarchy is one of the most
celebrated and widely applied methods for approximating the minimum of an
n-variate polynomial over a feasible region defined by polynomial
(in)equalities. A key feature of the hierarchy is that, at a fixed level, it
can be formulated as a semidefinite program of size polynomial in the number of
variables n. Although this suggests that it may therefore be computed in
polynomial time, this is not necessarily the case. Indeed, as O'Donnell (2017)
and later Raghavendra & Weitz (2017) show, there exist examples where the
sos-representations used in the hierarchy have exponential bit-complexity. We
study the computational complexity of the moment-SOS hierarchy, complementing
and expanding upon earlier work of Raghavendra & Weitz (2017). In particular,
we establish algebraic and geometric conditions under which polynomial-time
computation is guaranteed to be possible.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:32:02 GMT""}]","2023-05-25"
"2305.14945","Svend-Age Biehs","S.-A. Biehs and G.S. Agarwal","Enhancement of synthetic magnetic field induced nonreciprocity via bound
  states in continuum in dissipatively coupled systems",,,,,"cond-mat.mes-hall physics.optics","http://creativecommons.org/licenses/by/4.0/","  The nonreciprocal propagation of light typically requires use of materials
like ferrites or magneto-optical media with a strong magnetic bias or methods
based on material nonlinearities which require use of strong electromagnetic
fields. A simpler possibility to produce nonreciprocity is to use
spatio-temporal modulations to produce magnetic fields in synthetic dimensions.
In this paper we show that dissipatively coupled systems can lead to
considerable enhancement of nonreciprocity in synthetic fields. The enhancement
comes about from the existence of nearly nondecaying mode -bound state in
continuum (BIC) in dissipatively coupled systems. The dissipative coupling
occurs in a wide class of systems coupled via transmission lines, waveguides,
or nano fibers. The systems could be optical resonators or microscopic qubits.
Remarkably we find that for specific choice of the modulation amplitudes, the
transmission say in forward direction is completely extinguished whereas in the
backward direction it becomes maximum. The synthetic fields produce
transmission resonances which show significant line narrowing which owe their
origin to existence of BIC's in dissipative systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:32:25 GMT""}]","2023-05-25"
"2305.14946","Seyed Mohammadhossein Tabatabaee","Seyed Mohammadhossein Tabatabaee, Anne Bouillard, Jean-Yves Le Boudec","Quasi-Deterministic Burstiness Bound for Aggregate of Independent,
  Periodic Flows",,,,,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-sensitive networks require timely and accurate monitoring of the status
of the network. To achieve this, many devices send packets periodically, which
are then aggregated and forwarded to the controller. Bounding the aggregate
burstiness of the traffic is then crucial for effective resource management. In
this paper, we are interested in bounding this aggregate burstiness for
independent and periodic flows. A deterministic bound is tight only when flows
are perfectly synchronized, which is highly unlikely in practice and would be
overly pessimistic. We compute the probability that the aggregate burstiness
exceeds some value. When all flows have the same period and packet size, we
obtain a closed-form bound using the Dvoretzky-Kiefer-Wolfowitz inequality. In
the heterogeneous case, we group flows and combine the bounds obtained for each
group using the convolution bound. Our bounds are numerically close to
simulations and thus fairly tight. The resulting aggregate burstiness estimated
for a non-zero violation probability is considerably smaller than the
deterministic one: it grows in $\sqrt{n\log{n}}$, instead of $n$, where $n$ is
the number of flows.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:34:20 GMT""}]","2023-05-25"
"2305.14947","Qinyuan Ye","Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren, Robin Jia","How Predictable Are Large Language Model Capabilities? A Case Study on
  BIG-bench",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  We investigate the predictability of large language model (LLM) capabilities:
given records of past experiments using different model families, numbers of
parameters, tasks, and numbers of in-context examples, can we accurately
predict LLM performance on new experiment configurations? Answering this
question has practical implications for LLM users (e.g., deciding which models
to try), developers (e.g., prioritizing evaluation on representative tasks),
and the research community (e.g., identifying hard-to-predict capabilities that
warrant further investigation).
  We study the performance prediction problem on experiment records from
BIG-bench. On a random train-test split, an MLP-based predictor achieves RMSE
below 5%, demonstrating the presence of learnable patterns within the
experiment records. Further, we formulate the problem of searching for
""small-bench,"" an informative subset of BIG-bench tasks from which the
performance of the full set can be maximally recovered, and find a subset as
informative for evaluating new model families as BIG-bench Hard, while being 3x
smaller.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:35:34 GMT""}]","2023-05-25"
"2305.14948","Christopher Johann Clarke","Christopher Johann Clarke","Music Representing Corpus Virtual: An Open Sourced Library for
  Explorative Music Generation, Sound Design, and Instrument Creation with
  Artificial Intelligence and Machine Learning","16 pages",,,,"eess.AS cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Music Representing Corpus Virtual (MRCV) is an open source software suite
designed to explore the capabilities of Artificial Intelligence (AI) and
Machine Learning (ML) in Music Generation, Sound Design, and Virtual Instrument
Creation (MGSDIC). The software is accessible to users of varying levels of
experience, with an emphasis on providing an explorative approach to MGSDIC.
The main aim of MRCV is to facilitate creativity, allowing users to customize
input datasets for training the neural networks, and offering a range of
options for each neural network (thoroughly documented in the Github Wiki). The
software suite is designed to be accessible to musicians, audio professionals,
sound designers, and composers, regardless of their prior experience in AI or
ML. The documentation is prepared in such a way as to abstract technical
details, thereby making it easy to understand. The software is open source,
meaning users can contribute to its development, and the community can
collectively benefit from the insights and experience of other users.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:36:04 GMT""}]","2023-05-25"
"2305.14949","Qi Gou","Qi Gou, Zehua Xia, Wenzhe Du","Cross-lingual Data Augmentation for Document-grounded Dialog Systems in
  Low Resource Languages",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a framework to address the issue of data scarcity in
Document-Grounded Dialogue Systems(DGDS). Our model leverages high-resource
languages to enhance the capability of dialogue generation in low-resource
languages. Specifically, We present a novel pipeline CLEM (Cross-Lingual
Enhanced Model) including adversarial training retrieval (Retriever and
Re-ranker), and Fid (fusion-in-decoder) generator. To further leverage
high-resource language, we also propose an innovative architecture to conduct
alignment across different languages with translated training. Extensive
experiment results demonstrate the effectiveness of our model and we achieved
4th place in the DialDoc 2023 Competition. Therefore, CLEM can serve as a
solution to resource scarcity in DGDS and provide useful guidance for
multi-lingual alignment tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:40:52 GMT""}]","2023-05-25"
"2305.14950","Muhao Chen","Jiongxiao Wang, Zichen Liu, Keun Hee Park, Muhao Chen, Chaowei Xiao","Adversarial Demonstration Attacks on Large Language Models","Work in Progress",,,,"cs.CL cs.AI cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  With the emergence of more powerful large language models (LLMs), such as
ChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence
in leveraging these models for specific tasks by utilizing data-label pairs as
precondition prompts. While incorporating demonstrations can greatly enhance
the performance of LLMs across various tasks, it may introduce a new security
concern: attackers can manipulate only the demonstrations without changing the
input to perform an attack. In this paper, we investigate the security concern
of ICL from an adversarial perspective, focusing on the impact of
demonstrations. We propose an ICL attack based on TextAttack, which aims to
only manipulate the demonstration without changing the input to mislead the
models. Our results demonstrate that as the number of demonstrations increases,
the robustness of in-context learning would decreases. Furthermore, we also
observe that adversarially attacked demonstrations exhibit transferability to
diverse input examples. These findings emphasize the critical security risks
associated with ICL and underscore the necessity for extensive research on the
robustness of ICL, particularly given its increasing significance in the
advancement of LLMs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:40:56 GMT""}]","2023-05-25"
"2305.14951","Jue Liu","Jue Liu, Feipeng Da","Dual-Side Feature Fusion 3D Pose Transfer",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D pose transfer solves the problem of additional input and correspondence of
traditional deformation transfer, only the source and target meshes need to be
input, and the pose of the source mesh can be transferred to the target mesh.
Some lightweight methods proposed in recent years consume less memory but cause
spikes and distortions for some unseen poses, while others are costly in
training due to the inclusion of large matrix multiplication and adversarial
networks. In addition, the meshes with different numbers of vertices also
increase the difficulty of pose transfer. In this work, we propose a Dual-Side
Feature Fusion Pose Transfer Network to improve the pose transfer accuracy of
the lightweight method. Our method takes the pose features as one of the side
inputs to the decoding network and fuses them into the target mesh layer by
layer at multiple scales. Our proposed Feature Fusion Adaptive Instance
Normalization has the characteristic of having two side input channels that
fuse pose features and identity features as denormalization parameters, thus
enhancing the pose transfer capability of the network. Extensive experimental
results show that our proposed method has stronger pose transfer capability
than state-of-the-art methods while maintaining a lightweight network
structure, and can converge faster.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:42:08 GMT""}]","2023-05-25"
"2305.14952","Itamar Zimerman","Shahar Lutati, Itamar Zimerman, Lior Wolf","Focus Your Attention (with Adaptive IIR Filters)","11 pages, 4 figures",,,,"cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a new layer in which dynamic (i.e.,input-dependent) Infinite
Impulse Response (IIR) filters of order two are used to process the input
sequence prior to applying conventional attention. The input is split into
chunks, and the coefficients of these filters are determined based on previous
chunks to maintain causality. Despite their relatively low order, the causal
adaptive filters are shown to focus attention on the relevant sequence
elements. The layer performs on-par with state of the art networks, with a
fraction of the parameters and with time complexity that is sub-quadratic with
input size. The obtained layer is favorable to layers such as Heyna, GPT2, and
Mega, both with respect to the number of parameters and the obtained level of
performance on multiple long-range sequence problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:42:30 GMT""}]","2023-05-25"
"2305.14953","Waleed El Hanafy","Waleed El Hanafy and Adel Awad","Implications of the Conformal Sound Speed Constraint on the Radius of
  PSR J0952-0607 within Rastall Gravity","PdfLaTeX, 12 pages, 3 figures, 1 table, 1 appendix. To appear in ApJ",,,,"astro-ph.HE gr-qc hep-ph","http://creativecommons.org/licenses/by/4.0/","  It has been shown that the nonminimal coupling between geometry and matter
can provide models for massive compact Stars \citep{ElHanafy:2022kjl}, which
are consistent with the conformal bound on the sound speed, $0\leq c_s^2 \leq
c^2/3$, where the core density approaches a few times the nuclear saturation
density. We impose the conformal sound speed upper bound constraint on
Rastall's field equations of gravity, with Krori-Barua potentials in presence
of an anisotropic fluid as a matter source, to estimate the radius of the most
massive pulsar PSR J0952\textendash{0607} ever observed. For its measured mass
$M = 2.35\pm 0.17\, M_\odot$, we obtain a radius $R=14.087 \pm 1.0186$~km as
inferred by the model. We investigate possible connection between Rastall
garvity and MIT bag model with an EoS, $p_r(\rho) \approx c_s^2\left(\rho -
\rho_\text{s}\right)$, in the radial direction, with $c_s=c/\sqrt{3}$ and a
surface density $\rho_\text{s}$ slightly above the nuclear saturation density
$\rho_\text{nuc}=2.7\times 10^{14}$~g/cm$^3$. The corresponding
mass\textendash{radius} diagram is in agreement with our estimated value of the
radius and with astrophysical observations of other pulsars at 68\% C.L.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:42:35 GMT""}]","2023-05-25"
"2305.14954","Valeria Giunta","Valeria Giunta, Thomas Hillen, Mark A. Lewis, Jonathan R. Potts","Weakly nonlinear analysis of a two-species non-local advection-diffusion
  system",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  Nonlocal interactions are ubiquitous in nature and play a central role in
many biological systems. In this paper, we perform a bifurcation analysis of a
widely-applicable advection-diffusion model with nonlocal advection terms
describing the species movements generated by inter-species interactions. We
use linear analysis to assess the stability of the constant steady state, then
weakly nonlinear analysis to recover the shape and stability of non-homogeneous
solutions. Since the system arises from a conservation law, the resulting
amplitude equations consist of a Ginzburg-Landau equation coupled with an
equation for the zero mode. In particular, this means that supercritical
branches from the Ginzburg-Landau equation need not be stable. Indeed, we find
that, depending on the parameters, bifurcations can be subcritical (always
unstable), stable supercritical, or unstable supercritical. We show numerically
that, when small amplitude patterns are unstable, the system exhibits large
amplitude patterns and hysteresis, even in supercritical regimes. Finally, we
construct bifurcation diagrams by combining our analysis with a previous study
of the minimisers of the associated energy functional. Through this approach we
reveal parameter regions in which stable small amplitude patterns coexist with
strongly modulated solutions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:43:53 GMT""}]","2023-05-25"
"2305.14955","Jiayi Zhu","Jiayi Zhu, Xuebin Qin, Abdulmotaleb Elsaddik","DC-Net: Divide-and-Conquer for Salient Object Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce Divide-and-Conquer into the salient object
detection (SOD) task to enable the model to learn prior knowledge that is for
predicting the saliency map. We design a novel network, Divide-and-Conquer
Network (DC-Net) which uses two encoders to solve different subtasks that are
conducive to predicting the final saliency map, here is to predict the edge
maps with width 4 and location maps of salient objects and then aggregate the
feature maps with different semantic information into the decoder to predict
the final saliency map. The decoder of DC-Net consists of our newly designed
two-level Residual nested-ASPP (ResASPP$^{2}$) modules, which have the ability
to capture a large number of different scale features with a small number of
convolution operations and have the advantages of maintaining high resolution
all the time and being able to obtain a large and compact effective receptive
field (ERF). Based on the advantage of Divide-and-Conquer's parallel computing,
we use Parallel Acceleration to speed up DC-Net, allowing it to achieve
competitive performance on six LR-SOD and five HR-SOD datasets under high
efficiency (60 FPS and 55 FPS). Codes and results are available:
https://github.com/PiggyJerry/DC-Net.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:49:25 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 04:15:26 GMT""}]","2023-06-06"
"2305.14956","Debanjan Mondal","Anshita Gupta, Debanjan Mondal, Akshay Krishna Sheshadri, Wenlong
  Zhao, Xiang Lorraine Li, Sarah Wiegreffe, Niket Tandon","Editing Commonsense Knowledge in GPT","Code and data is available at https://github.com/anshitag/memit_csk",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Memory editing methods for updating encyclopedic knowledge in transformers
have received increasing attention for their efficacy, specificity, and
generalization advantages. However, it remains unclear if such methods can be
adapted for the more nuanced domain of commonsense knowledge. We propose
$MEMIT_{CSK}$, an adaptation of MEMIT to edit commonsense mistakes in GPT-2
Large and XL. We extend editing to various token locations and employ a robust
layer selection strategy. Models edited by $MEMIT_{CSK}$ outperforms the
fine-tuning baselines by 10.97% and 10.73% F1 scores on subsets of PEP3k and
20Q. We further propose a novel evaluation dataset, MEMIT-CSK-PROBE, that
contains unaffected neighborhood, affected neighborhood, affected paraphrase,
and affected reasoning challenges. $MEMIT_{CSK}$ demonstrates favorable
semantic generalization, outperforming fine-tuning baselines by 13.72% and
5.57% overall scores on MEMIT-CSK-PROBE. These results suggest a compelling
future direction of incorporating context-specific user feedback concerning
commonsense in GPT by direct model editing, rectifying and customizing model
behaviors via human-in-the-loop systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:50:54 GMT""}]","2023-05-25"
"2305.14957","Alessandro Ursi","Alessandro Ursi, Nicol\`o Parmiggiani, Mauro Messerotti, Alberto
  Pellizzoni, Carlotta Pittori, Francesco Longo, Francesco Verrecchia, Andrea
  Argan, Andrea Bulgarelli, Marco Tavani, Patrizio Tempesta, Fabio D'Amico","The First AGILE Solar Flare Catalog","22 pages, 10 figures",,,,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We report the Astrorivelatore Gamma ad Immagini LEggero (AGILE) observations
of solar flares, detected by the on board anticoincidence system in the 80-200
keV energy range, from 2007 May 1st to 2022 August 31st. In more than 15 yr,
AGILE detected 5003 X-ray, minute-lasting transients, compatible with a solar
origin. A cross-correlation of these transients with the Geostationary
Operational Environmental Satellites (GOES) official solar flare database
allowed to associate an intensity class (i.e., B, C, M, or X) to 3572 of them,
for which we investigated the main temporal and intensity parameters. The AGILE
data clearly revealed the solar activity covering the last stages of the 23rd
cycle, the whole 24th cycle, and the beginning of the current 25th cycle. In
order to compare our results with other space missions operating in the
high-energy range, we also analyzed the public lists of solar flares reported
by RHESSI and Fermi Gamma-ray Burst Monitor. This catalog reports 1424 events
not contained in the GOES official dataset, which, after statistical
comparisons, are compatible with low-intensity, short-duration solar flares.
  Besides providing a further dataset of solar flares detected in the hard
X-ray range, this study allowed to point out two main features: a longer
persistence of the decay phase in the high-energy regime, with respect to the
soft X-rays, and a tendency of the flare maximum to be reached earlier in the
soft X-rays with respect to the hard X-rays. Both these aspects support a
two-phase acceleration mechanism of electrons in the solar atmosphere.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:50:58 GMT""}]","2023-05-25"
"2305.14958","Fran\c{c}ois-Xavier Coudert","Fran\c{c}ois-Xavier Coudert","Failure to Reproduce the Results of ""A new transferable interatomic
  potential for molecular dynamics simulations of borosilicate glasses''",,"J. Non-Cryst. Solids, 2023, 615, 122423","10.1016/j.jnoncrysol.2023.122423",,"physics.comp-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We reproduced the simulations described in Wang et al [J. Non-Cryst. Sol.,
498 (2018) 294-304] and found we could not obtain the results reported. The
root cause was identified to be incorrect atom masses in the original
simulation files. As a consequence, the potential does not reproduce the
experimental glass density -- and presumably, other structural properties --
and should be considered with great caution.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:50:59 GMT""}]","2023-06-09"
"2305.14959","Omid Esrafilian","Omid Esrafilian, Rajeev Gangula, and David Gesbert","UAV Trajectory Optimization and Tracking for User Localization in
  Wireless Networks",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the problem of UAV-aided user localization in
wireless networks. Unlike the existing works, we do not assume perfect
knowledge of the UAV location, hence we not only need to localize the users but
also to track the UAV location. To do so, we utilize the time-of-arrival along
with received signal strength radio measurements collected from users using a
UAV. A simultaneous localization and mapping (SLAM) framework building on the
Expectation-Maximization-based least-squares method is proposed to classify
measurements into line-of-sight or non-line-of-sight categories and learn the
radio channel, and at the same, localize the users and track the UAV. This
framework also allows us to exploit other types of measurements such as the
rough estimate of the UAV location available from GPS, and the UAV velocity
measured by an inertial measurement unit (IMU) on-board, to achieve better
localization accuracy. Moreover, the trajectory of the UAV is optimized which
brings considerable improvement to the localization performance. The
simulations show the out-performance of the developed algorithm when compared
to other approaches.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:52:20 GMT""}]","2023-05-25"
"2305.14960","Jingwen Ma","Jingwen Ma, Ding Jia, Li Zhang, Yi-jun Guan, Yong Ge, Hong-xiang Sun,
  Shou-qi Yuan, Hongsheng Chen, Yihao Yang, Xiang Zhang","Observation of vortex-string chiral modes in metamaterials","3 Figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  As a hypothetical topological defect in the geometry of spacetime, vortex
strings play a crucial role in shaping the clusters of galaxies that exist
today, and their distinct features can provide observable clues about the early
universe's evolution. A key feature of vortex strings is that they can interact
with Weyl fermionic modes and support topological chiral-anomaly states with
massless dispersions at the core of strings. To date, despite many attempts to
detect vortex strings in astrophysics or to emulate them in artificially
created systems, observation of these topological vortex-string chiral modes
remains experimentally elusive. Here we report the experimental observation of
such vortex-string chiral modes using a metamaterial system. This is
implemented by inhomogeneous perturbation of a Yang-monopole phononic
metamaterial. The measured linear dispersion and modal profiles confirm the
existence of topological modes bound to and propagating along the vortex string
with the chiral anomaly. Our work not only provides a platform for studying
diverse cosmic topological defects in astrophysics but also offers intriguing
device applications as topological fibres in signal processing and
communication techniques.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:55:20 GMT""}]","2023-05-25"
"2305.14961","Simon Wiegrebe","Simon Wiegrebe, Philipp Kopper, Raphael Sonabend, and Andreas Bender","Deep Learning for Survival Analysis: A Review","24 pages, 6 figures, 2 tables, 1 interactive table",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The influx of deep learning (DL) techniques into the field of survival
analysis in recent years, coupled with the increasing availability of
high-dimensional omics data and unstructured data like images or text, has led
to substantial methodological progress; for instance, learning from such
high-dimensional or unstructured data. Numerous modern DL-based survival
methods have been developed since the mid-2010s; however, they often address
only a small subset of scenarios in the time-to-event data setting - e.g.,
single-risk right-censored survival tasks - and neglect to incorporate more
complex (and common) settings. Partially, this is due to a lack of exchange
between experts in the respective fields.
  In this work, we provide a comprehensive systematic review of DL-based
methods for time-to-event analysis, characterizing them according to both
survival- and DL-related attributes. In doing so, we hope to provide a helpful
overview to practitioners who are interested in DL techniques applicable to
their specific use case as well as to enable researchers from both fields to
identify directions for future investigation. We provide a detailed
characterization of the methods included in this review as an open-source,
interactive table: https://survival-org.github.io/DL4Survival. As this research
area is advancing rapidly, we encourage the research community to contribute to
keeping the information up to date.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:56:20 GMT""}]","2023-05-25"
"2305.14962","Maksym Lysak","Christoph Auer, Ahmed Nassar, Maksym Lysak, Michele Dolfi, Nikolaos
  Livathinos, Peter Staar","ICDAR 2023 Competition on Robust Layout Segmentation in Corporate
  Documents","ICDAR 2023, 10 pages, 4 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transforming documents into machine-processable representations is a
challenging task due to their complex structures and variability in formats.
Recovering the layout structure and content from PDF files or scanned material
has remained a key problem for decades. ICDAR has a long tradition in hosting
competitions to benchmark the state-of-the-art and encourage the development of
novel solutions to document layout understanding. In this report, we present
the results of our \textit{ICDAR 2023 Competition on Robust Layout Segmentation
in Corporate Documents}, which posed the challenge to accurately segment the
page layout in a broad range of document styles and domains, including
corporate reports, technical literature and patents. To raise the bar over
previous competitions, we engineered a hard competition dataset and proposed
the recent DocLayNet dataset for training. We recorded 45 team registrations
and received official submissions from 21 teams. In the presented solutions, we
recognize interesting combinations of recent computer vision models, data
augmentation strategies and ensemble methods to achieve remarkable accuracy in
the task we posed. A clear trend towards adoption of vision-transformer based
methods is evident. The results demonstrate substantial progress towards
achieving robust and highly generalizing methods for document layout
understanding.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:56:47 GMT""}]","2023-05-25"
"2305.14963","Yau-Shian Wang","Yau-Shian Wang and Ta-Chung Chi and Ruohong Zhang and Yiming Yang","PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text
  Classification","accepted by ACL 2023","ACL 2023",,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present PESCO, a novel contrastive learning framework that substantially
improves the performance of zero-shot text classification. We formulate text
classification as a neural text matching problem where each document is treated
as a query, and the system learns the mapping from each query to the relevant
class labels by (1) adding prompts to enhance label matching, and (2) using
retrieved labels to enrich the training set in a self-training loop of
contrastive learning. PESCO achieves state-of-the-art performance on four
benchmark text classification datasets. On DBpedia, we achieve 98.5\% accuracy
without any labeled data, which is close to the fully-supervised result.
Extensive experiments and analyses show all the components of PESCO are
necessary for improving the performance of zero-shot text classification.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:57:06 GMT""}]","2023-05-25"
"2305.14964","Einat Minkov","Sagi Penzel, Nir Lotan, Alon Zoizner, Einat Minkov","Detecting and Characterizing Political Incivility on Social Media",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Researchers of political communication study the impact and perceptions of
political incivility on social media. Yet, so far, relatively few works
attempted to automatically detect and characterize political incivility. In our
work, we study political incivility in Twitter, presenting several research
contributions. First, we present state-of-the-art incivility detection results
using a large dataset, which we collected and labeled via crowd sourcing.
Importantly, we distinguish between uncivil political speech that is impolite
and intolerant anti-democratic discourse. Applying political incivility
detection at large-scale, we derive insights regarding the prevalence of this
phenomenon across users, and explore the network characteristics of users who
are susceptible to disseminating uncivil political content online. Finally, we
propose an approach for modeling social context information about the tweet
author alongside the tweet content, showing that this leads to significantly
improved performance on the task of political incivility detection. This result
holds promise for related tasks, such as hate speech and stance detection.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:57:12 GMT""}]","2023-05-25"
"2305.14965","Abhinav Rao","Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit
  Choudhury","Tricking LLMs into Disobedience: Understanding, Analyzing, and
  Preventing Jailbreaks",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Recent explorations with commercial Large Language Models (LLMs) have shown
that non-expert users can jailbreak LLMs by simply manipulating the prompts;
resulting in degenerate output behavior, privacy and security breaches,
offensive outputs, and violations of content regulator policies. Limited formal
studies have been carried out to formalize and analyze these attacks and their
mitigations. We bridge this gap by proposing a formalism and a taxonomy of
known (and possible) jailbreaks. We perform a survey of existing jailbreak
methods and their effectiveness on open-source and commercial LLMs (such as GPT
3.5, OPT, BLOOM, and FLAN-T5-xxl). We further propose a limited set of prompt
guards and discuss their effectiveness against known attack types.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:57:37 GMT""}]","2023-05-25"
"2305.14966","Sanoopkumar P. S.","Sanoopkumar P. S., Stephen McWade, Arman Farhang","Truncated Turbo Equalizer with SIC for OTFS",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Orthogonal time frequency space (OTFS) is a promising candidate waveform for
the next generation wireless communication systems. OTFS places data in the
delay-Doppler (DD) domain, which simplifies channel estimation in highmobility
scenarios. However, due to the 2-D convolution effect of the time-varying
channel in the DD domain, equalization is still a challenge for OTFS. Existing
equalizers for OTFS are either highly complex or they do not consider
intercarrier interference present in high-mobility scenarios. Hence, in this
paper, we propose a novel two-stage detection technique for coded OTFS systems.
Our proposed detector brings orders of magnitude computational complexity
reduction compared to existing methods. At the first stage, it truncates the
channel by considering only the significant coefficients along the Doppler
dimension and performs turbo equalization. To reduce the computational load of
the turbo equalizer, our proposed method deploys the modified LSQR (mLSQR)
algorithm. At the second stage, with only two successive interference
cancellation (SIC) iterations, our proposed detector removes the residual
interference caused by channel truncation. To evaluate the performance of our
proposed truncated turbo equalizer with SIC (TTE-SIC), we set the minimum mean
squared error (MMSE) equalizer without channel truncation as a benchmark. Our
simulation results show that the proposed TTE-SIC technique achieves about the
same bit error rate (BER) performance as the benchmark.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:59:08 GMT""}]","2023-05-25"
"2305.14967","M.A. Moreno-Fr\'ias","M.A. Moreno-Fr\'ias and J.C. Rosales","The covariety of perfect numerical semigroups with fixed Frobenius
  number","arXiv admin note: text overlap with arXiv:2302.09121,
  arXiv:2303.12470, arXiv:2305.02070, arXiv:2305.13881",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $S$ be a numerical semigroup. We will say that $h\in {\mathbb{N}}
\backslash S$ is an {\it isolated gap }of $S$ if $\{h-1,h+1\}\subseteq S.$ A
numerical semigroup without isolated gaps is called perfect numerical
semigroup. Denote by ${\mathrm m}(S)$ the multiplicity of a numerical semigroup
$S$. A covariety is a nonempty family ${\mathscr{C}}$ of numerical semigroups
that fulfills the following conditions: there is the minimum of
${\mathscr{C}},$ the intersection of two elements of ${\mathscr{C}}$ is again
an element of ${\mathscr{C}}$ and $S\backslash \{{\mathrm m}(S)\}\in
{\mathscr{C}}$ for all $S\in {\mathscr{C}}$ such that $S\neq
\min({\mathscr{C}}).$ In this work we prove that the set
${\mathscr{P}}(F)=\{S\mid S \mbox{ is a perfect numerical}\ \mbox{semigroup
with Frobenius number }F\}$ is a covariety. Also, we describe three algorithms
which compute: the set ${\mathscr{P}}(F),$ the maximal elements of
${\mathscr{P}}(F)$ and the elements of ${\mathscr{P}}(F)$ with a given genus. A
${\mathrm{Parf}}$-semigroup (respectively, ${\mathrm{Psat}}$-semigroup) is a
perfect numerical semigroup that in addition is an Arf numerical semigroup
(respectively, saturated numerical semigroup). We will prove that the sets:
${\mathrm{Parf}}(F)=\{S\mid S \mbox{ is a ${\mathrm{Parf}}$-numerical semigroup
with Frobenius number} F\}$ and ${\mathrm{Psat}}(F)=\{S\mid S \mbox{ is a
${\mathrm{Psat}}$-numerical semigroup with Frobenius number } F\}$ are
covarieties. As a consequence we present some algorithms to compute
${\mathrm{Parf}}(F)$ and ${\mathrm{Psat}}(F)$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:00:30 GMT""}]","2023-05-25"
"2305.14968","Kris Nikov","Simon Wegener, Kris K. Nikov, Jose Nunez-Yanez, Kerstin Eder","EnergyAnalyzer: Using Static WCET Analysis Techniques to Estimate the
  Energy Consumption of Embedded Applications",,,,,"cs.SE","http://creativecommons.org/licenses/by-sa/4.0/","  This paper presents EnergyAnalyzer, a code-level static analysis tool for
estimating the energy consumption of embedded software based on statically
predictable hardware events. The tool utilises techniques usually used for
worst-case execution time (WCET) analysis together with bespoke energy models
developed for two predictable architectures - the ARM Cortex-M0 and the Gaisler
LEON3 - to perform energy usage analysis. EnergyAnalyzer has been applied in
various use cases, such as selecting candidates for an optimised convolutional
neural network, analysing the energy consumption of a camera pill prototype,
and analysing the energy consumption of satellite communications software. The
tool was developed as part of a larger project called TeamPlay, which aimed to
provide a toolchain for developing embedded applications where energy
properties are first-class citizens, allowing the developer to reflect directly
on these properties at the source code level. The analysis capabilities of
EnergyAnalyzer are validated across a large number of benchmarks for the two
target architectures and the results show that the statically estimated energy
consumption has, with a few exceptions, less than 1% difference compared to the
underlying empirical energy models which have been validated on real hardware.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:01:32 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 10:30:19 GMT""}]","2023-05-26"
"2305.14969","Yichen Yan","Yichen Yan, Xingjian He, Wenxuan Wan, Jing Liu","MMNet: Multi-Mask Network for Referring Image Segmentation","10 pages, 5 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Referring image segmentation aims to segment an object referred to by natural
language expression from an image. However, this task is challenging due to the
distinct data properties between text and image, and the randomness introduced
by diverse objects and unrestricted language expression. Most of previous work
focus on improving cross-modal feature fusion while not fully addressing the
inherent uncertainty caused by diverse objects and unrestricted language. To
tackle these problems, we propose an end-to-end Multi-Mask Network for
referring image segmentation(MMNet). we first combine picture and language and
then employ an attention mechanism to generate multiple queries that represent
different aspects of the language expression. We then utilize these queries to
produce a series of corresponding segmentation masks, assigning a score to each
mask that reflects its importance. The final result is obtained through the
weighted sum of all masks, which greatly reduces the randomness of the language
expression. Our proposed framework demonstrates superior performance compared
to state-of-the-art approaches on the two most commonly used datasets, RefCOCO,
RefCOCO+ and G-Ref, without the need for any post-processing. This further
validates the efficacy of our proposed framework.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:02:27 GMT""}]","2023-05-25"
"2305.14970","Tianqing Fang","Tianqing Fang, Zhaowei Wang, Wenxuan Zhou, Hongming Zhang, Yangqiu
  Song, Muhao Chen","Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge
  Conflicts in Event Temporal Reasoning","13 pages, 1 figure",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Event temporal reasoning aims at identifying the temporal relations between
two or more events. However, knowledge conflicts arise when there is a mismatch
between the actual temporal relations of events in the context and the prior
knowledge or biases learned by the model. We first systematically define
distinct kinds of bias in event temporal reasoning, which include event
relation prior bias, tense bias, narrative bias, and dependency bias, as
indicators to study knowledge conflicts. To mitigate such event-related
knowledge conflict, we introduce a Counterfactual Data Augmentation based
method that can be applied to both Pre-trained Language Models (PLMs) and Large
Language Models (LLMs) either as additional training data or demonstrations for
In-Context Learning. Experiments suggest the importance of mitigating knowledge
conflicts in event temporal reasoning tasks for reducing hallucination and
highlight the potential of counterfactual data augmentation for improving model
performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:04:06 GMT""}]","2023-05-25"
"2305.14971","Marilena Caramazza","M. Caramazza, B. Stelzer, E. Magaudda, St. Raetz, M. G\""udel, S.
  Orlando, K. Poppenh\""ager","Complete X-ray census of Mdwarfs in the solar Neighborhood I. GJ 745 AB:
  Coronal-hole Stars in the 10 pc Sample","accepted for publication in Astronomy & Astrophysics (A&A)",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have embarked in a systematic study of the X-ray emission in a
volume-limited sample of M dwarf stars, in order to explore the full range of
activity levels present in their coronae and, thus, to understand the
conditions in their outer atmospheres and their possible impact on the
circumstellar environment. We identify in a recent catalog of the Gaia objects
within 10 pc from the Sun all the stars with spectral type between M0 and M4,
and search systematically for X-ray measurements of this sample. To this end,
we use both archival data (from ROSAT, XMM-Newton, and from the ROentgen Survey
with an Imaging Telescope Array (eROSITA) onboard the Russian
Spektrum-Roentgen-Gamma mission) and our own dedicated XMM-Newton observations.
To make inferences on the properties of the M dwarf corona we compare the range
of their observed X-ray emission levels to the flux radiated by the Sun from
different types of magnetic structures: coronal holes, background corona,
active regions and cores of active regions. At the current state of our
project, with more than 90\% of the 10pc M dwarf sample observed in X-rays,
only GJ 745 A has no detection. With an upper limit luminosity of log Lx
[erg/s] < 25.4 and an X-ray surface flux of log FX,SURF [erg/cm^2/s] < 3.6 GJ
745 A defines the lower boundary of the X-ray emission level of M dwarfs.
Together with its companion GJ 745 B, GJ 745 A it is the only star in this
volume-complete sample located in the range of FX,SURF that corresponds to the
faintest solar coronal structures, the coronal holes. The ultra-low X-ray
emission level of GJ 745 B (log Lx [erg/s] = 25.6 and log FX,SURF [erg/cm^2/s]
= 3.8) is entirely attributed to flaring activity, indicating that, while its
corona is dominated by coronal holes, at least one magnetically active
structure is present and determines the total X-ray brightness and the coronal
temperature of the star.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:04:07 GMT""}]","2023-05-25"
"2305.14972","Vadim Sokolov","Nicholas G. Polson and Vadim Sokolov","Generative AI for Bayesian Computation","arXiv admin note: text overlap with arXiv:2209.02163",,,,"stat.CO","http://creativecommons.org/publicdomain/zero/1.0/","  We develop Generative AI (Gen-AI) methods for Bayesian Computation. Gen-AI
naturally applies to Bayesian models which are easily simulated. We generate a
large training dataset and together with deep neural networks we uncover the
inverse Bayes map for inference and prediction. To do this, we require high
dimensional regression methods and dimensionality reduction (a.k.a feature
selection). The main advantage of Generative AI is its ability to be model-free
and the fact that it doesn't rely on densities. Bayesian computation is
replaced by pattern recognition of an input-output map. This map is learned
from empirical model simulation. We show that Deep Quantile NNs provide a
general framework for inference decision making. To illustrate our methodology,
we provide three examples: a stylized synthetic example, a traffic flow
prediction problem and we analyze the well-known Ebola data-set. Finally, we
conclude with directions for future research.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:05:47 GMT""}]","2023-05-25"
"2305.14973","Jiazheng Li","Jiazheng Li, Runcong Zhao, Yulan He, Lin Gui","OverPrompt: Enhancing ChatGPT Capabilities through an Efficient
  In-Context Learning Approach",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The exceptional performance of pre-trained large language models has
revolutionised various applications, but their adoption in production
environments is hindered by prohibitive costs and inefficiencies, particularly
when utilising long prompts. This paper proposes OverPrompt, an in-context
learning method aimed at improving LLM efficiency and performance by processing
multiple inputs in parallel. Evaluated across diverse datasets, OverPrompt
enhances task efficiency and integrates a diverse range of examples for
improved performance. Particularly, it amplifies fact-checking and sentiment
analysis tasks when supplemented with contextual information. Synthetic data
grouping further enhances performance, suggesting a viable approach for data
augmentation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:08:04 GMT""}]","2023-05-25"
"2305.14974","David Kappel","David Kappel, Khaleelulla Khan Nazeer, Cabrel Teguemne Fokam,
  Christian Mayr, Anand Subramoney","Block-local learning with probabilistic latent representations",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ubiquitous backpropagation algorithm requires sequential updates across
blocks of a network, introducing a locking problem. Moreover, backpropagation
relies on the transpose of weight matrices to calculate updates, introducing a
weight transport problem across blocks. Both these issues prevent efficient
parallelisation and horizontal scaling of models across devices. We propose a
new method that introduces a twin network that propagates information backwards
from the targets to the input to provide auxiliary local losses. Forward and
backward propagation can work in parallel and with different sets of weights,
addressing the problems of weight transport and locking. Our approach derives
from a statistical interpretation of end-to-end training which treats
activations of network layers as parameters of probability distributions. The
resulting learning framework uses these parameters locally to assess the
matching between forward and backward information. Error backpropagation is
then performed locally within each block, leading to `block-local' learning.
Several previously proposed alternatives to error backpropagation emerge as
special cases of our model. We present results on various tasks and
architectures, including transformers, demonstrating state-of-the-art
performance using block-local learning. These results provide a new principled
framework to train very large networks in a distributed setting and can also be
applied in neuromorphic systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:11:30 GMT""}]","2023-05-25"
"2305.14975","Eric A Mitchell","Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael
  Rafailov, Huaxiu Yao, Chelsea Finn, Christopher D. Manning","Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence
  Scores from Language Models Fine-Tuned with Human Feedback",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  A trustworthy real-world prediction system should be well-calibrated; that
is, its confidence in an answer is indicative of the likelihood that the answer
is correct, enabling deferral to a more expensive expert in cases of
low-confidence predictions. While recent studies have shown that unsupervised
pre-training produces large language models (LMs) that are remarkably
well-calibrated, the most widely-used LMs in practice are fine-tuned with
reinforcement learning with human feedback (RLHF-LMs) after the initial
unsupervised pre-training stage, and results are mixed as to whether these
models preserve the well-calibratedness of their ancestors. In this paper, we
conduct a broad evaluation of computationally feasible methods for extracting
confidence scores from LLMs fine-tuned with RLHF. We find that with the right
prompting strategy, RLHF-LMs verbalize probabilities that are much better
calibrated than the model's conditional probabilities, enabling fairly
well-calibrated predictions. Through a combination of prompting strategy and
temperature scaling, we find that we can reduce the expected calibration error
of RLHF-LMs by over 50%.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:12:33 GMT""}]","2023-05-25"
"2305.14976","Md Tawkat Islam Khondaker","Md Tawkat Islam Khondaker, Abdul Waheed, El Moatez Billah Nagoudi,
  Muhammad Abdul-Mageed","GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP","Work in progress",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent emergence of ChatGPT has brought a revolutionary change in the
landscape of NLP. Although ChatGPT has consistently shown impressive
performance on English benchmarks, its exact capabilities on most other
languages remain largely unknown. To better understand ChatGPT's capabilities
on Arabic, we present a large-scale evaluation of the model on a broad range of
Arabic NLP tasks. Namely, we evaluate ChatGPT on 32 diverse natural language
understanding and generation tasks on over 60 different datasets. To the best
of our knowledge, our work offers the first performance analysis of ChatGPT on
Arabic NLP at such a massive scale. Our results show that, despite its success
on English benchmarks, ChatGPT trained in-context (few-shot) is consistently
outperformed by much smaller dedicated models finetuned on Arabic. These
results suggest that there is significant place for improvement for
instruction-tuned LLMs such as ChatGPT.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:12:39 GMT""}]","2023-05-25"
"2305.14977","Florian Heidecker","Florian Heidecker, Ahmad El-Khateeb, Bernhard Sick","Sampling-based Uncertainty Estimation for an Instance Segmentation
  Network",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The examination of uncertainty in the predictions of machine learning (ML)
models is receiving increasing attention. One uncertainty modeling technique
used for this purpose is Monte-Carlo (MC)-Dropout, where repeated predictions
are generated for a single input. Therefore, clustering is required to describe
the resulting uncertainty, but only through efficient clustering is it possible
to describe the uncertainty from the model attached to each object. This
article uses Bayesian Gaussian Mixture (BGM) to solve this problem. In
addition, we investigate different values for the dropout rate and other
techniques, such as focal loss and calibration, which we integrate into the
Mask-RCNN model to obtain the most accurate uncertainty approximation of each
instance and showcase it graphically.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:12:50 GMT""}]","2023-05-25"
"2305.14978","Nathanael Bosch","Nathanael Bosch, Philipp Hennig, Filip Tronarp","Probabilistic Exponential Integrators",,,,,"math.NA cs.LG cs.NA stat.ML","http://creativecommons.org/licenses/by/4.0/","  Probabilistic solvers provide a flexible and efficient framework for
simulation, uncertainty quantification, and inference in dynamical systems.
However, like standard solvers, they suffer performance penalties for certain
stiff systems, where small steps are required not for reasons of numerical
accuracy but for the sake of stability. This issue is greatly alleviated in
semi-linear problems by the probabilistic exponential integrators developed in
this paper. By including the fast, linear dynamics in the prior, we arrive at a
class of probabilistic integrators with favorable properties. Namely, they are
proven to be L-stable, and in a certain case reduce to a classic exponential
integrator -- with the added benefit of providing a probabilistic account of
the numerical error. The method is also generalized to arbitrary non-linear
systems by imposing piece-wise semi-linearity on the prior via Jacobians of the
vector field at the previous estimates, resulting in probabilistic exponential
Rosenbrock methods. We evaluate the proposed methods on multiple stiff
differential equations and demonstrate their improved stability and efficiency
over established probabilistic solvers. The present contribution thus expands
the range of problems that can be effectively tackled within probabilistic
numerics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:13:13 GMT""}]","2023-05-25"
"2305.14979","Gabriel Kasmi","Gabriel Kasmi and Laurent Dubus and Yves-Marie Saint Drenan and
  Philippe Blanc","Scale Matters: Attribution Meets the Wavelet Domain to Explain Model
  Sensitivity to Image Corruptions","main: 9 pages, appendix 19 pages, 32 figures, 5 tables",,,,"cs.CV cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Neural networks have shown remarkable performance in computer vision, but
their deployment in real-world scenarios is challenging due to their
sensitivity to image corruptions. Existing attribution methods are
uninformative for explaining the sensitivity to image corruptions, while the
literature on robustness only provides model-based explanations. However, the
ability to scrutinize models' behavior under image corruptions is crucial to
increase the user's trust. Towards this end, we introduce the Wavelet sCale
Attribution Method (WCAM), a generalization of attribution from the pixel
domain to the space-scale domain. Attribution in the space-scale domain reveals
where and on what scales the model focuses. We show that the WCAM explains
models' failures under image corruptions, identifies sufficient information for
prediction, and explains how zoom-in increases accuracy.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:13:32 GMT""}]","2023-05-25"
"2305.14980","Yuehong Chen","Yuehong Chen, Yu Dai and Mingde Ding","An Atypical Plateau-like Extreme-ultraviolet Late-phase Solar Flare
  Driven by the Non-radial Eruption of a Magnetic Flux Rope","Accepted by A&A",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent observations in extreme-ultraviolet (EUV) wavelengths reveal an EUV
late phase in some solar flares, which is characterized by a second peak in the
warm coronal emissions (about 3 MK) occurring several tens of minutes to a few
hours after the corresponding main flare peak. We aim to clarify the physical
origin of an atypical plateau-like EUV late phase in an X1.8-class solar flare
occurring on 2011 September 7 from active region (AR) 11283. We first
characterize the plateau-like late phase using EUV Variability Experiment (EVE)
full-disk integrated irradiance observations and Atmospheric Imaging Assembly
(AIA) spatially-resolved imaging observations on board the Solar Dynamics
Observatory (SDO). Then we perform a nonlinear force-free-field (NLFFF)
extrapolation, from which a filament-hosting magnetic flux rope (MFR) is
revealed. The eruption of the MFR is tracked both in the plane of the sky (POS)
and along the line of sight (LOS) through visual inspection and spectral
fitting, respectively. Finally, we carry out differential emission measure
(DEM) analysis to explore the thermodynamics of the late-phase loops. The MFR
shows a non-radial eruption from a fan-spine magnetic structure. The eruption
of the MFR and its interaction with overlying arcades invoke multiple magnetic
reconnections, which are responsible for the production of different groups of
late-phase loops. Afterwards, the late-phase loops enter a long-lasting cooling
stage, appearing sequentially in AIA passbands of decreasing response
temperatures. Due to their different lengths, the different groups of
late-phase loops cool down at different cooling rates, which makes their warm
coronal emission peaks temporally separated from each other. Combing the
emissions from all late-phase loops together, an elongated plateau-like late
phase is formed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:13:57 GMT""}]","2023-05-25"
"2305.14981","Muhao Chen","Tanay Dixit, Fei Wang, Muhao Chen","Improving Factuality of Abstractive Summarization without Sacrificing
  Summary Quality","ACL 2023",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Improving factual consistency of abstractive summarization has been a widely
studied topic. However, most of the prior works on training factuality-aware
models have ignored the negative effect it has on summary quality. We propose
EFACTSUM (i.e., Effective Factual Summarization), a candidate summary
generation and ranking technique to improve summary factuality without
sacrificing summary quality. We show that using a contrastive learning
framework with our refined candidate summaries leads to significant gains on
both factuality and similarity-based metrics. Specifically, we propose a
ranking strategy in which we effectively combine two metrics, thereby
preventing any conflict during training. Models trained using our approach show
up to 6 points of absolute improvement over the base model with respect to
FactCC on XSUM and 11 points on CNN/DM, without negatively affecting either
similarity-based metrics or absractiveness.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:15:17 GMT""}]","2023-05-25"
"2305.14982","Firoj Alam","Ahmed Abdelali, Hamdy Mubarak, Shammur Absar Chowdhury, Maram
  Hasanain, Basel Mousi, Sabri Boughorbel, Yassine El Kheir, Daniel Izham,
  Fahim Dalvi, Majd Hawasly, Nizi Nazar, Yousseif Elshahawy, Ahmed Ali, Nadir
  Durrani, Natasa Milic-Frayling, Firoj Alam","Benchmarking Arabic AI with Large Language Models","Foundation Models, Large Language Models, Arabic NLP, Arabic Speech,
  Arabic AI, , CHatGPT Evaluation, USM Evaluation, Whisper Evaluation",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With large Foundation Models (FMs), language technologies (AI in general) are
entering a new paradigm: eliminating the need for developing large-scale
task-specific datasets and supporting a variety of tasks through set-ups
ranging from zero-shot to few-shot learning. However, understanding FMs
capabilities requires a systematic benchmarking effort by comparing FMs
performance with the state-of-the-art (SOTA) task-specific models. With that
goal, past work focused on the English language and included a few efforts with
multiple languages. Our study contributes to ongoing research by evaluating FMs
performance for standard Arabic NLP and Speech processing, including a range of
tasks from sequence tagging to content classification across diverse domains.
We start with zero-shot learning using GPT-3.5-turbo, Whisper, and USM,
addressing 33 unique tasks using 59 publicly available datasets resulting in 96
test setups. For a few tasks, FMs performs on par or exceeds the performance of
the SOTA models but for the majority it under-performs. Given the importance of
prompt for the FMs performance, we discuss our prompt strategies in detail and
elaborate on our findings. Our future work on Arabic AI will explore few-shot
prompting, expand the range of tasks, and investigate additional open-source
models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:16:16 GMT""}]","2023-05-25"
"2305.14983","Benjamin Lowe","Benjamin Lowe, Bernard Field, Jack Hellerstedt, Julian Ceddia, Henry
  L. Nourse, Ben J. Powell, Nikhil V. Medhekar, and Agustin Schiffrin","Gate control of Mott metal-insulator transition in a 2D metal-organic
  framework","19 pages, 4 figures",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Strong electron-electron Coulomb interactions in materials can lead to a vast
range of exotic many-body quantum phenomena, including Mott metal-insulator
transitions, magnetic order, quantum spin liquids, and unconventional
superconductivity. These many-body phases are strongly dependent on band
occupation and can hence be controlled via the chemical potential. Flat
electronic bands in two-dimensional (2D) and layered materials such as the
kagome lattice, enhance strong electronic correlations. Although theoretically
predicted, correlated-electron phases in monolayer 2D metal-organic frameworks
(MOFs) - which benefit from efficient synthesis protocols and tunable
properties - with a kagome structure have not yet been realised experimentally.
Here, we synthesise a 2D kagome MOF comprised of 9,10-dicyanoanthracene
molecules and copper atoms on an atomically thin insulator, monolayer hexagonal
boron nitride (hBN) on Cu(111). Scanning tunnelling microscopy (STM) and
spectroscopy reveal an electronic energy gap of ~200 meV in this MOF,
consistent with dynamical mean-field theory predictions of a Mott insulating
phase. By tuning the electron population of kagome bands, via either
template-induced (via local work function variations of the hBN/Cu(111)
substrate) or tip-induced (via the STM probe) gating, we are able to induce
Mott metal-insulator transitions in the MOF. These findings pave the way for
devices and technologies based on 2D MOFs and on electrostatic control of
many-body quantum phases therein.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:17:10 GMT""}]","2023-05-25"
"2305.14984","Manuel Gl\""ockler","Manuel Gl\""ockler, Michael Deistler, Jakob H. Macke","Adversarial robustness of amortized Bayesian inference",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Bayesian inference usually requires running potentially costly inference
procedures separately for every new observation. In contrast, the idea of
amortized Bayesian inference is to initially invest computational cost in
training an inference network on simulated data, which can subsequently be used
to rapidly perform inference (i.e., to return estimates of posterior
distributions) for new observations. This approach has been applied to many
real-world models in the sciences and engineering, but it is unclear how robust
the approach is to adversarial perturbations in the observed data. Here, we
study the adversarial robustness of amortized Bayesian inference, focusing on
simulation-based estimation of multi-dimensional posterior distributions. We
show that almost unrecognizable, targeted perturbations of the observations can
lead to drastic changes in the predicted posterior and highly unrealistic
posterior predictive samples, across several benchmark tasks and a real-world
example from neuroscience. We propose a computationally efficient
regularization scheme based on penalizing the Fisher information of the
conditional density estimator, and show how it improves the adversarial
robustness of amortized Bayesian inference.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:18:45 GMT""}]","2023-05-25"
"2305.14985","Haoxuan You","Haoxuan You, Rui Sun, Zhecan Wang, Long Chen, Gengyu Wang, Hammad A.
  Ayyubi, Kai-Wei Chang, Shih-Fu Chang","IdealGPT: Iteratively Decomposing Vision and Language Reasoning via
  Large Language Models","13 pages, 5 figures",,,,"cs.CV cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The field of vision-and-language (VL) understanding has made unprecedented
progress with end-to-end large pre-trained VL models (VLMs). However, they
still fall short in zero-shot reasoning tasks that require multi-step
inferencing. To achieve this goal, previous works resort to a
divide-and-conquer pipeline. In this paper, we argue that previous efforts have
several inherent shortcomings: 1) They rely on domain-specific sub-question
decomposing models. 2) They force models to predict the final answer even if
the sub-questions or sub-answers provide insufficient information. We address
these limitations via IdealGPT, a framework that iteratively decomposes VL
reasoning using large language models (LLMs). Specifically, IdealGPT utilizes
an LLM to generate sub-questions, a VLM to provide corresponding sub-answers,
and another LLM to reason to achieve the final answer. These three modules
perform the divide-and-conquer procedure iteratively until the model is
confident about the final answer to the main question. We evaluate IdealGPT on
multiple challenging VL reasoning tasks under a zero-shot setting. In
particular, our IdealGPT outperforms the best existing GPT-4-like models by an
absolute 10% on VCR and 15% on SNLI-VE. Code is available at
https://github.com/Hxyou/IdealGPT
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:19:57 GMT""}]","2023-05-25"
"2305.14986","Gorana Goji\'c","Gorana Goji\'c, Vladimir Vincan, Ognjen Kunda\v{c}ina, Dragi\v{s}a
  Mi\v{s}kovi\'c and Dinu Dragan","Non-adversarial Robustness of Deep Learning Methods for Computer Vision",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  Non-adversarial robustness, also known as natural robustness, is a property
of deep learning models that enables them to maintain performance even when
faced with distribution shifts caused by natural variations in data. However,
achieving this property is challenging because it is difficult to predict in
advance the types of distribution shifts that may occur. To address this
challenge, researchers have proposed various approaches, some of which
anticipate potential distribution shifts, while others utilize knowledge about
the shifts that have already occurred to enhance model generalizability. In
this paper, we present a brief overview of the most recent techniques for
improving the robustness of computer vision methods, as well as a summary of
commonly used robustness benchmark datasets for evaluating the model's
performance under data distribution shifts. Finally, we examine the strengths
and limitations of the approaches reviewed and identify general trends in deep
learning robustness improvement for computer vision.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:21:31 GMT""}]","2023-05-25"
"2305.14987","Yilun Zhao","Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang,
  Arman Cohan","Large Language Models are Effective Table-to-Text Generators,
  Evaluators, and Feedback Providers","work in progress",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have shown remarkable ability on controllable
text generation. However, the potential of LLMs in generating text from
structured tables remains largely under-explored. In this paper, we study the
capabilities of LLMs for table-to-text generation tasks, particularly aiming to
investigate their performance in generating natural language statements that
can be logically entailed by a provided table. First, we investigate how LLMs
compare to state-of-the-art table-to-text fine-tuned models, and demonstrate
that LLMs can generate statements with higher faithfulness compared with
previous state-of-the-art fine-tuned models. Given this finding, we next
explore whether LLMs can serve as faithfulness-level automated evaluation
metrics. Through human evaluation, we show that evaluation metrics adopted from
LLMs correlates better with human judgments compared with existing
faithfulness-level metrics. Finally, we demonstrate that LLMs using
chain-of-thought prompting can generate high-fidelity natural language feedback
for other table-to-text models' generations, provide insights for future work
regarding the distillation of text generation capabilities from LLMs to smaller
models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:22:30 GMT""}]","2023-05-25"
"2305.14988","Shraddha Rajkhowa","Shraddha Rajkhowa and Nipen Saikia","Some Identities of Ramanujan's q-Continued Fractions of Order Fourteen
  and Twenty-Eight, and Vanishing Coefficients","8 Pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We deduce $q$-continued fractions $S_{1}(q)$, $S_{2}(q)$ and $S_{3}(q)$ of
order fourteen, and continued fractions $V_{1}(q)$, $V_{2}(q)$ and $V_{3}(q)$
of order twenty-eight from a general continued fraction identity of Ramanujan.
We establish some theta-function identities for the continued fractions and
derive some colour partition identities as applications. Some vanishing
coefficients results arising from the continued fractions are also offered.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:22:39 GMT""}]","2023-05-25"
"2305.14989","Abdelrahim Elmadany","El Moatez Billah Nagoudi, Ahmed El-Shangiti, AbdelRahim Elmadany,
  Muhammad Abdul-Mageed","Dolphin: A Challenging and Diverse Benchmark for Arabic NLG",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Dolphin, a novel benchmark that addresses the need for an
evaluation framework for the wide collection of Arabic languages and varieties.
The proposed benchmark encompasses a broad range of 13 different NLG tasks,
including text summarization, machine translation, question answering, and
dialogue generation, among others. Dolphin comprises a substantial corpus of 40
diverse and representative public datasets across 50 test splits, carefully
curated to reflect real-world scenarios and the linguistic richness of Arabic.
It sets a new standard for evaluating the performance and generalization
capabilities of Arabic and multilingual models, promising to enable researchers
to push the boundaries of current methodologies. We provide an extensive
analysis of Dolphin, highlighting its diversity and identifying gaps in current
Arabic NLG research. We also evaluate several Arabic and multilingual models on
our benchmark, allowing us to set strong baselines against which researchers
can compare.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:24:10 GMT""}]","2023-05-25"
"2305.14990","Ratna Kumar Annabattula","Akhil Reddy Peeketi, Edwin Joseph, Narasimhan Swaminathan, Ratna Kumar
  Annabattula","Photo-activated dynamic isomerization induced large density changes in
  liquid crystal polymers: A molecular dynamics study",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Recent experimental results [Liu and Broer, Nat. Commun. 6 8334 (2015)]
reveal that light-responsive azo-doped liquid crystal polymers under
dual-wavelength illumination exhibit a significant reduction in density. This
reduction in density was attributed to dynamic trans-cis-trans isomerization
cycles. The light-induced isomerization kinetics suggest that the fraction of
isomers undergoing dynamic isomerization increases with the light sources'
intensity. However, experiments have shown that such an increase in intensity
does not result in a monotonic decrease in density. Further, it was observed
that there exists an optimal combination of the intensities of the
dual-wavelength illumination that results in a maximum density reduction. The
exact reason for the existence of such an optimal combination remains elusive.
In this work, we have performed atomistic simulations to confirm the hypothesis
that the density reduction is caused by the dynamic trans-cis-trans
isomerization cycles. Subsequently, the atomistic simulations are used to
decipher the underlying physics responsible for the counter-intuitive relation
between density reduction and intensities. Intensity variations are simulated
by varying the forward and backward isomerization probabilities. The
simulations show that an optimal combination of these two probabilities will
exhibit a maximum density reduction corroborating experimental observations.
Consequently, we discovered that a specific frequency of the dynamic
trans-cis-trans isomerization cycles would induce maximum distortion in the
polymer network resulting in significant density reduction.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:25:50 GMT""}]","2023-05-25"
"2305.14991","Leshem Choshen","Taelin Karidi, Leshem Choshen, Gal Patel, Omri Abend","MuLER: Detailed and Scalable Reference-based Evaluation",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  We propose a novel methodology (namely, MuLER) that transforms any
reference-based evaluation metric for text generation, such as machine
translation (MT) into a fine-grained analysis tool.
  Given a system and a metric, MuLER quantifies how much the chosen metric
penalizes specific error types (e.g., errors in translating names of
locations). MuLER thus enables a detailed error analysis which can lead to
targeted improvement efforts for specific phenomena.
  We perform experiments in both synthetic and naturalistic settings to support
MuLER's validity and showcase its usability in MT evaluation, and other tasks,
such as summarization. Analyzing all submissions to WMT in 2014-2020, we find
consistent trends. For example, nouns and verbs are among the most frequent POS
tags. However, they are among the hardest to translate. Performance on most POS
tags improves with overall system performance, but a few are not thus
correlated (their identity changes from language to language). Preliminary
experiments with summarization reveal similar trends.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:26:13 GMT""}]","2023-05-25"
"2305.14992","Shibo Hao","Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe
  Wang, Zhiting Hu","Reasoning with Language Model is Planning with World Model",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LLMs) have shown remarkable reasoning capabilities,
especially when prompted to generate intermediate reasoning steps (e.g.,
Chain-of-Thought, CoT). However, LLMs can still struggle with problems that are
easy for humans, such as generating action plans for executing tasks in a given
environment, or performing complex math, logical, and commonsense reasoning.
The deficiency stems from the key fact that LLMs lack an internal
$\textit{world model}$ to predict the world $\textit{state}$ (e.g., environment
status, intermediate variable values) and simulate long-term outcomes of
actions. This prevents LLMs from performing deliberate planning akin to human
brains, which involves exploring alternative reasoning paths, anticipating
future states and rewards, and iteratively refining existing reasoning steps.
To overcome the limitations, we propose a new LLM reasoning framework,
$\underline{R}\textit{easoning vi}\underline{a} \underline{P}\textit{lanning}$
$\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning
agent, and incorporates a principled planning algorithm (based on Monto Carlo
Tree Search) for strategic exploration in the vast reasoning space. During
reasoning, the LLM (as agent) incrementally builds a reasoning tree under the
guidance of the LLM (as world model) and task-specific rewards, and obtains a
high-reward reasoning path efficiently with a proper balance between
exploration $\textit{vs.}$ exploitation. We apply RAP to a variety of
challenging reasoning problems including plan generation, math reasoning, and
logical inference. Empirical results on these tasks demonstrate the superiority
of RAP over various strong baselines, including CoT and least-to-most prompting
with self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%
relative improvement in a plan generation setting.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:28:28 GMT""}]","2023-05-25"
"2305.14993","Sweta Agrawal","Sweta Agrawal and Marine Carpuat","How To Control Text Simplification? An Empirical Study of Control Tokens
  for Meaning Preserving Controlled Simplification","work in progress",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Text simplification rewrites text to be more readable for a specific
audience, while preserving its meaning. However, determining what makes a text
easy to read depends on who are the intended readers. Recent work has
introduced a wealth of techniques to control output simplicity, ranging from
specifying the desired reading grade level to providing control tokens that
directly encode low-level simplification edit operations. However, it remains
unclear how to set the input parameters that control simplification in
practice. Existing approaches set them at the corpus level, disregarding the
complexity of individual source text, and do not directly evaluate them at the
instance level. In this work, we conduct an empirical study to understand how
different control mechanisms impact the adequacy and simplicity of model
outputs. Based on these insights, we introduce a simple method for predicting
control tokens at the sentence level to enhance the quality of the simplified
text. Predicting control token values using features extracted from the
original complex text and a user-specified degree of complexity improves the
quality of the simplified outputs over corpus-level search-based heuristics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:29:45 GMT""}]","2023-05-25"
"2305.14994","Dongjie Yang","Dongjie Yang, Ruifeng Yuan, YuanTao Fan, YiFei Yang, Zili Wang, Shusen
  Wang, Hai Zhao","RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs
  and for GPTs",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  General chat models, like ChatGPT, have attained impressive capability to
resolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with
high-quality instruction data. However, collecting human-written high-quality
data, especially multi-turn dialogues, is expensive and unattainable for most
people. Though previous studies have used powerful LLMs to generate the
dialogues automatically, but they all suffer from generating untruthful
dialogues because of the LLMs hallucination. Therefore, we propose a method
called RefGPT to generate enormous truthful and customized dialogues without
worrying about factual errors caused by the model hallucination. RefGPT solves
the model hallucination in dialogue generation by restricting the LLMs to
leverage the given reference instead of reciting their own knowledge to
generate dialogues. Additionally, RefGPT adds detailed controls on every
utterances to enable highly customization capability, which previous studies
have ignored. On the basis of RefGPT, we also propose two high-quality dialogue
datasets generated by GPT-4, namely RefGPT-Fact and RefGPT-Code. RefGPT-Fact is
100k multi-turn dialogue datasets based on factual knowledge and RefGPT-Code is
76k multi-turn dialogue dataset covering a wide range of coding scenarios. Our
code and datasets are released in https://github.com/ziliwangnlp/RefGPT
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:30:42 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 02:20:51 GMT""}]","2023-05-26"
"2305.14995","Benjamin Arras","Benjamin Arras","Some Notes on Quantitative Generalized CLTs with Self-Decomposable
  Limiting Laws by Spectral Methods","102 pages",,,,"math.PR math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In these notes, we obtain new stability estimates for centered
self-decomposable probability measures on $\mathbb{R}^d$ with finite second
moment and for non-degenerate symmetric $\alpha$-stable probability measures on
$\mathbb{R}^d$ with $\alpha \in (1,2)$. These new results are refinements of
the corresponding ones available in the literature. The proofs are based on
Stein's method for self-decomposable laws, recently developed in a series of
papers, and on closed forms techniques together with a new ingredient: weighted
Poincar\'e-type inequalities. As applications, rates of convergence in
Wasserstein-type distances are computed for several instances of the
generalized central limit theorems (CLTs). In particular, a
$n^{1-2/\alpha}$-rate is obtained in $1$-Wasserstein distance when the target
law is a non-degenerate symmetric $\alpha$-stable one with $\alpha \in (1,2)$.
Finally, the non-degenerate symmetric Cauchy case is studied at length from a
spectral point of view. At last, in this Cauchy situation, a $n^{-1}$-rate of
convergence is obtained when the initial law is a certain instance of layered
stable distributions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:32:47 GMT""}]","2023-05-25"
"2305.14996","Yanxia Qin","Shaurya Rohatgi, Yanxia Qin, Benjamin Aw, Niranjana Unnithan, Min-Yen
  Kan","The ACL OCL Corpus: advancing Open science in Computational Linguistics",,,,,"cs.CL cs.DL","http://creativecommons.org/licenses/by/4.0/","  We present a scholarly corpus from the ACL Anthology to assist Open
scientific research in the Computational Linguistics domain, named as ACL OCL.
Compared with previous ARC and AAN versions, ACL OCL includes structured
full-texts with logical sections, references to figures, and links to a large
knowledge resource (semantic scholar). ACL OCL contains 74k scientific papers,
together with 210k figures extracted up to September 2022. To observe the
development in the computational linguistics domain, we detect the topics of
all OCL papers with a supervised neural model. We observe ''Syntax: Tagging,
Chunking and Parsing'' topic is significantly shrinking and ''Natural Language
Generation'' is resurging. Our dataset is open and available to download from
HuggingFace in https://huggingface.co/datasets/ACL-OCL/ACL-OCL-Corpus.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:35:56 GMT""}]","2023-05-25"
"2305.14997","Jianhua Zhang","Zhaowei Chang and Jianhua Zhang and Pan Tang and Lei Tian and Yadong
  Yang and Jiaxin Lin and and Guangyi Liu","3GPP-Like THz Channel Modeling for Indoor Office and Urban Microcellular
  Scenarios","13 pages, 12 figures, 3 tables",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Terahertz (THz) communication is envisioned as the possible technology for
the sixth-generation (6G) communication system. THz channel propagation
characteristics are the basis of designing and evaluating for THz communication
system. In this paper, THz channel measurements at 100 GHz and 132 GHz are
conducted in an indoor office scenario and an urban microcellular (UMi)
scenario, respectively. Based on the measurement, the 3GPP-like channel
parameters are extracted and analyzed. Moreover, the parameters models are
available for the simulation of the channel impulse response by the
geometry-based stochastic model (GBSM). Then, the comparisons between
measurement-based parameter models and 3rd Generation Partnership Project
(3GPP) channel models are investigated. It is observed that the case with path
loss approaching free space exists in the NLoS scenario. Besides, the cluster
number are 4 at LoS and 5 at NLoS in the indoor office and 4 at LoS and 3 at
NLoS in the UMi, which are much less than 3GPP. The multipath component (MPC)
in the THz channel distributes more simpler and more sparsely than the 3GPP
millimeter wave (mm-wave) channel models. Furthermore, the ergodic capacity of
mm-wave and THz are evaluated by the proposed THz GBSM implementation
framework. The THz measurement model predicts the smallest capacity, indicating
that high carrier frequency is limited to the single transmission mechanism of
reflection and results in the reduction of cluster numbers and ergodic
capacity. Generally, these results are helpful to understand and model the THz
channel and apply the THz communication technique for 6G.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:36:04 GMT""}]","2023-05-26"
"2305.14998","Saba Ahmadi","Saba Ahmadi, Aishwarya Agrawal","An Examination of the Robustness of Reference-Free Image Captioning
  Evaluation Metrics",,,,,"cs.CL cs.AI cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and
UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image
captions, demonstrating a high correlation with human judgment. In this work,
our focus lies in evaluating the robustness of these metrics in scenarios that
require distinguishing between two captions with high lexical overlap but very
different meanings. Our findings reveal that despite their high correlation
with human judgment, both CLIPScore and UMIC struggle to identify fine-grained
errors in captions. However, when comparing different types of fine-grained
errors, both metrics exhibit limited sensitivity to implausibility of captions
and strong sensitivity to lack of sufficient visual grounding. Probing further
into the visual grounding aspect, we found that both CLIPScore and UMIC are
impacted by the size of image-relevant objects mentioned in the caption, and
that CLIPScore is also sensitive to the number of mentions of image-relevant
objects in the caption. In terms of linguistic aspects of a caption, we found
that both metrics lack the ability to comprehend negation, UMIC is sensitive to
caption lengths, and CLIPScore is insensitive to the structure of the sentence.
We hope our findings will serve as a valuable guide towards improving
reference-free evaluation in image captioning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:36:12 GMT""}]","2023-05-25"
"2305.14999","Zhiyang Xu","Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, Qifan Wang,
  Lifu Huang","The Art of SOCRATIC QUESTIONING: Zero-shot Multimodal Reasoning with
  Recursive Thinking and Self-Questioning","15 pages, 12 figure, 2 algorithms",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Chain-of-Thought prompting (CoT) enables large-scale language models to solve
complex reasoning problems by decomposing the problem and tackling it
step-by-step. However, Chain-of-Thought is a greedy thinking process that
requires the language model to come up with a starting point and generate the
next step solely based on previous steps. This thinking process is different
from how humans approach a complex problem e.g., we proactively raise
sub-problems related to the original problem and recursively answer them. In
this work, we propose Socratic Questioning, a divide-and-conquer fashion
algorithm that simulates the self-questioning and recursive thinking process.
Socratic Questioning is driven by a Self-Questioning module that employs a
large-scale language model to propose sub-problems related to the original
problem as intermediate steps and Socratic Questioning recursively backtracks
and answers the sub-problems until reaches the original problem. We apply our
proposed algorithm to the visual question-answering task as a case study and by
evaluating it on three public benchmark datasets, we observe a significant
performance improvement over all baselines on (almost) all datasets. In
addition, the qualitative analysis clearly demonstrates the intermediate
thinking steps elicited by Socratic Questioning are similar to the human's
recursively thinking process of a complex reasoning problem.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:36:14 GMT""}]","2023-05-25"
"2305.15000","Christian Berger","Christian Berger, L\'ivio Rodrigues, Hans P. Reiser, Vinicius Cogo,
  Alysson Bessani","Chasing the Speed of Light: Low-Latency Planetary-Scale Adaptive
  Byzantine Consensus","18 pages",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blockchain technology has sparked renewed interest in planetary-scale
Byzantine fault-tolerant (BFT) state machine replication (SMR). While recent
works have mainly focused on improving the scalability and throughput of these
protocols, few have addressed latency. We present FlashConsensus, a novel
transformation for optimizing the latency of quorum-based BFT consensus
protocols. FLASHCONSENSUS uses an adaptive resilience threshold that enables
faster transaction ordering when the system contains few faulty replicas. Our
construction exploits adaptive weighted replication to automatically assign
high voting power to the fastest replicas, forming small quorums that
significantly speed up consensus. Even when using such quorums with a smaller
resilience threshold, FlashConsensus still satisfies the standard SMR safety
and liveness guarantees with optimal resilience, thanks to the judicious
integration of abortable SMR and BFT forensics techniques. Our experiments with
tens of replicas spread in all continents show that FLASHCONSENSUS can order
transactions with finality in less than 0.4s, half the time of a PBFT-like
protocol (with optimal consensus latency) in the same network, and matching the
latency of this protocol running on the theoretically best possible internet
links (transmitting at 67% of the speed of light).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:37:17 GMT""}]","2023-05-25"
"2305.15001","Anand Gopalakrishnan","Aleksandar Stani\'c, Anand Gopalakrishnan, Kazuki Irie, J\""urgen
  Schmidhuber","Contrastive Training of Complex-Valued Autoencoders for Object Discovery","26 pages, 14 figures",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Current state-of-the-art object-centric models use slots and attention-based
routing for binding. However, this class of models has several conceptual
limitations: the number of slots is hardwired; all slots have equal capacity;
training has high computational cost; there are no object-level relational
factors within slots. Synchrony-based models in principle can address these
limitations by using complex-valued activations which store binding information
in their phase components. However, working examples of such synchrony-based
models have been developed only very recently, and are still limited to toy
grayscale datasets and simultaneous storage of less than three objects in
practice. Here we introduce architectural modifications and a novel contrastive
learning method that greatly improve the state-of-the-art synchrony-based
model. For the first time, we obtain a class of synchrony-based models capable
of discovering objects in an unsupervised manner in multi-object color datasets
and simultaneously representing more than three objects
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:37:43 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 08:57:57 GMT""}]","2023-05-26"
"2305.15002","Asahi Ushio","Asahi Ushio and Jose Camacho Collados and Steven Schockaert","A RelEntLess Benchmark for Modelling Graded Relations between Named
  Entities",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Relations such as ""is influenced by"", ""is known for"" or ""is a competitor of""
are inherently graded: we can rank entity pairs based on how well they satisfy
these relations, but it is hard to draw a line between those pairs that satisfy
them and those that do not. Such graded relations play a central role in many
applications, yet they are typically not covered by existing Knowledge Graphs.
In this paper, we consider the possibility of using Large Language Models
(LLMs) to fill this gap. To this end, we introduce a new benchmark, in which
entity pairs have to be ranked according to how much they satisfy a given
graded relation. The task is formulated as a few-shot ranking problem, where
models only have access to a description of the relation and five prototypical
instances. We use the proposed benchmark to evaluate state-of-the-art relation
embedding strategies as well as several recent LLMs, covering both publicly
available LLMs and closed models such as GPT-4. Overall, we find a strong
correlation between model size and performance, with smaller Language Models
struggling to outperform a naive baseline. The results of the largest Flan-T5
and OPT models are remarkably strong, although a clear gap with human
performance remains.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:41:24 GMT""}]","2023-05-25"
"2305.15003","Ashwin George","Ashwin George, Luciano Cavalcante Siebert, David Abbink and Arkady
  Zgonnikov","Measuring Causal Responsibility in Multi-Agent Spatial Interactions with
  Feasible Action-Space Reduction",,,,,"cs.MA","http://creativecommons.org/licenses/by-sa/4.0/","  Modelling causal responsibility in multi-agent spatial interactions is
crucial for safety and efficiency of interactions of humans with autonomous
agents. However, current formal metrics and models of responsibility either
lack grounding in ethical and philosophical concepts of responsibility, or
cannot be applied to spatial interactions. In this work we propose a metric of
causal responsibility which is tailored to multi-agent spatial interactions,
for instance interactions in traffic. In such interactions, a given agent can,
by reducing another agent's feasible action space, influence the latter.
Therefore, we propose feasible action space reduction (FeAR) as a metric for
causal responsibility among agents. Specifically, we look at ex-post causal
responsibility for simultaneous actions. We propose the use of Moves de Rigueur
- a consistent set of prescribed actions for agents - to model the effect of
norms on responsibility allocation. We apply the metric in a grid world
simulation for spatial interactions and show how the actions, contexts, and
norms affect the causal responsibility ascribed to agents. Finally, we
demonstrate the application of this metric in complex multi-agent interactions.
We argue that the FeAR metric is a step towards an interdisciplinary framework
for quantifying responsibility that is needed to ensure safety and meaningful
human control in human-AI systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:44:57 GMT""}]","2023-05-25"
"2305.15004","Kangxi Wu","Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng and Tat-Seng Chua","LLMDet: A Large Language Models Detection Tool","7 pages, 1 figure",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  With the advancement of generative language models, the generated text has
come remarkably close to high-quality human-authored text in terms of fluency
and diversity. This calls for a highly practical detection tool that can
identify the source of text, preferably pinpointing the language model it
originates from. However, existing detection tools typically require access to
language models and can only differentiate between machine-generated and
human-authored text, failing to meet the requirements of rapid detection and
text tracing. Therefore, in this paper, we propose an efficient, secure, and
scalable detection tool called LLMDet, which calculates the proxy perplexity of
text by utilizing the prior information of the model's next-token
probabilities, obtained through pre-training. Subsequently, we use the
self-watermarking information of the model, as measured by proxy perplexity, to
detect the source of the text. We found that our method demonstrates impressive
detection performance while ensuring speed and security, particularly achieving
a recognition accuracy of 97.97\% for human-authored text. Furthermore, our
detection tool also shows promising results in identifying the large language
model (e.g., GPT-2, OPT, LLaMA, Vicuna...) responsible for the text. We release
the code and processed data at \url{https://github.com/TrustedLLM/LLMDet}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:45:16 GMT""}]","2023-05-25"
"2305.15005","Wenxuan Zhang","Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, Lidong Bing","Sentiment Analysis in the Era of Large Language Models: A Reality Check",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sentiment analysis (SA) has been a long-standing research area in natural
language processing. It can offer rich insights into human sentiments and
opinions and has thus seen considerable interest from both academia and
industry. With the advent of large language models (LLMs) such as ChatGPT,
there is a great potential for their employment on SA problems. However, the
extent to which existing LLMs can be leveraged for different sentiment analysis
tasks remains unclear. This paper aims to provide a comprehensive investigation
into the capabilities of LLMs in performing various sentiment analysis tasks,
from conventional sentiment classification to aspect-based sentiment analysis
and multifaceted analysis of subjective texts. We evaluate performance across
13 tasks on 26 datasets and compare the results against small language models
(SLMs) trained on domain-specific datasets. Our study reveals that while LLMs
demonstrate satisfactory performance in simpler tasks, they lag behind in more
complex tasks requiring deeper understanding or structured sentiment
information. However, LLMs significantly outperform SLMs in few-shot learning
settings, suggesting their potential when annotation resources are limited. We
also highlight the limitations of current evaluation practices in assessing
LLMs' SA abilities and propose a novel benchmark, \textsc{SentiEval}, for a
more comprehensive and realistic evaluation. Data and code during our
investigations are available at
\url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:45:25 GMT""}]","2023-05-25"
"2305.15006","Nicola Leschke","Michael Gebauer, Faraz Maschhur, Nicola Leschke, Elias Gr\""unewald,
  Frank Pallas","A Human-in-the-Loop Approach for Information Extraction from Privacy
  Policies under Data Scarcity","Accepted for 2023 IEEE European Symposium on Security and Privacy
  Workshops (EuroS&P)",,,,"cs.CY cs.AI","http://creativecommons.org/licenses/by/4.0/","  Machine-readable representations of privacy policies are door openers for a
broad variety of novel privacy-enhancing and, in particular,
transparency-enhancing technologies (TETs). In order to generate such
representations, transparency information needs to be extracted from written
privacy policies. However, respective manual annotation and extraction
processes are laborious and require expert knowledge. Approaches for fully
automated annotation, in turn, have so far not succeeded due to overly high
error rates in the specific domain of privacy policies. In the end, a lack of
properly annotated privacy policies and respective machine-readable
representations persists and enduringly hinders the development and
establishment of novel technical approaches fostering policy perception and
data subject informedness.
  In this work, we present a prototype system for a `Human-in-the-Loop'
approach to privacy policy annotation that integrates ML-generated suggestions
and ultimately human annotation decisions. We propose an ML-based suggestion
system specifically tailored to the constraint of data scarcity prevalent in
the domain of privacy policy annotation. On this basis, we provide meaningful
predictions to users thereby streamlining the annotation process. Additionally,
we also evaluate our approach through a prototypical implementation to show
that our ML-based extraction approach provides superior performance over other
recently used extraction models for legal documents.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:45:26 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 09:58:15 GMT""}]","2023-06-01"
"2305.15007","Jacopo Giordano","Jacopo Giordano, Angelo Cenedese","Quaternion-based non-singular terminal sliding mode control for a
  satellite-mounted space manipulator","New figures and some text clarifications",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a robust control solution for a satellite equipped with a
robotic manipulator is presented. First, the dynamic model of the system is
derived based on quaternions to describe the evolution of the attitude of the
base satellite. Then, a non-singular terminal sliding mode controller that
employs quaternions for attitude control, is proposed for concurrently handling
all the degrees of freedom of the space manipulator. Moreover, an additional
adaptive term is embedded in the controller to estimate the upper bounds of
disturbances and uncertainties. The result is a resilient solution able to
withstand unmodelled dynamics and interactions. Lyapunov theory is used to
prove the stability of the controller and numerical simulations allow assessing
performance and fuel efficiency.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:46:42 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 13:27:53 GMT""}]","2023-05-26"
"2305.15008","Aman Priyanshu","Aman Priyanshu, Supriti Vijay, Ayush Kumar, Rakshit Naidu and
  Fatemehsadat Mireshghallah","Are Chatbots Ready for Privacy-Sensitive Applications? An Investigation
  into Input Regurgitation and Prompt-Induced Sanitization","12 pages, 9 figures, and 4 tables",,,,"cs.CL cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  LLM-powered chatbots are becoming widely adopted in applications such as
healthcare, personal assistants, industry hiring decisions, etc. In many of
these cases, chatbots are fed sensitive, personal information in their prompts,
as samples for in-context learning, retrieved records from a database, or as
part of the conversation. The information provided in the prompt could directly
appear in the output, which might have privacy ramifications if there is
sensitive information there. As such, in this paper, we aim to understand the
input copying and regurgitation capabilities of these models during inference
and how they can be directly instructed to limit this copying by complying with
regulations such as HIPAA and GDPR, based on their internal knowledge of them.
More specifically, we find that when ChatGPT is prompted to summarize cover
letters of a 100 candidates, it would retain personally identifiable
information (PII) verbatim in 57.4% of cases, and we find this retention to be
non-uniform between different subgroups of people, based on attributes such as
gender identity. We then probe ChatGPT's perception of privacy-related policies
and privatization mechanisms by directly instructing it to provide compliant
outputs and observe a significant omission of PII from output.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:48:05 GMT""}]","2023-05-25"
"2305.15009","Elena Losero","Elena Losero, Valentin Goblot, Yuchun Zhu, Hossein Babashah, Victor
  Boureau, Florian Burkart, and Christophe Galland","Creation of NV centers in diamond under 155 MeV electron irradiation",,,,,"quant-ph physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Single-crystal diamond substrates presenting a high concentration of
negatively charged nitrogen-vacancy centers (NV-) are on high demand for the
development of optically pumped solid-state sensors such as magnetometers,
thermometers or electrometers. While nitrogen impurities can be easily
incorporated during crystal growth, the creation of vacancies requires further
treatment. Electron irradiation and annealing is often chosen in this context,
offering advantages with respect to irradiation by heavier particles that
negatively affect the crystal lattice structure and consequently the NV-
optical and spin properties. A thorough investigation of electron irradiation
possibilities is needed to optimize the process and improve the sensitivity of
NV-based sensors. In this work we examine the effect of electron irradiation in
a previously unexplored regime: extremely high energy electrons, at 155 MeV. We
develop a simulation model to estimate the concentration of created vacancies
and experimentally demonstrate an increase of NV- concentration by more than 3
orders of magnitude following irradiation of a nitrogen-rich HPHT diamond over
a very large sample volume, which translates into an important gain in
sensitivity. Moreover, we discuss the impact of electron irradiation in this
peculiar regime on other figures of merits relevant for NV sensing, i.e. charge
state conversion efficiency and spin relaxation time. Finally, the effect of
extremely high energy irradiation is compared with the more conventional low
energy irradiation process, employing 200 keV electrons from a transmission
electron microscope, for different substrates and irradiation fluences,
evidencing sixty-fold higher yield of vacancy creation per electron at 155 MeV.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:48:47 GMT""}]","2023-05-25"
"2305.15010","Benyou Wang","Hongbo Zhang and Xiang Wan and Benyou Wang","Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism
  and Synonymous Substitution",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pre-trained language models (PLMs) were considered to be able to store
relational knowledge present in the training data. However, some relational
knowledge seems to be discarded unsafely in PLMs due to \textbf{report bias}:
low-frequency relational knowledge might be underexpressed compared to
high-frequency one in PLMs. This gives us a hint that relational knowledge
might not be redundant to the stored knowledge of PLMs, but rather be
complementary. To additionally inject relational knowledge into PLMs, we
propose a simple-yet-effective approach to inject relational knowledge into
PLMs, which is inspired by three observations (namely, polymorphism, synonymous
substitution, and association). In particular, we switch entities in the
training corpus to related entities (either hypernyms/hyponyms/synonyms, or
arbitrarily-related concepts). Experimental results show that the proposed
approach could not only better capture relational knowledge, but also improve
the performance in various biomedical downstream tasks. Our model is available
in \url{https://github.com/StevenZHB/BioPLM_InjectingKnowledge}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:48:53 GMT""}]","2023-05-25"
"2305.15011","Fajri Koto","Haonan Li and Fajri Koto and Minghao Wu and Alham Fikri Aji and
  Timothy Baldwin","Bactrian-X : A Multilingual Replicable Instruction-Following Model with
  Low-Rank Adaptation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Instruction tuning has shown great promise in the field of natural language
processing. However, the research on multilingual instruction tuning has been
limited due to the scarcity of high-quality instruction-response datasets. To
address this gap, we present Bactrian-X, a comprehensive multilingual parallel
dataset of 3.4 million instruction-response pairs across 52 languages.
Leveraging this dataset, we train a set of adapters using low-rank adaptation
(LoRA), which are lightweight components seamlessly integrated with
foundational models. These adapters have a significantly smaller parameter
count than the base model, making them easily replaceable and usable as
plug-ins for different languages or language groups. Through extensive
experiments on 52 languages, we demonstrate the superior performance of our
models in various multilingual evaluation settings. Our proposed models
outperform both the vanilla models and the existing instruction-tuned models.
The code and models are publicly available at
https://github.com/mbzuai-nlp/bactrian-x.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:50:31 GMT""}]","2023-05-25"
"2305.15012","Mir Alimuddin","Jitendra Joshi, Mir Alimuddin, T S Mahesh, Manik Banik","Experimental Verification of Many-Body Entanglement Using Thermodynamic
  Quantities","4.5 pages (two-column) + 9.5 pages (one-column) + 5 figures; Comments
  are welcome",,,,"quant-ph cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  The phenomenon of quantum entanglement underlies several important protocols
that enable emerging quantum technologies. Being an extremely delicate resource
entangled states easily get perturbed by their external environment, and thus
makes the question of entanglement certification immensely crucial for
successful implementation of the protocols involving entanglement. In this
work, we propose a set of entanglement criteria for multi-qubit systems that
can be easily verified by measuring certain thermodynamic quantities. In
particular, the criteria depend on the difference in optimal works extractable
from an isolated quantum system under global and local interactions,
respectively. As a proof of principle, we demonstrate the proposed
thermodynamic criteria on nuclear spin registers of up to 10 qubits using
Nuclear Magnetic Resonance architecture. We prepare noisy
Greenberger-Horne-Zeilinger class of states in star-topology systems and
certify their entanglement through our proposed criteria. We also provide
elegant means of entanglement certification in many-body systems when only
partial or even no knowledge about the state is available.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:52:35 GMT""}]","2023-05-25"
"2305.15013","Linxuan Pan","Linxuan Pan, Shenghui Song","Local SGD Accelerates Convergence by Exploiting Second Order Information
  of the Loss Function",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  With multiple iterations of updates, local statistical gradient descent
(L-SGD) has been proven to be very effective in distributed machine learning
schemes such as federated learning. In fact, many innovative works have shown
that L-SGD with independent and identically distributed (IID) data can even
outperform SGD. As a result, extensive efforts have been made to unveil the
power of L-SGD. However, existing analysis failed to explain why the multiple
local updates with small mini-batches of data (L-SGD) can not be replaced by
the update with one big batch of data and a larger learning rate (SGD). In this
paper, we offer a new perspective to understand the strength of L-SGD. We
theoretically prove that, with IID data, L-SGD can effectively explore the
second order information of the loss function. In particular, compared with
SGD, the updates of L-SGD have much larger projection on the eigenvectors of
the Hessian matrix with small eigenvalues, which leads to faster convergence.
Under certain conditions, L-SGD can even approach the Newton method. Experiment
results over two popular datasets validate the theoretical results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:54:45 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 05:18:28 GMT""}]","2023-05-29"
"2305.15014","Xingxuan Li","Xingxuan Li, Liying Cheng, Qingyu Tan, Hwee Tou Ng, Shafiq Joty,
  Lidong Bing","Unlocking Temporal Question Answering for Large Language Models Using
  Code Execution",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LLMs) have made significant progress in natural
language processing (NLP), and are utilized extensively in various
applications. Recent works, such as chain-of-thought (CoT), have shown that
intermediate reasoning steps can improve the performance of LLMs for complex
reasoning tasks, such as math problems and symbolic question-answering tasks.
However, we notice the challenge that LLMs face when it comes to temporal
reasoning. Our preliminary experiments show that generating intermediate
reasoning steps does not always boost the performance of complex temporal
question-answering tasks. Therefore, we propose a novel framework that combines
the extraction capability of LLMs and the logical reasoning capability of a
Python solver to tackle this issue. Extensive experiments and analysis
demonstrate the effectiveness of our framework in handling intricate time-bound
reasoning tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:57:53 GMT""}]","2023-05-25"
"2305.15015","Daniel Reich","Daniel Reich, Felix Putze, Tanja Schultz","Measuring Faithful and Plausible Visual Grounding in VQA",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metrics for Visual Grounding (VG) in Visual Question Answering (VQA) systems
primarily aim to measure a system's reliance on relevant parts of the image
when inferring an answer to the given question. Lack of VG has been a common
problem among state-of-the-art VQA systems and can manifest in over-reliance on
irrelevant image parts or a disregard for the visual modality entirely.
Although inference capabilities of VQA models are often illustrated by a few
qualitative illustrations, most systems are not quantitatively assessed for
their VG properties. We believe, an easily calculated criterion for
meaningfully measuring a system's VG can help remedy this shortcoming, as well
as add another valuable dimension to model evaluations and analysis. To this
end, we propose a new VG metric that captures if a model a) identifies
question-relevant objects in the scene, and b) actually relies on the
information contained in the relevant objects when producing its answer, i.e.,
if its visual grounding is both ""faithful"" and ""plausible"". Our metric, called
""Faithful and Plausible Visual Grounding"" (FPVG), is straightforward to
determine for most VQA model designs.
  We give a detailed description of FPVG and evaluate several reference systems
spanning various VQA architectures. Code to support the metric calculations on
the GQA data set is available on GitHub.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:58:02 GMT""}]","2023-05-25"
"2305.15016","Kostis Gourgoulias","Najah Ghalyan, Kostis Gourgoulias, Yash Satsangi, Sean Moran, Maxime
  Labonne, Joseph Sabelja","An Unsupervised Method for Estimating Class Separability of Datasets
  with Application to LLMs Fine-Tuning",,,,,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  This paper proposes an unsupervised method that leverages topological
characteristics of data manifolds to estimate class separability of the data
without requiring labels. Experiments conducted in this paper on several
datasets demonstrate a clear correlation and consistency between the class
separability estimated by the proposed method with supervised metrics like
Fisher Discriminant Ratio~(FDR) and cross-validation of a classifier, which
both require labels. This can enable implementing learning paradigms aimed at
learning from both labeled and unlabeled data, like semi-supervised and
transductive learning. This would be particularly useful when we have limited
labeled data and a relatively large unlabeled dataset that can be used to
enhance the learning process. The proposed method is implemented for language
model fine-tuning with automated stopping criterion by monitoring class
separability of the embedding-space manifold in an unsupervised setting. The
proposed methodology has been first validated on synthetic data, where the
results show a clear consistency between class separability estimated by the
proposed method and class separability computed by FDR. The method has been
also implemented on both public and internal data. The results show that the
proposed method can effectively aid -- without the need for labels -- a
decision on when to stop or continue the fine-tuning of a language model and
which fine-tuning iteration is expected to achieve a maximum classification
performance through quantification of the class separability of the embedding
manifold.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:58:09 GMT""}]","2023-05-25"
"2305.15017","Marek Kadl\v{c}\'ik","Marek Kadl\v{c}\'ik, Michal \v{S}tef\'anik","Calc-X: Enriching Arithmetical Chain-of-Thoughts Datasets by Interaction
  with Symbolic Systems",,,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  This report overviews our ongoing work in enriching chain-of-thoughts
datasets requiring arithmetical reasoning with the integration of
non-parametric components, such as a calculator. We conduct an analysis of
prominent relevant datasets such as GSM8K, Ape210K, AQuA-RAT, and MathQA and
propose a machine-processable HTML-like format specifically tailored for
working with semi-structured chains. By converting the datasets into this
unified format, we enable the effective integration of large language models
and symbolic systems, empowering them to tackle arithmetical reasoning tasks
more efficiently.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:58:20 GMT""}]","2023-05-25"
"2305.15018","Xiang-Bin Wang","Jian Leng, Fan Yang, Xiang-Bin Wang","Modifying $n$-qubit controlled-$ZX$ gate to be $n$-qubit Toffoli gate","6 pages, 9 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The decomposition for controlled-$ZX$ gate in [Phys. Rev. A, 87, 062318
(2013)] has a shallow circuit depth $8n-20$ with no ancilla. Here we modify
this decomposition to decompose $n$-qubit Toffoli gate with only $2n-3$
additional single-qubit gates. The circuit depth is unchanged and no ancilla is
needed. We explicitly show that the circuit after decomposition can be easily
constructed in present physical systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:58:54 GMT""}]","2023-05-25"
"2305.15019","Anurag Dey","Anurag Dey and Probal Chaudhuri","A comparison of estimators of mean and its functions in finite
  populations",,,"10.5705/ss.202022.0181",,"math.ST stat.ME stat.TH","http://creativecommons.org/publicdomain/zero/1.0/","  Several well known estimators of finite population mean and its functions are
investigated under some standard sampling designs. Such functions of mean
include the variance, the correlation coefficient and the regression
coefficient in the population as special cases. We compare the performance of
these estimators under different sampling designs based on their asymptotic
distributions. Equivalence classes of estimators under different sampling
designs are constructed so that estimators in the same class have equivalent
performance in terms of asymptotic mean squared errors (MSEs). Estimators in
different equivalence classes are then compared under some superpopulations
satisfying linear models. It is shown that the pseudo empirical likelihood
(PEML) estimator of the population mean under simple random sampling without
replacement (SRSWOR) has the lowest asymptotic MSE among all the estimators
under different sampling designs considered in this paper. It is also shown
that for the variance, the correlation coefficient and the regression
coefficient of the population, the plug-in estimators based on the PEML
estimator have the lowest asymptotic MSEs among all the estimators considered
in this paper under SRSWOR. On the other hand, for any high entropy $\pi$PS
(HE$\pi$PS) sampling design, which uses the auxiliary information, the plug-in
estimators of those parameters based on the H\'ajek estimator have the lowest
asymptotic MSEs among all the estimators considered in this paper.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:00:07 GMT""}]","2023-05-25"
"2305.15020","Asahi Ushio","Asahi Ushio and Yi Zhou and Jose Camacho-Collados","An Efficient Multilingual Language Model Compression through Vocabulary
  Trimming",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Multilingual language model (LM) have become a powerful tool in NLP
especially for non-English languages. Nevertheless, model parameters of
multilingual LMs remain large due to the larger embedding matrix of the
vocabulary covering tokens in different languages. On the contrary, monolingual
LMs can be trained in a target language with the language-specific vocabulary
only, but this requires a large budget and availability of reliable corpora to
achieve a high-quality LM from scratch. In this paper, we propose
vocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a
target language by deleting irrelevant tokens from its vocabulary. In theory,
VT can compress any existing multilingual LM to build monolingual LMs in any
language covered by the multilingual LM. In our experiments, we show that VT
can retain the original performance of the multilingual LM, while being smaller
in size (in general around 50% of the original vocabulary size is enough) than
the original multilingual LM. The evaluation is performed over four NLP tasks
(two generative and two classification tasks) among four widely used
multilingual LMs in seven languages. Finally, we show that this methodology can
keep the best of both monolingual and multilingual worlds by keeping a small
size as monolingual models without the need for specifically retraining them,
and even limiting potentially harmful social biases.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:00:33 GMT""}]","2023-05-25"
"2305.15021","Yao Mu Mark","Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun
  Jin, Bin Wang, Jifeng Dai, Yu Qiao, Ping Luo","EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought",,,,,"cs.RO cs.AI cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Embodied AI is a crucial frontier in robotics, capable of planning and
executing action sequences for robots to accomplish long-horizon tasks in
physical environments. In this work, we introduce EmbodiedGPT, an end-to-end
multi-modal foundation model for embodied AI, empowering embodied agents with
multi-modal understanding and execution capabilities. To achieve this, we have
made the following efforts: (i) We craft a large-scale embodied planning
dataset, termed EgoCOT. The dataset consists of carefully selected videos from
the Ego4D dataset, along with corresponding high-quality language instructions.
Specifically, we generate a sequence of sub-goals with the ""Chain of Thoughts""
mode for effective embodied planning. (ii) We introduce an efficient training
approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B
large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We
introduce a paradigm for extracting task-related features from LLM-generated
planning queries to form a closed loop between high-level planning and
low-level control. Extensive experiments show the effectiveness of EmbodiedGPT
on embodied tasks, including embodied planning, embodied control, visual
captioning, and visual question answering. Notably, EmbodiedGPT significantly
enhances the success rate of the embodied control task by extracting more
effective features. It has achieved a remarkable 1.6 times increase in success
rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World
benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:04:30 GMT""}]","2023-05-25"
"2305.15022","Nick Whiteley Prof.","Annie Gray, Alexander Modell, Patrick Rubin-Delanchy, Nick Whiteley","Hierarchical clustering with dot products recovers hidden tree structure",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper we offer a new perspective on the well established
agglomerative clustering algorithm, focusing on recovery of hierarchical
structure. We recommend a simple variant of the standard algorithm, in which
clusters are merged by maximum average dot product and not, for example, by
minimum distance or within-cluster variance. We demonstrate that the tree
output by this algorithm provides a bona fide estimate of generative
hierarchical structure in data, under a generic probabilistic graphical model.
The key technical innovations are to understand how hierarchical information in
this model translates into tree geometry which can be recovered from data, and
to characterise the benefits of simultaneously growing sample size and data
dimension. We demonstrate superior tree recovery performance with real data
over existing approaches such as UPGMA, Ward's method, and HDBSCAN.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:05:12 GMT""}]","2023-05-25"
"2305.15023","Gen Luo","Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, Rongrong
  Ji","Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large
  Language Models",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, growing interest has been aroused in extending the multimodal
capability of large language models (LLMs), e.g., vision-language (VL)
learning, which is regarded as the next milestone of artificial general
intelligence. However, existing solutions are prohibitively expensive, which
not only need to optimize excessive parameters, but also require another
large-scale pre-training before VL instruction tuning. In this paper, we
propose a novel and affordable solution for the effective VL adaption of LLMs,
called Mixture-of-Modality Adaptation (MMA). Instead of using large neural
networks to connect the image encoder and LLM, MMA adopts lightweight modules,
i.e., adapters, to bridge the gap between LLMs and VL tasks, which also enables
the joint optimization of the image and language models. Meanwhile, MMA is also
equipped with a routing algorithm to help LLMs achieve an automatic shift
between single- and multi-modal instructions without compromising their ability
of natural language understanding. To validate MMA, we apply it to a recent LLM
called LLaMA and term this formed large vision-language instructed model as
LaVIN. To validate MMA and LaVIN, we conduct extensive experiments under two
setups, namely multimodal science question answering and multimodal dialogue.
The experimental results not only demonstrate the competitive performance and
the superior training efficiency of LaVIN than existing multimodal LLMs, but
also confirm its great potential as a general-purpose chatbot. More
importantly, the actual expenditure of LaVIN is extremely cheap, e.g., only 1.4
training hours with 3.8M trainable parameters, greatly confirming the
effectiveness of MMA. Our project is released at
https://luogen1996.github.io/lavin.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:06:15 GMT""}]","2023-05-25"
"2305.15024","Weiqiang Jin","Biao Zhao, Weiqiang Jin, Javier Del Ser, Guang Yang","ChatAgri: Exploring Potentials of ChatGPT on Cross-linguistic
  Agricultural Text Classification","24 pages,10+figures,46references.Both the first two authors, Biao
  Zhao and Weiqiang Jin, made equal contributions to this work. Corresponding
  author: Guang Yang",,,,"cs.CL cs.AI","http://creativecommons.org/publicdomain/zero/1.0/","  In the era of sustainable smart agriculture, a massive amount of agricultural
news text is being posted on the Internet, in which massive agricultural
knowledge has been accumulated. In this context, it is urgent to explore
effective text classification techniques for users to access the required
agricultural knowledge with high efficiency. Mainstream deep learning
approaches employing fine-tuning strategies on pre-trained language models
(PLMs), have demonstrated remarkable performance gains over the past few years.
Nonetheless, these methods still face many drawbacks that are complex to solve,
including: 1. Limited agricultural training data due to the expensive-cost and
labour-intensive annotation; 2. Poor domain transferability, especially of
cross-linguistic ability; 3. Complex and expensive large models
deployment.Inspired by the extraordinary success brought by the recent ChatGPT
(e.g. GPT-3.5, GPT-4), in this work, we systematically investigate and explore
the capability and utilization of ChatGPT applying to the agricultural
informatization field. ....(shown in article).... Code has been released on
Github
https://github.com/albert-jin/agricultural_textual_classification_ChatGPT.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:06:23 GMT""}]","2023-05-25"
"2305.15025","Tianyu Yang","Tianyu Yang and Thy Thy Tran and Iryna Gurevych","Dior-CVAE: Diffusion Priors in Variational Dialog Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Conditional variational autoencoders (CVAEs) have been used recently for
diverse response generation, by introducing latent variables to represent the
relationship between a dialog context and its potential responses. However, the
diversity of the generated responses brought by a CVAE model is limited due to
the oversimplified assumption of the isotropic Gaussian prior. We propose,
Dior-CVAE, a hierarchical CVAE model with an informative prior produced by a
diffusion model. Dior-CVAE derives a series of layer-wise latent variables
using attention mechanism and infusing them into decoder layers accordingly. We
propose memory dropout in the latent infusion to alleviate posterior collapse.
The prior distribution of the latent variables is parameterized by a diffusion
model to introduce a multimodal distribution. Overall, experiments on two
popular open-domain dialog datasets indicate the advantages of our approach
over previous Transformer-based variational dialog models in dialog response
generation. We publicly release the code for reproducing Dior-CVAE and all
baselines at
https://github.com/SkyFishMoon/Latent-Diffusion-Response-Generation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:06:52 GMT""}]","2023-05-25"
"2305.15026","Rodrigo Valerio","Rodrigo Valerio, Joao Bordalo, Michal Yarom, Yonatan Bitton, Idan
  Szpektor, Joao Magalhaes","Transferring Visual Attributes from Natural Language to Verified Image
  Generation",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text to image generation methods (T2I) are widely popular in generating art
and other creative artifacts. While visual hallucinations can be a positive
factor in scenarios where creativity is appreciated, such artifacts are poorly
suited for cases where the generated image needs to be grounded in complex
natural language without explicit visual elements. In this paper, we propose to
strengthen the consistency property of T2I methods in the presence of natural
complex language, which often breaks the limits of T2I methods by including
non-visual information, and textual elements that require knowledge for
accurate generation. To address these phenomena, we propose a Natural Language
to Verified Image generation approach (NL2VI) that converts a natural prompt
into a visual prompt, which is more suitable for image generation. A T2I model
then generates an image for the visual prompt, which is then verified with VQA
algorithms. Experimentally, aligning natural prompts with image generation can
improve the consistency of the generated images by up to 11% over the state of
the art. Moreover, improvements can generalize to challenging domains like
cooking and DIY tasks, where the correctness of the generated image is crucial
to illustrate actions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:08:26 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 09:34:31 GMT""}]","2023-05-30"
"2305.15027","Sahra Ghalebikesabi","Veit David Wild, Sahra Ghalebikesabi, Dino Sejdinovic, Jeremias
  Knoblauch","A Rigorous Link between Deep Ensembles and (Variational) Bayesian
  Methods",,,,,"stat.ML cs.AI cs.LG math.ST stat.ME stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We establish the first mathematically rigorous link between Bayesian,
variational Bayesian, and ensemble methods. A key step towards this it to
reformulate the non-convex optimisation problem typically encountered in deep
learning as a convex optimisation in the space of probability measures. On a
technical level, our contribution amounts to studying generalised variational
inference through the lense of Wasserstein gradient flows. The result is a
unified theory of various seemingly disconnected approaches that are commonly
used for uncertainty quantification in deep learning -- including deep
ensembles and (variational) Bayesian methods. This offers a fresh perspective
on the reasons behind the success of deep ensembles over procedures based on
parameterised variational inference, and allows the derivation of new
ensembling schemes with convergence guarantees. We showcase this by proposing a
family of interacting deep ensembles with direct parallels to the interactions
of particle systems in thermodynamics, and use our theory to prove the
convergence of these algorithms to a well-defined global minimiser on the space
of probability measures.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:13:59 GMT""}]","2023-05-25"
"2305.15028","Qingxiu Dong","Heming Xia, Qingxiu Dong, Lei Li, Jingjing Xu, Ziwei Qin, Zhifang Sui","ImageNetVC: Zero-Shot Visual Commonsense Evaluation on 1000 ImageNet
  Categories",,,,,"cs.CL cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Pretrained Language Models (PLMs) have been serving as
general-purpose interfaces, posing a significant demand for comprehensive
visual knowledge. However, it remains unclear how well current PLMs and their
visually augmented counterparts (VaLMs) can master visual commonsense
knowledge. To investigate this, we propose ImageNetVC, a fine-grained,
human-annotated dataset specifically designed for zero-shot visual commonsense
evaluation across 1,000 ImageNet categories. Utilizing ImageNetVC, we delve
into the fundamental visual commonsense knowledge of both unimodal PLMs and
VaLMs, uncovering the scaling law and the influence of the backbone model on
VaLMs. Furthermore, we investigate the factors affecting the visual commonsense
knowledge of large-scale models, providing insights into the development of
language models enriched with visual commonsense knowledge. Our code and
dataset are available at https://github.com/hemingkx/ImageNetVC.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:14:31 GMT""}]","2023-05-25"
"2305.15029","Eros Mariani","Jamie Le Signe, Thomas McDermott and Eros Mariani","Tunable mechanically-induced hysteresis in suspended Josephson junctions",,,,,"cond-mat.supr-con cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The coupling of superconducting systems to mechanical resonators is an
emerging field, with wide reaching implications including high precision
sensing and metrology. Experimental signatures of this coupling have so far
been small, seldom and often reliant on high frequency AC electronics. To
overcome this limitation, in this work we consider a mechanical resonator
suspended between two superconducting contacts to form a suspended Josephson
junction in which the electronic normal- and super-currents can be coupled to
mechanical motion via the Lorentz force due to an external magnetic field. We
show both analytically and numerically that this electro-mechanical coupling
produces unprecedented mechanically-induced hysteresis loops in the junction's
DC I-V characteristic. Firstly, we unveil how this new hysteresis may be
exploited to access a huge mechanically-induced Shapiro-like voltage plateau,
extending over a current range comparable with the junction's critical current.
We then investigate a sudden mechanically-induced retrapping that occurs at
strong coupling. Our analytical treatment provides a clear explanation for the
effects above and allows us to derive simple relationships between the features
in the DC I-V characteristic and the resonance frequency and quality factor of
the mechanical resonator. We stress that our setup requires only DC current
bias and voltage measurements, allowing the activation and detection of
high-frequency mechanical oscillations in state of the art devices and without
the need of any AC equipment.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:14:32 GMT""}]","2023-05-25"
"2305.15030","Shilv Cai","Shilv Cai, Xu Zou, Liqun Chen, Luxin Yan, Sheng Zhong","Jointly Optimizing Image Compression with Low-light Image Enhancement","arXiv admin note: text overlap with arXiv:2303.06705 by other authors",,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning-based image compression methods have made great progress. Most of
them are designed for generic natural images. In fact, low-light images
frequently occur due to unavoidable environmental influences or technical
limitations, such as insufficient lighting or limited exposure time. %When
general-purpose image compression algorithms compress low-light images, useful
detail information is lost, resulting in a dramatic decrease in image
enhancement. Once low-light images are compressed by existing general image
compression approaches, useful information(e.g., texture details) would be lost
resulting in a dramatic performance decrease in low-light image enhancement. To
simultaneously achieve a higher compression rate and better enhancement
performance for low-light images, we propose a novel image compression
framework with joint optimization of low-light image enhancement. We design an
end-to-end trainable two-branch architecture with lower computational cost,
which includes the main enhancement branch and the signal-to-noise ratio~(SNR)
aware branch. Experimental results show that our proposed joint optimization
framework achieves a significant improvement over existing ``Compress before
Enhance"" or ``Enhance before Compress"" sequential solutions for low-light
images. Source codes are included in the supplementary material.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:14:40 GMT""}]","2023-05-25"
"2305.15031","Fanny Kassel","Jonas Beyrer, Fanny Kassel","$\mathbb{H}^{p,q}$-convex cocompactness and higher higher Teichm\""uller
  spaces","59 pages",,,,"math.GT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For any integers $p\geq 2$ and $q\geq 1$, let $\mathbb{H}^{p,q}$ be the
pseudo-Riemannian hyperbolic space of signature $(p,q)$. We prove that if
$\Gamma$ is the fundamental group of a closed aspherical $p$-manifold, then the
set of representations of $\Gamma$ to $\mathrm{PO}(p,q+1)$ which are convex
cocompact in $\mathbb{H}^{p,q}$ is a union of connected components of
$\mathrm{Hom}(\Gamma,\mathrm{PO}(p,q+1))$. This gives new examples of
higher-dimensional higher-rank Teichm\""uller spaces.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:15:37 GMT""}]","2023-05-25"
"2305.15032","Xinpeng Wang","Xinpeng Wang, Leonie Weissweiler, Hinrich Sch\""utze, Barbara Plank","How to Distill your BERT: An Empirical Study on the Impact of Weight
  Initialisation and Distillation Objectives","ACL 2023",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Recently, various intermediate layer distillation (ILD) objectives have been
shown to improve compression of BERT models via Knowledge Distillation (KD).
However, a comprehensive evaluation of the objectives in both task-specific and
task-agnostic settings is lacking. To the best of our knowledge, this is the
first work comprehensively evaluating distillation objectives in both settings.
We show that attention transfer gives the best performance overall. We also
study the impact of layer choice when initializing the student from the teacher
layers, finding a significant impact on the performance in task-specific
distillation. For vanilla KD and hidden states transfer, initialisation with
lower layers of the teacher gives a considerable improvement over higher
layers, especially on the task of QNLI (up to an absolute percentage change of
17.8 in accuracy). Attention transfer behaves consistently under different
initialisation settings. We release our code as an efficient transformer-based
model distillation framework for further studies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:16:09 GMT""}]","2023-05-25"
"2305.15033","Zekun Wang","Zekun Wang, Jingchang Chen, Wangchunshu Zhou, Ming Liu, Bing Qin","SmartTrim: Adaptive Tokens and Parameters Pruning for Efficient
  Vision-Language Models","Work in progress",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite achieving remarkable performance on various vision-language tasks,
Transformer-based pretrained vision-language models (VLMs) still suffer from
efficiency issues arising from long inputs and numerous parameters, limiting
their real-world applications. However, the huge computation is redundant for
most samples and the degree of redundancy and the respective components vary
significantly depending on tasks and input instances. In this work, we propose
an adaptive acceleration method SmartTrim for VLMs, which adjusts the inference
overhead based on the complexity of instances. Specifically, SmartTrim
incorporates lightweight trimming modules into the backbone to perform
task-specific pruning on redundant inputs and parameters, without the need for
additional pre-training or data augmentation. Since visual and textual
representations complement each other in VLMs, we propose to leverage
cross-modal interaction information to provide more critical semantic guidance
for identifying redundant parts. Meanwhile, we introduce a self-distillation
strategy that encourages the trimmed model to be consistent with the
full-capacity model, which yields further performance gains. Experimental
results demonstrate that SmartTrim significantly reduces the computation
overhead (2-3 times) of various VLMs with comparable performance (only a 1-2%
degradation) on various vision-language tasks. Compared to previous
acceleration methods, SmartTrim attains a better efficiency-performance
trade-off, demonstrating great potential for application in
resource-constrained scenarios.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:18:00 GMT""}]","2023-05-25"
"2305.15034","Adam Kubica","Adam Kubica, Katarzyna Ryszewska, Rico Zacher","Holder continuity of weak solutions to evolution equations with
  distributed order fractional time derivative",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the regularity of weak solutions to evolution equations with
distributed order fractional time derivative. We prove a weak Harnack
inequality for nonnegative weak supersolutions and H\""older continuity of weak
solutions to this problem. Our results substantially generalise analogous known
results for the problem with single order fractional time derivative.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:21:11 GMT""}]","2023-05-25"
"2305.15035","Wei-Lin Chen","Wei-Lin Chen, Cheng-Kuang Wu, Hsin-Hsi Chen","Self-ICL: Zero-Shot In-Context Learning with Self-Generated
  Demonstrations","Work in progress",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models (LMs) have exhibited superior in-context learning (ICL)
ability to adopt to target tasks by prompting with a few input-output
demonstrations. Towards better ICL, different methods are proposed to select
representative demonstrations from existing training corpora. However, such a
setting is not aligned with real-world practices, as end-users usually query
LMs without accesses to demonstration pools. Inspired by evidence suggesting
LMs' zero-shot capabilities are underrated, and the role of demonstrations are
primarily for exposing models' intrinsic functionalities, we introduce
Self-ICL, a simple framework for zero-shot ICL. Given a test input, Self-ICL
first prompts the model to generate pseudo-inputs. Next, the model predicts
pseudo-labels for the pseudo-inputs via zero-shot prompting. Finally, we
construct pseudo-demonstrations from pseudo-input-label pairs, and perform ICL
for the test input. Evaluation on BIG-Bench Hard shows Self-ICL steadily
surpasses zero-shot and zero-shot chain-of-thought baselines on head-to-head
and all-task average performance. Our findings suggest the possibility to
bootstrap LMs' intrinsic capabilities towards better zero-shot performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:22:34 GMT""}]","2023-05-25"
"2305.15036","Junchen Fu","Junchen Fu, Fajie Yuan, Yu Song, Zheng Yuan, Mingyue Cheng, Shenghui
  Cheng, Jiaqi Zhang, Jie Wang, Yunzhu Pan","Exploring Adapter-based Transfer Learning for Recommender Systems:
  Empirical Studies and Practical Insights",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adapters, a plug-in neural network module with some tunable parameters, have
emerged as a parameter-efficient transfer learning technique for adapting
pre-trained models to downstream tasks, especially for natural language
processing (NLP) and computer vision (CV) fields. Meanwhile, learning
recommendation models directly from raw item modality features -- e.g., texts
of NLP and images of CV -- can enable effective and transferable recommender
systems (called TransRec). In view of this, a natural question arises: can
adapter-based learning techniques achieve parameter-efficient TransRec with
good performance?
  To this end, we perform empirical studies to address several key
sub-questions. First, we ask whether the adapter-based TransRec performs
comparably to TransRec based on standard full-parameter fine-tuning? does it
hold for recommendation with different item modalities, e.g., textual RS and
visual RS. If yes, we benchmark these existing adapters, which have been shown
to be effective in NLP and CV tasks, in the item recommendation settings.
Third, we carefully study several key factors for the adapter-based TransRec in
terms of where and how to insert these adapters? Finally, we look at the
effects of adapter-based TransRec by either scaling up its source training data
or scaling down its target training data. Our paper provides key insights and
practical guidance on unified & transferable recommendation -- a less studied
recommendation scenario. We promise to release all code & datasets for future
research.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:23:31 GMT""}]","2023-05-25"
"2305.15037","Ulf-G. Mei{\ss}ner","Zhengxue Ren, Serdar Elhatisari, Timo A. L\""ahde, Dean Lee, Ulf-G.
  Mei{\ss}ner","Ab initio study of nuclear clustering in hot dilute nuclear matter","6+8 pages, 4+8 figures",,,,"nucl-th hep-ph nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a systematic ab initio study of clustering in hot dilute nuclear
matter using nuclear lattice effective field theory with an SU(4)-symmetric
interaction. We introduce a method called light-cluster distillation to
determine the abundances of dimers, trimers, and alpha clusters as a function
of density and temperature. Our lattice results are compared with an ideal gas
model composed of free nucleons and clusters. Excellent agreement is found at
very low density, while deviations from ideal gas abundances appear at
increasing density due to cluster-nucleon and cluster-cluster interactions. In
addition to determining the composition of hot dilute nuclear matter as a
function of density and temperature, the lattice calculations also serve as
benchmarks for virial expansion calculations, statistical models, and transport
models of fragmentation and clustering in nucleus-nucleus collisions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:26:42 GMT""}]","2023-05-25"
"2305.15038","Liying Cheng","Liying Cheng, Xingxuan Li, Lidong Bing","Is GPT-4 a Good Data Analyst?","11 pages, 2 figures",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As large language models (LLMs) have demonstrated their powerful capabilities
in plenty of domains and tasks, including context understanding, code
generation, language generation, data storytelling, etc., many data analysts
may raise concerns if their jobs will be replaced by AI. This controversial
topic has drawn a lot of attention in public. However, we are still at a stage
of divergent opinions without any definitive conclusion. Motivated by this, we
raise the research question of ""is GPT-4 a good data analyst?"" in this work and
aim to answer it by conducting head-to-head comparative studies. In detail, we
regard GPT-4 as a data analyst to perform end-to-end data analysis with
databases from a wide range of domains. We propose a framework to tackle the
problems by carefully designing the prompts for GPT-4 to conduct experiments.
We also design several task-specific evaluation metrics to systematically
compare the performance between several professional human data analysts and
GPT-4. Experimental results show that GPT-4 can achieve comparable performance
to humans. We also provide in-depth discussions about our results to shed light
on further studies before we reach the conclusion that GPT-4 can replace data
analysts.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:26:59 GMT""}]","2023-05-25"
"2305.15039","Irina Molodtsova","E.B. Balbutsev, I.V. Molodtsova","Electric $1^+$ state below nuclear scissors","20 pages, 6 figures, 2 tables",,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The solution of time dependent Hartree-Fock-Bogoliubov equations by the
Wigner function moments method predicts four low-lying $1^+$ states. Three of
them are known as various scissors modes. Fourth state is disposed below all
scissors modes and has the electrical nature. It is found that it represents
one of three branches of $2^+$ state which can exist in spherical nuclei and
which is split %due to a deformation. in deformed nuclei. It is discovered,
that the antiferromagnetic properties of nuclei lead to the splitting of $2^+$
states already at the zero deformation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:27:18 GMT""}]","2023-05-25"
"2305.15040","Yotam Perlitz","Yotam Perlitz and Ariel Gera, Michal Shmueli-Scheuer, Dafna Sheinwald,
  Noam Slonim, Liat Ein-Dor","Active Learning for Natural Language Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The field of text generation suffers from a severe shortage of labeled data
due to the extremely expensive and time consuming process involved in manual
annotation. A natural approach for coping with this problem is active learning
(AL), a well-known machine learning technique for improving annotation
efficiency by selectively choosing the most informative examples to label.
However, while AL has been well-researched in the context of text
classification, its application to text generation remained largely unexplored.
In this paper, we present a first systematic study of active learning for text
generation, considering a diverse set of tasks and multiple leading AL
strategies. Our results indicate that existing AL strategies, despite their
success in classification, are largely ineffective for the text generation
scenario, and fail to consistently surpass the baseline of random example
selection. We highlight some notable differences between the classification and
generation scenarios, and analyze the selection behaviors of existing AL
strategies. Our findings motivate exploring novel approaches for applying AL to
NLG tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:27:53 GMT""}]","2023-05-25"
"2305.15041","Veniamin Veselovsky","Veniamin Veselovsky, Manoel Horta Ribeiro, Akhil Arora, Martin
  Josifoski, Ashton Anderson, Robert West","Generating Faithful Synthetic Data with Large Language Models: A Case
  Study in Computational Social Science","8 pages",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large Language Models (LLMs) have democratized synthetic data generation,
which in turn has the potential to simplify and broaden a wide gamut of NLP
tasks. Here, we tackle a pervasive problem in synthetic data generation: its
generative distribution often differs from the distribution of real-world data
researchers care about (in other words, it is unfaithful). In a case study on
sarcasm detection, we study three strategies to increase the faithfulness of
synthetic data: grounding, filtering, and taxonomy-based generation. We
evaluate these strategies using the performance of classifiers trained with
generated synthetic data on real-world data. While all three strategies improve
the performance of classifiers, we find that grounding works best for the task
at hand. As synthetic data generation plays an ever-increasing role in NLP
research, we expect this work to be a stepping stone in improving its utility.
We conclude this paper with some recommendations on how to generate
high(er)-fidelity synthetic data for specific tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:27:59 GMT""}]","2023-05-25"
"2305.15042","Zaccharie Ramzi","Zaccharie Ramzi, Pierre Ablin, Gabriel Peyr\'e, Thomas Moreau","Test like you Train in Implicit Deep Learning",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Implicit deep learning has recently gained popularity with applications
ranging from meta-learning to Deep Equilibrium Networks (DEQs). In its general
formulation, it relies on expressing some components of deep learning pipelines
implicitly, typically via a root equation called the inner problem. In
practice, the solution of the inner problem is approximated during training
with an iterative procedure, usually with a fixed number of inner iterations.
During inference, the inner problem needs to be solved with new data. A popular
belief is that increasing the number of inner iterations compared to the one
used during training yields better performance. In this paper, we question such
an assumption and provide a detailed theoretical analysis in a simple setting.
We demonstrate that overparametrization plays a key role: increasing the number
of iterations at test time cannot improve performance for overparametrized
networks. We validate our theory on an array of implicit deep-learning
problems. DEQs, which are typically overparametrized, do not benefit from
increasing the number of iterations at inference while meta-learning, which is
typically not overparametrized, benefits from it.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:30:33 GMT""}]","2023-05-25"
"2305.15043","Jacob Holford","Jacob Holford, Myoungkyu Lee, Yongyun Hwang","A data-driven quasi-linear approximation for turbulent channel flow",,,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A data-driven implementation of a quasi-linear approximation is presented,
extending a minimal quasi-linear approximation (MQLA) (Hwang & Ekchardt, J.
Fluid Mech., 2020, 894:A23) to incorporate non-zero streamwise Fourier modes. A
data-based approach is proposed, matching the two-dimensional wavenumber
spectra for a fixed spanwise wavenumber between a direct numerical simulation
(DNS) (Lee & Moser, J. Fluid Mech., 2015, 774:395-415) and that generated by
the eddy viscosity-enhanced linearised Navier-Stokes equations at $Re{\tau}
\simeq 5200$. Leveraging the self-similar nature of the energy-containing part
in the DNS velocity spectra, a universal self-similar streamwise wavenumber
weight is determined for the linearised fluctuation equations at $Re_{\tau}
\simeq 5200$. This data-driven quasi-linear approximation (DQLA) offers
qualitatively similar findings to the MQLA, with quantitative improvements in
the turbulence intensities and additional insights from the streamwise
wavenumber spectra. By comparing the one-dimensional streamwise wavenumber
spectra and two-dimensional spectra to DNS results, the limitations of the
presented framework are discussed, mainly pertaining to the lack of the streak
instability (or transient growth) mechanism and energy cascade from the
linearised model. The DQLA is subsequently employed over a range of Reynolds
numbers up to $Re_{\tau} = 10^5$. Overall, the turbulence statistics and
spectra produced by the DQLA scale consistently with the available DNS and
experimental data, with the Townsend-Perry constants displaying a mild Reynolds
dependence (Hwang, Hutchins & Marusic, J. Fluid Mech., 2022, 933:A8). The
scaling behaviour of the turbulence intensity profiles deviates away from the
classic $\ln(Re_{\tau})$ scaling, following the inverse centreline velocity
scaling for the higher Reynolds numbers.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:31:56 GMT""}]","2023-05-25"
"2305.15044","Xiao Pu","Xiao Pu, Mingqi Gao, Xiaojun Wan","Is Summary Useful or Not? An Extrinsic Human Evaluation of Text
  Summaries on Downstream Tasks",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research on automated text summarization relies heavily on human and
automatic evaluation. While recent work on human evaluation mainly adopted
intrinsic evaluation methods, judging the generic quality of text summaries,
e.g. informativeness and coherence, our work focuses on evaluating the
usefulness of text summaries with extrinsic methods. We carefully design three
different downstream tasks for extrinsic human evaluation of summaries, i.e.,
question answering, text classification and text similarity assessment. We
carry out experiments using system rankings and user behavior data to evaluate
the performance of different summarization models. We find summaries are
particularly useful in tasks that rely on an overall judgment of the text,
while being less effective for question answering tasks. The results show that
summaries generated by fine-tuned models lead to higher consistency in
usefulness across all three tasks, as rankings of fine-tuned summarization
systems are close across downstream tasks according to the proposed extrinsic
metrics. Summaries generated by models in the zero-shot setting, however, are
found to be biased towards the text classification and similarity assessment
tasks, due to its general and less detailed summary style. We further evaluate
the correlation of 14 intrinsic automatic metrics with human criteria and show
that intrinsic automatic metrics perform well in evaluating the usefulness of
summaries in the question-answering task, but are less effective in the other
two tasks. This highlights the limitations of relying solely on intrinsic
automatic metrics in evaluating the performance and usefulness of summaries.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:34:39 GMT""}]","2023-05-25"
"2305.15045","Xiyan Fu","Xiyan Fu, Anette Frank","SETI: Systematicity Evaluation of Textual Inference","Accepted to Findings of ACL2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose SETI (Systematicity Evaluation of Textual Inference), a novel and
comprehensive benchmark designed for evaluating pre-trained language models
(PLMs) for their systematicity capabilities in the domain of textual inference.
Specifically, SETI offers three different NLI tasks and corresponding datasets
to evaluate various types of systematicity in reasoning processes. In order to
solve these tasks, models are required to perform compositional inference based
on known primitive constituents. We conduct experiments of SETI on six widely
used PLMs. Results show that various PLMs are able to solve unseen
compositional inferences when having encountered the knowledge of how to
combine primitives, with good performance. However, they are considerably
limited when this knowledge is unknown to the model (40-100% points decrease).
Furthermore, we find that PLMs can improve drastically once exposed to crucial
compositional knowledge in minimalistic shots. These findings position SETI as
the first benchmark for measuring the future progress of PLMs in achieving
systematicity generalization in the textual inference.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:35:31 GMT""}]","2023-05-25"
"2305.15046","Yanbo Hu","Geng Chen, Yanbo Hu, Qingtian Zhang","Initial-boundary value problems for Poiseuille flow of nematic liquid
  crystal via full Ericksen-Leslie model","36 pages, 3 figures",,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the initial-boundary value problem for the Poiseuille
flow of hyperbolic-parabolic Ericksen-Leslie model of nematic liquid crystals
in one space dimension. Due to the quasilinearity, the solution of this model
in general forms cusp singularity. We prove the global existence of H\""older
continuous solution, which may include cusp singularity, for initial-boundary
value problems with different types of boundary conditions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:35:56 GMT""}]","2023-05-25"
"2305.15047","Nicholas Tomlin","Vivek Verma, Eve Fleisig, Nicholas Tomlin, Dan Klein","Ghostbuster: Detecting Text Ghostwritten by Large Language Models",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  We introduce Ghostbuster, a state-of-the-art system for detecting
AI-generated text. Our method works by passing documents through a series of
weaker language models and running a structured search over possible
combinations of their features, then training a classifier on the selected
features to determine if the target document was AI-generated. Crucially,
Ghostbuster does not require access to token probabilities from the target
model, making it useful for detecting text generated by black-box models or
unknown model versions. In conjunction with our model, we release three new
datasets of human and AI-generated text as detection benchmarks that cover
multiple domains (student essays, creative fiction, and news) and task setups:
document-level detection, author identification, and a challenge task of
paragraph-level detection. Ghostbuster averages 99.1 F1 across all three
datasets on document-level detection, outperforming previous approaches such as
GPTZero and DetectGPT by up to 32.7 F1.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:37:10 GMT""}]","2023-05-25"
"2305.15048","Mete Sertkan","Mete Sertkan, Sophia Althammer and Sebastian Hofst\""atter","Ranger: A Toolkit for Effect-Size Based Multi-Task Evaluation","Accepted at ACL 2023 (System Demonstrations)",,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce Ranger - a toolkit to facilitate the easy use of
effect-size-based meta-analysis for multi-task evaluation in NLP and IR. We
observed that our communities often face the challenge of aggregating results
over incomparable metrics and scenarios, which makes conclusions and take-away
messages less reliable. With Ranger, we aim to address this issue by providing
a task-agnostic toolkit that combines the effect of a treatment on multiple
tasks into one statistical evaluation, allowing for comparison of metrics and
computation of an overall summary effect. Our toolkit produces
publication-ready forest plots that enable clear communication of evaluation
results over multiple tasks. Our goal with the ready-to-use Ranger toolkit is
to promote robust, effect-size-based evaluation and improve evaluation
standards in the community. We provide two case studies for common IR and NLP
settings to highlight Ranger's benefits.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:38:39 GMT""}]","2023-05-25"
"2305.15049","Bobby Eka Gunara","Mulyanto, Fiki Taufik Akbar, and Bobby Eka Gunara","Decay Estimate of Maxwell-Higgs System on Schwarzschild Black Holes","36 pages, no figure, comments are welcome",,,,"math.AP gr-qc hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we prove the decay estimate of Maxwell-Higgs system on four
dimensional Schwarzschild spacetimes. We show that if the field equations
support a Morawetz type estimate supported around the trapped surface, the
uniform decay properties in the entire exterior of the Schwarzschild black
holes can be obtained by using Sobolev inequalities and energy estimates. Our
results also consider various forms of physical potential such as the mass
terms, $\phi^4$-theory, sine Gordon potential, and Toda potential.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:39:02 GMT""}]","2023-05-25"
"2305.15050","Sunay Ibryamov","Sunay Ibryamov, Gabriela Zidarova, Evgeni Semkov, Stoyanka Peneva","Study of the long-term $BVR_{c}I_{c}$ photometric variability of eight
  PMS stars in the young open cluster Trumpler 37","13 pages, 11 figures, 4 tables, accepted for publication in Research
  in Astronomy and Astrophysics (RAA)",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper reports results from our long-term $BV(RI)_{c}$ photometric CCD
observations of eight pre-main-sequence stars collected from June 2008 to
October 2022. These stars are located in the young open cluster Trumpler 37, in
the field of GM Cephei. The observational data indicate that all stars from our
study exhibit variability in all-optical passbands, typical for young stars. In
this paper, we describe and discuss the photometric behavior of the stars and
the possible reasons for their variability. For two of the objects, we
identified periodicity in their light variation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:39:36 GMT""}]","2023-05-25"
"2305.15051","Erica Cai","Erica Cai, Brendan O'Connor","A Monte Carlo Language Model Pipeline for Zero-Shot Sociopolitical Event
  Extraction",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We consider dyadic zero-shot event extraction (EE) to identify actions
between pairs of actors. The \emph{zero-shot} setting allows social scientists
or other non-computational researchers to extract any customized,
user-specified set of events without training, resulting in a \emph{dyadic}
event database, allowing insight into sociopolitical relational dynamics among
actors and the higher level organizations or countries they represent.
Unfortunately, we find that current zero-shot EE methods perform poorly for the
task, with issues including word sense ambiguity, modality mismatch, and
efficiency. Straightforward application of large language model prompting
typically performs even worse. We address these challenges with a new
fine-grained, multi-stage generative question-answer method, using a Monte
Carlo approach to exploit and overcome the randomness of generative outputs. It
performs 90\% fewer queries than a previous approach, with strong performance
on the widely-used Automatic Content Extraction dataset. Finally, we extend our
method to extract affiliations of actor arguments and demonstrate our method
and findings on a dyadic international relations case study.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:41:33 GMT""}]","2023-05-25"
"2305.15052","Davi Rohe Rodrigues","Rayan Moukhader, Davi Rodrigues, Eleonora Raimondo, Vito Puliafito,
  Bruno Azzerboni, Mario Carpentieri, Abbass Hamadeh, Giovanni Finocchio,
  Riccardo Tomasello","Manipulation of magnetic solitons under the influence of DMI gradients","19 pages, 5 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Magnetic solitons are promising for applications due to their intrinsic
properties such as small size, topological stability, ultralow power
manipulation and potentially ultrafast operations. To date, research has
focused on the manipulation of skyrmions, domain walls, and vortices by applied
currents. The discovery of new methods to control magnetic parameters, such as
the interfacial Dzyaloshinskii-Moriya interaction (DMI) by strain, geometry
design, temperature gradients, and applied voltages promises new avenues for
energetically efficient manipulation of magnetic structures. The latter has
shown significant progress in 2d material-based technology. In this work, we
present a comprehensive study using numerical and analytical methods of the
stability and motion of different magnetic textures under the influence of DMI
gradients. Our results show that under the influence of linear DMI gradients,
N\'eel and Bloch-type skyrmions and radial vortex exhibit motion with finite
skyrmion Hall angle, while the circular vortex undergoes expulsion dynamics.
This work provides a deeper and crucial understanding of the stability and
gradient-driven dynamics of magnetic solitons, and paves the way for the design
of alternative low-power sources of magnetization manipulation in the emerging
field of 2d materials.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:42:18 GMT""}]","2023-05-25"
"2305.15053","Kyle Lo","Kevin Lin and Kyle Lo and Joseph E. Gonzalez and Dan Klein","Decomposing Complex Queries for Tip-of-the-tongue Retrieval",,,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  When re-finding items, users who forget or are uncertain about identifying
details often rely on creative strategies for expressing their information
needs -- complex queries that describe content elements (e.g., book characters
or events), information beyond the document text (e.g., descriptions of book
covers), or personal context (e.g., when they read a book). This retrieval
setting, called tip of the tongue (TOT), is especially challenging for models
heavily reliant on lexical and semantic overlap between query and document
text. In this work, we introduce a simple yet effective framework for handling
such complex queries by decomposing the query into individual clues, routing
those as sub-queries to specialized retrievers, and ensembling the results.
This approach allows us to take advantage of off-the-shelf retrievers (e.g.,
CLIP for retrieving images of book covers) or incorporate retriever-specific
logic (e.g., date constraints). We show that our framework incorportating query
decompositions into retrievers can improve gold book recall up to 7% relative
again for Recall@5 on a new collection of 14,441 real-world query-book pairs
from an online community for resolving TOT inquiries.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:43:40 GMT""}]","2023-05-25"
"2305.15054","Alessandro Stolfo","Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan","Understanding Arithmetic Reasoning in Language Models using Causal
  Mediation Analysis",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Mathematical reasoning in large language models (LLMs) has garnered attention
in recent research, but there is limited understanding of how these models
process and store information related to arithmetic tasks. In this paper, we
present a mechanistic interpretation of LLMs for arithmetic-based questions
using a causal mediation analysis framework. By intervening on the activations
of specific model components and measuring the resulting changes in predicted
probabilities, we identify the subset of parameters responsible for specific
predictions. We analyze two pre-trained language models with different sizes
(2.8B and 6B parameters). Experimental results reveal that a small set of
mid-late layers significantly affect predictions for arithmetic-based
questions, with distinct activation patterns for correct and wrong predictions.
We also investigate the role of the attention mechanism and compare the model's
activation patterns for arithmetic queries with the prediction of factual
knowledge. Our findings provide insights into the mechanistic interpretation of
LLMs for arithmetic tasks and highlight the specific components involved in
arithmetic reasoning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:43:47 GMT""}]","2023-05-25"
"2305.15055","Mayank Singh","Mayank Kumar Singh, Naoya Takahashi, Onoe Naoyuki","Iteratively Improving Speech Recognition and Voice Conversion",,,,,"cs.SD cs.AI eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many existing works on voice conversion (VC) tasks use automatic speech
recognition (ASR) models for ensuring linguistic consistency between source and
converted samples. However, for the low-data resource domains, training a
high-quality ASR remains to be a challenging task. In this work, we propose a
novel iterative way of improving both the ASR and VC models. We first train an
ASR model which is used to ensure content preservation while training a VC
model. In the next iteration, the VC model is used as a data augmentation
method to further fine-tune the ASR model and generalize it to diverse
speakers. By iteratively leveraging the improved ASR model to train VC model
and vice-versa, we experimentally show improvement in both the models. Our
proposed framework outperforms the ASR and one-shot VC baseline models on
English singing and Hindi speech domains in subjective and objective
evaluations in low-data resource settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:45:42 GMT""}]","2023-05-25"
"2305.15056","Jiajie Zhang","Jiajie Zhang, Shulin Cao, Tingjia Zhang, Xin Lv, Jiaxin Shi, Qi Tian,
  Juanzi Li, Lei Hou","Reasoning over Hierarchical Question Decomposition Tree for Explainable
  Question Answering","has been accepted by ACL2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Explainable question answering (XQA) aims to answer a given question and
provide an explanation why the answer is selected. Existing XQA methods focus
on reasoning on a single knowledge source, e.g., structured knowledge bases,
unstructured corpora, etc. However, integrating information from heterogeneous
knowledge sources is essential to answer complex questions. In this paper, we
propose to leverage question decomposing for heterogeneous knowledge
integration, by breaking down a complex question into simpler ones, and
selecting the appropriate knowledge source for each sub-question. To facilitate
reasoning, we propose a novel two-stage XQA framework, Reasoning over
Hierarchical Question Decomposition Tree (RoHT). First, we build the
Hierarchical Question Decomposition Tree (HQDT) to understand the semantics of
a complex question; then, we conduct probabilistic reasoning over HQDT from
root to leaves recursively, to aggregate heterogeneous knowledge at different
tree levels and search for a best solution considering the decomposing and
answering probabilities. The experiments on complex QA datasets KQA Pro and
Musique show that our framework outperforms SOTA methods significantly,
demonstrating the effectiveness of leveraging question decomposing for
knowledge integration and our RoHT framework.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:45:59 GMT""}]","2023-05-25"
"2305.15057","Tianyu Liu","Tianyu Liu, Afra Amini, Mrinmaya Sachan, Ryan Cotterell","Learning the String Partial Order","12 pages",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We show that most structured prediction problems can be solved in linear time
and space by considering them as partial orderings of the tokens in the input
string. Our method computes real numbers for each token in an input string and
sorts the tokens accordingly, resulting in as few as 2 total orders of the
tokens in the string. Each total order possesses a set of edges oriented from
smaller to greater tokens. The intersection of total orders results in a
partial order over the set of input tokens, which is then decoded into a
directed graph representing the desired structure. Experiments show that our
method achieves 95.4 LAS and 96.9 UAS by using an intersection of 2 total
orders, 95.7 LAS and 97.1 UAS with 4 on the English Penn Treebank dependency
parsing benchmark. Our method is also the first linear-complexity coreference
resolution model and achieves 79.2 F1 on the English OntoNotes benchmark, which
is comparable with state of the art.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:47:35 GMT""}]","2023-05-25"
"2305.15058","Lucas Giroto de Oliveira","Lucas Giroto de Oliveira, David Brunner, Axel Diewald, Charlotte Muth,
  Laurent Schmalen, Thomas Zwick and Benjamin Nuss","Bistatic OFDM-based Joint Radar-Communication: Synchronization, Data
  Communication and Sensing","Accepted for presentation at the focused session ""Joint Communication
  and Radar Sensing - a step towards 6G'' of the EuMW 2023",,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article introduces a bistatic joint radar-communication (RadCom) system
based on orthogonal frequency-division multiplexing (OFDM). In this context,
the adopted OFDM frame structure is described and system model encompassing
time, frequency, and sampling synchronization mismatches between the
transmitter and receiver of the bistatic system is outlined. Next, the signal
processing approaches for synchronization and communication are discussed, and
radar sensing processing approaches using either only pilots or a reconstructed
OFDM frame based on the estimated receive communication data are presented.
Finally, proof-of-concept measurement results are presented to validate the
investigated system and a trade-off between frame size and the performance of
the aforementioned processing steps is observed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:48:19 GMT""}]","2023-05-25"
"2305.15059","Baptiste Vergain","Bernard Boigelot (1), Pascal Fontaine (1), Baptiste Vergain (1) ((1)
  Montefiore Institute, Universit\'e de Li\`ege, Belgium)","Decidability of Difference Logic over the Reals with Uninterpreted Unary
  Predicates","This is the preprint for the submission published in CADE-29. It also
  includes an additional detailed proof in the appendix. The Version of Record
  of this contribution will be published in CADE-29",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  First-order logic fragments mixing quantifiers, arithmetic, and uninterpreted
predicates are often undecidable, as is, for instance, Presburger arithmetic
extended with a single uninterpreted unary predicate. In the SMT world,
difference logic is a quite popular fragment of linear arithmetic which is less
expressive than Presburger arithmetic. Difference logic on integers with
uninterpreted unary predicates is known to be decidable, even in the presence
of quantifiers. We here show that (quantified) difference logic on real numbers
with a single uninterpreted unary predicate is undecidable, quite surprisingly.
Moreover, we prove that difference logic on integers, together with order on
reals, combined with uninterpreted unary predicates, remains decidable.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:48:51 GMT""}]","2023-05-25"
"2305.15060","Jamin Shin","Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo
  Yun, Jamin Shin, Gunhee Kim","Who Wrote this Code? Watermarking for Code Generation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models for code have recently shown remarkable performance in
generating executable code. However, this rapid advancement has been
accompanied by many legal and ethical concerns, such as code licensing issues,
code plagiarism, and malware generation, making watermarking machine-generated
code a very timely problem. Despite such imminent needs, we discover that
existing watermarking and machine-generated text detection methods for LLMs
fail to function with code generation tasks properly. Hence, in this work, we
propose a new watermarking method, SWEET, that significantly improves upon
previous approaches when watermarking machine-generated code. Our proposed
method selectively applies watermarking to the tokens with high enough entropy,
surpassing a defined threshold. The experiments on code generation benchmarks
show that our watermarked code has superior quality compared to code produced
by the previous state-of-the-art LLM watermarking method. Furthermore, our
watermark method also outperforms DetectGPT for the task of machine-generated
code detection.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:49:52 GMT""}]","2023-05-25"
"2305.15061","Javier Ure\~na-Carrion","Javier Ure\~na-Carrion, Fariba Karimi, Gerardo I\~niguez, Mikko
  Kivel\""a","Assortative and preferential attachment lead to core-periphery networks","5 figures",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Core-periphery is a key feature of large-scale networks underlying a wide
range of social, biological, and transportation phenomena. Despite its
prevalence in empirical data, it is unclear whether this property is a
consequence of more fundamental network evolution processes. While preferential
attachment can create degree heterogeneity indistinguishable from
core-periphery, it doesn't explain why specific groups of nodes gain dominance
and become cores. We show that even small amounts of assortative attachment,
e.g. homophily in social networks, can break this symmetry, and that the
interplay of the two mechanisms leads to one of the groups emerging as a
prominent core. A systematic analysis of the phase space of the proposed model
reveals the levels of assortative and preferential attachment necessary for a
group to become either core or periphery, depending on initial conditions. We
find that relative group size is significant, with minority groups typically
having a disadvantage on becoming the core for similar assortative attachment
levels among groups. We also find that growing networks are less prone to
develop core-periphery than dynamically evolving networks, and that these two
network evolution mechanisms lead to different types of core-periphery
structures. Analyzing five empirical networks, our findings suggest that core
nodes are highly assortative, illustrating the potential of our model as a tool
for designing and analyzing interventions on evolving networks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:51:54 GMT""}]","2023-05-25"
"2305.15062","Quzhe Huang","Quzhe Huang, Mingxu Tao, Zhenwei An, Chen Zhang, Cong Jiang, Zhibin
  Chen, Zirui Wu, Yansong Feng","Lawyer LLaMA Technical Report","Work in progress",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Language Models (LLMs), like LLaMA, have exhibited remarkable
performances across various tasks. Nevertheless, when deployed to specific
domains such as law or medicine, the models still confront the challenge of a
deficiency in domain-specific knowledge and an inadequate capability to
leverage that knowledge to resolve domain-related problems. In this paper, we
focus on the legal domain and explore how to inject domain knowledge during the
continual training stage and how to design proper supervised finetune tasks to
help the model tackle practical issues. Moreover, to alleviate the
hallucination problem during model's generation, we add a retrieval module and
extract relevant articles before the model answers any queries. Augmenting with
the extracted evidence, our model could generate more reliable responses. We
release our data and model at https://github.com/AndrewZhe/lawyer-llama.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:52:07 GMT""}]","2023-05-25"
"2305.15063","Riccardo Walter Maffucci","Riccardo W. Maffucci","Rao's Theorem for forcibly planar sequences revisited",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the graph degree sequences such that every realisation is a
polyhedron. It turns out that there are exactly eight of them. All of these are
unigraphic, in the sense that each is realised by exactly one polyhedron. This
is a revisitation of a Theorem of Rao about sequences that are realised by only
planar graphs.
  Our proof yields additional geometrical insight on this problem. Moreover,
our proof is constructive: for each graph degree sequence that is not forcibly
polyhedral, we construct a non-polyhedral realisation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:52:18 GMT""}]","2023-05-25"
"2305.15064","Siqi Ouyang","Siqi Ouyang and Lei Li","Prompt Optimization of Large Language Model for Interactive Tasks
  without Gradient and Demonstrations","Draft. Work in Progress",,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Large language models (LLMs) have demonstrated remarkable language
proficiency, but they face challenges when solving interactive tasks
independently. Existing methods either rely on gradient access, which is often
inaccessible in state-of-the-art LLMs like GPT-4, or necessitate diverse and
high-quality in-context demonstrations. In this study, we propose LLM-PO, a
novel approach that enables LLMs to address these tasks without gradient access
or extensive demonstrations. The key idea is to maintain a text-based plan and
ask LLMs to reflect on pros and cons of the current plan based on experience
collected with it, to update the plan, and to collect more experiences with the
new plan. Experiments on HotpotQA demonstrate that LLM-PO achieves higher or on
par success rates compared to in-context learning (ICL) baselines while
requiring less inference cost.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:52:23 GMT""}]","2023-05-25"
"2305.15065","Ximing Lu","Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Chandu,
  Abhilasha Ravichander, Lianhui Qin, Prithviraj Ammanabrolu, Liwei Jiang,
  Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Yuchen Lin, Skyler
  Hallinan, Xiang Ren, Sean Welleck, Yejin Choi","Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs
  without Fine-tuning",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models excel at a variety of language tasks when prompted with
examples or instructions. Yet controlling these models through prompting alone
is limited. Tailoring language models through fine-tuning (e.g., via
reinforcement learning) can be effective, but it is expensive and requires
model access.
  We propose Inference-time Policy Adapters (IPA), which efficiently tailors a
language model such as GPT-3 without fine-tuning it. IPA guides a large base
model during decoding time through a lightweight policy adaptor trained to
optimize an arbitrary user objective with reinforcement learning.
  On five challenging text generation tasks, such as toxicity reduction and
open-domain generation, IPA consistently brings significant improvements over
off-the-shelf language models. It outperforms competitive baseline methods,
sometimes even including expensive fine-tuning. In particular, tailoring GPT-2
with IPA can outperform GPT-3, while tailoring GPT- 3 with IPA brings a major
performance boost over GPT-3 (and sometimes even over GPT-4). Our promising
results highlight the potential of IPA as a lightweight alternative to
tailoring extreme-scale language models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:52:55 GMT""}]","2023-05-25"
"2305.15066","Jiayan Guo","Jiayan Guo and Lun Du and Hengyu Liu","GPT4Graph: Can Large Language Models Understand Graph Structured Data ?
  An Empirical Evaluation and Benchmarking",,,,,"cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language models~(LLM) like ChatGPT have become indispensable to
artificial general intelligence~(AGI), demonstrating excellent performance in
various natural language processing tasks. In the real world, graph data is
ubiquitous and an essential part of AGI and prevails in domains like social
network analysis, bioinformatics and recommender systems. The training corpus
of large language models often includes some algorithmic components, which
allows them to achieve certain effects on some graph data-related problems.
However, there is still little research on their performance on a broader range
of graph-structured data. In this study, we conduct an extensive investigation
to assess the proficiency of LLMs in comprehending graph data, employing a
diverse range of structural and semantic-related tasks. Our analysis
encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph
understanding. Through our study, we not only uncover the current limitations
of language models in comprehending graph structures and performing associated
reasoning tasks but also emphasize the necessity for further advancements and
novel approaches to enhance their graph processing capabilities. Our findings
contribute valuable insights towards bridging the gap between language models
and graph understanding, paving the way for more effective graph mining and
knowledge extraction.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:53:19 GMT""}]","2023-05-25"
"2305.15067","Tianyi Tang","Tianyi Tang, Hongyuan Lu, Yuchen Eleanor Jiang, Haoyang Huang,
  Dongdong Zhang, Wayne Xin Zhao, Furu Wei","Not All Metrics Are Guilty: Improving NLG Evaluation with LLM
  Paraphrasing",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most research about natural language generation (NLG) relies on evaluation
benchmarks with limited references for a sample, which may result in poor
correlations with human judgements. The underlying reason is that one semantic
meaning can actually be expressed in different forms, and the evaluation with a
single or few references may not accurately reflect the quality of the model's
hypotheses. To address this issue, this paper presents a novel method, named
Para-Ref, to enhance existing evaluation benchmarks by enriching the number of
references. We leverage large language models (LLMs) to paraphrase a single
reference into multiple high-quality ones in diverse expressions. Experimental
results on representative NLG tasks of machine translation, text summarization,
and image caption demonstrate that our method can effectively improve the
correlation with human evaluation for sixteen automatic evaluation metrics by
+7.82% in ratio. We release the code and data at
https://github.com/RUCAIBox/Para-Ref.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:53:29 GMT""}]","2023-05-25"
"2305.15068","Lingyu Gao","Xiaomeng Ma, Lingyu Gao, Qihui Xu","ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks
  for Exploring Theory of Mind","work in progress",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Theory of Mind (ToM), the capacity to comprehend the mental states of
distinct individuals, is essential for numerous practical applications. With
the development of large language models, there is a heated debate about
whether they are able to perform ToM tasks. Previous studies have used
different tasks and prompts to test the ToM on large language models and the
results are inconsistent: some studies asserted these models are capable of
exhibiting ToM, while others suggest the opposite. In this study, We present
ToMChallenges, a dataset for comprehensively evaluating Theory of Mind based on
Sally-Anne and Smarties tests. We created 30 variations of each test (e.g.,
changing the person's name, location, and items). For each variation, we test
the model's understanding of different aspects: reality, belief, 1st order
belief, and 2nd order belief. We adapt our data for various tasks by creating
unique prompts tailored for each task category: Fill-in-the-Blank, Multiple
Choice, True/False, Chain-of-Thought True/False, Question Answering, and Text
Completion. If the model has a robust ToM, it should be able to achieve good
performance for different prompts across different tests. We evaluated two
GPT-3.5 models, text-davinci-003 and gpt-3.5-turbo-0301, with our datasets. Our
results indicate that consistent performance in ToM tasks remains a challenge.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:54:07 GMT""}]","2023-05-25"
"2305.15069","Lucas Giroto de Oliveira","Lucas Giroto de Oliveira, Elizabeth Bekker, Axel Diewald, Benjamin
  Nuss, Theresa Antes, Yueheng Li, Akanksha Bhutani, and Thomas Zwick","Enabling Joint Radar-Communication Operation in Shift Register-Based
  PMCW Radars","Accepted for presentation at the focused session ""Automotive PMCW
  Radars'' of the EuMW 2023",,,,"eess.SP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article introduces adaptations to the conventional frame structure in
binary phase-modulated continuous wave (PMCW) radars with sequence generation
via linear-feedbck shift registers and additional processing steps to enable
joint radar-communication (RadCom) operation. In this context, a preamble
structure based on pseudorandom binary sequences (PRBSs) that is compatible
with existing synchronization algorithms is outlined, and the allocation of
pilot PRBS blocks is discussed. Finally, results from proof-of-concept
measurements are presented to illustrate the effects of the choice of system
and signal parameters and validate the investigated PMCW-based RadCom system
and synchronization strategy.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:54:20 GMT""}]","2023-05-25"
"2305.15070","London Lowmanstone","London Lowmanstone, Ruyuan Wan, Risako Owan, Jaehyung Kim, Dongyeop
  Kang","Annotation Imputation to Individualize Predictions: Initial Studies on
  Distribution Dynamics and Model Predictions","12 pages, 5 figures",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Annotating data via crowdsourcing is time-consuming and expensive. Owing to
these costs, dataset creators often have each annotator label only a small
subset of the data. This leads to sparse datasets with examples that are marked
by few annotators; if an annotator is not selected to label an example, their
opinion regarding it is lost. This is especially concerning for subjective NLP
datasets where there is no correct label: people may have different valid
opinions. Thus, we propose using imputation methods to restore the opinions of
all annotators for all examples, creating a dataset that does not leave out any
annotator's view. We then train and prompt models with data from the imputed
dataset (rather than the original sparse dataset) to make predictions about
majority and individual annotations. Unfortunately, the imputed data provided
by our baseline methods does not improve predictions. However, through our
analysis of it, we develop a strong understanding of how different imputation
methods impact the original data in order to inform future imputation
techniques. We make all of our code and data publicly available.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:54:46 GMT""}]","2023-05-25"
"2305.15071","Hongjian Sun Prof.","Yue Cao and Sifan Li and Chenchen Lv and Di Wang and Hongjian Sun and
  Jing Jiang and Fanlin Meng and Lexi Xu and Xinzhou Cheng","Towards Cyber Security for Low-Carbon Transportation: Overview,
  Challenges and Future Directions","34 pages, 6 figures, accepted by journal Renewable and Sustainable
  Energy Reviews",,,,"cs.IT cs.CR math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, low-carbon transportation has become an indispensable part
as sustainable development strategies of various countries, and plays a very
important responsibility in promoting low-carbon cities. However, the security
of low-carbon transportation has been threatened from various ways. For
example, denial of service attacks pose a great threat to the electric vehicles
and vehicle-to-grid networks. To minimize these threats, several methods have
been proposed to defense against them. Yet, these methods are only for certain
types of scenarios or attacks. Therefore, this review addresses security aspect
from holistic view, provides the overview, challenges and future directions of
cyber security technologies in low-carbon transportation. Firstly, based on the
concept and importance of low-carbon transportation, this review positions the
low-carbon transportation services. Then, with the perspective of network
architecture and communication mode, this review classifies its typical attack
risks. The corresponding defense technologies and relevant security suggestions
are further reviewed from perspective of data security, network management
security and network application security. Finally, in view of the long term
development of low-carbon transportation, future research directions have been
concerned.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:54:53 GMT""}]","2023-05-25"
"2305.15072","Yuxuan Sun","Yuxuan Sun, Chenglu Zhu, Sunyi Zheng, Kai Zhang, Zhongyi Shui,
  Xiaoxuan Yu, Yizhi Zhao, Honglin Li, Yunlong Zhang, Ruojia Zhao, Xinheng Lyu,
  Lin Yang","PathAsst: Redefining Pathology through Generative Foundation AI
  Assistant for Pathology","13 pages, 5 figures, conference",,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As advances in large language models (LLMs) and multimodal techniques
continue to mature, the development of general-purpose multimodal large
language models (MLLMs) has surged, with significant applications in natural
image interpretation. However, the field of pathology has largely remained
untapped in this regard, despite the growing need for accurate, timely, and
personalized diagnostics. To bridge the gap in pathology MLLMs, we present the
PathAsst in this study, which is a generative foundation AI assistant to
revolutionize diagnostic and predictive analytics in pathology. To develop
PathAsst, we collect over 142K high-quality pathology image-text pairs from a
variety of reliable sources, including PubMed, comprehensive pathology
textbooks, reputable pathology websites, and private data annotated by
pathologists. Leveraging the advanced capabilities of ChatGPT/GPT-4, we
generate over 180K instruction-following samples. Furthermore, we devise
additional instruction-following data, specifically tailored for the invocation
of the pathology-specific models, allowing the PathAsst to effectively interact
with these models based on the input image and user intent, consequently
enhancing the model's diagnostic capabilities. Subsequently, our PathAsst is
trained based on Vicuna-13B language model in coordination with the CLIP vision
encoder. The results of PathAsst show the potential of harnessing the
AI-powered generative foundation model to improve pathology diagnosis and
treatment processes. We are committed to open-sourcing our meticulously curated
dataset, as well as a comprehensive toolkit designed to aid researchers in the
extensive collection and preprocessing of their own datasets. Resources can be
obtained at
https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:55:50 GMT""}]","2023-05-25"
"2305.15073","Hristo Tonchev","Hristo Tonchev, Petar Danev","Robustness of Quantum Random Walk Search Algorithm in Hypercube when
  only first or both first and second neighbors are measured","32 pages, 15 figures, 3 tables, 2 Appendices",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we study the robustness of two modifications of quantum random
walk search algorithm on hypercube. In the first previously suggested
modification, on each even iteration only quantum walk is applied. And in the
second, the closest neighbors of the solution are measured classically. In our
approach the traversing coin is constructed by both generalized Householder
reflection and an additional phase multiplier and we investigate the stability
of the algorithm to deviations in those phases. We have shown that the
unmodified algorithm becomes more robust when a certain relation between those
phases is preserved. The first modification we study here does not lead to any
change in the robustness of quantum random walk search algorithm. However, when
a measurement of the first and second neighbors is included, there are some
differences. The most important one, in view of our study of the robustness, is
an increase in the stability of the algorithm, especially for large coin
dimensions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:55:52 GMT""}]","2023-05-25"
"2305.15074","Daman Arora","Daman Arora, Himanshu Gaurav Singh, Mausam","Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For
  Large Language Models",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  The performance on Large Language Models (LLMs) on existing reasoning
benchmarks has shot up considerably over the past years. In response, we
present JEEBench, a considerably more challenging benchmark dataset for
evaluating the problem solving abilities of LLMs. We curate 450 challenging
pre-engineering mathematics, physics and chemistry problems from the IIT
JEE-Advanced exam. Long-horizon reasoning on top of deep in-domain knowledge is
essential for solving problems in this benchmark. Our evaluation on the GPT
series of models reveals that although performance improves with newer models,
the best being GPT-4, the highest performance, even after using techniques like
Self-Consistency and Chain-of-Thought prompting is less than 40 percent. Our
analysis demonstrates that errors in algebraic manipulation and failure in
retrieving relevant domain specific concepts are primary contributors to GPT4's
low performance. Given the challenging nature of the benchmark, we hope that it
can guide future research in problem solving using LLMs. Our code and dataset
is available here.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:55:59 GMT""}]","2023-05-25"
"2305.15075","Benyou Wang","Hongbo Zhang and Junying Chen and Feng Jiang and Fei Yu and Zhihong
  Chen and Jianquan Li and Guiming Chen and Xiangbo Wu and Zhiyi Zhang and
  Qingying Xiao and Xiang Wan and Benyou Wang and Haizhou Li","HuatuoGPT, towards Taming Language Model to Be a Doctor",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present HuatuoGPT, a large language model (LLM) for medical
consultation. The core recipe of HuatuoGPT is to leverage both
\textit{distilled data from ChatGPT} and \textit{real-world data from doctors}
in the supervised fine-tuned stage. The responses of ChatGPT are usually
detailed, well-presented and informative while it cannot perform like a doctor
in many aspects, e.g. for integrative diagnosis. We argue that real-world data
from doctors would be complementary to distilled data in the sense the former
could tame a distilled language model to perform like doctors. To better
leverage the strengths of both data, we train a reward model to align the
language model with the merits that both data bring, following an RLAIF
(reinforced learning from AI feedback) fashion. To evaluate and benchmark the
models, we propose a comprehensive evaluation scheme (including automatic and
manual metrics). Experimental results demonstrate that HuatuoGPT achieves
state-of-the-art results in performing medical consultation among open-source
LLMs in GPT-4 evaluation, human evaluation, and medical benchmark datasets. It
is worth noting that by using additional real-world data and RLAIF, the
distilled language model (i.e., HuatuoGPT) outperforms its teacher model
ChatGPT in most cases. Our code, data, and models are publicly available at
\url{https://github.com/FreedomIntelligence/HuatuoGPT}. The online demo is
available at \url{https://www.HuatuoGPT.cn/}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:56:01 GMT""}]","2023-05-25"
"2305.15076","Eric A Mitchell","Nathan Hu, Eric Mitchell, Christopher D. Manning, Chelsea Finn","Meta-Learning Online Adaptation of Language Models",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models encode surprisingly broad knowledge about the world
into their parameters. However, the knowledge in static language models can
fall out of date, limiting the model's effective ""shelf life."" While online
fine-tuning can reduce this degradation, we find that fine-tuning on a stream
of documents using standard optimizers such as Adam leads to a disappointingly
low level of information uptake. We hypothesize that online fine-tuning does
not sufficiently 'attend' to important information. That is, the gradient
signal from important tokens representing factual information is drowned out by
the gradient from inherently noisy tokens, suggesting a dynamic, context-aware
learning rate may be beneficial. To test this hypothesis, we meta-train a
small, autoregressive model to reweight the language modeling loss for each
token during online fine-tuning, with the objective of maximizing the
out-of-date base language model's ability to answer questions about a document
after a single weighted gradient step. We call this approach Context-aware
Meta-learned Loss Scaling (CaMeLS). Across three different distributions of
documents, our experiments find that fine-tuning on streams of thousands of
documents with CaMeLS substantially improves knowledge retention compared to
standard online fine-tuning. Finally, we find that the meta-learned weights are
general, and that a single reweighting model can be used to enhance the online
adaptation of many LMs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:56:20 GMT""}]","2023-05-25"
"2305.15077","Junxian He","Junlei Zhang, Zhenzhong Lan, Junxian He","Contrastive Learning of Sentence Embeddings from Scratch","Preprint",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contrastive learning has been the dominant approach to train state-of-the-art
sentence embeddings. Previous studies have typically learned sentence
embeddings either through the use of human-annotated natural language inference
(NLI) data or via large-scale unlabeled sentences in an unsupervised manner.
However, even in the case of unlabeled data, their acquisition presents
challenges in certain domains due to various reasons. To address these issues,
we present SynCSE, a contrastive learning framework that trains sentence
embeddings with synthesized data. Specifically, we explore utilizing large
language models to synthesize the required data samples for contrastive
learning, including (1) producing positive and negative annotations given
unlabeled sentences (SynCSE-partial), and (2) generating sentences along with
their corresponding annotations from scratch (SynCSE-scratch). Experimental
results on sentence similarity and reranking tasks indicate that both
SynCSE-partial and SynCSE-scratch greatly outperform unsupervised baselines,
and SynCSE-partial even achieves comparable performance to the supervised
models in most settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:56:21 GMT""}]","2023-05-25"
"2305.15078","Yunfan Lu","Yunfan Lu, Guoqiang Liang, Lin Wang","Learning INR for Event-guided Rolling Shutter Frame Correction, Deblur,
  and Interpolation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Images captured by rolling shutter (RS) cameras under fast camera motion
often contain obvious image distortions and blur, which can be modeled as a
row-wise combination of a sequence of global shutter (GS) frames within the
exposure time naturally, recovering high-frame-rate GS sharp frames from an RS
blur image needs to simultaneously consider RS correction, deblur, and frame
interpolation Taking this task is nontrivial, and to our knowledge, no feasible
solutions exist by far. A naive way is to decompose the complete process into
separate tasks and simply cascade existing methods; however, this results in
cumulative errors and noticeable artifacts. Event cameras enjoy many
advantages, e.g., high temporal resolution, making them potential for our
problem. To this end, we make the first attempt to recover high-frame-rate
sharp GS frames from an RS blur image and paired event data. Our key idea is to
learn an implicit neural representation (INR) to directly map the position and
time coordinates to RGB values to address the interlocking degradations in the
image restoration process. Specifically, we introduce spatial-temporal implicit
encoding (STE) to convert an RS blur image and events into a spatial-temporal
representation (STR). To query a specific sharp frame (GS or RS), we embed the
exposure time into STR and decode the embedded features to recover a sharp
frame. Moreover, we propose an RS blur image-guided integral loss to better
train the network. Our method is relatively lightweight as it contains only
0.379M parameters and demonstrates high efficiency as the STE is called only
once for any number of interpolation frames. Extensive experiments show that
our method significantly outperforms prior methods addressing only one or two
of the tasks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:57:03 GMT""}]","2023-05-25"
"2305.15079","Zhuoxiao Cheng","Yinguo Yang, Yiling Ye, Zhuoxiao Cheng, Guangchun Ruan, Qiuyu Lu, Xuan
  Wang, Haiwang Zhong","Life cycle economic viability analysis of battery storage in electricity
  market","17 pages, accepted by JPS",,,,"eess.SY cs.SY","http://creativecommons.org/publicdomain/zero/1.0/","  Battery storage is essential to enhance the flexibility and reliability of
electric power systems by providing auxiliary services and load shifting.
Storage owners typically gains incentives from quick responses to auxiliary
service prices, but frequent charging and discharging also reduce its lifetime.
Therefore, this paper embeds the battery degradation cost into the operation
simulation to avoid overestimated profits caused by an aggressive bidding
strategy. Based on an operation simulation model, this paper conducts the
economic viability analysis of whole life cycle using the internal rate of
return(IRR). A clustering method and a typical day method are developed to
reduce the huge computational burdens in the life-cycle simulation of battery
storage. Our models and algorithms are validated by the case study of two
mainstream technology routes currently: lithium nickel cobalt manganese oxide
(NCM) batteries and lithium iron phosphate (LFP) batteries. Then a sensitivity
analysis is presented to identify the critical factors that boost battery
storage in the future. We evaluate the IRR results of different types of
battery storage to provide guidance for investment portfolio.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:59:02 GMT""},{""version"":""v2"",""created"":""Sun, 28 May 2023 09:05:58 GMT""}]","2023-05-30"
"2305.15080","Geewook Kim","Geewook Kim, Hodong Lee, Daehee Kim, Haeji Jung, Sanghee Park, Yoonsik
  Kim, Sangdoo Yun, Taeho Kil, Bado Lee, Seunghyun Park","Cream: Visually-Situated Natural Language Understanding with Contrastive
  Reading Model and Frozen Large Language Models",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advances in Large Language Models (LLMs) have inspired a surge of research
exploring their expansion into the visual domain. While recent models exhibit
promise in generating abstract captions for images and conducting natural
conversations, their performance on text-rich images leaves room for
improvement. In this paper, we propose the Contrastive Reading Model (Cream), a
novel neural architecture designed to enhance the language-image understanding
capability of LLMs by capturing intricate details typically overlooked by
existing methods. Cream integrates vision and auxiliary encoders, complemented
by a contrastive feature alignment technique, resulting in a more effective
understanding of textual information within document images. Our approach,
thus, seeks to bridge the gap between vision and language understanding, paving
the way for more sophisticated Document Intelligence Assistants. Rigorous
evaluations across diverse tasks, such as visual question answering on document
images, demonstrate the efficacy of Cream as a state-of-the-art model in the
field of visual document understanding. We provide our codebase and
newly-generated datasets at https://github.com/naver-ai/cream
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:59:13 GMT""}]","2023-05-25"
"2305.15081","Maria Giovanna Dainotti","Petrosian Vah/'e and Maria Giovanna Dainotti","Progenitors of Low Redshift Gamma-ray Bursts","6 pages, 4 figures of two panels",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bimodal distribution of the observed duration of gamma-ray bursts (GRBs) has
led to two distinct progenitors; compact star mergers, either two neutron stars
(NSs) or a NS and a black hole (BH), for short GRBs (SGRBs), and so-called
collapsars for long GRBs (LGRBs). It is therefore expected that formation rate
(FR) of LGRBs should be similar to the cosmic star formation rate (SFR), while
that of SGRBs to be delayed relative to the SFR. The localization of some LGRBs
in and around the star forming regions of host galaxies and some SGRBs away
form such regions support this expectation. Another distinct feature of SGRBs
is their association with gravitational wave (GW) sources and kilonovae.
However, several independent investigations of the FRs of long and short
bursts, using the Efron-Petrosian non-parametric method have shown a LGRB FR
that is significantly larger than SFR at low redhift, and similar to the FR of
SGRBs. In addition, recent discovery of association of a low redshift long
GRB211211A with a kilonova raises doubt about its collapsar origin. In this
letter we review these results and show that low redshift LGRBs could also have
compact star mergers as progenitor increasing the expected rate of the GW
sources and kilonovae significantly.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:59:42 GMT""}]","2023-05-25"
"2305.15082","Rahul Rao","Rahul Rao, Ryan Selhorst, Jie Jiang, Benjamin S. Conner, Ryan
  Siebenaller, Emmanuel Rowe, Andrea Giordano, Ruth Pachter, Michael A. Susner","Investigating strain between phase-segregated domains in Cu-deficient
  CuInP2S6","12 pages, 6 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  CuInP2S6 (CIPS) is an emerging layered ferroelectric material with a TC above
room temperature. When synthesized with Cu deficiencies (i.e.,
Cu1-xIn1+x/3P2S6), the material segregates into CIPS and In4/3P2S6 (IPS)
self-assembled heterostructures within the same single crystal. This
segregation results in significant in-plane and out-of-plane strains between
the CIPS and IPS phases as the volume fraction of CIPS (IPS) domains shrink
(grow) with decreasing Cu fraction. Here, we synthesized CIPS with varying
amounts of Cu (x = 0, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8 and 1) and measured the
strains between the CIPS and IPS phases through the evolution of the respective
Raman, infrared, and optical reflectance spectra. Density functional theory
calculations revealed vibrational modes unique to the CIPS and IPS phases,
which can be used to distinguish between the two phases through two-dimensional
Raman mapping. A comparison of the composition-dependent frequencies and
intensities of the CIPS and IPS Raman peaks showed interesting trends with
decreasing CIPS phase fraction (i.e., Cu/In ratio). Our data reveal red- and
blue-shifted Raman and infrared peak frequencies that we correlate to lattice
strains arising from the segregation of the material into CIPS and IPS chemical
domains. The strain is highest for a Cu/In ratio of 0.33 (Cu0.4In1.2P2S6),
which we attribute to equal and opposite strains exerted by the CIPS and IPS
phases on each other. In addition, bandgaps extracted from the optical
reflectance spectra revealed a decrease in values, with the lowest value (~ 2.3
eV) for Cu0.4In1.2P2S6.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:00:23 GMT""}]","2023-05-25"
"2305.15083","Jiahuan Li","Jiahuan Li, Hao Zhou, Shujian Huang, Shanbo Chen, Jiajun Chen","Eliciting the Translation Ability of Large Language Models via
  Multilingual Finetuning with Translation Instructions",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large-scale Pretrained Language Models~(LLMs), such as ChatGPT and GPT4, have
shown strong abilities in multilingual translations, without being explicitly
trained on parallel corpora. It is interesting how the LLMs obtain their
ability to carry out translation instructions for different languages. In this
paper, we present a detailed analysis by finetuning a multilingual pretrained
language model, XGLM-7B, to perform multilingual translation following given
instructions. Firstly, we show that the multilingual LLMs have stronger
translation abilities than previously demonstrated. For a certain language
pair, the performance depends on both the language families and the amount of
data used in the pretraining phase. Secondly, we find that LLMs' ability to
carry out translation instructions relies on the understanding of translation
instruction and the alignment among different languages. With proper
enhancement, LLMs could perform the translation task well even for those
language pairs unseen during the instruction tuning phase.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:00:24 GMT""}]","2023-05-25"
"2305.15084","Arian Bakhtiarnia","B{\l}a\.zej Leporowski, Arian Bakhtiarnia, Nicole Bonnici, Adrian
  Muscat, Luca Zanella, Yiming Wang and Alexandros Iosifidis","Audio-Visual Dataset and Method for Anomaly Detection in Traffic Videos",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the first audio-visual dataset for traffic anomaly detection
taken from real-world scenes, called MAVAD, with a diverse range of weather and
illumination conditions. In addition, we propose a novel method named AVACA
that combines visual and audio features extracted from video sequences by means
of cross-attention to detect anomalies. We demonstrate that the addition of
audio improves the performance of AVACA by up to 5.2%. We also evaluate the
impact of image anonymization, showing only a minor decrease in performance
averaging at 1.7%.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:02:42 GMT""}]","2023-05-25"
"2305.15085","Yoshimichi Ueda","Yoshiki Aibara and Yoshimichi Ueda","Lebesgue decomposition for positive operators revisited","13pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explain how Pusz--Woronowicz's idea of their functional calculus fits the
theory of Lebesgue decomposition for positive operators on Hilbert spaces
initially developed by Ando. In this way, we reconstruct the essential and
fundamental part of the theory.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:02:58 GMT""}]","2023-05-25"
"2305.15086","Jong Chul Ye","Beomsu Kim, Gihyun Kwon, Kwanyoung Kim, Jong Chul Ye","Unpaired Image-to-Image Translation via Neural Schr\""odinger Bridge",,,,,"cs.CV cs.AI cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Diffusion models are a powerful class of generative models which simulate
stochastic differential equations (SDEs) to generate data from noise. Although
diffusion models have achieved remarkable progress in recent years, they have
limitations in the unpaired image-to-image translation tasks due to the
Gaussian prior assumption. Schr\""odinger Bridge (SB), which learns an SDE to
translate between two arbitrary distributions, have risen as an attractive
solution to this problem. However, none of SB models so far have been
successful at unpaired translation between high-resolution images. In this
work, we propose the Unpaired Neural Schr\""odinger Bridge (UNSB), which
combines SB with adversarial training and regularization to learn a SB between
unpaired data. We demonstrate that UNSB is scalable, and that it successfully
solves various unpaired image-to-image translation tasks. Code:
\url{https://github.com/cyclomon/UNSB}
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:05:24 GMT""}]","2023-05-25"
"2305.15087","Philipp Sadler","Philipp Sadler and David Schlangen","Pento-DIARef: A Diagnostic Dataset for Learning the Incremental
  Algorithm for Referring Expression Generation from Examples","9 pages, Accepted to EACL 2023",,,,"cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  NLP tasks are typically defined extensionally through datasets containing
example instantiations (e.g., pairs of image i and text t), but motivated
intensionally through capabilities invoked in verbal descriptions of the task
(e.g., ""t is a description of i, for which the content of i needs to be
recognised and understood""). We present Pento-DIARef, a diagnostic dataset in a
visual domain of puzzle pieces where referring expressions are generated by a
well-known symbolic algorithm (the ""Incremental Algorithm""), which itself is
motivated by appeal to a hypothesised capability (eliminating distractors
through application of Gricean maxims). Our question then is whether the
extensional description (the dataset) is sufficient for a neural model to pick
up the underlying regularity and exhibit this capability given the simple task
definition of producing expressions from visual inputs. We find that a model
supported by a vision detection step and a targeted data generation scheme
achieves an almost perfect BLEU@1 score and sentence accuracy, whereas simpler
baselines do not.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:05:53 GMT""}]","2023-05-25"
"2305.15088","Anton Kutsenko A","Anton A. Kutsenko","Complete left tail asymptotic for the density of branching processes in
  the Schr\""oder case",,,,,"math.PR math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the density of Galton-Watson processes in the Schr\""oder case, we derive
a complete left tail asymptotic series consisting of power terms multiplied by
periodic factors.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:14:28 GMT""}]","2023-05-25"
"2305.15089","Wiktoria Zajkowska","Wiktoria Zajkowska, Jakub Turczynski, Boguslawa Kurowska, Henryk
  Teisseyre, Krzysztof Fronc, Jerzy Dabrowski and Slawomir Kret","ZnO nanowires grown on Al2O3-ZnAl2O4 nanostructure using solid-vapor
  mechanism","Conference: 13th Polish-Japanese Joint Seminar on Micro and Nano
  Analysis",,"10.24425/amm.2023.145491",,"cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present Al2O3-ZnAl2O4-ZnO nanostructure, which could be a prominent
candidate for optoelectronics, mechanical and sensing applications. While ZnO
and ZnAl2O4 composites are mostly synthesized by sol-gel technique, we propose
a solid-vapor growth mechanism. To produce Al2O3-ZnAl2O4-ZnO nanostructure, we
conduct ZnO:C powder heating resulting in ZnO nanowires (NWs) growth on
sapphire substrate and ZnAl2O4 spinel layer at the interface. The nanostructure
was examined with Scanning Electron Microscopy (SEM) method. Focused Ion Beam
(FIB) technique enabled us to prepare a lamella for Transmission Electron
Microscopy (TEM) imaging. TEM examination revealed high crystallographic
quality of both spinel and NW structure. Epitaxial relationships of
Al2O3-ZnAl2O4 and ZnAl2O4-ZnO are given.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:15:17 GMT""}]","2023-05-25"
"2305.15090","Mingyu Derek Ma","Mingyu Derek Ma, Xiaoxuan Wang, Po-Nien Kung, P. Jeffrey Brantingham,
  Nanyun Peng, Wei Wang","STAR: Boosting Low-Resource Event Extraction by Structure-to-Text Data
  Generation with Large Language Models",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Structure prediction tasks such as event extraction require an in-depth
understanding of the output structure and sub-task dependencies, thus they
still heavily rely on task-specific training data to obtain reasonable
performance. Due to the high cost of human annotation, low-resource event
extraction, which requires minimal human cost, is urgently needed in real-world
information extraction applications. We propose to synthesize data instances
given limited seed demonstrations to boost low-resource event extraction
performance. We propose STAR, a structure-to-text data generation method that
first generates complicated event structures (Y) and then generates input
passages (X), all with Large Language Models. We design fine-grained
step-by-step instructions and the error cases and quality issues identified
through self-reflection can be self-refined. Our experiments indicate that data
generated by STAR can significantly improve the low-resource event extraction
performance and they are even more effective than human-curated data points in
some cases.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:15:19 GMT""}]","2023-05-25"
"2305.15091","Wadii Boulila Prof.","Zouhayra Ayadi, Wadii Boulila, Imed Riadh Farah","Modeling Complex Object Changes in Satellite Image Time-Series: Approach
  based on CSP and Spatiotemporal Graph",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper proposes a method for automatically monitoring and analyzing the
evolution of complex geographic objects. The objects are modeled as a
spatiotemporal graph, which separates filiation relations, spatial relations,
and spatiotemporal relations, and is analyzed by detecting frequent sub-graphs
using constraint satisfaction problems (CSP). The process is divided into four
steps: first, the identification of complex objects in each satellite image;
second, the construction of a spatiotemporal graph to model the spatiotemporal
changes of the complex objects; third, the creation of sub-graphs to be
detected in the base spatiotemporal graph; and fourth, the analysis of the
spatiotemporal graph by detecting the sub-graphs and solving a constraint
network to determine relevant sub-graphs. The final step is further broken down
into two sub-steps: (i) the modeling of the constraint network with defined
variables and constraints, and (ii) the solving of the constraint network to
find relevant sub-graphs in the spatiotemporal graph. Experiments were
conducted using real-world satellite images representing several cities in
Saudi Arabia, and the results demonstrate the effectiveness of the proposed
approach.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:15:19 GMT""}]","2023-05-25"
"2305.15092","Philipp Wiesner","Philipp Wiesner, Ramin Khalili, Dennis Grinwald, Pratik Agrawal,
  Lauritz Thamsen, Odej Kao","FedZero: Leveraging Renewable Excess Energy in Federated Learning",,,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning (FL) is an emerging machine learning technique that
enables distributed model training across data silos or edge devices without
data sharing. Yet, FL inevitably introduces inefficiencies compared to
centralized model training, which will further increase the already high energy
usage and associated carbon emissions of machine learning in the future.
Although the scheduling of workloads based on the availability of low-carbon
energy has received considerable attention in recent years, it has not yet been
investigated in the context of FL. However, FL is a highly promising use case
for carbon-aware computing, as training jobs constitute of energy-intensive
batch processes scheduled in geo-distributed environments.
  We propose FedZero, a FL system that operates exclusively on renewable excess
energy and spare capacity of compute infrastructure to effectively reduce the
training's operational carbon emissions to zero. Based on energy and load
forecasts, FedZero leverages the spatio-temporal availability of excess energy
by cherry-picking clients for fast convergence and fair participation. Our
evaluation, based on real solar and load traces, shows that FedZero converges
considerably faster under the mentioned constraints than state-of-the-art
approaches, is highly scalable, and is robust against forecasting errors.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:17:30 GMT""}]","2023-05-25"
"2305.15093","Ameet Deshpande","Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak Murahari,
  Victoria Graf, Tanmay Rajpurohit, Ashwin Kalyan, Danqi Chen, Karthik
  Narasimhan","CSTS: Conditional Semantic Textual Similarity",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Semantic textual similarity (STS) has been a cornerstone task in NLP that
measures the degree of similarity between a pair of sentences, with
applications in information retrieval, question answering, and embedding
methods. However, it is an inherently ambiguous task, with the sentence
similarity depending on the specific aspect of interest. We resolve this
ambiguity by proposing a novel task called conditional STS (C-STS) which
measures similarity conditioned on an aspect elucidated in natural language
(hereon, condition). As an example, the similarity between the sentences ""The
NBA player shoots a three-pointer."" and ""A man throws a tennis ball into the
air to serve."" is higher for the condition ""The motion of the ball."" (both
upward) and lower for ""The size of the ball."" (one large and one small).
C-STS's advantages are two-fold: (1) it reduces the subjectivity and ambiguity
of STS, and (2) enables fine-grained similarity evaluation using diverse
conditions. C-STS contains almost 20,000 instances from diverse domains and we
evaluate several state-of-the-art models to demonstrate that even the most
performant fine-tuning and in-context learning models (GPT-4, Flan, SimCSE)
find it challenging, with Spearman correlation scores of <50. We encourage the
community to evaluate their models on C-STS to provide a more holistic view of
semantic similarity and natural language understanding.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:18:50 GMT""}]","2023-05-25"
"2305.15094","Dongqing Wang","Dongqing Wang, Tong Zhang, Alaa Abboud, Sabine S\""usstrunk","InpaintNeRF360: Text-Guided 3D Inpainting on Unbounded Neural Radiance
  Fields",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Radiance Fields (NeRF) can generate highly realistic novel views.
However, editing 3D scenes represented by NeRF across 360-degree views,
particularly removing objects while preserving geometric and photometric
consistency, remains a challenging problem due to NeRF's implicit scene
representation. In this paper, we propose InpaintNeRF360, a unified framework
that utilizes natural language instructions as guidance for inpainting
NeRF-based 3D scenes.Our approach employs a promptable segmentation model by
generating multi-modal prompts from the encoded text for multiview
segmentation. We apply depth-space warping to enforce viewing consistency in
the segmentations, and further refine the inpainted NeRF model using perceptual
priors to ensure visual plausibility. InpaintNeRF360 is capable of
simultaneously removing multiple objects or modifying object appearance based
on text instructions while synthesizing 3D viewing-consistent and
photo-realistic inpainting. Through extensive experiments on both unbounded and
frontal-facing scenes trained through NeRF, we demonstrate the effectiveness of
our approach and showcase its potential to enhance the editability of implicit
radiance fields.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:22:23 GMT""}]","2023-05-25"
"2305.15095","David Viennot","David Viennot","Metrics and geodesics on fuzzy spaces",,,,,"math-ph gr-qc hep-th math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the fuzzy spaces (as special examples of noncommutative manifolds)
with their quasicoherent states in order to find their pertinent metrics. We
show that they are naturally endowed with two natural ""quantum metrics"" which
are associated with quantum fluctuations of ""paths"". The first one provides the
length the mean path whereas the second one provides the average length of the
fluctuated paths. Onto the classical manifold associated with the quasicoherent
state (manifold of the mean values of the coordinate observables in the state
minimising their quantum uncertainties) these two metrics provides two
minimising geodesic equations. Moreover, fuzzy spaces being not torsion free,
we have also two different autoparallel geodesic equations associated with two
different adiabatic regimes in the move of a probe onto the fuzzy space. We
apply these mathematical results to quantum gravity in BFSS matrix models, and
to the quantum information theory of a controlled qubit submitted to noises of
a large quantum environment.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:23:40 GMT""}]","2023-05-25"
"2305.15096","Zachary Ankner","Zachary Ankner, Naomi Saphra, Davis Blalock, Jonathan Frankle, and
  Matthew L. Leavitt","Dynamic Masking Rate Schedules for MLM Pretraining",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most works on transformers trained with the Masked Language Modeling (MLM)
objective use the original BERT model's fixed masking rate of 15%. Our work
instead dynamically schedules the masking ratio throughout training. We found
that linearly decreasing the masking rate from 30% to 15% over the course of
pretraining improves average GLUE accuracy by 0.46% in BERT-base, compared to a
standard 15% fixed rate. Further analyses demonstrate that the gains from
scheduling come from being exposed to both high and low masking rate regimes.
Our results demonstrate that masking rate scheduling is a simple way to improve
the quality of masked language models and achieve up to a 1.89x speedup in
pretraining.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:24:12 GMT""}]","2023-05-25"
"2305.15097","Jiesheng Yang","Jiesheng Yang, Andreas Wilde, Karsten Menzel, Md Zubair Sheikh, Boris
  Kuznetsov","Computer Vision for Construction Progress Monitoring: A Real-Time Object
  Detection Approach","15 Pages",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Construction progress monitoring (CPM) is essential for effective project
management, ensuring on-time and on-budget delivery. Traditional CPM methods
often rely on manual inspection and reporting, which are time-consuming and
prone to errors. This paper proposes a novel approach for automated CPM using
state-of-the-art object detection algorithms. The proposed method leverages
e.g. YOLOv8's real-time capabilities and high accuracy to identify and track
construction elements within site images and videos. A dataset was created,
consisting of various building elements and annotated with relevant objects for
training and validation. The performance of the proposed approach was evaluated
using standard metrics, such as precision, recall, and F1-score, demonstrating
significant improvement over existing methods. The integration of Computer
Vision into CPM provides stakeholders with reliable, efficient, and
cost-effective means to monitor project progress, facilitating timely
decision-making and ultimately contributing to the successful completion of
construction projects.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:27:42 GMT""}]","2023-05-25"
"2305.15098","Michael Tang","Michael Tang, Shunyu Yao, John Yang, Karthik Narasimhan","Referral Augmentation for Zero-Shot Information Retrieval",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Referral-Augmented Retrieval (RAR), a simple technique that
concatenates document indices with referrals, i.e. text from other documents
that cite or link to the given document, to provide significant performance
gains for zero-shot information retrieval. The key insight behind our method is
that referrals provide a more complete, multi-view representation of a
document, much like incoming page links in algorithms like PageRank provide a
comprehensive idea of a webpage's importance. RAR works with both sparse and
dense retrievers, and outperforms generative text expansion techniques such as
DocT5Query and Query2Doc a 37% and 21% absolute improvement on ACL paper
retrieval Recall@10 -- while also eliminating expensive model training and
inference. We also analyze different methods for multi-referral aggregation and
show that RAR enables up-to-date information retrieval without re-training.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:28:35 GMT""}]","2023-05-25"
"2305.15099","Ziwei He","Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, Jingwen
  Leng, Zhouhan Lin","Fourier Transformer: Fast Long Range Modeling by Removing Sequence
  Redundancy with FFT Operator",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  The transformer model is known to be computationally demanding, and
prohibitively costly for long sequences, as the self-attention module uses a
quadratic time and space complexity with respect to sequence length. Many
researchers have focused on designing new forms of self-attention or
introducing new parameters to overcome this limitation, however a large portion
of them prohibits the model to inherit weights from large pretrained models. In
this work, the transformer's inefficiency has been taken care of from another
perspective. We propose Fourier Transformer, a simple yet effective approach by
progressively removing redundancies in hidden sequence using the ready-made
Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation
(DCT). Fourier Transformer is able to significantly reduce computational costs
while retain the ability to inherit from various large pretrained models.
Experiments show that our model achieves state-of-the-art performances among
all transformer-based models on the long-range modeling benchmark LRA with
significant improvement in both speed and space. For generative seq-to-seq
tasks including CNN/DailyMail and ELI5, by inheriting the BART weights our
model outperforms the standard BART and other efficient models. \footnote{Our
code is publicly available at
\url{https://github.com/LUMIA-Group/FourierTransformer}}
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:33:06 GMT""}]","2023-05-25"
"2305.15100","Jing Liu","Jing Liu","Distinguishing nanohertz gravitational wave sources through the
  observations of ultracompact minihalos","7 pages, 1 figure, 1 table",,,,"astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The common-spectrum process observed by pulsar-timing arrays is interpreted
as stochastic gravitational wave backgrounds originating from various sources
in the early Universe. Along with generating gravitational waves, we find
energy density perturbations also arise with the sources such as bubble
collisions and sound waves during first-order phase transitions, cosmic
strings, domain walls, condensate fragmentation, and primordial curvature
perturbations from inflation. These perturbations can lead to the formation of
abundant ultracompact minihalos. Currently, the observational precision is
inadequate for discriminating between different models. Then, ongoing and
future astrophysical observations of ultracompact minihalos can help to
distinguish and constrain the gravitational-wave sources in the nanohertz and
$\mu$Hz bands.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:37:00 GMT""}]","2023-05-25"
"2305.15101","Felix Joos","Felix Joos and Jonathan Schrodt","Counting oriented trees in digraphs with large minimum semidegree","24 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $T$ be an oriented tree on $n$ vertices with maximum degree at most
$e^{o(\sqrt{\log n})}$. If $G$ is a digraph on $n$ vertices with minimum
semidegree $\delta^0(G)\geq(\frac12+o(1))n$, then $G$ contains $T$ as a
spanning tree, as recently shown by Kathapurkar and Montgomery (in fact, they
only require maximum degree $o(n/\log n)$). This generalizes the corresponding
result by Koml\'os, S\'ark\""ozy and Szemer\'edi for graphs. We investigate the
natural question how many copies of $T$ the digraph $G$ contains. Our main
result states that every such $G$ contains at least
$|Aut(T)|^{-1}(\frac12-o(1))^nn!$ copies of $T$, which is optimal. This implies
the analogous result in the undirected case.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:37:03 GMT""}]","2023-05-25"
"2305.15102","Diederick Vermetten","Diederick Vermetten and Manuel L\'opez-Ib\'a\~nez and Olaf Mersmann
  and Richard Allmendinger and Anna V. Kononova","Analysis of modular CMA-ES on strict box-constrained problems in the
  SBOX-COST benchmarking suite",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Box-constraints limit the domain of decision variables and are common in
real-world optimization problems, for example, due to physical, natural or
spatial limitations. Consequently, solutions violating a box-constraint may not
be evaluable. This assumption is often ignored in the literature, e.g.,
existing benchmark suites, such as COCO/BBOB, allow the optimizer to evaluate
infeasible solutions. This paper presents an initial study on the
strict-box-constrained benchmarking suite (SBOX-COST), which is a variant of
the well-known BBOB benchmark suite that enforces box-constraints by returning
an invalid evaluation value for infeasible solutions. Specifically, we want to
understand the performance difference between BBOB and SBOX-COST as a function
of two initialization methods and six constraint-handling strategies all tested
with modular CMA-ES. We find that, contrary to what may be expected, handling
box-constraints by saturation is not always better than not handling them at
all. However, across all BBOB functions, saturation is better than not
handling, and the difference increases with the number of dimensions. Strictly
enforcing box-constraints also has a clear negative effect on the performance
of classical CMA-ES (with uniform random initialization and no constraint
handling), especially as problem dimensionality increases.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:37:03 GMT""}]","2023-05-25"
"2305.15103","Andrea Seppi","Andrea Seppi, Graham Smith, J\'er\'emy Toulisse","On complete maximal submanifolds in pseudo-hyperbolic space","60 pages",,,,"math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a full classification of complete maximal $p$-dimensional
spacelike submanifolds in the pseudo-hyperbolic space $\mathbf{H}^{p,q}$, and
we study its applications to Teichm\""uller theory and to the theory of Anosov
representations of hyperbolic groups in $\mathsf{PO}(p,q+1)$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:39:17 GMT""}]","2023-05-25"
"2305.15104","Yican Sun","Yican Sun, Hongfei Fu, Krishnendu Chatterjee and Amir Kafshdar
  Goharshady","Automated Tail Bound Analysis for Probabilistic Recurrence Relations","46 pages, 15 figures",,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  Probabilistic recurrence relations (PRRs) are a standard formalism for
describing the runtime of a randomized algorithm. Given a PRR and a time limit
$\kappa$, we consider the classical concept of tail probability $\Pr[T \ge
\kappa]$, i.e., the probability that the randomized runtime $T$ of the PRR
exceeds the time limit $\kappa$. Our focus is the formal analysis of tail
bounds that aims at finding a tight asymptotic upper bound $u \geq
\Pr[T\ge\kappa]$ in the time limit $\kappa$. To address this problem, the
classical and most well-known approach is the cookbook method by Karp (JACM
1994), while other approaches are mostly limited to deriving tail bounds of
specific PRRs via involved custom analysis.
  In this work, we propose a novel approach for deriving
exponentially-decreasing tail bounds (a common type of tail bounds) for PRRs
whose preprocessing time and random passed sizes observe discrete or
(piecewise) uniform distribution and whose recursive call is either a single
procedure call or a divide-and-conquer. We first establish a theoretical
approach via Markov's inequality, and then instantiate the theoretical approach
with a template-based algorithmic approach via a refined treatment of
exponentiation. Experimental evaluation shows that our algorithmic approach is
capable of deriving tail bounds that are (i) asymptotically tighter than Karp's
method, (ii) match the best-known manually-derived asymptotic tail bound for
QuickSelect, and (iii) is only slightly worse (with a $\log\log n$ factor) than
the manually-proven optimal asymptotic tail bound for QuickSort. Moreover, our
algorithmic approach handles all examples (including realistic PRRs such as
QuickSort, QuickSelect, DiameterComputation, etc.) in less than 0.1 seconds,
showing that our approach is efficient in practice.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:47:50 GMT""}]","2023-05-25"
"2305.15105","Giorgio Di Russo","Massimo Bianchi, Giorgio Di Russo, Alfredo Grillo, Jose Francisco
  Morales, Giuseppe Sudano","On the stability and deformability of top stars",,,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Topological stars, or top stars for brevity, are smooth horizonless static
solutions of Einstein-Maxwell theory in 5-d that reduce to spherically
symmetric solutions of Einstein-Maxwell-Dilaton theory in 4-d. We study linear
scalar perturbations of top stars and argue for their stability and
deformability. We tackle the problem with different techniques including WKB
approximation, numerical analysis, Breit-Wigner resonance method and quantum
Seiberg-Witten curves. We identify three classes of quasi-normal modes
corresponding to prompt-ring down modes, long-lived meta-stable modes and what
we dub `blind' modes. All mode frequencies we find have negative imaginary
parts, thus suggesting linear stability of top stars. Moreover we determine the
tidal Love and dissipation numbers encoding the response to tidal deformations
and, similarly to black holes, we find zero value in the static limit but,
contrary to black holes, we find non-trivial dynamical Love numbers and
vanishing dissipative effects at linear order. For the sake of illustration in
a simpler context, we also consider a toy model with a piece-wise constant
potential and a centrifugal barrier that captures most of the above features in
a qualitative fashion.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:48:14 GMT""}]","2023-05-25"
"2305.15106","Amir Subba Mr","Amir Subba, Ritesh K. Singh","Study of anomalous $W^-W^+\gamma/Z$ couplings using polarizations and
  spin correlations in $e^-e^+\to W^-W^+$ with polarized beams",,,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the anomalous $W^-W^+\gamma/Z$ couplings in $e^-e^+\to W^-W^+$
followed by semileptonic decay using a complete set of polarization and spin
correlation observables of $W$ boson with the longitudinally polarized beam. We
consider a complete set of dimension-six operators affecting $W^-W^+\gamma/Z$
vertex, which are $SU(2)\times U(1)$ gauge invariant. Some of the polarization
and spin correlation asymmetries average out if the daughter of $W^+$ is not
tagged. We developed an artificial neural network and boosted decision trees to
distinguish down-type jets from up-type jets. We obtain bounds on the anomalous
couplings for center of mass energy $\sqrt{s} = 250$ GeV with integrated
luminosities of~$\mathcal{L}\in\{100~\text{fb}^{-1}, 250~\text{fb}^{-1},
1000~\text{fb}^{-1}, 3000~\text{fb}^{-1}\}$. We find that using spin-related
observables and cross~section in the presence of initial beam polarization
significantly improves the bounds on anomalous couplings compared to previous
studies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:50:02 GMT""}]","2023-05-25"
"2305.15107","David Meadon","Sven-Erik Ekstr\""om and David Meadon","On the eigenvalues of Toeplitz matrices with two off-diagonals",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  Consider the Toeplitz matrix $T_n(f)$ generated by the symbol
$f(\theta)=\hat{f}_r e^{\mathbf{i}r\theta}+\hat{f}_0+\hat{f}_{-s}
e^{-\mathbf{i}s\theta}$, where $\hat{f}_r, \hat{f}_0, \hat{f}_{-s} \in
\mathbb{C}$ and $0<r<n,~0<s<n$. For $r=s=1$ we have the classical tridiagonal
Toeplitz matrices, for which the eigenvalues and eigenvectors are known.
Similarly, the eigendecompositions are known for $1<r=s$, when the generated
matrices are ``symmetrically sparse tridiagonal''.
  In the current paper we study the eigenvalues of $T_n(f)$ for $1\leq r<s$,
which are ``non-symmetrically sparse tridiagonal''. We propose an algorithm
which constructs one or two ad hoc matrices smaller than $T_n(f)$, whose
eigenvalues are sufficient for determining the full spectrum of $T_n(f)$. The
algorithm is explained through use of a conjecture for which examples and
numerical experiments are reported for supporting it and for clarifying the
presentation. Open problems are briefly discussed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:53:28 GMT""}]","2023-05-25"
"2305.15108","Debayan Banerjee","Debayan Banerjee, Pranav Ajit Nair, Ricardo Usbeck, Chris Biemann","The Role of Output Vocabulary in T2T LMs for SPARQL Semantic Parsing","Accepted as a short paper to ACL 2023 findings",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  In this work, we analyse the role of output vocabulary for text-to-text (T2T)
models on the task of SPARQL semantic parsing. We perform experiments within
the the context of knowledge graph question answering (KGQA), where the task is
to convert questions in natural language to the SPARQL query language. We
observe that the query vocabulary is distinct from human vocabulary. Language
Models (LMs) are pre-dominantly trained for human language tasks, and hence, if
the query vocabulary is replaced with a vocabulary more attuned to the LM
tokenizer, the performance of models may improve. We carry out carefully
selected vocabulary substitutions on the queries and find absolute gains in the
range of 17% on the GrailQA dataset.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:55:04 GMT""}]","2023-05-25"
"2305.15109","Maximilian Prokop","Jan Kretinsky, Tobias Meggendorfer, Maximilian Prokop, Sabine Rieder","Guessing Winning Policies in LTL Synthesis by Semantic Learning",,,,,"cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a learning-based technique for guessing a winning strategy in a
parity game originating from an LTL synthesis problem. A cheaply obtained guess
can be useful in several applications. Not only can the guessed strategy be
applied as best-effort in cases where the game's huge size prohibits rigorous
approaches, but it can also increase the scalability of rigorous LTL synthesis
in several ways. Firstly, checking whether a guessed strategy is winning is
easier than constructing one. Secondly, even if the guess is wrong in some
places, it can be fixed by strategy iteration faster than constructing one from
scratch. Thirdly, the guess can be used in on-the-fly approaches to prioritize
exploration in the most fruitful directions.
  In contrast to previous works, we (i)~reflect the highly structured logical
information in game's states, the so-called semantic labelling, coming from the
recent LTL-to-automata translations, and (ii)~learn to reflect it properly by
learning from previously solved games, bringing the solving process closer to
human-like reasoning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:57:53 GMT""}]","2023-05-25"
"2305.15111","Elise \""Ozalp","Elise \""Ozalp and Georgios Margazoglou and Luca Magri","Reconstruction, forecasting, and stability of chaotic dynamics from
  partial data",,,,,"nlin.AO cs.LG nlin.CD","http://creativecommons.org/licenses/by/4.0/","  The forecasting and computation of the stability of chaotic systems from
partial observations are tasks for which traditional equation-based methods may
not be suitable. In this computational paper, we propose data-driven methods to
(i) infer the dynamics of unobserved (hidden) chaotic variables (full-state
reconstruction); (ii) time forecast the evolution of the full state; and (iii)
infer the stability properties of the full state. The tasks are performed with
long short-term memory (LSTM) networks, which are trained with observations
(data) limited to only part of the state: (i) the low-to-high resolution LSTM
(LH-LSTM), which takes partial observations as training input, and requires
access to the full system state when computing the loss; and (ii) the
physics-informed LSTM (PI-LSTM), which is designed to combine partial
observations with the integral formulation of the dynamical system's evolution
equations. First, we derive the Jacobian of the LSTMs. Second, we analyse a
chaotic partial differential equation, the Kuramoto-Sivashinsky (KS), and the
Lorenz-96 system. We show that the proposed networks can forecast the hidden
variables, both time-accurately and statistically. The Lyapunov exponents and
covariant Lyapunov vectors, which characterize the stability of the chaotic
attractors, are correctly inferred from partial observations. Third, the
PI-LSTM outperforms the LH-LSTM by successfully reconstructing the hidden
chaotic dynamics when the input dimension is smaller or similar to the
Kaplan-Yorke dimension of the attractor. This work opens new opportunities for
reconstructing the full state, inferring hidden variables, and computing the
stability of chaotic systems from partial data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:01:51 GMT""}]","2023-05-25"
"2305.15112","Shivam Bajpeyi Dr.","Shivam Bajpeyi, Dhiraj Patel and S. Sivananthan","Random Sampling of Mellin Band-limited Signals",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we address the random sampling problem for the class of Mellin
band-limited functions BT which is concentrated on a bounded cube. It is
established that any function in BT can be approximated by an element in a
finite-dimensional subspace of BT. Utilizing the notion of covering number and
Bernstein's inequality to the sum of independent random variables, we prove
that the random sampling inequality holds with an overwhelming probability
provided the sampling size is large enough.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:03:44 GMT""}]","2023-05-25"
"2305.15113","Martin Uray","Simon Schindler, Martin Uray, Stefan Huber","A Mini Review on the utilization of Reinforcement Learning with OPC UA","submitted to INDIN'23",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Reinforcement Learning (RL) is a powerful machine learning paradigm that has
been applied in various fields such as robotics, natural language processing
and game playing achieving state-of-the-art results. Targeted to solve
sequential decision making problems, it is by design able to learn from
experience and therefore adapt to changing dynamic environments. These
capabilities make it a prime candidate for controlling and optimizing complex
processes in industry. The key to fully exploiting this potential is the
seamless integration of RL into existing industrial systems. The industrial
communication standard Open Platform Communications UnifiedArchitecture (OPC
UA) could bridge this gap. However, since RL and OPC UA are from different
fields,there is a need for researchers to bridge the gap between the two
technologies. This work serves to bridge this gap by providing a brief
technical overview of both technologies and carrying out a semi-exhaustive
literature review to gain insights on how RL and OPC UA are applied in
combination. With this survey, three main research topics have been identified,
following the intersection of RL with OPC UA. The results of the literature
review show that RL is a promising technology for the control and optimization
of industrial processes, but does not yet have the necessary standardized
interfaces to be deployed in real-world scenarios with reasonably low effort.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:03:48 GMT""}]","2023-05-25"
"2305.15114","Fenghe Tang","Lingtao Wang, Jianrui Ding, Fenghe Tang, Chunping Ning","Thinking Twice: Clinical-Inspired Thyroid Ultrasound Lesion Detection
  Based on Feature Feedback","20 pages, 11 figures, released code for
  https://github.com/HIT-wanglingtao/Thinking-Twice",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate detection of thyroid lesions is a critical aspect of computer-aided
diagnosis. However, most existing detection methods perform only one feature
extraction process and then fuse multi-scale features, which can be affected by
noise and blurred features in ultrasound images. In this study, we propose a
novel detection network based on a feature feedback mechanism inspired by
clinical diagnosis. The mechanism involves first roughly observing the overall
picture and then focusing on the details of interest. It comprises two parts: a
feedback feature selection module and a feature feedback pyramid. The feedback
feature selection module efficiently selects the features extracted in the
first phase in both space and channel dimensions to generate high semantic
prior knowledge, which is similar to coarse observation. The feature feedback
pyramid then uses this high semantic prior knowledge to enhance feature
extraction in the second phase and adaptively fuses the two features, similar
to fine observation. Additionally, since radiologists often focus on the shape
and size of lesions for diagnosis, we propose an adaptive detection head
strategy to aggregate multi-scale features. Our proposed method achieves an AP
of 70.3% and AP50 of 99.0% on the thyroid ultrasound dataset and meets the
real-time requirement. The code is available at
https://github.com/HIT-wanglingtao/Thinking-Twice.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:07:46 GMT""}]","2023-05-25"
"2305.15115","Yubao Tang","Yubao Tang, Ruqing Zhang, Jiafeng Guo, Jiangui Chen, Zuowei Zhu,
  Shuaiqiang Wang, Dawei Yin, Xueqi Cheng","Semantic-Enhanced Differentiable Search Index Inspired by Learning
  Strategies","Accepted by KDD 2023",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, a new paradigm called Differentiable Search Index (DSI) has been
proposed for document retrieval, wherein a sequence-to-sequence model is
learned to directly map queries to relevant document identifiers. The key idea
behind DSI is to fully parameterize traditional ``index-retrieve'' pipelines
within a single neural model, by encoding all documents in the corpus into the
model parameters. In essence, DSI needs to resolve two major questions: (1) how
to assign an identifier to each document, and (2) how to learn the associations
between a document and its identifier. In this work, we propose a
Semantic-Enhanced DSI model (SE-DSI) motivated by Learning Strategies in the
area of Cognitive Psychology. Our approach advances original DSI in two ways:
(1) For the document identifier, we take inspiration from Elaboration
Strategies in human learning. Specifically, we assign each document an
Elaborative Description based on the query generation technique, which is more
meaningful than a string of integers in the original DSI; and (2) For the
associations between a document and its identifier, we take inspiration from
Rehearsal Strategies in human learning. Specifically, we select fine-grained
semantic features from a document as Rehearsal Contents to improve document
memorization. Both the offline and online experiments show improved retrieval
performance over prevailing baselines.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:09:35 GMT""}]","2023-05-25"
"2305.15116","Dominik Th\""onnes","Dominik Th\""onnes and Ulrich R\""ude","Model-Based Performance Analysis of the HyTeG Finite Element Framework",,,"10.1145/3592979.3593422",,"cs.PF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present how code generation techniques significantly improve
the performance of the computational kernels in the HyTeG software framework.
This HPC framework combines the performance and memory advantages of
matrix-free multigrid solvers with the flexibility of unstructured meshes. The
pystencils code generation toolbox is used to replace the original abstract C++
kernels with highly optimized loop nests. The performance of one of those
kernels (the matrix-vector multiplication) is thoroughly analyzed using the
Execution-Cache-Memory (ECM) performance model. We validate these predictions
by measurements on the SuperMUC-NG supercomputer. The experiments show that the
performance mostly matches the predictions. In cases where the prediction does
not match, we discuss the discrepancies. Additionally, we conduct a node-level
scaling study which shows the expected behavior for a memory-bound compute
kernel.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:10:25 GMT""}]","2023-05-25"
"2305.15117","Christian Herglotz","Christian Herglotz and Werner Robitza and Alexander Raake and Tobias
  Hossfeld and Andr\'e Kaup","Power Reduction Opportunities on End-User Devices in Quality-Steady
  Video Streaming","4 pages, 3 figures",,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper uses a crowdsourced dataset of online video streaming sessions to
investigate opportunities to reduce the power consumption while considering
QoE. For this, we base our work on prior studies which model both the
end-user's QoE and the end-user device's power consumption with the help of
high-level video features such as the bitrate, the frame rate, and the
resolution. On top of existing research, which focused on reducing the power
consumption at the same QoE optimizing video parameters, we investigate
potential power savings by other means such as using a different playback
device, a different codec, or a predefined maximum quality level. We find that
based on the power consumption of the streaming sessions from the crowdsourcing
dataset, devices could save more than 55% of power if all participants adhere
to low-power settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:10:40 GMT""}]","2023-05-25"
"2305.15118","Federico Fusco","Marwa El Halabi, Federico Fusco, Ashkan Norouzi-Fard, Jakab Tardos,
  Jakub Tarnawski","Fairness in Streaming Submodular Maximization over a Matroid Constraint","Accepted to ICML 23",,,,"cs.LG cs.CY cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Streaming submodular maximization is a natural model for the task of
selecting a representative subset from a large-scale dataset. If datapoints
have sensitive attributes such as gender or race, it becomes important to
enforce fairness to avoid bias and discrimination. This has spurred significant
interest in developing fair machine learning algorithms. Recently, such
algorithms have been developed for monotone submodular maximization under a
cardinality constraint.
  In this paper, we study the natural generalization of this problem to a
matroid constraint. We give streaming algorithms as well as impossibility
results that provide trade-offs between efficiency, quality and fairness. We
validate our findings empirically on a range of well-known real-world
applications: exemplar-based clustering, movie recommendation, and maximum
coverage in social networks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:10:46 GMT""}]","2023-05-25"
"2305.15119","Alberto Mu\~noz-Ortiz","Alberto Mu\~noz-Ortiz and David Vilares","Another Dead End for Morphological Tags? Perturbed Inputs and Parsing","Accepted at Findings of ACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The usefulness of part-of-speech tags for parsing has been heavily questioned
due to the success of word-contextualized parsers. Yet, most studies are
limited to coarse-grained tags and high quality written content; while we know
little about their influence when it comes to models in production that face
lexical errors. We expand these setups and design an adversarial attack to
verify if the use of morphological information by parsers: (i) contributes to
error propagation or (ii) if on the other hand it can play a role to correct
mistakes that word-only neural parsers make. The results on 14 diverse UD
treebanks show that under such attacks, for transition- and graph-based models
their use contributes to degrade the performance even faster, while for the
(lower-performing) sequence labeling parsers they are helpful. We also show
that if morphological tags were utopically robust against lexical
perturbations, they would be able to correct parsing mistakes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:11:04 GMT""}]","2023-05-25"
"2305.15120","Patrick Meisner","Chantal David, Patrick Meisner","Expected Values of $L$-functions Away from the Central Point","31 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We compute the expected value of Dirichlet $L$-functions defined over
$\mathbb{F}_q[T]$ attached to cubic characters evaluated at an arbitrary $s \in
(0,1)$. We find a transition term at the point $s=\frac{1}{3}$, reminiscent of
the transition at the point $s=\frac{1}{2}$ of the bound for the size of an
$L$-function implied by the Lindel\""of hypothesis. We show that at
$s=\frac{1}{3}$, the expected value matches corresponding statistics of the
group of unitary matrices multiplied by a weight function.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:11:26 GMT""}]","2023-05-25"
"2305.15121","Hugo Thimonier","Hugo Thimonier, Fabrice Popineau, Arpad Rimmel and Bich-Li\^en Doan","Beyond Individual Input for Deep Anomaly Detection on Tabular Data",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anomaly detection is crucial in various domains, such as finance, healthcare,
and cybersecurity. In this paper, we propose a novel deep anomaly detection
method for tabular data that leverages Non-Parametric Transformers (NPTs), a
model initially proposed for supervised tasks, to capture both feature-feature
and sample-sample dependencies. In a reconstruction-based framework, we train
the NPT model to reconstruct masked features of normal samples. We use the
model's ability to reconstruct the masked features during inference to generate
an anomaly score. To the best of our knowledge, our proposed method is the
first to combine both feature-feature and sample-sample dependencies for
anomaly detection on tabular datasets. We evaluate our method on an extensive
benchmark of tabular datasets and demonstrate that our approach outperforms
existing state-of-the-art methods based on both the F1-Score and AUROC.
Moreover, our work opens up new research directions for exploring the potential
of NPTs for other tasks on tabular data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:13:26 GMT""}]","2023-05-25"
"2305.15122","Gon\c{c}alo Paulo","Gon\c{c}alo Paulo and Alberto Gubbiotti and Alberto Giacomello","An atomistically informed multiscale approach to the intrusion and
  extrusion of water in hydrophobic nanopores","This article may be downloaded for personal use only. Any other use
  requires prior permission of the author and AIP Publishing. This article
  appeared in ""Gon\c{c}alo Paulo, Alberto Gubbiotti, Alberto Giacomello; J.
  Chem. Phys. 28 May 2023; 158 (20)"" and may be found at
  https://doi.org/10.1063/5.0147647","J. Chem. Phys. 28 May 2023; 158 (20): 204707","10.1063/5.0147647",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Understanding intrusion and extrusion in nanoporous materials is a
challenging multiscale problem of utmost importance for applications ranging
from energy storage and dissipation to water desalination and hydrophobic
gating in ion channels. Including atomistic details in simulations is required
to predict the overall behavior of such systems, because the statics and
dynamics of these processes depend sensitively on microscopic features of the
pore such as the surface hydrophobicity, geometry, and charge distribution and
on the composition of the liquid. On the other hand, the transitions between
the filled (intruded) and empty (extruded) states are rare events which often
require long simulation times difficult to achieve with standard atomistic
simulations. In this work, we explored the intrusion and extrusion processes by
a multiscale approach in which the atomistic details of the system, extracted
from molecular dynamics simulations, inform a simple Langevin model of water
intrusion/extrusion in the pore. We then used the Langevin simulations to
compute the transition times at different pressures, validating our
coarse-grained model by comparing it with nonequilibrium molecular dynamics
simulations. The proposed approach reproduces experimentally relevant features
such as the time and temperature dependence of the intrusion/extrusion cycles,
as well as specific details about the shape of the cycle. This approach also
drastically increases the timescales that can be simulated allowing to reduce
the gap between simulations and experiments and showing promise for more
complex systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:14:22 GMT""}]","2023-05-25"
"2305.15123","Manas Kulkarni","Manas Kulkarni, Satya N. Majumdar","First detection probability in quantum resetting via random projective
  measurements","40 pages, 6 figures, 1 table",,,,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a general framework to compute the probability distribution
$F_r(t)$ of the first detection time of a 'state of interest' in a generic
quantum system subjected to random projective measurements. In our 'quantum
resetting' protocol, resetting of a state is not implemented by an additional
classical stochastic move, but rather by the random projective measurement. We
then apply this general framework to Poissoinian measurement protocol with a
constant rate $r$ and demonstrate that exact results for $F_r(t)$ can be
obtained for a generic two level system. Interestingly, the result depends
crucially on the detection schemes involved and we have studied two
complementary schemes, where the state of interest either coincides or differs
from the initial state. We show that $F_r(t)$ at short times vanishes
universally as $F_r(t)\sim t^2$ as $t\to 0$ in the first scheme, while it
approaches a constant as $t\to 0$ in the second scheme. The mean first
detection time, as a function of the measurement rate $r$, also shows rather
different behaviors in the two schemes. In the former, the mean detection time
is a nonmonotonic function of $r$ with a single minimum at an optimal value
$r^*$, while in the later, it is a monotonically decreasing function of $r$,
signalling the absence of a finite optimal value. These general predictions for
arbitrary two level systems are then verified via explicit computation in the
Jaynes-Cummings model of light-matter interaction. We also generalise our
results to non-Poissonian measurement protocols with a renewal structure where
the intervals between successive independent measurements are distributed via a
general distribution $p(\tau)$ and show that the short time behavior of
$F_r(t)\sim p(0)\, t^2$ is universal as long as $p(0)\ne 0$. This universal
$t^2$ law emerges from purely quantum dynamics that dominates at early times.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:15:01 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jun 2023 17:12:43 GMT""}]","2023-06-06"
"2305.15124","Anurag Dey","Anurag Dey and Probal Chaudhuri","On estimators of the mean of infinite dimensional data in finite
  populations",,,,,"math.ST stat.TH","http://creativecommons.org/publicdomain/zero/1.0/","  The Horvitz-Thompson (HT), the Rao-Hartley-Cochran (RHC) and the generalized
regression (GREG) estimators of the finite population mean are considered, when
the observations are from an infinite dimensional space. We compare these
estimators based on their asymptotic distributions under some commonly used
sampling designs and some superpopulations satisfying linear regression models.
We show that the GREG estimator is asymptotically at least as efficient as any
of the other two estimators under different sampling designs considered in this
paper. Further, we show that the use of some well known sampling designs
utilizing auxiliary information may have an adverse effect on the performance
of the GREG estimator, when the degree of heteroscedasticity present in linear
regression models is not very large. On the other hand, the use of those
sampling designs improves the performance of this estimator, when the degree of
heteroscedasticity present in linear regression models is large. We develop
methods for determining the degree of heteroscedasticity, which in turn
determines the choice of appropriate sampling design to be used with the GREG
estimator. We also investigate the consistency of the covariance operators of
the above estimators. We carry out some numerical studies using real and
synthetic data, and our theoretical results are supported by the results
obtained from those numerical studies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:15:41 GMT""}]","2023-05-25"
"2305.15125","Kazuo Murota","Kazuo Murota and Akihisa Tamura","Shapley-Folkman-type Theorem for Integrally Convex Sets","13 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Shapley-Folkman theorem is a statement about the Minkowski sum of
(non-convex) sets, expressing the closeness of the Minkowski sum to convexity
in a quantitative manner. This paper establishes similar theorems for
integrally convex sets and M-natural-convex sets, which are major classes of
discrete convex sets in discrete convex analysis.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:18:16 GMT""}]","2023-05-25"
"2305.15126","Kotaro Kohno","K. Kohno, S. Fujimoto, A. Tsujita, V. Kokorev, G. Brammer, G. E.
  Magdis, F. Valentino, N. Laporte, Fengwu Sun, E. Egami, F. E. Bauer, A.
  Guerrero, N. Nagar, K. I. Caputi, G. B. Caminha, J.-B. Jolly, K. K. Knudsen,
  R. Uematsu, Y. Ueda, M. Oguri, A. Zitrin, M. Ouchi, Y. Ono, J.
  Gonzalez-Lopez, J. Richard, I. Smail, D. Coe, M. Postman, L. Bradley, A. M.
  Koekemoer, A. M. Munoz Arancibia, M. Dessauges-Zavadsky, D. Espada, H.
  Umehata, B. Hatsukade, F. Egusa, K. Shimasaku, K. Matsui-Morokuma, W.-H.
  Wang, T. Wang, Y. Ao, A. J. Baker, Minju M. Lee, C. del P. Lagos, D. H.
  Hughes and ALCS collaboration","Unbiased surveys of dust-enshrouded galaxies using ALMA","6 pages, 4 figures, Proceedings of the 7th
  Chile-Cologne-Bonn-Symposium: Physics and Chemistry of Star Formation, V.
  Ossenkopf-Okada, R. Schaaf, I. Breloy (eds.)",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The ALMA lensing cluster survey (ALCS) is a 96-hr large program dedicated to
uncovering and characterizing intrinsically faint continuum sources and line
emitters with the assistance of gravitational lensing. All 33 cluster fields
were selected from HST/Spitzer treasury programs including CLASH, Hubble
Frontier Fields, and RELICS, which also have Herschel and Chandra coverages.
The total sky area surveyed reaches $\sim$133 arcmin$^2$ down to a depth of
$\sim$60 $\mu$Jy beam$^{-1}$ (1$\sigma$) at 1.2 mm, yielding 141 secure blind
detections of continuum sources and additional 39 sources aided by priors. We
present scientific motivation, survey design, the status of spectroscopy
follow-up observations, and number counts down to $\sim$7 $\mu$Jy. Synergies
with JWST are also discussed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:19:41 GMT""}]","2023-05-25"
"2305.15127","Lorenz Diener","Lorenz Diener, Marju Purin, Sten Sootla, Ando Saabas, Robert Aichner,
  Ross Cutler","PLCMOS -- a data-driven non-intrusive metric for the evaluation of
  packet loss concealment algorithms","to appear: INTERSPEECH 2023, associated model release:
  https://aka.ms/PLCMOS",,,,"cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Speech quality assessment is a problem for every researcher working on models
that produce or process speech. Human subjective ratings, the gold standard in
speech quality assessment, are expensive and time-consuming to acquire in a
quantity that is sufficient to get reliable data, while automated objective
metrics show a low correlation with gold standard ratings. This paper presents
PLCMOS, a non-intrusive data-driven tool for generating a robust, accurate
estimate of the mean opinion score a human rater would assign an audio file
that has been processed by being transmitted over a degraded packet-switched
network with missing packets being healed by a packet loss concealment
algorithm. Our new model shows a model-wise Pearson's correlation of ~0.97 and
rank correlation of ~0.95 with human ratings, substantially above all other
available intrusive and non-intrusive metrics. The model is released as an ONNX
model for other researchers to use when building PLC systems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:21:22 GMT""}]","2023-05-25"
"2305.15128","He (Henry) Chen","Qian Wang and He (Henry) Chen","Age of Information in Reservation Multi-Access Networks with Stochastic
  Arrivals: Analysis and Optimization","This work has been submitted for possible publication. arXiv admin
  note: substantial text overlap with arXiv:2206.00874",,,,"cs.IT cs.NI math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper analyzes and optimizes the average Age of Information (AAoI) of
Frame Slotted ALOHA with Reservation and Data slots (FSA-RD) in a multi-access
network, where multiple users transmit their randomly generated status updates
to a common access point in a framed manner. Each frame consists of one
reservation slot and several data slots. The reservation slot is further split
into several mini-slots. In each reservation slot, users that want to transmit
a status update will randomly send short reservation packets in one of the
mini-slots to contend for data slots of the current frame. The reservation is
successful only if one reservation packet is sent in a mini-slot. The data
slots are then allocated to those users that succeed in the reservation slot.
In the considered FSA-RD scheme, one user with a status update for
transmission, termed active user, may need to perform multiple reservation
attempts before successfully delivering it. As such, the number of active
user(s) in different frames are dependent and thus the probability of making a
successful reservation varies from frame to frame, making the AAoI analysis
non-trivial. We manage to derive an analytical expression of AAoI for FSA-RD by
characterizing the evolution of the number of active user(s) in each frame as a
discrete-time Markov chain. We then consider the FSA-RD scheme with one
reservation attempt per status update, termed FSA-RD-One. Thanks to the
independent frame behaviors of FSA-RD-One, we attain a closed-form expression
for its AAoI, which is further used to find the near-optimal reservation
probability. Our analysis reveals the impact of key protocol parameters, such
as frame size and reservation probability, on the AAoI. Simulation results
validate our analysis and show that the optimized FSA-RD outperforms the
optimized slotted ALOHA.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:22:45 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 07:04:03 GMT""},{""version"":""v3"",""created"":""Sun, 28 May 2023 02:45:33 GMT""}]","2023-05-30"
"2305.15129","Yong Pang Dr","Yong Pang, Tao Liu","Quasi-static responses of marine mussel plaques attached to deformable
  wet substrates under directional tensions","19 pages",,,,"physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Quantifying the response of marine mussel plaque attachment on wet surfaces
remains a significant challenge to a mechanistic understanding of plaque
adhesion. Here, we developed a customised microscopy system combined with
two-dimensional (2D) in-situ digital image correlation (DIC) to quantify the
in-plane deformation of a deformable substrate that interacts with a mussel
plaque while under directional tension. By analysing the strain field in the
substrate, we gained insight into how in-plane traction forces are transmitted
from the mussel plaque to the underlying substrate. Finite element (FE) models
were developed to assist the interpretation of the experimental measurement.
Our study revealed a synergistic effect of pulling angle and substrate
stiffness on plaque detachment, with mussel plaques anchoring to a 'stiff'
substrate at a smaller pulling angle having mechanical advantages with higher
load-bearing capacity and less plaque deformation. We identified two distinct
failure modes, i.e., shear traction-governed failure (STGF) mode and normal
traction-governed failure (NTGF). It was found that increasing the substrate
stiffness or reducing the pulling angle resulted in a failure mode change from
NTGF to STGF. Our findings offer new insights into the mechanistic
understanding of plaque and substrate interaction, which provides a general
plaque-inspired strategy for wet adhesion.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:22:59 GMT""}]","2023-05-25"
"2305.15130","Saku Sugawara","Saku Sugawara, Shun Tsugita","On Degrees of Freedom in Defining and Testing Natural Language
  Understanding","Accepted to Findings of ACL 2023",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Natural language understanding (NLU) studies often exaggerate or
underestimate the capabilities of systems, thereby limiting the reproducibility
of their findings. These erroneous evaluations can be attributed to the
difficulty of defining and testing NLU adequately. In this position paper, we
reconsider this challenge by identifying two types of researcher degrees of
freedom. We revisit Turing's original interpretation of the Turing test and
indicate that an NLU test does not provide an operational definition; it merely
provides inductive evidence that the test subject understands the language
sufficiently well to meet stakeholder objectives. In other words, stakeholders
are free to arbitrarily define NLU through their objectives. To use the test
results as inductive evidence, stakeholders must carefully assess if the
interpretation of test scores is valid or not. However, designing and using NLU
tests involve other degrees of freedom, such as specifying target skills and
defining evaluation metrics. As a result, achieving consensus among
stakeholders becomes difficult. To resolve this issue, we propose a validity
argument, which is a framework comprising a series of validation criteria
across test components. By demonstrating that current practices in NLU studies
can be associated with those criteria and organizing them into a comprehensive
checklist, we prove that the validity argument can serve as a coherent
guideline for designing credible test sets and facilitating scientific
communication.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:25:20 GMT""}]","2023-05-25"
"2305.15131","Praveen Chandra Srivastava Dr.","Sakshi Shukla, Praveen C. Srivastava, Larry Zamick","Systematic shell-model study for structure and isomeric states in
  $^{200-210}$Po isotopes","20 pages, 11 figures",,,,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  We report systematic large-scale shell-model calculation for Po isotopes with
$A=$ 200 to 210. We have performed calculations using KHH7B interaction in the
model space $Z$ = 58-114 and $N$ = 100-164 around doubly-magic $^{208}$Pb. We
allow valence neutrons to occupy in the $1f_{5/2}$, $2p_{3/2}$, $2p_{1/2}$, and
$0i_{13/2}$ orbitals, while two valence protons beyond $Z=82$ are occupied in
$0h_{9/2}$, $1f_{7/2}$ and $0i_{13/2}$ orbitals. The calculated energies and
electromagnetic properties are compared with the available experimental data
and predicted where experimental data are not available. We have also reported
shell-model results for different isomeric states of these nuclei.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:26:19 GMT""}]","2023-05-25"
"2305.15132","Takatora Suzuki","Takatora Suzuki, Han Guo, Momoko Hayamizu","Rooted Almost-binary Phylogenetic Networks for which the Maximum
  Covering Subtree Problem is Solvable in Linear Time","16 pages, 12 figures",,,,"math.CO cs.DM q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phylogenetic networks are a flexible model of evolution that can represent
reticulate evolution and handle complex data. Tree-based networks, which are
phylogenetic networks that have a spanning tree with the same root and leaf-set
as the network itself, have been well studied. However, not all networks are
tree-based. Francis-Semple-Steel (2018) thus introduced several indices to
measure the deviation of rooted binary phylogenetic networks $N$ from being
tree-based, such as the minimum number $\delta^\ast(N)$ of additional leaves
needed to make $N$ tree-based, and the minimum difference $\eta^\ast(N)$
between the number of vertices of $N$ and the number of vertices of a subtree
of $N$ that shares the root and leaf set with $N$. Hayamizu (2021) has
established a canonical decomposition of almost-binary phylogenetic networks of
$N$, called the maximal zig-zag trail decomposition, which has many
implications including a linear time algorithm for computing $\delta^\ast(N)$.
The Maximum Covering Subtree Problem (MCSP) is the problem of computing
$\eta^\ast(N)$, and Davidov et al. (2022) showed that this can be solved in
polynomial time (in cubic time when $N$ is binary) by an algorithm for the
minimum cost flow problem. In this paper, under the assumption that $N$ is
almost-binary (i.e. each internal vertex has in-degree and out-degree at most
two), we show that $\delta^\ast(N)\leq \eta^\ast (N)$ holds, which is tight,
and give a characterisation of such phylogenetic networks $N$ that satisfy
$\delta^\ast(N)=\eta^\ast(N)$. Our approach uses the canonical decomposition of
$N$ and focuses on how the maximal W-fences (i.e. the forbidden subgraphs of
tree-based networks) are connected to maximal M-fences in the network $N$. Our
results introduce a new class of phylogenetic networks for which MCSP can be
solved in linear time, which can be seen as a generalisation of tree-based
networks.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:26:41 GMT""}]","2023-05-25"
"2305.15133","Katie Ansaldi","Katie Ansaldi, Gabriel Cowley, Eric Green, Kihyun Kim, JT Rapp","Rainbow Free Colorings and Rainbow Numbers for $x-y=z^2$",,,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An exact r-coloring of a set $S$ is a surjective function $c:S \rightarrow
\{1, 2, \ldots,r\}$. A rainbow solution to an equation over $S$ is a solution
such that all components are a different color. We prove that every 3-coloring
of $\mathbb{N}$ with an upper density greater than $(4^s-1)/(3 \cdot 4^s)$
contains a rainbow solution to $x-y=z^k$. The rainbow number for an equation in
the set $S$ is the smallest integer $r$ such that every exact $r$-coloring has
a rainbow solution. We compute the rainbow numbers of $\mathbb{Z}_p$ for the
equation $x-y=z^k$, where $p$ is prime and $k\geq 2$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:26:42 GMT""}]","2023-05-25"
"2305.15134","Jinjin Gu","Jinjin Gu, Xianzheng Ma, Xiangtao Kong, Yu Qiao, Chao Dong","Networks are Slacking Off: Understanding Generalization Problem in Image
  Deraining",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep deraining networks, while successful in laboratory benchmarks,
consistently encounter substantial generalization issues when deployed in
real-world applications. A prevailing perspective in deep learning encourages
the use of highly complex training data, with the expectation that a richer
image content knowledge will facilitate overcoming the generalization problem.
However, through comprehensive and systematic experimentation, we discovered
that this strategy does not enhance the generalization capability of these
networks. On the contrary, it exacerbates the tendency of networks to overfit
to specific degradations. Our experiments reveal that better generalization in
a deraining network can be achieved by simplifying the complexity of the
training data. This is due to the networks are slacking off during training,
that is, learning the least complex elements in the image content and
degradation to minimize training loss. When the complexity of the background
image is less than that of the rain streaks, the network will prioritize the
reconstruction of the background, thereby avoiding overfitting to the rain
patterns and resulting in improved generalization performance. Our research not
only offers a valuable perspective and methodology for better understanding the
generalization problem in low-level vision tasks, but also displays promising
practical potential.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:27:11 GMT""}]","2023-05-25"
"2305.15135","David Salomoni","D. Salomoni, Y. Peng, L. Farcis, S. Auffret, M. Hehn, G. Malinowski,
  S. Mangin, B. Dieny, L. D. Buda-Prejbeanu, R.C. Sousa, I. L. Prejbeanu","Field-free all-optical switching and electrical read-out of Tb/Co-based
  magnetic tunnel junctions",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Switching of magnetic tunnel junction using femto-second laser enables a
possible path for THz frequency memory operation, which means writing speeds 2
orders of magnitude faster than alternative electrical approaches based on spin
transfer or spin orbit torque. In this work we demonstrate successful
field-free 50fs single laser pulse driven magnetization reversal of [Tb/Co]
based storage layer in a perpendicular magnetic tunnel junction. The
nanofabricated magnetic tunnel junction devices have an optimized bottom
reference electrode and show Tunnel Magnetoresistance Ratio values (TMR) up to
74\% after patterning down to sub-100nm lateral dimensions. Experiments on
continuous films reveal peculiar reversal patterns of concentric rings with
opposite magnetic directions, above certain threshold fluence. These rings have
been correlated to patterned device switching probability as a function of the
applied laser fluence. Moreover, the magnetization reversal is independent on
the duration of the laser pulse. According to our macrospin model, the
underlying magnetization reversal mechanism can be attributed to an in-plane
reorientation of the magnetization due to a fast reduction of the out-of-plane
uniaxial anisotropy. These aspects are of great interest both for the physical
understanding of the switching phenomenon and their consequences for
all-optical-switching memory devices, since they allow for a large fluence
operation window with high resilience to pulse length variability.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:29:18 GMT""}]","2023-05-25"
"2305.15136","Xiao Li","Huikang Liu, Xiao Li, Anthony Man-Cho So","ReSync: Riemannian Subgradient-based Robust Rotation Synchronization","24 pages, 3 figures",,,,"math.OC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents ReSync, a Riemannian subgradient-based algorithm for
solving the robust rotation synchronization problem, which arises in various
engineering applications. ReSync solves a least-unsquared minimization
formulation over the rotation group, which is nonsmooth and nonconvex, and aims
at recovering the underlying rotations directly. We provide strong theoretical
guarantees for ReSync under the random corruption setting. Specifically, we
first show that the initialization procedure of ReSync yields a proper initial
point that lies in a local region around the ground-truth rotations. We next
establish the weak sharpness property of the aforementioned formulation and
then utilize this property to derive the local linear convergence of ReSync to
the ground-truth rotations. By combining these guarantees, we conclude that
ReSync converges linearly to the ground-truth rotations under appropriate
conditions. Experiment results demonstrate the effectiveness of ReSync.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:31:11 GMT""}]","2023-05-25"
"2305.15137","Matteo Rinaldi Dr.","Matteo Rinaldi, Matous Mrovec, Anton Bochkarev, Yury Lysogorskiy, and
  Ralf Drautz","Non-collinear Magnetic Atomic Cluster Expansion for Iron","19 pages, 20 figures, 2 tables",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Atomic Cluster Expansion (ACE) provides a formally complete basis for the
local atomic environment. ACE is not limited to representing energies as a
function of atomic positions and chemical species, but can be generalized to
vectorial or tensorial properties and to incorporate further degrees of freedom
(DOF). This is crucial for magnetic materials with potential energy surfaces
that depend on atomic positions and atomic magnetic moments simultaneously. In
this work, we employ the ACE formalism to develop a non-collinear magnetic ACE
parametrization for the prototypical magnetic element Fe. The model is trained
on a broad range of collinear and non-collinear magnetic structures calculated
using spin density functional theory. We demonstrate that the non-collinear
magnetic ACE is able to reproduce not only ground state properties of various
magnetic phases of Fe but also the magnetic and lattice excitations that are
essential for a correct description of the finite temperature behavior and
properties of crystal defects.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:31:23 GMT""}]","2023-05-25"
"2305.15138","Chunpu Xu","Chunpu Xu, Jing Li, Piji Li, Min Yang","Topic-Guided Self-Introduction Generation for Social Media Users",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Millions of users are active on social media. To allow users to better
showcase themselves and network with others, we explore the auto-generation of
social media self-introduction, a short sentence outlining a user's personal
interests. While most prior work profiles users with tags (e.g., ages), we
investigate sentence-level self-introductions to provide a more natural and
engaging way for users to know each other. Here we exploit a user's tweeting
history to generate their self-introduction. The task is non-trivial because
the history content may be lengthy, noisy, and exhibit various personal
interests. To address this challenge, we propose a novel unified topic-guided
encoder-decoder (UTGED) framework; it models latent topics to reflect salient
user interest, whose topic mixture then guides encoding a user's history and
topic words control decoding their self-introduction. For experiments, we
collect a large-scale Twitter dataset, and extensive results show the
superiority of our UTGED to the advanced encoder-decoder models without topic
modeling.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:35:08 GMT""}]","2023-05-25"
"2305.15139","Nicolas Blanco","Nicolas Blanco","Bifibrations of polycategories and classical multiplicative linear logic","250 pages, 15 figures, PhD thesis in the Theory Group at the Computer
  Science School of the University of Birmingham under the supervision of Noam
  Zeilberger and Paul Levy",,,,"math.CT cs.LO","http://creativecommons.org/licenses/by/4.0/","  In this thesis, we develop the theory of bifibrations of polycategories.
  We start by studying how to express certain categorical structures as
universal properties by generalising the shape of morphism. We call this
phenomenon representability and look at different variations, namely the
correspondence between representable multicategories and monoidal categories,
birepresentable polycategories and $\ast$-autonomous categories, and
representable virtual double categories and double categories.
  We then move to introduce (bi)fibrations for these structures. We show that
it generalises representability in the sense that these structures are
(bi)representable when they are (bi)fibred over the terminal one. We show how
to use this theory to lift models of logic to more refined ones. In particular,
we illustrate it by lifting the compact closed structure of the category of
finite dimensional vector spaces and linear maps to the (non-compact)
$\ast$-autonomous structure of the category of finite dimensional Banach spaces
and contractive maps by passing to their respective polycategories. We also
give an operational reading of this example, where polylinear maps correspond
to operations between systems that can act on their inputs and whose outputs
can be measured/probed and where norms correspond to properties of the systems
that are preserved by the operations.
  Finally, we recall the B\'enabou-Grothendieck correspondence linking
fibrations to indexed categories. We show how the B-G construction can be
defined as a pullback of virtual double categories and we make use of
fibrational properties of vdcs to get properties of this pullback. Then we
provide a polycategorical version of the B-G correspondence.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:35:51 GMT""}]","2023-05-25"
"2305.15140","Hanlin Ren","Lijie Chen, Zhenjian Lu, Igor C. Oliveira, Hanlin Ren, and Rahul
  Santhanam","Polynomial-Time Pseudodeterministic Construction of Primes",,,,,"cs.CC cs.DM cs.DS","http://creativecommons.org/licenses/by-sa/4.0/","  A randomized algorithm for a search problem is *pseudodeterministic* if it
produces a fixed canonical solution to the search problem with high
probability. In their seminal work on the topic, Gat and Goldwasser posed as
their main open problem whether prime numbers can be pseudodeterministically
constructed in polynomial time.
  We provide a positive solution to this question in the infinitely-often
regime. In more detail, we give an *unconditional* polynomial-time randomized
algorithm $B$ such that, for infinitely many values of $n$, $B(1^n)$ outputs a
canonical $n$-bit prime $p_n$ with high probability. More generally, we prove
that for every dense property $Q$ of strings that can be decided in polynomial
time, there is an infinitely-often pseudodeterministic polynomial-time
construction of strings satisfying $Q$. This improves upon a
subexponential-time construction of Oliveira and Santhanam.
  Our construction uses several new ideas, including a novel bootstrapping
technique for pseudodeterministic constructions, and a quantitative
optimization of the uniform hardness-randomness framework of Chen and Tell,
using a variant of the Shaltiel--Umans generator.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:35:57 GMT""}]","2023-05-25"
"2305.15141","Guy Kornowski","Guy Kornowski, Gilad Yehudai, Ohad Shamir","From Tempered to Benign Overfitting in ReLU Neural Networks","43 pages",,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Overparameterized neural networks (NNs) are observed to generalize well even
when trained to perfectly fit noisy data. This phenomenon motivated a large
body of work on ""benign overfitting"", where interpolating predictors achieve
near-optimal performance. Recently, it was conjectured and empirically observed
that the behavior of NNs is often better described as ""tempered overfitting"",
where the performance is non-optimal yet also non-trivial, and degrades as a
function of the noise level. However, a theoretical justification of this claim
for non-linear NNs has been lacking so far. In this work, we provide several
results that aim at bridging these complementing views. We study a simple
classification setting with 2-layer ReLU NNs, and prove that under various
assumptions, the type of overfitting transitions from tempered in the extreme
case of one-dimensional data, to benign in high dimensions. Thus, we show that
the input dimension has a crucial role on the type of overfitting in this
setting, which we also validate empirically for intermediate dimensions.
Overall, our results shed light on the intricate connections between the
dimension, sample size, architecture and training algorithm on the one hand,
and the type of resulting overfitting on the other hand.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:36:06 GMT""}]","2023-05-25"
"2305.15142","Clemens Thielen","Cristina Bazgan, Arne Herzel, Stefan Ruzika, Clemens Thielen, Daniel
  Vanderpooten","Approximating Multiobjective Optimization Problems: How exact can you
  be?",,,,,"math.OC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that, under very weak assumptions, multiobjective
optimization problems admit $(1+\varepsilon,\dots,1+\varepsilon)$-approximation
sets (also called $\varepsilon$-Pareto sets) of polynomial cardinality (in the
size of the instance and in $\frac{1}{\varepsilon}$). While an approximation
guarantee of $1+\varepsilon$ for any $\varepsilon>0$ is the best one can expect
for singleobjective problems (apart from solving the problem to optimality),
even better approximation guarantees than $(1+\varepsilon,\dots,1+\varepsilon)$
can be considered in the multiobjective case since the approximation might be
exact in some of the objectives.
  Hence, in this paper, we consider partially exact approximation sets that
require to approximate each feasible solution exactly, i.e., with an
approximation guarantee of $1$, in some of the objectives while still obtaining
a guarantee of $1+\varepsilon$ in all others. We characterize the types of
polynomial-cardinality, partially exact approximation sets that are guaranteed
to exist for general multiobjective optimization problems. Moreover, we study
minimum-cardinality partially exact approximation sets concerning (weak)
efficiency of the contained solutions and relate their cardinalities to the
minimum cardinality of a $(1+\varepsilon,\dots,1+\varepsilon)$-approximation
set.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:37:00 GMT""}]","2023-05-25"
"2305.15143","Almudena Alonso-Herrero","A. Alonso-Herrero, S. Garcia-Burillo, M. Pereira-Santaella, T.
  Shimizu, F. Combes, E. K. S. Hicks, R. Davies, C. Ramos Almeida, I.
  Garcia-Bernete, S. F. Hoenig, N. A. Levenson, C. Packham, E. Bellocchi, L. K.
  Hunt, M. Imanishi, C. Ricci, P. Roche","AGN feedback in action in the molecular gas ring of the Seyfert galaxy
  NGC7172","Accepted for publication to A&A",,,,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present new ALMA observations of the CO(3-2) transition and 854micron
continuum at 0.06-0.3"" resolution, together with new VLT/SINFONI observations
of NGC7172. This is a luminous (bolometric luminosity of ~10^44 erg/s) Seyfert
galaxy that belongs to the Galaxy Activity, Torus, and Outflow Survey (GATOS).
The CO(3-2) observations reveal the presence of a highly inclined cold
molecular gas ring with an approximate radius of 3-4""~540-720 pc, which is
likely associated with an inner Lindblad resonance of a putative stellar bar.
There are noncircular motions in the VLT/SINFONI [SiVI]1.96micron and H2 at
2.12micron, and ALMA CO(3-2) velocity fields. After subtracting the stellar
velocity field, we detected [SiVI] blueshifted velocities of a few hundred km/s
to the south of the AGN. They trace outflowing ionized gas outside the plane of
the galaxy and out to projected distances of ~200 pc. The CO(3-2)
position-velocity diagram along the kinematic minor axis displays noncircular
motions with observed velocities of up to ~150 km/s. Assuming that these are
taking place in the disk of the galaxy, the observed velocity signs imply that
the molecular gas ring is not only rotating but also outflowing. We derived an
integrated cold molecular gas mass outflow rate of ~40 Msun/yr for the ring.
Using the 854micron map, we resolved a 32 pc radius torus with a gas mass of
8x10^5 Msun. These torus properties are similar to other Seyfert galaxies in
the GATOS sample. We measured a decreased cold molecular gas concentration in
the nuclear-torus region relative to the circumnuclear region when compared to
other less luminous Seyfert galaxies. We conclude that the effects of AGN
feedback in NGC7172, which are likely caused by the AGN wind and/or the
moderate luminosity radio jet, are seen as a large-scale outflowing molecular
gas ring and accompanying redistribution of molecular gas in the nuclear
regions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:37:03 GMT""}]","2023-05-25"
"2305.15144","Akihiro Ozawa","Akihiro Ozawa, Koji Kobayashi, and Kentaro Nomura","Effective model analysis of intrinsic spin Hall effect with magnetism in
  stacked-kagome Weyl semimetal Co3Sn2S2","8 pages, 5 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  We theoretically study the spin Hall effect in a simple tight-binding model
of stacked-kagome Weyl semimetal Co3Sn2S2 with ferromagnetic ordering. We focus
on the two types of the spin Hall current: one flowing in the in-plane
direction with respect to the kagome lattice (in-plane spin Hall current), and
one flowing in the stacking direction (out-of-plane spin Hall current). We show
the spin Hall conductivities for those spin currents drastically change
depending on the direction of the magnetic moment. Especially, the out-of-plane
spin Hall current may induce surface spin accumulation, which are useful for
the perpendicular magnetization switching via spin-orbit torque.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:37:04 GMT""}]","2023-05-25"
"2305.15145","Zheng Hu","Zheng Hu, Fuji Ren","Bert4CMR: Cross-Market Recommendation with Bidirectional Encoder
  Representations from Transformer",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-world multinational e-commerce companies, such as Amazon and eBay, serve
in multiple countries and regions. Obviously, these markets have similar goods
but different users. Some markets are data-scarce, while others are data-rich.
In recent years, cross-market recommendation (CMR) has been proposed to enhance
data-scarce markets by leveraging auxiliary information from data-rich markets.
Previous works fine-tune the pre-trained model on the local market after
freezing part of the parameters or introducing inter-market similarity into the
local market to improve the performance of CMR. However, they generally do not
consider eliminating the mutual interference between markets. Therefore, the
existing methods are neither unable to learn unbiased general knowledge nor
efficient transfer reusable information across markets. In this paper, we
propose a novel attention-based model called Bert4CMR to simultaneously improve
all markets' recommendation performance. Specifically, we employ the attention
mechanism to capture user interests by modelling user behavioural sequences. We
pre-train the proposed model on global data to learn the general knowledge of
items. Then we fine-tune specific target markets to perform local
recommendations. We propose market embedding to model the bias of each market
and reduce the mutual inference between the parallel markets. Extensive
experiments conducted on seven markets show that our model is state-of-the-art.
Our model outperforms the suboptimal model by 4.82%, 4.73%, 7.66% and 6.49% on
average of seven datasets in terms of four metrics, respectively. We conduct
ablation experiments to analyse the effectiveness of the proposed components.
Experimental results indicate that our model is able to learn general knowledge
through global data and shield the mutual interference between markets.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:39:14 GMT""}]","2023-05-25"
"2305.15146","Clement Calvino","Cl\'ement Calvino, Lucille Furgerot, Emmanuel Poizot, Pascal Bailly du
  Bois, Anne-Claire Bennis","Model and method to predict the turbulent kinetic energy induced by
  tidal currents, application to the wave-induced turbulence",,,,,"physics.flu-dyn physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A prediction model for the turbulent kinetic energy (TKE) induced by
tidal-currents is proposed as a function of the barotropic velocity only, along
with a robust method evaluating the different parameters involved using
Acoustic Doppler Current Profiler (ADCP) measurements from Alderney Race. We
find that the model is able to reproduce correctly the TKE profiles with
coefficients of correlation on average higher than 0.90 and normalised
root-mean-square errors (NRMSE) less than 14%. Different profiles are also
tested for the mean velocity, no satisfactory prediction model is found but we
are able to have decent estimates of the velocity shear and friction velocity.
Two applications are then carried out. First the turbulent budget terms are
estimated and discussed. We identify the turbulent production and dissipation
of TKE as the most important mechanisms, then we discuss the validity of
several theoretical results derived for isotropic turbulence for this
application. A strong departure for the estimation of the turbulent dissipation
is notably found and explained by the turbulent anisotropy. At last the
prediction model for the TKE is used to infer the wave-induced TKE. We show the
importance of removing the tidal component, waves can have a strong influence
down to mid-depth.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:41:05 GMT""}]","2023-05-25"
"2305.15147","Veit Krause","Elena Bachini, Veit Krause, Ingo Nitschke and Axel Voigt","Derivation and simulation of a two-phase fluid deformable surface model",,,,,"math.NA cs.NA math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider two-phase fluid deformable surfaces as model systems for
biomembranes. Such surfaces are modeled by incompressible surface
Navier-Stokes-Cahn-Hilliard-like equations with bending forces. We derive this
model using the Lagrange-D'Alembert principle considering various dissipation
mechanisms. The highly nonlinear model is solved numerically to explore the
tight interplay between surface evolution, surface phase composition, surface
curvature and surface hydrodynamics. It is demonstrated that hydrodynamics can
enhance bulging and furrow formation, which both can further develop to
pinch-offs. The numerical approach builds on a Taylor-Hood element for the
surface Navier-Stokes part, a semi-implicit approach for the Cahn-Hilliard
part, higher order surface parametrizations, appropriate approximations of the
geometric quantities, and mesh redistribution. We demonstrate convergence
properties that are known to be optimal for simplified sub-problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:42:54 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 14:04:51 GMT""}]","2023-05-26"
"2305.15148","Xiaojin Zhang","Xiaojin Zhang, Wenjie Li, Kai Chen, Shutao Xia, Qiang Yang","Theoretically Principled Federated Learning for Balancing Privacy and
  Utility",,,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a general learning framework for the protection mechanisms that
protects privacy via distorting model parameters, which facilitates the
trade-off between privacy and utility. The algorithm is applicable to arbitrary
privacy measurements that maps from the distortion to a real value. It can
achieve personalized utility-privacy trade-off for each model parameter, on
each client, at each communication round in federated learning. Such adaptive
and fine-grained protection can improve the effectiveness of privacy-preserved
federated learning.
  Theoretically, we show that gap between the utility loss of the protection
hyperparameter output by our algorithm and that of the optimal protection
hyperparameter is sub-linear in the total number of iterations. The
sublinearity of our algorithm indicates that the average gap between the
performance of our algorithm and that of the optimal performance goes to zero
when the number of iterations goes to infinity. Further, we provide the
convergence rate of our proposed algorithm. We conduct empirical results on
benchmark datasets to verify that our method achieves better utility than the
baseline methods under the same privacy budget.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:44:02 GMT""},{""version"":""v2"",""created"":""Sat, 3 Jun 2023 12:35:57 GMT""}]","2023-06-06"
"2305.15149","Jana Kierdorf","Jana Kierdorf and Ribana Roscher","Reliability Scores from Saliency Map Clusters for Improved Image-based
  Harvest-Readiness Prediction in Cauliflower","Preprint, 8 pages, 6 figures",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Cauliflower is a hand-harvested crop that must fulfill high-quality standards
in sales making the timing of harvest important. However, accurately
determining harvest-readiness can be challenging due to the cauliflower head
being covered by its canopy. While deep learning enables automated
harvest-readiness estimation, errors can occur due to field-variability and
limited training data. In this paper, we analyze the reliability of a
harvest-readiness classifier with interpretable machine learning. By
identifying clusters of saliency maps, we derive reliability scores for each
classification result using knowledge about the domain and the image
properties. For unseen data, the reliability can be used to (i) inform farmers
to improve their decision-making and (ii) increase the model prediction
accuracy. Using RGB images of single cauliflower plants at different
developmental stages from the GrowliFlower dataset, we investigate various
saliency mapping approaches and find that they result in different quality of
reliability scores. With the most suitable interpretation tool, we adjust the
classification result and achieve a 15.72% improvement of the overall accuracy
to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for
the GrowliFlower dataset.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:48:36 GMT""}]","2023-05-25"
"2305.15150","Alejandro Naser Pastoriza","Alejandro Naser Pastoriza, Gregory Chockler, Alexey Gotsman","Fault-tolerant computing with unreliable channels",,,,,"cs.DC","http://creativecommons.org/licenses/by/4.0/","  We study implementations of basic fault-tolerant primitives, such as
consensus and registers, in message-passing systems subject to process crashes
and a broad range of communication failures. Our results characterize the
necessary and sufficient conditions for implementing these primitives as a
function of the connectivity constraints and synchrony assumptions. Our main
contribution is a new algorithm for partially synchronous consensus that is
resilient to process crashes and channel failures and is optimal in its
connectivity requirements. In contrast to prior work, our algorithm assumes the
most general model of message loss where faulty channels are flaky, i.e., can
lose messages without any guarantee of fairness. This failure model is
particularly challenging for consensus algorithms, as it rules out standard
solutions based on leader oracles and failure detectors. To circumvent this
limitation, we construct our solution using a new variant of the recently
proposed view synchronizer abstraction, which we adapt to the crash-prone
setting with flaky channels.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:49:05 GMT""}]","2023-05-25"
"2305.15152","Yi-Zhi Huang","Yi-Zhi Huang","Modular invariance of (logarithmic) intertwining operators","81 pages",,,,"math.QA hep-th math.RA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $V$ be a $C_2$-cofinite vertex operator algebra without nonzero elements
of negative weights. We prove the conjecture that the spaces spanned by
analytic extensions of pseudo-$q$-traces ($q=e^{2\pi i\tau}$) shifted by
$-\frac{c}{24}$ of products of geometrically-modified (logarithmic)
intertwining operators among grading-restricted generalized $V$-modules are
invariant under modular transformations. The convergence and analytic extension
result needed to formulate this conjecture and some consequences on such
shifted pseudo-$q$-traces were proved by Fiordalisi [F1} and [F2] using the
method developed by the author in [H2]. The method that we use to prove this
conjecture is based on the theory of the associative algebras $A^{N}(V)$ for
$N\in \mathbb{N}$, their graded modules and their bimodules introduced and
studied by the author in [H8] and [H9]. This modular invariance result gives a
construction of $C_2$-cofinite genus-one logarithmic conformal field theories
from the corresponding genus-zero logarithmic conformal field theories.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:51:29 GMT""}]","2023-05-25"
"2305.15154","Kiran Kokilepersaud","Kiran Kokilepersaud, Stephanie Trejo Corona, Mohit Prabhushankar,
  Ghassan AlRegib, Charles Wykoff","Clinically Labeled Contrastive Learning for OCT Biomarker Classification","Accepted in IEEE Journal of Biomedical and Health Informatics. arXiv
  admin note: text overlap with arXiv:2211.05092",,"10.1109/JBHI.2023.3277789",,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  This paper presents a novel positive and negative set selection strategy for
contrastive learning of medical images based on labels that can be extracted
from clinical data. In the medical field, there exists a variety of labels for
data that serve different purposes at different stages of a diagnostic and
treatment process. Clinical labels and biomarker labels are two examples. In
general, clinical labels are easier to obtain in larger quantities because they
are regularly collected during routine clinical care, while biomarker labels
require expert analysis and interpretation to obtain. Within the field of
ophthalmology, previous work has shown that clinical values exhibit
correlations with biomarker structures that manifest within optical coherence
tomography (OCT) scans. We exploit this relationship by using the clinical data
as pseudo-labels for our data without biomarker labels in order to choose
positive and negative instances for training a backbone network with a
supervised contrastive loss. In this way, a backbone network learns a
representation space that aligns with the clinical data distribution available.
Afterwards, we fine-tune the network trained in this manner with the smaller
amount of biomarker labeled data with a cross-entropy loss in order to classify
these key indicators of disease directly from OCT scans. We also expand on this
concept by proposing a method that uses a linear combination of clinical
contrastive losses. We benchmark our methods against state of the art
self-supervised methods in a novel setting with biomarkers of varying
granularity. We show performance improvements by as much as 5\% in total
biomarker detection AUROC.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:51:48 GMT""}]","2023-05-25"
"2305.15155","Ilyas Fatkhullin","Ilyas Fatkhullin, Alexander Tyurin, Peter Richt\'arik","Momentum Provably Improves Error Feedback!",,,,,"cs.LG cs.DC math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the high communication overhead when training machine learning models
in a distributed environment, modern algorithms invariably rely on lossy
communication compression. However, when untreated, the errors caused by
compression propagate, and can lead to severely unstable behavior, including
exponential divergence. Almost a decade ago, Seide et al [2014] proposed an
error feedback (EF) mechanism, which we refer to as EF14, as an immensely
effective heuristic for mitigating this issue. However, despite steady
algorithmic and theoretical advances in the EF field in the last decade, our
understanding is far from complete. In this work we address one of the most
pressing issues. In particular, in the canonical nonconvex setting, all known
variants of EF rely on very large batch sizes to converge, which can be
prohibitive in practice. We propose a surprisingly simple fix which removes
this issue both theoretically, and in practice: the application of Polyak's
momentum to the latest incarnation of EF due to Richt\'{a}rik et al. [2021]
known as EF21. Our algorithm, for which we coin the name EF21-SGDM, improves
the communication and sample complexities of previous error feedback algorithms
under standard smoothness and bounded variance assumptions, and does not
require any further strong assumptions such as bounded gradient dissimilarity.
Moreover, we propose a double momentum version of our method that improves the
complexities even further. Our proof seems to be novel even when compression is
removed from the method, and as such, our proof technique is of independent
interest in the study of nonconvex stochastic optimization enriched with
Polyak's momentum.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:52:02 GMT""}]","2023-05-25"
"2305.15157","Li Shen","Yifan Shi, Yingqi Liu, Yan Sun, Zihao Lin, Li Shen, Xueqian Wang,
  Dacheng Tao","Towards More Suitable Personalization in Federated Learning via
  Decentralized Partial Model Training","26 pages",,,,"cs.LG cs.DC math.OC","http://creativecommons.org/licenses/by/4.0/","  Personalized federated learning (PFL) aims to produce the greatest
personalized model for each client to face an insurmountable problem--data
heterogeneity in real FL systems. However, almost all existing works have to
face large communication burdens and the risk of disruption if the central
server fails. Only limited efforts have been used in a decentralized way but
still suffers from inferior representation ability due to sharing the full
model with its neighbors. Therefore, in this paper, we propose a personalized
FL framework with a decentralized partial model training called DFedAlt. It
personalizes the ""right"" components in the modern deep models by alternately
updating the shared and personal parameters to train partially personalized
models in a peer-to-peer manner. To further promote the shared parameters
aggregation process, we propose DFedSalt integrating the local Sharpness Aware
Minimization (SAM) optimizer to update the shared parameters. It adds proper
perturbation in the direction of the gradient to overcome the shared model
inconsistency across clients. Theoretically, we provide convergence analysis of
both algorithms in the general non-convex setting for decentralized partial
model training in PFL. Our experiments on several real-world data with various
data partition settings demonstrate that (i) decentralized training is more
suitable for partial personalization, which results in state-of-the-art (SOTA)
accuracy compared with the SOTA PFL baselines; (ii) the shared parameters with
proper perturbation make partial personalized FL more suitable for
decentralized training, where DFedSalt achieves most competitive performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:52:18 GMT""}]","2023-05-25"
"2305.15158","David Fernandes E.","David E. Fernandes, M\'ario G. Silveirinha","Enhancing the Directional Violation of Kirchhoff's Law of Thermal
  Radiation with a Nonreciprocal Wire Medium","34 pages, 11 figures",,,,"physics.app-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  In this work, we develop a homogenization model to determine the effective
response of a metallic nanowire array embedded in an electric gyrotropic
material. We study the interaction of electromagnetic waves with the
metamaterial and demonstrate that the nanowire array can greatly enhance the
nonreciprocal response of the gyrotropic substrate. In particular, the
metamaterial can either absorb the incoming energy almost entirely or reflect
it with little loss, depending on the sign of the incidence angle. We explore
the implications of our findings in the context of Kirchhoff's law of thermal
radiation. Our results demonstrate that the wire array can boost the difference
between the emissivity and absorptivity in a broad spectrum of frequencies and
incidence angles as compared to an unstructured gyrotropic substrate. These
findings suggest potential applications for the nonreciprocal wire medium in
thermal management, radiative cooling, and others.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:52:47 GMT""}]","2023-05-25"
"2305.15159","Zheng Hu","Zheng Hu, Shi-Min Cai, Jun Wang, Tao Zhou","Collaborative Recommendation Model Based on Multi-modal Multi-view
  Attention Network: Movie and literature cases",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The existing collaborative recommendation models that use multi-modal
information emphasize the representation of users' preferences but easily
ignore the representation of users' dislikes. Nevertheless, modelling users'
dislikes facilitates comprehensively characterizing user profiles. Thus, the
representation of users' dislikes should be integrated into the user modelling
when we construct a collaborative recommendation model. In this paper, we
propose a novel Collaborative Recommendation Model based on Multi-modal
multi-view Attention Network (CRMMAN), in which the users are represented from
both preference and dislike views. Specifically, the users' historical
interactions are divided into positive and negative interactions, used to model
the user's preference and dislike views, respectively. Furthermore, the
semantic and structural information extracted from the scene is employed to
enrich the item representation. We validate CRMMAN by designing contrast
experiments based on two benchmark MovieLens-1M and Book-Crossing datasets.
Movielens-1m has about a million ratings, and Book-Crossing has about 300,000
ratings. Compared with the state-of-the-art knowledge-graph-based and
multi-modal recommendation methods, the AUC, NDCG@5 and NDCG@10 are improved by
2.08%, 2.20% and 2.26% on average of two datasets. We also conduct controlled
experiments to explore the effects of multi-modal information and multi-view
mechanism. The experimental results show that both of them enhance the model's
performance.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:52:56 GMT""}]","2023-05-25"
"2305.15160","Tetyana Shalomayeva","Jianpei Geng, Tetyana Shalomayeva, Mariia Gryzlova, Amlan Mukherjee,
  Santo Santonocito, Dzhavid Dzhavadzade, Durga Dasari, Hiromitsu Kato, Rainer
  St\""ohr, Andrej Denisenko, Norikazu Mizuochi, and J\""org Wrachtrup","Dopant-assisted stabilization of negatively charged single
  nitrogen-vacancy centers in phosphorus-doped diamond at low temperatures","8 pages, 4 figures",,,,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Charge state instabilities have been a bottleneck for the implementation of
solid-state spin systems and pose a major challenge to the development of
spin-based quantum technologies. Here we investigate the stabilization of
negatively charged nitrogen-vacancy (NV$^-$) centers in phosphorus-doped
diamond at liquid helium temperatures. Photoionization of phosphorous donors in
conjunction with charge diffusion at the nanoscale enhances NV$^0$ to NV$^-$
conversion and stabilizes the NV$^-$ charge state without the need for an
additional repump laser. The phosphorus-assisted stabilization is explored and
confirmed both with experiments and our theoretical model. Stable
photoluminescence-excitation spectra are obtained for NV$^-$ centers created
during the growth. The fluorescence is continuously recorded under resonant
excitation to real-time monitor the charge state and the ionization and
recombination rates are extracted from time traces. We find a linear laser
power dependence of the recombination rate as opposed to the conventional
quadratic dependence, which is attributed to the photo-ionization of phosphorus
atoms.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:53:10 GMT""}]","2023-05-25"
"2305.15161","Takeshi Morita","Takeshi Morita","A Derivation of the Critical Dimensions in Superstring Theories from
  Scale Invariance and Electric-Magnetic Duality","6+3 pages, 2 figures, v2: minor changes",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a low energy effective theory of $p$-branes in a $D$-dimensional
spacetime, and impose two conditions: 1) the system is scale invariant, and 2)
the electric-magnetic dual $(D-p-4)$-branes exist and they obey the same type
of interactions to the $p$-branes. (We do not assume supersymmetry or general
relativity.) We then ask what $p$ and $D$ are consistent with these conditions.
Using a simple dimensional analysis, we find that only two solutions are
possible: $(p,D)=(2,11)$ and $(p,D)=(2n-1,4n+2)$, ($n=1,2,3,\cdots$). The first
solution corresponds to M-theory, and the second solutions at $n=1$ and $n=2$
correspond to self-dual strings in little string theory and D3-branes in type
IIB superstring theory, respectively, although the second solutions for $n \ge
3$ are unknown. Thus, our two conditions may be strong enough to characterize
superstring theories.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:53:59 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 16:04:46 GMT""}]","2023-06-01"
"2305.15162","Christopher Lutsko","Dubi Kelmer, Alex Kontorovich, Christopher Lutsko","Mean square of Eisenstein series","13 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the sup-norm and mean-square-norm problems for Eisenstein series on
certain arithmetic hyperbolic orbifolds, producing sharp exponents for the
modular surface and Picard 3-fold. The methods involve bounds for Epstein zeta
functions, and counting restricted values of indefinite quadratic forms at
integer points.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:55:46 GMT""}]","2023-05-25"
"2305.15163","Alejandro Diaz","Alejandro N. Diaz, Youngsoo Choi, Matthias Heinkenschloss","A fast and accurate domain-decomposition nonlinear manifold reduced
  order model",,,,"LLNL-JRNL-849457","math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper integrates nonlinear-manifold reduced order models (NM-ROMs) with
domain decomposition (DD). NM-ROMs approximate the FOM state in a
nonlinear-manifold by training a shallow, sparse autoencoder using FOM snapshot
data. These NM-ROMs can be advantageous over linear-subspace ROMs (LS-ROMs) for
problems with slowly decaying Kolmogorov $n$-width. However, the number of
NM-ROM parameters that need to trained scales with the size of the FOM.
Moreover, for ""extreme-scale"" problems, the storage of high-dimensional FOM
snapshots alone can make ROM training expensive. To alleviate the training
cost, this paper applies DD to the FOM, computes NM-ROMs on each subdomain, and
couples them to obtain a global NM-ROM. This approach has several advantages:
Subdomain NM-ROMs can be trained in parallel, each involve fewer parameters to
be trained than global NM-ROMs, require smaller subdomain FOM dimensional
training data, and training of subdomain NM-ROMs can tailor them to
subdomain-specific features of the FOM. The shallow, sparse architecture of the
autoencoder used in each subdomain NM-ROM allows application of hyper-reduction
(HR), reducing the complexity caused by nonlinearity and yielding computational
speedup of the NM-ROM. This paper provides the first application of NM-ROM
(with HR) to a DD problem. In particular, it details an algebraic DD
formulation of the FOM, trains a NM-ROM with HR for each subdomain, and
develops a sequential quadratic programming (SQP) solver to evaluate the
coupled global NM-ROM. Theoretical convergence results for the SQP method and a
priori and a posteriori error estimates for the DD NM-ROM with HR are provided.
The proposed DD NM-ROM with HR approach is numerically compared to a DD LS-ROM
with HR on 2D steady-state Burgers' equation, showing an order of magnitude
improvement in accuracy of the proposed DD NM-ROM over the DD LS-ROM.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:56:37 GMT""}]","2023-05-25"
"2305.15164","Daichi Takeuchi","Daichi Takeuchi","Quadratic $\ell$-adic sheaf and its Heisenberg group","39 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a new class of $\ell$-adic sheaves, which we call
quadratic $\ell$-adic sheaves, on connected unipotent commutative algebraic
groups over finite fields. They are sheaf-theoretic enhancements of quadratic
forms on finite abelian groups in the spirit of the function-sheaf dictionary.
We show that a certain finite Heisenberg group acts on a quadratic sheaf and
that the cohomology of the quadratic sheaf gives an irreducible representation
of the group. We also compute the Frobenius eigenvalues of the cohomology
groups. As a byproduct, we find a large number of examples of affine
supersingular varieties.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:56:53 GMT""}]","2023-05-25"
"2305.15165","Geon Heo","Geon Heo, Junseok Seo, and Steven Euijong Whang","Personalized DP-SGD using Sampling Mechanisms","10 pages, 5 figures",,,,"cs.LG cs.AI cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Personalized privacy becomes critical in deep learning for Trustworthy AI.
While Differentially Private Stochastic Gradient Descent (DP-SGD) is widely
used in deep learning methods supporting privacy, it provides the same level of
privacy to all individuals, which may lead to overprotection and low utility.
In practice, different users may require different privacy levels, and the
model can be improved by using more information about the users with lower
privacy requirements. There are also recent works on differential privacy of
individuals when using DP-SGD, but they are mostly about individual privacy
accounting and do not focus on satisfying different privacy levels. We thus
extend DP-SGD to support a recent privacy notion called
($\Phi$,$\Delta$)-Personalized Differential Privacy (($\Phi$,$\Delta$)-PDP),
which extends an existing PDP concept called $\Phi$-PDP. Our algorithm uses a
multi-round personalized sampling mechanism and embeds it within the DP-SGD
iterations. Experiments on real datasets show that our algorithm outperforms
DP-SGD and simple combinations of DP-SGD with existing PDP mechanisms in terms
of model performance and efficiency due to its embedded sampling mechanism.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:56:57 GMT""}]","2023-05-25"
"2305.15166","Stephan Helfrich","Stephan Helfrich, Stefan Ruzika, Clemens Thielen","Efficiently Constructing Convex Approximation Sets in Multiobjective
  Optimization Problems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convex approximation sets for multiobjective optimization problems are a
well-studied relaxation of the common notion of approximation sets. Instead of
approximating each image of a feasible solution by the image of some solution
in the approximation set up to a multiplicative factor in each component, a
convex approximation set only requires this multiplicative approximation to be
achieved by some convex combination of finitely many images of solutions in the
set. This makes convex approximation sets efficiently computable for a wide
range of multiobjective problems - even for many problems for which (classic)
approximations sets are hard to compute.
  In this article, we propose a polynomial-time algorithm to compute convex
approximation sets that builds upon an exact or approximate algorithm for the
weighted sum scalarization and is, therefore, applicable to a large variety of
multiobjective optimization problems. The provided convex approximation quality
is arbitrarily close to the approximation quality of the underlying algorithm
for the weighted sum scalarization. In essence, our algorithm can be
interpreted as an approximate variant of the dual variant of Benson's Outer
Approximation Algorithm. Thus, in contrast to existing convex approximation
algorithms from the literature, information on solutions obtained during the
approximation process is utilized to significantly reduce both the practical
running time and the cardinality of the returned solution sets while still
guaranteeing the same worst-case approximation quality. We underpin these
advantages by the first comparison of all existing convex approximation
algorithms on several instances of the triobjective knapsack problem and the
triobjective symmetric metric traveling salesman problem.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:58:36 GMT""}]","2023-05-25"
"2305.15167","Siu Lun Chau","Siu Lun Chau and Krikamol Muandet and Dino Sejdinovic","Explaining the Uncertain: Stochastic Shapley Values for Gaussian Process
  Models","26 pages, 6 figures",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present a novel approach for explaining Gaussian processes (GPs) that can
utilize the full analytical covariance structure present in GPs. Our method is
based on the popular solution concept of Shapley values extended to stochastic
cooperative games, resulting in explanations that are random variables. The GP
explanations generated using our approach satisfy similar favorable axioms to
standard Shapley values and possess a tractable covariance function across
features and data observations. This covariance allows for quantifying
explanation uncertainties and studying the statistical dependencies between
explanations. We further extend our framework to the problem of predictive
explanation, and propose a Shapley prior over the explanation function to
predict Shapley values for new data based on previously computed ones. Our
extensive illustrations demonstrate the effectiveness of the proposed approach.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:59:03 GMT""}]","2023-05-25"
"2305.15168","Domenico Trotta","Domenico Trotta, Oreste Pezzi, David Burgess, Luis Preisser, Xochitl
  Blanco-Cano, Primoz Kajdic, Heli Hietala, Timothy S. Horbury, Rami Vainio,
  Nina Dresing, Alessandro Retino', Maria Federica Marcucci, Luca
  Sorriso-Valvo, Sergio Servidio and Francesco Valentini","Three-dimensional modelling of the shock-turbulence interaction","Submitted to MNRAS",,,,"physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  The complex interaction between shocks and plasma turbulence is extremely
important to address crucial features of energy conversion in a broad range of
astrophysical systems. We study the interaction between a supercritical,
perpendicular shock and pre-existing, fully-developed plasma turbulence,
employing a novel combination of magnetohydrodynamic (MHD) and small-scale,
hybrid-kinetic simulations where a shock is propagating through a turbulent
medium. The variability of the shock front in the unperturbed case and for two
levels of upstream fluctuations is addressed.We find that the behaviour of
shock ripples, i.e., shock surface fluctuations with short (a few ion skin
depths, $d_i$) wavelengths, is modified by the presence of pre-existing
turbulence, which also induces strong corrugations of the shock front at larger
scales. We link this complex behaviour of the shock front and the shock
downstream structuring with the proton temperature anisotropies produced in the
shock-turbulence system. Finally, we put our modelling effort in the context of
spacecraft observations, elucidating the role of novel cross-scale,
multi-spacecraft measurements in resolving shock front irregularities at
different scales. These results are relevant for a broad range of astrophysical
systems characterised by the presence of shock waves interacting with plasma
turbulence.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:59:18 GMT""}]","2023-05-25"
"2305.15169","Ricardo G\'azquez","Concepci\'on Dom\'inguez, Ricardo G\'azquez, Juan Miguel Morales,
  Salvador Pineda","The Cooperative Maximum Capture Facility Location Problem","32 pages, 8 tables, 2 algorithms, 8 figures",,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  In the Maximum Capture Facility Location (MCFL) problem with a binary choice
rule, a company intends to locate a series of facilities to maximize the
captured demand, and customers patronize the facility that maximizes their
utility. In this work, we generalize the MCFL problem assuming that the
facilities of the decision maker act cooperatively to increase the customers'
utility over the company. We propose a utility maximization rule between the
captured utility of the decision maker and the opt-out utility of a competitor
already installed in the market. Furthermore, we model the captured utility by
means of an Ordered Median function (OMf) of the partial utilities of newly
open facilities. We name this problem ""the Cooperative Maximum Capture Facility
Location problem"" (CMCFL). The OMf serves as a means to compute the utility of
each customer towards the company as an aggregation of ordered partial
utilities, and constitutes a unifying framework for CMCFL models. We introduce
a multiperiod non-linear bilevel formulation for the CMCFL with an embedded
assignment problem characterizing the captured utilities. For this model, two
exact resolution approaches are presented: a MILP reformulation with valid
inequalities and an effective approach based on Benders' decomposition.
Extensive computational experiments are provided to test our results with
randomly generated data and an application to the location of charging stations
for electric vehicles in the city of Trois-Rivi\`eres, Qu\`ebec, is addressed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:59:28 GMT""}]","2023-05-25"
"2305.15170","Sebastian Buschow","Sebastian Buschow, Jan Keller and Sabrina Wahl","Explaining heatwaves with machine learning",,,,,"physics.ao-ph","http://creativecommons.org/licenses/by/4.0/","  Heatwaves are known to arise from the interplay between large-scale climate
variability, synoptic weather patterns and regional to local scale surface
processes. While recent research has made important progress for each
individual contributing factor, ways to properly incorporate multiple or all of
them in a unified analysis are still lacking. In this study, we consider a wide
range of possible predictor variables from the ERA5 reanalysis, and ask, how
much information on heatwave occurrence in Europe can be learned from each of
them. To simplify the problem, we first adapt the recently developed logistic
principal component analysis to the task of compressing large binary heatwave
fields to a small number of interpretable principal components. The
relationships between heatwaves and various climate variables can then be
learned by a neural network. Starting from the simple notion that the
importance of a variable is given by its impact on the performance of our
statistical model, we arrive naturally at the definition of Shapley values.
Classic results of game theory show that this is the only fair way of
distributing the overall success of a model among its inputs. With this
approach, we find a non-linear model that explains 70% of reduced heatwave
variability, 27% of which are due to upper level geopotential while top level
soil moisture contributes 15% of the overall score. In addition, Shapley
interaction values enable us to quantify overlapping information and positive
synergies between all pairs of predictors.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:59:42 GMT""}]","2023-05-25"
"2305.15171","Shiu-Hong Kao","Xinhang Liu, Shiu-hong Kao, Jiaben Chen, Yu-Wing Tai, Chi-Keung Tang","Deceptive-NeRF: Enhancing NeRF Reconstruction using Pseudo-Observations
  from Diffusion Models","Project page: https://deceptive-nerf.github.io/",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces Deceptive-NeRF, a new method for enhancing the quality
of reconstructed NeRF models using synthetically generated pseudo-observations,
capable of handling sparse input and removing floater artifacts. Our proposed
method involves three key steps: 1) reconstruct a coarse NeRF model from sparse
inputs; 2) generate pseudo-observations based on the coarse model; 3) refine
the NeRF model using pseudo-observations to produce a high-quality
reconstruction. To generate photo-realistic pseudo-observations that faithfully
preserve the identity of the reconstructed scene while remaining consistent
with the sparse inputs, we develop a rectification latent diffusion model that
generates images conditional on a coarse RGB image and depth map, which are
derived from the coarse NeRF and latent text embedding from input images.
Extensive experiments show that our method is effective and can generate
perceptually high-quality NeRF even with very sparse inputs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:00:32 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 20:41:29 GMT""}]","2023-06-02"
"2305.15172","Rodrigo Aldana-L\'opez","Rodrigo Aldana-Lopez, Eduardo Sebastian, Rosario Aragues, Eduardo
  Montijano and Carlos Sagues","Distributed outer approximation of the intersection of ellipsoids","This is the accepted version of the manuscript: ""Distributed outer
  approximation of the intersection of ellipsoids,"" Rodrigo Aldana-Lopez,
  Eduardo Sebastian, Rosario Aragues, Eduardo Montijano and Carlos Sagues, in
  IEEE Control Systems Letters, 2023, DOI: 10.1109/LCSYS.2023.3280259",,"10.1109/LCSYS.2023.3280259",,"eess.SY cs.MA cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The outer Lowner-John method is widely used in sensor fusion applications to
find the smallest ellipsoid that can approximate the intersection of a set of
ellipsoids, described by positive definite covariance matrices modeling the
quality of each sensor. We propose a distributed algorithm to solve this
problem when these matrices are defined over the network's nodes. This is of
particular significance as it is the first decentralized algorithm capable of
computing the covariance intersection ellipsoid by combining information from
the entire network using only local interactions. The solution is based on a
reformulation of the centralized problem, leading to a local protocol based on
exact dynamic consensus tools. After reaching consensus, the protocol converges
to an outer Lowner-John ellipsoid in finite time, and to the global optimum
asymptotically. Formal convergence analysis and numerical experiments are
provided to validate the proposal's advantages.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:03:29 GMT""}]","2023-05-25"
"2305.15173","Stephan Helfrich","Stephan Helfrich, Arne Herzel, Stefan Ruzika, Clemens Thielen","Using Scalarizations for the Approximation of Multiobjective
  Optimization Problems: Towards a General Theory",,,,,"math.OC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the approximation of general multiobjective optimization problems
with the help of scalarizations. Existing results state that multiobjective
minimization problems can be approximated well by norm-based scalarizations.
However, for multiobjective maximization problems, only impossibility results
are known so far. Countering this, we show that all multiobjective optimization
problems can, in principle, be approximated equally well by scalarizations. In
this context, we introduce a transformation theory for scalarizations that
establishes the following: Suppose there exists a scalarization that yields an
approximation of a certain quality for arbitrary instances of multiobjective
optimization problems with a given decomposition specifying which objective
functions are to be minimized / maximized. Then, for each other decomposition,
our transformation yields another scalarization that yields the same
approximation quality for arbitrary instances of problems with this other
decomposition. In this sense, the existing results about the approximation via
scalarizations for minimization problems carry over to any other objective
decomposition -- in particular, to maximization problems -- when suitably
adapting the employed scalarization.
  We further provide necessary and sufficient conditions on a scalarization
such that its optimal solutions achieve a constant approximation quality. We
give an upper bound on the best achievable approximation quality that applies
to general scalarizations and is tight for the majority of norm-based
scalarizations applied in the context of multiobjective optimization. As a
consequence, none of these norm-based scalarizations can induce approximation
sets for optimization problems with maximization objectives, which unifies and
generalizes the existing impossibility results concerning the approximation of
maximization problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:04:50 GMT""}]","2023-05-25"
"2305.15174","Cornelius Schr\""oder","Cornelius Schr\""oder, Jakob H. Macke","Simultaneous identification of models and parameters of scientific
  simulators",,,,,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Many scientific models are composed of multiple discrete components, and
scien tists often make heuristic decisions about which components to include.
Bayesian inference provides a mathematical framework for systematically
selecting model components, but defining prior distributions over model
components and developing associated inference schemes has been challenging. We
approach this problem in an amortized simulation-based inference framework: We
define implicit model priors over a fixed set of candidate components and train
neural networks to infer joint probability distributions over both, model
components and associated parameters from simulations. To represent
distributions over model components, we introduce a conditional mixture of
multivariate binary distributions in the Grassmann formalism. Our approach can
be applied to any compositional stochastic simulator without requiring access
to likelihood evaluations. We first illustrate our method on a simple time
series model with redundant components and show that it can retrieve joint
posterior distribution over a set of symbolic expressions and their parameters
while accurately capturing redundancy with strongly correlated posteriors. We
then apply our approach to drift-diffusion models, a commonly used model class
in cognitive neuroscience. After validating the method on synthetic data, we
show that our approach explains experimental data as well as previous methods,
but that our fully probabilistic approach can help to discover multiple
data-consistent model configurations, as well as reveal non-identifiable model
components and parameters. Our method provides a powerful tool for data-driven
scientific inquiry which will allow scientists to systematically identify
essential model components and make uncertainty-informed modelling decisions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:06:02 GMT""}]","2023-05-25"
"2305.15175","Yiyang Li","Yiyang Li, Xinting Huang, Wei Bi, Hai Zhao","Pre-training Multi-party Dialogue Models with Latent Discourse Inference","Accepted by ACL 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Multi-party dialogues are more difficult for models to understand than
one-to-one two-party dialogues, since they involve multiple interlocutors,
resulting in interweaving reply-to relations and information flows. To step
over these obstacles, an effective way is to pre-train a model that understands
the discourse structure of multi-party dialogues, namely, to whom each
utterance is replying. However, due to the lack of explicitly annotated
discourse labels in multi-party dialogue corpora, previous works fail to scale
up the pre-training process by putting aside the unlabeled multi-party
conversational data for nothing. To fully utilize the unlabeled data, we
propose to treat the discourse structures as latent variables, then jointly
infer them and pre-train the discourse-aware model by unsupervised latent
variable inference methods. Experiments on multiple downstream tasks show that
our pre-trained model outperforms strong baselines by large margins and
achieves state-of-the-art (SOTA) results, justifying the effectiveness of our
method. The official implementation of this paper is available at
https://github.com/EricLee8/MPD_EMVI.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:06:27 GMT""}]","2023-05-25"
"2305.15176","Matthew Zaremsky","Matthew C. B. Zaremsky","Finitely presented simple groups with at least exponential Dehn function","10 pages",,,,"math.GR","http://creativecommons.org/licenses/by/4.0/","  We construct examples of finitely presented simple groups whose Dehn
functions are at least exponential. To the best of our knowledge, these are the
first such examples known. Our examples arise from R\""over-Nekrashevych groups,
using carefully calibrated self-similar representations of Baumslag-Solitar
groups.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:09:01 GMT""}]","2023-05-25"
"2305.15177","Hang Yu","Hang Yu, Zhenxing Dou, Zhiwei Chen and Xiaomeng Yan","Optimal subsampling for large scale Elastic-net regression","28 pages, 7 figures",,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Datasets with sheer volume have been generated from fields including computer
vision, medical imageology, and astronomy whose large-scale and
high-dimensional properties hamper the implementation of classical statistical
models. To tackle the computational challenges, one of the efficient approaches
is subsampling which draws subsamples from the original large datasets
according to a carefully-design task-specific probability distribution to form
an informative sketch. The computation cost is reduced by applying the original
algorithm to the substantially smaller sketch. Previous studies associated with
subsampling focused on non-regularized regression from the computational
efficiency and theoretical guarantee perspectives, such as ordinary least
square regression and logistic regression. In this article, we introduce a
randomized algorithm under the subsampling scheme for the Elastic-net
regression which gives novel insights into L1-norm regularized regression
problem. To effectively conduct consistency analysis, a smooth approximation
technique based on alpha absolute function is firstly employed and
theoretically verified. The concentration bounds and asymptotic normality for
the proposed randomized algorithm are then established under mild conditions.
Moreover, an optimal subsampling probability is constructed according to
A-optimality. The effectiveness of the proposed algorithm is demonstrated upon
synthetic and real data datasets.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:10:55 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 07:33:38 GMT""}]","2023-05-30"
"2305.15178","Yuchang Jiang","Yuchang Jiang, Vivien Sainte Fare Garnot, Konrad Schindler, Jan Dirk
  Wegner","Mixture of Experts with Uncertainty Voting for Imbalanced Deep
  Regression Problems",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Data imbalance is ubiquitous when applying machine learning to real-world
problems, particularly regression problems. If training data are imbalanced,
the learning is dominated by the densely covered regions of the target
distribution, consequently, the learned regressor tends to exhibit poor
performance in sparsely covered regions. Beyond standard measures like
over-sampling or re-weighting, there are two main directions to handle learning
from imbalanced data. For regression, recent work relies on the continuity of
the distribution; whereas for classification there has been a trend to employ
mixture-of-expert models and let some ensemble members specialize in
predictions for the sparser regions. Here, we adapt the mixture-of-experts
approach to the regression setting. A main question when using this approach is
how to fuse the predictions from multiple experts into one output. Drawing
inspiration from recent work on probabilistic deep learning, we propose to base
the fusion on the aleatoric uncertainties of individual experts, thus obviating
the need for a separate aggregation module. In our method, dubbed MOUV, each
expert predicts not only an output value but also its uncertainty, which in
turn serves as a statistically motivated criterion to rely on the right
experts. We compare our method with existing alternatives on multiple public
benchmarks and show that MOUV consistently outperforms the prior art, while at
the same time producing better calibrated uncertainty estimates. Our code is
available at link-upon-publication.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:12:21 GMT""}]","2023-05-25"
"2305.15179","Julien Donini","Louis Vaslin, Vincent Barra, Julien Donini","GAN-AE : An anomaly detection algorithm for New Physics search in LHC
  data","10 pages, 8 figures",,,,"hep-ex","http://creativecommons.org/licenses/by/4.0/","  In recent years, interest has grown in alternative strategies for the search
for New Physics beyond the Standard Model. One envisaged solution lies in the
development of anomaly detection algorithms based on unsupervised machine
learning techniques. In this paper, we propose a new Generative Adversarial
Network-based auto-encoder model that allows both anomaly detection and
model-independent background modeling. This algorithm can be integrated with
other model-independent tools in a complete heavy resonance search strategy.
The proposed strategy has been tested on the LHC Olympics 2020 dataset with
promising results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:13:37 GMT""}]","2023-05-25"
"2305.15180","Fei Yang","Yuming Fu and Fei Yang","Mating Siegel and parabolic quadratic polynomials","40 pages, 9 figures",,,,"math.DS math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $f_\theta(z)=e^{2\pi i\theta}z+z^2$ be the quadratic polynomial having an
indifferent fixed point at the origin. For any bounded type irrational number
$\theta\in\mathbb{R}\setminus\mathbb{Q}$ and any rational number
$\nu\in\mathbb{Q}$, we prove that $f_\theta$ and $f_\nu$ are conformally
mateable, and that the mating is unique up to conjugacy by a M\""{o}bius map.
This gives an affirmative (partial) answer to a question raised by Milnor in
2004.
  A crucial ingredient in the proof relies on an expansive property when
iterating certain rational maps near Siegel disk boundaries. Combining this
with the expanding property in repelling petals of parabolic points, we also
prove that the Julia sets of a class of Siegel rational maps with parabolic
points are locally connected.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:13:43 GMT""}]","2023-05-25"
"2305.15181","Anson Ka Long Yip","Anson Ka Long Yip, Patrick Chi-Kit Cheong, Tjonnie Guang Feng Li","Gravitational wave signatures from the phase-transition-induced collapse
  of a magnetized neutron star","12 pages, 4 figures",,,,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Strong magnetic fields make neutron stars potential sources of detectable
electromagnetic and gravitational-wave signals. Hence, inferring these magnetic
fields is critical to understand the emissions of neutron stars. However, due
to the lack of direct observational evidence, the interior magnetic field
configuration remains ambiguous. Here, for the first time, we show that the
internal magnetic field strength along with the composition of a neutron star
can be directly constrained by detecting the gravitational waves from the
phase-transition-induced collapse of a magnetized neutron star. By dynamically
simulating this collapsing event, we first find that the dominant peaks in the
gravitational waveform are the fundamental $l=0$ quasi-radial $F$ mode and the
fundamental $l=2$ quadrupolar $^2f$ mode. We next show that the maximum
gravitational wave amplitude $|h|_\mathrm{max}$ increases with the maximum
magnetic field strength of the interior toroidal field
$\mathcal{B}_\mathrm{max}$ until the maximum rest-mass density at bounce
$\rho_\mathrm{max,b}$ decreases due to the increasing
$\mathcal{B}_\mathrm{max}$. We then demonstrated that the magnetic suppression
of fundamental modes found in our previous work remains valid for the hybrid
stars formed after the phase-transition-induced collapses. We finally show that
measuring the frequency ratio between the two fundamental modes $f_{^2f}/f_{F}$
allows one to infer $\mathcal{B}_\mathrm{max}$ and the baryonic mass fraction
of matter in the mixed phase $M_\mathrm{mp} / M_{0}$ of the resulting hybrid
star. Consequently, taking $\mathcal{B}_\mathrm{max}$ and $M_\mathrm{mp} /
M_{0}$ as examples, this work has demonstrated that much information inside
neutron stars could be extracted similarly through measuring the oscillation
modes of the stars.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:14:04 GMT""}]","2023-05-25"
"2305.15182","Junran Wu","He Zhu, Chong Zhang, Junjie Huang, Junran Wu, Ke Xu","HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text
  Classification","Accepted by ACL'23",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Hierarchical text classification (HTC) is a challenging subtask of
multi-label classification as the labels form a complex hierarchical structure.
Existing dual-encoder methods in HTC achieve weak performance gains with huge
memory overheads and their structure encoders heavily rely on domain knowledge.
Under such observation, we tend to investigate the feasibility of a
memory-friendly model with strong generalization capability that could boost
the performance of HTC without prior statistics or label semantics. In this
paper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance
the text representations with only syntactic information of the label
hierarchy. Specifically, we convert the label hierarchy into an unweighted tree
structure, termed coding tree, with the guidance of structural entropy. Then we
design a structure encoder to incorporate hierarchy-aware information in the
coding tree into text representations. Besides the text encoder, HiTIN only
contains a few multi-layer perceptions and linear transformations, which
greatly saves memory. We conduct experiments on three commonly used datasets
and the results demonstrate that HiTIN could achieve better test performance
and less memory consumption than state-of-the-art (SOTA) methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:14:08 GMT""}]","2023-05-25"
"2305.15183","Chenming Tang","Chenming Tang, Xiuyu Wu and Yunfang Wu","Are Pre-trained Language Models Useful for Model Ensemble in Chinese
  Grammatical Error Correction?","7 pages, 1 figure. Accepted by ACL 2023 (main conference, short
  paper)",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model ensemble has been in widespread use for Grammatical Error Correction
(GEC), boosting model performance. We hypothesize that model ensemble based on
the perplexity (PPL) computed by pre-trained language models (PLMs) should
benefit the GEC system. To this end, we explore several ensemble strategies
based on strong PLMs with four sophisticated single models. However, the
performance does not improve but even gets worse after the PLM-based ensemble.
This surprising result sets us doing a detailed analysis on the data and coming
up with some insights on GEC. The human references of correct sentences is far
from sufficient in the test data, and the gap between a correct sentence and an
idiomatic one is worth our attention. Moreover, the PLM-based ensemble
strategies provide an effective way to extend and improve GEC benchmark data.
Our source code is available at
https://github.com/JamyDon/PLM-based-CGEC-Model-Ensemble.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:18:52 GMT""}]","2023-05-25"
"2305.15184","Ruiqi Liu","Ruiqi Liu, Meng Hua, Ke Guan, Xiping Wang, Leyi Zhang, Tianqi Mao, Di
  Zhang, Qingqing Wu, Abbas Jamalipour","6G Enabled Advanced Transportation Systems","Submitted to an open access journal",,,,"cs.IT cs.NI cs.SY eess.SP eess.SY math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The 6th generation (6G) wireless communication network is envisaged to be
able to change our lives drastically, including transportation. In this paper,
two ways of interactions between 6G communication networks and transportation
are introduced. With the new usage scenarios and capabilities 6G is going to
support, passengers on all sorts of transportation systems will be able to get
data more easily, even in the most remote areas on the planet. The quality of
communication will also be improved significantly, thanks to the advanced
capabilities of 6G. On top of providing seamless and ubiquitous connectivity to
all forms of transportation, 6G will also transform the transportation systems
to make them more intelligent, more efficient, and safer. Based on the latest
research and standardization progresses, technical analysis on how 6G can
empower advanced transportation systems are provided, as well as challenges and
insights for a possible road ahead.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:23:32 GMT""}]","2023-05-25"
"2305.15185","Andrew L. Miller","Andrew L. Miller","Recent results from continuous gravitational wave searches using data
  from LIGO/Virgo/KAGRA's third observing run","Contribution to the 2023 Gravitation session of the 57th Rencontres
  de Moriond",,,,"gr-qc astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The third observing run of advanced LIGO, Virgo and KAGRA brought
unprecedented sensitivity towards a variety of quasi-monochromatic, persistent
gravitational-wave signals. Continuous waves allow us to probe not just the
existence of canonical asymmetrically rotating neutron stars, but also
different forms of dark matter, thus showing the wide-ranging astrophysical
implications of using a relatively simple signal model. I will describe the
major results from the numerous continuous-wave searches that were performed in
O3, both inside and outside the LIGO/Virgo/KAGRA collaborations, and show how
impactful to multi-messenger physics that they have been.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:25:43 GMT""}]","2023-05-25"
"2305.15186","Tetsu Kasanishi","Tetsu Kasanishi, Masaru Isonuma, Junichiro Mori, Ichiro Sakata","SciReviewGen: A Large-scale Dataset for Automatic Literature Review
  Generation","ACL findings 2023 (to be appeared). arXiv admin note: text overlap
  with arXiv:1810.04020 by other authors",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic literature review generation is one of the most challenging tasks
in natural language processing. Although large language models have tackled
literature review generation, the absence of large-scale datasets has been a
stumbling block to the progress. We release SciReviewGen, consisting of over
10,000 literature reviews and 690,000 papers cited in the reviews. Based on the
dataset, we evaluate recent transformer-based summarization models on the
literature review generation task, including Fusion-in-Decoder extended for
literature review generation. Human evaluation results show that some
machine-generated summaries are comparable to human-written reviews, while
revealing the challenges of automatic literature review generation such as
hallucinations and a lack of detailed information. Our dataset and code are
available at https://github.com/tetsu9923/SciReviewGen.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:26:30 GMT""}]","2023-05-25"
"2305.15187","Julian Frederik Schumann","Julian F. Schumann, Aravinda Ramakrishnan Srinivasan, Jens Kober,
  Gustav Markkula, Arkady Zgonnikov","Using Models Based on Cognitive Theory to Predict Human Behavior in
  Traffic: A Case Study","6 pages, 2 figures",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The development of automated vehicles has the potential to revolutionize
transportation, but they are currently unable to ensure a safe and
time-efficient driving style. Reliable models predicting human behavior are
essential for overcoming this issue. While data-driven models are commonly used
to this end, they can be vulnerable in safety-critical edge cases. This has led
to an interest in models incorporating cognitive theory, but as such models are
commonly developed for explanatory purposes, this approach's effectiveness in
behavior prediction has remained largely untested so far. In this article, we
investigate the usefulness of the \emph{Commotions} model -- a novel
cognitively plausible model incorporating the latest theories of human
perception, decision-making, and motor control -- for predicting human behavior
in gap acceptance scenarios, which entail many important traffic interactions
such as lane changes and intersections. We show that this model can compete
with or even outperform well-established data-driven prediction models across
several naturalistic datasets. These results demonstrate the promise of
incorporating cognitive theory in behavior prediction models for automated
vehicles.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:27:00 GMT""}]","2023-05-25"
"2305.15188","Wenjian Hao","Wenjian Hao, Paulo C. Heredia, Bowen Huang, Zehui Lu, Zihao Liang,
  Shaoshuai Mou","Policy Learning based on Deep Koopman Representation",,,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper proposes a policy learning algorithm based on the Koopman operator
theory and policy gradient approach, which seeks to approximate an unknown
dynamical system and search for optimal policy simultaneously, using the
observations gathered through interaction with the environment. The proposed
algorithm has two innovations: first, it introduces the so-called deep Koopman
representation into the policy gradient to achieve a linear approximation of
the unknown dynamical system, all with the purpose of improving data
efficiency; second, the accumulated errors for long-term tasks induced by
approximating system dynamics are avoided by applying Bellman's principle of
optimality. Furthermore, a theoretical analysis is provided to prove the
asymptotic convergence of the proposed algorithm and characterize the
corresponding sampling complexity. These conclusions are also supported by
simulations on several challenging benchmark environments.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:27:22 GMT""}]","2023-05-25"
"2305.15189","Jan Achterhold","Jan Achterhold, Philip Tobuschat, Hao Ma, Dieter Buechler, Michael
  Muehlebach, Joerg Stueckler","Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball
  Trajectory Prediction with Spin and Impacts","Accepted for publication at the 5th Annual Conference on Learning for
  Dynamics and Control (L4DC) 2023. With supplementary material",,,,"cs.RO cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a method for table tennis ball trajectory filtering
and prediction. Our gray-box approach builds on a physical model. At the same
time, we use data to learn parameters of the dynamics model, of an extended
Kalman filter, and of a neural model that infers the ball's initial condition.
We demonstrate superior prediction performance of our approach over two
black-box approaches, which are not supplied with physical prior knowledge. We
demonstrate that initializing the spin from parameters of the ball launcher
using a neural network drastically improves long-time prediction performance
over estimating the spin purely from measured ball positions. An accurate
prediction of the ball trajectory is crucial for successful returns. We
therefore evaluate the return performance with a pneumatic artificial muscular
robot and achieve a return rate of 29/30 (97.7%).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:28:22 GMT""}]","2023-05-25"
"2305.15190","Changsub Kim","Changsub Kim, Christina Bell, Jake Evans, Jonathan Greenfield, Nathan
  Lewis, Daniel Cunnane","Wafer-scale magnesium diboride thin films and devices with tunable high
  kinetic inductance",,,,,"cond-mat.supr-con cond-mat.mtrl-sci physics.app-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  Progress in superconducting device and detector technologies over the past
decade have realized practical applications in quantum computers, detectors for
far-IR telescopes, and optical communications. Superconducting thin film
materials, however, have remained largely unchanged, with aluminum still being
the material of choice for superconducting qubits, and Nb compounds for higher
frequency devices. $\mathrm{MgB}_2$, known for its highest $\mathrm{T}_c$ (39
K) among metallic superconductors, is a viable material for higher frequency
superconducting devices moving towards THz frequencies. However, difficulty in
synthesizing thin films have prevented implementation of $\mathrm{MgB}_2$
devices into the application base of superconducting electronics, despite
promising preliminary results for a number of applications. We have developed
smooth and uniform $\mathrm{MgB}_2$ films on 4-inch Si wafers by depositing
uniform Mg-B co-sputtered film, capping the film in situ to create a closed
environment, followed by an optimized post-annealing step. We further report
mature device fabrication processes and demonstrate test structures to measure
properties of the films. This includes resonators with internal Q factor over
$\mathrm{10}^4$ at 4.5 K and tunable high kinetic inductance (5-50 pH/$\square$
readily achieved in a 40 nm film), opening up the path for development of high
frequency and high temperature $\mathrm{MgB}_2$ microdevices.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:28:58 GMT""}]","2023-05-25"
"2305.15191","Aldin Vehabovic","Farooq Shaikh, Elias Bou-Harb, Aldin Vehabovic, Jorge Crichigno,
  Aysegul Yayimli and Nasir Ghani","IoT Threat Detection Testbed Using Generative Adversarial Networks","8 pages, 5 figures",,"10.1109/BlackSeaCom54372.2022.9858239",,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Internet of Things(IoT) paradigm provides persistent sensing and data
collection capabilities and is becoming increasingly prevalent across many
market sectors. However, most IoT devices emphasize usability and function over
security, making them very vulnerable to malicious exploits. This concern is
evidenced by the increased use of compromised IoT devices in large scale bot
networks (botnets) to launch distributed denial of service(DDoS) attacks
against high value targets. Unsecured IoT systems can also provide entry points
to private networks, allowing adversaries relatively easy access to valuable
resources and services. Indeed, these evolving IoT threat vectors (ranging from
brute force attacks to remote code execution exploits) are posing key
challenges. Moreover, many traditional security mechanisms are not amenable for
deployment on smaller resource-constrained IoT platforms. As a result,
researchers have been developing a range of methods for IoT security, with many
strategies using advanced machine learning(ML) techniques. Along these lines,
this paper presents a novel generative adversarial network(GAN) solution to
detect threats from malicious IoT devices both inside and outside a network.
This model is trained using both benign IoT traffic and global darknet data and
further evaluated in a testbed with real IoT devices and malware threats.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:29:46 GMT""}]","2023-05-25"
"2305.15192","Kiarash Banihashem","Kiarash Banihashem, Leyla Biabani, Samira Goudarzi, MohammadTaghi
  Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh","Dynamic Constrained Submodular Optimization with Polylogarithmic Update
  Time",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Maximizing a monotone submodular function under cardinality constraint $k$ is
a core problem in machine learning and database with many basic applications,
including video and data summarization, recommendation systems, feature
extraction, exemplar clustering, and coverage problems. We study this classic
problem in the fully dynamic model where a stream of insertions and deletions
of elements of an underlying ground set is given and the goal is to maintain an
approximate solution using a fast update time.
  A recent paper at NeurIPS'20 by Lattanzi, Mitrovic, Norouzi{-}Fard,
Tarnawski, Zadimoghaddam claims to obtain a dynamic algorithm for this problem
with a $\frac{1}{2} -\epsilon$ approximation ratio and a query complexity
bounded by $\mathrm{poly}(\log(n),\log(k),\epsilon^{-1})$. However, as we
explain in this paper, the analysis has some important gaps. Having a dynamic
algorithm for the problem with polylogarithmic update time is even more
important in light of a recent result by Chen and Peng at STOC'22 who show a
matching lower bound for the problem -- any randomized algorithm with a
$\frac{1}{2}+\epsilon$ approximation ratio must have an amortized query
complexity that is polynomial in $n$.
  In this paper, we develop a simpler algorithm for the problem that maintains
a $(\frac{1}{2}-\epsilon)$-approximate solution for submodular maximization
under cardinality constraint $k$ using a polylogarithmic amortized update time.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:30:07 GMT""}]","2023-05-25"
"2305.15193","Wenjian Hao","Wenjian Hao, Zehui Lu, Zihao Liang, Tianyu Zhou, Shaoshuai Mou","Adaptive Policy Learning to Additional Tasks",,,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper develops a policy learning method for tuning a pre-trained policy
to adapt to additional tasks without altering the original task. A method named
Adaptive Policy Gradient (APG) is proposed in this paper, which combines
Bellman's principle of optimality with the policy gradient approach to improve
the convergence rate. This paper provides theoretical analysis which guarantees
the convergence rate and sample complexity of $\mathcal{O}(1/T)$ and
$\mathcal{O}(1/\epsilon)$, respectively, where $T$ denotes the number of
iterations and $\epsilon$ denotes the accuracy of the resulting stationary
policy. Furthermore, several challenging numerical simulations, including
cartpole, lunar lander, and robot arm, are provided to show that APG obtains
similar performance compared to existing deterministic policy gradient methods
while utilizing much less data and converging at a faster rate.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:31:11 GMT""}]","2023-05-25"
"2305.15194","Sungnyun Kim","Sungnyun Kim, Junsoo Lee, Kibeom Hong, Daesik Kim, Namhyuk Ahn","DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion
  Models","18 pages, 16 figures, and 3 tables",,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The recent progress in diffusion-based text-to-image generation models has
significantly expanded generative capabilities via conditioning the text
descriptions. However, since relying solely on text prompts is still
restrictive for fine-grained customization, we aim to extend the boundaries of
conditional generation to incorporate diverse types of modalities, e.g.,
sketch, box, and style embedding, simultaneously. We thus design a multimodal
text-to-image diffusion model, coined as DiffBlender, that achieves the
aforementioned goal in a single model by training only a few small
hypernetworks. DiffBlender facilitates a convenient scaling of input
modalities, without altering the parameters of an existing large-scale
generative model to retain its well-established knowledge. Furthermore, our
study sets new standards for multimodal generation by conducting quantitative
and qualitative comparisons with existing approaches. By diversifying the
channels of conditioning modalities, DiffBlender faithfully reflects the
provided information or, in its absence, creates imaginative generation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:31:20 GMT""}]","2023-05-25"
"2305.15195","Peihu Duan","Peihu Duan and Tao Liu and Yuezu Lv and Guanghui Wen","Cooperative Control of Multi-Channel Linear Systems with Self-Organizing
  Private Agents",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cooperative behavior design for multi-agent systems with collective tasks is
a critical issue to promote swarm intelligence. This paper investigates
cooperative control for a multi-channel system, where each channel is managed
by an agent that can communicate with neighbors in a network. Each agent is
expected to self-organize a controller based only on local information and
local interaction to stabilize the multi-channel system collaboratively. A
novel cooperative control strategy is designed for each agent by leveraging a
decomposing technique and a fusion approach. Then, a privacy-preserving
mechanism is incorporated into this strategy to shield all private information
from eavesdropping. Moreover, a fully distributed designing method for the
strategy parameters is developed. As a result, agents can self-design and
self-perform their controllers with private information preserved. It is proved
that the multi-channel system stability can be ensured by the proposed strategy
with finite fusion steps during each control interval. In addition, the cost of
introducing the privacy-preserving mechanism and the effect of adding more
channels on the system performance are quantitatively analyzed, which benefits
mechanism design and channel placement. Finally, several comparative simulation
examples are provided to demonstrate the effectiveness of the theoretical
results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:31:28 GMT""}]","2023-05-25"
"2305.15196","Kyunghyun Park","Myeongho Jeon, Myungjoo Kang, Joonhun Lee, Kyunghyun Park","Feature-aligned N-BEATS with Sinkhorn divergence",,,,,"cs.LG cs.AI math.OC math.PR","http://creativecommons.org/licenses/by/4.0/","  In this study, we propose Feature-aligned N-BEATS as a domain generalization
model for univariate time series forecasting problems. The proposed model is an
extension of the doubly residual stacking architecture of N-BEATS (Oreshkin et
al. [34]) into a representation learning framework. The model is a new
structure that involves marginal feature probability measures (i.e.,
pushforward measures of multiple source domains) induced by the intricate
composition of residual operators of N-BEATS in each stack and aligns them
stack-wise via an entropic regularized Wasserstein distance referred to as the
Sinkhorn divergence (Genevay et al. [14]). The loss function consists of a
typical forecasting loss for multiple source domains and an alignment loss
calculated with the Sinkhorn divergence, which allows the model to learn
invariant features stack-wise across multiple source data sequences while
retaining N-BEATS's interpretable design. We conduct a comprehensive
experimental evaluation of the proposed approach and the results demonstrate
the model's forecasting and generalization capabilities in comparison with
methods based on the original N-BEATS.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:32:23 GMT""}]","2023-05-25"
"2305.15197","Navdeep Rana","Navdeep Rana, Rayan Chatterjee, Sunghan Ro, Dov Levine, Sriram
  Ramaswamy, Prasad Perlekar","Defect turbulence in a dense suspension of polar, active swimmers","8 pages, 7 figures, 1 appendix",,,,"cond-mat.soft physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the effects of inertia in dense suspensions of polar swimmers. The
hydrodynamic velocity field and the polar order parameter field describe the
dynamics of the suspension. We show that a dimensionless parameter $R$ (ratio
of the swimmer self-advection speed to the active stress invasion speed)
controls the stability of an ordered swimmer suspension. For $R$ smaller than a
threshold $R_1$, perturbations grow at a rate proportional to their wave number
$q$. Beyond $R_1$, we show that the growth rate is $\mathcal{O}(q^2)$ until a
second threshold $R=R_2$ is reached. The suspension is stable for $R>R_2$. We
perform direct numerical simulations to investigate the steady state properties
and observe defect turbulence for $R<R_2$. An investigation of the spatial
organisation of defects unravels a hidden transition: for small $R\approx 0$
defects are uniformly distributed and cluster as $R\to R_1$. Beyond $R_1$,
clustering saturates and defects are arranged in nearly string-like structures.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:32:49 GMT""}]","2023-05-25"
"2305.15198","Yuya Hattori","Yuya Hattori, Keisuke Sagisaka, Shunsuke Yoshizawa, Yuki Tokumoto, and
  Keiichi Edagawa","Topological surface states hybridized with bulk states of Bi-doped
  PbSb2Te4 revealed in quasiparticle interference","7+8 pages, 4+5 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological surface states of Bi-doped PbSb2Te4 [Pb(Bi0.20Sb0.80)2Te4] are
investigated through analyses of quasiparticle interference (QPI) patterns
observed by scanning tunneling microscopy. Interpretation of the experimental
QPI patterns in the reciprocal space is achieved by numerical QPI simulations
using two types of surface density of states produced by density functional
theory calculations or a kp surface state model. We found that the Dirac point
(DP) of the surface state appears in the bulk band gap of this material and,
with the energy being away from the DP, the isoenergy contour of the surface
state is substantially deformed or separated into segments due to hybridization
with bulk electronic states. These findings provide a more accurate picture of
topological surface states, especially at energies away from the DP, providing
valuable insight into the electronic properties of topological insulators.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:34:38 GMT""}]","2023-05-25"
"2305.15199","Nathan Vance","Nathan Vance, Jeremy Speth, Benjamin Sporrer, Patrick Flynn","Promoting Generalization in Cross-Dataset Remote Photoplethysmography","8 pages, accepted for publication at CVPM 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Remote Photoplethysmography (rPPG), or the remote monitoring of a subject's
heart rate using a camera, has seen a shift from handcrafted techniques to deep
learning models. While current solutions offer substantial performance gains,
we show that these models tend to learn a bias to pulse wave features inherent
to the training dataset. We develop augmentations to mitigate this learned bias
by expanding both the range and variability of heart rates that the model sees
while training, resulting in improved model convergence when training and
cross-dataset generalization at test time. Through a 3-way cross dataset
analysis we demonstrate a reduction in mean absolute error from over 13 beats
per minute to below 3 beats per minute. We compare our method with other recent
rPPG systems, finding similar performance under a variety of evaluation
parameters.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:35:54 GMT""}]","2023-05-25"
"2305.15200","Mark Saffman","J.C. Bohorquez, R. Chinnarasu, J. Isaacs, D. Booth, M. Beck, R.
  McDermott, and M. Saffman","Reducing Rydberg state dc polarizability by microwave dressing","factor of 4 in Table 3 corrected",,,,"physics.atom-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  We demonstrate reduction of the dc polarizability of Cesium atom Rydberg
states in a 77 K environment utilizing microwave field dressing. In particular
we reduce the polarizability of $52P_{3/2}$ states which have resonances at
5.35 GHz to $51D_{5/2}$, suitable for interfacing Rydberg atoms to
superconducting resonators in a cryogenic environment. We measure the
polarizability of the Rydberg states using Magneto-Optical-Trap (MOT) loss
spectroscopy. Using an off-resonant radio-frequency (RF) dressing field
coupling $52P_{3/2}$ and $51D_{5/2}$ we demonstrate a reduction in dc
polarizability of the $ 52P_{3/2}$ states over 80$\%$. Experimental findings
are in good agreement with a numerical model of the atom-dressing field system
developed using the Shirley-Floquet formalism. We also demonstrate that the dc
polarizability reduction is highly anisotropic, with near total nulling
possible when the dc and dressing fields are aligned, but only a factor of two
reduction in polarizability when the fields are orthogonal. These results may
aid in stabilizing Rydberg resonances against varying dc fields present near
surfaces, enabling advancement in the development of hybrid Rydberg atom -
superconducting resonator quantum gates.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:35:57 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 02:08:29 GMT""}]","2023-05-26"
"2305.15201","Dylan Herman","Shree Hari Sureshbabu, Dylan Herman, Ruslan Shaydulin, Joao Basso,
  Shouvanik Chakrabarti, Yue Sun, and Marco Pistoia","Parameter Setting in Quantum Approximate Optimization of Weighted
  Problems",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum Approximate Optimization Algorithm (QAOA) is a leading candidate
algorithm for solving combinatorial optimization problems on quantum computers.
However, in many cases QAOA requires computationally intensive parameter
optimization. The challenge of parameter optimization is particularly acute in
the case of weighted problems, for which the eigenvalues of the phase operator
are non-integer and the QAOA energy landscape is not periodic. In this work, we
develop parameter setting heuristics for QAOA applied to a general class of
weighted problems. First, we derive optimal parameters for QAOA with depth
$p=1$ applied to the weighted MaxCut problem under different assumptions on the
weights. In particular, we rigorously prove the conventional wisdom that in the
average case the first local optimum near zero gives globally-optimal QAOA
parameters. Second, for $p\geq 1$ we prove that the QAOA energy landscape for
weighted MaxCut approaches that for the unweighted case under a simple
rescaling of parameters. Therefore, we can use parameters previously obtained
for unweighted MaxCut for weighted problems. Finally, we prove that for $p=1$
the QAOA objective sharply concentrates around its expectation, which means
that our parameter setting rules hold with high probability for a random
weighted instance. We numerically validate this approach on general weighted
graphs and show that on average the QAOA energy with the proposed fixed
parameters is only $1.1$ percentage points away from that with optimized
parameters. Third, we propose a general heuristic rescaling scheme inspired by
the analytical results for weighted MaxCut and demonstrate its effectiveness
using QAOA with the XY Hamming-weight-preserving mixer applied to the portfolio
optimization problem. Our heuristic improves the convergence of local
optimizers, reducing the number of iterations by 7.2x on average.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:37:33 GMT""}]","2023-05-25"
"2305.15202","Xiaomeng Chen","Xiaomeng Chen, Wei Jiang, Themistoklis Charalambous and Ling Shi","A Privacy-Preserving Finite-Time Push-Sum based Gradient Method for
  Distributed Optimization over Digraphs",,,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper addresses the problem of distributed optimization, where a network
of agents represented as a directed graph (digraph) aims to collaboratively
minimize the sum of their individual cost functions. Existing approaches for
distributed optimization over digraphs, such as Push-Pull, require agents to
exchange explicit state values with their neighbors in order to reach an
optimal solution. However, this can result in the disclosure of sensitive and
private information. To overcome this issue, we propose a
state-decomposition-based privacy-preserving finite-time push-sum (PrFTPS)
algorithm without any global information such as network size or graph
diameter. Then, based on PrFTPS, we design a gradient descent algorithm
(PrFTPS-GD) to solve the distributed optimization problem. It is proved that
under PrFTPS-GD, the privacy of each agent is preserved and the linear
convergence rate related to the optimization iteration number is achieved.
Finally, numerical simulations are provided to illustrate the effectiveness of
the proposed approach.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:38:18 GMT""}]","2023-05-25"
"2305.15203","Lorenzo Basile","Lorenzo Basile, Nikos Karantzas, Alberto D'Onofrio, Luca Bortolussi,
  Alex Rodriguez, Fabio Anselmi","Relating Implicit Bias and Adversarial Attacks through Intrinsic
  Dimension",,,,,"cs.LG cs.AI cs.CR stat.ML","http://creativecommons.org/licenses/by/4.0/","  Despite their impressive performance in classification, neural networks are
known to be vulnerable to adversarial attacks. These attacks are small
perturbations of the input data designed to fool the model. Naturally, a
question arises regarding the potential connection between the architecture,
settings, or properties of the model and the nature of the attack. In this
work, we aim to shed light on this problem by focusing on the implicit bias of
the neural network, which refers to its inherent inclination to favor specific
patterns or outcomes. Specifically, we investigate one aspect of the implicit
bias, which involves the essential Fourier frequencies required for accurate
image classification. We conduct tests to assess the statistical relationship
between these frequencies and those necessary for a successful attack. To delve
into this relationship, we propose a new method that can uncover non-linear
correlations between sets of coordinates, which, in our case, are the
aforementioned frequencies. By exploiting the entanglement between intrinsic
dimension and correlation, we provide empirical evidence that the network bias
in Fourier space and the target frequencies of adversarial attacks are closely
tied.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:40:23 GMT""}]","2023-05-25"
"2305.15204","Tyler Lawson","Tyler Lawson","Lax monoidality for products of enriched higher categories","22 pages. Comments welcome",,,,"math.CT math.AT","http://creativecommons.org/licenses/by/4.0/","  We prove that a lax $\mathbb{E}_{n+1}$-monoidal functor from $\mathcal V$ to
$\mathcal W$ induces a lax $\mathbb{E}_n$-monoidal functor from $\mathcal
V$-enriched $\infty$-categories to $\mathcal W$-enriched $\infty$-categories in
the sense of Gepner--Haugseng.
  We prove this as part of a general-purpose interaction with the
Boardman--Vogt tensor product $\otimes$: given a construction that takes an
$\mathcal E$-monoidal $\infty$-category to a category expressible in
diagrammatic terms, we give a criterion for it to take $(\mathcal{O} \otimes
\mathcal{E})$-monoidal $\infty$-categories to $\mathcal{O}$-monoidal
$\infty$-categories using a ""pointwise"" monoidal structure.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:40:27 GMT""}]","2023-05-25"
"2305.15205","Anton Yurchenko-Tytarenko","Yuliya Mishura, Anton Yurchenko-Tytarenko","Parameter estimation in rough Bessel model",,,,,"math.PR","http://creativecommons.org/licenses/by/4.0/","  In this paper, we construct consistent statistical estimators of the Hurst
index, volatility coefficient, and drift parameter for Bessel processes driven
by fractional Brownian motion with $H<1/2$. As an auxiliary result, we also
prove the continuity of the fractional Bessel process. The results are
illustrated with simulations.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:40:34 GMT""}]","2023-05-25"
"2305.15206","Vasiliki Velona","Anna Ben-Hamou, Vasiliki Velona","Inference in balanced community modulated recursive trees",,,,,"math.ST math.PR stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a random recursive tree model with two communities, called
balanced community modulated random recursive tree, or BCMRT in short. In this
setting, pairs of nodes of different type appear sequentially. Each one of them
decides independently to attach to their own type with probability 1-q, or to
the other type with probability q, and then chooses its parent uniformly within
the set of existing nodes with the selected type. We find that the limiting
degree distributions coincide for different q. Therefore, as far as inference
is concerned, other statistics have to be studied. We first consider the
setting where the time-labels of the nodes, i.e. their time of arrival, are
observed but their type is not. In this setting, we design a consistent
estimator for q and provide bounds for the feasibility of testing between two
different values of q. Moreover, we show that if q is small enough, then it is
possible to cluster in a way correlated with the true partition, even though
the algorithm is exponential in time. In the unlabelled setting, i.e. when only
the tree structure is observed, we show that it is possible to test between
different values of q in a strictly better way than by random guessing. This
follows from a delicate analysis of the sum-of-distances statistic.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:40:37 GMT""}]","2023-05-25"
"2305.15207","Edwin van Dam","Pepijn Wissing and Edwin R. van Dam","Symmetry in complex unit gain graphs and their spectra",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Complex unit gain graphs may exhibit various kinds of symmetry. In this work,
we explore structural symmetry, spectral symmetry and sign-symmetry in gain
graphs, and their respective relations to one-another. Our main result is a
construction that transforms an arbitrary gain graph into infinitely many
switching-distinct gain graphs whose spectral symmetry does not imply
sign-symmetry. This provides a more general answer to the gain graph analogue
of an existence question that was recently treated in the context of signed
graphs.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:42:51 GMT""}]","2023-05-25"
"2305.15208","Michael Deistler","Richard Gao, Michael Deistler, Jakob H. Macke","Generalized Bayesian Inference for Scientific Simulators via Amortized
  Cost Estimation",,,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Simulation-based inference (SBI) enables amortized Bayesian inference for
simulators with implicit likelihoods. But when we are primarily interested in
the quality of predictive simulations, or when the model cannot exactly
reproduce the observed data (i.e., is misspecified), targeting the Bayesian
posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims
to robustify inference for (misspecified) simulator models, replacing the
likelihood-function with a cost function that evaluates the goodness of
parameters relative to data. However, GBI methods generally require running
multiple simulations to estimate the cost function at each parameter value
during inference, making the approach computationally infeasible for even
moderately complex simulators. Here, we propose amortized cost estimation (ACE)
for GBI to address this challenge: We train a neural network to approximate the
cost function, which we define as the expected distance between simulations
produced by a parameter and observed data. The trained network can then be used
with MCMC to infer GBI posteriors for any observation without running
additional simulations. We show that, on several benchmark tasks, ACE
accurately predicts cost and provides predictive simulations that are closer to
synthetic observations than other SBI methods, especially for misspecified
simulators. Finally, we apply ACE to infer parameters of the Hodgkin-Huxley
model given real intracellular recordings from the Allen Cell Types Database.
ACE identifies better data-matching parameters while being an order of
magnitude more simulation-efficient than a standard SBI method. In summary, ACE
combines the strengths of SBI methods and GBI to perform robust and
simulation-amortized inference for scientific simulators.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:45:03 GMT""}]","2023-05-25"
"2305.15209","Graham Manuell","Graham Manuell and Joshua L. Wrigley","The representing localic groupoid for a geometric theory","36 pages",,,,"math.CT math.AG math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an expository, and hopefully approachable, account of the
Joyal-Tierney result that every topos can be represented as a topos of sheaves
on a localic groupoid. We give an explicit presentation of a representing
localic groupoid for the classifying topos of a given geometric theory and
discuss links with the topological groupoids of Forssell.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:45:37 GMT""}]","2023-05-25"
"2305.15210","Matt Franchi","Matt Franchi, J.D. Zamfirescu-Pereira, Wendy Ju, Emma Pierson","Detecting disparities in police deployments using dashcam data","To appear in ACM Conference on Fairness, Accountability, and
  Transparency (FAccT) '23",,"10.1145/3593013.3594020",,"cs.CY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Large-scale policing data is vital for detecting inequity in police behavior
and policing algorithms. However, one important type of policing data remains
largely unavailable within the United States: aggregated police deployment data
capturing which neighborhoods have the heaviest police presences. Here we show
that disparities in police deployment levels can be quantified by detecting
police vehicles in dashcam images of public street scenes. Using a dataset of
24,803,854 dashcam images from rideshare drivers in New York City, we find that
police vehicles can be detected with high accuracy (average precision 0.82, AUC
0.99) and identify 233,596 images which contain police vehicles. There is
substantial inequality across neighborhoods in police vehicle deployment
levels. The neighborhood with the highest deployment levels has almost 20 times
higher levels than the neighborhood with the lowest. Two strikingly different
types of areas experience high police vehicle deployments - 1) dense,
higher-income, commercial areas and 2) lower-income neighborhoods with higher
proportions of Black and Hispanic residents. We discuss the implications of
these disparities for policing equity and for algorithms trained on policing
data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:48:59 GMT""}]","2023-05-25"
"2305.15211","Arpita Mondal","Arghya Choudhury, Sourav Mitra, Arpita Mondal and Subhadeep Mondal","Bilinear R-parity violating supersymmetry under the light of neutrino
  oscillation, higgs and flavor data","35 pages, 9 figures, references added",,,,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  In this work, we explore a well motivated beyond the Standard Model scenario,
namely, R-parity violating Supersymmetry, in the context of light neutrino
masses and mixing. We assume that the R-parity is only broken by the lepton
number violating bilinear term. We try to fit two non-zero neutrino mass square
differences and three mixing angle values obtained from the global $\chi^2$
analysis of neutrino oscillation data. We have also taken into account the
updated data of the standard model (SM) Higgs mass and its coupling strengths
with other SM particles from LHC Run-II along with low energy flavor violating
constraints like rare b-hadron decays. We have used a Markov Chain Monte Carlo
(MCMC) analysis to constrain the new physics parameter space. While doing so,
we ensure that all the existing collider constraints are duly taken into
account. Through our analysis we have derived the most stringent constraints
possible till date with existing data on the 9 bilinear R-parity violating
parameters along with $\mu$ and $\tan\beta$. We further explore the possibility
of explaining the anomalous muon (g - 2) measurement staying within the
parameter space allowed by neutrino, Higgs and flavor data while satisfying the
collider constraints as well. We find that there still remains a small sub-TeV
parameter space where the required excess can be obtained.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:48:59 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 09:53:32 GMT""}]","2023-06-08"
"2305.15212","Zhen-Ru Zhang","Zhen-Ru Zhang, Chuanqi Tan, Haiyang Xu, Chengyu Wang, Jun Huang,
  Songfang Huang","Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model
  Fine-tuning","Accepted to ACL 2023 (Main conference)",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Fine-tuning large pre-trained language models on various downstream tasks
with whole parameters is prohibitively expensive. Hence, Parameter-efficient
fine-tuning has attracted attention that only optimizes a few task-specific
parameters with the frozen pre-trained model. In this work, we focus on prefix
tuning, which only optimizes continuous prefix vectors (i.e. pseudo tokens)
inserted into Transformer layers. Based on the observation that the learned
syntax and semantics representation varies a lot at different layers, we argue
that the adaptive prefix will be further tailored to each layer than the fixed
one, enabling the fine-tuning more effective and efficient. Thus, we propose
Adaptive Prefix Tuning (APT) to adjust the prefix in terms of both fine-grained
token level and coarse-grained layer level with a gate mechanism. Experiments
on the SuperGLUE and NER datasets show the effectiveness of APT. In addition,
taking the gate as a probing, we validate the efficiency and effectiveness of
the variable prefix.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:51:01 GMT""}]","2023-05-25"
"2305.15213","Qian Wang","Wei Zhou, Qian Wang, Weiwei Jin, Xinzhe Shi, Dekui Wang, Xingxing Hao,
  Yongxiang Yu","GTNet: Graph Transformer Network for 3D Point Cloud Classification and
  Semantic Segmentation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, graph-based and Transformer-based deep learning networks have
demonstrated excellent performances on various point cloud tasks. Most of the
existing graph methods are based on static graph, which take a fixed input to
establish graph relations. Moreover, many graph methods apply maximization and
averaging to aggregate neighboring features, so that only a single neighboring
point affects the feature of centroid or different neighboring points have the
same influence on the centroid's feature, which ignoring the correlation and
difference between points. Most Transformer-based methods extract point cloud
features based on global attention and lack the feature learning on local
neighbors. To solve the problems of these two types of models, we propose a new
feature extraction block named Graph Transformer and construct a 3D point point
cloud learning network called GTNet to learn features of point clouds on local
and global patterns. Graph Transformer integrates the advantages of graph-based
and Transformer-based methods, and consists of Local Transformer and Global
Transformer modules. Local Transformer uses a dynamic graph to calculate all
neighboring point weights by intra-domain cross-attention with dynamically
updated graph relations, so that every neighboring point could affect the
features of centroid with different weights; Global Transformer enlarges the
receptive field of Local Transformer by a global self-attention. In addition,
to avoid the disappearance of the gradient caused by the increasing depth of
network, we conduct residual connection for centroid features in GTNet; we also
adopt the features of centroid and neighbors to generate the local geometric
descriptors in Local Transformer to strengthen the local information learning
capability of the model. Finally, we use GTNet for shape classification, part
segmentation and semantic segmentation tasks in this paper.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:51:18 GMT""}]","2023-05-25"
"2305.15214","Michele Pizzochero","Nikita V. Tepliakov, Ruize Ma, Johannes Lischner, Efthimios Kaxiras,
  Arash A. Mostofi, Michele Pizzochero","Dirac half-semimetallicity and antiferromagnetism in graphene
  nanoribbon/hexagonal boron nitride heterojunctions",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Half-metals have been envisioned as active components in spintronic devices
by virtue of their completely spin-polarized electrical currents. Actual
materials hosting half-metallic phases, however, remain scarce. Here, we
predict that recently fabricated heterojunctions of zigzag nanoribbons embedded
in two-dimensional hexagonal boron nitride are half-semimetallic, featuring
fully spin-polarized Dirac points at the Fermi level. The half-semimetallicity
originates from the transfer of charges from hexagonal boron nitride to the
embedded graphene nanoribbon. These charges give rise to opposite energy shifts
of the states residing at the two edges while preserving their intrinsic
antiferromagnetic exchange coupling. Upon doping, an
antiferromagnetic-to-ferrimagnetic phase transition occurs in these
heterojunctions, with the sign of the excess charge controlling the spatial
localization of the net magnetic moments. Our findings demonstrate that such
heterojunctions realize tunable one-dimensional conducting channels of
spin-polarized Dirac fermions that are seamlessly integrated into a
two-dimensional insulator, thus holding promise for the development of
carbon-based spintronics.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:52:07 GMT""}]","2023-05-25"
"2305.15215","Tao Yu","Tao Yu, Toni J.B. Liu, Albert Tseng, Christopher De Sa","Shadow Cones: Unveiling Partial Orders in Hyperbolic Space",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Hyperbolic space has been shown to produce superior low-dimensional
embeddings of hierarchical structures that are unattainable in Euclidean space.
Building upon this, the entailment cone formulation of Ganea et al. uses
geodesically convex cones to embed partial orderings in hyperbolic space.
However, these entailment cones lack intuitive interpretations due to their
definitions via complex concepts such as tangent vectors and the exponential
map in Riemannian space. In this paper, we present shadow cones, an innovative
framework that provides a physically intuitive interpretation for defining
partial orders on general manifolds. This is achieved through the use of
metaphoric light sources and object shadows, inspired by the sun-earth-moon
relationship. Shadow cones consist of two primary classes: umbral and penumbral
cones. Our results indicate that shadow cones offer robust representation and
generalization capabilities across a variety of datasets, such as WordNet and
ConceptNet, thereby outperforming the top-performing entailment cones. Our
findings indicate that shadow cones offer an innovative, general approach to
geometrically encode partial orders, enabling better representation and
analysis of datasets with hierarchical structures.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:52:56 GMT""}]","2023-05-25"
"2305.15216","Tanveer Hussain","Tanveer Hussain, Juan Gallego-Calderon, S M Shafiul Alam","Open Source High Fidelity Modeling of a Type 5 Wind Turbine Drivetrain
  for Grid Integration","This manuscript is originally submitted to Journal of Physics",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing integration of renewable energy resources in evolving bulk
power system (BPS) is impacting the system inertia. Type-5 wind turbine
generation has the potential to behave like a traditional synchronous generator
and can help improve system inertia. Hydraulic torque converter (TC) and
gearbox with torque limiting feature are integral parts of a Type-5 wind
turbine unit. High fidelity model of Type-5 wind turbine including these core
components is not openly and widely available for grid integration and
transient stability studies. This hinders appropriate assessment of Type-5 wind
power plant's contribution to bulk grid resilience. This work develops a TC
model based on those generally used in automobile's transmission system.
Moreover, the concept of torsional coupling is leveraged to integrate the TC
and gearbox system dynamics. The entire integrated model will be open sourced
and publicly available for grid integration studies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:53:06 GMT""}]","2023-05-25"
"2305.15217","Shuchen Weng","Zheng Chang, Shuchen Weng, Peixuan Zhang, Yu Li, Si Li, Boxin Shi","L-CAD: Language-based Colorization with Any-level Descriptions",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Language-based colorization produces plausible and visually pleasing colors
under the guidance of user-friendly natural language descriptions. Previous
methods implicitly assume that users provide comprehensive color descriptions
for most of the objects in the image, which leads to suboptimal performance. In
this paper, we propose a unified model to perform language-based colorization
with any-level descriptions. We leverage the pretrained cross-modality
generative model for its robust language understanding and rich color priors to
handle the inherent ambiguity of any-level descriptions. We further design
modules to align with input conditions to preserve local spatial structures and
prevent the ghosting effect. With the proposed novel sampling strategy, our
model achieves instance-aware colorization in diverse and complex scenarios.
Extensive experimental results demonstrate our advantages of effectively
handling any-level descriptions and outperforming both language-based and
automatic colorization methods. The code and pretrained models are available
at: https://github.com/changzheng123/L-CAD.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:57:42 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 11:37:53 GMT""}]","2023-05-29"
"2305.15218","Hanqi Su","Hanqi Su, Binyang Song and Faez Ahmed","Multi-modal Machine Learning for Vehicle Rating Predictions Using Image,
  Text, and Parametric Data","The paper submitted to IDETC/CIE2023, the International Design
  Engineering Technical Conferences & Computers and Information in Engineering
  Conference, has been accepted",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Accurate vehicle rating prediction can facilitate designing and configuring
good vehicles. This prediction allows vehicle designers and manufacturers to
optimize and improve their designs in a timely manner, enhance their product
performance, and effectively attract consumers. However, most of the existing
data-driven methods rely on data from a single mode, e.g., text, image, or
parametric data, which results in a limited and incomplete exploration of the
available information. These methods lack comprehensive analyses and
exploration of data from multiple modes, which probably leads to inaccurate
conclusions and hinders progress in this field. To overcome this limitation, we
propose a multi-modal learning model for more comprehensive and accurate
vehicle rating predictions. Specifically, the model simultaneously learns
features from the parametric specifications, text descriptions, and images of
vehicles to predict five vehicle rating scores, including the total score,
critics score, performance score, safety score, and interior score. We compare
the multi-modal learning model to the corresponding unimodal models and find
that the multi-modal model's explanatory power is 4% - 12% higher than that of
the unimodal models. On this basis, we conduct sensitivity analyses using SHAP
to interpret our model and provide design and optimization directions to
designers and manufacturers. Our study underscores the importance of the
data-driven multi-modal learning approach for vehicle design, evaluation, and
optimization. We have made the code publicly available at
http://decode.mit.edu/projects/vehicleratings/.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:58:49 GMT""},{""version"":""v2"",""created"":""Sat, 27 May 2023 10:20:16 GMT""}]","2023-05-30"
"2305.15219","Yao Rong","Yao Rong, Xiangyu Wei, Tianwei Lin, Yueyu Wang, Enkelejda Kasneci","DynStatF: An Efficient Feature Fusion Strategy for LiDAR 3D Object
  Detection","Accepted to CVPR2023 Workshop on End-to-End Autonomous Driving",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Augmenting LiDAR input with multiple previous frames provides richer semantic
information and thus boosts performance in 3D object detection, However,
crowded point clouds in multi-frames can hurt the precise position information
due to the motion blur and inaccurate point projection. In this work, we
propose a novel feature fusion strategy, DynStaF (Dynamic-Static Fusion), which
enhances the rich semantic information provided by the multi-frame (dynamic
branch) with the accurate location information from the current single-frame
(static branch). To effectively extract and aggregate complimentary features,
DynStaF contains two modules, Neighborhood Cross Attention (NCA) and
Dynamic-Static Interaction (DSI), operating through a dual pathway
architecture. NCA takes the features in the static branch as queries and the
features in the dynamic branch as keys (values). When computing the attention,
we address the sparsity of point clouds and take only neighborhood positions
into consideration. NCA fuses two features at different feature map scales,
followed by DSI providing the comprehensive interaction. To analyze our
proposed strategy DynStaF, we conduct extensive experiments on the nuScenes
dataset. On the test set, DynStaF increases the performance of PointPillars in
NDS by a large margin from 57.7% to 61.6%. When combined with CenterPoint, our
framework achieves 61.0% mAP and 67.7% NDS, leading to state-of-the-art
performance without bells and whistles.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:00:01 GMT""}]","2023-05-25"
"2305.15220","Caitlin Grasso","Caitlin Grasso and Josh Bongard","Selection for short-term empowerment accelerates the evolution of
  homeostatic neural cellular automata","To be published in the Proceedings of the Genetic and Evolutionary
  Computation Conference 2023 (GECCO'23), 8 pages, 9 figures",,"10.1145/3583131.3590469",,"cs.NE cs.AI cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Empowerment -- a domain independent, information-theoretic metric -- has
previously been shown to assist in the evolutionary search for neural cellular
automata (NCA) capable of homeostasis when employed as a fitness function. In
our previous study, we successfully extended empowerment, defined as maximum
time-lagged mutual information between agents' actions and future sensations,
to a distributed sensorimotor system embodied as an NCA. However, the
time-delay between actions and their corresponding sensations was arbitrarily
chosen. Here, we expand upon previous work by exploring how the time scale at
which empowerment operates impacts its efficacy as an auxiliary objective to
accelerate the discovery of homeostatic NCAs. We show that shorter time delays
result in marked improvements over empowerment with longer delays, when
compared to evolutionary selection only for homeostasis. Moreover, we evaluate
stability and adaptability of evolved NCAs, both hallmarks of living systems
that are of interest to replicate in artificial ones. We find that short-term
empowered NCA are more stable and are capable of generalizing better to unseen
homeostatic challenges. Taken together, these findings motivate the use of
empowerment during the evolution of other artifacts, and suggest how it should
be incorporated to accelerate evolution of desired behaviors for them. Source
code for the experiments in this paper can be found at:
https://github.com/caitlingrasso/empowered-nca-II.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:01:30 GMT""}]","2023-05-25"
"2305.15221","Kenneth Dere","Kenneth Dere, Peter Young, Giulio Del Zanna, Enrico Landi","CHIANTI -- an atomic database for emission lines -- Paper XVII: Version
  10.1, revised ionization and recombination rates and other updates","24 pages, 18 figures, submitted to The Astrophysical Journal
  Supplement Series",,,,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The CHIANTI atomic database provides sets of assessed data used for
simulating spectral observations of astrophysical plasmas. This article
describes updates that will be released as version~10.1 of the database. A key
component of CHIANTI is the provision of ionization and recombination rates
that are used to compute the ionization balance of a plasma over a range of
temperatures. Parameters for calculating the ionization rates of all stages of
ions from H through Zn were compiled and inserted into the CHIANTI database in
2009. These were based on all measurements that were available at the time and
supplemented with distorted wave calculations. Since then, there have been a
number of new laboratory measurements for ions that produce spectral lines that
are commonly observed. Parameters have been fit to these new measurements to
provide improved ability to reproduce the ionization cross sections and rate
coefficients, and these are added to the database. CHIANTI 10.1 also includes
new recombination rates for the phosphorus isoelectronic sequence, and the
updated ionization and recombination rates have been used to calculate a new
ionization equilibrium file. In addition, CHIANTI 10.1 has new electron
collision and radiative datasets for eight ions in the nitrogen and oxygen
isoelectronic sequences, and updated energy level and wavelength data for seven
other ions.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:03:37 GMT""}]","2023-05-25"
"2305.15222","Koyena Pal","Koyena Pal, Seyed Ali Bahrainian, Laura Mercurio, Carsten Eickhoff","Neural Summarization of Electronic Health Records",,,,,"cs.CL cs.AI cs.IR","http://creativecommons.org/licenses/by/4.0/","  Hospital discharge documentation is among the most essential, yet
time-consuming documents written by medical practitioners. The objective of
this study was to automatically generate hospital discharge summaries using
neural network summarization models. We studied various data preparation and
neural network training techniques that generate discharge summaries. Using
nursing notes and discharge summaries from the MIMIC-III dataset, we studied
the viability of the automatic generation of various sections of a discharge
summary using four state-of-the-art neural network summarization models (BART,
T5, Longformer and FLAN-T5). Our experiments indicated that training
environments including nursing notes as the source, and discrete sections of
the discharge summary as the target output (e.g. ""History of Present Illness"")
improve language model efficiency and text quality. According to our findings,
the fine-tuned BART model improved its ROUGE F1 score by 43.6% against its
standard off-the-shelf version. We also found that fine-tuning the baseline
BART model with other setups caused different degrees of improvement (up to 80%
relative improvement). We also observed that a fine-tuned T5 generally achieves
higher ROUGE F1 scores than other fine-tuned models and a fine-tuned FLAN-T5
achieves the highest ROUGE score overall, i.e., 45.6. For majority of the
fine-tuned language models, summarizing discharge summary report sections
separately outperformed the summarization the entire report quantitatively. On
the other hand, fine-tuning language models that were previously instruction
fine-tuned showed better performance in summarizing entire reports. This study
concludes that a focused dataset designed for the automatic generation of
discharge summaries by a language model can produce coherent Discharge Summary
sections.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:05:53 GMT""}]","2023-05-25"
"2305.15223","Yuzhu Han","Qian Zhang and Yuzhu Han","Existence of nontrivial solutions to a fourth-order Kirchhoff type
  elliptic equation with critical exponent",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a critical fourth-order Kirchhoff type elliptic equation with
a subcritical perturbation is studied. The main feature of this problem is that
it involves both a nonlocal coefficient and a critical term, which bring
essential difficulty for the proof of the existence of weak solutions. When the
dimension of the space is smaller than or equals to $7$, the existence of weak
solution is obtained by combining the Mountain Pass Lemma with some delicate
estimate on the Talenti's functions. When the dimension of the space is larger
than or equals to $8$, the above argument no longer works. By introducing an
appropriate truncation on the nonlocal coefficient, it is shown that the
problem admits a nontrivial solution under appropriate conditions on the
parameter.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:06:20 GMT""}]","2023-05-25"
"2305.15224","Alexander Cliffe","Gui-Qiang G. Chen, Alexander Cliffe, Feimin Huang, Song Liu, Qin Wang","Global Solutions of the Two-Dimensional Riemann Problem with Four-Shock
  Interactions for the Euler Equations for Potential Flow","75 pages, 7 figures",,,,"math.AP math-ph math.MP physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We present a rigorous approach and related techniques to construct global
solutions of the 2-D Riemann problem with four-shock interactions for the Euler
equations for potential flow. With the introduction of three critical angles:
the vacuum critical angle from the compatibility conditions, the detachment
angle, and the sonic angle, we clarify all configurations of the Riemann
solutions for the interactions of two-forward and two-backward shocks,
including the subsonic-subsonic reflection configuration that has not emerged
in previous results. To achieve this, we first identify the three critical
angles that determine the configurations, whose existence and uniqueness follow
from our rigorous proof of the strict monotonicity of the steady detachment and
sonic angles for 2-D steady potential flow with respect to the Mach number of
the upstream state. Then we reformulate the 2-D Riemann problem into the shock
reflection-diffraction problem with respect to a symmetric line, along with two
independent incident angles and two sonic boundaries varying with the choice of
incident angles. With these, the problem can be further reformulated as a free
boundary problem for a second-order quasilinear equation of mixed
elliptic-hyperbolic type. The difficulties arise from the degenerate
ellipticity of the nonlinear equation near the sonic boundaries, the
nonlinearity of the free boundary condition, the singularity of the solution
near the corners of the domain, and the geometric properties of the free
boundary. To the best of our knowledge, this is the first rigorous result for
the 2-D Riemann problem with four-shock interactions for the Euler equations.
The approach and techniques developed for the Riemann problem for four-wave
interactions should be useful for solving other 2-D Riemann problems for more
general Euler equations and related nonlinear hyperbolic systems of
conservation laws.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:06:53 GMT""}]","2023-05-25"
"2305.15225","Hongyin Luo","Hongyin Luo, Yung-Sung Chuang, Yuan Gong, Tianhua Zhang, Yoon Kim,
  Xixin Wu, Danny Fox, Helen Meng, James Glass","SAIL: Search-Augmented Instruction Learning",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large language models (LLMs) have been significantly improved by instruction
fine-tuning, but still lack transparency and the ability to utilize up-to-date
knowledge and information. In this work, we propose search-augmented
instruction learning (SAIL), which grounds the language generation and
instruction following abilities on complex search results generated by in-house
and external search engines. With an instruction tuning corpus, we collect
search results for each training case from different search APIs and domains,
and construct a new search-grounded training set containing
\textit{(instruction, grounding information, response)} triplets. We then
fine-tune the LLaMA-7B model on the constructed training set. Since the
collected results contain unrelated and disputing languages, the model needs to
learn to ground on trustworthy search results, filter out distracting passages,
and generate the target response. The search result-denoising process entails
explicit trustworthy information selection and multi-hop reasoning, since the
retrieved passages might be informative but not contain the
instruction-following answer. Experiments show that the fine-tuned SAIL-7B
model has a strong instruction-following ability, and it performs significantly
better on transparency-sensitive tasks, including open-ended question answering
and fact checking.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:07:30 GMT""}]","2023-05-25"
"2305.15226","Matteo Baggioli","Matteo Baggioli","Topological defects reveal the plasticity of glasses","News and Views commentary for the paper by Wu et Al. [Nat Commun 14,
  2955 (2023)]","Nat Commun 14, 2956 (2023)","10.1038/s41467-023-38549-8",,"cond-mat.soft cond-mat.dis-nn cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Mixing theoretical topological structures with cutting-edge simulation
methods, a recent study in Nature Communications has finally confirmed the
existence of topological defects in glasses and their crucial role for
plasticity.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:08:36 GMT""}]","2023-05-25"
"2305.15227","Anja Deli\'c","Anja Deli\'c and Matej Grci\'c and Sini\v{s}a \v{S}egvi\'c","Real time dense anomaly detection by learning on synthetic negative data","3 pages",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Most approaches to dense anomaly detection rely on generative modeling or on
discriminative methods that train with negative data. We consider a recent
hybrid method that optimizes the same shared representation according to
cross-entropy of the discriminative predictions, and negative log likelihood of
the predicted energy-based density. We extend that work with a jointly trained
generative flow that samples synthetic negatives at the border of the inlier
distribution. The proposed extension provides potential to learn the hybrid
method without real negative data. Our experiments analyze the impact of
training with synthetic negative data and validate contribution of the
energy-based density during training and evaluation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:09:41 GMT""}]","2023-05-25"
"2305.15228","Daniel Kelshaw","Daniel Kelshaw, Luca Magri","Short and Straight: Geodesics on Differentiable Manifolds",,,,,"cs.LG cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Manifolds discovered by machine learning models provide a compact
representation of the underlying data. Geodesics on these manifolds define
locally length-minimising curves and provide a notion of distance, which are
key for reduced-order modelling, statistical inference, and interpolation. In
this work, we first analyse existing methods for computing length-minimising
geodesics. We find that these are not suitable for obtaining valid paths, and
thus, geodesic distances. We remedy these shortcomings by leveraging numerical
tools from differential geometry, which provide the means to obtain
Hamiltonian-conserving geodesics. Second, we propose a model-based
parameterisation for distance fields and geodesic flows on continuous
manifolds. Our approach exploits a manifold-aware extension to the Eikonal
equation, eliminating the need for approximations or discretisation. Finally,
we develop a curvature-based training mechanism, sampling and scaling points in
regions of the manifold exhibiting larger values of the Ricci scalar. This
sampling and scaling approach ensures that we capture regions of the manifold
subject to higher degrees of geodesic deviation. Our proposed methods provide
principled means to compute valid geodesics and geodesic distances on
manifolds. This work opens opportunities for latent-space interpolation,
optimal control, and distance computation on differentiable manifolds.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:09:41 GMT""}]","2023-05-25"
"2305.15229","Rhiannon Griffiths","Rhiannon Griffiths","Higher Categories and Slices of Globular Operads","arXiv admin note: text overlap with arXiv:2101.00077",,,,"math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In an unpublished preprint \cite{batanin}, Batanin conjectures that it is
possible to take `slices' of a globular operad, thereby isolating the algebraic
structure in each dimension. It was further hypothesised that the slices of a
globular operad for some theory of higher category contain essential
information about those higher categories, namely whether or not they are
equivalent to the fully weak variety. In this paper, we use the theory of
presentations for globular operads developed in \cite{Me} to provide a concrete
definition of slices, and calculate the slices for several key theories of
$n$-category.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:11:12 GMT""}]","2023-05-25"
"2305.15230","Ron Folman","Carsten Henkel and Ron Folman","Universal limit on spatial quantum superpositions with massive objects
  due to phonons",,,,,"quant-ph gr-qc physics.atom-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The superposition principle is one of the founding principles of quantum
theory. Spatial quantum superpositions have so far been tested only with small
systems, from photons and elementary particles to atoms and molecules. Such
superpositions for massive objects have been a long-standing sought-after goal.
This is important not only in order to confirm quantum theory in new regimes,
but also in order to probe the quantum-gravity interface. In addition, such an
experiment will enable to test exotic theories, and may even enable new
technology. Creating such superpositions is notoriously hard because of
environmental decoherence, whereby the large object couples strongly to the
environment which turns the delicate quantum state into a statistical mixture
(classical state). However, advances in the technology of isolation could in
future suppress such decoherence. Here we present a decoherence channel which
is not external but internal to the object, and consequently improved isolation
would not help. This channel originates from the phonons (sound waves) within
the object. We show that such phonons are excited as part of any splitting
process, and thus we establish a fundamental and universal limit on the
possibility of future spatial quantum superpositions with massive objects.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:13:05 GMT""}]","2023-05-25"
"2305.15231","Madalina Erascu","Bogdan David and Madalina Erascu","Benchmarking Optimization Solvers and Symmetry Breakers for the
  Automated Deployment of Component-based Applications in the Cloud (EXTENDED
  ABSTRACT)","Presented at 7th International Workshop on Satisfiability Checking
  and Symbolic Computation (SC-square), Part of IJCAR 22, at FLOC 2022, August
  12, 2022, Haifa, Israel. arXiv admin note: substantial text overlap with
  arXiv:2006.05401",,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Optimization solvers based on methods from constraint programming (OR-Tools,
Chuffed, Gecode), optimization modulo theory (Z3), and mathematical programming
(CPLEX) are successfully applied nowadays to solve many non-trivial examples.
However, for solving the problem of automated deployment in the Cloud of
component-based applications, their computational requirements are huge making
automatic optimization practically impossible with the current general
optimization techniques. To overcome the difficulty, we exploited the sweet
spots of the underlying problem in order to identify search space reduction
methods. We came up with 15 symmetry breaking strategies which we tested in a
static symmetry breaking setting on the solvers enumerated above and on 4
classes of problems. As a result, all symmetry breaking strategies led to
significant improvement of the computational time of all solvers, most notably,
Z3 performed the best compared to the others. As an observation, the symmetry
breaking strategies confirmed that, when applied in a static setting, they may
interact badly with the underlying techniques implemented by the solvers.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:13:41 GMT""}]","2023-05-25"
"2305.15232","Ernesto Contreras","A. Di Teodoro, E. Contreras","A vacuum solution of modified Einstein equations based on fractional
  calculus",,"Eur. Phys. J. C (2023) 83:434","10.1140/epjc/s10052-023-11626-4",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we construct a modified version of the Einstein field equations
for a vacuum and spherically symmetric spacetime in terms of the
Riemann-Louville fractional derivative. The main difference between our
approach and other works is that we ensure that both the classical differential
equations and the classical solutions are exactly recovered in the limit when
the fractional parameter is turned off. We assume that the fractional equations
are valid inside and near the horizon radius and match the classical solution
at the horizon. Our approach resembles the Herrera--Witten strategy shown in
Adv.High Energy Phys. 2018 (2018) 3839103, where the authors constructed an
alternative black hole solution by assuming that inside the horizon the
spacetime is hyperbolically symmetric and matches the classical spherically
symmetric exterior solution at one point at the horizon. We obtain that,
depending on the value of the fractional parameter, the solutions can be
interpreted as a regular black hole or a gravatar. As a final step, we compute
the fractional curvature scalars and show that the solution is regular
everywhere inside the horizon.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:13:59 GMT""}]","2023-05-25"
"2305.15233","Sunkyoung Kim","Sunkyoung Kim, Dayeon Ki, Yireun Kim, Jinsik Lee","Boosting Cross-lingual Transferability in Multilingual Models via
  In-Context Learning","Work In Progress",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Existing cross-lingual transfer (CLT) prompting methods are only concerned
with monolingual demonstration examples in the source language. In this paper,
we propose In-CLT, a novel cross-lingual transfer prompting method that
leverages both source and target languages to construct the demonstration
examples. We conduct comprehensive evaluations on multilingual benchmarks,
focusing on question answering tasks. Experiment results show that In-CLT
prompt not only improves multilingual models' cross-lingual transferability,
but also demonstrates remarkable unseen language generalization ability. In-CLT
prompting, in particular, improves model performance by 10 to 20\% points on
average when compared to prior cross-lingual transfer approaches. We also
observe the surprising performance gain on the other multilingual benchmarks,
especially in reasoning tasks. Furthermore, we investigate the relationship
between lexical similarity and pre-training corpora in terms of the
cross-lingual transfer gap.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:14:49 GMT""}]","2023-05-25"
"2305.15234","Natalia Vesselinova","Natalia Vassileva Vesselinova","On the road to more accurate mobile cellular traffic predictions",,,,,"cs.LG cs.NI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The main contribution reported in the paper is a novel paradigm through which
mobile cellular traffic forecasting is made substantially more accurate.
Specifically, by incorporating freely available road metrics we characterise
the data generation process and spatial dependencies. Therefore, this provides
a means for improving the forecasting estimates. We employ highway flow and
average speed variables together with a cellular network traffic metric in a
light learning structure to predict the short-term future load on a cell
covering a segment of a highway. This is in sharp contrast to prior art that
mainly studies urban scenarios (with pedestrian and limited vehicular speeds)
and develops machine learning approaches that use exclusively network metrics
and meta information to make mid-term and long-term predictions. The learning
structure can be used at a cell or edge level, and can find application in both
federated and centralised learning.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:18:46 GMT""}]","2023-05-25"
"2305.15235","Jiatu Li","Jiatu Li and Igor Carboni Oliveira","Unprovability of Strong Complexity Lower Bounds in Bounded Arithmetic","full version of a conference paper to appear in STOC 2023",,,,"cs.CC cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While there has been progress in establishing the unprovability of complexity
statements in lower fragments of bounded arithmetic, understanding the limits
of Je\v{r}\'abek's theory $APC_1$ (2007) and of higher levels of Buss's
hierarchy $S^i_2$ (1986) has been a more elusive task. Even in the more
restricted setting of Cook's theory PV (1975), known results often rely on a
less natural formalization that encodes a complexity statement using a
collection of sentences instead of a single sentence. This is done to reduce
the quantifier complexity of the resulting sentences so that standard
witnessing results can be invoked.
  In this work, we establish unprovability results for stronger theories and
for sentences of higher quantifier complexity. In particular, we
unconditionally show that $APC_1$ cannot prove strong complexity lower bounds
separating the third level of the polynomial hierarchy. In more detail, we
consider non-uniform average-case separations, and establish that $APC_1$
cannot prove a sentence stating that $\forall n \ge n_0\;\exists\,f_n \in
\Pi_{3}$-$SIZE[n^d]$ that is $(1/n)$-far from every
$\Sigma_{3}$-$SIZE[2^{n^{\delta}}]$ circuit. This is a consequence of a much
more general result showing that, for every $i \geq 1$, strong separations for
$\Pi_{i}$-$SIZE[poly(n)]$ versus $\Sigma_{i}$-$SIZE[2^{n^{\Omega(1)}}]$ cannot
be proved in the theory $T_{PV}^i$ consisting of all true $\forall
\Sigma^b_{i-1}$-sentences in the language of Cook's theory PV.
  Our argument employs a convenient game-theoretic witnessing result that can
be applied to sentences of arbitrary quantifier complexity. We combine it with
extensions of a technique introduced by Kraj\'i\v{c}ek (2011) that was recently
employed by Pich and Santhanam (2021) to establish the unprovability of lower
bounds in PV (i.e., the case $i=1$ above, but under a weaker formalization) and
in a fragment of $APC_1$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:19:44 GMT""}]","2023-05-25"
"2305.15236","Ettore Vicari","Claudio Bonati, Andrea Pelissetto, Ettore Vicari","The Coulomb-Higgs phase transition of three-dimensional lattice
  Abelian-Higgs gauge models with noncompact gauge variables and gauge fixing","14 pages",,,,"cond-mat.stat-mech hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the critical behavior of three-dimensional (3D) lattice
Abelian-Higgs (AH) gauge models with noncompact gauge variables and
multicomponent complex scalar fields, along the transition line between the
Coulomb and Higgs phases. Previous works that focused on gauge-invariant
correlations provided evidence that, for a sufficiently large number of scalar
components, these transitions are continuous and associated with the stable
charged fixed point of the renormalization-group flow of the 3D AH field theory
(scalar electrodynamics), in which charged scalar matter is minimally coupled
with an electromagnetic field. Here we extend these studies by considering
gauge-dependent correlations of the gauge and matter fields, in the presence of
two different gauge fixings, the Lorenz and the axial gauge fixing. Our results
for N=25 are definitely consistent with the predictions of the AH field theory
and therefore provide additional evidence for the characterization of the 3D AH
transitions along the Coulomb-Higgs line as charged transitions in the AH
field-theory universality class. Moreover, our results give additional insights
on the role of the gauge fixing at charged transitions. In particular, we show
that scalar correlations are critical only if a hard Lorenz gauge fixing is
imposed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:19:53 GMT""}]","2023-05-25"
"2305.15237","Ramy Taki Eldin F.","Ramy Taki Eldin and Patrick Sole","Generator polynomial matrices of the Galois hulls of multi-twisted codes",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we consider the Euclidean and Galois hulls of multi-twisted
(MT) codes over a finite field $\mathbb{F}_{p^e}$ of characteristic $p$. Let
$\mathbf{G}$ be a generator polynomial matrix (GPM) of a MT code $\mathcal{C}$.
For any $0\le \kappa<e$, the $\kappa$-Galois hull of $\mathcal{C}$, denoted by
$h_\kappa\left(\mathcal{C}\right)$, is the intersection of $\mathcal{C}$ with
its $\kappa$-Galois dual. The main result in this paper is that a GPM for
$h_\kappa\left(\mathcal{C}\right)$ has been obtained from $\mathbf{G}$. We
start by associating a linear code $\mathcal{Q}_\mathbf{G}$ with $\mathbf{G}$.
We show that $\mathcal{Q}_\mathbf{G}$ is quasi-cyclic. In addition, we prove
that the dimension of $h_\kappa\left(\mathcal{C}\right)$ is the difference
between the dimension of $\mathcal{C}$ and that of $\mathcal{Q}_\mathbf{G}$.
Thus the determinantal divisors are used to derive a formula for the dimension
of $h_\kappa\left(\mathcal{C}\right)$. Finally, we deduce a GPM formula for
$h_\kappa\left(\mathcal{C}\right)$. In particular, we handle the cases of
$\kappa$-Galois self-orthogonal and linear complementary dual MT codes; we
establish equivalent conditions that characterize these cases. Equivalent
results can be deduced immediately for the classes of cyclic, constacyclic,
quasi-cyclic, generalized quasi-cyclic, and quasi-twisted codes, because they
are all special cases of MT codes. Some numerical examples, containing optimal
and maximum distance separable codes, are used to illustrate the theoretical
results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:20:45 GMT""}]","2023-05-25"
"2305.15238","Alessandra Fumagalli","Alessandra Fumagalli, Yodovina Pi\v{s}kur, An\v{z}e Slosar","Superhorizon isocurvature fluctuations relax tensions","14 pages, 7 figures",,,,"astro-ph.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a new class of models that have potential to alleviate tensions
present in the cosmological data today. We postulate variation in the sound
horizon scale on super-horizon scales, i.e. on scales that are larger than that
of the present observable low-redshift universe ($\gtrsim 1\,$Gpc) while at the
same time smaller than the largest scales probed by the cosmic microwave
background (CMB) ($\lesssim10\,$Gpc). In this scenario, CMB peaks are naturally
smoothed as preferred by the Planck data, while at the same time the
low-redshift baryon acoustic oscillation calibration is partially decoupled
from the CMB. Taking super-horizon variations in baryon fraction as an example
and using approximate modeling, we find improvement in the best fit Planck
power spectrum model $\Delta \chi^2 \sim 6$ for one extra degree of freedom
with the relevant extension parameter $10^3 \sigma_b = 2.12 \pm 0.50 $,
implying about $10\%$ variations in baryon fraction across the universe. At the
same time, $S_8$ drops by about 1 sigma, easing tension with weak lensing
surveys. While $H_0$ increases in this model by about 1 sigma, this is
insufficient to explain the Hubble tension in $\Lambda$CDM. Since the power of
low redshift BAO is relaxed, we find that the combination of Planck 2018 data,
eBOSS BAO data and Riess et al distance ladder Hubble parameter determination
produces a satisfactory fit in the model with free dark energy equation of
state. Such a fit, however, favors a phantom dark energy equation of state
$w<-1$ at 2-3 sigma.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:22:09 GMT""}]","2023-05-25"
"2305.15239","Travis LaCroix","Travis LaCroix and Simon J. D. Prince","Ethics and Deep Learning","Copyright in this Work has been licensed exclusively to The MIT
  Press, https://mitpress.mit.edu, which will be releasing the final version to
  the public in 2023. All inquiries regarding rights should be addressed to The
  MIT Press, Rights and Permissions Department",,,,"cs.AI cs.CY cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article appears as chapter 21 of Prince (2023, Understanding Deep
Learning); a complete draft of the textbook is available here:
http://udlbook.com. This chapter considers potential harms arising from the
design and use of AI systems. These include algorithmic bias, lack of
explainability, data privacy violations, militarization, fraud, and
environmental concerns. The aim is not to provide advice on being more ethical.
Instead, the goal is to express ideas and start conversations in key areas that
have received attention in philosophy, political science, and the broader
social sciences.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:24:19 GMT""}]","2023-05-25"
"2305.15240","Tomas Lazna","Tomas Lazna, Ludek Zalud","Localizing Multiple Radiation Sources Actively with a Particle Filter","9 pages, 2 tables, 3 figures; submitted to IEEE RA-L",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The article discusses the localization of radiation sources whose number and
other relevant parameters are not known in advance. The data collection is
ensured by an autonomous mobile robot that performs a survey in a defined
region of interest populated with static obstacles. The measurement trajectory
is information-driven rather than pre-planned. The localization exploits a
regularized particle filter estimating the sources' parameters continuously.
The dynamic robot control switches between two modes, one attempting to
minimize the Shannon entropy and the other aiming to reduce the variance of
expected measurements in unexplored parts of the target area; both of the modes
maintain safe clearance from the obstacles. The performance of the algorithms
was tested in a simulation study based on real-world data acquired previously
from three radiation sources exhibiting various activities. Our approach
reduces the time necessary to explore the region and to find the sources by
approximately 40 %; at present, however, the method is unable to reliably
localize sources that have a relatively low intensity. In this context,
additional research has been planned to increase the credibility and robustness
of the procedure and to improve the robotic platform autonomy.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:24:42 GMT""}]","2023-05-25"
"2305.15241","Huanran Chen","Huanran Chen, Yinpeng Dong, Zhengyi Wang, Xiao Yang, Chengqi Duan,
  Hang Su, Jun Zhu","Robust Classification via a Single Diffusion Model",,,,,"cs.CV cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, diffusion models have been successfully applied to improving
adversarial robustness of image classifiers by purifying the adversarial noises
or generating realistic data for adversarial training. However, the
diffusion-based purification can be evaded by stronger adaptive attacks while
adversarial training does not perform well under unseen threats, exhibiting
inevitable limitations of these methods. To better harness the expressive power
of diffusion models, in this paper we propose Robust Diffusion Classifier
(RDC), a generative classifier that is constructed from a pre-trained diffusion
model to be adversarially robust. Our method first maximizes the data
likelihood of a given input and then predicts the class probabilities of the
optimized input using the conditional likelihood of the diffusion model through
Bayes' theorem. Since our method does not require training on particular
adversarial attacks, we demonstrate that it is more generalizable to defend
against multiple unseen threats. In particular, RDC achieves $73.24\%$ robust
accuracy against $\ell_\infty$ norm-bounded perturbations with
$\epsilon_\infty=8/255$ on CIFAR-10, surpassing the previous state-of-the-art
adversarial training models by $+2.34\%$. The findings highlight the potential
of generative classifiers by employing diffusion models for adversarial
robustness compared with the commonly studied discriminative classifiers.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:25:19 GMT""}]","2023-05-25"
"2305.15242","Luciano Floridi","Luciano Floridi","Machine Unlearning: its nature, scope, and importance for a ""delete
  culture""",,,,,"cs.CY cs.LG","http://creativecommons.org/licenses/by/4.0/","  The article explores the cultural shift from recording to deleting
information in the digital age and its implications on privacy, intellectual
property (IP), and Large Language Models like ChatGPT. It begins by defining a
delete culture where information, in principle legal, is made unavailable or
inaccessible because unacceptable or undesirable, especially but not only due
to its potential to infringe on privacy or IP. Then it focuses on two
strategies in this context: deleting, to make information unavailable; and
blocking, to make it inaccessible. The article argues that both strategies have
significant implications, particularly for machine learning (ML) models where
information is not easily made unavailable. However, the emerging research area
of Machine Unlearning (MU) is highlighted as a potential solution. MU, still in
its infancy, seeks to remove specific data points from ML models, effectively
making them 'forget' completely specific information. If successful, MU could
provide a feasible means to manage the overabundance of information and ensure
a better protection of privacy and IP. However, potential ethical risks, such
as misuse, overuse, and underuse of MU, should be systematically studied to
devise appropriate policies.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:27:04 GMT""}]","2023-05-25"
"2305.15243","Jacob B Khurgin","Jacob B Khurgin","Photonic Time Crystals and Parametric Amplification: similarity and
  distinction",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Photonic Time crystals (PTC) arise in time-modulated media when the frequency
of modulation of permittivity is on the order of twice the frequency of light
and are manifested by the generation and amplification of so-called time
reversed waves propagating in the direction opposite to the incoming light.
Superficially, the observed phenomenon bears resemblance to the widely known
phenomena of optical parametric generation (OPG) and amplification (OPA) using
second or third order optical nonlinearities. I show that while indeed the same
physical mechanism underpins both PTC and OPA , the difference arises from the
boundary conditions. Thus , while dispersion for both PTC and OPA exhibit the
same bandgap in momentum space, only in the case of PTC can one have
propagation in that bandgap with exponential amplification. I also show that
PTC can be engineered with both second and third order nonlinearities, and that
rather unexpectedly, modulating permittivity on the ultrafast (few fs) rate is
not a necessity, and that one can emulate all the PTC features using materials
with a few picoseconds response time commensurate with the propagation time
through the medium.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:29:29 GMT""}]","2023-05-25"
"2305.15244","Daniel Layeghi","Daniel Layeghi, Steve Tonneau, Michael Mistry","Neural Lyapunov and Optimal Control",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  Optimal control (OC) is an effective approach to controlling complex
dynamical systems. However, traditional approaches to parameterising and
learning controllers in optimal control have been ad-hoc, collecting data and
fitting it to neural networks. However, this can lead to learnt controllers
ignoring constraints like optimality and time variability. We introduce a
unified framework that simultaneously solves control problems while learning
corresponding Lyapunov or value functions. Our method formulates OC-like
mathematical programs based on the Hamilton-Jacobi-Bellman (HJB) equation. We
leverage the HJB optimality constraint and its relaxation to learn time-varying
value and Lyapunov functions, implicitly ensuring the inclusion of constraints.
We show the effectiveness of our approach on linear and nonlinear
control-affine problems. Additionally, we demonstrate significant reductions in
planning horizons (up to a factor of 25) when incorporating the learnt
functions into Model Predictive Controllers.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:29:59 GMT""}]","2023-05-25"
"2305.15245","Fu Xing Long","Fu Xing Long, Diederick Vermetten, Anna V. Kononova, Roman Kalkreuth,
  Kaifeng Yang, Thomas B\""ack, Niki van Stein","Challenges of ELA-guided Function Evolution using Genetic Programming",,,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the optimization community, the question of how to generate new
optimization problems has been gaining traction in recent years. Within topics
such as instance space analysis (ISA), the generation of new problems can
provide new benchmarks which are not yet explored in existing research. Beyond
that, this function generation can also be exploited for solving complex
real-world optimization problems. By generating functions with similar
properties to the target problem, we can create a robust test set for algorithm
selection and configuration.
  However, the generation of functions with specific target properties remains
challenging. While features exist to capture low-level landscape properties,
they might not always capture the intended high-level features. We show that a
genetic programming (GP) approach guided by these exploratory landscape
analysis (ELA) properties is not always able to find satisfying functions. Our
results suggest that careful considerations of the weighting of landscape
properties, as well as the distance measure used, might be required to evolve
functions that are sufficiently representative to the target landscape.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:31:01 GMT""}]","2023-05-25"
"2305.15246","B\'alint Vet\H{o}","B\'alint Vet\H{o} and B\'alint Vir\'ag","The geometry of coalescing random walks, the Brownian web distance and
  KPZ universality","33 pages, 2 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coalescing simple random walks in the plane form an infinite tree. A natural
directed distance on this tree is given by the number of jumps between branches
when one is only allowed to move in one direction. The Brownian web distance is
the scale-invariant limit of this directed metric. It is integer-valued and has
scaling exponents 0:1:2 as compared to 1:2:3 in the KPZ world. However, we show
that the shear limit of the Brownian web distance is still given by the Airy
process. We conjecture that our limit theorem can be extended to the full
directed landscape.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:31:18 GMT""}]","2023-05-25"
"2305.15247","Anna Nickolaevna Morozovska","Anna N. Morozovska, Eugene A. Eliseev, Yongtao Liu, Kyle P. Kelley,
  Ayana Ghosh, Ying Liu, Jinyuan Yao, Nicholas V. Morozovsky, Andrei L Kholkin,
  Yulian M. Vysochanskii, and Sergei V. Kalinin","Bending-induced isostructural transitions in ultrathin layers of van der
  Waals ferrielectrics","26 pages, 7 figures and Appendices A-C",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using Landau-Ginzburg-Devonshire (LGD) phenomenological approach we analyze
the bending-induced re-distribution of electric polarization and field, elastic
stresses and strains inside ultrathin layers of van der Waals ferrielectrics.
We consider a CuInP2S6 (CIPS) thin layer with fixed edges and suspended central
part, the bending of which is induced by external forces. The unique aspect of
CIPS is the existence of two ferrielectric states, FI1 and FI2, corresponding
to big and small polarization values, which arise due to the specific four-well
potential of the eighth-order LGD functional. When the CIPS layer is flat, the
single-domain FI1 state is stable in the central part of the layer, and the FI2
states are stable near the fixed edges. With an increase of the layer bending
below the critical value, the sizes of the FI2 states near the fixed edges
decreases, and the size of the FI1 region increases. When the bending exceeds
the critical value, the edge FI2 states disappear being substituted by the FI1
state, but they appear abruptly near the inflection regions and expand as the
bending increases. The bending-induced isostructural FI1-FI2 transition is
specific for the bended van der Waals ferrielectrics described by the eighth
(or higher) order LGD functional with consideration of linear and nonlinear
electrostriction couplings. The isostructural transition, which is revealed in
the vicinity of room temperature, can significantly reduce the coercive voltage
of ferroelectric polarization reversal in CIPS nanoflakes, allowing for the
curvature-engineering control of various flexible nanodevices.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:31:36 GMT""}]","2023-05-25"
"2305.15248","Cheng-Ze Lu","Cheng-Ze Lu, Xiaojie Jin, Qibin Hou, Jun Hao Liew, Ming-Ming Cheng,
  Jiashi Feng","Delving Deeper into Data Scaling in Masked Image Modeling",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding whether self-supervised learning methods can scale with
unlimited data is crucial for training large-scale models. In this work, we
conduct an empirical study on the scaling capability of masked image modeling
(MIM) methods (e.g., MAE) for visual recognition. Unlike most previous works
that depend on the widely-used ImageNet dataset, which is manually curated and
object-centric, we take a step further and propose to investigate this problem
in a more practical setting. Specifically, we utilize the web-collected
Coyo-700M dataset. We randomly sample varying numbers of training images from
the Coyo dataset and construct a series of sub-datasets, containing 0.5M, 1M,
5M, 10M, and 100M images, for pre-training. Our goal is to investigate how the
performance changes on downstream tasks when scaling with different sizes of
data and models. The study reveals that: 1) MIM can be viewed as an effective
method to improve the model capacity when the scale of the training data is
relatively small; 2) Strong reconstruction targets can endow the models with
increased capacities on downstream tasks; 3) MIM pre-training is data-agnostic
under most scenarios, which means that the strategy of sampling pre-training
data is non-critical. We hope these observations could provide valuable
insights for future research on MIM.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:33:46 GMT""}]","2023-05-25"
"2305.15249","Sharan Vaswani","Sharan Vaswani, Amirreza Kazemi, Reza Babanezhad, Nicolas Le Roux","Decision-Aware Actor-Critic with Function Approximation and Theoretical
  Guarantees","44 pages",,,,"cs.LG cs.AI math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Actor-critic (AC) methods are widely used in reinforcement learning (RL) and
benefit from the flexibility of using any policy gradient method as the actor
and value-based method as the critic. The critic is usually trained by
minimizing the TD error, an objective that is potentially decorrelated with the
true goal of achieving a high reward with the actor. We address this mismatch
by designing a joint objective for training the actor and critic in a
decision-aware fashion. We use the proposed objective to design a generic, AC
algorithm that can easily handle any function approximation. We explicitly
characterize the conditions under which the resulting algorithm guarantees
monotonic policy improvement, regardless of the choice of the policy and critic
parameterization. Instantiating the generic algorithm results in an actor that
involves maximizing a sequence of surrogate functions (similar to TRPO, PPO)
and a critic that involves minimizing a closely connected objective. Using
simple bandit examples, we provably establish the benefit of the proposed
critic objective over the standard squared error. Finally, we empirically
demonstrate the benefit of our decision-aware actor-critic framework on simple
RL problems.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:34:21 GMT""}]","2023-05-25"
"2305.15250","Alberto Giacomello Ph. D.","Sonia Cambiaso, Fabio Rasera, Antonio Tinti, Davide Bochicchio,
  Yaroslav Grosu, Giulia Rossi, Alberto Giacomello","Grafting heterogeneities rule water intrusion and extrusion in nanopores",,,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Hydrophobic nanoporous materials can be intruded by water only by exerting an
external action, typically increasing pressure. For some materials, water
extrudes when the pressure is lowered again. Controlling intrusion/extrusion
hysteresis is central in a number of technological applications, including
materials for energy applications and for high performance liquid
chromatography, and experimental techniques, as liquid porosimetry, but is
still far from being understood. In this work, we consider water intrusion and
extrusion in common mesoporous materials grafted with hydrophobic chains,
showing that the macroscopic properties of the system are significantly
affected by subnanometric heterogeneities in the grafting. For example,
intrusion and extrusion pressures can vary more than 20 MPa depending on the
chain length and density of the grafting. Coarse-grained molecular dynamics
simulations reveal that local changes of radius and contact angle produced by
grafting heterogeneities can pin the interface during intrusion or facilitate
bubble nucleation in extrusion. These unprecedented microscopic insights can
directly impact the design of energy materials and chromatography columns, as
well as the interpretation of porosimetry results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:34:35 GMT""}]","2023-05-25"
"2305.15251","Taiping Zhang","Taiping Zhang","Plasmonic-Photonic Hybrid Nanodevice","Doctoral thesis",,,,"physics.optics physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  In this thesis, we propose to tackle this important issue by designing and
realizing a novel nano-optical device based on the use of a photonic crystal
(PC) structure to generate an efficient coupling between the external source
and a NA. In this dissertation, the content is arranged into three charpters.
Chapter 1 introduces the theoritical background of this research including
surface plasmon and photonic crystal concepts. This chapter also shows the
design of the hybrid devices and demonstrates the numerical simulation of their
optical properties. Chapter 2 mainly describes the process and the fabricated
samples. The nanodevices are fabricated on an InP membrane substrate. The
critical technology for the fabrication is complex electron beam lithography.
With this technology the alignment of the positions of PC structure and NA is
well controlled. Chapter 3 demonstrates the optical characterizations of the
hybrid nanodevices including far-field characterizations and near-field
characterizations. The far-field measurement is performed by
micro-photoluminescence spectroscopy at room temperature. The results show that
for the defect PC cavities, the presence of the NA influences the optical
properties of the laser, such as lasing threshold and laser wavelength. The
near-field measurement is performed by near-field scanning microscopy, at room
temperature also. The investigation shows that the NA modifies the optical
field distribution of the laser mode. The modification depends on the position
and direction of the NA and it is sensitive to the polarization of the optical
field.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:36:00 GMT""}]","2023-05-25"
"2305.15252","Sadaf Ul Zuhra Dr","Sadaf Ul Zuhra, Prasanna Chaporkar, Abhay Karandikar, H. Vincent Poor","Multi-Connectivity for Multicast Video Streaming in Cellular Networks
  (Extended Abstract)","arXiv admin note: substantial text overlap with arXiv:2202.05053",,,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  In video streaming applications especially during live streaming events (such
as the Super Bowl), video traffic can account for a significant portion of
network traffic and can lead to severe network congestion. During such events,
multicast transmission can be used to avoid network congestion since the same
video content is being streamed to multiple users simultaneously. However,
providing seamless connectivity to cellular users in multicast streaming
remains an open problem. To address this issue, this paper explores the
potential of using multi-connectivity (MC) in wireless multicast streaming. Our
results reveal that MC significantly improves the performance of multicast
services, especially for cell edge users who often suffer from poor channel
conditions. We prove that optimal resource allocation in MC multicast streaming
is an NP-hard problem. Therefore, we propose a greedy approximation algorithm
for this problem with an approximation factor of $(1-1/e)$. We also prove that
no other polynomial-time algorithm can provide a better approximation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:36:21 GMT""}]","2023-05-25"
"2305.15253","Han Yu","Han Yu, Xingxuan Zhang, Renzhe Xu, Jiashuo Liu, Yue He, Peng Cui","Rethinking the Evaluation Protocol of Domain Generalization",,,,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain generalization aims to solve the challenge of Out-of-Distribution
(OOD) generalization by leveraging common knowledge learned from multiple
training domains to generalize to unseen test domains. To accurately evaluate
the OOD generalization ability, it is necessary to ensure that test data
information is unavailable. However, the current domain generalization protocol
may still have potential test data information leakage. This paper examines the
potential risks of test data information leakage in two aspects of the current
protocol: pretraining on ImageNet and oracle model selection. We propose that
training from scratch and using multiple test domains would result in a more
precise evaluation of OOD generalization ability. We also rerun the algorithms
with the modified protocol and introduce a new leaderboard to encourage future
research in domain generalization with a fairer comparison.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:36:46 GMT""}]","2023-05-25"
"2305.15254","Benno K\""ach","Benno K\""ach, Isabell Melzer-Pellmann","Attention to Mean-Fields for Particle Cloud Generation",,,,,"hep-ex cs.LG","http://creativecommons.org/licenses/by/4.0/","  The generation of collider data using machine learning has emerged as a
prominent research topic in particle physics due to the increasing
computational challenges associated with traditional Monte Carlo simulation
methods, particularly for future colliders with higher luminosity. Although
generating particle clouds is analogous to generating point clouds, accurately
modelling the complex correlations between the particles presents a
considerable challenge. Additionally, variable particle cloud sizes further
exacerbate these difficulties, necessitating more sophisticated models. In this
work, we propose a novel model that utilizes an attention-based aggregation
mechanism to address these challenges. The model is trained in an adversarial
training paradigm, ensuring that both the generator and critic exhibit
permutation equivariance/invariance with respect to their input. A novel
feature matching loss in the critic is introduced to stabilize the training.
The proposed model performs competitively to the state-of-art whilst having
significantly fewer parameters.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:38:43 GMT""}]","2023-05-25"
"2305.15255","Eliya Nachmani","Eliya Nachmani, Alon Levkovitch, Julian Salazar, Chulayuth
  Asawaroengchai, Soroosh Mariooryad, RJ Skerry-Ryan, Michelle Tadmor
  Ramanovich","LMs with a Voice: Spoken Language Modeling beyond Speech Tokens",,,,,"cs.CL cs.LG cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present SPECTRON, a novel approach to adapting pre-trained language models
(LMs) to perform speech continuation. By leveraging pre-trained speech
encoders, our model generates both text and speech outputs with the entire
system being trained end-to-end operating directly on spectrograms. Training
the entire model in the spectrogram domain simplifies our speech continuation
system versus existing cascade methods which use discrete speech
representations. We further show our method surpasses existing spoken language
models both in semantic content and speaker preservation while also benefiting
from the knowledge transferred from pre-existing models. Audio samples can be
found in our website https://michelleramanovich.github.io/spectron/spectron
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:39:43 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 08:04:19 GMT""}]","2023-06-02"
"2305.15256","Munyque Mittelmann","Munyque Mittelmann, Aniello Murano, Laurent Perrussel","Discounting in Strategy Logic","Extended version of the paper accepted at IJCAI 2023",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Discounting is an important dimension in multi-agent systems as long as we
want to reason about strategies and time. It is a key aspect in economics as it
captures the intuition that the far-away future is not as important as the near
future. Traditional verification techniques allow to check whether there is a
winning strategy for a group of agents but they do not take into account the
fact that satisfying a goal sooner is different from satisfying it after a long
wait. In this paper, we augment Strategy Logic with future discounting over a
set of discounted functions D, denoted SLdisc[D]. We consider ""until"" operators
with discounting functions: the satisfaction value of a specification in
SLdisc[D] is a value in [0, 1], where the longer it takes to fulfill
requirements, the smaller the satisfaction value is. We motivate our approach
with classical examples from Game Theory and study the complexity of
model-checking SLdisc[D]-formulas.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:40:53 GMT""}]","2023-05-25"
"2305.15257","Min Liu","Min Liu, Zhiqiang Cai and Karthik Ramani","Deep Ritz Method with Adaptive Quadrature for Linear Elasticity",,,,,"math.NA cs.NA math-ph math.MP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we study the deep Ritz method for solving the linear
elasticity equation from a numerical analysis perspective. A modified Ritz
formulation using the $H^{1/2}(\Gamma_D)$ norm is introduced and analyzed for
linear elasticity equation in order to deal with the (essential) Dirichlet
boundary condition. We show that the resulting deep Ritz method provides the
best approximation among the set of deep neural network (DNN) functions with
respect to the ``energy'' norm. Furthermore, we demonstrate that the total
error of the deep Ritz simulation is bounded by the sum of the network
approximation error and the numerical integration error, disregarding the
algebraic error. To effectively control the numerical integration error, we
propose an adaptive quadrature-based numerical integration technique with a
residual-based local error indicator. This approach enables efficient
approximation of the modified energy functional. Through numerical experiments
involving smooth and singular problems, as well as problems with stress
concentration, we validate the effectiveness and efficiency of the proposed
deep Ritz method with adaptive quadrature.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:41:47 GMT""}]","2023-05-25"
"2305.15258","Ningchen Bai","Ning-Chen Bai, Lei Li and Jun Tao","Superfluid $\lambda$ Transition in Charged AdS Black Holes","8 pages, 5 figures",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we reconsider $P-V$ criticality of charged AdS black holes in a
holographic extended thermodynamics that considers the variation of Newton's
constant $G$. Interestingly, a superfluid-like $\lambda$ phase transition is
observed. We calculate the critical exponents and find that they coincide with
those of a superfluid transition in liquid $^4\text{He}$ and the Bose-Einstein
condensation of hard-sphere Bose gas. Moreover, the independence of entropy and
thermodynamic volume in the holographic framework allows us to construct a
well-defined Ruppeiner metric. The associated scalar curvature suggests that
the black holes show similar microscopic interactions with the hard-sphere Bose
gas, where the superfluid (condensed) phase is dominated by repulsive
interactions, while the normal (gas) phase is dominated by attractive
interactions. These findings might provide us with new insights into the
quantum aspect of charged AdS black holes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:42:13 GMT""}]","2023-05-25"
"2305.15259","Marcel Moosbrugger","Marcel Moosbrugger, Julian M\""ullner, Laura Kov\'acs","Automated Sensitivity Analysis for Probabilistic Loops",,,,,"cs.PL","http://creativecommons.org/licenses/by/4.0/","  We present an exact approach to analyze and quantify the sensitivity of
higher moments of probabilistic loops with symbolic parameters, polynomial
arithmetic and potentially uncountable state spaces. Our approach integrates
methods from symbolic computation, probability theory, and static analysis in
order to automatically capture sensitivity information about probabilistic
loops. Sensitivity information allows us to formally establish how value
distributions of probabilistic loop variables influence the functional behavior
of loops, which can in particular be helpful when choosing values of loop
variables in order to ensure efficient/expected computations. Our work uses
algebraic techniques to model higher moments of loop variables via linear
recurrence equations and introduce the notion of sensitivity recurrences. We
show that sensitivity recurrences precisely model loop sensitivities, even in
cases where the moments of loop variables do not satisfy a system of linear
recurrences. As such, we enlarge the class of probabilistic loops for which
sensitivity analysis was so far feasible. We demonstrate the success of our
approach while analyzing the sensitivities of probabilistic loops.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:43:29 GMT""}]","2023-05-25"
"2305.15260","Qi Wang","Qi Wang, Junming Yang, Yunbo Wang, Xin Jin, Wenjun Zeng, Xiaokang Yang","Collaborative World Models: An Online-Offline Transfer RL Approach",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Training visual reinforcement learning (RL) models in offline datasets is
challenging due to overfitting issues in representation learning and
overestimation problems in value function. In this paper, we propose a transfer
learning method called Collaborative World Models (CoWorld) to improve the
performance of visual RL under offline conditions. The core idea is to use an
easy-to-interact, off-the-shelf simulator to train an auxiliary RL model as the
online ""test bed"" for the offline policy learned in the target domain, which
provides a flexible constraint for the value function -- Intuitively, we want
to mitigate the overestimation problem of value functions outside the offline
data distribution without impeding the exploration of actions with potential
advantages. Specifically, CoWorld performs domain-collaborative representation
learning to bridge the gap between online and offline hidden state
distributions. Furthermore, it performs domain-collaborative behavior learning
that enables the source RL agent to provide target-aware value estimation,
allowing for effective offline policy regularization. Experiments show that
CoWorld significantly outperforms existing methods in offline visual control
tasks in DeepMind Control and Meta-World.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:45:35 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 05:31:38 GMT""}]","2023-05-26"
"2305.15261","Diana Carbajal","Jorge Antezana, Diana Carbajal and Jos\'e Luis Romero","Random periodic sampling patterns for shift-invariant spaces",,,,,"math.FA cs.IT math.CA math.IT","http://creativecommons.org/licenses/by/4.0/","  We consider multi-variate signals spanned by the integer shifts of a set of
generating functions with distinct frequency profiles and the problem of
reconstructing them from samples taken on a random periodic set. We show that
such a sampling strategy succeeds with high probability provided that the
density of the sampling pattern exceeds the number of frequency profiles by a
logarithmic factor.
  The signal model includes bandlimited functions with multi-band spectra.
While in this well-studied setting delicate constructions provide sampling
strategies that meet the information theoretic benchmark of Shannon and Landau,
the sampling pattern that we consider provides, at the price of a logarithmic
oversampling factor, a simple alternative that is accompanied by favorable a
priori stability margins (snug frames). More generally, we also treat
bandlimited functions with arbitrary compact spectra, and different measures of
its complexity and approximation rates by integer tiles.
  At the technical level, we elaborate on recent work on relevant sampling,
with the key difference that the reconstruction guarantees that we provide hold
uniformly for all signals, rather than for a subset of well-concentrated ones.
This is achieved by methods of concentration of measure formulated on the Zak
domain.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:47:34 GMT""}]","2023-05-25"
"2305.15262","Kejuan Yang","Kejuan Yang, Xiao Liu, Kaiwen Men, Aohan Zeng, Yuxiao Dong, Jie Tang","Revisiting Parallel Context Windows: A Frustratingly Simple Alternative
  and Chain-of-Thought Deterioration",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We identify two crucial limitations in the evaluation of recent
parallel-integrated method Parallel Context Windows (PCW), which extends the
maximum context lengths of language models, e.g., 2048 for LLaMA, by harnessing
window-wise attention and positional embedding techniques. We first show that a
simple yet strong baseline, weighted sum ensemble, is missing for the
in-context few-shot classification. Moreover, on more challenging
Chain-of-Thought (CoT) reasoning (e.g., HotpotQA), PCW would present unexpected
deterioration regarding question miscomprehension and false inference. Based on
our findings, we suggest that the existing PCW design may not guarantee
sufficient improvement and practicality in handling lengthy documents in
real-world applications. More community efforts on enabling language models'
long context understanding ability should be paid.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:48:29 GMT""}]","2023-05-25"
"2305.15263","Michael Hahsler","Michael Hahsler","ARULESPY: Exploring Association Rules and Frequent Itemsets in Python",,,,,"cs.DB","http://creativecommons.org/licenses/by-sa/4.0/","  The R arules package implements a comprehensive infrastructure for
representing, manipulating, and analyzing transaction data and patterns using
frequent itemsets and association rules. The package also provides a wide range
of interest measures and mining algorithms, including the code of Christian
Borgelt's popular and efficient C implementations of the association mining
algorithms Apriori and Eclat, and optimized C/C++ code for mining and
manipulating association rules using sparse matrix representation. This
document describes the new Python package arulespy, which makes this
infrastructure available for Python users.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:52:01 GMT""}]","2023-05-25"
"2305.15264","Elnur Gasanov","Peter Richt\'arik, Elnur Gasanov, Konstantin Burlachenko","Error Feedback Shines when Features are Rare",,,,,"math.OC cs.DC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide the first proof that gradient descent $\left({\color{green}\sf
GD}\right)$ with greedy sparsification $\left({\color{green}\sf TopK}\right)$
and error feedback $\left({\color{green}\sf EF}\right)$ can obtain better
communication complexity than vanilla ${\color{green}\sf GD}$ when solving the
distributed optimization problem $\min_{x\in \mathbb{R}^d}
{f(x)=\frac{1}{n}\sum_{i=1}^n f_i(x)}$, where $n$ = # of clients, $d$ = # of
features, and $f_1,\dots,f_n$ are smooth nonconvex functions. Despite intensive
research since 2014 when ${\color{green}\sf EF}$ was first proposed by Seide et
al., this problem remained open until now. We show that ${\color{green}\sf EF}$
shines in the regime when features are rare, i.e., when each feature is present
in the data owned by a small number of clients only. To illustrate our main
result, we show that in order to find a random vector $\hat{x}$ such that
$\lVert {\nabla f(\hat{x})} \rVert^2 \leq \varepsilon$ in expectation,
${\color{green}\sf GD}$ with the ${\color{green}\sf Top1}$ sparsifier and
${\color{green}\sf EF}$ requires ${\cal O} \left(\left( L+{\color{blue}r}
\sqrt{ \frac{{\color{red}c}}{n} \min \left( \frac{{\color{red}c}}{n} \max_i
L_i^2, \frac{1}{n}\sum_{i=1}^n L_i^2 \right) }\right) \frac{1}{\varepsilon}
\right)$ bits to be communicated by each worker to the server only, where $L$
is the smoothness constant of $f$, $L_i$ is the smoothness constant of $f_i$,
${\color{red}c}$ is the maximal number of clients owning any feature ($1\leq
{\color{red}c} \leq n$), and ${\color{blue}r}$ is the maximal number of
features owned by any client ($1\leq {\color{blue}r} \leq d$). Clearly, the
communication complexity improves as ${\color{red}c}$ decreases (i.e., as
features become more rare), and can be much better than the ${\cal
O}({\color{blue}r} L \frac{1}{\varepsilon})$ communication complexity of
${\color{green}\sf GD}$ in the same regime.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:52:07 GMT""}]","2023-05-25"
"2305.15265","Zirui Liu","Zirui Liu, Guanchu Wang, Shaochen Zhong, Zhaozhuo Xu, Daochen Zha,
  Ruixiang Tang, Zhimeng Jiang, Kaixiong Zhou, Vipin Chaudhary, Shuai Xu, Xia
  Hu","Winner-Take-All Column Row Sampling for Memory Efficient Adaptation of
  Language Model",,,,,"cs.LG cs.CL","http://creativecommons.org/licenses/by/4.0/","  With the rapid growth in model size, fine-tuning the large pre-trained
language model has become increasingly difficult due to its extensive memory
usage. Previous works usually focus on reducing the number of trainable
parameters in the network. While the model parameters do contribute to memory
usage, the primary memory bottleneck during training arises from storing
feature maps, also known as activations, as they are crucial for gradient
calculation. Notably, neural networks are usually trained using stochastic
gradient descent. We argue that in stochastic optimization, models can handle
noisy gradients as long as the gradient estimator is unbiased with reasonable
variance. Following this motivation, we propose a new family of unbiased
estimators called WTA-CRS, for matrix production with reduced variance, which
only requires storing the sub-sampled activations for calculating the gradient.
Our work provides both theoretical and experimental evidence that, in the
context of tuning transformers, our proposed estimators exhibit lower variance
compared to existing ones. By replacing the linear operation with our
approximated one in transformers, we can achieve up to 2.7$\times$ peak memory
reduction with almost no accuracy drop and enables up to $6.4\times$ larger
batch size. Under the same hardware, WTA-CRS enables better down-streaming task
performance by applying larger models and/or faster training speed with larger
batch sizes.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:52:08 GMT""}]","2023-05-25"
"2305.15266","Eloi Moliner","Eloi Moliner, Vesa V\""alim\""aki","Diffusion-Based Audio Inpainting","Submitted for publication to the Journal of Audio Engineering Society
  on January 30th, 2023",,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by/4.0/","  Audio inpainting aims to reconstruct missing segments in corrupted
recordings. Previous methods produce plausible reconstructions when the gap
length is shorter than about 100\;ms, but the quality decreases for longer
gaps. This paper explores recent advancements in deep learning and,
particularly, diffusion models, for the task of audio inpainting. The proposed
method uses an unconditionally trained generative model, which can be
conditioned in a zero-shot fashion for audio inpainting, offering high
flexibility to regenerate gaps of arbitrary length. An improved deep neural
network architecture based on the constant-Q transform, which allows the model
to exploit pitch-equivariant symmetries in audio, is also presented. The
performance of the proposed algorithm is evaluated through objective and
subjective metrics for the task of reconstructing short to mid-sized gaps. The
results of a formal listening test show that the proposed method delivers a
comparable performance against state-of-the-art for short gaps, while retaining
a good audio quality and outperforming the baselines for the longest gap
lengths tested, 150\;ms and 200\;ms. This work helps improve the restoration of
sound recordings having fairly long local disturbances or dropouts, which must
be reconstructed.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:52:11 GMT""}]","2023-05-25"
"2305.15267","Chen-Hao Chao","Chen-Hao Chao, Wei-Fang Sun, Yen-Chang Hsu, Zsolt Kira, Chun-Yi Lee","Training Energy-Based Normalizing Flow with Score-Matching Objectives",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we establish a connection between the parameterization of
flow-based and energy-based generative models, and present a new flow-based
modeling approach called energy-based normalizing flow (EBFlow). We demonstrate
that by optimizing EBFlow with score-matching objectives, the computation of
Jacobian determinants for linear transformations can be entirely bypassed. This
feature enables the use of arbitrary linear layers in the construction of
flow-based models without increasing the computational time complexity of each
training iteration from $\mathcal{O}(D^2L)$ to $\mathcal{O}(D^3L)$ for an
$L$-layered model that accepts $D$-dimensional inputs. This makes the training
of EBFlow more efficient than the commonly-adopted maximum likelihood training
method. In addition to the reduction in runtime, we enhance the training
stability and empirical performance of EBFlow through a number of techniques
developed based on our analysis on the score-matching methods. The experimental
results demonstrate that our approach achieves a significant speedup compared
to maximum likelihood estimation, while outperforming prior efficient training
techniques with a noticeable margin in terms of negative log-likelihood (NLL).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:54:29 GMT""}]","2023-05-25"
"2305.15268","Zhengwei Tao","Zhengwei Tao, Zhi Jin, Xiaoying Bai, Haiyan Zhao, Yanlin Feng, Jia Li,
  Wenpeng Hu","EvEval: A Comprehensive Evaluation of Event Semantics for Large Language
  Models",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Events serve as fundamental units of occurrence within various contexts. The
processing of event semantics in textual information forms the basis of
numerous natural language processing (NLP) applications. Recent studies have
begun leveraging large language models (LLMs) to address event semantic
processing. However, the extent that LLMs can effectively tackle these
challenges remains uncertain. Furthermore, the lack of a comprehensive
evaluation framework for event semantic processing poses a significant
challenge in evaluating these capabilities. In this paper, we propose an
overarching framework for event semantic processing, encompassing
understanding, reasoning, and prediction, along with their fine-grained
aspects. To comprehensively evaluate the event semantic processing abilities of
models, we introduce a novel benchmark called EVEVAL. We collect 8 datasets
that cover all aspects of event semantic processing. Extensive experiments are
conducted on EVEVAL, leading to several noteworthy findings based on the
obtained results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:55:40 GMT""}]","2023-05-25"
"2305.15269","Abulhair Saparov","Abulhair Saparov, Richard Yuanzhe Pang, Vishakh Padmakumar, Nitish
  Joshi, Seyed Mehran Kazemi, Najoung Kim, He He","Testing the General Deductive Reasoning Capacity of Large Language
  Models Using OOD Examples",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Given the intractably large size of the space of proofs, any model that is
capable of general deductive reasoning must generalize to proofs of greater
complexity. Recent studies have shown that large language models (LLMs) possess
some abstract deductive reasoning ability given chain-of-thought prompts.
However, they have primarily been tested on proofs using modus ponens or of a
specific size, and from the same distribution as the in-context examples. To
measure the general deductive reasoning ability of LLMs, we test on a broad set
of deduction rules and measure their ability to generalize to more complex
proofs from simpler demonstrations from multiple angles: depth-, width-, and
compositional generalization. To facilitate systematic exploration, we
construct a new synthetic and programmable reasoning dataset that enables
control over deduction rules and proof complexity. Our experiments on four LLMs
of various sizes and training objectives show that they are able to generalize
to longer and compositional proofs. However, they require explicit
demonstrations to produce hypothetical subproofs, specifically in proof by
cases and proof by contradiction.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:55:51 GMT""}]","2023-05-25"
"2305.15270","Siyang Song","Tong Xu, Micol Spitale, Hao Tang, Lu Liu, Hatice Gunes, Siyang Song","Reversible Graph Neural Network-based Reaction Distribution Learning for
  Multiple Appropriate Facial Reactions Generation",,,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Generating facial reactions in a human-human dyadic interaction is complex
and highly dependent on the context since more than one facial reactions can be
appropriate for the speaker's behaviour. This has challenged existing machine
learning (ML) methods, whose training strategies enforce models to reproduce a
specific (not multiple) facial reaction from each input speaker behaviour. This
paper proposes the first multiple appropriate facial reaction generation
framework that re-formulates the one-to-many mapping facial reaction generation
problem as a one-to-one mapping problem. This means that we approach this
problem by considering the generation of a distribution of the listener's
appropriate facial reactions instead of multiple different appropriate facial
reactions, i.e., 'many' appropriate facial reaction labels are summarised as
'one' distribution label during training. Our model consists of a perceptual
processor, a cognitive processor, and a motor processor. The motor processor is
implemented with a novel Reversible Multi-dimensional Edge Graph Neural Network
(REGNN). This allows us to obtain a distribution of appropriate real facial
reactions during the training process, enabling the cognitive processor to be
trained to predict the appropriate facial reaction distribution. At the
inference stage, the REGNN decodes an appropriate facial reaction by using this
distribution as input. Experimental results demonstrate that our approach
outperforms existing models in generating more appropriate, realistic, and
synchronized facial reactions. The improved performance is largely attributed
to the proposed appropriate facial reaction distribution learning strategy and
the use of a REGNN. The code is available at
https://github.com/TongXu-05/REGNN-Multiple-Appropriate-Facial-Reaction-Generation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:56:26 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 17:41:49 GMT""}]","2023-05-26"
"2305.15271","Enrico Valdinoci","Serena Dipierro, Ovidiu Savin, Enrico Valdinoci","Boundary continuity of nonlocal minimal surfaces in domains with
  singularities and a problem posed by Borthagaray, Li, and Nochetto",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  Differently from their classical counterpart, nonlocal minimal surfaces are
known to present boundary discontinuities, by sticking at the boundary of
smooth domains.
  It has been observed numerically by J. P. Borthagaray, W. Li, and R. H.
Nochetto ``that stickiness is larger near the concave portions of the boundary
than near the convex ones, and that it is absent in the corners of the
square'', leading to the conjecture ``that there is a relation between the
amount of stickiness on $\partial\Omega$ and the nonlocal mean curvature of
$\partial\Omega$''.
  In this paper, we give a positive answer to this conjecture, by showing that
the nonlocal minimal surfaces are continuous at convex corners of the domain
boundary and discontinuous at concave corners.
  More generally, we show that boundary continuity for nonlocal minimal
surfaces holds true at all points in which the domain is not better than
$C^{1,s}$, with the singularity pointing outward, while, as pointed out by a
concrete example, discontinuities may occur at all point in which the domain
possesses an interior touching set of class $C^{1,\alpha}$ with $\alpha>s$.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:57:03 GMT""}]","2023-05-25"
"2305.15272","Jingfeng Yao","Jingfeng Yao, Xinggang Wang, Shusheng Yang, Baoyuan Wang","ViTMatte: Boosting Image Matting with Pretrained Plain Vision
  Transformers","codes: https://github.com/hustvl/ViTMatte",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Recently, plain vision Transformers (ViTs) have shown impressive performance
on various computer vision tasks, thanks to their strong modeling capacity and
large-scale pretraining. However, they have not yet conquered the problem of
image matting. We hypothesize that image matting could also be boosted by ViTs
and present a new efficient and robust ViT-based matting system, named
ViTMatte. Our method utilizes (i) a hybrid attention mechanism combined with a
convolution neck to help ViTs achieve an excellent performance-computation
trade-off in matting tasks. (ii) Additionally, we introduce the detail capture
module, which just consists of simple lightweight convolutions to complement
the detailed information required by matting. To the best of our knowledge,
ViTMatte is the first work to unleash the potential of ViT on image matting
with concise adaptation. It inherits many superior properties from ViT to
matting, including various pretraining strategies, concise architecture design,
and flexible inference strategies. We evaluate ViTMatte on Composition-1k and
Distinctions-646, the most commonly used benchmark for image matting, our
method achieves state-of-the-art performance and outperforms prior matting
works by a large margin.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:59:35 GMT""},{""version"":""v2"",""created"":""Wed, 31 May 2023 09:12:06 GMT""}]","2023-06-01"
"2305.15273","Qihuang Zhong","Qihuang Zhong, Liang Ding, Juhua Liu, Xuebo Liu, Min Zhang, Bo Du and
  Dacheng Tao","Revisiting Token Dropping Strategy in Efficient BERT Pretraining","Accepted to ACL2023 Main Conference",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Token dropping is a recently-proposed strategy to speed up the pretraining of
masked language models, such as BERT, by skipping the computation of a subset
of the input tokens at several middle layers. It can effectively reduce the
training time without degrading much performance on downstream tasks. However,
we empirically find that token dropping is prone to a semantic loss problem and
falls short in handling semantic-intense tasks. Motivated by this, we propose a
simple yet effective semantic-consistent learning method (ScTD) to improve the
token dropping. ScTD aims to encourage the model to learn how to preserve the
semantic information in the representation space. Extensive experiments on 12
tasks show that, with the help of our ScTD, token dropping can achieve
consistent and significant performance gains across all task types and model
sizes. More encouragingly, ScTD saves up to 57% of pretraining time and brings
up to +1.56% average improvement over the vanilla token dropping.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:59:44 GMT""}]","2023-05-25"
"2305.15274","Giulio Romani","Daniele Cassani, Zhisu Liu, Giulio Romani","Nonlocal planar Schr\""odinger-Poisson systems in the fractional Sobolev
  limiting case",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We study the nonlinear Schr\""odinger equation for the $s-$fractional
$p-$Laplacian strongly coupled with the Poisson equation in dimension two and
with $p=\frac2s$, which is the limiting case for the embedding of the
fractional Sobolev space $W^{s,p}(\mathbb{R}^2)$. We prove existence of
solutions by means of a variational approximating procedure for an auxiliary
Choquard equation in which the uniformly approximated sign-changing logarithmic
kernel competes with the exponential nonlinearity. Qualitative properties of
solutions such as symmetry and decay are also established by exploiting a
suitable moving planes technique.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:59:55 GMT""}]","2023-05-25"
"2305.15439","Elisa Maggio","Elisa Maggio","Tests of general relativity in the nonlinear regime: a parametrized
  plunge-merger-ringdown waveform model","2 pages, 1 figure, contribution to the 2023 Gravitation session of
  the 57th Rencontres de Moriond",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Gravitational waves provide a unique opportunity to test gravity in the
dynamical and nonlinear regime. We present a parametrized test of general
relativity (GR) that introduces generic deviations to the plunge, merger and
ringdown stages of binary-black-hole coalescences. The novel feature of the
model is that it can capture signatures of beyond-GR physics in the
plunge-merger phase. We use the model to provide constraints on the
plunge-merger parameters from the analysis of GW150914. Alarmingly, we find
that GW200129 shows a strong violation of GR. We interpret this result as a
false violation of GR either due to waveform systematics (mismodeling of spin
precession) or data-quality issues.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:53:40 GMT""}]","2023-05-26"
"2305.15440","Oliver Janssen","Thomas Hertog, Oliver Janssen and Joel Karlsson","The KS-criterion constrains inflation in the no-boundary state","Dedicated to the memory of Jim Hartle",,,,"hep-th gr-qc","http://creativecommons.org/licenses/by/4.0/","  We show that the Kontsevich-Segal (KS) criterion, applied to the complex
saddles that specify the semiclassical no-boundary wave function, acts as a
selection mechanism on inflationary scalar field potentials. In this context
the KS-criterion effectively bounds the tensor-to-scalar ratio of cosmic
microwave background fluctuations to be less than 0.08, in line with current
observations. We trace the failure of complex saddles to meet the KS-criterion
to the development of a tachyon in their spectrum of perturbations.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 20:03:34 GMT""}]","2023-05-26"
"2305.15441","Timothy Daley","M. Zaki Jawaid and Robin W. Yeo and Aayushma Gautam and T. Blair
  Gainous and Daniel O. Hart and Timothy P. Daley","Improving few-shot learning-based protein engineering with evolutionary
  sampling",,,,,"q-bio.QM cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Designing novel functional proteins remains a slow and expensive process due
to a variety of protein engineering challenges; in particular, the number of
protein variants that can be experimentally tested in a given assay pales in
comparison to the vastness of the overall sequence space, resulting in low hit
rates and expensive wet lab testing cycles. In this paper, we propose a
few-shot learning approach to novel protein design that aims to accelerate the
expensive wet lab testing cycle and is capable of leveraging a training dataset
that is both small and skewed ($\approx 10^5$ datapoints, $< 1\%$ positive
hits). Our approach is composed of two parts: a semi-supervised transfer
learning approach to generate a discrete fitness landscape for a desired
protein function and a novel evolutionary Monte Carlo Markov Chain sampling
algorithm to more efficiently explore the fitness landscape. We demonstrate the
performance of our approach by experimentally screening predicted high fitness
gene activators, resulting in a dramatically improved hit rate compared to
existing methods. Our method can be easily adapted to other protein engineering
and design problems, particularly where the cost associated with obtaining
labeled data is significantly high. We have provided open source code for our
method at https://
github.com/SuperSecretBioTech/evolutionary_monte_carlo_search.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 23:07:53 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 00:53:37 GMT""}]","2023-05-29"
"2305.15442","Per Enflo","Per H. Enflo","On the invariant subspace problem in Hilbert spaces","13 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show that every bounded linear operator T on a Hilbert space
H has a closed non-trivial invariant subspace.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 05:21:46 GMT""}]","2023-05-26"
"2305.15443","Farhod Halimjonovich Haydarov","F.H.Haydarov","Kolmogorov extension theorem for non-probability measures on Cayley
  trees","Cayley tree, cylinder sets, Kolmogorov's extension theorem, spin
  values, non-probability measures",,,,"math.PR math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we shall discuss the extendability of probability and
non-probability measures on Cayley trees to a $\sigma$-additive measure on
Borel fields which has a fundamental role in the theory of Gibbs measures.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 06:37:58 GMT""}]","2023-05-26"
"2305.15444","Dhananjay Ashok","Dhananjay Ashok, Zachary C. Lipton","PromptNER: Prompting For Named Entity Recognition",,,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  In a surprising turn, Large Language Models (LLMs) together with a growing
arsenal of prompt-based heuristics now offer powerful off-the-shelf approaches
providing few-shot solutions to myriad classic NLP problems. However, despite
promising early results, these LLM-based few-shot methods remain far from the
state of the art in Named Entity Recognition (NER), where prevailing methods
include learning representations via end-to-end structural understanding and
fine-tuning on standard labeled corpora. In this paper, we introduce PromptNER,
a new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to
any new NER task PromptNER requires a set of entity definitions in addition to
the standard few-shot examples. Given a sentence, PromptNER prompts an LLM to
produce a list of potential entities along with corresponding explanations
justifying their compatibility with the provided entity type definitions.
Remarkably, PromptNER achieves state-of-the-art performance on few-shot NER,
achieving an 11% (absolute) improvement in F1 score on the ConLL dataset, and a
10% (absolute) improvement on the FewNERD dataset. PromptNER also moves the
state of the art on Cross Domain NER, outperforming all prior methods
(including those not limited to the few-shot setting), setting a new mark on
all 5 CrossNER target domains, with an average F1 gain of 9%, despite using
less than 2% of the available data.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:38:24 GMT""}]","2023-05-26"
"2305.15445","Andreas Bott","Andreas Bott, Tim Janke, Florian Steinke","Deep Learning-enabled MCMC for Probabilistic State Estimation in
  District Heating Grids","The code for this paper is available under
  https://github.com/EINS-TUDa/DNN_MCMC4DH","Applied Energy 336 (2023): 120837","10.1016/j.apenergy.2023.120837",,"cs.LG cs.NA cs.SY eess.SY math.NA stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Flexible district heating grids form an important part of future, low-carbon
energy systems. We examine probabilistic state estimation in such grids, i.e.,
we aim to estimate the posterior probability distribution over all grid state
variables such as pressures, temperatures, and mass flows conditional on
measurements of a subset of these states. Since the posterior state
distribution does not belong to a standard class of probability distributions,
we use Markov Chain Monte Carlo (MCMC) sampling in the space of network heat
exchanges and evaluate the samples in the grid state space to estimate the
posterior. Converting the heat exchange samples into grid states by solving the
non-linear grid equations makes this approach computationally burdensome.
However, we propose to speed it up by employing a deep neural network that is
trained to approximate the solution of the exact but slow non-linear solver.
This novel approach is shown to deliver highly accurate posterior distributions
both for classic tree-shaped as well as meshed heating grids, at significantly
reduced computational costs that are acceptable for online control. Our state
estimation approach thus enables tightening the safety margins for temperature
and pressure control and thereby a more efficient grid operation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:47:01 GMT""}]","2023-05-26"
"2305.15446","Alexander Zakharov","Alexander F. Zakharov","Constraints on black hole charges in M87* and Sgr A* with the EHT
  observations","presented as a talk at ICRANet Meeting in May 2022",,,,"gr-qc physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  In May 2022 ICRANet organized the Workshop dedicated to the 80th anniversary
of Professor Ruffini. This paper is based on the talk delivered at the meeting.
  Professor Ruffini was well known for Soviet scientific community not only due
to his publications in leading journals but also due Russian translations of
his books where he was an author or a contributor in collection of articles.
  But only in 1988 I had an opportunity to watch and listen professor R.
Ruffini at the Conference dedicated to the century since the birthday of
Alexander Alexandrovich Friedmann. This conference was organized in Leningrad
(Soviet Union) in June during a short magic period when there are white nights
there. In June 2023 we celebrate the 135th anniversary of Friedmann's birth.
Friedmann and his closed friend V. K. Frederics were the founders of Soviet
school of general relativity and George Gamow was one of the brilliant
representative of the school and he was the author of the hot Universe model
which is the most popular now. In the USSR a development of general relativity
and relativistic cosmology was not smooth and only in sixties of the last
century these branches of science freed from the total control of
representatives of the ideology of Marxism -- Leninism. I also discussed a
Soviet contribution in a discovery of cosmic microwave background radiation
done by T. Shmaonov in 1957 and reasons why his supervisors did not connect
these results with the hot Universe models discussed by G. Gamow. Author's
results about observational features of supemassive black holes (including the
black hole in our Galactic Center) are also briefly discussed, it was
considered
  an opportunity to evaluate a (tidal) charge of Reissner -- Nordstr\""om black
hole from observational estimates of shadow size in the Galactic Center and
M87* done by the EHT Collaboration based its observations in April 2017.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 09:42:38 GMT""}]","2023-05-26"
"2305.15447","Andrew Hyman","Andrew T. Hyman","Alternative Formulation of Classical Electrodynamics that Eliminates the
  Infinite Self-Energies of Point-Charges but Leaves their Motion and
  Interaction Unaffected","13 pages, no figures, miscellaneous minor improvements in response to
  comments",,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of point-particles in classical electrodynamics has a well-known
problem of infinite self-energy, and the same is true of quantum
electrodynamics. Instead of concluding that there is no such thing as a true
point-particle, it is shown here how to remove the infinities by supposing that
the electromagnetic field tensor has a symmetric part. This does not change the
physics, as the equation of motion and the antisymmetric part of the retarded
fields appearing in the equation of motion are unaffected. The symmetric part
of the field tensor is not observable and therefore it need not be
gauge-invariant, whereas the antisymmetric part is observable, gauge-invariant,
and satisfies both the Maxwell Equations and the field equations governing the
whole field tensor. This approach goes well beyond prior efforts at classical
renormalization, and also entails a new derivation of the Lorentz-Abraham-Dirac
(LAD) equation of motion.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:29:12 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 12:05:49 GMT""}]","2023-05-30"
"2305.15448","Javier Molina Dr","Javier Molina-Vilaplana","A post-Gaussian approach to dipole symmetries and interacting fractons","34 pages, 4 figures, 4 appendices",,,,"hep-th cond-mat.str-el nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a post-Gaussian variational approach to non-perturbatively study a
general class of interacting bosonic quantum field theories with generalized
dipole symmetries and fractonic behaviour. We find that while a Gaussian
approach allows to carry out a consistent renormalization group (RG) flow
analysis of these theories, this only grasps the interaction terms associated
to the longitudinal motion of dipoles, which is consistent with previous
analysis using large $N$ techniques. Remarkably, our post-Gaussian proposal, by
providing a variational improved effective potential, is able to capture the
transverse part of the interaction between dipoles in such a way that a non
trivial RG flow for this term is obtained and analyzed. Our results suggest
that dipole symmetries that manifest due to the strong coupling of dipoles, may
robustly emerge at low energies from short distance models without that
symmetry.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:15:26 GMT""}]","2023-05-26"
"2305.15449","Qian Zhang","Jianqing Chen and Qian Zhang","Existence of ground state solution of Nehari-Poho\v{z}aev type for a
  quasilinear Schr\""{o}dinger system","arXiv admin note: substantial text overlap with arXiv:2305.14911",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the following quasilinear Schr\""{o}dinger system
in the entire space $\mathbb R^{N}$($N\geq3$): $$\left\{\begin{align} &-\Delta
u+A(x)u-\frac{1}{2}\triangle(u^{2})u =
\frac{2\alpha}{\alpha+\beta}|u|^{\alpha-2}u|v|^{\beta},\\ &-\Delta
v+Bv-\frac{1}{2}\triangle(v^{2})v=\frac{2\beta}{\alpha+\beta}|u|^{\alpha}|v|^{\beta-2}v.\end{align}\right.
$$ By establishing a suitable constraint set and studying related minimization
problem, we prove the existence of ground state solution for $\alpha,\beta>1$,
$2<\alpha+\beta<\frac{4N}{N-2}$. Our results can be looked on as a
generalization to results by Guo and Tang (Ground state solutions for
quasilinear Schr\""{o}dinger systems, J. Math. Anal. Appl. 389 (2012) 322).
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:45:10 GMT""}]","2023-05-26"
"2305.15450","Hoang Nguyen","Hoang Ky Nguyen, Mustapha Azreg-A\""inou","New insights into Weak Energy Condition and wormholes in Brans-Dicke
  gravity","11 pages, 3 figures",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The formation of a wormhole typically involves a violation of the Weak Energy
Condition (WEC), but the reverse is not necessarily true. In the context of
Brans-Dicke gravity, the $\textit{generalized}$ Campanelli-Lousto solution,
which we shall unveil in this paper, demonstrates a WEC violation that
coincides with the appearance of $\textit{unbounded}$ sheets of spacetime
within the ``interior'' section. The emergence of a wormhole in the
``exterior'' section is thus only an indirect consequence of the WEC violation.
Additionally, we use the generalized Campanelli-Lousto solution to construct a
Kruskal-Szekeres diagram, which exhibits a ``gulf'' sandwiched between the four
quadrants in the diagram, a novel feature in Brans-Dicke gravity. Overall, our
findings shed new light onto a complex interplay between the WEC and wormholes
in the Brans-Dicke theory.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 12:59:54 GMT""}]","2023-05-26"
"2305.15451","Atakan Coban","Atakan Coban","Algodoo for Online Education: Impulse and Momentum Activities","7 pages, published article","Physics Education, 2021","10.1088/1361-6552/abd1e9",,"physics.ed-ph cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  During the periods of sudden transition to online education, the opportunity
to make applications that might attract students' attention to the course has
decreased even more. Although this deficiency was tried to be eliminated with
videos and simulations, it was not possible to ensure active participation of
students in some cases. In this study, the Algodoo program, which can increase
the efficiency of the teaching environment by ensuring active participation of
students in online lessons and the applications that can be done about Impulse
and momentum are explained in detail. A total of 6 different applications were
carried out, 1 related to the subject of impulse, 1 related to the momentum, 2
related to the relationship between impulse and momentum change, and 2 related
to momentum conservation. At the same time, while developing these
applications, the adjustments made on the simulation and the reasons are
explained in detail. In this way, both the introduction of the program and the
sample application suggestion were presented. The values obtained as a result
of the applications were calculated and compared both theoretically and on
simulation in different ways. As a result, it has been observed that the values
have internal consistency with each other and are also compatible with
theoretical calculations. Algodoo program, which allows many interactive
applications and can be downloaded for free, is a program that can be used both
in lecturing and evaluation processes in physics lessons while online education
process.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 13:10:59 GMT""}]","2023-05-26"
"2305.15452","Eliad Tsfadia","Kobbi Nissim, Uri Stemmer, Eliad Tsfadia","Adaptive Data Analysis in a Balanced Adversarial Model",,,,,"cs.LG cs.CR cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an
unknown distribution $D$, and is required to provide accurate estimations to a
sequence of adaptively chosen statistical queries with respect to $D$. Hardt
and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in
general, it is computationally hard to answer more than $\Theta(n^2)$ adaptive
queries, assuming the existence of one-way functions.
  However, these negative results strongly rely on an adversarial model that
significantly advantages the adversarial analyst over the mechanism, as the
analyst, who chooses the adaptive queries, also chooses the underlying
distribution $D$. This imbalance raises questions with respect to the
applicability of the obtained hardness results -- an analyst who has complete
knowledge of the underlying distribution $D$ would have little need, if at all,
to issue statistical queries to a mechanism which only holds a finite number of
samples from $D$.
  We consider more restricted adversaries, called \emph{balanced}, where each
such adversary consists of two separated algorithms: The \emph{sampler} who is
the entity that chooses the distribution and provides the samples to the
mechanism, and the \emph{analyst} who chooses the adaptive queries, but does
not have a prior knowledge of the underlying distribution. We improve the
quality of previous lower bounds by revisiting them using an efficient
\emph{balanced} adversary, under standard public-key cryptography assumptions.
We show that these stronger hardness assumptions are unavoidable in the sense
that any computationally bounded \emph{balanced} adversary that has the
structure of all known attacks, implies the existence of public-key
cryptography.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:08:05 GMT""}]","2023-05-26"
"2305.16336","Sergey Ershkov","Sergey Ershkov, Dmytro Leshchenko, Evgeniy Prosviryakov","On the motion of satellite around the natural moons of planets using the
  concept of ER3BP with variable eccentricity","24 pages, 10 Figures; Key words: elliptic restricted three-body
  problem (ER3BP), three body problem, trapped motion, tidal phenomena,
  satellite",,,,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the current study, we explore stability of motion of satellite around the
natural moons of planets in Solar system using the novel concept of ER3BP with
variable eccentricity. This concept was introduced earlier when novel type of
ER3BP (Sun-planet-satellite) was investigated with variable spin state of
secondary planet correlated implicitly to the motion of satellite (in the
synodic co-rotating Cartesian coordinate system) for its trapped orbit near the
secondary planet (which is involved in kepler duet <Sun-planet>). But it is of
real interest to explore another kind of aforedescribed problem, ER3BP
(planet-moon-satellite) with respect to investigation of motion of satellite m
around the natural moon m_moon of planet in Solar system with variable
eccentricity of the moon in its motion around the planet. So, we consider here
two primaries, M_planet and m_moon, the last is orbiting around their common
barycenter on quasi-elliptic orbit with slow-changing, not constant
eccentricity (on a large-time scale) due to tidal phenomena. Our aim is to
investigate motion of small dot satellite around the natural moon of planet on
quasi-stable elliptic orbit. Both novel theoretical and numerical findings (for
various cases of trio <planet-moon-satellite>) are presented in the current
research.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:38:06 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 06:13:00 GMT""},{""version"":""v3"",""created"":""Wed, 7 Jun 2023 10:55:03 GMT""}]","2023-06-08"
"2305.16337","Maha Agro","Maha Tufail Agro, Hanan Aldarmaki","Handling Realistic Label Noise in BERT Text Classification",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Labels noise refers to errors in training labels caused by cheap data
annotation methods, such as web scraping or crowd-sourcing, which can be
detrimental to the performance of supervised classifiers. Several methods have
been proposed to counteract the effect of random label noise in supervised
classification, and some studies have shown that BERT is already robust against
high rates of randomly injected label noise. However, real label noise is not
random; rather, it is often correlated with input features or other
annotator-specific factors. In this paper, we evaluate BERT in the presence of
two types of realistic label noise: feature-dependent label noise, and
synthetic label noise from annotator disagreements. We show that the presence
of these types of noise significantly degrades BERT classification performance.
To improve robustness, we evaluate different types of ensembles and
noise-cleaning methods and compare their effectiveness against label noise
across different datasets.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 18:30:31 GMT""}]","2023-05-29"
"2305.16338","Jikun Kang","Jikun Kang, Romain Laroche, Xindi Yuan, Adam Trischler, Xue Liu, Jie
  Fu","Think Before You Act: Decision Transformers with Internal Working Memory",,,,,"cs.LG cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large language model (LLM)-based decision-making agents have shown the
ability to generalize across multiple tasks. However, their performance relies
on massive data and compute. We argue that this inefficiency stems from the
forgetting phenomenon, in which a model memorizes its behaviors in parameters
throughout training. As a result, training on a new task may deteriorate the
model's performance on previous tasks. In contrast to LLMs' implicit memory
mechanism, the human brain utilizes distributed memory storage, which helps
manage and organize multiple skills efficiently, mitigating the forgetting
phenomenon. Thus inspired, we propose an internal working memory module to
store, blend, and retrieve information for different downstream tasks.
Evaluation results show that the proposed method improves training efficiency
and generalization in both Atari games and meta-world object manipulation
tasks. Moreover, we demonstrate that memory fine-tuning further enhances the
adaptability of the proposed architecture.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 01:20:22 GMT""}]","2023-05-29"
"2305.16339","Xiang Zhang","Xiang Zhang, Senyu Li, Bradley Hauer, Ning Shi, Grzegorz Kondrak","Don't Trust GPT When Your Question Is Not In English","10 pages, 6 figures",,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by/4.0/","  Large Language Models (LLMs) have demonstrated exceptional natural language
understanding abilities and have excelled in a variety of natural language
processing (NLP)tasks in recent years. Despite the fact that most LLMs are
trained predominantly in English, multiple studies have demonstrated their
comparative performance in many other languages. However, fundamental questions
persist regarding how LLMs acquire their multi-lingual abilities and how
performance varies across different languages. These inquiries are crucial for
the study of LLMs since users and researchers often come from diverse language
backgrounds, potentially influencing their utilization and interpretation of
LLMs' results. In this work, we propose a systematic way of qualifying the
performance disparities of LLMs under multilingual settings. We investigate the
phenomenon of across-language generalizations in LLMs, wherein insufficient
multi-lingual training data leads to advanced multi-lingual capabilities. To
accomplish this, we employ a novel back-translation-based prompting method. The
results show that GPT exhibits highly translating-like behaviour in
multilingual settings.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 02:05:03 GMT""}]","2023-05-29"
"2305.16340","Yinghan Long","Yinghan Long, Sayeed Shafayet Chowdhury, Kaushik Roy","Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformers have shown dominant performance across a range of domains
including language and vision. However, their computational cost grows
quadratically with the sequence length, making their usage prohibitive for
resource-constrained applications. To counter this, our approach is to divide
the whole sequence into segments. The information across segments can then be
aggregated using neurons with recurrence leveraging their inherent memory. Such
an approach leads to models with sequential processing capability at a lower
computation/memory cost. To investigate this idea, first, we examine the
effects of using local attention mechanism on the individual segments. Then we
propose a segmented recurrent transformer (SRformer) that combines segmented
attention with recurrent attention. It uses recurrent accumulate and fire (RAF)
layers to process information between consecutive segments. The loss caused by
reducing the attention window length is compensated by updating the product of
keys and values with RAF neurons' inherent recurrence. The segmented attention
and lightweight RAF gates ensure the efficiency of the proposed transformer. We
apply the proposed method to T5 and BART transformers. The modified models are
tested on summarization datasets including CNN-dailymail and XSUM. Notably,
using segmented inputs of different sizes, the proposed model achieves 4-19%
higher ROUGE1 scores than the segmented transformer baseline. Compared to full
attention, the proposed model largely reduces the complexity of cross attention
and results in around 40% reduction in computation cost.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 03:47:22 GMT""}]","2023-05-29"
"2305.16341","Mohsen Pourvali","Mohsen Pourvali, Yao Meng, Chen Sheng, Yangzhou Du","TaxoKnow: Taxonomy as Prior Knowledge in the Loss Function of
  Multi-class Classification",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigate the effectiveness of integrating a hierarchical
taxonomy of labels as prior knowledge into the learning algorithm of a flat
classifier. We introduce two methods to integrate the hierarchical taxonomy as
an explicit regularizer into the loss function of learning algorithms. By
reasoning on a hierarchical taxonomy, a neural network alleviates its output
distributions over the classes, allowing conditioning on upper concepts for a
minority class. We limit ourselves to the flat classification task and provide
our experimental results on two industrial in-house datasets and two public
benchmarks, RCV1 and Amazon product reviews. Our obtained results show the
significant effect of a taxonomy in increasing the performance of a learner in
semisupervised multi-class classification and the considerable results obtained
in a fully supervised fashion.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:08:56 GMT""}]","2023-05-29"
"2305.16342","Zhihao Lai","Zhi-Hao Lai, Tian-Hao Zhang, Qi Liu, Xinyuan Qian, Li-Fang Wei,
  Song-Lu Chen, Feng Chen, Xu-Cheng Yin","InterFormer: Interactive Local and Global Features Fusion for Automatic
  Speech Recognition","Accepted by Interspeech 2023",,,,"cs.CL cs.AI cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The local and global features are both essential for automatic speech
recognition (ASR). Many recent methods have verified that simply combining
local and global features can further promote ASR performance. However, these
methods pay less attention to the interaction of local and global features, and
their series architectures are rigid to reflect local and global relationships.
To address these issues, this paper proposes InterFormer for interactive local
and global features fusion to learn a better representation for ASR.
Specifically, we combine the convolution block with the transformer block in a
parallel design. Besides, we propose a bidirectional feature interaction module
(BFIM) and a selective fusion module (SFM) to implement the interaction and
fusion of local and global features, respectively. Extensive experiments on
public ASR datasets demonstrate the effectiveness of our proposed InterFormer
and its superior performance over the other Transformer and Conformer models.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:43:44 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 11:28:27 GMT""}]","2023-05-30"
"2305.16343","Ciprian-Octavian Truic\u{a}","Ciprian-Octavian Truic\u{a} and Neculai-Ovidiu Istrate and
  Elena-Simona Apostol","A Distributed Automatic Domain-Specific Multi-Word Term Recognition
  Architecture using Spark Ecosystem",,,,,"cs.CL cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Automatic Term Recognition is used to extract domain-specific terms that
belong to a given domain. In order to be accurate, these corpus and
language-dependent methods require large volumes of textual data that need to
be processed to extract candidate terms that are afterward scored according to
a given metric. To improve text preprocessing and candidate terms extraction
and scoring, we propose a distributed Spark-based architecture to automatically
extract domain-specific terms. The main contributions are as follows: (1)
propose a novel distributed automatic domain-specific multi-word term
recognition architecture built on top of the Spark ecosystem; (2) perform an
in-depth analysis of our architecture in terms of accuracy and scalability; (3)
design an easy-to-integrate Python implementation that enables the use of Big
Data processing in fields such as Computational Linguistics and Natural
Language Processing. We prove empirically the feasibility of our architecture
by performing experiments on two real-world datasets.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:05:59 GMT""}]","2023-05-29"
"2305.16344","Chongjian Yue","Chongjian Yue, Xinrun Xu, Xiaojun Ma, Lun Du, Hengyu Liu, Zhiming
  Ding, Yanbing Jiang, Shi Han, Dongmei Zhang","Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A
  Comprehensive Framework and Dataset",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Large Language Models (LLMs) demonstrate exceptional performance in textual
understanding and tabular reasoning tasks. However, their ability to comprehend
and analyze hybrid text, containing textual and tabular data, remains
underexplored. In this research, we specialize in harnessing the potential of
LLMs to comprehend critical information from financial reports, which are
hybrid long-documents. We propose an Automated Financial Information Extraction
(AFIE) framework that enhances LLMs' ability to comprehend and extract
information from financial reports. To evaluate AFIE, we develop a Financial
Reports Numerical Extraction (FINE) dataset and conduct an extensive
experimental analysis. Our framework is effectively validated on GPT-3.5 and
GPT-4, yielding average accuracy increases of 53.94% and 33.77%, respectively,
compared to a naive method. These results suggest that the AFIE framework
offers accuracy for automated numerical extraction from complex, hybrid
documents.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:35:58 GMT""}]","2023-05-29"
"2305.16345","A. D. Alhaidari","A. D. Alhaidari and A. Laradji","A Novel Algebraic System in Quantum Field Theory",,"AppliedMath 3 (2023) 461-467","10.3390/appliedmath3020024",,"physics.gen-ph","http://creativecommons.org/licenses/by/4.0/","  An algebraic system is introduced, which is very useful for doing scattering
calculations in quantum field theory. It is the set of all real numbers greater
than or equal to -m^2 with parity designation and a special rule for addition
and subtraction, where m is the rest mass of the scattered particle.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:57:02 GMT""}]","2023-05-29"
"2305.16346","Farida Mohsen","Farida Mohsen, Hamada R. H. Al-Absi, Noha A.Yousri, Nady El Hajj, and
  Zubair Shah","Artificial Intelligence-Based Methods for Precision Medicine: Diabetes
  Risk Prediction",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  The rising prevalence of type 2 diabetes mellitus (T2DM) necessitates the
development of predictive models for T2DM risk assessment. Artificial
intelligence (AI) models are being extensively used for this purpose, but a
comprehensive review of their advancements and challenges is lacking. This
scoping review analyzes existing literature on AI-based models for T2DM risk
prediction. Forty studies were included, mainly published in the past four
years. Traditional machine learning models were more prevalent than deep
learning models. Electronic health records were the most commonly used data
source. Unimodal AI models relying on EHR data were prominent, while only a few
utilized multimodal models. Both unimodal and multimodal models showed
promising performance, with the latter outperforming the former. Internal
validation was common, while external validation was limited. Interpretability
methods were reported in half of the studies. Few studies reported novel
biomarkers, and open-source code availability was limited. This review provides
insights into the current state and limitations of AI-based T2DM risk
prediction models and highlights challenges for their development and clinical
implementation.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:45:54 GMT""}]","2023-05-29"
"2305.16347","Melvin Wong","Melvin Wong, Yew-Soon Ong, Abhishek Gupta, Kavitesh K. Bali, Caishun
  Chen","Prompt Evolution for Generative AI: A Classifier-Guided Approach","To appear in Proceedings of the 2023 IEEE Conference on Artificial
  Intelligence (CAI'23)",,"10.1109/CAI54212.2023.00105",,"cs.LG cs.AI cs.CV cs.NE","http://creativecommons.org/licenses/by/4.0/","  Synthesis of digital artifacts conditioned on user prompts has become an
important paradigm facilitating an explosion of use cases with generative AI.
However, such models often fail to connect the generated outputs and desired
target concepts/preferences implied by the prompts. Current research addressing
this limitation has largely focused on enhancing the prompts before output
generation or improving the model's performance up front. In contrast, this
paper conceptualizes prompt evolution, imparting evolutionary selection
pressure and variation during the generative process to produce multiple
outputs that satisfy the target concepts/preferences better. We propose a
multi-objective instantiation of this broader idea that uses a multi-label
image classifier-guided approach. The predicted labels from the classifiers
serve as multiple objectives to optimize, with the aim of producing diversified
images that meet user preferences. A novelty of our evolutionary algorithm is
that the pre-trained generative model gives us implicit mutation operations,
leveraging the model's stochastic generative capability to automate the
creation of Pareto-optimized images more faithful to user preferences.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 14:48:18 GMT""}]","2023-06-06"
"2305.16402","Yanran Wang","Yanran Wang, Jonghyuk Baek, Yichun Tang, Jing Du, Mike Hillman, J. S.
  Chen","Support Vector Machine Guided Reproducing Kernel Particle Method for
  Image-Based Modeling of Microstructures","58 pages, 51 figures, keywords: image-based modeling, support vector
  machine, reproducing kernel particle method, weak discontinuity,
  microstructures",,,,"cs.LG cs.CE cs.NA math.NA physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents an approach for automating the discretization and
approximation procedures in constructing digital representations of composites
from Micro-CT images featuring intricate microstructures. The proposed method
is guided by the Support Vector Machine (SVM) classification, offering an
effective approach for discretizing microstructural images. An SVM soft margin
training process is introduced as a classification of heterogeneous material
points, and image segmentation is accomplished by identifying support vectors
through a local regularized optimization problem. In addition, an
Interface-Modified Reproducing Kernel Particle Method (IM-RKPM) is proposed for
appropriate approximations of weak discontinuities across material interfaces.
The proposed method modifies the smooth kernel functions with a regularized
heavy-side function concerning the material interfaces to alleviate Gibb's
oscillations. This IM-RKPM is formulated without introducing duplicated degrees
of freedom associated with the interface nodes commonly needed in the
conventional treatments of weak discontinuities in the meshfree methods.
Moreover, IM-RKPM can be implemented with various domain integration
techniques, such as Stabilized Conforming Nodal Integration (SCNI). The
extension of the proposed method to 3-dimension is straightforward, and the
effectiveness of the proposed method is validated through the image-based
modeling of polymer-ceramic composite microstructures.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 19:00:09 GMT""}]","2023-05-29"
"2305.17453","N\'ickolas De Aguiar Alves","N\'ickolas de Aguiar Alves","Nonperturbative Aspects of Quantum Field Theory in Curved Spacetime","MSc thesis defended at the Federal University of ABC (Brazil) on 28
  April 2023. xxiv + 152 pages, 22 figures",,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  Quantum field theory in curved spacetime is perhaps the most reliable
framework in which one can investigate quantum effects in the presence of
strong gravitational fields. Nevertheless, it is often studied by means of
perturbative treatments. In this thesis, we aim at using the functional
renormalization group -- a nonperturbative realization of the renormalization
group -- as a technique to describe nonperturbative quantum phenomena in curved
spacetimes. The chosen system is an Unruh--DeWitt particle detector coupled to
a scalar quantum field. We discuss how to formulate such a system in terms of
an action and how one can compute its renormalization group flow in the case of
an inertial detector in flat spacetime, for simplicity. We learn, however, that
the results are divergent in the limit in which the detector's energy gap
vanishes. Possible workarounds are discussed at the end.
  This thesis also presents a review of quantum field theory in curved
spacetimes by means of the algebraic approach, although it assumes no previous
experience with functional analysis. Hence, it fills a pedagogical gap in the
literature. Furthermore, we also review the functional renormalization group
and derive the Wetterich equation assuming a general field content that might
include both bosonic and fermionic fields. Such a derivation is also hardly
found in pedagogical introductions available in the high energy physics
literature.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 22:34:24 GMT""}]","2023-05-30"
"2305.18219","Michele Albano","Alexander Droob, Daniel Morratz, Frederik Langkilde Jakobsen, Jacob
  Carstensen, Magnus Mathiesen, Rune Bohnstedt, Michele Albano, Sergio
  Moreschini, Davide Taibi","Workrs: Fault Tolerant Horizontal Computation Offloading","extended version of a paper accepted at IEEE Edge 2023",,,,"cs.DC cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The broad development and usage of edge devices has highlighted the
importance of creating resilient and computationally advanced environments.
When working with edge devices these desiderata are usually achieved through
replication and offloading. This paper reports on the design and implementation
of Workrs, a fault tolerant service that enables the offloading of jobs from
devices with limited computational power. We propose a solution that allows
users to upload jobs through a web service, which will be executed on edge
nodes within the system. The solution is designed to be fault tolerant and
scalable, with no single point of failure as well as the ability to accommodate
growth, if the service is expanded. The use of Docker checkpointing on the
worker machines ensures that jobs can be resumed in the event of a fault. We
provide a mathematical approach to optimize the number of checkpoints that are
created along a computation, given that we can forecast the time needed to
execute a job. We present experiments that indicate in which scenarios
checkpointing benefits job execution. The results achieved are based on a
working prototype which shows clear benefits of using checkpointing and restore
when the completion jobs' time rises compared with the forecast fault rate. The
code of Workrs is released as open source, and it is available at
\url{https://github.com/orgs/P7-workrs/repositories}. This paper is an extended
version of \cite{edge2023paper}.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 08:08:51 GMT""}]","2023-05-30"
"2305.18242","Haoran Liu","Runxi Liu, Peng Li, Haoran Liu","Dataset for neutron and gamma-ray pulse shape discrimination","11 pages,10 figures",,,,"eess.SP physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The publicly accessible dataset includes neutron and gamma-ray pulse signals
for conducting pulse shape discrimination experiments. Several traditional and
recently proposed pulse shape discrimination algorithms are utilized to
evaluate the performance of pulse shape discrimination under raw pulse signals
and noise-enhanced datasets. These algorithms comprise zero-crossing (ZC),
charge comparison (CC), falling edge percentage slope (FEPS), frequency
gradient analysis (FGA), pulse-coupled neural network (PCNN), ladder gradient
(LG), and het-erogeneous quasi-continuous spiking cortical model (HQC-SCM). In
addition to the pulse signals, this dataset includes the source code for all
the aforementioned pulse shape discrimination methods. Moreover, the dataset
provides the source code for schematic pulse shape discrimination performance
evaluation and anti-noise performance evaluation. This feature enables
researchers to evaluate the performance of these methods using standard
procedures and assess their anti-noise ability under various noise conditions.
In conclusion, this dataset offers a comprehensive set of resources for
conducting pulse shape discrimination experiments and evaluating the
performance of various pulse shape discrimination methods under different noise
scenarios.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:12:45 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 11:16:27 GMT""}]","2023-05-31"
"2305.18329","Pengfei Zhang","Pengfei Zhang","Perturbative Page Curve Induced by External Impulse","19 pages, 2 figures",,,,"cond-mat.stat-mech cond-mat.str-el hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  In this work, we extend the recent study of entropy dynamics induced by an
external impulse in open quantum systems, where the entropy response follows
the Page curve. For small system-bath coupling $\kappa$, we expect that the
entropy first increases exponentially $\kappa^2 e^{\varkappa t}$ in the
early-time regime $t\lesssim |\log \kappa|$ due to quantum many-body chaos, and
then decreases as $~e^{-\lambda_0 t}$ with $\lambda_0 \propto \kappa^2$ due to
the energy relaxation. These results are confirmed through explicit
calculations using two methods: 1) generalized Boltzmann equation for systems
with quasi-particles; 2) scramblon effective theory in the early-time regime
and perturbation theory in the late-time regime for 0+1-d systems. We also
prove that in the second stage, the entropy of the system is equal to the
coarse-grained entropy.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:08:12 GMT""}]","2023-05-31"
"2305.18330","Areej Alsini","Areej Alsini, Du Q. Huynh and Amitava Datta","#REVAL: a semantic evaluation framework for hashtag recommendation","18 pages, 4 figures",,,,"cs.IR cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Automatic evaluation of hashtag recommendation models is a fundamental task
in many online social network systems. In the traditional evaluation method,
the recommended hashtags from an algorithm are firstly compared with the ground
truth hashtags for exact correspondences. The number of exact matches is then
used to calculate the hit rate, hit ratio, precision, recall, or F1-score. This
way of evaluating hashtag similarities is inadequate as it ignores the semantic
correlation between the recommended and ground truth hashtags. To tackle this
problem, we propose a novel semantic evaluation framework for hashtag
recommendation, called #REval. This framework includes an internal module
referred to as BERTag, which automatically learns the hashtag embeddings. We
investigate on how the #REval framework performs under different word embedding
methods and different numbers of synonyms and hashtags in the recommendation
using our proposed #REval-hit-ratio measure. Our experiments of the proposed
framework on three large datasets show that #REval gave more meaningful hashtag
synonyms for hashtag recommendation evaluation. Our analysis also highlights
the sensitivity of the framework to the word embedding technique, with #REval
based on BERTag more superior over #REval based on FastText and Word2Vec.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 07:10:56 GMT""}]","2023-05-31"
"2305.18331","Valentina Belova","Valentina Belova, Hao Gao, Wissal Sghaier, Anastasios Manikas, Mehdi
  Saedi, Hendrik H. Heenen, Costas Galiotis, Gilles Renaud, Oleg V. Konovalov,
  Irene M. N. Groot, Karsten Reuter, Maciej Jankowski","Kinetics of Graphene Growth on Liquid Copper by Chemical Vapor
  Deposition",,,,,"cond-mat.mtrl-sci physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  We report a combined experimental and computational study of the kinetics of
graphene growth during chemical vapor deposition on a liquid copper catalyst.
The use of liquid metal catalysts offers bright perspectives for controllable
large-scale, high-quality synthesis technologies of two-dimensional materials.
We carried out a series of growth experiments varying CH4-to-H2 pressure ratios
and deposition temperature. By monitoring the graphene flake morphology in real
time during growth using in situ optical microscopy in radiation mode, we
explored the morphology and kinetics of the growth within a wide range of
experimental conditions. Following an analysis of the flakes' growth rates, we
conclude that the growth mode was attachment-limited. The attachment and
detachment activation energies of carbon species are derived as 1.9 +- 0.3 eV
and 2.0 +- 0.1 eV, respectively. We also conducted free-energy calculations by
a moment tensor potential trained to density functional theory data. Our
simulations propose that carbon dimers are most likely the active carbon
species during growth, with attachment and detachment barriers of 1.71 +- 0.15
eV and 2.09 +- 0.02 eV, respectively, being in good agreement with the
experimental results.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:47:41 GMT""}]","2023-05-31"
"2305.19329","Fanjie Kong","Fanjie Kong, Shuai Yuan, Weituo Hao, Ricardo Henao","Mitigating Test-Time Bias for Fair Image Retrieval",,,,,"cs.CV cs.IR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the challenge of generating fair and unbiased image retrieval
results given neutral textual queries (with no explicit gender or race
connotations), while maintaining the utility (performance) of the underlying
vision-language (VL) model. Previous methods aim to disentangle learned
representations of images and text queries from gender and racial
characteristics. However, we show these are inadequate at alleviating bias for
the desired equal representation result, as there usually exists test-time bias
in the target retrieval set. So motivated, we introduce a straightforward
technique, Post-hoc Bias Mitigation (PBM), that post-processes the outputs from
the pre-trained vision-language model. We evaluate our algorithm on real-world
image search datasets, Occupation 1 and 2, as well as two large-scale
image-text datasets, MS-COCO and Flickr30k. Our approach achieves the lowest
bias, compared with various existing bias-mitigation methods, in text-based
image retrieval result while maintaining satisfactory retrieval performance.
The source code is publicly available at
\url{https://anonymous.4open.science/r/Fair_Text_based_Image_Retrieval-D8B2}.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 21:31:16 GMT""}]","2023-06-01"
"2306.01756","Jingtao Guo","Jingtao Guo, Ivan Wang-Hei Ho","CSI-Based Efficient Self-Quarantine Monitoring System Using Branchy
  Convolution Neural Network","6 pages, 7 figures, to be published in Proceedings of the 8th IEEE
  World Forum on the Internet of Things",,,,"cs.CV cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nowadays, Coronavirus disease (COVID-19) has become a global pandemic because
of its fast spread in various countries. To build an anti-epidemic barrier,
self-isolation is required for people who have been to any at-risk places or
have been in close contact with infected people. However, existing camera or
wearable device-based monitoring systems may present privacy leakage risks or
cause user inconvenience in some cases. In this paper, we propose a Wi-Fi-based
device-free self-quarantine monitoring system. Specifically, we exploit channel
state information (CSI) derived from Wi-Fi signals as human activity features.
We collect CSI data in a simulated self-quarantine scenario and present
BranchyGhostNet, a lightweight convolution neural network (CNN) with an early
exit prediction branch, for the efficient joint task of room occupancy
detection (ROD) and human activity recognition (HAR). The early exiting branch
is used for ROD, and the final one is used for HAR. Our experimental results
indicate that the proposed model can achieve an average accuracy of 98.19% for
classifying five different human activities. They also confirm that after
leveraging the early exit prediction mechanism, the inference latency for ROD
can be significantly reduced by 54.04% when compared with the final exiting
branch while guaranteeing the accuracy of ROD.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 04:02:49 GMT""}]","2023-06-06"
"2306.04629","Szabolcs Cs\'efalvay","Arturo Salmi, Szabolcs Cs\'efalvay, James Imber","Generative Adversarial Shaders for Real-Time Realism Enhancement","12 pages, 9 figures, 2 tables",,,,"cs.GR cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Application of realism enhancement methods, particularly in real-time and
resource-constrained settings, has been frustrated by the expense of existing
methods. These achieve high quality results only at the cost of long runtimes
and high bandwidth, memory, and power requirements. We present an efficient
alternative: a high-performance, generative shader-based approach that adapts
machine learning techniques to real-time applications, even in
resource-constrained settings such as embedded and mobile GPUs. The proposed
learnable shader pipeline comprises differentiable functions that can be
trained in an end-to-end manner using an adversarial objective, allowing for
faithful reproduction of the appearance of a target image set without manual
tuning. The shader pipeline is optimized for highly efficient execution on the
target device, providing temporally stable, faster-than-real time results with
quality competitive with many neural network-based methods.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 15:42:38 GMT""}]","2023-06-08"
"2306.04657","Hua Cai","Hua Cai, Xuli Shen, Qing Xu, Weilin Shen, Xiaomei Wang, Weifeng Ge,
  Xiaoqing Zheng and Xiangyang Xue","Improving Empathetic Dialogue Generation by Dynamically Infusing
  Commonsense Knowledge","Accepted by ACL 2023. arXiv admin note: substantial text overlap with
  arXiv:2109.05739 by other authors",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In empathetic conversations, individuals express their empathy towards
others. Previous work has mainly focused on generating empathetic responses by
utilizing the speaker's emotion. Besides, external commonsense knowledge has
been applied to enhance the system's understandings of the speaker's situation.
However, given an event, commonsense knowledge base contains various relations,
potentially leading to confusion for the dialogue system. Consequently,
inconsistencies arise among the emotion, generated response and speaker's
contextual information. To this end, we propose a novel approach for empathetic
response generation, which incorporates an adaptive module for commonsense
knowledge selection to ensure consistency between the generated empathetic
responses and the speaker's situation. This selected knowledge is used to
refine the commonsense cognition and empathy expression for generated
responses. Experimental results show that our approach significantly
outperforms baseline models in both automatic and human evaluations, exhibiting
the generation of more coherent and empathetic responses. Moreover, case
studies highlight the interpretability of knowledge selection in the responses
and the effectiveness of adaptive module in our model. Code:
https://github.com/Hanscal/DCKS.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 10:25:12 GMT""}]","2023-06-09"
"2306.05375","Anwar Said","Ammar Ahmed, Anwar Said, Mudassir Shabbir, Xenofon Koutsoukos","Sequential Graph Neural Networks for Source Code Vulnerability
  Identification","7 pages paper presented at HotSoS2023 conference",,,,"cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Vulnerability identification constitutes a task of high importance for cyber
security. It is quite helpful for locating and fixing vulnerable functions in
large applications. However, this task is rather challenging owing to the
absence of reliable and adequately managed datasets and learning models.
Existing solutions typically rely on human expertise to annotate datasets or
specify features, which is prone to error. In addition, the learning models
have a high rate of false positives. To bridge this gap, in this paper, we
present a properly curated C/C++ source code vulnerability dataset, denoted as
CVEFunctionGraphEmbeddings (CVEFGE), to aid in developing models. CVEFGE is
automatically crawled from the CVE database, which contains authentic and
publicly disclosed source code vulnerabilities. We also propose a learning
framework based on graph neural networks, denoted SEquential Graph Neural
Network (SEGNN) for learning a large number of code semantic representations.
SEGNN consists of a sequential learning module, graph convolution, pooling, and
fully connected layers. Our evaluations on two datasets and four baseline
methods in a graph classification setting demonstrate state-of-the-art results.
","[{""version"":""v1"",""created"":""Tue, 23 May 2023 17:25:51 GMT""}]","2023-06-09"
"2306.05380","Jiacheng Yao","Jiacheng Yao, Zhaohui Yang, Wei Xu, Mingzhe Chen, and Dusit Niyato","GoMORE: Global Model Reuse for Resource-Constrained Wireless Federated
  Learning","accepted by TEEE WCL",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the dynamics of wireless environment and limited bandwidth, wireless
federated learning (FL) is challenged by frequent transmission errors and
incomplete aggregation from devices. In order to overcome these challenges, we
propose a global model reuse strategy (GoMORE) that reuses the outdated global
model to replace the local model parameters once a transmission error occurs.
We analytically prove that the proposed GoMORE is strictly superior over the
existing strategy, especially at low signal-to-noise ratios (SNRs). In
addition, based on the derived expression of weight divergence, we further
optimize the number of participating devices in the model aggregation to
maximize the FL performance with limited communication resources. Numerical
results verify that the proposed GoMORE successfully approaches the performance
upper bound by an ideal transmission. It also mitigates the negative impact of
non-independent and non-identically distributed (non-IID) data while achieving
over 5 dB reduction in energy consumption.
","[{""version"":""v1"",""created"":""Wed, 24 May 2023 11:50:21 GMT""}]","2023-06-09"
