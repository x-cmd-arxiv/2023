"2302.00753","Ayan Paul","Fady Bishara, Ayan Paul, and Jennifer Dy","High-precision regressors for particle physics","15 pages, 7 figure and 2 tables",,,"DESY 22-174","physics.comp-ph cs.LG hep-ex hep-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Monte Carlo simulations of physics processes at particle colliders like the
Large Hadron Collider at CERN take up a major fraction of the computational
budget. For some simulations, a single data point takes seconds, minutes, or
even hours to compute from first principles. Since the necessary number of data
points per simulation is on the order of $10^9$ - $10^{12}$, machine learning
regressors can be used in place of physics simulators to significantly reduce
this computational burden. However, this task requires high-precision
regressors that can deliver data with relative errors of less than $1\%$ or
even $0.1\%$ over the entire domain of the function. In this paper, we develop
optimal training strategies and tune various machine learning regressors to
satisfy the high-precision requirement. We leverage symmetry arguments from
particle physics to optimize the performance of the regressors. Inspired by
ResNets, we design a Deep Neural Network with skip connections that outperform
fully connected Deep Neural Networks. We find that at lower dimensions, boosted
decision trees far outperform neural networks while at higher dimensions neural
networks perform significantly better. We show that these regressors can speed
up simulations by a factor of $10^3$ - $10^6$ over the first-principles
computations currently used in Monte Carlo simulations. Additionally, using
symmetry arguments derived from particle physics, we reduce the number of
regressors necessary for each simulation by an order of magnitude. Our work can
significantly reduce the training and storage burden of Monte Carlo simulations
at current and future collider experiments.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:55:12 GMT""}]","2023-02-03"
"2302.01180","Peter Sunehag","Peter Sunehag, Alexander Sasha Vezhnevets, Edgar Du\'e\~nez-Guzm\'an,
  Igor Mordach, Joel Z. Leibo","Diversity Through Exclusion (DTE): Niche Identification for
  Reinforcement Learning through Value-Decomposition","Full length paper accompanying short format appearing at AAMAS 2023",,,,"cs.AI cs.NE","http://creativecommons.org/licenses/by/4.0/","  Many environments contain numerous available niches of variable value, each
associated with a different local optimum in the space of behaviors (policy
space). In such situations it is often difficult to design a learning process
capable of evading distraction by poor local optima long enough to stumble upon
the best available niche. In this work we propose a generic reinforcement
learning (RL) algorithm that performs better than baseline deep Q-learning
algorithms in such environments with multiple variably-valued niches. The
algorithm we propose consists of two parts: an agent architecture and a
learning rule. The agent architecture contains multiple sub-policies. The
learning rule is inspired by fitness sharing in evolutionary computation and
applied in reinforcement learning using Value-Decomposition-Networks in a novel
manner for a single-agent's internal population. It can concretely be
understood as adding an extra loss term where one policy's experience is also
used to update all the other policies in a manner that decreases their value
estimates for the visited states. In particular, when one sub-policy visits a
particular state frequently this decreases the value predicted for other
sub-policies for going to that state. Further, we introduce an artificial
chemistry inspired platform where it is easy to create tasks with multiple
rewarding strategies utilizing different resources (i.e. multiple niches). We
show that agents trained this way can escape poor-but-attractive local optima
to instead converge to harder-to-discover higher value strategies in both the
artificial chemistry environments and in simpler illustrative environments.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:00:19 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 10:23:48 GMT""}]","2023-02-06"
"2302.01181","Pritam Chattopadhyay","Jonas F. G. Santos, Pritam Chattopadhyay","$\mathcal{PT}$-symmetric effects in measurement-based quantum thermal
  machines",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Measurement-based quantum thermal machines are fascinating models of
thermodynamic cycles where measurement protocols play an important role in the
performance and functioning of the cycle. Despite theoretical advances,
interesting experimental implementations have been reported. Here we move a
step further by considering in this class of cycle $\mathcal{PT}$-symmetric
non-Hermitian Hamiltonians and their implications in quantum thermal machines
fueled by generalized measurements. We present theoretical results indicating
that $\mathcal{PT}$-symmetric effects and measurement protocols are related
along the cycle. Furthermore, tuning the parameters suitably it is possible to
improve the power output (engine configuration) and the cooling rate
(refrigerator configuration), operating in the Otto limit, in a finite-time
cycle that satisfies the quantum adiabatic theorem. Our model also allows
switching the configuration of the cycle, engine, or refrigerator, depending on
the strength of the measurement protocol.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:09:26 GMT""}]","2023-02-03"
"2302.01182","Abdul Haddi Amjad","Abdul Haddi Amjad, Zubair Shafiq, Muhammad Ali Gulzar","Blocking JavaScript without Breaking the Web: An Empirical Investigation",,"petsymposium 2023",,,"cs.CR cs.SE","http://creativecommons.org/licenses/by/4.0/","  Modern websites heavily rely on JavaScript (JS) to implement legitimate
functionality as well as privacy-invasive advertising and tracking. Browser
extensions such as NoScript block any script not loaded by a trusted list of
endpoints, thus hoping to block privacy-invasive scripts while avoiding
breaking legitimate website functionality. In this paper, we investigate
whether blocking JS on the web is feasible without breaking legitimate
functionality. To this end, we conduct a large-scale measurement study of JS
blocking on 100K websites. We evaluate the effectiveness of different JS
blocking strategies in tracking prevention and functionality breakage. Our
evaluation relies on quantitative analysis of network requests and resource
loads as well as manual qualitative analysis of visual breakage. First, we show
that while blocking all scripts is quite effective at reducing tracking, it
significantly degrades functionality on approximately two-thirds of the tested
websites. Second, we show that selective blocking of a subset of scripts based
on a curated list achieves a better tradeoff. However, there remain
approximately 15% `mixed` scripts, which essentially merge tracking and
legitimate functionality and thus cannot be blocked without causing website
breakage. Finally, we show that fine-grained blocking of a subset of JS
methods, instead of scripts, reduces major breakage by 3.8$\times$ while
providing the same level of tracking prevention. Our work highlights the
promise and open challenges in fine-grained JS blocking for tracking prevention
without breaking the web.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:10:25 GMT""},{""version"":""v2"",""created"":""Sun, 5 Feb 2023 19:16:36 GMT""},{""version"":""v3"",""created"":""Thu, 23 Mar 2023 18:38:36 GMT""}]","2023-03-27"
"2302.01183","Christopher Harbord","Christopher Harbord, Nicolas Brantut and David Wallis","Grain-size effects during semi-brittle flow of calcite rocks",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  We study the role of grain size in the rheological behaviour of calcite
aggregates in the semi-brittle regime. We conduct triaxial deformation tests on
three rocks, Solnhofen limestone, Carrara marble and Wombeyan marble, with
average grain sizes of 5-10 $\mu$m, 200 $\mu$m and 2 mm, respectively, at
pressures in the range 200-800 MPa and temperatures in the range 20-400
$^\circ$C. At all conditions, both strength and hardening rate increase with
decreasing grain size. Flow stress scales with the inverse of grain size to a
power between 1/3 and 2/3. Hardening rate decreases linearly with the logarithm
of grain size. In-situ ultrasonic monitoring reveals that P-wave speed tends to
decrease with increasing strain, and that this decrease is more marked at room
temperature than at 200 and 400 $^\circ$C. The decrease in wave speed is
consistent with microcracking, which is more prevalent at low temperature and
low pressure. Microstructural observations reveal high twin densities in all
deformed samples. Twin density increases with stress, consistent with previous
datasets. Spatial distributions of intragranular misorientation indicate that
twins are sometimes obstacles to dislocation motion, but this effect is not
ubiquitous. Computed slip-transfer statistics indicate that that twins are
typically weaker barriers to dislocation glide than grain boundaries, so that
their effect on dislocation accumulation and hardening rates is likely smaller
than the effect of grain size. Indeed, our data reveal that grain size exerts a
first-order control on flow stress and hardening in calcite, whereas twinning
may only have a secondary impact on these behaviours.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:10:25 GMT""}]","2023-02-03"
"2302.01185","Marcus Berg","Marcus Berg","Manifest Modular Invariance in the Near-Critical Ising Model","23 pages, 7 figures",,,"NORDITA 2022-174","cond-mat.stat-mech cond-mat.str-el hep-th math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  Using recent results in mathematics, I point out that free energies and
scale-dependent central charges away from criticality can be represented in
compact form where modular invariance is manifest. The main example is the
near-critical Ising model on a thermal torus, but the methods are not
restricted to modular symmetry, and apply to automorphic symmetries more
generally. One application is finite-size effects.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:10:53 GMT""}]","2023-02-06"
"2302.01186","Xingyu Xu","Xingyu Xu, Yandi Shen, Yuejie Chi, Cong Ma","The Power of Preconditioning in Overparameterized Low-Rank Matrix
  Sensing",,,,,"cs.LG eess.SP math.OC stat.ML","http://creativecommons.org/licenses/by/4.0/","  We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descent
method to tackle the low-rank matrix sensing problem when the true rank is
unknown, and when the matrix is possibly ill-conditioned. Using
overparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ starts
from a small random initialization, and proceeds by gradient descent with a
specific form of damped preconditioning to combat bad curvatures induced by
overparameterization and ill-conditioning. At the expense of light
computational overhead incurred by preconditioners,
$\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioning
compared to vanilla gradient descent ($\textsf{GD}$) even with
overprameterization. Specifically, we show that, under the Gaussian design,
$\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at a
constant linear rate after a small number of iterations that scales only
logarithmically with respect to the condition number and the problem dimension.
This significantly improves over the convergence rate of vanilla $\textsf{GD}$
which suffers from a polynomial dependency on the condition number. Our work
provides evidence on the power of preconditioning in accelerating the
convergence without hurting generalization in overparameterized learning.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:13:27 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 16:36:11 GMT""}]","2023-06-07"
"2302.01187","Stephen Keeley","Stephen Keeley, Benjamin Letham, Chase Tymms, Craig Sanders, Michael
  Shvartsman","A Semi-Parametric Model for Decision Making in High-Dimensional Sensory
  Discrimination Tasks",,,,,"q-bio.NC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Psychometric functions typically characterize binary sensory decisions along
a single stimulus dimension. However, real-life sensory tasks vary along a
greater variety of dimensions (e.g. color, contrast and luminance for visual
stimuli). Approaches to characterizing high-dimensional sensory spaces either
require strong parametric assumptions about these additional contextual
dimensions, or fail to leverage known properties of classical psychometric
curves. We overcome both limitations by introducing a semi-parametric model of
sensory discrimination that applies traditional psychophysical models along a
stimulus intensity dimension, but puts Gaussian process (GP) priors on the
parameters of these models with respect to the remaining dimensions. By
combining the flexibility of the GP with the deep literature on parametric
psychophysics, our semi-parametric models achieve good performance with much
less data than baselines on both synthetic and real-world high-dimensional
psychophysics datasets. We additionally show strong performance in a Bayesian
active learning setting, and present a novel active learning paradigm for the
semi-parametric model.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:14:16 GMT""}]","2023-02-03"
"2302.01188","Zongqing Lu","Jiechuan Jiang and Zongqing Lu","Best Possible Q-Learning","14 pages",,,,"cs.LG cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fully decentralized learning, where the global information, i.e., the actions
of other agents, is inaccessible, is a fundamental challenge in cooperative
multi-agent reinforcement learning. However, the convergence and optimality of
most decentralized algorithms are not theoretically guaranteed, since the
transition probabilities are non-stationary as all agents are updating policies
simultaneously. To tackle this challenge, we propose best possible operator, a
novel decentralized operator, and prove that the policies of agents will
converge to the optimal joint policy if each agent independently updates its
individual state-action value by the operator. Further, to make the update more
efficient and practical, we simplify the operator and prove that the
convergence and optimality still hold with the simplified one. By instantiating
the simplified operator, the derived fully decentralized algorithm, best
possible Q-learning (BQL), does not suffer from non-stationarity. Empirically,
we show that BQL achieves remarkable improvement over baselines in a variety of
cooperative multi-agent tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:14:19 GMT""}]","2023-02-03"
"2302.01190","John Bronskill","Marlon Tobaben, Aliaksandra Shysheya, John Bronskill, Andrew Paverd,
  Shruti Tople, Santiago Zanella-Beguelin, Richard E Turner, Antti Honkela","On the Efficacy of Differentially Private Few-shot Image Classification",,,,,"stat.ML cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There has been significant recent progress in training differentially private
(DP) models which achieve accuracy that approaches the best non-private models.
These DP models are typically pretrained on large public datasets and then
fine-tuned on private downstream datasets that are relatively large and similar
in distribution to the pretraining data. However, in many applications
including personalization and federated learning, it is crucial to perform well
(i) in the few-shot setting, as obtaining large amounts of labeled data may be
problematic; and (ii) on datasets from a wide variety of domains for use in
various specialist settings. To understand under which conditions few-shot DP
can be effective, we perform an exhaustive set of experiments that reveals how
the accuracy and vulnerability to attack of few-shot DP image classification
models are affected as the number of shots per class, privacy level, model
architecture, downstream dataset, and subset of learnable parameters in the
model vary. We show that to achieve DP accuracy on par with non-private models,
the shots per class must be increased as the privacy level increases by as much
as 20 - 35$\times$ at $\epsilon=1$. We also show that learning
parameter-efficient FiLM adapters under DP is competitive with and often
superior to learning just the final classifier layer or learning all of the
network parameters. Finally, we evaluate DP federated learning systems and
establish state-of-the-art performance on the challenging FLAIR benchmark.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:16:25 GMT""},{""version"":""v2"",""created"":""Fri, 26 May 2023 08:43:01 GMT""}]","2023-05-29"
"2302.01192","Patrick Barry","P. C. Barry, L. Gamberg, W. Melnitchouk, E. Moffat, D. Pitonyak, A.
  Prokudin, N. Sato","Tomography of pions and protons via transverse momentum dependent
  distributions","7 pages, 3 figures",,,"JLAB-THY-23-3749, ADP-23-03/T1212","hep-ph hep-ex hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform the first simultaneous extraction of parton collinear and
transverse degrees of freedom from low-energy fixed-target Drell-Yan data in
order to compare the transverse momentum dependent (TMD) parton distribution
functions (PDFs) of the pion and proton. We demonstrate that the transverse
separation of the quark field encoded in TMDs of the pion is more than $5
\sigma$ smaller than that of the proton. Additionally, we find the transverse
separation of the quark field decreases as its longitudinal momentum fraction
decreases. In studying the nuclear modification of TMDs, we find clear evidence
for a transverse EMC effect. We comment on possible explanations for these
intriguing behaviors, which call for a deeper examination of tomography in a
variety of strongly interacting quark-gluon systems.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:18:11 GMT""}]","2023-02-03"
"2302.01193","Jack Hanslope","Jack R. P. Hanslope and Laurence Aitchison","Imitating careful experts to avoid catastrophic events","9 pages, 8 figures, accepted to NeurIPS 2022 Workshop on Robot
  Learning: Trustworthy Robotics",,,,"cs.LG cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RL is increasingly being used to control robotic systems that interact
closely with humans. This interaction raises the problem of safe RL: how to
ensure that a RL-controlled robotic system never, for instance, injures a
human. This problem is especially challenging in rich, realistic settings where
it is not even possible to clearly write down a reward function which
incorporates these outcomes. In these circumstances, perhaps the only viable
approach is based on IRL, which infers rewards from human demonstrations.
However, IRL is massively underdetermined as many different rewards can lead to
the same optimal policies; we show that this makes it difficult to distinguish
catastrophic outcomes (such as injuring a human) from merely undesirable
outcomes. Our key insight is that humans do display different behaviour when
catastrophic outcomes are possible: they become much more careful. We
incorporate carefulness signals into IRL, and find that they do indeed allow
IRL to disambiguate undesirable from catastrophic outcomes, which is critical
to ensuring safety in future real-world human-robot interactions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:19:13 GMT""}]","2023-02-03"
"2302.01194","Minglun Han","Minglun Han, Qingyu Wang, Tielin Zhang, Yi Wang, Duzhen Zhang, Bo Xu","Complex Dynamic Neurons Improved Spiking Transformer Network for
  Efficient Automatic Speech Recognition","8 pages. Spiking Neural Networks, ASR, Speech and Language
  Processing. The first three authors contributed equally",,,,"cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spiking neural network (SNN) using leaky-integrated-and-fire (LIF)
neurons has been commonly used in automatic speech recognition (ASR) tasks.
However, the LIF neuron is still relatively simple compared to that in the
biological brain. Further research on more types of neurons with different
scales of neuronal dynamics is necessary. Here we introduce four types of
neuronal dynamics to post-process the sequential patterns generated from the
spiking transformer to get the complex dynamic neuron improved spiking
transformer neural network (DyTr-SNN). We found that the DyTr-SNN could handle
the non-toy automatic speech recognition task well, representing a lower
phoneme error rate, lower computational cost, and higher robustness. These
results indicate that the further cooperation of SNNs and neural dynamics at
the neuron and network scales might have much in store for the future,
especially on the ASR tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:20:27 GMT""}]","2023-02-03"
"2302.01195","Birgit Jacob","B\'alint Farkas and Birgit Jacob and Timo Reis and Merlin Schmitz","Operator splitting based dynamic iteration for linear
  infinite-dimensional port-Hamiltonian systems",,,,,"math.FA cs.NA math.AP math.NA math.OC","http://creativecommons.org/licenses/by/4.0/","  A dynamic iteration scheme for linear infinite-dimensional port-Hamiltonian
systems is proposed. The dynamic iteration is monotone in the sense that the
error is decreasing, it does not require any stability condition and is in
particular applicable to port-Hamiltonian formulations arising from domain
decompositions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:20:41 GMT""}]","2023-02-03"
"2302.01196","Silvana Pesenti","Bernardo Freitas Paulo da Costa, Silvana M. Pesenti, Rodrigo S.
  Targino","Risk Budgeting Portfolios from Simulations",,,,,"q-fin.PM q-fin.RM","http://creativecommons.org/licenses/by-sa/4.0/","  Risk budgeting is a portfolio strategy where each asset contributes a
prespecified amount to the aggregate risk of the portfolio. In this work, we
propose an efficient numerical framework that uses only simulations of returns
for estimating risk budgeting portfolios. Besides a general cutting planes
algorithm for determining the weights of risk budgeting portfolios for
arbitrary coherent distortion risk measures, we provide a specialised version
for the Expected Shortfall, and a tailored Stochastic Gradient Descent (SGD)
algorithm, also for the Expected Shortfall. We compare our algorithm to
standard convex optimisation solvers and illustrate different risk budgeting
portfolios, constructed using an especially designed Julia package, on real
financial data and compare it to classical portfolio strategies.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:23:00 GMT""}]","2023-02-03"
"2302.01197","Marcos Lopez-Garcia Dr.","Leandro Galo-Mendoza and Marcos L\'opez-Garc\'ia","Boundary controllability for a 1D degenerate parabolic equation with
  drift and a singular potential","17 pages",,,,"math.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We prove the null controllability of a one dimensional degenerate parabolic
equation with drift and a singular potential. We study the case the potential
arises at the left end point and the weighted Dirichlet boundary control is
located at this point. We get a spectral decomposition of a suitable operator,
defined in a weighted Sobolev space, involving Bessel functions and their
zeros, then we use the moment method by Fattorini and Russell to obtain an
upper estimate of the cost of controllability. We also obtain a lower estimate
of the cost of controllability by using a representation theorem for analytic
functions of exponential type.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:23:40 GMT""}]","2023-02-03"
"2302.01198","Leonardo Cotta","Leonardo Cotta, Beatrice Bevilacqua, Nesreen Ahmed, Bruno Ribeiro","Causal Lifting and Link Prediction",,,,,"cs.LG cs.AI stat.ME stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current state-of-the-art causal models for link prediction assume an
underlying set of inherent node factors -- an innate characteristic defined at
the node's birth -- that governs the causal evolution of links in the graph. In
some causal tasks, however, link formation is path-dependent, i.e., the outcome
of link interventions depends on existing links. For instance, in the
customer-product graph of an online retailer, the effect of an 85-inch TV ad
(treatment) likely depends on whether the costumer already has an 85-inch TV.
Unfortunately, existing causal methods are impractical in these scenarios. The
cascading functional dependencies between links (due to path dependence) are
either unidentifiable or require an impractical number of control variables. In
order to remedy this shortcoming, this work develops the first causal model
capable of dealing with path dependencies in link prediction. It introduces the
concept of causal lifting, an invariance in causal models that, when satisfied,
allows the identification of causal link prediction queries using limited
interventional data. On the estimation side, we show how structural pairwise
embeddings -- a type of symmetry-based joint representation of node pairs in a
graph -- exhibit lower bias and correctly represent the causal structure of the
task, as opposed to existing node embedding methods, e.g., GNNs and matrix
factorization. Finally, we validate our theoretical findings on four datasets
under three different scenarios for causal link prediction tasks: knowledge
base completion, covariance matrix estimation and consumer-product
recommendations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:25:16 GMT""}]","2023-02-03"
"2302.01200","Ingrid Vanessa Daza Perilla","I. V. Daza-Perilla, L. V. Gramajo, M. Lares, T. Palma, C. E. Ferreira
  Lopes, D. Minniti, J. J. Clari\'a","Automated classification of eclipsing binary systems in the VVV Survey","11 pages, 9 figures, , accepted in MNRAS",,"10.1093/mnras/stad141",,"astro-ph.SR astro-ph.GA astro-ph.IM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With the advent of large-scale photometric surveys of the sky, modern science
witnesses the dawn of big data astronomy, where automatic handling and
discovery are paramount. In this context, classification tasks are among the
key capabilities a data reduction pipeline must possess in order to compile
reliable datasets, to accomplish data processing with an efficiency level
impossible to achieve by means of detailed processing and human intervention.
The VISTA Variables of the V\'ia L\'actea Survey, in the southern part of the
Galactic disc, comprises multi-epoch photometric data necessary for the
potential discovery of variable objects, including eclipsing binary systems
(EBs). In this study we use a recently published catalogue of one hundred EBs,
classified by fine-tuning theoretical models according to contact, detached or
semi-detached classes belonging to the tile d040 of the VVV. We describe the
method implemented to obtain a supervised machine learning model, capable of
classifying EBs using information extracted from the light curves of variable
object candidates in the phase space from tile d078. We also discuss the
efficiency of the models, the relative importance of the features and the
future prospects to construct an extensive database of EBs in the VVV survey.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:27:43 GMT""}]","2023-02-03"
"2302.01201","Jean Van Schaftingen","Jean Van Schaftingen","Injective ellipticity, cancelling operators, and endpoint
  Gagliardo-Nirenberg-Sobolev inequalities for vector fields","46 pages, lecture notes for the CIME summer school ""Geometric and
  analytic aspects of functional variational principles'', June 27 - July 1,
  2022",,,,"math.AP math.CA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although Ornstein's nonestimate entails the impossibility to control in
general all the $L^1$-norm of derivatives of a function by the $L^1$-norm of a
constant coefficient homogeneous vector differential operator, the
corresponding endpoint Sobolev inequality has been known to hold in many cases:
the gradient of scalar functions (Gagliardo and Nirenberg), the deformation
operator (Korn-Sobolev inequality by M.J. Strauss), and the Hodge complex
(Bourgain and Brezis). The class of differential operators for which estimates
holds can be characterized by a cancelling condition. The proof of the
estimates rely on a duality estimate for $L^1$-vector fields lying in the
kernel of a cocancelling differential operator, combined with classical linear
algebra and harmonic analysis techniques. This characterization unifies classes
of known Sobolev inequalities and extends to fractional Sobolev and Hardy
inequalities. A similar weaker condition introduced by Rai\c{t}\u{a}
characterizes the operators for which there is an $L^\infty$-estimate on
lower-order derivatives.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:30:15 GMT""}]","2023-02-03"
"2302.01202","Ulrik Enstad","Ulrik Enstad, Jordy Timo van Velthoven","Linear independence of coherent systems associated to lattices","12 pages",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This note considers the finite linear independence of coherent systems. We
show by simple arguments that lattice coherent systems of amenable groups are
linearly independent whenever the associated twisted group ring does not
contain any nontrivial zero divisors. We verify the latter for discrete locally
indicable groups, which includes lattices in nilpotent Lie groups. For the
particular case of time-frequency translates of Euclidean space, our main
result recovers the Heil-Ramanathan-Topiwala (HRT) conjecture for subsets of
arbitrary lattices.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:30:20 GMT""}]","2023-02-03"
"2302.01203","Andrea Celli","Matteo Castiglioni, Andrea Celli, Christian Kroer","Online Learning under Budget and ROI Constraints and Applications to
  Bidding in Non-Truthful Auctions",,,,,"cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study online learning problems in which a decision maker has to make a
sequence of costly decisions, with the goal of maximizing their expected reward
while adhering to budget and return-on-investment (ROI) constraints. Previous
work requires the decision maker to know beforehand some specific parameters
related to the degree of strict feasibility of the offline problem. Moreover,
when inputs are adversarial, it requires the existence of a strictly feasible
solution to the offline optimization problem at each round. Both requirements
are unrealistic for practical applications such as bidding in online ad
auctions. We propose a best-of-both-worlds primal-dual framework which
circumvents both assumptions by exploiting the notion of interval regret,
providing guarantees under both stochastic and adversarial inputs. Our proof
techniques can be applied to both input models with minimal modifications,
thereby providing a unified perspective on the two problems. Finally, we show
how to instantiate the framework to optimally bid in various mechanisms of
practical relevance, such as first- and second-price auctions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:30:33 GMT""},{""version"":""v2"",""created"":""Thu, 25 May 2023 10:56:53 GMT""}]","2023-05-26"
"2302.01204","Shenyang Huang","Shenyang Huang, Samy Coulombe, Yasmeen Hitti, Reihaneh Rabbany,
  Guillaume Rabusseau","Laplacian Change Point Detection for Single and Multi-view Dynamic
  Graphs","30 pages, 15 figures, extended version of previous paper ""Laplacian
  Change Point Detection for Dynamic Graphs"" with novel material. arXiv admin
  note: substantial text overlap with arXiv:2007.01229",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamic graphs are rich data structures that are used to model complex
relationships between entities over time. In particular, anomaly detection in
temporal graphs is crucial for many real world applications such as intrusion
identification in network systems, detection of ecosystem disturbances and
detection of epidemic outbreaks. In this paper, we focus on change point
detection in dynamic graphs and address three main challenges associated with
this problem: i). how to compare graph snapshots across time, ii). how to
capture temporal dependencies, and iii). how to combine different views of a
temporal graph. To solve the above challenges, we first propose Laplacian
Anomaly Detection (LAD) which uses the spectrum of graph Laplacian as the low
dimensional embedding of the graph structure at each snapshot. LAD explicitly
models short term and long term dependencies by applying two sliding windows.
Next, we propose MultiLAD, a simple and effective generalization of LAD to
multi-view graphs. MultiLAD provides the first change point detection method
for multi-view dynamic graphs. It aggregates the singular values of the
normalized graph Laplacian from different views through the scalar power mean
operation. Through extensive synthetic experiments, we show that i). LAD and
MultiLAD are accurate and outperforms state-of-the-art baselines and their
multi-view extensions by a large margin, ii). MultiLAD's advantage over
contenders significantly increases when additional views are available, and
iii). MultiLAD is highly robust to noise from individual views. In five real
world dynamic graphs, we demonstrate that LAD and MultiLAD identify significant
events as top anomalies such as the implementation of government COVID-19
interventions which impacted the population mobility in multi-view traffic
networks.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:30:43 GMT""}]","2023-02-03"
"2302.01205","Seth Taylor","Seth Taylor and Jean-Christophe Nave","A characteristic mapping method for incompressible hydrodynamics on a
  rotating sphere",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The characteristic mapping method uses a computational framework for
non-linear advection capable of resolving fine scale fluid phenomena without
the necessity of increasing the resolution of the computational grid. By
approximating the inverse flow map generated by a velocity field as a
composition of submaps, the method generates a discretization with an
exponentially increasing polynomial degree of approximation using only a linear
increase in the degrees of freedom. This functional spatio-temporal
discretization has the capacity of accurately and sparsely representing fine
scales globally, substituting the effects of spatial refinement with the
operation of composition. As a step towards the application of these techniques
to geophysical fluid phenomena, we present a characteristic mapping method for
the rotating barotropic vorticity equations. The method is verified using
standard test cases demonstrating third-order accuracy in the supremum norm.
Numerical experiments illustrating the ability to reproduce the direct energy
cascade at finer scales than the computational grid are provided.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:33:51 GMT""}]","2023-02-03"
"2302.01206","Lewis Sword","Sanjaye Ramgoolam and Lewis Sword","Matrix and tensor witnesses of hidden symmetry algebras","53 pages + Appendices, 9 Figures",,"10.1007/JHEP03(2023)056","QMUL-PH-22-33","hep-th math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Permutation group algebras, and their generalizations called permutation
centralizer algebras (PCAs), play a central role as hidden symmetries in the
combinatorics of large $N$ gauge theories and matrix models with manifest
continuous gauge symmetries. Polynomial functions invariant under the manifest
symmetries are the observables of interest and have applications in AdS/CFT. We
compute such correlators in the presence of matrix or tensor witnesses, which
by definition, can include a matrix or tensor field appearing as a coupling in
the action (i.e a spurion) or as a classical (un-integrated) field in the
observables, appearing alongside quantum (integrated) fields. In both matrix
and tensor cases we find that two-point correlators of general gauge-invariant
observables can be written in terms of gauge invariant functions of the witness
fields, with coefficients given by structure constants of the associated PCAs.
Fourier transformation on the relevant PCAs, relates combinatorial bases to
representation theoretic bases. The representation theory basis elements obey
orthogonality results for the two-point correlators which generalise known
orthogonality relations to the case with witness fields. The new orthogonality
equations involve two representation basis elements for observables as input
and a representation basis observable constructed purely from witness fields as
the output. These equations extend known equations in the super-integrability
programme initiated by Mironov and Morozov, and are a direct physical
realization of the Wedderburn-Artin decompositions of the hidden permutation
centralizer algebras of matrix/tensor models.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:34:25 GMT""}]","2023-03-29"
"2302.01207","Haruki Watanabe","Yaozong Hu, Haruki Watanabe","Spontaneous symmetry breaking without ground state degeneracy in
  generalized $N$-state clock model","10 pages, 6 figures; v2: Fig 1 is added. Minor changes throughout the
  manuscript","Phys. Rev. B 107, 195139 (2023)","10.1103/PhysRevB.107.195139",,"cond-mat.stat-mech cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Spontaneous symmetry breaking is ubiquitous phenomenon in nature. One of the
defining features of symmetry broken phases is that the large system size limit
and the vanishing external field limit do not commute. In this work, we study a
family of extensions of the $N$-state clock model. We find that the exact
symmetry and the ground state degeneracy under the periodic boundary condition
heavily depend on the system size, although the model has the manifest
translation symmetry. In particular, the ground state can be unique and all
excitations are gapped even when the phase exhibits non-commutativity of the
two limits. Our model hence poses a question on the standard understanding of
spontaneous symmetry breaking.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:37:30 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 22:43:10 GMT""}]","2023-05-24"
"2302.01208","Xiao Zhong","Xiao Zhong","Dynamical Cancellation of Polynomials",,,,,"math.NT math.AG math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extending the work of Bell, Matsuzawa and Satriano, we consider a finite set
of polynomials $S$ over a number field $K$ and give a necessary and sufficient
condition for the existence of a $N \in \mathbb{N}_{> 0}$ and a finite set $Z
\subset \mathbb{P}^1_K \times \mathbb{P}^1_K$ such that for any $(a,b) \in
(\mathbb{P}^1_K \times \mathbb{P}^1_K) \setminus Z$ we have the cancellation
result: if $k>N$ and $\phi_1,\ldots ,\phi_k$ are maps in $S$ such that
$\phi_{k} \circ \dots \circ \phi_1 (a) = \phi_k \circ \dots \circ \phi_1(b)$,
then in fact $\phi_N \circ \dots \circ \phi_1(a) = \phi_N \circ \dots \circ
\phi_1(b)$. Moreover, the conditions we give for this cancellation result to
hold can be checked by a finite number of computations from the given set of
polynomials.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:38:24 GMT""}]","2023-02-03"
"2302.01209","Henry Legg","Matthias R\""o{\ss}ler, Dingxun Fan, Felix M\""unning, Henry F. Legg,
  Andrea Bliesener, Gertjan Lippertz, Anjana Uday, Roozbeh Yazdanpanah, Junya
  Feng, Alexey A. Taskin, Yoichi Ando","Top-down fabrication of bulk-insulating topological insulator nanowires
  for quantum devices","32 pages. 22 main text, 10 SI",,"10.1021/acs.nanolett.3c00169",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In a nanowire (NW) of a three-dimensional topological insulator (TI), the
quantum-confinement of topological surface states leads to a peculiar subband
structure that is useful for generating Majorana bound states. Top-down
fabrication of TINWs from a high-quality thin film would be a scalable
technology with great design flexibility, but there has been no report on
top-down-fabricated TINWs where the chemical potential can be tuned to the
charge neutrality point (CNP). Here we present a top-down fabrication process
for bulk-insulating TINWs etched from high-quality
(Bi$_{1-x}$Sb$_{x}$)$_2$Te$_3$ thin films without degradation. We show that the
chemical potential can be gate-tuned to the CNP and the resistance of the NW
presents characteristic oscillations as functions of the gate voltage and the
parallel magnetic field, manifesting the TI-subband physics. We further
demonstrate the superconducting proximity effect in these TINWs, preparing the
groundwork for future devices to investigate Majorana bound states.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:42:37 GMT""}]","2023-04-26"
"2302.01210","Qiang Zhao","Yin Cheng, Lin Qiu, Qiang Zhao","On the widths of $\eta(1295)$ and $\eta(1405/1475)$","17 pages and 7 figures",,,,"hep-ph hep-ex","http://creativecommons.org/publicdomain/zero/1.0/","  Based on the assignment of the first radial excitation states of the
isoscalar pseudoscalars for $\eta(1295)$ and $\eta(1405/1475)$, we investigate
their three-body and four-body decay contributions to the total widths. In
agreement with our previous studies we find that the triangle singularity (TS)
mechanism arising from the intermediate $K^*\bar{K}$ rescatterings by
exchanging a kaon or pion plays a crucial role in both $K\bar{K}\pi$ and
$\eta\pi\pi$ channels. For the $\eta_X$ ($\eta_X$ stands for $\eta(1295)$ and
$\eta(1405/1475)$) decays into $K\bar{K}\pi$, we find that although the
transition $\eta_X\to K^*\bar{K}+c.c.\to K\bar{K}\pi$ is the dominant
tree-level process, the productions of the intermediate $K\bar{\kappa}+c.c.$
and $a_0(980)\pi$ are strongly enhanced by the TS mechanism. For the $\eta_X$
decays into $\eta\pi\pi$, we find that the production of the intermediate
$a_0(980)\pi$ via the triangle transition is the dominant one for $\eta(1295)$
partly because of the large $\eta(1295)K^*\bar{K}$ coupling. In contrast, the
tree-level and triangle loop contributions are compatible and dominant in the
$\eta(1405/1475)$ decays into $\eta\pi\pi$. It shows that a combined analysis
is useful for disentangling the underlying dynamics for these two states.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:43:51 GMT""}]","2023-02-03"
"2302.01211","Haesung Lee","Haesung Lee","On weak solutions to linear elliptic equations with $L^2$-drifts of
  negative divergence","15 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show the existence and uniqueness as well as boundedness of weak solutions
to linear elliptic equations with $L^2$-drifts of negative divergence and
singular zero-order terms which are positive. In particular, using Dirichlet
form theory we connect a unique solution to the corresponding resolvent and
obtain the $L^r$-contraction properties of the unique solution. Furthermore, an
elliptic $L^1$-stability is derived through the $L^1$-contraction property.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:45:36 GMT""}]","2023-02-03"
"2302.01212","Theo McKenzie","Jun-Ting Hsieh, Theo McKenzie, Sidhanth Mohanty, Pedro Paredes","Explicit two-sided unique-neighbor expanders","22 pages, 1 figure",,,,"math.CO cs.CC cs.DM cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of constructing explicit sparse imbalanced bipartite
unique-neighbor expanders. For large enough $d_1$ and $d_2$, we give a strongly
explicit construction of an infinite family of $(d_1,d_2)$-biregular graph
(assuming $d_1 \leq d_2$) where all sets $S$ with fewer than $1/d_1^3$ fraction
of vertices have $\Omega(d_1\cdot |S|)$ unique-neighbors. Further, for each
$\beta\in(0,1)$, we give a construction with the additional property that the
left side of each graph has roughly $\beta$ fraction of the total number of
vertices. Our work provides the first two-sided construction of imbalanced
unique-neighbor expanders, meaning small sets contained in both the left and
right side of the bipartite graph exhibit unique-neighbor expansion.
  Our construction is obtained from the ``line product'' of a large small-set
edge expander and a sufficiently good constant-sized unique-neighbor expander,
a product defined in the work of Alon and Capalbo.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:45:55 GMT""}]","2023-02-06"
"2302.01213","Maud Szusterman","Maud Szusterman","A New Excluding Condition towards the Soprunov-Zvavitch conjecture on
  Bezout-type inequalities","13 pages, 1 picture",,,,"math.FA math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2015, I. Soprunov and A. Zvavitch have shown how to use the
Bernstein-Khovanskii-Kushnirenko theorem to derive non-negativity of a certain
bilinear form $F_{\Delta}$, defined on (pairs of) convex bodies. Together with
C. Saroglou, they proved non-negativity of $F_K$ characterizes simplices, among
all polytopes. It is conjectured the characterization further holds among all
convex bodies. Towards this conjecture, several necessary conditions on $K$
(for non-negativity of $F_K$), were derived. We give a new necessary condition,
expressed with isoperimetric ratios, which provides a further step towards a
(conjectural) characterization of simplices among a certain subclass of convex
bodies.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:47:21 GMT""},{""version"":""v2"",""created"":""Sat, 4 Feb 2023 23:14:53 GMT""}]","2023-02-07"
"2302.01214","Duong Thuy Anh Nguyen","Duong Thuy Anh Nguyen, Duong Tung Nguyen, Angelia Nedich","Accelerated $AB$/Push-Pull Methods for Distributed Optimization over
  Time-Varying Directed Networks",,,,,"math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper investigates a novel approach for solving the distributed
optimization problem in which multiple agents collaborate to find the global
decision that minimizes the sum of their individual cost functions. First, the
$AB$/Push-Pull gradient-based algorithm is considered, which employs row- and
column-stochastic weights simultaneously to track the optimal decision and the
gradient of the global cost function, ensuring consensus on the optimal
decision. Building on this algorithm, we then develop a general algorithm that
incorporates acceleration techniques, such as heavy-ball momentum and Nesterov
momentum, as well as their combination with non-identical momentum parameters.
Previous literature has established the effectiveness of acceleration methods
for various gradient-based distributed algorithms and demonstrated linear
convergence for static directed communication networks. In contrast, we focus
on time-varying directed communication networks and provide theoretical proof
of linear convergence to the optimal solution, when the agents' cost functions
are smooth and strongly convex. Additionally, we provide explicit bounds for
the step-size value and momentum parameters, based on the properties of the
cost functions, the mixing matrices, and the graph connectivity structures. Our
numerical results illustrate the benefits of the proposed acceleration
techniques on the $AB$/Push-Pull algorithm.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:51:24 GMT""}]","2023-02-03"
"2302.01215","Baleegh Ahmad","Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri, Hammond
  Pearce","Fixing Hardware Security Bugs with Large Language Models",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's
Codex have demonstrated capabilities in many coding-adjacent domains. In this
work we consider how LLMs maybe leveraged to automatically repair security
relevant bugs present in hardware designs. We focus on bug repair in code
written in the Hardware Description Language Verilog. For this study we build a
corpus of domain-representative hardware security bugs. We then design and
implement a framework to quantitatively evaluate the performance of any LLM
tasked with fixing the specified bugs. The framework supports design space
exploration of prompts (i.e., prompt engineering) and identifying the best
parameters for the LLM. We show that an ensemble of LLMs can repair all ten of
our benchmarks. This ensemble outperforms the state-of-the-art Cirfix hardware
bug repair tool on its own suite of bugs. These results show that LLMs can
repair hardware security bugs and the framework is an important step towards
the ultimate goal of an automated end-to-end bug repair framework.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:51:28 GMT""}]","2023-02-03"
"2302.01216","Aymeric Vie","Aymeric Vie, J. Doyne Farmer","Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual
  Funds II","AI4ABM, ICLR23",,,,"cs.MA q-fin.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Agent-based models (ABMs) are fit to model heterogeneous, interacting systems
like financial markets. We present the latest advances in Evology: a
heterogeneous, empirically calibrated market ecology agent-based model of the
US stock market. Prices emerge endogenously from the interactions of market
participants with diverse investment behaviours and their reactions to
fundamentals. This approach allows testing trading strategies while accounting
for the interactions of this strategy with other market participants and
conditions. Those early results encourage a closer association between ABMs and
ML algorithms for testing and optimising investment strategies using machine
learning algorithms.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:53:28 GMT""}]","2023-02-03"
"2302.01217","Litu Rout","Litu Rout and Advait Parulekar and Constantine Caramanis and Sanjay
  Shakkottai","A Theoretical Justification for Image Inpainting using Denoising
  Diffusion Probabilistic Models","30 pages, 5 figures, 1 Table",,,,"stat.ML cs.AI cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  We provide a theoretical justification for sample recovery using diffusion
based image inpainting in a linear model setting. While most inpainting
algorithms require retraining with each new mask, we prove that diffusion based
inpainting generalizes well to unseen masks without retraining. We analyze a
recently proposed popular diffusion based inpainting algorithm called RePaint
(Lugmayr et al., 2022), and show that it has a bias due to misalignment that
hampers sample recovery even in a two-state diffusion process. Motivated by our
analysis, we propose a modified RePaint algorithm we call RePaint$^+$ that
provably recovers the underlying true sample and enjoys a linear rate of
convergence. It achieves this by rectifying the misalignment error present in
drift and dispersion of the reverse process. To the best of our knowledge, this
is the first linear convergence result for a diffusion based image inpainting
algorithm.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:55:03 GMT""}]","2023-02-03"
"2302.01218","Nagaraj Nagalingam","Nagaraj Nagalingam, Aswin Raghunathan, Vikram Korede, Christian
  Poelma, Carlas S. Smith, Remco Hartkamp, Johan T. Padding, and Huseyin Burak
  Eral","Laser-Induced Cavitation for Controlling Crystallization from Solution",,,,,"physics.chem-ph cond-mat.other physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We demonstrate that a cavitation bubble initiated by a Nd:YAG laser pulse
below breakdown threshold induces crystallization from supersaturated aqueous
solutions with supersaturation and laser-energy dependent nucleation kinetics.
Combining high-speed video microscopy and simulations, we argue that a
competition between the dissipation of absorbed laser energy as latent and
sensible heat dictates the solvent evaporation rate and creates a momentary
supersaturation peak at the vapor-liquid interface. The number and morphology
of crystals correlate to the characteristics of the simulated supersaturation
peak.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:57:08 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 10:40:52 GMT""}]","2023-04-27"
"2302.01219","Elena Bannikova Prof.","Elena Yu. Bannikova, Sergey V. Skolota","Outer gravitational potential of a homogeneous torus with an elliptical
  cross-section: I. Representation by two massive circles","10 pages, 11 figures",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper deals with the gravitational potential of a homogeneous torus with
elliptical cross-section. We present a new expression for its gravitational
potential which is valid in any point of the space, obtained by modeling the
torus with a set of massive circles (infinitely thin rings). We found that the
outer potential can be represented with good accuracy by the potential of two
massive circles with masses which are half of the torus mass. These massive
circles intercept the elliptical cross-section at two points along the major
axis which are in opposite directions and at half of the distances to the foci
of the cross-section. The same formula works for both cases: oblate and prolate
cross-sections. For the case of the prolate cross-section of the torus the
distances to massive circles are imaginary and conjugate ones but the values of
the torus potential for this case are real. The obtained approximation is
robust as the error maps show.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:57:21 GMT""}]","2023-02-03"
"2302.01220","Nicolas Cuervo Ovalle","Camilo Argoty, Alexander Berenstein and Nicolas Cuervo Ovalle","SB-property on metric structures",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A complete theory $T$ has the Schr\""oder-Bernstein property or simply the
SB-property if any pair of elementarily bi-embeddable models are isomorphic.
This property has been studied in the discrete first-order setting and can be
seen as a first step towards classification theory. This paper deals with the
SB-property on continuous theories. Examples of complete continuous theories
that have this property include Hilbert spaces and probability algebras with or
without atoms. We also study a weaker notion, the SB-property up to
perturbations. This property holds if any two bi-embeddable models are
isomorphic up to perturbations. We prove that the theory of Hilbert spaces
expanded with a bounded self-adjoint operator has the SB-property up to
perturbations of the operator and that the theory of atomless probability
algebras with a generic automorphism have the SB-property up to perturbations
of the automorphism. Finally we study how the SB-property behaves with respect
to randomizations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:00:06 GMT""}]","2023-02-03"
"2302.01221","Emese Forgacs-Dajka Dr.","E. Forg\'acs-Dajka, E. K\H{o}v\'ari, T. Kov\'acs, Cs. Kiss, Zs.
  S\'andor","A dynamical survey of the trans-Neptunian region I.: Mean-motion
  resonances with Neptune","16 pages, 17 figures, accepted by The Astrophysical Journal
  Supplement Series",,"10.3847/1538-4365/acc4c8",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present a large-scale dynamical survey of the
trans-Neptunian region, with particular attention to mean-motion resonances
(MMRs). We study a set of 4121 trans-Neptunian objects (TNOs), a sample far
larger than in previous works. We perform direct long-term numerical
integrations that enable us to examine the overall dynamics of the individual
TNOs as well as to identify all MMRs. For the latter purpose, we apply the
own-developed FAIR method that allows the semi-automatic identification of even
very high-order MMRs. Apart from searching for the more frequent
eccentricity-type resonances that previous studies concentrated on, we set our
method to allow the identification of inclination-type MMRs, too. Furthermore,
we distinguish between TNOs that are locked in the given MMR throughout the
whole integration time span ($10^8$\,years) and those that are only temporarily
captured in resonances. For a more detailed dynamical analysis of the
trans-Neptunian space, we also construct dynamical maps using test particles.
Observing the fine structure of the $ 34-80 $~AU region underlines the
stabilizing role of the MMRs, with the regular regions coinciding with the
position of the real TNOs.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:00:53 GMT""}]","2023-05-24"
"2302.01222","Meiyu Jiang","Meiyu Jiang, Jun Shen, Xuetao Jiang, Qingguo Zhou, Rui Zhou","A novel framework for medium-term wind power prediction based on
  temporal attention mechanisms",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Wind energy is a widely distributed, recyclable and environmentally friendly
energy source that plays an important role in mitigating global warming and
energy shortages. Wind energy's uncertainty and fluctuating nature makes grid
integration of large-scale wind energy systems challenging. Medium-term wind
power forecasts can provide an essential basis for energy dispatch, so accurate
wind power forecasts are essential. Much research has yielded excellent results
in recent years. However, many of them require additional experimentation and
analysis when applied to other data. In this paper, we propose a novel
short-term forecasting framework by tree-structured parzen estimator (TPE) and
decomposition algorithms. This framework defines the TPE-VMD-TFT method for
24-h and 48-h ahead wind power forecasting based on variational mode
decomposition (VMD) and time fusion transformer (TFT). In the Engie wind
dataset from the electricity company in France, the results show that the
proposed method significantly improves the prediction accuracy. In addition,
the proposed framework can be used to other decomposition algorithms and
require little manual work in model training.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:03:08 GMT""},{""version"":""v2"",""created"":""Sun, 5 Feb 2023 14:08:57 GMT""},{""version"":""v3"",""created"":""Fri, 28 Apr 2023 08:00:02 GMT""},{""version"":""v4"",""created"":""Wed, 3 May 2023 14:55:23 GMT""}]","2023-05-04"
"2302.01223","Bram Van Den Akker","Bram van den Akker, Olivier Jeunen, Ying Li, Ben London, Zahra Nazari,
  Devesh Parekh","Practical Bandits: An Industry Perspective","Tutorial held at The Web Conference 2023 (formerly known as WWW) in
  Austin, Texas (USA), on April 30 - May 4, 2023",,,,"cs.LG cs.IR","http://creativecommons.org/licenses/by-sa/4.0/","  The bandit paradigm provides a unified modeling framework for problems that
require decision-making under uncertainty. Because many business metrics can be
viewed as rewards (a.k.a. utilities) that result from actions, bandit
algorithms have seen a large and growing interest from industrial applications,
such as search, recommendation and advertising. Indeed, with the bandit lens
comes the promise of direct optimisation for the metrics we care about.
  Nevertheless, the road to successfully applying bandits in production is not
an easy one. Even when the action space and rewards are well-defined,
practitioners still need to make decisions regarding multi-arm or contextual
approaches, on- or off-policy setups, delayed or immediate feedback, myopic or
long-term optimisation, etc. To make matters worse, industrial platforms
typically give rise to large action spaces in which existing approaches tend to
break down. The research literature on these topics is broad and vast, but this
can overwhelm practitioners, whose primary aim is to solve practical problems,
and therefore need to decide on a specific instantiation or approach for each
project. This tutorial will take a step towards filling that gap between the
theory and practice of bandits. Our goal is to present a unified overview of
the field and its existing terminology, concepts and algorithms -- with a focus
on problems relevant to industry. We hope our industrial perspective will help
future practitioners who wish to leverage the bandit paradigm for their
application.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:03:40 GMT""}]","2023-02-03"
"2302.01224","Giorgio Bacci","Giorgio Bacci and Radu Mardare and Prakash Panangaden and Gordon
  Plotkin","Propositional Logics for the Lawvere Quantale",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Lawvere showed that generalised metric spaces are categories enriched over
$[0, \infty]$, the quantale of the positive extended reals. The statement of
enrichment is a quantitative analogue of being a preorder. Towards seeking a
logic for quantitative metric reasoning, we investigate three (closely related)
many-valued propositional logics over the Lawvere quantale. The basic logical
connectives shared by all three logics are those that can be interpreted in any
quantale, viz finite conjunctions and disjunctions, tensor (addition for the
Lawvere quantale) and linear implication (here a truncated subtraction); to
these we add, in turn, the constant 1 to express integer values, and scalar
multiplication by a non-negative real to express general affine combinations.
Propositional Boolean logic can already be interpreted in the first of these
logics; {\L}ukasiewicz logic can be interpreted in the second; Ben Yaacov's
continuous propositional logic can be interpreted in the third; and
quantitative equational logic can be interpreted in the third if we allow
inference systems instead of axiomatic systems. For each of these logics we
develop a natural deduction system which we prove to be decidably complete
w.r.t.\ the quantale-valued semantics. The heart of the completeness proof
makes use of Motzkin transposition theorem. Consistency is also decidable; the
proof makes use of Fourier-Motzkin elimination of linear inequalities. Strong
completeness does not hold in general, even for theories over finitely-many
propositional variables; indeed even an approximate form of strong completeness
in the sense of Ben Yaacov -- provability up to arbitrary precision -- does not
hold. However, we can show it for such theories having only models never
mapping variables to $\infty$; the proof uses Hurwicz's general form of the
Farkas lemma.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:04:28 GMT""}]","2023-02-03"
"2302.01225","Jakub Ruszil","Jakub Ruszil","Asymmetric Cryptosystem Using Careful Synchronization","17 pages, 7 figures",,,,"cs.CR","http://creativecommons.org/publicdomain/zero/1.0/","  We present public-private key cryptosystem which utilizes the fact that
checking whether a partial automaton is carefully synchronizing is
$PSPACE$-complete, even in the case of a binary alphabet.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:04:58 GMT""}]","2023-02-03"
"2302.01226","Anpei Chen","Anpei Chen, Zexiang Xu, Xinyue Wei, Siyu Tang, Hao Su, Andreas Geiger","Factor Fields: A Unified Framework for Neural Fields and Beyond","13 pages, 7 figures",,,,"cs.CV cs.GR cs.LG","http://creativecommons.org/licenses/by/4.0/","  We present Factor Fields, a novel framework for modeling and representing
signals. Factor Fields decomposes a signal into a product of factors, each of
which is represented by a neural or regular field representation operating on a
coordinate transformed input signal. We show that this decomposition yields a
unified framework that generalizes several recent signal representations
including NeRF, PlenOxels, EG3D, Instant-NGP, and TensoRF. Moreover, the
framework allows for the creation of powerful new signal representations, such
as the Coefficient-Basis Factorization (CoBaFa) which we propose in this paper.
As evidenced by our experiments, CoBaFa leads to improvements over previous
fast reconstruction methods in terms of the three critical goals in neural
signal representation: approximation quality, compactness and efficiency.
Experimentally, we demonstrate that our representation achieves better image
approximation quality on 2D image regression tasks, higher geometric quality
when reconstructing 3D signed distance fields and higher compactness for
radiance field reconstruction tasks compared to previous fast reconstruction
methods. Besides, our CoBaFa representation enables generalization by sharing
the basis across signals during training, enabling generalization tasks such as
image regression with sparse observations and few-shot radiance field
reconstruction.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:06:50 GMT""}]","2023-02-03"
"2302.01227","Alice Paul","Alice Paul and Susan Martonosi","The All-Pairs Vitality-Maximization (VIMAX) Problem",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Traditional network interdiction problems focus on removing vertices or edges
from a network so as to disconnect or lengthen paths in the network; network
diversion problems seek to remove vertices or edges to reroute flow through a
designated critical vertex or edge. We introduce the all-pairs vitality
maximization problem (VIMAX), in which vertex deletion attempts to maximize the
amount of flow passing through a critical vertex, measured as the all-pairs
vitality of the vertex. The assumption in this problem is that in a network for
which the structure is known but the physical locations of vertices may not be
known (e.g. a social network), locating a person or asset of interest might
require the ability to detect a sufficient amount of flow (e.g., communications
or financial transactions) passing through the corresponding vertex in the
network. We formulate VIMAX as a mixed integer program, and show that it is
NP-Hard. We compare the performance of the MIP and a simulated annealing
heuristic on both real and simulated data sets and highlight the potential
increase in vitality of key vertices that can be attained by subset removal. We
also present graph theoretic results that can be used to narrow the set of
vertices to consider for removal.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:07:07 GMT""}]","2023-02-03"
"2302.01228","Rasmus Kj{\ae}r  H{\o}ier","Rasmus H{\o}ier, D. Staudt, Christopher Zach","Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic
  Neurons","Added reflections on biological plausibility and results comparisons
  to state-of-the-art versions of equilibrium propagation and difference target
  propagation",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Activity difference based learning algorithms-such as contrastive Hebbian
learning and equilibrium propagation-have been proposed as biologically
plausible alternatives to error back-propagation. However, on traditional
digital chips these algorithms suffer from having to solve a costly inference
problem twice, making these approaches more than two orders of magnitude slower
than back-propagation. In the analog realm equilibrium propagation may be
promising for fast and energy efficient learning, but states still need to be
inferred and stored twice. Inspired by lifted neural networks and compartmental
neuron models we propose a simple energy based compartmental neuron model,
termed dual propagation, in which each neuron is a dyad with two intrinsic
states. At inference time these intrinsic states encode the error/activity
duality through their difference and their mean respectively. The advantage of
this method is that only a single inference phase is needed and that inference
can be solved in layerwise closed-form. Experimentally we show on common
computer vision datasets, including Imagenet32x32, that dual propagation
performs equivalently to back-propagation both in terms of accuracy and
runtime.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:07:36 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 13:21:37 GMT""},{""version"":""v3"",""created"":""Wed, 7 Jun 2023 08:48:04 GMT""}]","2023-06-08"
"2302.01229","Dominik B\""ar","Dominik B\""ar, Nicolas Pr\""ollochs, Stefan Feuerriegel","New threats to society from free-speech social media platforms",,,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In recent years, several free-speech social media platforms (so-called
""alt-techs"") have emerged, such as Parler, Gab, and Telegram. These platforms
market themselves as alternatives to mainstream social media and proclaim
""free-speech"" due to the absence of content moderation, which has been
attracting a large base of partisan users, extremists, and supporters of
conspiracy theories. In this comment, we discuss some of the threats that
emerge from such social media platforms and call for more policy efforts
directed at understanding and countering the risks for society.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:08:12 GMT""}]","2023-02-03"
"2302.01230","Efstratios Manousakis","Efstratios Manousakis","Transition to an excitonic insulator from a two-dimensional conventional
  insulator","12 double column document in pdf and the Latex source files and 7
  figures with subfigures","Physical Review B, 107, 075105 (2023)","10.1103/PhysRevB.107.075105",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, first, we present a general formulation to investigate the
ground-state and elementary excitations of an excitonic insulator (EI) in real
materials. In addition, we discuss the out-of-equilibrium state induced (albeit
transiently) by high-intensity light illumination of a conventional
two-dimensional (2D) insulator. We then, present various band-structure models
which allow us to study the transition from a conventional insulator to an EI
in 2D materials as a function of the dielectric constant, the conventional
insulator gap (and chemical potential), the bandwidths of the conduction and
valence bands and the Bravais lattice unit-cell size. One of the goals of this
investigation is to determine which range of these experimentally determined
parameters to consider in order to find the best candidate materials to realize
the excitonic insulator. The numerical solution to the EI gap equation for
various band-structures shows a significant and interesting momentum-dependence
of the EI gap function $\Delta(\vec k)$ and of the zero-temperature electron
and hole momentum-distribution across the Brillouin zone. Last, we discuss that
these features can be detected by tunneling microscopy
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:11:08 GMT""}]","2023-02-03"
"2302.01231","Stuart Dowker","J. S. Dowker","On the limiting behaviour of the su(N) structure constants","11 pages",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  The details are expounded of an old treatment of the limit of the su(N)
structure constants as N tends to infinity. A recently derived parity property
of the series expansion is shown to be the same as the known mirror symmetry of
6-j symbols.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:11:12 GMT""}]","2023-02-03"
"2302.01232","Vincenzo Liccardo","V. Liccardo, C. H. Lenzi, R. M. Marinho Jr., O. D. Aguiar, C. Frajuca,
  F. S. Bortoli and C. A. Costa","The Design Strain Sensitivity of the Schenberg Spherical Resonant
  Antenna for Gravitational Waves",,,,,"astro-ph.IM gr-qc physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main purpose of this study is to review the Schenberg resonant antenna
transfer function and to recalculate the antenna design strain sensitivity for
gravitational waves. We consider the spherical antenna with six transducers in
the semi dodecahedral configuration. When coupled to the antenna, the
transducer-sphere system will work as a mass-spring system with three masses.
The first one is the antenna effective mass for each quadrupole mode, the
second one is the mass of the mechanical structure of the transducer first
mechanical mode and the third one is the effective mass of the transducer
membrane that makes one of the transducer microwave cavity walls. All the
calculations are done for the degenerate (all the sphere quadrupole mode
frequencies equal) and non-degenerate sphere cases. We have come to the
conclusion that the 'ultimate' sensitivity of an advanced version of Schenberg
antenna (aSchenberg) is around the standard quantum limit (although the
parametric transducers used could, in principle, surpass this limit). However,
this sensitivity, in the frequency range where Schenberg operates, has already
been achieved by the two aLIGOs in the O3 run, therefore, the only reasonable
justification for remounting the Schenberg antenna and trying to place it in
the sensitivity of the standard quantum limit would be to detect gravitational
waves with another physical principle, different from the one used by laser
interferometers. This other physical principle would be the absorption of the
gravitational wave energy by a resonant mass like Schenberg.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:14:04 GMT""}]","2023-02-03"
"2302.01233","Ines Wilms","Robert Adamek, Stephan Smeekes, Ines Wilms","Sparse High-Dimensional Vector Autoregressive Bootstrap",,,,,"econ.EM math.ST stat.ME stat.TH","http://creativecommons.org/licenses/by/4.0/","  We introduce a high-dimensional multiplier bootstrap for time series data
based capturing dependence through a sparsely estimated vector autoregressive
model. We prove its consistency for inference on high-dimensional means under
two different moment assumptions on the errors, namely sub-gaussian moments and
a finite number of absolute moments. In establishing these results, we derive a
Gaussian approximation for the maximum mean of a linear process, which may be
of independent interest.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:14:54 GMT""}]","2023-02-03"
"2302.01234","ALICE Publications","ALICE Collaboration","Symmetry plane correlations in Pb-Pb collisions at $\sqrt{s_{\rm NN}} =
  2.76$TeV","21 pages, 5 captioned figures, submitted to EPJC, figures at
  http://alice-publications.web.cern.ch/node/8964",,,"CERN-EP-2023-012","nucl-ex hep-ex","http://creativecommons.org/licenses/by/4.0/","  A newly developed observable for correlations between symmetry planes, which
characterize the direction of the anisotropic emission of produced particles,
is measured in Pb-Pb collisions at $\sqrt{s_{\rm NN}} = 2.76$ TeV with ALICE.
This so-called Gaussian Estimator allows for the first time the study of these
quantities without the influence of correlations between different flow
amplitudes. The centrality dependence of various correlations between two,
three and four symmetry planes is presented. The ordering of magnitude between
these symmetry plane correlations is discussed and the results of the Gaussian
Estimator are compared with measurements of previously used estimators. The
results utilizing the new estimator lead to significantly smaller correlations
than reported by studies using the Scalar Product method. Furthermore, the
obtained symmetry plane correlations are compared to state-of-the-art
hydrodynamic model calculations for the evolution of heavy-ion collisions.
While the model predictions provide a qualitative description of the data,
quantitative agreement is not always observed, particularly for correlators
with significant non-linear response of the medium to initial state
anisotropies of the collision system. As these results provide unique and
independent information, their usage in future Bayesian analysis can further
constrain our knowledge on the properties of the QCD matter produced in
ultrarelativistic heavy-ion collisions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:15:53 GMT""}]","2023-02-03"
"2302.01235","Suthee Ruangwises","Suthee Ruangwises","Physical Zero-Knowledge Proof for Five Cells","arXiv admin note: text overlap with arXiv:2202.09788",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Five Cells is a pencil puzzle consisting of a rectangular grid, with some
cells containg a number. The player has to partition the grid into blocks, each
consisting of five cells, such that the number in each cell must be equal to
the number of edges of that cell that are borders of blocks. In this paper, we
propose a physical zero-knowledge proof protocol for Shikaku using a deck of
playing cards, which allows a prover to physically show that he/she knows a
solution of the puzzle without revealing it. More importantly, in the
optimization we develop a technique to verify a graph coloring that no two
adjacent vertices have the same color without revealing any information about
the coloring. This technique reduces the number of required cards in our
protocol from quadratic to linear in the number of cells, and can also be used
in other protocols related to graph coloring.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:16:32 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 17:10:03 GMT""}]","2023-02-16"
"2302.01236","Max Vilgalys","Max Vilgalys","A Machine Learning Approach to Measuring Climate Adaptation",,,,,"stat.AP econ.EM stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  I measure adaptation to climate change by comparing elasticities from
short-run and long-run changes in damaging weather. I propose a debiased
machine learning approach to flexibly measure these elasticities in panel
settings. In a simulation exercise, I show that debiased machine learning has
considerable benefits relative to standard machine learning or ordinary least
squares, particularly in high-dimensional settings. I then measure adaptation
to damaging heat exposure in United States corn and soy production. Using rich
sets of temperature and precipitation variation, I find evidence that short-run
impacts from damaging heat are significantly offset in the long run. I show
that this is because the impacts of long-run changes in heat exposure do not
follow the same functional form as short-run shocks to heat exposure.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:16:48 GMT""}]","2023-02-03"
"2302.01237","Sloan Nietert","Sloan Nietert, Rachel Cummings, and Ziv Goldfeld","Robust Estimation under the Wasserstein Distance","arXiv admin note: text overlap with arXiv:2111.01361",,,,"stat.ML cs.LG math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of robust distribution estimation under the Wasserstein
metric, a popular discrepancy measure between probability distributions rooted
in optimal transport (OT) theory. We introduce a new outlier-robust Wasserstein
distance $\mathsf{W}_p^\varepsilon$ which allows for $\varepsilon$ outlier mass
to be removed from its input distributions, and show that minimum distance
estimation under $\mathsf{W}_p^\varepsilon$ achieves minimax optimal robust
estimation risk. Our analysis is rooted in several new results for partial OT,
including an approximate triangle inequality, which may be of independent
interest. To address computational tractability, we derive a dual formulation
for $\mathsf{W}_p^\varepsilon$ that adds a simple penalty term to the classic
Kantorovich dual objective. As such, $\mathsf{W}_p^\varepsilon$ can be
implemented via an elementary modification to standard, duality-based OT
solvers. Our results are extended to sliced OT, where distributions are
projected onto low-dimensional subspaces, and applications to homogeneity and
independence testing are explored. We illustrate the virtues of our framework
via applications to generative modeling with contaminated datasets.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:20:25 GMT""}]","2023-03-02"
"2302.01238","ALICE Publications","ALICE Collaboration","ALICE upgrades during the LHC Long Shutdown 2","151 pages, 110 captioned figures, 10 tables, submitted to JINST,
  figures at http://alice-publications.web.cern.ch/node/8965",,,"CERN-EP-2023-009","physics.ins-det hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  A Large Ion Collider Experiment (ALICE) has been conceived and constructed as
a heavy-ion experiment at the LHC. During LHC Runs 1 and 2, it has produced a
wide range of physics results using all collision systems available at the LHC.
In order to best exploit new physics opportunities opening up with the upgraded
LHC and new detector technologies, the experiment has undergone a major upgrade
during the LHC Long Shutdown 2 (2019-2022). This comprises the move to
continuous readout, the complete overhaul of core detectors, as well as a new
online event processing farm with a redesigned online-offline software
framework. These improvements will allow to record Pb-Pb collisions at rates up
to 50 kHz, while ensuring sensitivity for signals without a triggerable
signature.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:20:27 GMT""}]","2023-02-03"
"2302.01239","David E. Trilling","David E. Trilling, Michael Gowanlock, Daniel Kramer, Andrew McNeill,
  Brian Donnelly, Nat Butler, John Kececioglu","The Solar System Notification Alert Processing System (SNAPS): Design,
  Architecture, and First Data Release (SNAPShot1)","AJ, in press",,"10.3847/1538-3881/acac7f",,"astro-ph.EP astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present here the design, architecture, and first data release for the
Solar System Notification Alert Processing System (SNAPS). SNAPS is a Solar
System broker that ingests alert data from all-sky surveys. At present, we
ingest data from the Zwicky Transient Facility (ZTF) public survey, and we will
ingest data from the forthcoming Legacy Survey of Space and Time (LSST) when it
comes online. SNAPS is an official LSST downstream broker. In this paper we
present the SNAPS design goals and requirements. We describe the details of our
automatic pipeline processing in which physical properties of asteroids are
derived. We present SNAPShot1, our first data release, which contains 5,458,459
observations of 31,693 asteroids observed by ZTF from July, 2018, through May,
2020. By comparing a number of derived properties for this ensemble to
previously published results for overlapping objects we show that our automatic
processing is highly reliable. We present a short list of science results,
among many that will be enabled by our SNAPS catalog: (1) we demonstrate that
there are no known asteroids with very short periods and high amplitudes, which
clearly indicates that in general asteroids in the size range 0.3--20 km are
strengthless; (2) we find no difference in the period distributions of Jupiter
Trojan asteroids, implying that the L4 and L5 cloud have different shape
distributions; and (3) we highlight several individual asteroids of interest.
Finally, we describe future work for SNAPS and our ability to operate at LSST
scale.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:21:00 GMT""}]","2023-02-22"
"2302.01240","Alexandros Kehagias","Alex Kehagias, Antonio Riotto","On Nonlinear Black Hole Ringdowns from Gauge-Invariance and Measurements","10 pages",,,,"gr-qc hep-ph hep-th","http://creativecommons.org/licenses/by/4.0/","  It has been recently shown that nonlinear effects emerging at the time of the
generation of the quasi-normal modes are necessary to model ringdowns from
black hole mergers. In this note, we describe how nonlinerarities also arise
when defining gauge-invariant tensor modes and in the calculation of the
observable measured in the interferometers beyond linear order.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:22:52 GMT""}]","2023-02-03"
"2302.01241","Brian Lim","Brian Y. Lim, Joseph P. Cahaly, Chester Y. F. Sng, Adam Chew","Diagrammatization: Rationalizing with diagrammatic AI explanations for
  abductive reasoning on hypotheses",,,,,"cs.AI cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support abductive reasoning - inference to the best explanation - with
diagrammatic reasoning to convey hypothesis generation and evaluation. Inspired
by Peircean diagrammatic reasoning and the 5-step abduction process, we propose
Diagrammatization, an approach to provide diagrammatic, abductive explanations
based on domain hypotheses. We implemented DiagramNet for a clinical
application to predict diagnoses from heart auscultation, and explain with
shape-based murmur diagrams. In modeling studies, we found that DiagramNet not
only provides faithful murmur shape explanations, but also has better
prediction performance than baseline models. We further demonstrate the
usefulness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:23:28 GMT""}]","2023-02-03"
"2302.01242","Emanuele Marconato","Emanuele Marconato, Gianpaolo Bontempo, Elisa Ficarra, Simone
  Calderara, Andrea Passerini, Stefano Teso","Neuro Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and
  Concept Rehearsal",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce Neuro-Symbolic Continual Learning, where a model has to solve a
sequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to
high-level concepts and compute predictions by reasoning consistently with
prior knowledge. Our key observation is that neuro-symbolic tasks, although
different, often share concepts whose semantics remains stable over time.
Traditional approaches fall short: existing continual strategies ignore
knowledge altogether, while stock neuro-symbolic architectures suffer from
catastrophic forgetting. We show that leveraging prior knowledge by combining
neuro-symbolic architectures with continual strategies does help avoid
catastrophic forgetting, but also that doing so can yield models affected by
reasoning shortcuts. These undermine the semantics of the acquired concepts,
even when detailed prior knowledge is provided upfront and inference is exact,
and in turn continual performance. To overcome these issues, we introduce COOL,
a COncept-level cOntinual Learning strategy tailored for neuro-symbolic
continual problems that acquires high-quality concepts and remembers them over
time. Our experiments on three novel benchmarks highlights how COOL attains
sustained high performance on neuro-symbolic continual learning tasks in which
other strategies fail.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:24:43 GMT""}]","2023-02-03"
"2302.01243","Jun Luo","Zhengbo Zhou, Jun Luo, Dooman Arefan, Gene Kitamura, Shandong Wu","Human not in the loop: objective sample difficulty measures for
  Curriculum Learning","ISBI 2023",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Curriculum learning is a learning method that trains models in a meaningful
order from easier to harder samples. A key here is to devise automatic and
objective difficulty measures of samples. In the medical domain, previous work
applied domain knowledge from human experts to qualitatively assess
classification difficulty of medical images to guide curriculum learning, which
requires extra annotation efforts, relies on subjective human experience, and
may introduce bias. In this work, we propose a new automated curriculum
learning technique using the variance of gradients (VoG) to compute an
objective difficulty measure of samples and evaluated its effects on elbow
fracture classification from X-ray images. Specifically, we used VoG as a
metric to rank each sample in terms of the classification difficulty, where
high VoG scores indicate more difficult cases for classification, to guide the
curriculum training process We compared the proposed technique to a baseline
(without curriculum learning), a previous method that used human annotations on
classification difficulty, and anti-curriculum learning. Our experiment results
showed comparable and higher performance for the binary and multi-class bone
fracture classification tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:25:29 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 13:11:13 GMT""}]","2023-02-28"
"2302.01244","Xiyao Wang","Ruijie Zheng, Xiyao Wang, Huazhe Xu, Furong Huang","Is Model Ensemble Necessary? Model-based RL via a Single Model with
  Lipschitz Regularized Value Function","ICLR 2023",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Probabilistic dynamics model ensemble is widely used in existing model-based
reinforcement learning methods as it outperforms a single dynamics model in
both asymptotic performance and sample efficiency. In this paper, we provide
both practical and theoretical insights on the empirical success of the
probabilistic dynamics model ensemble through the lens of Lipschitz continuity.
We find that, for a value function, the stronger the Lipschitz condition is,
the smaller the gap between the true dynamics- and learned dynamics-induced
Bellman operators is, thus enabling the converged value function to be closer
to the optimal value function. Hence, we hypothesize that the key functionality
of the probabilistic dynamics model ensemble is to regularize the Lipschitz
condition of the value function using generated samples. To test this
hypothesis, we devise two practical robust training mechanisms through
computing the adversarial noise and regularizing the value network's spectral
norm to directly regularize the Lipschitz condition of the value functions.
Empirical results show that combined with our mechanisms, model-based RL
algorithms with a single dynamics model outperform those with an ensemble of
probabilistic dynamics models. These findings not only support the theoretical
insight, but also provide a practical solution for developing computationally
efficient model-based RL algorithms.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:27:16 GMT""}]","2023-02-03"
"2302.01245","Clara Froment","C. Froment, O.V. Agapitov, V. Krasnoselskikh, S. Karbashewski, T.
  Dudok de Wit, A. Larosa, L. Colomban, D. Malaspina, M. Kretzschmar, V. K.
  Jagarlamudi, S. D. Bale, J. W. Bonnell, F. S. Mozer, and M. Pulupa","Whistler waves generated inside magnetic dips in the young solar wind:
  observations of the Search-Coil Magnetometer on board Parker Solar Probe","15 pages, 14 figures, recommended for publication in A&A","A&A 672, A135 (2023)","10.1051/0004-6361/202245140",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context. Whistler waves are electromagnetic waves produced by electron-driven
instabilities, that in turn can reshape the electron distributions via
wave-particle interactions. In the solar wind, they are one of the main
candidates for explaining the scattering of the strahl electron population into
the halo at increasing radial distances from the Sun and for subsequently
regulating the solar wind heat flux. However, it is unclear what type of
instability dominates to drive whistlers in the solar wind. Aims. Our goal is
to study whistler wave parameters in the young solar wind sampled by Parker
Solar Probe (PSP). The wave normal angle (WNA) in particular is a key parameter
to discriminate between the generation mechanisms of these waves. Methods. We
analyze the cross-spectral matrices of magnetic fieldfluctuations measured by
the Search-Coil Magnetometer (SCM) and processed by the Digital Fields Board
(DFB) from the FIELDS suite during PSP's first perihelion. Results. Among the
2701 wave packets detected in the cross spectra, namely individual bins in time
and frequency, most were quasi-parallel to the background magnetic field but a
significant part (3%) of observed waves had oblique (> 45{\deg}) WNA. The
validation analysis conducted with the time-series waveforms reveal that this
percentage is a lower limit. Moreover, we find that about 64% of the whistler
waves detected in the spectra are associated with at least one magnetic dip.
Conclusions. We conclude that magnetic dips provides favorable conditions for
the generation of whistler waves. We hypothesize that the whistlers detected in
magnetic dips are locally generated by the thermal anisotropy as quasi-parallel
and can gain obliqueness during their propagation. We finally discuss the
implication of our results for the scattering of the strahl in the solar wind.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:27:27 GMT""}]","2023-04-12"
"2302.01246","Ting Ye","Danni Shi and Ting Ye","Behavioral Carry-Over Effect and Power Consideration in Crossover Trials",,,,,"stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A crossover trial is an efficient trial design when there is no carry-over
effect. To reduce the impact of the biological carry-over effect, a wash-out
period is often designed. However, the carry-over effect remains an outstanding
concern when a wash-out period is unethical or cannot sufficiently diminish the
impact of the carry-over effect. The latter can occur in comparative
effectiveness research where the carry-over effect is often non-biological but
behavioral. In this paper, we investigate the crossover design under a
potential outcomes framework with and without the carry-over effect. We find
that when the carry-over effect exists and satisfies a sign condition, the
basic estimator underestimates the treatment effect, which does not inflate the
type I error of one-sided tests but negatively impacts the power. This leads to
a power trade-off between the crossover design and the parallel-group design,
and we derive the condition under which the crossover design does not lead to
type I error inflation and is still more powerful than the parallel-group
design. We also develop covariate adjustment methods for crossover trials. We
illustrate the performance of cross-over design and covariate adjustment using
simulations based on resampling data from an HIV prevention trial.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:28:14 GMT""}]","2023-02-03"
"2302.01247","Anthony Guillen","Ignatios Antoniadis, Jules Cunat, Anthony Guillen","More on massive gravitino scattering amplitudes and the unitarity cutoff
  of the new Fayet-Iliopoulos terms","14 pages, 2 figures",,"10.1007/JHEP04(2023)002",,"hep-th gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend the $2\rightarrow2$ gravitino scattering amplitude computed in [1]
to an arbitrary $\mathcal{N}=1$ supergravity model of one chiral and one vector
multiplet, in a Minkowski background with supersymmetry breaking driven by both
$F$- and $D$-terms. We find that the cancellation of the leading term in
$\mathcal{O}(\kappa^2 E^4/|m_{3/2}|^2)$, that would lead to a breakdown of
perturbative unitarity at a scale $\Lambda\sim M_\mathrm{SUSY}$, is a
consequence of the vanishing of the scalar potential at its minimum, which is
implied by the flat background. We then analyse the inclusion of the new
Fayet-Iliopoulos (FI) terms. We find that, since they modify the scalar
potential without contributing to the amplitudes, they generically lead to
uncanceled leading terms in the latter and a perturbative cutoff at the
supersymmetry breaking scale, except for particular cases where the new FI term
does not modify the potential at its minimum and the cutoff is pushed up to the
Planck scale.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:28:26 GMT""}]","2023-04-19"
"2302.01248","Wenhao Yang","Wenhao Yang, Han Wang, Tadashi Kozuno, Scott M. Jordan, Zhihua Zhang","Avoiding Model Estimation in Robust Markov Decision Processes with a
  Generative Model",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robust Markov Decision Processes (MDPs) are getting more attention for
learning a robust policy which is less sensitive to environment changes. There
are an increasing number of works analyzing sample-efficiency of robust MDPs.
However, most works study robust MDPs in a model-based regime, where the
transition probability needs to be estimated and requires
$\mathcal{O}(|\mathcal{S}|^2|\mathcal{A}|)$ storage in memory. A common way to
solve robust MDPs is to formulate them as a distributionally robust
optimization (DRO) problem. However, solving a DRO problem is non-trivial, so
prior works typically assume a strong oracle to obtain the optimal solution of
the DRO problem easily. To remove the need for an oracle, we first transform
the original robust MDPs into an alternative form, as the alternative form
allows us to use stochastic gradient methods to solve the robust MDPs.
Moreover, we prove the alternative form still preserves the role of robustness.
With this new formulation, we devise a sample-efficient algorithm to solve the
robust MDPs in a model-free regime, from which we benefit lower memory space
$\mathcal{O}(|\mathcal{S}||\mathcal{A}|)$ without using the oracle. Finally, we
validate our theoretical findings via numerical experiments and show the
efficiency to solve the alternative form of robust MDPs.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:29:10 GMT""}]","2023-02-03"
"2302.01249","Brian Nevins","Brian Nevins, Luke F. Roberts","Proto-Neutron Star Convection and the Neutrino-Driven Wind: Implications
  for the r-Process","14 pages, 14 figures, accepted for publication in MNRAS",,"10.1093/mnras/stad372",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The neutrino-driven wind from proto-neutron stars is a proposed site for
r-process nucleosynthesis, although most previous work has found that a wind
heated only by neutrinos cannot produce the third r-process peak. However,
several groups have noted that introducing a secondary heating source within
the wind can change the hydrodynamic conditions sufficiently for a strong
r-process to proceed. One possible secondary heating source is gravito-acoustic
waves, generated by convection inside the proto-neutron star. As these waves
propagate into the wind, they can both accelerate the wind and shock and
deposit energy into the wind. Additionally, the acceleration of the wind by
these waves can reduce the total number of neutrino captures and thereby reduce
the final electron fraction of the wind. In neutron rich conditions, all of
these effects can make conditions more favorable for r-process nucleosynthesis.
Here, we present a systematic investigation of the impact of these
convection-generated gravito-acoustic waves within the wind on potential
nucleosynthesis. We find that wave effects in the wind can generate conditions
favorable for a strong r-process, even when the energy flux in the waves is a
factor of $10^{-4}$ smaller than the total neutrino energy flux and the wind is
marginally neutron-rich. Nevertheless, this depends strongly on the radius at
which the wave become non-linear and form shocks. We also find that both
entropy production after shock formation and the acceleration of the wind due
to stresses produced by the waves prior to shock formation impact the structure
and nucleosynthesis of these waves.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:29:54 GMT""}]","2023-02-06"
"2302.01250","Andres Cremades","Andres Cremades, Sergio Hoyas, Pedro Quintero, Martin Lellep, Moritz
  Linkmann, Ricardo Vinuesa","Explaining wall-bounded turbulence through deep learning",,,,,"physics.flu-dyn cs.AI","http://creativecommons.org/licenses/by/4.0/","  Despite its great scientific and technological importance, wall-bounded
turbulence is an unresolved problem that requires new perspectives to be
tackled. One of the key strategies has been to study interactions among the
coherent structures in the flow. Such interactions are explored in this study
for the first time using an explainable deep-learning method. The instantaneous
velocity field in a turbulent channel is used to predict the velocity field in
time through a convolutional neural network. Based on the predicted flow, we
assess the importance of each structure for this prediction using the
game-theoretic algorithm of SHapley Additive exPlanations (SHAP). This work
provides results in agreement with previous observations in the literature and
extends them by quantifying the importance of the Reynolds-stress structures,
finding a connection between these structures and the dynamics of the flow. The
process, based on deep-learning explainability, has the potential to shed light
on numerous fundamental phenomena of wall-bounded turbulence, including the
objective definition of new types of flow structures.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:34:33 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 07:57:31 GMT""}]","2023-04-07"
"2302.01251","Max Downing","Max Downing, Sameer Murthy, Gerard M. T. Watts","Modular symmetry of massive free fermions",,,,,"hep-th","http://creativecommons.org/publicdomain/zero/1.0/","  We construct an infinite set of conserved tensor currents of rank $2n$,
$n=1,2,\dots$, in the two-dimensional theory of free massive fermions, which
are bilinear in the fermionic fields. The one-point functions of these currents
on the torus depend on the modular parameter $\tau$ and spin structure
$(\alpha,\beta)$. We show that, upon scaling the mass $m$ so as to keep the
combination $m^2$Im($\tau$) invariant, the one-point functions are
non-holomorphic Jacobi forms of weights $(2n,0)$ or $(0,2n)$ and index 0, with
respect to the modular parameter $\tau$ and elliptic parameter
$z=\alpha\tau+\beta$. In particular, we express the one-point functions as
Kronecker-Eisenstein-type sums over the lattice $\mathbb{Z}\tau+\mathbb{Z}$,
which makes the modular symmetry manifest. We show that there is an action of
three differential operators on these Jacobi forms which form an
$\mathfrak{sl}_2(\mathbb{R})$ Lie algebra. Further we show that these Jacobi
forms obey three differential equations arising from the representation theory
of the Jacobi group.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:36:34 GMT""},{""version"":""v2"",""created"":""Fri, 17 Feb 2023 17:20:11 GMT""}]","2023-02-20"
"2302.01252","Evan McKinney","Evan McKinney, Chao Zhou, Mingkang Xia, Michael Hatridge, Alex K.
  Jones","Parallel Driving for Fast Quantum Computing Under Speed Limits","13 pages, 11 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Increasing quantum circuit fidelity requires an efficient instruction set to
avoid errors from decoherence. The choice of a two-qubit (2Q) hardware basis
gate depends on a quantum modulator's native Hamiltonian interactions and
applied control drives. In this paper, we propose a collaborative design
approach to select the best ratio of drive parameters that determine the best
basis gate for a particular modulator. This requires considering the
theoretical computing power of the gate along with the practical speed limit of
that gate, given the modulator drive parameters. The practical speed limit
arises from the couplers' tolerance for strong driving when one or more pumps
is applied, for which some combinations can result in higher overall speed
limits than others. Moreover, as this 2Q basis gate is typically applied
multiple times in succession, interleaved by 1Q gates applied directly to the
qubits, the speed of the 1Q gates can become a limiting factor for the quantum
circuit. We propose a parallel-drive approach that drives the modulator and
qubits simultaneously, allowing a richer capability of the 2Q basis gate and in
some cases for this 1Q drive time to be absorbed entirely into the 2Q
operation. This allows increasingly short duration 2Q gates while mitigating a
significant source of overhead in some quantum systems. On average, this
approach can decrease circuit duration by 17.84% and decrease infidelity for
random 2Q gates by 10.5% compared to the best basic 2Q gate,
$\sqrt{\texttt{iSWAP}}$.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:38:05 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 01:52:09 GMT""},{""version"":""v3"",""created"":""Wed, 8 Mar 2023 21:24:36 GMT""}]","2023-03-10"
"2302.01253","Cristina Ballantine","Cristina Ballantine and Mircea Merca","$6$-regular partitions: new combinatorial properties, congruences, and
  linear inequalities","27 pages",,,,"math.NT math.CO","http://creativecommons.org/licenses/by/4.0/","  We consider the number of the $6$-regular partitions of $n$, $b_6(n)$, and
give infinite families of congruences modulo $3$ (in arithmetic progression)
for $b_6(n)$. We also consider the number of the partitions of $n$ into
distinct parts not congruent to $\pm 2$ modulo $6$, $Q_2(n)$, and investigate
connections between $b_6(n)$ and $Q_2(n)$ providing new combinatorial
interpretations for these partition functions. In this context, we discover new
infinite families of linear inequalities involving Euler's partition function
$p(n)$. Infinite families of linear inequalities involving the $6$-regular
partition function $b_6(n)$ and the distinct partition function $Q_2(n)$ are
proposed as open problems.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:38:40 GMT""}]","2023-02-03"
"2302.01254","Natalia Perkins","Susmita Singh, P. Peter Stavropoulos and Natalia B. Perkins","Phonon Dynamics in the Generalized Kitaev Spin Liquid","15 pahes, 7 figures",,,,"cond-mat.str-el","http://creativecommons.org/licenses/by-sa/4.0/","  Candidate materials for the Kitaev spin liquid generically have residual
interactions beyond the Kitaev coupling. It therefore becomes necessary to
understand how signatures of the quantum spin liquid, e.g., fractionalization
of the spin excitations, are affected by the presence of these interactions.
Recently it was shown that phonon dynamics is an indirect but effective probe
to study fractionalized excitations in the Kitaev spin liquid. Ultrasound
experiments can measure sound attenuation, which should show characteristic
temperature and angular dependence of the sound attenuation coefficient if the
scattering of phonons happens predominantly on Majorana fermions. So far the
computation of the sound attenuation was only done in the pure spin-phonon
coupled Kitaev model, without taking into account residual interactions. In
order to understand experimental signatures, here we present a mean-field study
of the sound attenuation in the generalized $J$-$K$-$\Gamma$ model, which is
relevant to candidate materials. Our findings show that as long as the system
is in the spin liquid phase, characteristic features of the sound attenuation
remain observable even in the presence of residual interactions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:39:00 GMT""}]","2023-02-03"
"2302.01255","Denisa A. O. Roberts","Alaa Awad, Denisa Roberts, Eden Dolev, Andrea Heyman, Zahra
  Ebrahimzadeh, Zoe Weil, Marcin Mejran, Vaibhav Malpani, Mahir Yavuz","adSformers: Personalization from Short-Term Sequences and Diversity of
  Representations in Etsy Ads",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this article, we present our approach to personalizing Etsy Ads through
encoding and learning from short-term (one-hour) sequences of user actions and
diverse representations. To this end we introduce a three-component adSformer
diversifiable personalization module (ADPM) and illustrate how we use this
module to derive a short-term dynamic user representation and personalize the
Click-Through Rate (CTR) and Post-Click Conversion Rate (PCCVR) models used in
sponsored search (ad) ranking. The first component of the ADPM is a custom
transformer encoder that learns the inherent structure from the sequence of
actions. ADPM's second component enriches the signal through visual, multimodal
and textual pretrained representations. Lastly, the third ADPM component
includes a ""learned"" on the fly average pooled representation. The
ADPM-personalized CTR and PCCVR models, henceforth referred to as adSformer CTR
and adSformer PCCVR, outperform the CTR and PCCVR production baselines by
$+6.65\%$ and $+12.70\%$, respectively, in offline Precision-Recall Area Under
the Curve (PR AUC). At the time of this writing, following the online gains in
A/B tests, such as $+5.34\%$ in return on ad spend, a seller success metric, we
are ramping up the adSformers to $100\%$ traffic in Etsy Ads.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:39:10 GMT""}]","2023-02-03"
"2302.01256","Tania Bossio","Davide Barilari and Tania Bossio","Steiner and tube formulae in 3D contact sub-Riemannian geometry","31 pages. To appear in Communications in Contemporary Mathematics",,,,"math.DG math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a Steiner formula for regular surfaces with no characteristic points
in 3D contact sub-Riemannian manifolds endowed with an arbitrary smooth volume.
The formula we obtain, which is equivalent to a half-tube formula, is of local
nature. It can thus be applied to any surface in a region not containing
characteristic points. We provide a geometrical interpretation of the
coefficients appearing in the expansion, and compute them on some relevant
examples in three-dimensional sub-Riemannian model spaces. These results
generalize those obtained in 10.1016/j.na.2015.05.006 and arXiv:1703.01592v3
for the Heisenberg group.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:41:20 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 10:17:57 GMT""}]","2023-06-05"
"2302.01257","Roland Combescot","Roland Combescot and Shiue-Yuan Shiau","Exciton ground-state energy with full hole warping structure","10 pages, 1 figure",,,,"cond-mat.str-el cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Most semiconductors, in particular III-V compounds, have a complex valence
band structure near the band edge, due to degeneracy at the zone center. One
peculiar feature is the warping of the electronic dispersion relations, which
are not isotropic even in the vicinity of the band edge. When the exciton, all
important for the semiconductor optical properties, is considered, this problem
is usually handled by using some kind of angular averaging procedure, that
would restore the isotropy of the hole effective dispersion relations. In the
present paper, we consider the problem of the exciton ground-state energy for
semiconductors with zinc-blende crystal structure, and we solve it exactly by a
numerical treatment, taking fully into account the warping of the valence band.
In the resulting four-dimensional problem, we first show exactly that the
exciton ground state is fourfold degenerate. We then explore the ground-state
energy across the full range of allowed Luttinger parameters. We find that the
correction due to warping may in principle be quite large. However, for the
semiconductors with available data for the band structure we have considered,
the correction turns out to be in the $10\% - 15\%$ range.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:43:18 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 13:53:45 GMT""}]","2023-02-09"
"2302.01258","John Scott","J. W. Scott, M. D. Nguyen, D. Park, and W. P. Halperin","Magnetic Susceptibility of Andreev Bound States in Superfluid $^3$He-B","Fixes to references, acknowledgements",,,,"cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  Nuclear magnetic resonance measurements of the magnetic susceptibility of
superfluid $^3$He imbibed in anisotropic aerogel reveal anomalous behavior at
low temperatures. Although the frequency shift clearly identifies a
low-temperature phase as the $B$ phase, the magnetic susceptibility does not
display the expected decrease associated with the formation of the
opposite-spin Cooper pairs. This susceptibility anomaly appears to be the
predicted high-field behavior corresponding to the Ising-like magnetic
character of surface Andreev bound states within the planar aerogel structures.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:43:35 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 16:12:48 GMT""}]","2023-02-06"
"2302.01259","Eivind Meyer","Eivind Meyer, Maurice Brenner, Bowen Zhang, Max Schickert, Bilal
  Musani, and Matthias Althoff","Geometric Deep Learning for Autonomous Driving: Unlocking the Power of
  Graph Neural Networks With CommonRoad-Geometric","Presented at IV 2023",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Heterogeneous graphs offer powerful data representations for traffic, given
their ability to model the complex interaction effects among a varying number
of traffic participants and the underlying road infrastructure. With the recent
advent of graph neural networks (GNNs) as the accompanying deep learning
framework, the graph structure can be efficiently leveraged for various machine
learning applications such as trajectory prediction. As a first of its kind,
our proposed Python framework offers an easy-to-use and fully customizable data
processing pipeline to extract standardized graph datasets from traffic
scenarios. Providing a platform for GNN-based autonomous driving research, it
improves comparability between approaches and allows researchers to focus on
model implementation instead of dataset curation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:45:02 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 08:30:35 GMT""}]","2023-04-25"
"2302.01260","Istvan Pusztai","Istvan Pusztai, Ida Ekmark, Hannes Bergstr\""om, Peter Halldestam,
  Patrik Jansson, Mathias Hoppe, Oskar Vallhagen, T\""unde F\""ul\""op","Bayesian optimization of massive material injection for disruption
  mitigation in tokamaks",,,"10.1017/S0022377823000193",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Bayesian optimization framework is used to investigate scenarios for
disruptions mitigated with combined deuterium and neon injection in ITER. The
optimization cost function takes into account limits on the maximum runaway
current, the transported fraction of the heat loss and the current quench time.
The aim is to explore the dependence of the cost function on injected
densities, and provide insights into the behaviour of the disruption dynamics
for representative scenarios. The simulations are conducted using the numerical
framework DREAM (Disruption Runaway Electron Analysis Model). We show that
irrespective of the quantities of the material deposition, multi-megaampere
runaway currents will be produced in the deuterium-tritium phase of operations,
even in the optimal scenarios. However, the severity of the outcome can be
influenced by tailoring the radial profile of the injected material; in
particular if the injected neon is deposited at the edge region it leads to a
significant reduction of both the final runaway current and the transported
heat losses. The Bayesian approach allows us to map the parameter space
efficiently, with more accuracy in favorable parameter regions, thereby
providing us information about the robustness of the optima.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:45:29 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 15:19:32 GMT""}]","2023-04-19"
"2302.01261","Renwen Yu","Renwen Yu and Shanhui Fan","Manipulating coherence of near-field thermal radiation in time-modulated
  systems",,"Phys. Rev. Lett. 130, 096902 (2023)","10.1103/PhysRevLett.130.096902",,"physics.optics cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the spatial coherence of thermal radiation can be manipulated in
time-modulated photonic systems supporting surface polaritons. We develop a
fluctuational electrodynamics formalism for such systems to calculate the
cross-spectral density tensor of the emitted thermal electromagnetic fields in
the near-field regime. Our calculations indicate that, due to time-modulation,
spatial coherence can be transferred between different frequencies, and
correlations between different frequency components become possible. All these
effects are unique to time-modulated systems. We also show that the decay rate
of optical emitters can be controlled in the proximity of such time-modulated
structure. Our findings open a promising avenue toward coherence control in
thermal radiation, dynamical thermal imaging, manipulating energy transfer
among thermal or optical emitters, efficient near-field radiative cooling, and
engineering spontaneous emission rates of molecules.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:45:40 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 23:04:19 GMT""}]","2023-03-01"
"2302.01262","Khrystyna Gnatenko","Kh. P. Gnatenko, V. M. Tkachuk","Deformed Heisenberg algebras of different types with preserved weak
  equivalence principle",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the paper a review of results for recovering of the weak equivalence
principle in a space with deformed commutation relations for operators of
coordinates and momenta is presented. Different types of deformed algebras
leading to a space quantization are considered among them noncommutative
algebra of canonical type, algebra of Lie type, nonlinear deformed algebra with
arbitrary function of deformation depending on momenta. A motion of a particle
and a composite system in gravitational field is examined and the
implementation of the weak equivalence principle is studied. The principle is
preserved in quantized space if we consider parameters of deformed algebras to
be dependent on mass. It is also shown that dependencies of parameters of
deformed algebras on mass lead to preserving of the properties of the kinetic
energy in quantized spaces and solving of the problem of significant effect of
space quantization on the motion of macroscopic bodies (the problem is known as
the soccer-ball problem).
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:45:45 GMT""}]","2023-02-03"
"2302.01263","Erik Kalz","Erik Kalz, Hidde Derk Vuijk, Jens-Uwe Sommer, Ralf Metzler, Abhinav
  Sharma","Oscillatory force autocorrelations in equilibrium odd-diffusive systems",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The force autocorrelation function, a concept of fundamental interest in
statistical mechanics, encodes the effect of interactions on the dynamics of a
tagged particle. In equilibrium, the correlation is believed to decay
monotonically in time which is a hallmark signature of slowing down of the
dynamics of the tagged particle due to interactions. Here we analytically show
that in odd-diffusive systems, which are characterized by a diffusion tensor
with antisymmetric elements, the force autocorrelation function can become
negative and even exhibit temporal oscillations. %Remarkably this holds
regardless of the dilute limit where collisions are rare. We further
demonstrate that, despite the isotropy, the knowledge of force autocorrelation
function alone is not sufficient to determine the self-diffusion coefficient:
the full autocorrelation tensor is required and contains an antisymmetric part.
These unusual properties translate into enhanced dynamics of the tagged
particle quantified via the self-diffusion coefficient that, remarkably,
increases due to particle interactions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:46:09 GMT""}]","2023-02-03"
"2302.01264","Luca Ferialdi Dr.","Luca Ferialdi","General ordering theorem",,"Physical Review D 107, 105010 (2023)","10.1103/PhysRevD.107.105010",,"quant-ph hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of ordering operators has afflicted quantum mechanics since its
foundation. Several orderings have been devised, but a systematic procedure to
move from one ordering to another is still missing. The importance of
establishing relations among different orderings is demonstrated by Wick's
theorem (which relates time ordering to normal ordering), which played a
crucial role in the development of quantum field theory. We prove the General
Ordering Theorem (GOT), which establishes a relation among any pair of
orderings, that act on operators satisfying generic (i.e. operatorial)
commutation relations. We expose the working principles of the GOT by simple
examples, and we demonstrate its potential by recovering two famous algebraic
theorems as special instances: the Magnus expansion and the
Baker-Campbell-Hausdorff formula. Remarkably, the GOT establishes a formal
relation between these two theorems, and it provides compact expressions for
them, unlike the notoriously complicated ones currently known.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:49:35 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 14:07:14 GMT""}]","2023-05-25"
"2302.01265","M\'ario Pereira","Tiago Soares and M\'ario Pereira","A Framework for the Automated Verification of Algebraic Effects and
  Handlers (extended version)",,,,,"cs.LO","http://creativecommons.org/licenses/by/4.0/","  Algebraic effects and handlers are a powerful abstraction to build non-local
control-flow mechanisms such as resumable exceptions, lightweight threads,
co-routines, generators, and asynchronous I/O. All of such features have very
evolved semantics, hence they pose very interesting challenges to deductive
verification techniques. In fact, there are very few proposed techniques to
deductively verify programs featuring these constructs, even fewer when it
comes to automated proofs. In this paper, we present an extension to Cameleer,
a deductive verification tool for OCaml code, that allows one to reason about
algebraic effects and handlers. Our proposal embeds the behavior of effects and
handlers using exceptions and employs defunctionalization to deal with
continuations exposed by effect handlers.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:49:47 GMT""},{""version"":""v2"",""created"":""Sat, 4 Feb 2023 00:14:35 GMT""},{""version"":""v3"",""created"":""Tue, 7 Feb 2023 10:25:44 GMT""}]","2023-02-08"
"2302.01266","Hanlin Fang","Qiaoling Lin, Hanlin Fang, Yuanda Liu, Yi Zhang, Moritz Fischer,
  Juntao Li, Joakim Hagel, Samuel Brem, Ermin Malic, Nicolas Stenger, Zhipei
  Sun, Martijn Wubs, and Sanshui Xiao","A room-temperature moir\'e interlayer exciton laser",,,,,"physics.optics cond-mat.mes-hall","http://creativecommons.org/publicdomain/zero/1.0/","  Moir\'e superlattices in van der Waals heterostructures offer highly tunable
quantum systems with emergent electronic and excitonic properties such as
superconductivity, topological edge states, and moir\'e-trapped excitons.
Theoretical calculations predicted the existence of the moir\'e potential at
elevated temperatures; however, its impact on the optical properties of
interlayer excitons (IXs) at room temperature is lacking, and the benefits of
the moir\'e effects for lasing applications remain unexplored. We report that
the moir\'e potential in a molybdenum disulfide/tungsten diselenide (MoS2/WSe2)
heterobilayer system can significantly enhance light emission, elongate the IX
lifetime, and modulate the IX emission energy at room temperature. By
integrating a moir\'e superlattice with a silicon topological nanocavity, we
achieve ultra-low-threshold lasing at the technologically important
telecommunication O-band thanks to the significant moir\'e modulation.
Moreover, the high-quality topological nanocavities facilitate the highest
spectral coherence of < 0.1 nm linewidth among all reported two-dimensional
material-based laser systems. Our findings not only open a new avenue for
studying correlated states at elevated temperatures, but also enable novel
architectures for integrated on-chip photonics and optoelectronics.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:53:25 GMT""}]","2023-02-03"
"2302.01267","Joaquim Anacleto","Joaquim Anacleto","Thermal capacities and polytropic processes","9 pages, 1 figure","Eur. J. Phys. 44 045101 (2023)","10.1088/1361-6404/acce0b",,"physics.ed-ph physics.class-ph","http://creativecommons.org/licenses/by/4.0/","  Herein, we analyse polytropic processes for an ideal gas within the wider
concept of thermal capacity. To answer the question of whether the thermal
capacity is a process, path, or state function, we argue that it should be
tentatively set as a path function and if it remains constant along the path,
the corresponding process is polytropic. Of all the paths, there are only two,
at constant volume and constant pressure, for which the thermal capacities, Cv
and Cp, are state functions, i.e., system properties. The discussions herein
are valuable both scientifically and instructively because they shed light on
issues in undergraduate curricula that are not addressed in sufficient detail
in physics textbooks, not even in the most advanced ones.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:53:48 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 16:44:15 GMT""}]","2023-06-07"
"2302.01268","David Strubbe","Karen Mohammadtabar, Enrique Guerrero, Sergio Romero Garcia, Yun Kyung
  Shin, Adri C. T. van Duin, David A. Strubbe, and Ashlie Martini","Development and Demonstration of a ReaxFF Reactive Force Field for
  Ni-Doped MoS$_2$","39 pages, 11 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The properties of $\mathrm{MoS_2}$ can be tuned or optimized through doping.
In particular, Ni doping has been shown to improve the performance of
$\mathrm{MoS_2}$ for various applications, including catalysis and tribology.
To enable investigation of Ni-doped $\mathrm{MoS_2}$ with reactive molecular
dynamics simulations, we developed a new ReaxFF force field to describe this
material. The force field parameters were optimized to match a large set of
density-functional theory (DFT) calculations of 2H-$\mathrm{MoS_2}$ doped with
Ni, at four different sites (Mo-substituted, S-substituted, octahedral
intercalation, and tetrahedral intercalation), under uniaxial, biaxial,
triaxial, and shear strain. The force field was evaluated by comparing ReaxFF-
and DFT-relaxed structural parameters and the tetrahedral/octahedral energy
difference in doped 2H, energies of doped 1H and 1T monolayers, and doped 2H
structures with vacancies. We demonstrated the force field with reactive
simulations of sputtering deposition and annealing of Ni-doped MoS$_2$ films.
Results show that the developed force field can accurately model the phase
transition of Ni-doped $\mathrm{MoS_2}$ from amorphous to crystalline. The
newly developed force field can be used in subsequent investigations to study
the properties and behavior of Ni-doped $\mathrm{MoS_2}$ using reactive
molecular dynamics simulations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:54:11 GMT""}]","2023-02-03"
"2302.01269","Ting Ye","Yilin Song, James P. Hughes, Ting Ye","Adjusting for Incomplete Baseline Covariates in Randomized Controlled
  Trials: A Cross-World Imputation Framework",,,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In randomized controlled trials, adjusting for baseline covariates is often
applied to improve the precision of treatment effect estimation. However,
missingness in covariates is common. Recently, Zhao & Ding (2022) studied two
simple strategies, the single imputation method and missingness indicator
method (MIM), to deal with missing covariates, and showed that both methods can
provide efficiency gain. To better understand and compare these two strategies,
we propose and investigate a novel imputation framework termed cross-world
imputation (CWI), which includes single imputation and MIM as special cases.
Through the lens of CWI, we show that MIM implicitly searches for the optimal
CWI values and thus achieves optimal efficiency. We also derive conditions
under which the single imputation method, by searching for the optimal single
imputation values, can achieve the same efficiency as the MIM.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:57:31 GMT""}]","2023-02-03"
"2302.01270","Yuji Hirono","Yuji Hirono, Hyukpyo Hong, and Jae Kyoung Kim","Robust Perfect Adaptation of Reaction Fluxes Ensured by Network Topology","5 pages, 2 figures (Supplemental Material: 14 pages, 1 figure)",,,"RIKEN-iTHEMS-Report-23","q-bio.MN physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Maintaining stability in an uncertain environment is essential for proper
functioning of living systems. Robust perfect adaptation (RPA) is a property of
a system that generates an output at a fixed level even after fluctuations in
input stimulus without fine-tuning parameters, and it is important to
understand how this feature is implemented through biochemical networks. The
existing literature has mainly focused on RPA of the concentration of a chosen
chemical species, and no generic analysis has been made on RPA of reaction
fluxes, that play an equally important role. Here, we identify structural
conditions on reaction networks under which all the reaction fluxes exhibit RPA
against the perturbation of the parameters inside a subnetwork. Based on this
understanding, we give a recipe for obtaining a simpler reaction network, from
which we can fully recover the steady-state reaction fluxes of the original
system. This helps us identify key parameters that determine the fluxes and
study the properties of complex reaction networks using a smaller one without
losing any information about steady-state reaction fluxes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:58:19 GMT""}]","2023-02-03"
"2302.01271","Johannes Pollanen","J. M. Kitzman, J. R. Lane, C. Undershute, N. R. Beysengulov, C. A.
  Mikolas, K. W. Murch and J. Pollanen","Surface acoustic wave Fano interference in the quantum regime","5 pages, 3 figures",,,,"quant-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Quantum acoustic systems, which integrate surface or bulk phonons with
superconducting qubits, offer a unique opportunity to investigate phononic
interference and scattering processes in the quantum regime. In particular the
interaction between a superconducting qubit and a phononic oscillator allows
the qubit to operate as a sensor of the oscillator's excitation spectra and
underlying interference effects. Here we present measurements revealing the
interference of a resonantly trapped piezoelectric surface acoustic wave (SAW)
mode and a broad continuum of surface phonons in a system consisting of a SAW
resonator coupled to a superconducting qubit. By populating the SAW device with
phonons we leverage the resulting ac Stark shift of the qubit to extract the
mean excitation number of the surface phonon coherent state as a function of
frequency. In this fashion, the qubit functions as a spectroscopic sensor of
the surface phonon environment in the hybrid device and allows us to reveal the
interaction between phonons in the resonant SAW mode and the broader surface
phonon background, which is well-described within the context of Fano
interference of surface piezo-phonons.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:58:44 GMT""}]","2023-02-03"
"2302.01272","Alexis Diaz-Torres","Iain Lee, Gilbert Gosselin and Alexis Diaz-Torres","Thermal and atomic effects on coupled-channels heavy-ion fusion","5 pages, 5 figures, Accepted in Physical Review C","Physical Review C 107 (2023) 054609","10.1103/PhysRevC.107.054609",,"nucl-th astro-ph.SR nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Stellar nuclear fusion reactions take place in a hot, dense plasma within
stars. To account for the effect of these environments, the theory of open
quantum systems is used to conduct pioneering studies of thermal and atomic
effects on fusion probability at a broad range of temperatures and densities.
Since low-lying excited states are more likely to be populated at stellar
temperatures and increase nuclear plasma interaction rates, a 188Os nucleus was
used as a target that interacts with an inert 16O projectile. Key results
showed thermal effects yield an average increase in fusion probability of 15.5%
and 36.9% for our test nuclei at temperatures of 0.1 and 0.5 MeV respectively,
compared to calculations at zero temperature. Thermal effects could be tested
in a laboratory using targets prepared in excited states as envisaged in
facilities exploiting laser-nucleus interactions.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:03:41 GMT""},{""version"":""v2"",""created"":""Thu, 11 May 2023 13:53:21 GMT""}]","2023-05-18"
"2302.01273","Matthias Engel","Matthias Engel, Omid Ashtari, Moritz Linkmann","Symmetry-reduced low-dimensional representation of large-scale dynamics
  in the asymptotic suction boundary layer",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  An important feature of turbulent boundary layers are persistent large-scale
coherent structures in the flow. Here, we use Dynamic Mode Decomposition (DMD),
a data-driven technique designed to detect spatio-temporal coherence, to
construct optimal low-dimensional representations of such large-scale dynamics
in the asymptotic suction boundary layer (ASBL). In the ASBL, fluid is removed
by suction through the bottom wall, resulting in a constant boundary layer
thickness in streamwise direction. That is, the streamwise advection of
coherent structures by the mean flow ceases to be of dynamical importance and
can be interpreted as a continuous shift symmetry in streamwise direction.
However, this results in technical difficulties, as DMD is known to perform
poorly in presence of continuous symmetries. We address this issue using
symmetry-reduced DMD (Marensi et al., J. Fluid Mech. 721, A10 (2023)), and find
the large-scale dynamics of the ASBL to be low-dimensional indeed and
potentially self-sustained, featuring ejection and sweeping events at large
scale. Interactions with near-wall structures are captured when including only
a few more modes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:04:15 GMT""}]","2023-02-03"
"2302.01274","Ji-Chong Yang Mr","Shuai Zhang and Ji-Chong Yang and Yu-Chen Guo","Using k-means assistant event selection strategy to study anomalous
  quartic gauge couplings at muon colliders","24 pages, 6 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The search for new physics beyond the Standard Model is one of the central
problems of current high energy physics interest. As the luminosities of
current and near-future colliders continue to increase, the search for new
physics has increased the requirements for processing large amounts of data.
Mean while, quantum computing which is rapidly evolving, has great potential to
become a powerful tool to help search for new physics signals. Since the
k-means algorithm is known to be able to be speeded up with the help of quantum
computing, we investigate and propose an event selection strategy based on
k-means algorithm to search for new physics signals. Taking the case of
tri-photon processes at the muon colliders as an example, the event selection
strategy is shown to be effective in helping to search for the signal of
dimension-8 operators contributing to anomalous quartic gauge couplings.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:05:26 GMT""}]","2023-02-03"
"2302.01275","Theodore Moskovitz","Ted Moskovitz, Brendan O'Donoghue, Vivek Veeriah, Sebastian
  Flennerhag, Satinder Singh, Tom Zahavy","ReLOAD: Reinforcement Learning with Optimistic Ascent-Descent for
  Last-Iterate Convergence in Constrained MDPs",,,,,"cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  In recent years, Reinforcement Learning (RL) has been applied to real-world
problems with increasing success. Such applications often require to put
constraints on the agent's behavior. Existing algorithms for constrained RL
(CRL) rely on gradient descent-ascent, but this approach comes with a caveat.
While these algorithms are guaranteed to converge on average, they do not
guarantee last-iterate convergence, i.e., the current policy of the agent may
never converge to the optimal solution. In practice, it is often observed that
the policy alternates between satisfying the constraints and maximizing the
reward, rarely accomplishing both objectives simultaneously. Here, we address
this problem by introducing Reinforcement Learning with Optimistic
Ascent-Descent (ReLOAD), a principled CRL method with guaranteed last-iterate
convergence. We demonstrate its empirical effectiveness on a wide variety of
CRL problems including discrete MDPs and continuous control. In the process we
establish a benchmark of challenging CRL problems.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:05:27 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 00:26:43 GMT""}]","2023-03-07"
"2302.01276","Vincent Tatischeff","Vincent Tatischeff and Margarita Hernanz","Nova explosions -- The fascinating gamma-ray emitting recurrent nova RS
  Ophiuchi","8 pages, 3 figures, proceedings of the 7th Heidelberg International
  Symposium on High-Energy Gamma-Ray Astronomy (Gamma2022) in Barcelona (Spain)
  on 4-8 July 2022",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Classical and recurrent nova explosions occur on top of white dwarfs
accreting H-rich matter from a companion main sequence or red giant star, in a
close binary system. In the recent years, since the launch of the Fermi
gamma-ray satellite by NASA in 2008, several novae have been detected by
Fermi/LAT (LAT: Large Area Telescope) in high-energy (HE) gamma rays, with
energies larger than 100 MeV. This emission is known to be related to the
acceleration of particles in the internal and/or external shocks occurring
early after the thermonuclear nova explosion. However, very-high-energy (VHE)
gamma-rays, with energies larger than 100 GeV, produced as a consequence of
nova explosions have only been discovered very recently, in the recurrent nova
RS Oph, that had an outburst in August 2021. These require the acceleration of
protons, and not only of electrons; this was in fact predicted theoretically -
based in observations at other wavelengths - in the previous eruption of RS
Oph, in 2006, but has not been confirmed observationally until now. We review
the origin of the different types of gamma-ray emission in novae and highlight
the relevance of the recent VHE gamma-ray emission discoveries for the nova
theory, mainly in the field of the mass ejection and the associated particle
(electrons and protons) acceleration processes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:09:02 GMT""}]","2023-02-03"
"2302.01277","Anatol Guglielmi","A. Guglielmi, B. Klain, A. Zavyalov, O. Zotov","Omori Law. To the 100th anniversary of death of the famous Japanese
  seismologist","6 pages, 1 figures",,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  One hundred years ago, Fusakichi Omori died. Our paper is dedicated to his
memory. Omori made an outstanding contribution to the physics of earthquakes.
In 1894 he formulated the law of aftershock evolution. Omori's Law states that
after the main shock of an earthquake, the frequency of aftershocks decreases
hyperbolically with time. In this paper, we briefly describe one of the
directions of modern aftershock research. Keywords: earthquake, mainshock,
aftershock, evolution equation, deactivation coefficient, inverse problem,
trigger, proper time.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:10:05 GMT""}]","2023-02-03"
"2302.01278","Yongho Kim","Yongho Kim, Jan Heiland","Convolutional Autoencoders, Clustering and POD for Low-dimensional
  Parametrization of Navier-Stokes Equations","16 pages, 12 figures",,,,"math.DS cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simulations of large-scale dynamical systems require expensive computations.
Low-dimensional parametrization of high-dimensional states such as Proper
Orthogonal Decomposition (POD) can be a solution to lessen the burdens by
providing a certain compromise between accuracy and model complexity. However,
for really low-dimensional parametrizations (for example for controller design)
linear methods like the POD come to their natural limits so that nonlinear
approaches will be the methods of choice. In this work we propose a
convolutional autoencoder (CAE) consisting of a nonlinear encoder and an affine
linear decoder and consider combinations with k-means clustering for improved
encoding performance. The proposed set of methods is compared to the standard
POD approach in two cylinder-wake scenarios modeled by the incompressible
Navier-Stokes equations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:12:08 GMT""},{""version"":""v2"",""created"":""Fri, 3 Feb 2023 13:54:04 GMT""}]","2023-02-06"
"2302.01279","Claudia Garc\'ia","Claudia Garc\'ia, Taoufik Hmidi, Joan Mateu","Time periodic solutions close to localized radial monotone profiles for
  the 2D Euler equations","50 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we address for the 2D Euler equations the existence of rigid
time periodic solutions close to stationary radial vortices of type
$f_0(|x|){\bf 1}_{\mathbb{D}}(x)$, with $\mathbb{D}$ the unit disc and $f_0$
being a strictly monotonic profile with constant sign. We distinguish two
scenarios according to the sign of the profile: defocusing and focusing. In the
first regime, we have scarcity of the bifurcating curves associated with lower
symmetry. However in the focusing case we get a countable family of bifurcating
solutions associated with large symmetry. The approach developed in this work
is new and flexible, and the explicit expression of the radial profile is no
longer required as in [41] with the quadratic shape. The alternative for that
is a refined study of the associated spectral problem based on Sturm-Liouville
differential equation with a variable potential that changes the sign depending
on the shape of the profile and the location of the time period. Deep hidden
structure on positive definiteness of some intermediate integral operators are
also discovered and used in a crucial way. Notice that a special study will be
performed for the linear problem associated with the first mode founded on
Pr\""{u}fer transformation and Kneser's Theorem on the non-oscillation
phenomenon.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:13:14 GMT""}]","2023-02-03"
"2302.01280","Pedro J. Colmenares Dr.","Pedro J. Colmenares","Generalized optimal protocols of Brownian motion in a parabolic potentia",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The generalized Langevin equation with an exponential kernel is used to
analyze memory effects on the optimal work done by a Brownian particle in a
heat bath and subjected to a harmonic moving potential. The generalized
overdamping scenario is also investigated. Several facts emerge in these more
precise descriptions using the same initial conditions of the Markovian which
lead the particle to do mechanical work against the field. Compared with the
results obtained with the latter, the memory fades the discontinuities observed
in the highly underdamped regime, which suggests that this trait is a
consequence of the Markov approximation as well as the dependence of the
different dynamical susceptibilities with the external field. Unlike the
overdamped Markovian, work is done by the external field in the analog
generalized counterpart. A detailed calculation of the rate of entropy
production gives negative values. It is mathematically correct because the
dynamics deal with a reduced description of the degrees of freedom of the bath.
The theory then requires improving the treatment of them to restore the second
law and thus to get the results with the required thermodynamics consistency.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:16:55 GMT""}]","2023-02-03"
"2302.01283","The ATLAS Collaboration","ATLAS Collaboration","Observation of single-top-quark production in association with a photon
  using the ATLAS detector","16 pages, no author list 3 figures, 0 tables, submitted to Phys. Rev.
  Lett. All figures including auxiliary figures are available at
  https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/TOPQ-2018-44/",,,"CERN-EP-2022-229","hep-ex","http://creativecommons.org/licenses/by/4.0/","  This Letter reports the observation of single top quarks produced together
with a photon using 139 fb$^{-1}$ of 13 TeV proton-proton collision data
collected with the ATLAS detector at the Large Hadron Collider. The analysis
uses the presence of a forward jet, characteristic of $t$-channel production,
and separates the signal from the background with neural networks. Requiring a
photon with transverse momentum larger than 20 GeV and within the detector
acceptance, the fiducial cross section is measured to be 688 $\pm$ 23 (stat.)
$^{+75}_{-71}$ (syst.) fb, to be compared with the Standard Model prediction of
515 $^{+36}_{-42}$ fb at next-to-leading order in QCD.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:17:57 GMT""}]","2023-02-03"
"2302.01287","Kevin Thandiackal","Kevin Thandiackal, Luigi Piccinelli, Pushpak Pati, Orcun Goksel","Multi-scale Feature Alignment for Continual Learning of Unlabeled
  Domains",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Methods for unsupervised domain adaptation (UDA) help to improve the
performance of deep neural networks on unseen domains without any labeled data.
Especially in medical disciplines such as histopathology, this is crucial since
large datasets with detailed annotations are scarce. While the majority of
existing UDA methods focus on the adaptation from a labeled source to a single
unlabeled target domain, many real-world applications with a long life cycle
involve more than one target domain. Thus, the ability to sequentially adapt to
multiple target domains becomes essential. In settings where the data from
previously seen domains cannot be stored, e.g., due to data protection
regulations, the above becomes a challenging continual learning problem. To
this end, we propose to use generative feature-driven image replay in
conjunction with a dual-purpose discriminator that not only enables the
generation of images with realistic features for replay, but also promotes
feature alignment during domain adaptation. We evaluate our approach
extensively on a sequence of three histopathological datasets for tissue-type
classification, achieving state-of-the-art results. We present detailed
ablation experiments studying our proposed method components and demonstrate a
possible use-case of our continual UDA method for an unsupervised patch-based
segmentation task given high-resolution tissue images.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:19:01 GMT""}]","2023-02-03"
"2302.01289","Isaac Neal","Isaac Neal, Steve Shkoller, Vlad Vicol","A characteristics approach to shock formation in 2D Euler with azimuthal
  symmetry and entropy",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  We provide a detailed analysis of the shock formation process for the
non-isentropic 2d Euler equations in azimuthal symmetry. We prove that from an
open set of smooth and generic initial data, solutions of Euler form a first
singularity or gradient blow-up or shock. This first singularity is termed a
H\""{o}lder $C^{\frac{1}{3}}$ pre-shock, and our analysis provides the first
detailed description of this cusp solution. The novelty of this work relative
to [Buckmaster-Drivas-Shkoller-Vicol, 2022] is that we herein consider a much
larger class of initial data, allow for a non-constant initial entropy, allow
for a non-trivial sub-dominant Riemann variable, and introduce a host of new
identities to avoid apparent derivative loss due to entropy gradients. The
method of proof is also new and robust, exploring the transversality of the
three different characteristic families to transform space derivatives into
time derivatives. Our main result provides a fractional series expansion of the
Euler solution about the pre-shock, whose coefficients are computed from the
initial data.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:19:37 GMT""}]","2023-02-03"
"2302.01295","Cheng-Chun Hsu","Cheng-Chun Hsu and Zhenyu Jiang and Yuke Zhu","Ditto in the House: Building Articulation Models of Indoor Scenes
  through Interactive Perception","ICRA 2023. Code and additional results are available at
  https://ut-austin-rpl.github.io/HouseDitto/",,,,"cs.RO cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Virtualizing the physical world into virtual models has been a critical
technique for robot navigation and planning in the real world. To foster
manipulation with articulated objects in everyday life, this work explores
building articulation models of indoor scenes through a robot's purposeful
interactions in these scenes. Prior work on articulation reasoning primarily
focuses on siloed objects of limited categories. To extend to room-scale
environments, the robot has to efficiently and effectively explore a
large-scale 3D space, locate articulated objects, and infer their
articulations. We introduce an interactive perception approach to this task.
Our approach, named Ditto in the House, discovers possible articulated objects
through affordance prediction, interacts with these objects to produce
articulated motions, and infers the articulation properties from the visual
observations before and after each interaction. It tightly couples affordance
prediction and articulation inference to improve both tasks. We demonstrate the
effectiveness of our approach in both simulation and real-world scenes. Code
and additional results are available at
https://ut-austin-rpl.github.io/HouseDitto/
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:22:00 GMT""}]","2023-02-03"
"2302.01296","Joshua Ramette","Joshua Ramette, Josiah Sinclair, Nikolas P. Breuckmann, and Vladan
  Vuleti\'c","Fault-Tolerant Connection of Error-Corrected Qubits with Noisy Links",,,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most promising routes towards scalable quantum computing is a
modular approach. We show that distinct surface code patches can be connected
in a fault-tolerant manner even in the presence of substantial noise along
their connecting interface. We quantify analytically and numerically the
combined effect of errors across the interface and bulk. We show that the
system can tolerate 14 times higher noise at the interface compared to the
bulk, with only a small effect on the code's threshold and sub-threshold
behavior, reaching threshold with $\sim 1 \%$ bulk errors and $\sim 10 \%$
interface errors. This implies that fault-tolerant scaling of error-corrected
modular devices is within reach using existing technology.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:22:17 GMT""}]","2023-02-03"
"2302.01297","Bingqing Cheng","Rochus Schmid, Bingqing Cheng","Computing chemical potentials of adsorbed or confined fluids",,,"10.1063/5.0146711",,"cond-mat.stat-mech cond-mat.mtrl-sci physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The chemical potential of adsorbed or confined fluids provides insight into
their unique thermodynamic properties and determines adsorption isotherms.
However, it is often difficult to compute this quantity from atomistic
simulations using existing statistical mechanical methods. We introduce a
computational framework that utilizes static structure factors, thermodynamic
integration and free energy perturbation, for calculating the absolute chemical
potential of fluids. For demonstration, we apply the method to compute the
adsorption isotherms of carbon dioxide in a metal-organic framework (MOF) and
water in carbon nanotubes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:23:50 GMT""}]","2023-05-10"
"2302.01298","Christopher Kane","Davide Giusti, Christopher F. Kane, Christoph Lehner, Stefan Meinel,
  Amarjit Soni","Methods for high-precision determinations of radiative-leptonic decay
  form factors using lattice QCD","31 pages, 14 figures","Phys. Rev. D 107, 074507 (2023)","10.1103/PhysRevD.107.074507",,"hep-lat hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a study of lattice-QCD methods to determine the relevant hadronic
form factors for radiative leptonic decays of pseudoscalar mesons. We provide
numerical results for $D_s^+ \to \ell^+ \nu \gamma$. Our calculation is
performed using a domain-wall action for all quark flavors and on a single
RBC/UKQCD lattice gauge-field ensemble. The first part of the study is how to
best control two sources of systematic error inherent in the calculation,
specifically the unwanted excited states created by the meson interpolating
field, and unwanted exponentials in the sum over intermediate states. Using a
3d sequential propagator allows for better control over unwanted exponentials
from intermediate states, while using a 4d sequential propagator allows for
better control over excited states. We perform individual analyses of the 3d
and 4d methods as well as a combined analysis using both methods, and find that
the 3d sequential propagator offers good control over both sources of
systematic uncertainties for the smallest number of propagator solves. From
there, we further improve the use of a 3d sequential propagator by employing an
infinite-volume approximation method, which allows us to calculate the relevant
form factors over the entire allowed range of photon energies. We then study
improvements gained by performing the calculation using a different three-point
function, using ratios of three-point functions, averaging over positive and
negative photon momentum, and using an improved method for extracting the
structure-dependent part of the axial form factor. The optimal combination of
methods yields results for the $D_s^+ \to \ell^+ \nu \gamma$
structure-dependent vector and axial form factors in the entire kinematic range
with statistical plus fitting uncertainties of order 5%, using 25 gauge
configurations with 64 samples per configuration.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:24:16 GMT""},{""version"":""v2"",""created"":""Wed, 19 Apr 2023 19:44:00 GMT""}]","2023-04-21"
"2302.01299","Pedro J. Colmenares Dr.","Pedro J. Colmenares and Oscar Paredes-Altuve","Optimal work of Brownian motion in a harmonic time-dependent stiffness
  potential. Effect of the initial position",,,,,"cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  The system consists of a Brownian particle immersed in a heat bath trapped in
optical tweezers with a time-dependent strength acting as an external protocol.
In [Phys. Rev. Letts., 98:108301, 2007] the optimal mean work in the overdamped
regime was thoroughly calculated by assuming the work must be averaged over the
distribution of the initial position of the particle. The present research
assumes instead the solution of the Langevin equation for any given initial
position and its average done over the noise distribution. Therefore, this
proposal extends in a more general sense the results already published,
including the appearance of Maxwell's demon for particular initial conditions
which is analyzed in terms of entropy production rate and the mutual
information obtained by measuring the particle position. The proposed research
has the advantage of being able to be compared with data from numerical
simulations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:26:31 GMT""}]","2023-02-03"
"2302.01300","Yaniv Kurman","Yaniv Kurman, Neta Lahav, Roman Schuetz, Avner Shultzman, Charles
  Roques-Carmes, Alon Lifshits, Segev Zaken, Tom Lenkiewicz, Rotem Strassberg,
  Orr Beer, Yehonadav Bekenstein, Ido Kaminer","Purcell-enhanced X-ray scintillation",,,,,"physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scintillators are used extensively in X-ray imaging technologies from medical
diagnostics to security inspections. Scintillation materials convert
high-energy radiation to optical light through a highly non-linear multi-stage
process. The last stage of the process is light emission via spontaneous
emission, which usually governs and limits the scintillator emission rate and
light yield. For decades, the desire for faster emission rate and greater light
yield motivated the frontier of scintillators research to focus on developing
better materials and dopants. Here, we experimentally demonstrate a
fundamentally different, recently proposed concept for enhancing the
scintillation rate and yield: the Purcell effect. The Purcell effect is the
universal enhancement of spontaneous emission by engineering the optical
environment. In the case of scintillators, such an enhancement arises from
engineering the nanoscale geometry within the scintillation bulk, which thus
applies universally to any scintillating material and dopant. We design and
fabricate a thin multilayer nanophotonic scintillator, demonstrating
Purcell-enhanced scintillation, achieving a 50% enhancement in emission rate
and an 80% enhancement in light yield. We also demonstrate the potential of our
device for realizing these enhancements in real-life settings for X-ray imaging
applications. First, we show that these enhancements are robust to fabrication
inaccuracies due to the robustness of the nanophotonic design. Second, we
demonstrate a 3-fold resolution enhancement in X-ray imaging. Our results show
the bright prospects of bridging nanophotonics and scintillators science:
toward reduced radiation dosage and increased resolution in medical X-ray
imaging, nuclear medicine, and other technologies relying on detection of
high-energy particles.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:26:50 GMT""}]","2023-02-03"
"2302.01301","Raffaele Galliera","Raffaele Galliera, Alessandro Morelli, Roberto Fronteddu, Niranjan
  Suri","MARLIN: Soft Actor-Critic based Reinforcement Learning for Congestion
  Control in Real Networks","10 pages, 5 figures, AAAI 2023 workshop ""Reinforcement Learning Ready
  for Production"", accepted at NOMS 2023 - IEEE/IFIP Network Operations and
  Management Symposium",,,,"cs.LG cs.AI cs.NI","http://creativecommons.org/licenses/by/4.0/","  Fast and efficient transport protocols are the foundation of an increasingly
distributed world. The burden of continuously delivering improved communication
performance to support next-generation applications and services, combined with
the increasing heterogeneity of systems and network technologies, has promoted
the design of Congestion Control (CC) algorithms that perform well under
specific environments. The challenge of designing a generic CC algorithm that
can adapt to a broad range of scenarios is still an open research question. To
tackle this challenge, we propose to apply a novel Reinforcement Learning (RL)
approach. Our solution, MARLIN, uses the Soft Actor-Critic algorithm to
maximize both entropy and return and models the learning process as an
infinite-horizon task. We trained MARLIN on a real network with varying
background traffic patterns to overcome the sim-to-real mismatch that
researchers have encountered when applying RL to CC. We evaluated our solution
on the task of file transfer and compared it to TCP Cubic. While further
research is required, results have shown that MARLIN can achieve comparable
results to TCP with little hyperparameter tuning, in a task significantly
different from its training setting. Therefore, we believe that our work
represents a promising first step toward building CC algorithms based on the
maximum entropy RL framework.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:27:20 GMT""}]","2023-02-03"
"2302.01302","Prabodh Katti Mr","Prabodh Katti, Nicolas Skatchkovsky, Osvaldo Simeone, Bipin Rajendran,
  Bashir M. Al-Hashimi","Bayesian Inference on Binary Spiking Networks Leveraging Nanoscale
  Device Stochasticity","Submitted and Accepted in ISCAS 2023",,,,"cs.NE cs.AR cs.ET cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayesian Neural Networks (BNNs) can overcome the problem of overconfidence
that plagues traditional frequentist deep neural networks, and are hence
considered to be a key enabler for reliable AI systems. However, conventional
hardware realizations of BNNs are resource intensive, requiring the
implementation of random number generators for synaptic sampling. Owing to
their inherent stochasticity during programming and read operations, nanoscale
memristive devices can be directly leveraged for sampling, without the need for
additional hardware resources. In this paper, we introduce a novel Phase Change
Memory (PCM)-based hardware implementation for BNNs with binary synapses. The
proposed architecture consists of separate weight and noise planes, in which
PCM cells are configured and operated to represent the nominal values of
weights and to generate the required noise for sampling, respectively. Using
experimentally observed PCM noise characteristics, for the exemplary Breast
Cancer Dataset classification problem, we obtain hardware accuracy and expected
calibration error matching that of an 8-bit fixed-point (FxP8) implementation,
with projected savings of over 9$\times$ in terms of core area transistor
count.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:27:31 GMT""}]","2023-02-03"
"2302.01303","Leo S\""unkel","Leo S\""unkel, Darya Martyniuk, Denny Mattern, Johannes Jung, Adrian
  Paschke","GA4QCO: Genetic Algorithm for Quantum Circuit Optimization",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The design of quantum circuits is often still done manually, for instance by
following certain patterns or rule of thumb. While this approach may work well
for some problems, it can be a tedious task and present quite the challenge in
other situations. Designing the architecture of a circuit for a simple
classification problem may be relatively straightforward task, however,
creating circuits for more complex problems or that are resilient to certain
known problems (e.g. barren plateaus, trainability, etc.) is a different issue.
Moreover, efficient state preparation or circuits with low depth are important
for virtually most algorithms. In attempts to automate the process of designing
circuits, different approaches have been suggested over the years, including
genetic algorithms and reinforcement learning. We propose our GA4QCO framework
that applies a genetic algorithm to automatically search for quantum circuits
that exhibit user-defined properties. With our framework, the user specifies
through a fitness function what type of circuit should be created, for instance
circuits that prepare a specific target state while keeping depth at a minimum
and maximizing fidelity. Our framework is designed in such a way that the user
can easily integrate a custom designed fitness function. In this paper, we
introduce our framework and run experiments to show the validity of the
approach.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:30:23 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 16:33:00 GMT""}]","2023-05-11"
"2302.01304","Matthew Skiles","Matthew J. Skiles, Joshua D. Rhodes, Michael E. Webber","Observations of peak electric load growth in ERCOT with the rise of
  electrified heating and its implications for future resource planning","28 pages, 10 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This analysis quantitatively compares the evolution in summer and winter peak
demands in the Electric Reliability Council of Texas (ERCOT) service area from
1997 through 2021. Weather data for the days in which peak demand occurred were
also compiled to investigate the relationship between peak heating and cooling
loads and ambient temperature. This relationship was then applied along with
population projections and a climate scenario with medium to high radiative
forcing to create winter and summer peak demand growth scenarios for 2025
through 2050. This analysis informs resource planners about how ERCOT peak
demand might change in the future and provides new insight into how electric
load growth and non-flexible electrified heating demand could have contributed
to the February 2021 ERCOT blackouts. We found that historically, summer peak
demand growth has been generally stable and approximately linear with time. The
stable summer peak load is likely a consequence of fairly constant temperatures
observed on summer peak demand days. Conversely, the winter peak demand growth
has been less consistent, varying much more around the broader trend. This
phenomenon is likely a consequence of high residential electrical heating load
on winter peak demand days, which saw temperatures that varied widely from the
mean value. Future peak winter and summer electricity demand scenarios
indicated that while average temperatures on winter peak demand days will
remain fairly constant, they will be more erratic than temperatures on summer
peak demand days. As a result, winter peak demand will remain more erratic and
will sporadically surpass summer peak demand between 2025 and 2050. Thus,
resource planners in ERCOT should place less certainty on winter peak demand
projections and an increased level of winter preparedness on both the supply
and demand sectors appears warranted.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:30:29 GMT""}]","2023-02-03"
"2302.01305","Teng Guo","Teng Guo, Jingjin Yu","Toward Efficient Physical and Algorithmic Design of Automated Garages","Accepted by ICRA 2023",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parking in large metropolitan areas is often a time-consuming task with
further implications toward traffic patterns that affect urban landscaping.
Reducing the premium space needed for parking has led to the development of
automated mechanical parking systems. Compared to regular garages having one or
two rows of vehicles in each island, automated garages can have multiple rows
of vehicles stacked together to support higher parking demands. Although this
multi-row layout reduces parking space, it makes the parking and retrieval more
complicated. In this work, we propose an automated garage design that supports
near 100% parking density. Modeling the problem of parking and retrieving
multiple vehicles as a special class of multi-robot path planning problem, we
propose associated algorithms for handling all common operations of the
automated garage, including (1) optimal algorithm and near-optimal methods that
find feasible and efficient solutions for simultaneous parking/retrieval and
(2) a novel shuffling mechanism to rearrange vehicles to facilitate scheduled
retrieval at rush hours. We conduct thorough simulation studies showing the
proposed methods are promising for large and high-density real-world parking
applications.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:31:41 GMT""}]","2023-02-03"
"2302.01306","Manouchehr Zaker","Abbas Khaleghi, Manouchehr Zaker","More results on the $z$-chromatic number of graphs","Submitted To Disc. Appl. Math. on September 8, 2022",,,,"math.CO cs.DM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  By a $z$-coloring of a graph $G$ we mean any proper vertex coloring
consisting of the color classes $C_1, \ldots, C_k$ such that $(i)$ for any two
colors $i$ and $j$ with $1 \leq i < j \leq k$, any vertex of color $j$ is
adjacent to a vertex of color $i$, $(ii)$ there exists a set $\{u_1, \ldots,
u_k\}$ of vertices of $G$ such that $u_j \in C_j$ for any $j \in \{1, \ldots,
k\}$ and $u_k$ is adjacent to $u_j$ for each $1 \leq j \leq k$ with $j \not=k$,
and $(iii)$ for each $i$ and $j$ with $i \not= j$, the vertex $u_j$ has a
neighbor in $C_i$. Denote by $z(G)$ the maximum number of colors used in any
$z$-coloring of $G$. Denote the Grundy and {\rm b}-chromatic number of $G$ by
$\Gamma(G)$ and ${\rm b}(G)$, respectively. The $z$-coloring is an improvement
over both the Grundy and b-coloring of graphs. We prove that $z(G)$ is much
better than $\min\{\Gamma(G), {\rm b}(G)\}$ for infinitely many graphs $G$ by
obtaining an infinite sequence $\{G_n\}_{n=3}^{\infty}$ of graphs such that
$z(G_n)=n$ but $\Gamma(G_n)={\rm b}(G_n)=2n-1$ for each $n\geq 3$. We show that
acyclic graphs are $z$-monotonic and $z$-continuous. Then it is proved that to
decide whether $z(G)=\Delta(G)+1$ is $NP$-complete even for bipartite graphs
$G$. We finally prove that to recognize graphs $G$ satisfying $z(G)=\chi(G)$ is
$coNP$-complete, improving a previous result for the Grundy number.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:32:01 GMT""}]","2023-02-03"
"2302.01307","Carrie Filion","Carrie Filion, Rachel L. McClure, Martin D. Weinberg, Elena D'Onghia,
  Kathryne J. Daniel","The Non-Axisymmetric Influence: Radius and Angle-Dependent Trends in a
  Barred Galaxy","10 pages, 6 figures. Submitted to MNRAS, comments welcome",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many disc galaxies host galactic bars, which exert time-dependent,
non-axisymmetric forces that can alter the orbits of stars. There should be
both angle and radius-dependence in the resulting radial re-arrangement of
stars ('radial mixing') due to a bar; we present here novel results and trends
through analysis of the joint impact of these factors. We use an N-body
simulation to investigate the changes in the radial locations of star particles
in a disc after a bar forms by quantifying the change in orbital radii in a
series of annuli at different times post bar-formation. We find that the bar
induces both azimuth angle- and radius-dependent trends in the median distance
that stars have travelled to enter a given annulus. Angle-dependent trends are
present at all radii we consider, and the radius-dependent trends roughly
divide the disc into three 'zones'. In the inner zone, stars generally
originated at larger radii and their orbits evolved inwards. Stars in the outer
zone likely originated at smaller radii and their orbits evolved outwards. In
the intermediate zone, there is no net inwards or outwards evolution of orbits.
We adopt a simple radius-dependent initial metallicity gradient and discuss
recent observational evidence for angle-dependent stellar metallicity
variations in the Milky Way in the context of this toy model. We briefly
comment on the possibility of using observed angle-dependent metallicity trends
to learn about the initial metallicity gradient(s) and the radial
re-arrangement that occurred in the disc.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:32:15 GMT""}]","2023-02-03"
"2302.01308","Raja Marjieh","Raja Marjieh, Ilia Sucholutsky, Pol van Rijn, Nori Jacoby, Thomas L.
  Griffiths","What Language Reveals about Perception: Distilling Psychophysical
  Knowledge from Large Language Models","7 pages, 5 figures",,,,"cs.CL cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Understanding the extent to which the perceptual world can be recovered from
language is a fundamental problem in cognitive science. We reformulate this
problem as that of distilling psychophysical information from text and show how
this can be done by combining large language models (LLMs) with a classic
psychophysical method based on similarity judgments. Specifically, we use the
prompt auto-completion functionality of GPT3, a state-of-the-art LLM, to elicit
similarity scores between stimuli and then apply multidimensional scaling to
uncover their underlying psychological space. We test our approach on six
perceptual domains and show that the elicited judgments strongly correlate with
human data and successfully recover well-known psychophysical structures such
as the color wheel and pitch spiral. We also explore meaningful divergences
between LLM and human representations. Our work showcases how combining
state-of-the-art machine models with well-known cognitive paradigms can shed
new light on fundamental questions in perception and language research.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:32:46 GMT""}]","2023-02-03"
"2302.01309","Pauli Kehayias","P. Kehayias, J. Walraven, A. L. Rodarte, A. M. Mounce","High-Resolution Short-Circuit Fault Localization in a Multi-Layer
  Integrated Circuit using a Quantum Diamond Microscope","9 pages main text (6 figures), 5 pages supplementary information (4
  figures)",,,,"physics.ins-det physics.app-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  As integrated circuit (IC) geometry and packaging become more sophisticated
with ongoing fabrication and design innovations, the electrical engineering
community needs increasingly-powerful failure analysis (FA) methods to meet the
growing troubleshooting challenges of multi-layer (with multiple metal layers)
and multi-chip components. In this work, we investigate a new electronics FA
method using a quantum diamond microscope (QDM) to image the magnetic fields
from short-circuit faults. After quantifying the performance by detecting
short-circuit faults in a multi-layer silicon die, we assess how a QDM would
detect faults in a heterogeneously integrated (HI) die stack. This work
establishes QDM-based magnetic imaging as a competitive technique for
electronics FA, offering high spatial resolution, high sensitivity, and robust
instrumentation. We anticipate these advantages to be especially useful for
finding faults deep within chip-stack ICs with many metal layers,
optically-opaque layers, or optically-scattering layers.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:33:02 GMT""}]","2023-02-03"
"2302.01310","Jack Buckingham","Jack M. Buckingham, Sebastian Rojas Gonzalez and Juergen Branke","Bayesian Optimization of Multiple Objectives with Different Latencies","25 pages",,,,"stat.ML cs.LG math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-objective Bayesian optimization aims to find the Pareto front of
optimal trade-offs between a set of expensive objectives while collecting as
few samples as possible. In some cases, it is possible to evaluate the
objectives separately, and a different latency or evaluation cost can be
associated with each objective. This presents an opportunity to learn the
Pareto front faster by evaluating the cheaper objectives more frequently. We
propose a scalarization based knowledge gradient acquisition function which
accounts for the different evaluation costs of the objectives. We prove
consistency of the algorithm and show empirically that it significantly
outperforms a benchmark algorithm which always evaluates both objectives.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:33:34 GMT""}]","2023-02-03"
"2302.01311","Zineb Hassainia","Zineb Hassainia, Taoufik Hmidi and Emeric Roulley","Invariant KAM tori around annular vortex patches for 2D Euler equations","107 pages",,,,"math.AP math.DS physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct time quasi-periodic vortex patch solutions with one hole for the
planar Euler equations. These structures are captured close to any annulus
provided that its modulus belongs to a massive Borel set. The proof is based on
Nash-Moser scheme and KAM theory applied with a Hamiltonian system governing
the radial deformations of the patch. Compared to the scalar case, some
technical issues emerge due to the interaction between the interfaces. One of
them is related to a new small divisor problem in the second order Melnikov
non-resonances condition coming from the transport equations advected with
different velocities.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:36:02 GMT""}]","2023-02-03"
"2302.01312","Lucas Berry","Lucas Berry and David Meger","Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty
  Modeling",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we demonstrate how to reliably estimate epistemic uncertainty
while maintaining the flexibility needed to capture complicated aleatoric
distributions. To this end, we propose an ensemble of Normalizing Flows (NF),
which are state-of-the-art in modeling aleatoric uncertainty. The ensembles are
created via sets of fixed dropout masks, making them less expensive than
creating separate NF models. We demonstrate how to leverage the unique
structure of NFs, base distributions, to estimate aleatoric uncertainty without
relying on samples, provide a comprehensive set of baselines, and derive
unbiased estimates for differential entropy. The methods were applied to a
variety of experiments, commonly used to benchmark aleatoric and epistemic
uncertainty estimation: 1D sinusoidal data, 2D windy grid-world ($\it{Wet
Chicken}$), $\it{Pendulum}$, and $\it{Hopper}$. In these experiments, we setup
an active learning framework and evaluate each model's capability at measuring
aleatoric and epistemic uncertainty. The results show the advantages of using
NF ensembles in capturing complicated aleatoric while maintaining accurate
epistemic uncertainty estimates.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:38:35 GMT""},{""version"":""v2"",""created"":""Mon, 1 May 2023 20:35:12 GMT""}]","2023-05-03"
"2302.01313","Jianfei Gao","Jianfei Gao, Yangze Zhou, Jincheng Zhou, Bruno Ribeiro","Inductive Link Prediction for Both New Nodes and New Relation Types via
  Double Equivariance",,,,,"cs.LG cs.AI cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Despite recent advances in relational learning, the task of inductive link
prediction in discrete attributed multigraphs with both new nodes and new
relation types in test remains an open problem. In this work we tackle this
task by defining the concept of double exchangeability and its associated
double-permutation equivariant graph neural network that are equivariant to
permutations of both node identities and edge relations. Our neural
architecture imposes a structural representation of relations that can
inductively generalize from training nodes and relations to arbitrarily new
test nodes and relations, without the need for adaptation or retraining, thus
enabling a new direction in relational learning. Finally, we introduce a
general blueprint for such double equivariant representations and empirically
showcase its capability on two proposed real-world benchmarks that no existing
works can perform accurately.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:39:30 GMT""},{""version"":""v2"",""created"":""Fri, 7 Apr 2023 20:09:20 GMT""},{""version"":""v3"",""created"":""Fri, 5 May 2023 18:23:05 GMT""},{""version"":""v4"",""created"":""Sat, 13 May 2023 02:13:16 GMT""},{""version"":""v5"",""created"":""Sun, 28 May 2023 22:50:23 GMT""}]","2023-05-30"
"2302.01314","Yasutada Oohama","Bagus Santoso and Yasutada Oohama","Universal Coding for Shannon Ciphers under Side-Channel Attacks","6 pages, 3 figures. previous version has some mistake on the problem
  set up and the order of the authors. We correct those mistakes in this
  version. The problem set up in this paper is the same as the one proposed by
  Santoso and Oohama (Entropy 2019) but is different from the one proposed by
  Oohama and Santoso (ISIT 2022, arXivarXiv:2201.11670). arXiv admin note:
  substantial text overlap with arXiv:1801.02563, arXiv:2201.11670,
  arXiv:1901.05940",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We study the universal coding under side-channel attacks posed and
investigated by Santoso and Oohama (2019). They proposed a theoretical security
model for Shannon cipher system under side-channel attacks, where the adversary
is not only allowed to collect ciphertexts by eavesdropping the public
communication channel, but is also allowed to collect the physical information
leaked by the devices where the cipher system is implemented on such as running
time, power consumption, electromagnetic radiation, etc. For any distributions
of the plain text, any noisy channels through which the adversary observe the
corrupted version of the key, and any measurement device used for collecting
the physical information, we can derive an achievable rate region for
reliability and security such that if we compress the ciphertext using an
affine encoder with rate within the achievable rate region, then: (1) anyone
with secret key will be able to decrypt and decode the ciphertext correctly,
but (2) any adversary who obtains the ciphertext and also the
  side physical information will not be able to obtain any information about
the hidden source as long as the leaked physical information is encoded with a
rate within the rate region.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:41:06 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 08:45:53 GMT""}]","2023-02-08"
"2302.01315","Eli Halperin","Eli J. Halperin, Shai Ronen, and J. L. Bohn","Frustration in a dipolar Bose-Einstein condensate introduced by an
  optical lattice",,"Phys. Rev. A 107, L041301 (2023)","10.1103/PhysRevA.107.L041301",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the application of a square perturbing lattice to the naturally
forming hexagonal arrays of dipolar droplets in a dipolar Bose-Einstein
condensate. We find that the application of the lattice causes spontaneous
pattern formation and leads to frustration in some regimes. For certain
parameters, the ground state has neither the symmetry of the intrinsic
hexagonal supersolid nor the symmetry of the square lattice. These results may
give another axis on which to explore dipolar Bose-Einstein condensates and to
probe the nature of supersolidity.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:41:42 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 15:39:06 GMT""}]","2023-04-26"
"2302.01316","Jinhao Duan","Jinhao Duan, Fei Kong, Shiqi Wang, Xiaoshuang Shi, Kaidi Xu","Are Diffusion Models Vulnerable to Membership Inference Attacks?","To appear in ICML 2023",,,,"cs.CV cs.AI cs.CR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Diffusion-based generative models have shown great potential for image
synthesis, but there is a lack of research on the security and privacy risks
they may pose. In this paper, we investigate the vulnerability of diffusion
models to Membership Inference Attacks (MIAs), a common privacy concern. Our
results indicate that existing MIAs designed for GANs or VAE are largely
ineffective on diffusion models, either due to inapplicable scenarios (e.g.,
requiring the discriminator of GANs) or inappropriate assumptions (e.g., closer
distances between synthetic samples and member samples). To address this gap,
we propose Step-wise Error Comparing Membership Inference (SecMI), a
query-based MIA that infers memberships by assessing the matching of forward
process posterior estimation at each timestep. SecMI follows the common
overfitting assumption in MIA where member samples normally have smaller
estimation errors, compared with hold-out samples. We consider both the
standard diffusion models, e.g., DDPM, and the text-to-image diffusion models,
e.g., Latent Diffusion Models and Stable Diffusion. Experimental results
demonstrate that our methods precisely infer the membership with high
confidence on both of the two scenarios across multiple different datasets.
Code is available at https://github.com/jinhaoduan/SecMI.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:43:16 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 02:42:23 GMT""}]","2023-05-31"
"2302.01317","Peter Elmer","Brian Bockelman, Peter Elmer, Gordon Watts","IRIS-HEP Strategic Plan for the Next Phase of Software Upgrades for
  HL-LHC Physics",,,,,"hep-ex physics.acc-ph physics.comp-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The quest to understand the fundamental building blocks of nature and their
interactions is one of the oldest and most ambitious of human scientific
endeavors. CERN's Large Hadron Collider (LHC) represents a huge step forward in
this quest. The discovery of the Higgs boson, the observation of exceedingly
rare decays of $B$ mesons, and stringent constraints on many viable theories of
physics beyond the Standard Model (SM) demonstrate the great scientific value
of the LHC physics program. The next phase of this global scientific project
will be the High-Luminosity LHC (HL-LHC) which will collect data starting circa
2029 and continue through the 2030s. The primary science goal is to search for
physics beyond the SM and, should it be discovered, to study its implications.
In the HL-LHC era, the ATLAS and CMS experiments will record around 100 times
as many collisions as were used to discover the Higgs boson (and at twice the
energy). Both NSF and DOE are making large detector upgrade investments so the
HL-LHC can operate in this high-rate environment. Similar investment in
software R&D for acquiring, managing, processing and analyzing HL-LHC data is
critical to maximize the return-on-investment in the upgraded accelerator and
detectors. This report presents a strategic plan for a possible second 5-year
funded phase (2023 through 2028) for the Institute for Research and Innovation
in Software for High Energy Physics (IRIS-HEP) which will close remaining
software and computing gaps to deliver HL-LHC science.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:44:00 GMT""}]","2023-02-03"
"2302.01318","Charlie Chen","Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste
  Lespiau, Laurent Sifre, John Jumper","Accelerating Large Language Model Decoding with Speculative Sampling",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We present speculative sampling, an algorithm for accelerating transformer
decoding by enabling the generation of multiple tokens from each transformer
call. Our algorithm relies on the observation that the latency of parallel
scoring of short continuations, generated by a faster but less powerful draft
model, is comparable to that of sampling a single token from the larger target
model. This is combined with a novel modified rejection sampling scheme which
preserves the distribution of the target model within hardware numerics. We
benchmark speculative sampling with Chinchilla, a 70 billion parameter language
model, achieving a 2-2.5x decoding speedup in a distributed setup, without
compromising the sample quality or making modifications to the model itself.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:44:11 GMT""}]","2023-02-03"
"2302.01319","Salvatore Scamperti Mr","Rapha\""el Carroy, Luca Motto Ros, Salvatore Scamperti","A classification of the Wadge hierarchies on zero-dimensional Polish
  spaces","Correction of some references and typos",,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  We provide a complete classification, up to order-isomorphism, of all
possible Wadge hierarchies on zero-dimensional Polish spaces using
(essentially) countable ordinals as complete invariants. We also observe that
although our assignment of invariants is very simple and there are only
$\aleph_1$-many equivalence classes, the above classification problem is quite
complex from the descriptive set-theoretic point of view: in particular, there
is no Borel procedure to determine whether two zero-dimensional Polish spaces
have isomorphic Wadge hierarchies. All results are based on a complete and
explicit description of the Wadge hierarchy on an arbitrary zero-dimensional
Polish space, depending on its topological properties.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:45:30 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 12:07:06 GMT""}]","2023-05-17"
"2302.01320","Andrea Merlo","Gianmarco Caldini and Andrea Marchese and Andrea Merlo and Simone
  Steinbr\""uchel","Generic uniqueness for the Plateau problem","Minor changes",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a complete Riemannian manifold $\mathcal{M}\subset\mathbb{R}^d$ which
is a Lipschitz neighbourhood retract of dimension $m+n$, of class $C^{h,\beta}$
and an oriented, closed submanifold $\Gamma \subset \mathcal M$ of dimension
$m-1$, which is a boundary in integral homology, we construct a complete metric
space $\mathcal{B}$ of $C^{h,\alpha}$-perturbations of $\Gamma$ inside
$\mathcal{M}$, with $\alpha<\beta$, enjoying the following property. For the
typical element $b\in\mathcal B$, in the sense of Baire categories, there
exists a unique $m$-dimensional integral current in $\mathcal{M}$ which solves
the corresponding Plateau problem and it has multiplicity one.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:47:52 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 23:12:02 GMT""}]","2023-02-23"
"2302.01321","Wenlong Zhang","W. L. Zhang, T. Grismayer, L. O. Silva","Signatures for strong-field QED physics in the quantum limit of
  beamstrahlung","With a Supplemental Material; Submitted",,,,"physics.plasm-ph hep-ex hep-th physics.acc-ph physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Collisions between round ultrarelativistic leptonic beams are proposed to
probe strong-field quantum electrodynamics (SF-QED) in the quantum limit of
beamstrahlung. The collective radiation spectrum from a leptonic collision is
derived. A characteristic spectral peak close to the beam energy is identified,
as a signature predicted by SF-QED theory. The dependences of the spectral peak
and beamstrahlung on the collision parameters are determined, paving the way to
experimentally verify SF-QED. Ultrashort, ultrabright, and high-luminosity
colliding gamma-ray beams are generated. The theoretical results are confirmed
by self-consistent 3-dimensional QED particle-in-cell simulations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:50:21 GMT""},{""version"":""v2"",""created"":""Sun, 5 Feb 2023 15:49:39 GMT""}]","2023-02-07"
"2302.01322","Vanja Mari\'c","Vanja Mari\'c and Maurizio Fagotti","Universality in the tripartite information after global quenches:
  (generalised) quantum XY models",,,,,"cond-mat.stat-mech hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  We consider the R\'enyi-$\alpha$ tripartite information $I_3^{(\alpha)}$ of
three adjacent subsystems in the stationary state emerging after global
quenches in noninteracting spin chains from both homogeneous and bipartite
states. We identify settings in which $I_3^{(\alpha)}$ remains nonzero also in
the limit of infinite lengths and develop a field theory description. We map
the calculation into a Riemann-Hilbert problem with a piecewise constant matrix
for a doubly connected domain. We find an explicit solution for $\alpha=2$ and
an implicit one for $\alpha>2$. In the latter case, we develop a rapidly
convergent perturbation theory that we use to derive analytic formulae
approximating $I_3^{(\alpha)}$ with outstanding accuracy.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:50:42 GMT""}]","2023-02-03"
"2302.01323","Lucas Koerner","Lucas J. Koerner","The impact of frame quantization on the dynamic range of a one-bit image
  sensor",,,,,"physics.ins-det eess.IV","http://creativecommons.org/licenses/by/4.0/","  For a one-bit image sensor, the number of frames captured determines the
quantization step size of the binary rate measurement. The discrete values of
the binary rate set a maximum measurable intensity. In this note, we consider
how this frame quantization impacts the high-end of the dynamic range of a
one-bit image sensor.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:51:28 GMT""}]","2023-02-03"
"2302.01324","Fares Fourati","Fares Fourati, Vaneet Aggarwal, Christopher John Quinn, Mohamed-Slim
  Alouini","Randomized Greedy Learning for Non-monotone Stochastic Submodular
  Maximization Under Full-bandit Feedback",,,,,"cs.LG cs.AI math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the problem of unconstrained combinatorial multi-armed bandits
with full-bandit feedback and stochastic rewards for submodular maximization.
Previous works investigate the same problem assuming a submodular and monotone
reward function. In this work, we study a more general problem, i.e., when the
reward function is not necessarily monotone, and the submodularity is assumed
only in expectation. We propose Randomized Greedy Learning (RGL) algorithm and
theoretically prove that it achieves a $\frac{1}{2}$-regret upper bound of
$\tilde{\mathcal{O}}(n T^{\frac{2}{3}})$ for horizon $T$ and number of arms
$n$. We also show in experiments that RGL empirically outperforms other
full-bandit variants in submodular and non-submodular settings.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:52:14 GMT""}]","2023-02-03"
"2302.01325","Shubhayan Sarkar","Shubhayan Sarkar","Certification of entangled quantum states and quantum measurements in
  Hilbert spaces of arbitrary dimension","Doctoral thesis accepted at CFT PAN based on four papers (i) npj
  Quantum Information, 7, 151 (2021) (ii) Phys. Rev. A, 105, 032416 (2022)
  (iii) Phys. Rev. A, 106, L040402(2022) (iv) arXiv:2110.15176(2021)",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The emergence of quantum theory at the beginning of 20$-th$ century has
changed our view of the microscopic world and has led to applications such as
quantum teleportation, quantum random number generation and quantum computation
to name a few, that could never have been realised using classical systems. One
such application that has attracted considerable attention lately is
device-independent (DI) certification of composite quantum systems. The basic
idea behind it is to treat a given device as a black box that given some input
generates an output, and then to verify whether it works as expected by only
studying the statistics generated by this device. The novelty of these
certification schemes lies in the fact that one can almost completely
characterise the device (up to certain equivalences) under minimal physically
well-motivated assumptions such as that the device is described using quantum
theory. The resource required in most of these certification schemes is quantum
non-locality. In this thesis, we construct schemes to device-independently
certify quantum states and quantum measurements in Hilbert spaces of arbitrary
dimension along with the optimal amount randomness that one can extract from
any quantum system of arbitrary dimension.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:54:51 GMT""}]","2023-02-03"
"2302.01326","Yahya H. Ezzeldin","Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Shanshan Han, Shantanu
  Sharma, Chaoyang He, Sharad Mehrotra and Salman Avestimehr","Federated Analytics: A survey","To appear in APSIPA Transactions on Signal and Information
  Processing, Volume 12, Issue 1","APSIPA Transactions on Signal and Information Processing, Volume
  12, Issue 1, 2023",,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  Federated analytics (FA) is a privacy-preserving framework for computing data
analytics over multiple remote parties (e.g., mobile devices) or silo-ed
institutional entities (e.g., hospitals, banks) without sharing the data among
parties. Motivated by the practical use cases of federated analytics, we follow
a systematic discussion on federated analytics in this article. In particular,
we discuss the unique characteristics of federated analytics and how it differs
from federated learning. We also explore a wide range of FA queries and discuss
various existing solutions and potential use case applications for different FA
queries.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:56:24 GMT""}]","2023-02-03"
"2302.01327","Manoj Kumar","Manoj Kumar, Mostafa Dehghani, Neil Houlsby","Dual PatchNorm","TMLR 2023 (https://openreview.net/forum?id=jgMqve6Qhw)",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  We propose Dual PatchNorm: two Layer Normalization layers (LayerNorms),
before and after the patch embedding layer in Vision Transformers. We
demonstrate that Dual PatchNorm outperforms the result of exhaustive search for
alternative LayerNorm placement strategies in the Transformer block itself. In
our experiments, incorporating this trivial modification, often leads to
improved accuracy over well-tuned Vision Transformers and never hurts.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:56:25 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 09:53:56 GMT""},{""version"":""v3"",""created"":""Mon, 8 May 2023 16:06:13 GMT""}]","2023-05-09"
"2302.01328","David Chan","David M. Chan, Austin Myers, Sudheendra Vijayanarasimhan, David A.
  Ross, John Canny","$IC^3$: Image Captioning by Committee Consensus",,,,,"cs.CV cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  If you ask a human to describe an image, they might do so in a thousand
different ways. Traditionally, image captioning models are trained to
approximate the reference distribution of image captions, however, doing so
encourages captions that are viewpoint-impoverished. Such captions often focus
on only a subset of the possible details, while ignoring potentially useful
information in the scene. In this work, we introduce a simple, yet novel,
method: ""Image Captioning by Committee Consensus"" ($IC^3$), designed to
generate a single caption that captures high-level details from several
viewpoints. Notably, humans rate captions produced by $IC^3$ at least as
helpful as baseline SOTA models more than two thirds of the time, and $IC^3$
captions can improve the performance of SOTA automated recall systems by up to
84%, indicating significant material improvements over existing SOTA approaches
for visual description. Our code is publicly available at
https://github.com/DavidMChan/caption-by-committee
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:58:05 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 23:38:25 GMT""}]","2023-02-20"
"2302.01329","Eliahu Horwitz","Eyal Molad, Eliahu Horwitz, Dani Valevski, Alex Rav Acha, Yossi
  Matias, Yael Pritch, Yaniv Leviathan, Yedid Hoshen","Dreamix: Video Diffusion Models are General Video Editors",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-driven image and video diffusion models have recently achieved
unprecedented generation realism. While diffusion models have been successfully
applied for image editing, very few works have done so for video editing. We
present the first diffusion-based method that is able to perform text-based
motion and appearance editing of general videos. Our approach uses a video
diffusion model to combine, at inference time, the low-resolution
spatio-temporal information from the original video with new, high resolution
information that it synthesized to align with the guiding text prompt. As
obtaining high-fidelity to the original video requires retaining some of its
high-resolution information, we add a preliminary stage of finetuning the model
on the original video, significantly boosting fidelity. We propose to improve
motion editability by a new, mixed objective that jointly finetunes with full
temporal attention and with temporal attention masking. We further introduce a
new framework for image animation. We first transform the image into a coarse
video by simple image processing operations such as replication and perspective
geometric projections, and then use our general video editor to animate it. As
a further application, we can use our method for subject-driven video
generation. Extensive qualitative and numerical experiments showcase the
remarkable editing ability of our method and establish its superior performance
compared to baseline methods.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:58:58 GMT""}]","2023-02-03"
"2302.01330","Zhaoxi Chen","Zhaoxi Chen, Guangcong Wang, Ziwei Liu","SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections","Project Page https://scene-dreamer.github.io/ Code
  https://github.com/FrozenBurning/SceneDreamer",,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present SceneDreamer, an unconditional generative model for
unbounded 3D scenes, which synthesizes large-scale 3D landscapes from random
noise. Our framework is learned from in-the-wild 2D image collections only,
without any 3D annotations. At the core of SceneDreamer is a principled
learning paradigm comprising 1) an efficient yet expressive 3D scene
representation, 2) a generative scene parameterization, and 3) an effective
renderer that can leverage the knowledge from 2D images. Our approach begins
with an efficient bird's-eye-view (BEV) representation generated from simplex
noise, which includes a height field for surface elevation and a semantic field
for detailed scene semantics. This BEV scene representation enables 1)
representing a 3D scene with quadratic complexity, 2) disentangled geometry and
semantics, and 3) efficient training. Moreover, we propose a novel generative
neural hash grid to parameterize the latent space based on 3D positions and
scene semantics, aiming to encode generalizable features across various scenes.
Lastly, a neural volumetric renderer, learned from 2D image collections through
adversarial training, is employed to produce photorealistic images. Extensive
experiments demonstrate the effectiveness of SceneDreamer and superiority over
state-of-the-art methods in generating vivid yet diverse unbounded 3D worlds.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:59:16 GMT""},{""version"":""v2"",""created"":""Wed, 19 Apr 2023 08:45:36 GMT""}]","2023-04-20"
"2302.01331","Nhat-Minh Nguyen","Nhat-Minh Nguyen, Dragan Huterer and Yuewei Wen","Evidence for suppression of structure growth in the concordance
  cosmological model","5 pages + references; 5 figures, 2 tables, 2900 words. Comments
  welcome!",,,,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present evidence for a suppressed growth rate of large-scale structure
during the dark-energy dominated era. Modeling the growth rate of perturbations
with the ``growth index'' $\gamma$, we find that current cosmological data
strongly prefer a higher growth index than the value $\gamma=0.55$ predicted by
general relativity in a flat $\Lambda$CDM cosmology. Both the cosmic microwave
background data from Planck and the large-scale structure data from weak
lensing, galaxy clustering, and cosmic velocities separately favor growth
suppression. When combined, they yield $\gamma=0.633^{+0.025}_{-0.024}$,
excluding $\gamma=0.55$ at a statistical significance of 3.7$\sigma$. The
combination of $f\sigma_8$ and Planck measurements prefers an even higher
growth index of $\gamma=0.639^{+0.024}_{-0.025}$, corresponding to a
4.2$\sigma$-tension with the concordance model. In Planck data, the suppressed
growth rate offsets the preference for nonzero curvature and fits the data
equally well as the latter model. A higher $\gamma$ leads to a higher matter
fluctuation amplitude $S_8$ inferred from galaxy clustering and weak lensing
measurements, and a lower $S_8$ from Planck data, effectively resolving the
$S_8$ tension.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:59:19 GMT""}]","2023-02-03"
"2302.01332","Marco Miani","Frederik Warburg, Marco Miani, Silas Brack, Soren Hauberg","Bayesian Metric Learning for Uncertainty Quantification in Image
  Retrieval","Code: https://github.com/FrederikWarburg/bayesian-metric-learning",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  We propose the first Bayesian encoder for metric learning. Rather than
relying on neural amortization as done in prior works, we learn a distribution
over the network weights with the Laplace Approximation. We actualize this by
first proving that the contrastive loss is a valid log-posterior. We then
propose three methods that ensure a positive definite Hessian. Lastly, we
present a novel decomposition of the Generalized Gauss-Newton approximation.
Empirically, we show that our Laplacian Metric Learner (LAM) estimates
well-calibrated uncertainties, reliably detects out-of-distribution examples,
and yields state-of-the-art predictive performance.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:59:23 GMT""},{""version"":""v2"",""created"":""Sat, 4 Feb 2023 14:11:00 GMT""}]","2023-02-07"
"2302.01333","Yu Bai","Fan Chen, Huan Wang, Caiming Xiong, Song Mei, Yu Bai","Lower Bounds for Learning in Revealing POMDPs",,,,,"cs.LG cs.IT math.IT math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies the fundamental limits of reinforcement learning (RL) in
the challenging \emph{partially observable} setting. While it is
well-established that learning in Partially Observable Markov Decision
Processes (POMDPs) requires exponentially many samples in the worst case, a
surge of recent work shows that polynomial sample complexities are achievable
under the \emph{revealing condition} -- A natural condition that requires the
observables to reveal some information about the unobserved latent states.
However, the fundamental limits for learning in revealing POMDPs are much less
understood, with existing lower bounds being rather preliminary and having
substantial gaps from the current best upper bounds.
  We establish strong PAC and regret lower bounds for learning in revealing
POMDPs. Our lower bounds scale polynomially in all relevant problem parameters
in a multiplicative fashion, and achieve significantly smaller gaps against the
current best upper bounds, providing a solid starting point for future studies.
In particular, for \emph{multi-step} revealing POMDPs, we show that (1) the
latent state-space dependence is at least $\Omega(S^{1.5})$ in the PAC sample
complexity, which is notably harder than the $\widetilde{\Theta}(S)$ scaling
for fully-observable MDPs; (2) Any polynomial sublinear regret is at least
$\Omega(T^{2/3})$, suggesting its fundamental difference from the
\emph{single-step} case where $\widetilde{O}(\sqrt{T})$ regret is achievable.
Technically, our hard instance construction adapts techniques in
\emph{distribution testing}, which is new to the RL literature and may be of
independent interest.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:59:30 GMT""}]","2023-02-03"
"2302.01334","Yupeng Zheng","Yupeng Zheng, Chengliang Zhong, Pengfei Li, Huan-ang Gao, Yuhang
  Zheng, Bu Jin, Ling Wang, Hao Zhao, Guyue Zhou, Qichao Zhang and Dongbin Zhao","STEPS: Joint Self-supervised Nighttime Image Enhancement and Depth
  Estimation","Accepted by ICRA 2023, Code: https://github.com/ucaszyp/STEPS",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised depth estimation draws a lot of attention recently as it can
promote the 3D sensing capabilities of self-driving vehicles. However, it
intrinsically relies upon the photometric consistency assumption, which hardly
holds during nighttime. Although various supervised nighttime image enhancement
methods have been proposed, their generalization performance in challenging
driving scenarios is not satisfactory. To this end, we propose the first method
that jointly learns a nighttime image enhancer and a depth estimator, without
using ground truth for either task. Our method tightly entangles two
self-supervised tasks using a newly proposed uncertain pixel masking strategy.
This strategy originates from the observation that nighttime images not only
suffer from underexposed regions but also from overexposed regions. By fitting
a bridge-shaped curve to the illumination map distribution, both regions are
suppressed and two tasks are bridged naturally. We benchmark the method on two
established datasets: nuScenes and RobotCar and demonstrate state-of-the-art
performance on both of them. Detailed ablations also reveal the mechanism of
our proposal. Last but not least, to mitigate the problem of sparse ground
truth of existing datasets, we provide a new photo-realistically enhanced
nighttime dataset based upon CARLA. It brings meaningful new challenges to the
community. Codes, data, and models are available at
https://github.com/ucaszyp/STEPS.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:59:47 GMT""}]","2023-02-03"
"2302.01335","Christopher Manser","Christopher J. Manser, Boris T. G\""ansicke, Keith Inight, Akshay
  Robert, S. Ahlen, C. Allende Prieto, D. Brooks, A.P. Cooper, A. de la
  Macorra, A. Font-Ribera, K. Honscheid, T. Kisner, M. Landriau, Aaron M.
  Meisner, R. Miquel, Jundan Nie, C. Poppett, Gregory Tarl\'e, Zhimin Zhou","DAHe white dwarfs from the DESI survey","19 pages, 10 Figures, accepted for publication in MNRAS",,"10.1093/mnras/stad727",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A new class of white dwarfs, dubbed DAHe, that present Zeeman-split Balmer
lines in emission has recently emerged. However, the physical origin of these
emission lines remains unclear. We present here a sample of 21 newly identified
DAHe systems and determine magnetic field strengths and (for a subset) periods
which span the ranges of ~ 6.5 -- 147 MG and ~ 0.4 -- 36 h respectively. All
but four of these systems were identified from the Dark Energy Spectroscopic
Instrument (DESI) survey sample of more than 47000 white dwarf candidates
observed during its first year of observations. We present detailed analysis of
the new DAHe WDJ161634.36+541011.51 with a spin period of 95.3 min, which
exhibits an anti-correlation between broadband flux and Balmer line strength
that is typically observed for this class of systems. All DAHe systems cluster
closely on the Gaia Hertzsprung-Russell diagram where they represent ~ 1 per
cent of white dwarfs within that region. This grouping further solidifies their
unexplained emergence at relatively late cooling times and we discuss this in
context of current formation theories. Nine of the new DAHe systems are
identifiable from SDSS spectra of white dwarfs that had been previously
classified as featureless DC-type systems. We suggest high S/N, unbiased
observations of DCs as a possible route for discovering additional DAHe
systems.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 18:59:59 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 20:42:47 GMT""}]","2023-03-29"
"2302.01343","Aaron Goldberg","Aaron Z. Goldberg, Guillaume S. Thekkadath, and Khabat Heshami","Measuring the quadrature coherence scale on a cloud quantum computer","11 pages including 4 figures and 1 appendix; close to published
  version","Phys. Rev. A 107, 042610 (2023)","10.1103/PhysRevA.107.042610",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Coherence underlies quantum phenomena, yet it is manifest in classical
theories; delineating coherence's role is a fickle business. The quadrature
coherence scale (QCS) was invented to remove such ambiguity, quantifying
quantum features of any single-mode bosonic system without choosing a preferred
orientation of phase space. The QCS is defined for any state, reducing to
well-known quantities in appropriate limits, including Gaussian and pure
states, and perhaps most importantly for a coherence measure, it is highly
sensitive to decoherence. Until recently, it was unknown how to measure the
QCS; we here report on an initial measurement of the QCS for squeezed light and
thermal states of light. This is performed using Xanadu's machine Borealis,
accessed through the cloud, which offers the configurable beam splitters and
photon-number-resolving detectors essential for measuring the QCS. The data and
theory match well, certifying the usefulness of interferometers and
photon-counting devices in certifying quantumness.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 14:03:20 GMT""}]","2023-04-19"
"2302.01344","Taylor Murphy","Linda M. Carpenter, Taylor Murphy, Matthew J. Smylie","LEX-EFT: The light exotics effective field theory","33 pages, 8 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the creation of a Light Exotics Effective Field Theory (LEX-EFT)
catalog. LEX-EFT is a generic framework to capture all interactions between the
Standard Model (SM) and all (or at least a large class of) theoretically
allowed exotic states beyond the Standard Model (bSM), indexed by their SM and
bSM charges. These states are light enough to be on or nearly on shell in some
collider processes. This framework, which subsumes beyond the Standard Model
paradigms as generally as possible, is meant to extend recent successful
implementations of bSM EFTs and complement e.g. the Standard Model Effective
Field Theory (SMEFT), which can capture the off-shell effects of exotic fields.
In this work, we review a general method for the construction of a complete
list of gauge-invariant operators involving SM interactions with light exotics
via iterative tensor product decomposition, up to the desired order in mass
dimension. Each operator is characterized by specific Clebsch-Gordan
coefficients determined by the charge flow; we show how this charge flow
affects the range of EFT validity and cross sections associated with an
effective operator. We create an example catalog of exotic scalars coupling to
SM gauge boson pairs, and we highlight some operators with exotic weak
$\mathrm{SU}(2)_{\text{L}}$ charges that can produce spectacular LHC
phenomenology. We further demonstrate the utility of the LEX-EFT approach with
several examples of effects on kinematic distributions and cross sections that
would not be captured by EFTs agnostic to the exotic degrees of freedom and may
evade the main inclusive collider searches tailored to the existing preferred
set of standard bSM theories.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:00 GMT""}]","2023-02-06"
"2302.01345","Mitchell Revalski","Mitchell Revalski, Marc Rafelski, Michele Fumagalli, Matteo Fossati,
  Norbert Pirzkal, Ben Sunnquist, Laura J. Prichard, Alaina Henry, Micaela
  Bagley, Rajeshwari Dutta, Giulia Papini, Fabrizio Arrigoni Battaia, Valentina
  D'Odorico, Pratika Dayal, Vicente Estrada-Carpenter, Emma K. Lofthouse,
  Elisabeta Lusso, Simon L. Morris, Kalina V. Nedkova, Casey Papovich, Celine
  Peroux","The MUSE Ultra Deep Field (MUDF). III. Hubble Space Telescope WFC3 Grism
  Spectroscopy and Imaging","Accepted for publication in ApJS on February 1, 2023. The paper has
  25 pages, 13 figures, and 7 tables. Version two includes minor corrections to
  match the journal publication. The calibrated data are available through MAST
  at: https://archive.stsci.edu/hlsp/mudf",,"10.3847/1538-4365/acb8ae",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present extremely deep Hubble Space Telescope (HST) Wide Field Camera 3
(WFC3) observations of the MUSE Ultra Deep Field (MUDF). This unique region of
the sky contains two quasars at $z \approx$ 3.22 that are separated by only
$\sim$500 kpc, providing a stereoscopic view of gas and galaxies in emission
and absorption across $\sim$10 billion years of cosmic time. We have obtained
90 orbits of HST WFC3 G141 near-infrared grism spectroscopy of this field in a
single pointing, as well as 142 hours of optical spectroscopy with the Very
Large Telescope (VLT) Multi Unit Spectroscopic Explorer (MUSE). The WFC3
(F140W, F125W, and F336W) and archival WFPC2 (F702W and F450W) imaging provides
five-filter photometry that we use to detect 3,375 sources between $z \approx$
0 - 6, including 1,536 objects in a deep central pointing with both
spectroscopic and photometric coverage. The F140W and F336W mosaics reach
exceptional depths of $m_\mathrm{AB}\approx$ 28 and 29, respectively, providing
near-infrared and rest-frame ultraviolet information for 1,580 sources, and we
reach 5$\sigma$ continuum detections for objects as faint as
$m_\mathrm{AB}\approx$ 27 in the grism spectra. The extensive wavelength
coverage of MUSE and WFC3 allows us to measure spectroscopic redshifts for 419
sources, down to galaxy stellar masses of log(M/M$_{\odot}$) $\approx$ 7 at $z
\approx$ 1 - 2. In this publication, we provide the calibrated HST data and
source catalogs as High Level Science Products for use by the community, which
includes photometry, morphology, and redshift measurements that enable a
variety of studies aimed at advancing our models of galaxy formation and
evolution in different environments.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 18:00:00 GMT""}]","2023-03-20"
"2302.01346","Ismael Mendoza","Ismael Mendoza, Philip Mansfield, Kuan Wang, Camille Avestruz","MultiCAM: A multivariable framework for connecting the mass accretion
  history of haloes with their properties","16 pages, 7 + 1 figures, comments welcome, to be submitted to MNRAS",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Models that connect galaxy and halo properties often summarize a halo's mass
accretion history (MAH) with a single value, and use this value as the basis
for predictions. However, a single-value summary fails to capture the
complexity of MAHs and information can be lost in the process. We present
MultiCAM, a generalization of traditional abundance matching frameworks, which
can simultaneously connect the full MAH of a halo with multiple halo and/or
galaxy properties. As a first case study, we apply MultiCAM to the problem of
connecting dark matter halo properties to their MAHs in the context of a dark
matter-only simulation. While some halo properties, such as concentration, are
more strongly correlated to the early-time mass growth of a halo, others, like
the virial ratio, have stronger correlations with late-time mass growth. This
highlights the necessity of considering the impact of the entire MAH on halo
properties. For most of the halo properties we consider, we find that MultiCAM
models that use the full MAH achieve higher accuracy than conditional abundance
matching models which use a single epoch. We also demonstrate an extension of
MultiCAM that captures the covariance between predicted halo properties. This
extension provides a baseline model for applications where the covariance
between predicted properties is important.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:00 GMT""}]","2023-02-06"
"2302.01347","Erik S{\o}rensen","Erik S. S{\o}rensen, Jonathon Riddell, Hae-Young Kee","Islands of Chiral Solitons in Integer Spin Kitaev Chains","17 pages, 13 figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An intriguing chiral soliton phase has recently been identified in the
$S$=1/2 Kitaev spin chain. Here we show that for $S$=1,2,3,4,5 an analogous
phase can be identified, but contrary to the $S$=1/2 case the chiral soliton
phases appear as islands within the sea of the polarized phase. In fact, a
small field applied in a general direction will adiabatically connect the
integer spin Kitaev chain to the polarized phase. Only at sizable intermediate
fields along symmetry directions does the soliton phase appear centered around
the special point $h^\star_x$=$h^\star_y$=$S$ where two exact product
ground-states can be identified. The large $S$ limit can be understood from a
semi-classical analysis, and variational calculations provide a detailed
picture of the $S$=1 soliton phase. Under open boundary conditions, the chain
has a single soliton in the ground-state which can be excited, leading to a
proliferation of in-gap states. In contrast, even length periodic chains
exhibit a gap above a twice degenerate ground-state. The presence of solitons
leaves a distinct imprint on the low temperature specific heat.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:01 GMT""}]","2023-02-06"
"2302.01348","Silvia Martocchia","Silvia Martocchia, Nate Bastian, Sara Saracino, Sebastian Kamann","On the origin of UV-dim stars: a population of rapidly rotating shell
  stars?","9 pages, 6 Figures. Accepted for publication in MNRAS",,"10.1093/mnras/stad403",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The importance of stellar rotation in setting the observed properties of
young star clusters has become clearer over the past decade, with rotation
being identified as the main cause of the observed extended main sequence
turn-off (eMSTO) phenomenon and split main-sequences. Additionally, young star
clusters are observed to host large fractions of rapidly rotating Be stars,
many of which are seen nearly equator-on through decretion disks that cause
self-extinction (the so called ""shell stars""). Recently, a new phenomenon has
been reported in the $\sim1.5$ Gyr star cluster NGC 1783, where a fraction of
the main sequence turn-off stars appears abnormally dim in the UV. We
investigate the origin of these ""UV-dim"" stars by comparing the UV
colour-magnitude diagrams of NGC 1850 ($\sim100$ Myr), NGC 1783 ($\sim1.5$
Gyr), NGC 1978 ($\sim2$ Gyr) and NGC 2121 ($\sim2.5$ Gyr), massive star
clusters in the Large Magellanic Cloud. While the younger clusters show a
non-negligible fraction of UV-dim stars, we find a significant drop of such
stars in the two older clusters. This is remarkable as clusters older than
$\sim$2 Gyr do not have an eMSTO, thus a large populations of rapidly rotating
stars, because their main sequence turn-off stars are low enough in mass to
slow down due to magnetic braking. We conclude that the UV-dim stars are likely
rapidly rotating stars with decretion disks seen nearly equator-on (i.e., are
shell stars) and discuss future observations that can confirm or refute our
hypothesis.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:01 GMT""}]","2023-02-15"
"2302.01349","Nikolay Britavskiy","N. Britavskiy, S. Sim\'on-D\'iaz, G. Holgado, S. Burssens, J. Ma\'iz
  Apell\'aniz, J.J. Eldridge, Y. Naz\'e, M. Pantaleoni Gonz\'alez, A. Herrero","The IACOB project VIII. Searching for empirical signatures of binarity
  in fast-rotating O-type stars","33 pages, 16 figures, accepted for publication in ""Astronomy and
  Astrophysics""","A&A 672, A22 (2023)","10.1051/0004-6361/202245145",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The empirical distribution of projected rotational velocities (vsini) in
massive O-type stars is characterized by a dominant slow velocity component and
a tail of fast rotators. Binary interaction has been proposed to play a
dominant role in the formation of this tail. We perform a complete and
homogeneous search for empirical signatures of binarity in a sample of 54
fast-rotating stars with the aim of evaluating this hypothesis. This working
sample has been extracted from a larger sample of 415 Galactic O-type stars
which covers the full range of vsini values. We use new and archival
multi-epoch spectra in order to detect spectroscopic binary systems. We
complement this information with Gaia proper motions and TESS photometric data
to aid in the identification of runaway stars and eclipsing binaries,
respectively. The identified fraction of single-lined spectroscopic binary
(SB1) systems and apparently single stars among the fast-rotating sample is
$\sim$18% and $\sim$70%, respectively. When comparing these percentages with
those corresponding to the slow-rotating sample we find that our sample of fast
rotators is characterized by a slightly larger percentage of SB1 systems
($\sim$18% vs. $\sim$13%) and a considerably smaller fraction of clearly
detected SB2 systems (8% vs. 33%). Overall, there seems to be a clear deficit
of spectroscopic binaries (SB1+SB2) among fast-rotating O-type stars ($\sim$26%
vs. $\sim$46%). On the contrary, the fraction of runaway stars is significantly
higher in the fast-rotating domain ($\sim$33-50%) than among those stars with
vsini < 200 km/s. Lastly, almost 65% of the apparently single fast-rotating
stars are runaways. Our empirical results seem to be in good agreement with the
idea that the tail of fast-rotating O-type stars (with vsini > 200 km/s) is
mostly populated by post-interaction binary products.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 13:39:09 GMT""}]","2023-03-29"
"2302.01350","Markus Huber Q.","Markus Q. Huber, Wolfgang J. Kern, Reinhard Alkofer","How to determine the branch points of correlation functions in Euclidean
  space II: Three-point functions","12 pages, 8 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The analytic structure of elementary correlation functions of a quantum field
is relevant for the calculation of masses of bound states and their time-like
properties in general. In quantum chromodynamics, the calculation of
correlation functions for purely space-like momenta has reached a high level of
sophistication, but the calculation at time-like momenta requires refined
methods. One of them is the contour deformation method. Here we describe how to
employ it for three-point functions. The basic mechanisms are discussed for a
scalar theory, but they are the same for more complicated theories and are thus
relevant, e.g., for the three-gluon or quark-gluon vertices of quantum
chromodynamics. Their inclusion in existing truncation schemes is a crucial
step for investigating the analytic structure of elementary correlation
functions of quantum chromodynamics and the calculation of its spectrum from
them.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:01 GMT""}]","2023-02-06"
"2302.01351","Beverly Lowell","Beverly Lowell (1), Jonatan Jacquemin-Ide (1), Alexander Tchekhovskoy
  (1), and Alex Duncan (2) ((1) Northwestern University, (2) Cornell
  University)","Rapid Black Hole Spin-down by Thick Magnetically Arrested Disks","14 pages, 7 figures. To be submitted to ApJ. Comments welcome",,,,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black hole (BH) spin can play an important role in galaxy evolution by
controlling the amount of energy and momentum ejected from near the BH into the
surroundings. We focus on the magnetically-arrested disk (MAD) state in the
sub- and super-Eddington regimes, when the accretion disk is
radiatively-inefficient and geometrically-thick, and the system launches strong
BH-powered jets. Using a suite of 3D general relativistic magnetohydrodynamic
(GRMHD) simulations, we find that for any initial spin, a MAD rapidly spins
down the BH to the equilibrium spin of $0 < a_{\rm eq} \lesssim 0.1$, very low
compared to $a_{\rm eq} = 1$ for the standard thin luminous (Novikov-Thorne)
disks. This implies that rapidly accreting (super-Eddington) BHs fed by MADs
tend to lose most of their rotational energy to magnetized relativistic
outflows. In a MAD, a BH only needs to accrete $10\%$ of its own mass to spin
down from $a=1$ to $a=0.2$. We construct a semi-analytic model of BH spin
evolution in MADs by taking into account the torques on the BH due to both the
hydrodynamic disk and electromagnetic jet components, and find that the low
value of $a_{\rm eq}$ is due to both the jets slowing down the BH rotation and
the disk losing a large fraction of its angular momentum to outflows. Our
results have crucial implications on how BH spins evolve in active galaxies and
other systems such as collapsars, where BH spin-down timescale can be short
enough to significantly affect the evolution of BH-powered jets.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:01 GMT""}]","2023-02-06"
"2302.01352","Valerio Nascimbeni","V. Nascimbeni, L. Borsato, T. Zingales, G. Piotto, I. Pagano, M. Beck,
  C. Broeg, D. Ehrenreich, S. Hoyer, F. Z. Majidi, V. Granata, S. G. Sousa, T.
  G. Wilson, V. Van Grootel, A. Bonfanti, S. Salmon, A. J. Mustill, L. Delrez,
  Y. Alibert, R. Alonso, G. Anglada, T. B\'arczy, D. Barrado, S. C. C. Barros,
  W. Baumjohann, T. Beck, W. Benz, M. Bergomi, N. Billot, X. Bonfils, A.
  Brandeker, J. Cabrera, S. Charnoz, A. Collier Cameron, Sz. Csizmadia, P. E.
  Cubillos, M. B. Davies, M. Deleuil, A. Deline, O. D. S. Demangeon, B.-O.
  Demory, A. Erikson, A. Fortier, L. Fossati, M. Fridlund, D. Gandolfi, M.
  Gillon, M. G\""udel, K. G. Isaak, L. L. Kiss, J. Laskar, A. Lecavelier des
  Etangs, M. Lendl, C. Lovis, R. Luque, D. Magrin, P. F. L. Maxted, C.
  Mordasini, G. Olofsson, R. Ottensamer, E. Pall\'e, G. Peter, D. Piazza, D.
  Pollacco, D. Queloz, R. Ragazzoni, N. Rando, F. Ratti, H. Rauer, I. Ribas, N.
  C. Santos, G. Scandariato, D. S\'egransan, A. E. Simon, A. M. S. Smith, M.
  Steinberger, M. Steller, Gy. M. Szab\'o, N. Thomas, S. Udry, J. Venturini, N.
  A. Walton, D. Wolter","A new dynamical modeling of the WASP-47 system with CHEOPS observations","17 pages, 8 figures, 10 tables, A&A in press. Typos corrected",,"10.1051/0004-6361/202245486",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Among the hundreds of known hot Jupiters (HJs), only five have been found to
have companions on short-period orbits. Within this rare class of multiple
planetary systems, the architecture of WASP-47 is unique, hosting an HJ (planet
-b) with both an inner and an outer sub-Neptunian mass companion (-e and -d,
respectively) as well as an additional non-transiting, long-period giant (-c).
The small period ratio between planets -b and -d boosts the transit time
variation (TTV) signal, making it possible to reliably measure the masses of
these planets in synergy with the radial velocity (RV) technique. In this
paper, we present new space- and ground-based photometric data of WASP-47b and
WASP-47-d, including 11 unpublished light curves from the ESA mission CHEOPS.
We analyzed the light curves in a homogeneous way together with all the
publicly available data to carry out a global $N$-body dynamical modeling of
the TTV and RV signals. We retrieved, among other parameters, a mass and
density for planet -d of $M_\mathrm{d}=15.5\pm 0.8$ $M_\oplus$ and
$\rho_\mathrm{d}=1.69\pm 0.22$ g\,cm$^{-3}$, which is in good agreement with
the literature and consistent with a Neptune-like composition. For the inner
planet (-e), we found a mass and density of $M_\mathrm{e}=9.0\pm 0.5$
$M_\oplus$ and $\rho_\mathrm{e}=8.1\pm 0.5$ g\,cm$^{-3}$, suggesting an
Earth-like composition close to other ultra-hot planets at similar irradiation
levels. Though this result is in agreement with previous RV+TTV studies, it is
not in agreement with the most recent RV analysis (at 2.8$\sigma$), which
yielded a lower density compatible with a pure silicate composition. This
discrepancy highlights the still unresolved issue of suspected systematic
offsets between RV and TTV measurements. In this paper, we also significantly
improve the orbital ephemerides of all transiting planets, which will be
crucial for any future follow-up.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 14:21:59 GMT""}]","2023-05-10"
"2302.01353","Janusz Rosiek","A. Dedes, J. Rosiek, M. Ryczkowski, K. Suxho, L. Trifyllis","SmeftFR v3 -- Feynman rules generator for the Standard Model Effective
  Field Theory","47 pages. arXiv admin note: substantial text overlap with
  arXiv:1904.03204",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We present version 3 of SmeftFR, a Mathematica package designed to generate
the Feynman rules for the Standard Model Effective Field Theory (SMEFT)
including the complete set of gauge invariant operators up to dimension-6 and
the complete set of bosonic operators of dimension-8. Feynman rules are
generated with the use of FeynRules package, directly in the physical (mass
eigenstates) basis for all fields. The complete set of interaction vertices can
be derived, including all or any chosen subset of SMEFT operators. As an
option, the user can also choose preferred gauge fixing, generating Feynman
rules in unitary or $R_\xi$-gauges. The novel feature in version-3 of SmeftFR
is its ability to calculate SMEFT interactions consistently up to dimension-8
in EFT expansion (including quadratic dimension-6 terms) and express the
vertices directly in terms of user-defined set of input-parameters. The derived
Lagrangian in the mass basis can be exported in various formats supported by
FeynRules, such as UFO, FeynArts etc. Initialisation of numerical values of
Wilson coefficients of higher dimension operators is interfaced to WCxf format.
The package also includes a dedicated Latex generator allowing to print the
result in clear human-readable form. The SmeftFR v3 is publicly available at
www.fuw.edu.pl/smeft.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:02 GMT""}]","2023-02-06"
"2302.01354","Andrzej Buras","Andrzej J. Buras","$Z^\prime$-Tandem Mechanism for the Suppression of New Physics in Quark
  Mixing with Implications for K, D and B Decays","10 pages, no figures. V2: the use of the new mixing matrix for
  $Z^\prime$ interactions allows a much more transparent description of this
  tandem and provides new insights into this framework",,,,"hep-ph hep-ex hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  $Z^\prime$ models belong to the ones that can most easily explain the
anomalies in $b\to s \mu^+\mu^-$ transitions. However, such an explanation by a
single $Z^\prime$ gauge boson, as done in the literature, is severly
constrained by the $B^0_s-\bar B_s^0$ mixing. Also the recent finding, hat the
mass differences $\Delta M_s$, $\Delta M_d$, the CP-violating parameter
$\varepsilon_K$, and the mixing induced CP-asymmetries $S_{\psi K_S}$ and
$S_{\psi \phi}$ can be simultaneously well described within the SM without new
physics (NP) contributions, is a challenge for $Z^\prime$ models with a single
$Z^\prime$ contributing at tree-level to quark mixing. We point out that
including a second $Z^\prime$ in the model allows to eliminate simultaneously
tree-level contributions to the five $\Delta F=2$ observables used in the
determination of the CKM parameters while leaving the room for NP in $\Delta
M_K$ and $\Delta M_D$. The latter one can be removed at the price of infecting
$\Delta M_s$ or $\Delta M_d$ by NP which is presently disfavoured. This pattern
is transparently seen using the new mixing matrix for $Z^\prime$ interactions
with quarks. This strategy allows significant tree-level contributions to $K$,
$B_s$ and $B_d$ decays thereby allowing to explain the existing anomalies in
$b\to s\mu^+\mu^-$ transitions and the anticipated anomaly in the ratio
$\varepsilon'/\varepsilon$ much easier than in $Z^\prime$-Single scenarios. The
proposed $Z^\prime$-Tandem mechanism bears some similarities to the GIM
mechanism for the suppression of the FCNCs in the SM with the role of the charm
quark played here by the second $Z^\prime$. However, it differs from the latter
profoundly in that only NP contributions to quark mixing are eliminated at
tree-level. We discuss briefly the implied flavour patterns in $K$ and $B$
decay observables in this NP scenario.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 12:37:33 GMT""}]","2023-02-21"
"2302.01355","Ewan McCulloch","Ewan McCulloch, Jacopo De Nardis, Sarang Gopalakrishnan, Romain
  Vasseur","Full Counting Statistics of Charge in Chaotic Many-body Quantum Systems","5 pages, 2 figures, 9 page supplementary",,,,"quant-ph cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We investigate the full counting statistics of charge transport in
$U(1)$-symmetric random unitary circuits. We consider an initial mixed state
prepared with a chemical potential imbalance between the left and right halves
of the system, and study the fluctuations of the charge transferred across the
central bond in typical circuits. Using an effective replica statistical
mechanics model and a mapping onto an emergent classical stochastic process
valid at large onsite Hilbert space dimension, we show that charge transfer
fluctuations approach those of the symmetric exclusion process at long times,
with subleading $t^{-1/2}$ quantum corrections. We discuss our results in the
context of fluctuating hydrodynamics and macroscopic fluctuation theory of
classical non-equilibrium systems, and check our predictions against direct
matrix-product state calculations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:05 GMT""}]","2023-02-06"
"2302.01356","Matthias Steinhauser","Joshua Davies, Go Mishima, Kay Sch\""onwald, Matthias Steinhauser","Analytic approximations of $2\to 2$ processes with massive internal
  particles","25 pages",,,"P3H-23-008, TTP23-004, TU-1178, ZU-TH 06/23","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider two-loop corrections to $2\to 2$ scattering processes with
massive particles in the final state and massive particles in the loop. We
discuss the combination of analytic expansions in the high-energy limit and for
small Mandelstam variable~$t$. For the example of double Higgs boson production
we show that the whole phase space can be covered and time-consuming numerical
integrations can be avoided.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:06 GMT""}]","2023-02-06"
"2302.01357","Vijay Mahatma","V. H. Mahatma, A. Basu, M. J. Hardcastle, L. K. Morabito, and R. J.
  van Weeren","A low frequency sub-arcsecond view of powerful radio galaxies in
  rich-cluster environments: 3C 34 and 3C 320","16 pages, 7 figures, 2 tables. Accepted for publication in Monthly
  Notices of the Royal Astronomical Society, 2023 February 01",,"10.1093/mnras/stad395",,"astro-ph.GA astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Models of radio galaxy physics have been primarily based on high frequency
($\geqslant$1 GHz) observations of their jets, hotspots, and lobes. Without
highly resolved low frequency observations, which provide information on older
plasma, our understanding of the dynamics of radio galaxies and their
interaction with their environment is limited. Here, we present the first
sub-arcsecond (0.3"") resolution images at 144 MHz of two powerful radio
galaxies situated in rich cluster environments, namely 3C 34 and 3C 320, using
the International Low Frequency Array Telescope. We detect for the first time
at low frequencies a plethora of structures in these objects, including
strikingly large filaments across the base of the lobes in both sources, which
are spatially associated with dense regions in the ambient medium. For 3C 34 we
report a spectral flattening in the region of the central filament, suggesting
that the origin of the filaments is related to the presence of large-scale
ordered magnetic fields. We also report periodic total intensity and spectral
index banding of diffuse emission in the eastern lobe, seen for the first time
in radio galaxy lobes. The hotspot complexes are resolved into multiple
fragments of varying structure and spectral index; we discuss the implications
for particle acceleration and jet termination models. We find at most smooth
gradients in the spectral behaviour of the hotspot structure suggesting that
particle acceleration, if present, may be occurring throughout the complex, in
contrast to simple models, but different jet termination models may apply to
both sources.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:08 GMT""}]","2023-02-15"
"2302.01358","Iv\'an Ezequiel L\'opez","I. E. L\'opez, M. Brusa, S. Bonoli, F. Shankar, N. Acharya, B.Laloux,
  K. Dolag, A. Georgakakis, A. Lapi, C. Ramos Almeida, M. Salvato, J.
  Chaves-Montero, P. Coelho, L. A. D\'iaz-Garc\'ia, J. A.
  Fern\'andez-Ontiveros, A. Hern\'an-Caballero, R. M. Gonz\'alez Delgado, I.
  Marquez, M. Povi\'c, R. Soria, C. Queiroz, P. T. Rahna, R. Abramo, J.
  Alcaniz, N. Benitez, S. Carneiro, J. Cenarro, D. Crist\'obal-Hornillos, R.
  Dupke, A. Ederoclite, C. L\'opez-Sanjuan, A. Mar\'in-Franch, C. Mendes de
  Oliveira, M. Moles, L. Sodr\'e Jr, K. Taylor, J. Varela, H. V. Rami\'o","The miniJPAS survey: AGN & host galaxy co-evolution of X-ray selected
  sources","Accepted for publication in A&A","A&A 672, A137 (2023)","10.1051/0004-6361/202245168",,"astro-ph.GA astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Studies indicate strong evidence of a scaling relation in the local Universe
between the supermassive black hole mass ($M_\rm{BH}$) and the stellar mass of
their host galaxies ($M_\star$). They even show similar histories across cosmic
times of their differential terms: star formation rate (SFR) and black hole
accretion rate (BHAR). However, a clear picture of this coevolution is far from
being understood. We select an X-ray sample of active galactic nuclei (AGN) up
to $z=2.5$ in the miniJPAS footprint. Their X-ray to infrared spectral energy
distributions (SEDs) have been modeled with CIGALE, constraining the emission
to 68 bands. For a final sample of 308 galaxies, we derive their physical
properties (e.g., $M_\star$, $\rm{SFR}$, $\rm{SFH}$, and $L_\rm{AGN}$). We also
fit their optical spectra for a subsample of 113 sources to estimate the
$M_\rm{BH}$. We calculate the BHAR depending on two radiative efficiency
regimes. We find that the Eddington ratios ($\lambda$) and its popular proxy
($L_\rm{X}$/$M_\star$) have 0.6 dex of difference, and a KS-test indicates that
they come from different distributions. Our sources exhibit a considerable
scatter on the $M_\rm{BH}$-$M_\star$ relation, which can explain the difference
between $\lambda$ and its proxy. We also model three evolution scenarios to
recover the integral properties at $z=0$. Using the SFR and BHAR, we show a
notable diminution in the scattering between $M_\rm{BH}$-$M_\star$. For the
last scenario, we consider the SFH and a simple energy budget for the AGN
accretion, obtaining a relation similar to the local Universe. Our study covers
$\sim 1$ deg$^2$ in the sky and is sensitive to biases in luminosity.
Nevertheless, we show that, for bright sources, the link between SFR and BHAR,
and their decoupling based on an energy limit is the key that leads to the
local $M_\rm{BH}$-$M_\star$ scaling relation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:20 GMT""}]","2023-04-12"
"2302.01359","David D\'iaz-Calder\'on","M. Davier, D. D\'iaz-Calder\'on, B. Malaescu, A. Pich, A.
  Rodr\'iguez-S\'anchez, Z. Zhang","The Euclidean Adler Function and its Interplay with
  $\Delta\alpha^{\mathrm{had}}_{\mathrm{QED}}$ and $\alpha_s$","56 pages, 22 figures, 14 tables. Published version","JHEP 04 (2023) 067","10.1007/JHEP04(2023)067",,"hep-ph hep-ex hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three different approaches to precisely describe the Adler function in the
Euclidean regime at around $2\, \mathrm{GeVs}$ are available: dispersion
relations based on the hadronic production data in $e^+e^-$ annihilation,
lattice simulations and perturbative QCD (pQCD). We make a comprehensive study
of the perturbative approach, supplemented with the leading power corrections
in the operator product expansion. All known contributions are included, with a
careful assessment of uncertainties. The pQCD predictions are compared with the
Adler functions extracted from
$\Delta\alpha^{\mathrm{had}}_{\mathrm{QED}}(Q^2)$, using both the DHMZ
compilation of $e^+e^-$ data and published lattice results. Taking as input the
FLAG value of $\alpha_s$, the pQCD Adler function turns out to be in good
agreement with the lattice data, while the dispersive results lie
systematically below them. Finally, we explore the sensitivity to $\alpha_s$ of
the direct comparison between the data-driven, lattice and QCD Euclidean Adler
functions. The precision with which the renormalisation group equation can be
tested is also evaluated.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:44 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 16:39:34 GMT""}]","2023-04-27"
"2302.01360","Shunyu Yao","Andreas Blommaert, Jorrit Kruthoff and Shunyu Yao","The power of Lorentzian wormholes","39 pages + appendices",,,,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As shown by Louko and Sorkin in 1995, topology change in Lorentzian signature
involves spacetimes with singular points, which they called crotches. We modify
their construction to obtain Lorentzian semiclassical wormholes in
asymptotically AdS. These solutions are obtained by inserting crotches on known
saddles, like the double-cone or multiple copies of the Lorentzian black hole.
The crotches implement swap-identifications, and are classically located at an
extremal surface. The resulting Lorentzian wormholes have an instanton action
equal to their area, which is responsible for topological suppression in any
number of dimensions. We conjecture that including these Lorentzian wormhole
spacetimes is gauge-equivalent to path integrating over all mostly Euclidean
smooth spacetimes. We present evidence for this by reproducing semiclassical
features of the genus expansion of the spectral form factor, and of a late-time
two point function, by summing over the moduli space of Lorentzian wormholes.
As a final piece of evidence, we discuss the Lorentzian version of West-Coast
replica wormholes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:00:46 GMT""}]","2023-02-06"
"2302.01361","Christopher Baldwin","Christopher L. Baldwin, Brian Swingle","Revisiting the replica trick: Competition between spin glass and
  conventional order","35 pages, 4 figures. Comments welcome",,,,"cond-mat.dis-nn cond-mat.stat-mech math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  There is an ambiguity in how to apply the replica trick to spin glass models
which have additional order parameters unrelated to spin glass order -- with
respect to which quantities does one minimize vs maximize the action, and in
what sequence? Here we show that the correct procedure is to first maximize
with respect to ``replica'' order parameters, and then minimize with respect to
``conventional'' order parameters. With this result, we further elucidate the
relationship between quenched free energies, annealed free energies, and
replica order. Phase transitions in which the quenched and annealed free
energies become unequal, which we term ``self-averaging transitions'', do not
necessarily correspond to the appearance of replica order. In fact, the
quenched and annealed ensembles can each undergo transitions entirely
independently of the other.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:01:03 GMT""}]","2023-02-06"
"2302.01362","Sara Svaluto-Ferro","Christa Cuchiero, Sara Svaluto-Ferro and Josef Teichmann","Signature SDEs from an affine and polynomial perspective",,,,,"math.PR q-fin.MF","http://creativecommons.org/licenses/by/4.0/","  Signature stochastic differential equations (SDEs) constitute a large class
of stochastic processes, here driven by Brownian motions, whose characteristics
are entire or real-analytic functions of their own signature, i.e. of iterated
integrals of the process with itself, and allow therefore for a generic path
dependence. We show that their prolongation with the corresponding signature is
an affine and polynomial process taking values in subsets of group-like
elements of the extended tensor algebra. By relying on the duality theory for
affine and polynomial processes we obtain explicit formulas in terms of novel
and proper notions of converging power series for the Fourier-Laplace transform
and the expected value of entire functions of the signature process. The
coefficients of these power series are solutions of extended tensor algebra
valued Riccati and linear ordinary differential equations (ODEs), respectively,
whose vector fields can be expressed in terms of the entire characteristics of
the corresponding SDEs. In other words, we construct a class of stochastic
processes, which is universal within It\^o processes with path-dependent
characteristics and which allows for a relatively explicit characterization of
the Fourier-Laplace transform and hence the full law on path space. We also
analyze the special case of one-dimensional signature SDEs, which correspond to
classical SDEs with real-analytic characteristics. Finally, the practical
feasibility of this affine and polynomial approach is illustrated by several
numerical examples.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:01:04 GMT""}]","2023-02-06"
"2302.01363","Aaron Ouellette","Aaron Ouellette, Gilbert Holder, Ely Kerman","Topological data analysis reveals differences between simulated galaxies
  and dark matter haloes","9 pages, 7 figures",,,,"astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  We use topological summaries based on Betti curves to characterize the
large-scale spatial distribution of simulated dark matter haloes and galaxies.
Using the IllustrisTNG and CAMELS-SAM simulations, we show that the topology of
the galaxy distribution is significantly different from the topology of the
dark matter halo distribution. Further, there are significant differences
between the distributions of star-forming and quiescent galaxies. These
topological differences are broadly consistent across all simulations, while at
the same time there are noticeable differences when comparing between different
models. Finally, using the CAMELS-SAM simulations, we show that the topology of
the quiescent galaxies, in particular, depends strongly on the amount of
supernova feedback. These results suggest that topological summary statistics
could be used to help better understand the processes of galaxy formation and
evolution.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:04:31 GMT""}]","2023-02-06"
"2302.01364","Anton V. Proskurnikov","Anton V. Proskurnikov, H{\aa}kan Runvik, Alexander Medvedev","Cycles in Impulsive Goodwin's Oscillators of Arbitrary Order",,,,,"math.OC cs.SY eess.SY math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Existence of periodical solutions, i.e. cycles, in the Impulsive Goodwin's
Oscillator (IGO) with the continuous part of an arbitrary order m is
considered. The original IGO with a third-order continuous part is a hybrid
model that portrays a chemical or biochemical system composed of three
substances represented by their concentrations and arranged in a cascade. The
first substance in the chain is introduced via an impulsive feedback where both
the impulse frequency and weights are modulated by the measured output of the
continuous part. It is shown that, under the standard assumptions on the IGO, a
positive periodic solution with one firing of the pulse-modulated feedback in
the least period also exists in models with any m >= 1. Furthermore, the
uniqueness of this 1-cycle is proved for the IGO with m <= 10 whereas, for m >
10, the uniqueness can still be guaranteed under mild assumptions on the
frequency modulation function.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:06:49 GMT""}]","2023-02-06"
"2302.01365","Joseph Bowles","Joseph Bowles, Victoria J Wright, M\'at\'e Farkas, Nathan Killoran,
  Maria Schuld","Contextuality and inductive bias in quantum machine learning","comments welcome",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Generalisation in machine learning often relies on the ability to encode
structures present in data into an inductive bias of the model class. To
understand the power of quantum machine learning, it is therefore crucial to
identify the types of data structures that lend themselves naturally to quantum
models. In this work we look to quantum contextuality -- a form of
nonclassicality with links to computational advantage -- for answers to this
question. We introduce a framework for studying contextuality in machine
learning, which leads us to a definition of what it means for a learning model
to be contextual. From this, we connect a central concept of contextuality,
called operational equivalence, to the ability of a model to encode a linearly
conserved quantity in its label space. A consequence of this connection is that
contextuality is tied to expressivity: contextual model classes that encode the
inductive bias are generally more expressive than their noncontextual
counterparts. To demonstrate this, we construct an explicit toy learning
problem -- based on learning the payoff behaviour of a zero-sum game -- for
which this is the case. By leveraging tools from geometric quantum machine
learning, we then describe how to construct quantum learning models with the
associated inductive bias, and show through our toy problem that they
outperform their corresponding classical surrogate models. This suggests that
understanding learning problems of this form may lead to useful insights about
the power of quantum machine learning.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:07:26 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 17:06:12 GMT""},{""version"":""v3"",""created"":""Tue, 18 Apr 2023 08:15:59 GMT""}]","2023-04-19"
"2302.01366","Christine Konicki","Christine Konicki and Mithun Chakraborty and Michael P. Wellman","Exploiting Extensive-Form Structure in Empirical Game-Theoretic Analysis","This paper has been slightly revised from the original version
  published at WINE 2022; to wit, the proof included in the appendices of our
  key theoretical result has been expanded","Web and Internet Economics: 18th International Conference (WINE
  2022), Proceedings. 132--149",,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  Empirical game-theoretic analysis (EGTA) is a general framework for reasoning
about complex games using agent-based simulation. Data from simulating select
strategy profiles is employed to estimate a cogent and tractable game model
approximating the underlying game. To date, EGTA methodology has focused on
game models in normal form; though the simulations play out in sequential
observations and decisions over time, the game model abstracts away this
temporal structure. Richer models of \textit{extensive-form games} (EFGs)
provide a means to capture temporal patterns in action and information, using
tree representations. We propose \textit{tree-exploiting EGTA} (TE-EGTA), an
approach to incorporate EFG models into EGTA\@. TE-EGTA constructs game models
that express observations and temporal organization of activity, albeit at a
coarser grain than the underlying agent-based simulation model. The idea is to
exploit key structure while maintaining tractability. We establish
theoretically and experimentally that exploiting even a little temporal
structure can vastly reduce estimation error in strategy-profile payoffs
compared to the normal-form model. Further, we explore the implications of EFG
models for iterative approaches to EGTA, where strategy spaces are extended
incrementally. Our experiments on several game instances demonstrate that
TE-EGTA can also improve performance in the iterative setting, as measured by
the quality of equilibrium approximation as the strategy spaces are expanded.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:08:15 GMT""}]","2023-02-06"
"2302.01367","Heng Chen","Heng Chen, Michael L. LeBlanc and James Y. Dai","Augmented Learning of Heterogeneous Treatment Effects via Gradient
  Boosting Trees",,,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heterogeneous treatment effects (HTE) based on patients' genetic or clinical
factors are of significant interest to precision medicine. Simultaneously
modeling HTE and corresponding main effects for randomized clinical trials with
high-dimensional predictive markers is challenging. Motivated by the modified
covariates approach, we propose a two-stage statistical learning procedure for
estimating HTE with optimal efficiency augmentation, generalizing to arbitrary
interaction model and exploiting powerful extreme gradient boosting trees
(XGBoost). Target estimands for HTE are defined in the scale of mean difference
for quantitative outcomes, or risk ratio for binary outcomes, which are the
minimizers of specialized loss functions. The first stage is to estimate the
main-effect equivalency of the baseline markers on the outcome, which is then
used as an augmentation term in the second stage estimation for HTE. The
proposed two-stage procedure is robust to model mis-specification of main
effects and improves efficiency for estimating HTE through nonparametric
function estimation, e.g., XGBoost. A permutation test is proposed for global
assessment of evidence for HTE. An analysis of a genetic study in Prostate
Cancer Prevention Trial led by the SWOG Cancer Research Network, is conducted
to showcase the properties and the utilities of the two-stage method.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:10:04 GMT""}]","2023-02-06"
"2302.01368","Brooke Krajancich","Brooke Krajancich, Petr Kellnhofer, Gordon Wetzstein","Towards Attention-aware Foveated Rendering","10 pages, 6 figures",,,,"cs.HC cs.GR eess.IV","http://creativecommons.org/licenses/by/4.0/","  Foveated graphics is a promising approach to solving the bandwidth challenges
of immersive virtual and augmented reality displays by exploiting the falloff
in spatial acuity in the periphery of the visual field. However, the perceptual
models used in these applications neglect the effects of higher-level cognitive
processing, namely the allocation of visual attention, and are thus
overestimating sensitivity in the periphery in many scenarios. Here, we
introduce the first attention-aware model of contrast sensitivity. We conduct
user studies to measure contrast sensitivity under different attention
distributions and show that sensitivity in the periphery drops significantly
when the user is required to allocate attention to the fovea. We motivate the
development of future foveation models with another user study and demonstrate
that tolerance for foveation in the periphery is significantly higher when the
user is concentrating on a task in the fovea. Analysis of our model predicts
significant bandwidth savings over those afforded by current models. As such,
our work forms the foundation for attention-aware foveated graphics techniques.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:10:21 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 18:50:12 GMT""}]","2023-05-12"
"2302.01370","Amarjit Haty","Amarjit Haty, Rajendra K. Ray and H.V.R. Mittal","Impact of a Cold Control Plate on Fluid Flow and Heat Transfer across an
  Isothermally Heated Rotary Oscillating Circular Cylinder",,,,,"physics.flu-dyn cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The main objective of this paper is to study the effect of a cold, vertical,
arc-shaped control plate on the flow characteristics and forced convective heat
transfer mechanism across a rotary oscillating, isothermally heated circular
cylinder. Two-dimensional, unsteady, incompressible, laminar, and viscous flow
of a Newtonian, constant property fluid is considered across the cylinder. The
simulations are performed with an in-house code for various gap ratios between
the control plate and the cylinder ($0\leq d/R_0 \leq 3$), maximum angular
velocity ($0.5\leq \alpha_m \leq 4$) and frequency ratio of oscillation
($f/f_0=0.5,\ 3$) at Prandtl number $0.7$ and Reynolds number $150$. Here, $d$
denotes the gap between the surface of the cylinder and the leading surface of
the control plate, $R_0$ denotes the radius of the cylinder, $f$ is the
frequency of oscillation and $f_0$ is the frequency of natural vortex shedding.
$d/R_0=0$ corresponds to the no plate case. Heat transfer and vortex shedding
phenomena are discussed in relation to one another. A significant increase in
heat transmission is observed for all $\alpha_m$ with the gap ratio of
$d/R_0=0.5$ and $f/f_0=0.5$. The heat absorption on the surface of the control
plate decreases to zero with increasing gap ratio when $\alpha_m=0.5$ and
$f/f_0=0.5$ but never becomes zero when $\alpha_m=4$ and $f/f_0=3$.
Additionally, when compared to the no plate case with $(\alpha_m,\
f/f_0)=(0.5,\ 0.5)$, the maximum peak of the drag coefficient is decreased by
$9.877\%$ for the gap ratio of $d/R_0=3$. For $\alpha_m=4$ and $f/f_0=3$, the
smallest gap ratio of $d/R_0=0.5$ is found to significantly increase the lift
coefficient relative to other cases.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:12:11 GMT""}]","2023-02-06"
"2302.01371","Aaron Sarvet","Aaron L. Sarvet and Mats J. Stensrud","Perspectives on harm in personalized medicine",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Avoiding harm is an uncontroversial aim of personalized medicine and other
epidemiologic initiatives. However, the precise mathematical translation of
""harm"" is disputable. Here we use a formal causal language to study common, but
distinct, definitions of ""harm"". We clarify that commitment to a definition of
harm has important practical and philosophical implications for decision
making. We relate our practical and philosophical considerations to ideas from
medical ethics and legal practice.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:14:52 GMT""}]","2023-02-06"
"2302.01372","Eric S. Swanson","E.S. Swanson","Light Hybrid Meson Mixing and Phenomenology","16 pages, 7 figures",,"10.1103/PhysRevD.107.074028",,"hep-ph hep-ex","http://creativecommons.org/licenses/by/4.0/","  A simple constituent model of gluodynamics that is motivated by lattice field
theory and the QCD Hamiltonian in Coulomb gauge is applied to descriptions of
hybrid meson flavor mixing and vector hybrid configuration mixing. Good
agreement with lattice gauge computations is obtained for flavor multiplet
masses, while mixing angles are in approximate agreement, given large errors.
The configuration mixing results are also in rough agreement with lattice NRQCD
calculations. Thus the viability of constituent gluon models of hybrid hadrons
and glueballs is supported. The results suggest that a flavor multiplet of
vector hybrids should appear with masses of approximately 2100, 2200, and 2300
MeV and that the isovector vector hybrid decay constant is about 20 MeV.
Similarly, the $\pi_1$ exotic hybrid should have isospin partner states near
1760 and 1900 MeV, and it is suggested that the recently seen $\eta_1$ hybrid
signal is the latter state.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:16:25 GMT""}]","2023-05-03"
"2302.01373","Karol Pokorski","Panagiotis Charalampopoulos, Bart{\l}omiej Dudek, Pawe{\l}
  Gawrychowski, Karol Pokorski","Optimal Heaviest Induced Ancestors",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  We revisit the Heaviest Induced Ancestors (HIA) problem that was introduced
by Gagie, Gawrychowski, and Nekrich [CCCG 2013] and has a number of
applications in string algorithms. Let $T_1$ and $T_2$ be two rooted trees
whose nodes have weights that are increasing in all root-to-leaf paths, and
labels on the leaves, such that no two leaves of a tree have the same label. A
pair of nodes $(u, v)\in T_1 \times T_2$ is \emph{induced} if and only if there
is a label shared by leaf-descendants of $u$ and $v$. In an HIA query, given
nodes $x \in T_1$ and $y \in T_2$, the goal is to find an induced pair of nodes
$(u, v)$ of the maximum total weight such that $u$ is an ancestor of~$x$ and
$v$ is an ancestor of $y$.
  Let $n$ be the upper bound on the sizes of the two trees. It is known that no
data structure of size $\tilde{\mathcal{O}}(n)$ can answer HIA queries in
$o(\log n / \log \log n)$ time [Charalampopoulos, Gawrychowski, Pokorski; ICALP
2020]. This (unconditional) lower bound is a $\operatorname{polyloglog} n$
factor away from the query time of the fastest $\tilde{\mathcal{O}}(n)$-size
data structure known to date for the HIA problem [Abedin, Hooshmand, Ganguly,
Thankachan; Algorithmica 2022]. In this work, we resolve the query-time
complexity of the HIA problem for the near-linear space regime by presenting a
data structure that can be built in $\tilde{\mathcal{O}}(n)$ time and answers
HIA queries in $\mathcal{O}(\log n/\log\log n)$ time. As a direct corollary, we
obtain an $\tilde{\mathcal{O}}(n)$-size data structure that maintains the LCS
of a static string and a dynamic string, both of length at most $n$, in time
optimal for this space regime.
  The main ingredients of our approach are fractional cascading and the
utilization of an $\mathcal{O}(\log n/ \log\log n)$-depth tree decomposition.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:17:03 GMT""}]","2023-02-06"
"2302.01374","William Sleeman Iv","William C. Sleeman IV, Rishabh Kapoor, Preetam Ghosh","Neural Network Architecture for Database Augmentation Using Shared
  Features","22 pages, 8 figures, 4 tables",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  The popularity of learning from data with machine learning and neural
networks has lead to the creation of many new datasets for almost every problem
domain. However, even within a single domain, these datasets are often
collected with disparate features, sampled from different sub-populations, and
recorded at different time points. Even with the plethora of individual
datasets, large data science projects can be difficult as it is often not
trivial to merge these smaller datasets. Inherent challenges in some domains
such as medicine also makes it very difficult to create large single source
datasets or multi-source datasets with identical features. Instead of trying to
merge these non-matching datasets directly, we propose a neural network
architecture that can provide data augmentation using features common between
these datasets. Our results show that this style of data augmentation can work
for both image and tabular data.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:17:06 GMT""}]","2023-02-06"
"2302.01375","Hassan Dbouk","Hassan Dbouk, Naresh R. Shanbhag","On the Robustness of Randomized Ensembles to Adversarial Perturbations","Published as a conference paper in ICML 2023",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Randomized ensemble classifiers (RECs), where one classifier is randomly
selected during inference, have emerged as an attractive alternative to
traditional ensembling methods for realizing adversarially robust classifiers
with limited compute requirements. However, recent works have shown that
existing methods for constructing RECs are more vulnerable than initially
claimed, casting major doubts on their efficacy and prompting fundamental
questions such as: ""When are RECs useful?"", ""What are their limits?"", and ""How
do we train them?"". In this work, we first demystify RECs as we derive
fundamental results regarding their theoretical limits, necessary and
sufficient conditions for them to be useful, and more. Leveraging this new
understanding, we propose a new boosting algorithm (BARRE) for training robust
RECs, and empirically demonstrate its effectiveness at defending against strong
$\ell_\infty$ norm-bounded adversaries across various network architectures and
datasets. Our code can be found at https://github.com/hsndbk4/BARRE.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:17:34 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 03:45:47 GMT""},{""version"":""v3"",""created"":""Sun, 28 May 2023 20:29:12 GMT""}]","2023-05-30"
"2302.01376","Andrea Merlo","Gioacchino Antonelli and Enrico Le Donne and Andrea Merlo","Carnot rectifiability and Alberti representations",,,,,"math.MG math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces and studies the analogue of the notion of Lipschitz
differentiability space by Cheeger, using Carnot groups and Pansu derivatives
as models. We call such metric measure spaces Pansu differentiability spaces
(PDS). After fixing a Carnot group $\mathbb G$, we prove three main results.
  (i) Being a PDS with $\mathbb G$-valued charts is equivalent to having
$\mathrm{rank}(\mathbb G)$ independent and horizontally universal Alberti
representations with respect to complete $\mathbb G$-valued charts. This result
leverages on a characterization by D. Bate, and extends it to our setting. For
non-Abelian Carnot groups, the completeness assumption cannot be removed as in
the Euclidean case. One direction of this equivalence can be seen as a metric
analogue of Pansu-Rademacher theorem.
  (ii) In every PDS the push-forward of the measure with respect to every
$\mathbb G$-valued chart is absolutely continuous with respect to the Haar
measure on $\mathbb G$. This extends the proof of Cheeger's conjecture by De
Philippis-Marchese-Rindler to our setting.
  (iii) For $Q$ being the homogeneous dimension of $\mathbb G$, being a PDS
with $\mathbb G$-valued charts, with finite $Q$-upper density, and positive
$Q$-lower density almost everywhere, is equivalent to being $\mathbb
G$-biLipschitz rectifiable. This extends a result by D. Bate and S. Li to our
setting. Moreover, the previous equivalence is false if we substitute $\mathbb
G$-biLipschitz with $\mathbb G$-Lipschitz, contrarily to what happens in the
Euclidean realm.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:23:23 GMT""}]","2023-02-06"
"2302.01377","Omer Ben-Porat","Omer Ben-Porat and Rotem Torkan","Learning with Exposure Constraints in Recommendation Systems","Published in The Web Conference 2023 (WWW 23)",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Recommendation systems are dynamic economic systems that balance the needs of
multiple stakeholders. A recent line of work studies incentives from the
content providers' point of view. Content providers, e.g., vloggers and
bloggers, contribute fresh content and rely on user engagement to create
revenue and finance their operations. In this work, we propose a contextual
multi-armed bandit setting to model the dependency of content providers on
exposure. In our model, the system receives a user context in every round and
has to select one of the arms. Every arm is a content provider who must receive
a minimum number of pulls every fixed time period (e.g., a month) to remain
viable in later rounds; otherwise, the arm departs and is no longer available.
The system aims to maximize the users' (content consumers) welfare. To that
end, it should learn which arms are vital and ensure they remain viable by
subsidizing arm pulls if needed. We develop algorithms with sub-linear regret,
as well as a lower bound that demonstrates that our algorithms are optimal up
to logarithmic factors.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:23:50 GMT""}]","2023-02-06"
"2302.01378","Wuchen Li","Wuchen Li, Linyuan Lu","Optimal Ricci curvature Markov chain Monte Carlo methods on finite
  states",,,,,"math.OC math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a new Markov chain Monte Carlo method on finite states with
optimal choices of acceptance-rejection ratio functions. We prove that the
constructed continuous time Markov jumping process has a global in-time
convergence rate in $L^1$ distance. The convergence rate is no less than
one-half and is independent of the target distribution. For example, our method
recovers the Metropolis-Hastings algorithm on a two-point state. And it forms a
new algorithm for sampling general target distributions. Numerical examples are
presented to demonstrate the effectiveness of the proposed algorithm.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:24:36 GMT""}]","2023-02-06"
"2302.01379","Francesco Sylos Labini Dr.","Francesco Sylos Labini, Zofia Chrobakova, Roberto Capuzzo-Dolcetta,
  Martin Lopez-Corredoira","Mass models of the Milky Way and estimation of its mass from the GAIA
  DR3 data-set","14 pages, 5 figures, accepted for publication in The Astrophysical
  Journal","2023 ApJ 945 3","10.3847/1538-4357/acb92c",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We use data from the Gaia DR3 dataset to estimate the mass of the Milky Way
(MW) by analyzing the rotation curve in the range of distances 5 kpc to 28 kpc.
We consider three mass models: the first model adds a spherical dark matter
(DM) halo, following the Navarro-Frenk-White (NFW) profile, to the known
stellar components. The second model assumes that DM is confined to the
Galactic disk, following the idea that the observed density of gas in the
Galaxy is related to the presence of more massive DM disk (DMD), similar to the
observed correlation between DM and gas in other galaxies. The third model only
uses the known stellar mass components and is based on the Modified Newton
Dynamics (MOND) theory. Our results indicate that the DMD model is comparable
in accuracy to the NFW and MOND models and fits the data better at large radii
where the rotation curve declines but has the largest errors. For the NFW model
we obtain a virial mass $M_{vir}= (6.5 \pm 0.3) \times 10^{11} \; M_\odot$ with
concentration parameter $c=14.5$, that is lower than what is typically
reported. In the DMD case we find that the MW mass is $M_d = (1.6 \pm 0.5)
\times 10^{11} \; M_\odot$ with a disk's characteristic radius of $R_d=17$ kpc.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:27:20 GMT""}]","2023-03-29"
"2302.01380","Yizhuang Liu","Yizhuang Liu, Maciej A. Nowak, Ismail Zahed","Universality of Koba-Nielsen-Olesen scaling in QCD at high energy and
  entanglement","6 pages, 1 figures",,,,"hep-ph hep-ex hep-th nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using Mueller's dipole formalism for deep inelastic scattering in QCD, we
formulate and solve the evolution for the generating function for the
multiplicities of the produced particles, in hadronic processes at high energy.
The solution for the multiplicities satisfies Koba-Nielsen-Olesen (KNO)
scaling, with good agreement with the recently re-analyzed data from the H1
experiment at HERA (DESY), and the old ALEPH data for hadronic $Z$ decay at LEP
(CERN). The same scaling function with KNO scaling, carries to the hadronic
multiplicities from jets in electron-positron annihilation. This agreement is
{\it a priori} puzzling, since in Mueller's dipole evolution, one accounts for
virtual dipoles in a wave function, whereas in electron-positron annihilation,
one describes cross-sections of real particles. We explain the origin of this
similarity, pointing at a particular duality between the two processes.
Finally, we interpret our results from the point of view of quantum
entanglement between slow and fast degrees of freedom in QCD, and derive the
entanglement entropy pertinent to electron-positron annihilation into hadronic
jets.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:27:48 GMT""}]","2023-02-06"
"2302.01381","Zhouxing Shi","Zhouxing Shi, Nicholas Carlini, Ananth Balashankar, Ludwig Schmidt,
  Cho-Jui Hsieh, Alex Beutel, Yao Qin","Effective Robustness against Natural Distribution Shifts for Models with
  Different Training Data",,,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ``Effective robustness'' measures the extra out-of-distribution (OOD)
robustness beyond what can be predicted from the in-distribution (ID)
performance. Existing effective robustness evaluations typically use a single
test set such as ImageNet to evaluate ID accuracy. This becomes problematic
when evaluating models trained on different data distributions, e.g., comparing
models trained on ImageNet vs. zero-shot language-image pre-trained models
trained on LAION. In this paper, we propose a new effective robustness
evaluation metric to compare the effective robustness of models trained on
different data distributions. To do this we control for the accuracy on
multiple ID test sets that cover the training distributions for all the
evaluated models. Our new evaluation metric provides a better estimate of the
effectiveness robustness and explains the surprising effective robustness gains
of zero-shot CLIP-like models exhibited when considering only one ID dataset,
while the gains diminish under our evaluation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:28:41 GMT""}]","2023-02-06"
"2302.01382","Clemens Jonathan Simon Schaefer","Clemens JS Schaefer, Elfie Guo, Caitlin Stanton, Xiaofan Zhang, Tom
  Jablin, Navid Lambert-Shirzad, Jian Li, Chiachen Chou, Siddharth Joshi, Yu
  Emma Wang","Mixed Precision Post Training Quantization of Neural Networks with
  Sensitivity Guided Search",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Serving large-scale machine learning (ML) models efficiently and with low
latency has become challenging owing to increasing model size and complexity.
Quantizing models can simultaneously reduce memory and compute requirements,
facilitating their widespread access. However, for large models not all layers
are equally amenable to the same numerical precision and aggressive
quantization can lead to unacceptable loss in model accuracy. One approach to
prevent this accuracy degradation is mixed-precision quantization, which allows
different tensors to be quantized to varying levels of numerical precision,
leveraging the capabilities of modern hardware. Such mixed-precision
quantiztaion can more effectively allocate numerical precision to different
tensors `as needed' to preserve model accuracy while reducing footprint and
compute latency. In this paper, we propose a method to efficiently determine
quantization configurations of different tensors in ML models using
post-training mixed precision quantization. We analyze three sensitivity
metrics and evaluate them for guiding configuration search of two algorithms.
We evaluate our method for computer vision and natural language processing and
demonstrate latency reductions of up to 27.59% and 34.31% compared to the
baseline 16-bit floating point model while guaranteeing no more than 1%
accuracy degradation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:30:00 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 00:10:44 GMT""}]","2023-02-08"
"2302.01383","Laurence Boxer","Laurence Boxer","Limiting Sets in Digital Topology","I have quoted and paraphrased a significant amount of material. I
  have indicated the sources of such material",,,,"math.GN","http://creativecommons.org/licenses/by/4.0/","  Freezing sets and cold sets have been introduced as part of the theory of
fixed points in digital topology. In this paper, we introduce a generalization
of these notions, the limiting set, and examine properties of limiting sets.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:37:53 GMT""}]","2023-02-06"
"2302.01384","Ze Wang","Ze Wang, Jiang Wang, Zicheng Liu, and Qiang Qiu","Energy-Inspired Self-Supervised Pretraining for Vision Models",,"ICLR 2023",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by the fact that forward and backward passes of a deep network
naturally form symmetric mappings between input and output representations, we
introduce a simple yet effective self-supervised vision model pretraining
framework inspired by energy-based models (EBMs). In the proposed framework, we
model energy estimation and data restoration as the forward and backward passes
of a single network without any auxiliary components, e.g., an extra decoder.
For the forward pass, we fit a network to an energy function that assigns low
energy scores to samples that belong to an unlabeled dataset, and high energy
otherwise. For the backward pass, we restore data from corrupted versions
iteratively using gradient-based optimization along the direction of energy
minimization. In this way, we naturally fold the encoder-decoder architecture
widely used in masked image modeling into the forward and backward passes of a
single vision model. Thus, our framework now accepts a wide range of pretext
tasks with different data corruption methods, and permits models to be
pretrained from masked image modeling, patch sorting, and image restoration,
including super-resolution, denoising, and colorization. We support our
findings with extensive experiments, and show the proposed method delivers
comparable and even better performance with remarkably fewer epochs of training
compared to the state-of-the-art self-supervised vision model pretraining
methods. Our findings shed light on further exploring self-supervised vision
model pretraining and pretext tasks beyond masked image modeling.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:41:00 GMT""}]","2023-02-06"
"2302.01385","Akshaj Kumar Veldanda","Akshaj Kumar Veldanda, Ivan Brugere, Sanghamitra Dutta, Alan Mishler,
  Siddharth Garg","Hyper-parameter Tuning for Fair Classification without Sensitive
  Attribute Access",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Fair machine learning methods seek to train models that balance model
performance across demographic subgroups defined over sensitive attributes like
race and gender. Although sensitive attributes are typically assumed to be
known during training, they may not be available in practice due to privacy and
other logistical concerns. Recent work has sought to train fair models without
sensitive attributes on training data. However, these methods need extensive
hyper-parameter tuning to achieve good results, and hence assume that sensitive
attributes are known on validation data. However, this assumption too might not
be practical. Here, we propose Antigone, a framework to train fair classifiers
without access to sensitive attributes on either training or validation data.
Instead, we generate pseudo sensitive attributes on the validation data by
training a biased classifier and using the classifier's incorrectly (correctly)
labeled examples as proxies for minority (majority) groups. Since fairness
metrics like demographic parity, equal opportunity and subgroup accuracy can be
estimated to within a proportionality constant even with noisy sensitive
attribute information, we show theoretically and empirically that these proxy
labels can be used to maximize fairness under average accuracy constraints. Key
to our results is a principled approach to select the hyper-parameters of the
biased classifier in a completely unsupervised fashion (meaning without access
to ground truth sensitive attributes) that minimizes the gap between fairness
estimated using noisy versus ground-truth sensitive labels.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:45:50 GMT""}]","2023-02-06"
"2302.01386","Gobinda Saha","Gobinda Saha, Kaushik Roy","Continual Learning with Scaled Gradient Projection","Accepted at AAAI 2023","Proceedings of Thirty-Seventh AAAI Conference on Artificial
  Intelligence (2023)",,,"cs.LG cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In neural networks, continual learning results in gradient interference among
sequential tasks, leading to catastrophic forgetting of old tasks while
learning new ones. This issue is addressed in recent methods by storing the
important gradient spaces for old tasks and updating the model orthogonally
during new tasks. However, such restrictive orthogonal gradient updates hamper
the learning capability of the new tasks resulting in sub-optimal performance.
To improve new learning while minimizing forgetting, in this paper we propose a
Scaled Gradient Projection (SGP) method, where we combine the orthogonal
gradient projections with scaled gradient steps along the important gradient
spaces for the past tasks. The degree of gradient scaling along these spaces
depends on the importance of the bases spanning them. We propose an efficient
method for computing and accumulating importance of these bases using the
singular value decomposition of the input representations for each task. We
conduct extensive experiments ranging from continual image classification to
reinforcement learning tasks and report better performance with less training
overhead than the state-of-the-art approaches.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:46:39 GMT""}]","2023-02-06"
"2302.01388","Mark Yen","Mark Yen, Geir E. Dullerud, Yu Wang","Statistical Verification of Traffic Systems with Expected Differential
  Privacy","American Control Conference 2023 (ACC23)",,,,"cs.CR cs.SY eess.SY stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traffic systems are multi-agent cyber-physical systems whose performance is
closely related to human welfare. They work in open environments and are
subject to uncertainties from various sources, making their performance hard to
verify by traditional model-based approaches. Alternatively, statistical model
checking (SMC) can verify their performance by sequentially drawing sample data
until the correctness of a performance specification can be inferred with
desired statistical accuracy. This work aims to verify traffic systems with
privacy, motivated by the fact that the data used may include personal
information (e.g., daily itinerary) and get leaked unintendedly by observing
the execution of the SMC algorithm. To formally capture data privacy in SMC, we
introduce the concept of expected differential privacy (EDP), which constrains
how much the algorithm execution can change in the expectation sense when data
change. Accordingly, we introduce an exponential randomization mechanism for
the SMC algorithm to achieve the EDP. Our case study on traffic intersections
by Vissim simulation shows the high accuracy of SMC in traffic model
verification without significantly sacrificing computing efficiency. The case
study also shows EDP successfully bounding the algorithm outputs to guarantee
privacy.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:49:28 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 15:35:43 GMT""}]","2023-03-01"
"2302.01389","Minghui Ding","Rico Zollner, Minghui Ding, Burkhard Kampfer","Masses of compact (neutron) stars with distinguished cores","20 pages, 9 figures, 1 table. Contribution to a Special Issue of
  PARTICLES: ""Strong Interactions in the Standard Model: Massless Bosons to
  Compact Stars"". Version accepted for publication. arXiv admin note: text
  overlap with arXiv:2203.17228",,,,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The impact of the core mass on the compact/neutron-star mass-radius relation
is studied. Besides the mass, the core is parameterized by its radius and
surface pressure, which supports the outside one-component Standard Model (SM)
matter. The core may accommodate SM matter with unspecified (or poorly known)
equation-of-state or several components, e.g. consisting of admixtures of Dark
Matter and/or Mirror World matter etc. beyond the SM. Thus, the admissible
range of masses and radii of compact stars can be considerably extended.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:52:11 GMT""}]","2023-02-06"
"2302.01390","Aijaz Lone","Aijaz H. Lone, Arnab Ganguly, Hanrui Li, Nazek El- Atab, Gobind Das
  and H. Fariborzi","Controlling the Skyrmion Density and Size for Quantized Convolutional
  Neural Networks","23 Pages",,,,"cond-mat.mtrl-sci cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Skyrmion devices show energy efficient and high integration data storage and
computing capabilities. Herein, we present the results of experimental and
micromagnetic investigations of the creation and stability of magnetic
skyrmions in the Ta/IrMn/CoFeB/MgO thin film system. We investigate the
magnetic-field dependence of the skyrmion density and size using polar magneto
optical Kerr effect MOKE microscopy supported by a micromagnetic study. The
evolution of the topological charge with time under a magnetic field is
investigated, and the transformation dynamics are explained. Furthermore,
considering the voltage control of these skyrmion devices, we evaluate the
dependence of the skyrmion size and density on the Dzyaloshinskii Moriya
interaction and the magnetic anisotropy. We furthermore propose a skyrmion
based synaptic device based on the results of the MOKE and micromagnetic
investigations. We demonstrate the spin-orbit torque controlled discrete
topological resistance states with high linearity and uniformity in the device.
The discrete nature of the topological resistance makes it a good candidate to
realize hardware implementation of weight quantization in a quantized neural
network (QNN). The neural network is trained and tested on the CIFAR10 dataset,
where the devices act as synapses to achieve a recognition accuracy of 87%,
which is comparable to the result of ideal software-based methods.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:56:14 GMT""}]","2023-02-06"
"2302.01391","Philipp Krah","Julian Koellermeier, Philipp Krah, Jonas Kusch","Macro-micro decomposition for consistent and conservative model order
  reduction of hyperbolic shallow water moment equations: A study using
  POD-Galerkin and dynamical low rank approximation","Code available under
  https://github.com/JonasKu/Publication-Split-conservative-model-order-reduction-for-hyperbolic-shallow-water-moment-equations",,,,"math.NA cs.NA physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Geophysical flow simulations using hyperbolic shallow water moment equations
require an efficient discretization of a potentially large system of PDEs, the
so-called moment system. This calls for tailored model order reduction
techniques that allow for efficient and accurate simulations while guaranteeing
physical properties like mass conservation.
  In this paper, we develop the first model reduction for the hyperbolic
shallow water moment equations and achieve mass conservation. This is
accomplished using a macro-micro decomposition of the model into a macroscopic
(conservative) part and a microscopic (non-conservative) part with subsequent
model reduction using either POD-Galerkin or dynamical low-rank approximation
only on the microscopic (non-conservative) part. Numerical experiments showcase
the performance of the new model reduction methods including high accuracy and
fast computation times together with guaranteed conservation and consistency
properties.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:57:38 GMT""}]","2023-02-06"
"2302.01392","Yiming Sun","Yiming Sun, Bing Cao, Pengfei Zhu, Qinghua Hu","Multi-modal Gated Mixture of Local-to-Global Experts for Dynamic Image
  Fusion",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Infrared and visible image fusion aims to integrate comprehensive information
from multiple sources to achieve superior performances on various practical
tasks, such as detection, over that of a single modality. However, most
existing methods directly combined the texture details and object contrast of
different modalities, ignoring the dynamic changes in reality, which diminishes
the visible texture in good lighting conditions and the infrared contrast in
low lighting conditions. To fill this gap, we propose a dynamic image fusion
framework with a multi-modal gated mixture of local-to-global experts, termed
MoE-Fusion, to dynamically extract effective and comprehensive information from
the respective modalities. Our model consists of a Mixture of Local Experts
(MoLE) and a Mixture of Global Experts (MoGE) guided by a multi-modal gate. The
MoLE performs specialized learning of multi-modal local features, prompting the
fused images to retain the local information in a sample-adaptive manner, while
the MoGE focuses on the global information that complements the fused image
with overall texture detail and contrast. Extensive experiments show that our
MoE-Fusion outperforms state-of-the-art methods in preserving multi-modal image
texture and contrast through the local-to-global dynamic learning paradigm, and
also achieves superior performance on detection tasks. Our code will be
available: https://github.com/SunYM2020/MoE-Fusion.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:06:58 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 07:15:53 GMT""}]","2023-03-24"
"2302.01393","Federico Bosia","Martin Lott, Antonio S. Gliozzi, Federico Bosia","Source and defect localization in thin elastic plates of arbitrary
  geometry using eigenmodes",,"Mechanical Systems and Signal Processing 184 (2023) 109706","10.1016/j.ymssp.2022.109706",,"physics.app-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, we experimentally demonstrate how discrete resonances can be
used to image acoustic sources and mechanical changes in thin plates with
different boundary shapes. The proposed method uses coupled numerical and
experimental data processing, and it only requires the knowledge of the sample
geometry (and not its elastic properties). If a limited number of measurement
points is available in experiments, the free modes of the plates are not
orthogonal from the receivers' point of view, and this induces an artificial
coupling in the post-processing of the experimental signals. However, we show
that this effect can be corrected using numerical simulations and a
mathematical transformation of the antenna geometry. After this correction,
imaging of active sources is performed using coherent summation of the elastic
field over the natural frequencies of the plates, leading to an unique
localization of the sources. Imaging mechanical changes in the two plates,
instead, is addressed using incoherent summation over the modes, leading to
symmetry problems for the plates. This work experimentally illustrates the
spatial resolution, perspectives and limitations in the use of eigenmodes to
produce images in complex elastic systems of arbitrary shape and materials.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:09:10 GMT""}]","2023-02-06"
"2302.01395","Eric Kleinherbers","Eric Kleinherbers, Thomas Stegmann, and Nikodem Szpak","Electronic transport in bent carbon nanotubes","13 pages, 9 figures","Phys. Rev. B 107, 195424 (2023)","10.1103/PhysRevB.107.195424",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the electronic transport through uniformly bent carbon nanotubes.
For this purpose, we describe the nanotube with the tight-binding model and
calculate the local current flow by employing non-equilibrium Green's functions
(NEGF) in the Keldysh formalism. In addition, we describe the low-energy
excitations using an effective Dirac equation in curved space with a
strain-induced pseudo-magnetic field which can be solved analytically for the
torus geometry in terms of the Mathieu functions. We obtain a perfect
quantitative agreement with the NEGF results. For nanotubes with an armchair
edge, already a weak bending of 1% substantially changes the electronic
properties. Depending on the valley, the current of the zero mode flows either
on the outer or the inner side of the torus and, therefore, can be used as a
valley splitter. In contrast, the zigzag nanotubes are largely unaffected by
the bending. Our findings are of importance for nanoelectronic applications of
carbon nanotubes and open new possibilities for valleytronics.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:11:34 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 18:39:12 GMT""}]","2023-05-26"
"2302.01396","Martha Kalina","Martha Kalina, Tom Schneider, J\""org Brummund, Markus K\""astner","Overview of phase-field models for fatigue fracture in a unified
  framework",,,"10.1016/j.engfracmech.2023.109318",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  In the last ten years, the phase-field method has gained much attention as a
novel method to simulate fracture due to its straightforward way allowing to
cover crack initiation and propagation without additional conditions. More
recently, it has also been applied to fatigue fracture due to cyclic loading.
This publication gives an overview of the main phase-field fatigue models
published to date. We present all models in a unified variational framework for
best comparability. Subsequently, the models are compared regarding their most
important features. It becomes apparent that they can be classified in mainly
two categories according to the way fatigue is implemented in the model - that
is as a gradual degradation of the fracture toughness or with an additional
term in the crack driving force. We aim to provide a helpful guide for choosing
the appropriate model for different applications and for developing existing
models further.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:17:36 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 17:12:57 GMT""},{""version"":""v3"",""created"":""Tue, 30 May 2023 00:26:38 GMT""}]","2023-05-31"
"2302.01397","Antonis Papasavva","Antonis Papasavva and Enrico Mariconti","Waiting for Q: An Exploration of QAnon Users' Online Migration to Poal
  in the Wake of Voat's Demise",,,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Many controversial and hateful online communities on mainstream social
networks get banned due to moderation efforts. One of the platforms known to
have taken such measures is Reddit, which banned various communities and users
in recent years. Although banning these communities eliminates the problem on
one platform, the participants of those communities often tend to regroup on
other, laxer alternative social networks. One alternative to Reddit was Voat, a
Reddit-like social network that allowed its users to share their controversial
ideas freely. Voat bloomed and became more popular with every Reddit ban, and
although it had a troubled history, it managed to stay afloat for four years
before shutting down in December 2020. In this work, we investigate the Voat
shutdown and how the users of the conspiracy theory QAnon organized their
online migration. We find that many users proposed Poal as a Voat alternative,
resulting in about half of the QAnon user base of Voat migrating there. In
addition, we find that only a few Voat users lost hope close to the end of
Voat, turning against Q, while others encouraged their fellow conspiracy
adherents to ""wait for Q"" to tell them where to go. Lastly, we find evidence
that shortly after the Voat shutdown, users on Poal (most of them Voat
migrants) start discussing and planning the January 6th, 2021, attack on the US
Capitol.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:17:54 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 15:01:24 GMT""}]","2023-02-07"
"2302.01398","Xavier Garcia","Xavier Garcia, Yamini Bansal, Colin Cherry, George Foster, Maxim
  Krikun, Fangxiaoyu Feng, Melvin Johnson, Orhan Firat","The unreasonable effectiveness of few-shot learning for machine
  translation",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate the potential of few-shot translation systems, trained with
unpaired language data, for both high and low-resource language pairs. We show
that with only 5 examples of high-quality translation data shown at inference,
a transformer decoder-only model trained solely with self-supervised learning,
is able to match specialized supervised state-of-the-art models as well as more
general commercial translation systems. In particular, we outperform the best
performing system on the WMT'21 English - Chinese news translation task by only
using five examples of English - Chinese parallel data at inference. Moreover,
our approach in building these models does not necessitate joint multilingual
training or back-translation, is conceptually simple and shows the potential to
extend to the multilingual setting. Furthermore, the resulting models are two
orders of magnitude smaller than state-of-the-art language models. We then
analyze the factors which impact the performance of few-shot translation
systems, and highlight that the quality of the few-shot demonstrations heavily
determines the quality of the translations generated by our models. Finally, we
show that the few-shot paradigm also provides a way to control certain
attributes of the translation -- we show that we are able to control for
regional varieties and formality using only a five examples at inference,
paving the way towards controllable machine translation systems.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:19:46 GMT""}]","2023-02-06"
"2302.01399","Md Masudur Rahman","Md Masudur Rahman and Yexiang Xue","Accelerating Policy Gradient by Estimating Value Function from Prior
  Computation in Deep Reinforcement Learning",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates the use of prior computation to estimate the value
function to improve sample efficiency in on-policy policy gradient methods in
reinforcement learning. Our approach is to estimate the value function from
prior computations, such as from the Q-network learned in DQN or the value
function trained for different but related environments. In particular, we
learn a new value function for the target task while combining it with a value
estimate from the prior computation. Finally, the resulting value function is
used as a baseline in the policy gradient method. This use of a baseline has
the theoretical property of reducing variance in gradient computation and thus
improving sample efficiency. The experiments show the successful use of prior
value estimates in various settings and improved sample efficiency in several
tasks.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:23:22 GMT""}]","2023-02-06"
"2302.01400","Sam Royston","Sam Royston","Personalized Understanding of Blood Glucose Dynamics via Mobile Sensor
  Data","Technical Report, 9 Pages",,,,"cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous Blood Glucose (CGM) monitors have revolutionized the ability of
diabetics to manage their blood glucose, and paved the way for artificial
pancreas systems. In this paper we augment CGM data with sensor input collected
by a smart phone and use it to provide analytical tools for patients and
clinicians. We collected GPS data, activity classifications, and blood glucose
data with a custom iOS application over a 9 month period from a single
free-living type-1 diabetic patient. This data set is novel in terms of it's
size, the inclusion of GPS data, and the fact that it was collected
non-intrusively from a free-living patient. We describe a method to measure the
occurrence of lifestyle \textit{events} based on GPS and activity data, and
show that they can capture instances of food consumption and are therefore
correlated to changes in blood glucose. Finally, we incorporate these event
representations into our system to create useful visualizations and
notifications to aid patients in managing their diabetes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:26:05 GMT""}]","2023-02-06"
"2302.01401","Andrick Adhikari","Philipp Markert, Andrick Adhikari and Sanchari Das","A Transcontinental Analysis of Account Remediation Protocols of Popular
  Websites","Conference: Symposium on Usable Security and Privacy (USEC) 2023At:
  San Diego, California",,"10.14722/usec.2023.235078",,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  Websites are used regularly in our day-today lives, yet research has shown
that it is challenging for many users to use them securely, e.g., most
prominently due to weak passwords through which they access their accounts. At
the same time, many services employ low-security measures, making their users
even more prone to account compromises with little to no means of remediating
compromised accounts. Additionally, remediating compromised accounts requires
users to complete a series of steps, ideally all provided and explained by the
service. However, for U.S.-based websites, prior research has shown that the
advice provided by many services is often incomplete. To further understand the
underlying issue and its implications, this paper reports on a study that
analyzes the account remediation procedure covering the 50 most popular
websites in 30 countries, 6 each in Africa, the Americas, Asia, Europe, and
Oceania. We conducted the first transcontinental analysis on the account
remediation protocols of popular websites. The analysis is based on 5 steps
websites need to provide advice for: compromise discovery, account recovery,
access limitation, service restoration, and prevention. We find that the lack
of advice prior work identified for websites from the U.S. also holds across
continents, with the presence ranging from 37% to 77% on average. Additionally,
we identified considerable differences when comparing countries and continents,
with countries in Africa and Oceania significantly more affected by the lack of
advice. To address this, we suggest providing publicly available and
easy-to-follow remediation advice for users and guidance for website providers
so they can provide all the necessary information.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:26:08 GMT""}]","2023-02-06"
"2302.01402","Lingyuan Gao","Lingyuan Gao, Sergei Prokhorenko, Yousra Nahas, and Laurent Bellaiche","Dynamical control of topology in ferroelectric skyrmions via twisted
  light",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/publicdomain/zero/1.0/","  Twisted light carries a non-zero orbital angular momentum, that can be
transferred from light to electrons and particles ranging from nanometers to
micrometers. Up to now, the interplay between twisted light with dipolar
systems has scarcely been explored, though the latter bear abundant forms of
topologies such as skyrmions and embrace strong light-matter coupling. Here,
using first-principles-based simulations, we show that twisted light can excite
and drive dynamical polar skyrmions and transfer its nonzero winding number to
ferroelectric ultrathin films. The skyrmion is successively created and
annihilated alternately at the two interfaces, and experiences a periodic
transition from a markedly ""Bloch"" to ""Neel"" character, accompanied with the
emergence of a ""Bloch point"" topological defect with vanishing polarization.
The dynamical evolution of skyrmions is connected to a constant jump of
topological number between ""0"" and ""1"" over time. These intriguing phenomena
are found to have an electrostatic origin. Our study thus demonstrates that,
and explains why, this unique light-matter interaction can be very powerful in
creating and manipulating topological solitons in functional materials.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:32:56 GMT""}]","2023-02-06"
"2302.01403","Bicheng Xu","Bicheng Xu, Renjie Liao, Leonid Sigal","Self-Supervised Relation Alignment for Scene Graph Generation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of scene graph generation is to predict a graph from an input image,
where nodes correspond to identified and localized objects and edges to their
corresponding interaction predicates. Existing methods are trained in a fully
supervised manner and focus on message passing mechanisms, loss functions,
and/or bias mitigation. In this work we introduce a simple-yet-effective
self-supervised relational alignment regularization designed to improve the
scene graph generation performance. The proposed alignment is general and can
be combined with any existing scene graph generation framework, where it is
trained alongside the original model's objective. The alignment is achieved
through distillation, where an auxiliary relation prediction branch, that
mirrors and shares parameters with the supervised counterpart, is designed. In
the auxiliary branch, relational input features are partially masked prior to
message passing and predicate prediction. The predictions for masked relations
are then aligned with the supervised counterparts after the message passing. We
illustrate the effectiveness of this self-supervised relational alignment in
conjunction with two scene graph generation architectures, SGTR and Neural
Motifs, and show that in both cases we achieve significantly improved
performance.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:34:13 GMT""}]","2023-02-06"
"2302.01404","Suhas Kotha","Suhas Kotha, Christopher Brix, Zico Kolter, Krishnamurthy Dvijotham,
  Huan Zhang","Provably Bounding Neural Network Preimages",,,,,"cs.LG cs.AI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most work on the formal verification of neural networks has focused on
bounding forward images of neural networks, i.e., the set of outputs of a
neural network that correspond to a given set of inputs (for example, bounded
perturbations of a nominal input). However, many use cases of neural network
verification require solving the inverse problem, i.e, over-approximating the
set of inputs that lead to certain outputs. In this work, we present the first
efficient bound propagation algorithm, INVPROP, for verifying properties over
the preimage of a linearly constrained output set of a neural network, which
can be combined with branch-and-bound to achieve completeness. Our efficient
algorithm allows multiple passes of intermediate bound refinements, which are
crucial for tight inverse verification because the bounds of an intermediate
layer depend on relaxations both before and after this layer. We demonstrate
our algorithm on applications related to quantifying safe control regions for a
dynamical system and detecting out-of-distribution inputs to a neural network.
Our results show that in certain settings, we can find over-approximations that
are over 2500 times tighter than prior work while being 2.5 times faster on the
same hardware.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:34:45 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 16:54:46 GMT""}]","2023-02-08"
"2302.01405","Erik Demaine","Josh Brunner, Lily Chung, Michael Coulombe, Erik D. Demaine, Timothy
  Gomez, Jayson Lynch","Complexity of Solo Chess with Unlimited Moves","22 pages, 9 figures. Presented at JCDCGGG 2022",,,,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze Solo Chess puzzles, where the input is an $n \times n$ board
containing some standard Chess pieces of the same color, and the goal is to
make a sequence of capture moves to reduce down to a single piece. Prior work
analyzes this puzzle for a single piece type when each piece is limited to make
at most two capture moves (as in the Solo Chess puzzles on chess.com). By
contrast, we study when each piece can make an unlimited number of capture
moves. We show that any single piece type can be solved in polynomial time in a
general model of piece types, while any two standard Chess piece types are
NP-complete. We also analyze the restriction (as on chess.com) that one piece
type is unique and must be the last surviving piece, showing that in this case
some pairs of piece types become tractable while others remain hard.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:40:43 GMT""}]","2023-02-06"
"2302.01406","Maurizio De Sanctis","M. De Sanctis","The role of scalar and mass interactions in a relativistic model of the
  charmonium spectrum","20 pages",,"10.5506/APhysPolB.54.1-A2",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Lorentz scalar and mass interactions are studied in more detail in the
framework of a reduced Dirac equation for heavy quark-antiquark mesons. A
microscopic model for these interactions is proposed and analyzed. The
charmonium mass spectrum is reproduced by means of two free parameters; a third
parameter is fixed by means of a phenomenological hypothesis in accordance with
the model.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:42:34 GMT""},{""version"":""v2"",""created"":""Sat, 11 Feb 2023 00:05:13 GMT""}]","2023-02-22"
"2302.01407","Wolfgang Messner","Wolfgang Messner","Hypothesis Testing and Machine Learning: Interpreting Variable Effects
  in Deep Artificial Neural Networks using Cohen's f2","16 pages, 2 figures, 4 tables",,,,"stat.ME cs.AI cs.LG stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep artificial neural networks show high predictive performance in many
fields, but they do not afford statistical inferences and their black-box
operations are too complicated for humans to comprehend. Because positing that
a relationship exists is often more important than prediction in scientific
experiments and research models, machine learning is far less frequently used
than inferential statistics. Additionally, statistics calls for improving the
test of theory by showing the magnitude of the phenomena being studied. This
article extends current XAI methods and develops a model agnostic hypothesis
testing framework for machine learning. First, Fisher's variable permutation
algorithm is tweaked to compute an effect size measure equivalent to Cohen's f2
for OLS regression models. Second, the Mann-Kendall test of monotonicity and
the Theil-Sen estimator is applied to Apley's accumulated local effect plots to
specify a variable's direction of influence and statistical significance. The
usefulness of this approach is demonstrated on an artificial data set and a
social survey with a Python sandbox implementation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:43:37 GMT""}]","2023-02-06"
"2302.01408","Mariana Rossi","Sharon Hammes-Schiffer, Nancy Makri, Mariana Rossi","Simulating Nuclear Dynamics with Quantum Effects",,,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper, part of a Roadmap article, provides an account of the status and
the current challenges in the area of nuclear quantum dynamics simulations, and
presents advances in theory and computational techniques to address these
challenges.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:45:20 GMT""}]","2023-02-06"
"2302.01409","Fangzhou Lin","Yun Yue, Fangzhou Lin, Kazunori D Yamada, Ziming Zhang","Hyperbolic Contrastive Learning",,,,,"cs.CV cs.LG","http://creativecommons.org/publicdomain/zero/1.0/","  Learning good image representations that are beneficial to downstream tasks
is a challenging task in computer vision. As such, a wide variety of
self-supervised learning approaches have been proposed. Among them, contrastive
learning has shown competitive performance on several benchmark datasets. The
embeddings of contrastive learning are arranged on a hypersphere that results
in using the inner (dot) product as a distance measurement in Euclidean space.
However, the underlying structure of many scientific fields like social
networks, brain imaging, and computer graphics data exhibit highly
non-Euclidean latent geometry. We propose a novel contrastive learning
framework to learn semantic relationships in the hyperbolic space. Hyperbolic
space is a continuous version of trees that naturally owns the ability to model
hierarchical structures and is thus beneficial for efficient contrastive
representation learning. We also extend the proposed Hyperbolic Contrastive
Learning (HCL) to the supervised domain and studied the adversarial robustness
of HCL. The comprehensive experiments show that our proposed method achieves
better results on self-supervised pretraining, supervised classification, and
higher robust accuracy than baseline methods.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:47:45 GMT""}]","2023-02-06"
"2302.01410","Benjamin Boutin","Benjamin Boutin, Pierre Le Barbenchon, Nicolas Seguin","Stability of finite difference schemes for the hyperbolic initial
  boundary value problem by winding number computations","arXiv admin note: text overlap with arXiv:2207.10978",,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-sa/4.0/","  In this paper, we present a numerical strategy to check the strong stability
(or GKS-stability) of one-step explicit finite difference schemes for the
one-dimensional advection equation with an inflow boundary condition. The
strong stability is studied using the Kreiss-Lopatinskii theory. We introduce a
new tool, the intrinsic Kreiss-Lopatinskii determinant, which possesses the
same regularity as the vector bundle of discrete stable solutions. By applying
standard results of complex analysis to this determinant, we are able to relate
the strong stability of numerical schemes to the computation of a winding
number, which is robust and cheap. The study is illustrated with the O3 scheme
and the fifth-order Lax-Wendroff (LW5) scheme together with a reconstruction
procedure at the boundary.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:50:57 GMT""}]","2023-02-06"
"2302.01411","Roozbeh Tabrizian","Faysal Hakim, Nicholas Rudawski, Troy Tharpe, Roozbeh Tabrizian","The Ferroelectric-Gate Fin Microwave Acoustic Signal Processor",,,,,"physics.app-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Wireless communication through dynamic spectrum allocation over microwave
bands, essential to accommodate exponentially growing data traffic, requires
massive array of radio-frequency (RF) filters for adaptive signal shaping at
arbitrary frequencies. However, conventional RF filters based on planar
acoustic resonators are incapable to realize such massive integrated arrays,
due to their large footprint and limited on-chip frequency scalability. Here,
we present a signal processor enabled by integration of three-dimensional
ferroelectric-gate fin (FGF) nano-acoustic resonators with extreme frequency
tailorability and large-scale integrability. FGFs are created by growing
atomic-layered ferroelectric hafnia-zirconia transducers on silicon nano-fins,
operate in bulk acoustic modes with lithographically scalable frequency over
3-28 GHz, and provide record high frequency - quality factor -
electromechanical coupling product (f.Q.kt2) of 19.4 x 1010 (at ~11GHz). A
monolithic filter-array covering 9-12 GHz is also demonstrated by on-chip
electrical coupling of FGFs. This demonstration highlights the potential of FGF
resonators to realize chip-scale adaptive processors extendable to
millimeter-wave frequencies.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:56:18 GMT""}]","2023-02-06"
"2302.01412","Alexander Katsevich","Alexander Katsevich","Analysis of view aliasing for the generalized Radon transform in
  $\mathbb R^2$",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the generalized Radon transform $\mathcal R$ in the
plane. Let $f$ be a piecewise smooth function, which has a jump across a
smooth, convex curve $\mathcal S$. We obtain a precise, quantitative formula
describing view aliasing artifacts when $f$ is reconstructed from the data
$\mathcal R f$ discretized in the view direction. The formula is asymptotic, it
is established in the limit as the sampling rate $\epsilon\to0$. The proposed
approach does not require that $f$ be band-limited. Numerical experiments with
the classical Radon transform and generalized Radon transform (which integrates
over circles) demonstrate the accuracy of the formula.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:56:31 GMT""}]","2023-02-06"
"2302.01413","Elliott Holliday","Elliott G. Holliday, John F. Lindner, William L. Ditto","Solving two-dimensional quantum eigenvalue problems using
  physics-informed machine learning",,,,,"physics.comp-ph quant-ph","http://creativecommons.org/licenses/by/4.0/","  A particle confined to an impassable box is a paradigmatic and exactly
solvable one-dimensional quantum system modeled by an infinite square well
potential. Here we explore some of its infinitely many generalizations to two
dimensions, including particles confined to rectangle, elliptic, triangle, and
cardioid-shaped boxes, using physics-informed neural networks. In particular,
we generalize an unsupervised learning algorithm to find the particles'
eigenvalues and eigenfunctions. During training, the neural network adjusts its
weights and biases, one of which is the energy eigenvalue, so its output
approximately solves the Schr\""odinger equation with normalized and mutually
orthogonal eigenfunctions. The same procedure solves the Helmholtz equation for
the harmonics and vibration modes of waves on drumheads or transverse magnetic
modes of electromagnetic cavities. Related applications include dynamical
billiards, quantum chaos, and Laplacian spectra.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:57:15 GMT""}]","2023-02-06"
"2302.01414","Edit Matyus","Gustavo Avila, Alberto Mart\'in Santa Dar\'ia, Edit M\'atyus","Vibrational infrared and Raman spectrum of HCOOH from variational
  computations",,,,,"physics.chem-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  All vibrational energies of the (trans-, cis-, delocalized-) formic acid
molecule are converged up to 4500 cm$^{-1}$ beyond the zero-point vibrational
energy with the GENIUSH-Smolyak variational approach and using an ab initio
potential energy surface [D. P. Tew and W. Mizukami, J. Phys. Chem. A, 120,
9815-9828 (2016)]. Full-dimensional dipole and polarizability surfaces are
fitted to points computed at the CCSD/aug-cc-pVTZ level of theory. Then,
body-fixed vibrational dipole and polarizability transition moments are
evaluated and used to simulate jet-cooled infrared and Raman spectra of HCOOH.
The benchmark-quality vibrational energy, transition moment, and wave function
list will be used in further work in comparison with vibrational experiments,
and in further rovibrational computations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:00:27 GMT""},{""version"":""v2"",""created"":""Fri, 14 Apr 2023 17:45:21 GMT""}]","2023-04-17"
"2302.01415","Birthe van den Berg","Birthe van den Berg and Tom Schrijvers","A Framework for Higher-Order Effects & Handlers",,,,,"cs.PL cs.LO","http://creativecommons.org/licenses/by/4.0/","  Algebraic effects & handlers are a modular approach for modeling side-effects
in functional programming. Their syntax is defined in terms of a signature of
effectful operations, encoded as a functor, that are plugged into the free
monad; their denotational semantics is defined by fold-style handlers that only
interpret their part of the syntax and forward the rest. However, not all
effects are algebraic: some need to access an internal computation. For
example, scoped effects distinguish between a computation in scope and out of
scope; parallel effects parallellize over a computation, latent effects defer a
computation. Separate definitions have been proposed for these higher-order
effects and their corresponding handlers, often leading to expedient and
complex monad definitions. In this work we propose a generic framework for
higher-order effects, generalizing algebraic effects & handlers: a generic free
monad with higher-order effect signatures and a corresponding interpreter.
Specializing this higher-order syntax leads to various definitions of
previously defined (scoped, parallel, latent) and novel (writer, bracketing)
effects. Furthermore, we formally show our framework theoretically correct,
also putting different effect instances on formal footing; a significant
contribution for parallel, latent, writer and bracketing effects.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:03:30 GMT""}]","2023-02-06"
"2302.01416","Fanjie Kong","Fanjie Kong, Yuan Li, Houssam Nassif, Tanner Fiez, Ricardo Henao,
  Shreya Chakrabarti","Neural Insights for Digital Marketing Content Design",,,"10.1145/3580305.3599875",,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In digital marketing, experimenting with new website content is one of the
key levers to improve customer engagement. However, creating successful
marketing content is a manual and time-consuming process that lacks clear
guiding principles. This paper seeks to close the loop between content creation
and online experimentation by offering marketers AI-driven actionable insights
based on historical data to improve their creative process. We present a
neural-network-based system that scores and extracts insights from a marketing
content design, namely, a multimodal neural network predicts the attractiveness
of marketing contents, and a post-hoc attribution method generates actionable
insights for marketers to improve their content in specific marketing
locations. Our insights not only point out the advantages and drawbacks of a
given current content, but also provide design recommendations based on
historical data. We show that our scoring model and insights work well both
quantitatively and qualitatively.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:04:47 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 00:54:58 GMT""},{""version"":""v3"",""created"":""Wed, 7 Jun 2023 20:23:14 GMT""}]","2023-06-09"
"2302.01417","Nelly Elsayed","Shrish Pellakur, Nelly Elsayed, Zag ElSayed, Murat Ozer","A Convolutional-based Model for Early Prediction of Alzheimer's based on
  the Dementia Stage in the MRI Brain Images","Short paper, Under Review in FLAIRS-36",,,,"cs.LG cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alzheimer's disease is a degenerative brain disease. Being the primary cause
of Dementia in adults and progressively destroys brain memory. Though
Alzheimer's disease does not have a cure currently, diagnosing it at an earlier
stage will help reduce the severity of the disease. Thus, early diagnosis of
Alzheimer's could help to reduce or stop the disease from progressing. In this
paper, we proposed a deep convolutional neural network-based model for learning
model using to determine the stage of Dementia in adults based on the Magnetic
Resonance Imaging (MRI) images to detect the early onset of Alzheimer's.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:10:31 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 23:54:18 GMT""}]","2023-02-17"
"2302.01418","Eric Vasserot","Michela Varagnolo, Eric Vasserot","Critical convolution algebras and quantum loop groups","57 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new family of algebras attached to quivers with potentials,
using critical K-theory and critical Borel-Moore homology, which generalizes
the convolution algebras attached to quivers defined by Nakajima. We give some
applications to representations of quantum loop groups and shifted quantum loop
groups, in particular to Kirillov-Reshetikhin and prefundamental
representations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:11:17 GMT""},{""version"":""v2"",""created"":""Sun, 2 Apr 2023 16:18:11 GMT""},{""version"":""v3"",""created"":""Sat, 20 May 2023 09:32:24 GMT""}]","2023-05-23"
"2302.01419","Saman Zare","Saman Zare, Ramin Pouria, Philippe K. Chow, Tom Tiwald, Carl P. Tripp,
  Sheila Edalatpour","Probing Near-Field Thermal Emission of Localized Surface Phonons from
  Silicon Carbide Nanopillars",,,,,"cond-mat.mes-hall physics.app-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal emission of localized surface phonons (LSPhs) from nanostructures of
polaritonic materials is a promising mechanism for tuning the spectrum of
near-field thermal radiation. Previous studies have theoretically shown that
thermal emission of LSPhs results in narrow-band peaks in the near-field
spectra, whose spectral locations can be modulated by changing the dimensions
of the nanostructure. However, near-field thermal emission of LSPhs has not
been experimentally explored yet. In this study, we measure the spectrum of
near-field thermal radiation from arrays of 6H-silicon carbide (6H-SiC)
nanopillars using an internal-reflection-element based spectroscopy technique.
We present an experimental demonstration of thermal emission of the transverse
dipole, quadrupole, and octupole, as well as longitudinal monopole from 6H-SiC
nanopillars at a near-field distance from the array. We show that the spectral
location of the longitudinal monopole and transverse dipole are significantly
affected by the near-field coupling between neighboring nanopillars as well as
the intercoupling of the nanopillars and the substrate. We also experimentally
demonstrate that the spectrum of near-field thermal radiation from 6H-SiC
nanopillar arrays can be tuned by varying the dimensions of the nanopillars,
providing an opportunity for designing emitters with tailored near-field
thermal radiation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:14:39 GMT""}]","2023-02-06"
"2302.01420","Tingfeng Yi PhD","X. Chang, T. F. Yi, D. R. Xiong, C. X. Liu, X. Yang, H. Z. Li, Y. L.
  Gong, W. W. Na, Y. Li, Z. H. Chen, J. P. Chen, L. S. Mao","Multicolour Optical Variability Monitoring of Blazars with High Time
  Resolution","18 pages, 8 figures, accepted in MNRAS",,"10.1093/mnras/stad409",,"astro-ph.HE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We carried out a high time-resolution, multicolour optical observing campaign
for eight $\gamma$-ray detected blazars during 2010-2020. We analyze flux
variations, correlations between magnitudes and colours on different
timescales. Intraday variability (IDV) is detected in all eight sources of our
sample. A bluer-when-brighter (BWB) chromatic trend is dominant on intraday
timescales. On the short timescales, the BWB trend only shows up in ON 231, 3C
279, BL Lacertae and 1E 1458.8+2249. There is a BWB trend in 3C 279 on the long
timescale. We estimate the upper limits of black hole mass for three blazars
(i.e. ON 321, 1ES 1426+42.8, PKS 1510-089) using variability timescales. On
April 13, 2010 a potential quasi-periodic oscillation (QPO) with the period of
$P=48.67\pm13.90$ minutes is found in 1ES 1426+42.8. The light curve on March
16, 2021 further shows the existence of the QPO phenomenon. The QPO in this
target deserves further observation and confirmation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:18:06 GMT""}]","2023-02-15"
"2302.01421","Chinmay Maheshwari","Chinmay Maheshwari and S. Shankar Sasty and Lillian Ratliff and Eric
  Mazumdar","Follower Agnostic Methods for Stackelberg Games","21 pages",,,,"math.OC cs.AI cs.GT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an algorithm to solve a class of Stackelberg games (possibly with
multiple followers) in a follower agnostic manner. Particularly, unlike other
contemporary works, our algorithm does not require the use of an oracle
estimator for the gradient of the leader's objective or knowledge about the
follower's utility function or strategy space. Instead, we design two-loop
algorithm where the leader updates its strategies using specially constructed
gradient estimator obtained by probing followers with specially designed
strategies. Upon receiving the followers engage in an adaptation rule such that
the joint strategy of followers converges near equilibrium which is the only
information observed by leader to construct the aforementioned gradient
estimator. We provide non-asymptotic convergence rates to stationary points of
the leader's objective in the absence of convexity of the closed-loop function
and further show asymptotic convergence to a local minima of the leader's
objective.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:21:14 GMT""},{""version"":""v2"",""created"":""Wed, 24 May 2023 17:43:37 GMT""}]","2023-05-25"
"2302.01422","Erik Mainellis","Erik Mainellis","Characterizing Nilpotent Associative Algebras by Their Multiplier","9 pages",,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper concerns an analogue of the famous Schur multiplier in the context
of associative algebras and a measure of how far its dimension is from being
maximal. Applying a methodology from Lie theory, we characterize all
finite-dimensional nilpotent associative algebras for which this measure is ten
or less.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:24:55 GMT""}]","2023-02-06"
"2302.01423","Ayana Sarkar","Ayana Sarkar, Sunidhi Sen and Santosh Kumar","Spectral crossover in non-hermitian spin chains: comparison with random
  matrix theory","15 Pages, 16 figures",,,,"quant-ph cond-mat.dis-nn nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematically study the short range spectral fluctuation properties of
three non-hermitian spin chain hamiltonians using complex spacing ratios. In
particular we focus on the non-hermitian version of the standard
one-dimensional anisotropic XY model having intrinsic rotation-time-reversal
($\mathcal{RT}$) symmetry that has been explored analytically by Zhang and Song
in [Phys.Rev.A {\bf 87}, 012114 (2013)]. The corresponding hermitian
counterpart is also exactly solvable and has been widely employed as a toy
model in several condensed matter physics problems. We show that the presence
of a random field along the $x$-direction together with the one along $z$
facilitates integrability and $\mathcal{RT}$-symmetry breaking leading to the
emergence of quantum chaotic behaviour indicated by a spectral crossover
resembling Poissonian to Ginibre unitary ensemble (GinUE) statistics of random
matrix theory. Additionally, we consider two $n \times n$ dimensional
phenomenological random matrix models in which, depending upon crossover
parameters, the fluctuation properties measured by the complex spacing ratios
show an interpolation between 1D-Poisson to GinUE and 2D-Poisson to GinUE
behaviour. Here 1D and 2D Poisson correspond to real and complex uncorrelated
levels, respectively.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:26:44 GMT""},{""version"":""v2"",""created"":""Sun, 19 Feb 2023 13:50:30 GMT""}]","2023-02-21"
"2302.01424","Mohammadali Ghafarian Dr","Mohammadali Ghafarian, Bijan Shirinzadeh, Ammar Al-Jodah","Monolithic Six-DOF Parallel Positioning System for High-precision and
  Large-range Applications","This work has been submitted elsewhere for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  A compact large-range six-degrees-of-freedom (six-DOF) parallel positioning
system with high resolution, high resonant frequency, and high repeatability
was proposed. It mainly consists of three identical kinematic sections. Each
kinematic section consists of two identical displacement amplification and
guiding mechanisms, which are finally connected to a limb. Each limb was
designed with a universal joint at each end and connected to a moving stage. A
computational model of the positioner was built in the ANSYS software package,
hence, the input stiffness, output compliance, range, and modal analysis of the
system were found. Furthermore, a monolithic prototype made of Acrylonitrile
Butadiene Styrene (ABS) was successfully manufactured by the 3D-printing
process. It was actuated and sensed by piezoelectric actuators (PEAs) and
capacitive displacement sensors, respectively. Finally, the performances of
this proposed positioner were experimentally investigated. The positioning
resolution was achieved as 10.5nm {\times} 10.5nm {\times} 15nm {\times}
1.8{\mu}rad {\times} 1.3{\mu}rad {\times} 0.5{\mu}rad. The experimental results
validate the behavior and capabilities of the proposed positioning system, and
also verify the nanometer-scale spatial positioning accuracy within the overall
stroke range. Practical applications of the proposed system can be expanded to
pick-and-place manipulation, vibration-canceling in
microsurgery/micro-assembly, and collaborative manipulators systems.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:30:23 GMT""}]","2023-02-06"
"2302.01425","Michael E. Sander","Michael E. Sander, Joan Puigcerver, Josip Djolonga, Gabriel Peyr\'e
  and Mathieu Blondel","Fast, Differentiable and Sparse Top-k: a Convex Analysis Perspective","ICML 2023 18 pages",,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  The top-k operator returns a sparse vector, where the non-zero values
correspond to the k largest values of the input. Unfortunately, because it is a
discontinuous function, it is difficult to incorporate in neural networks
trained end-to-end with backpropagation. Recent works have considered
differentiable relaxations, based either on regularization or perturbation
techniques. However, to date, no approach is fully differentiable and sparse.
In this paper, we propose new differentiable and sparse top-k operators. We
view the top-k operator as a linear program over the permutahedron, the convex
hull of permutations. We then introduce a p-norm regularization term to smooth
out the operator, and show that its computation can be reduced to isotonic
optimization. Our framework is significantly more general than the existing one
and allows for example to express top-k operators that select values in
magnitude. On the algorithmic side, in addition to pool adjacent violator (PAV)
algorithms, we propose a new GPU/TPU-friendly Dykstra algorithm to solve
isotonic optimization problems. We successfully use our operators to prune
weights in neural networks, to fine-tune vision transformers, and as a router
in sparse mixture of experts.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:32:13 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 18:34:36 GMT""},{""version"":""v3"",""created"":""Sun, 4 Jun 2023 07:58:10 GMT""}]","2023-06-06"
"2302.01426","Gino Biondini","Asela Abeya, Gino Biondini and Mark A. Hoefer","Whitham modulation theory for the defocusing nonlinear Schrodinger
  equation in two and three spatial dimensions","30 pages, no figures","J. Phys. A 56, 025701 (2023)","10.1088/1751-8121/acb117",,"nlin.PS","http://creativecommons.org/licenses/by/4.0/","  The Whitham modulation equations for the defocusing nonlinear Schrodinger
(NLS) equation in two, three and higher spatial dimensions are derived using a
two-phase ansatz for the periodic traveling wave solutions and by
period-averaging the conservation laws of the NLS equation. The resulting
Whitham modulation equations are written in vector form, which allows one to
show that they preserve the rotational invariance of the NLS equation, as well
as the invariance with respect to scaling and Galilean transformations, and to
immediately generalize the calculations from two spatial dimensions to three.
The transformation to Riemann-type variables is described in detail; the
harmonic and soliton limits of the Whitham modulation equations are explicitly
written down; and the reduction of the Whitham equations to those for the
radial NLS equation is explicitly carried out. Finally, the extension of the
theory to higher spatial dimensions is briefly outlined. The multidimensional
NLS-Whitham equations obtained here may be used to study large amplitude
wavetrains in a variety of applications including nonlinear photonics and
matter waves.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:33:23 GMT""}]","2023-02-06"
"2302.01427","Franziska Schirrmacher","Franziska Schirrmacher, Benedikt Lorch, Anatol Maier, Christian Riess","Benchmarking Probabilistic Deep Learning Methods for License Plate
  Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning-based algorithms for automated license plate recognition implicitly
assume that the training and test data are well aligned. However, this may not
be the case under extreme environmental conditions, or in forensic applications
where the system cannot be trained for a specific acquisition device.
Predictions on such out-of-distribution images have an increased chance of
failing. But this failure case is oftentimes hard to recognize for a human
operator or an automated system. Hence, in this work we propose to model the
prediction uncertainty for license plate recognition explicitly. Such an
uncertainty measure allows to detect false predictions, indicating an analyst
when not to trust the result of the automated license plate recognition. In
this paper, we compare three methods for uncertainty quantification on two
architectures. The experiments on synthetic noisy or blurred low-resolution
images show that the predictive uncertainty reliably finds wrong predictions.
We also show that a multi-task combination of classification and
super-resolution improves the recognition performance by 109\% and the
detection of wrong predictions by 29 %.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:37:42 GMT""}]","2023-02-06"
"2302.01428","Ramin Hasani","Noel Loo, Ramin Hasani, Mathias Lechner, Daniela Rus","Dataset Distillation Fixes Dataset Reconstruction Attacks",,,,,"cs.LG cs.AI cs.NE stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Modern deep learning requires large volumes of data, which could contain
sensitive or private information which cannot be leaked. Recent work has shown
for homogeneous neural networks a large portion of this training data could be
reconstructed with only access to the trained network parameters. While the
attack was shown to work empirically, there exists little formal understanding
of its effectiveness regime, and ways to defend against it. In this work, we
first build a stronger version of the dataset reconstruction attack and show
how it can provably recover its entire training set in the infinite width
regime. We then empirically study the characteristics of this attack on
two-layer networks and reveal that its success heavily depends on deviations
from the frozen infinite-width Neural Tangent Kernel limit. More importantly,
we formally show for the first time that dataset reconstruction attacks are a
variation of dataset distillation. This key theoretical result on the
unification of dataset reconstruction and distillation not only sheds more
light on the characteristics of the attack but enables us to design defense
mechanisms against them via distillation algorithms.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:41:59 GMT""}]","2023-02-06"
"2302.01429","Hao Zhang","Hao Zhang, Xinyi Wang, Jiarui Zhang, Hai-Bin Yu, Jack F. Douglas","Approach to Hyperuniformity in a Metallic Glass-Forming Material
  Exhibiting a Fragile to Strong Glass Transition",,,,,"cond-mat.soft cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We investigate a metallic glass-forming (GF) material (Al90Sm10) exhibiting a
fragile-strong (FS) glass-formation by molecular dynamics simulation to better
understand this highly distinctive pattern of glass-formation in which many of
the usual phenomenological relations describing relaxation times and diffusion
of OGF liquids no longer apply, and where instead genuine thermodynamic
features are observed in response functions and little thermodynamic signature
is exhibited at the glass transition temperature, Tg. Given the many unexpected
similarities between the thermodynamics and dynamics of this metallic GF
material with water, we first focus on the anomalous static scattering in this
liquid, following recent studies on water, silicon and other FS GF liquids. In
particular, we quantify the 'hyperuniformity index' H of our liquid which
provides a quantitative measure of molecular 'jamming'. To gain insight into
the T-dependence and magnitude of H, we also estimated another more familiar
measure of particle localization, the Debye-Waller parameter $<u^2>$ describing
the mean-square particle displacement on a timescale on the order of the fast
relaxation time, and we also calculate H and $<u^2>$ for heated crystalline Cu.
This comparative analysis between H and $<u^2>$ for crystalline and metallic
glass materials allows us to understand the critical value of H on the order of
$10^{-3}$ as being analogous to the Lindemann criterion for both the melting of
crystals and the 'softening' of glasses. We further interpret the emergence of
FS GF and liquid-liquid phase separation in this class of liquids to arise from
a cooperative assembly process in the GF liquid.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:43:15 GMT""},{""version"":""v2"",""created"":""Sat, 18 Feb 2023 21:24:59 GMT""},{""version"":""v3"",""created"":""Tue, 30 May 2023 19:38:06 GMT""}]","2023-06-01"
"2302.01430","Guangwei Yang","Guangwei Yang, Qiao Cheng, Jianying Li, Shuai Zhang, Senior Member,
  Steven Gao, and Xiaodong Chen","A Multifunctional Array System Based on Adjustable-Phase Antenna for
  Wireless Communications",,,"10.1109/TAP.2023.3243987",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, an innovative method for controlling the current distribution
of the radiating patch by adjusting the input phase is investigated to achieve
both pattern and polarization reconfigurable characteristics for the
multifunction. A compact and low-profile antenna with four fed ports is
designed to implement the proposed method, which can operate linear, right-hand
circular polarization (RHCP) and left-hand circular polarization (LHCP) with
different beam directions in the operating band from 4.0 to 5.0 GHz. Even more,
a four-by-four passive planar array is designed and fabricated based on this
antenna element, which can scan the coverage of 70{\deg} with low gain
fluctuation and low sidelobe with dual-polarization. Meanwhile, it can realize
the wide-angle scanning capability up to 60{\deg} with low sidelobe with RHCP
and LHCP. More important, the dual- and triple-beam with different directions
can be obtained by the proposed array. Good agreement has been shown between
measured and simulated results. Therefore, the proposed antenna is a good
solution for wireless communication systems because of its
simple-configuration, multifunction, and beamforming capability.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:44:47 GMT""}]","2023-05-17"
"2302.01431","Karim Johannes Becher","Karim Johannes Becher","Fields with bounded Brauer $2$-torsion index",,,"10.1007/s00208-023-02566-1",,"math.RA math.KT math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that, over a field of characteristic not $2$, the dimension of an
anisotropic quadratic Pfister form of trivial total signature is at most twice
the dimension of some central division algebra of exponent $2$. The proof is
based on computations with quadratic trace forms of central simple algebras.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:50:38 GMT""}]","2023-02-06"
"2302.01432","Slobodan Zdravkovi\'c","Slobodan Zdravkovi\'c and Slobodan Zekovi\'c","Tangential Model of Microtubules","5 pages, 2 figures, 15th International Conference on Fundamental and
  Applied Aspects of Physical Chemistry, September 20-24, 2021, Belgrade,
  Serbia","Volume I, page 265; ISBN 978-86-82475-38-5; 2021",,,"physics.bio-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Microtubules (MTs) represent basic components of a cytoskeleton. The present
work studies nonlinear dynamics of MTs assuming tangential oscillations of the
dimers. We introduce a two component model and show that the dynamics of MTs
can be explained in terms of breather solitary waves.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:52:32 GMT""}]","2023-02-06"
"2302.01433","Giovanni Rosotti","Giovanni P. Rosotti","Empirical constraints on turbulence in proto-planetary discs","24 pages, 7 figures. Accepted for publication on New Astronomy
  Reviews; small changes following community feedback in v2",,"10.1016/j.newar.2023.101674",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Proto-planetary discs, the birth environment of planets, are an example of a
structure commonly found in astrophysics, accretion discs. Identifying the
mechanism responsible for accretion is a long-standing problem, dating back
several decades. The common picture is that accretion is a consequence of
turbulence, with several instabilities proposed for its origin. While
traditionally this field used to be a purely theoretical endeavour, the
landscape is now changing thanks mainly to new observational facilities such as
the ALMA radio interferometer. Thanks to large improvements in spatial and
spectral resolution and sensitivity (which have enabled the study of disc
substructure, kinematics and surveys of large disc populations), multiple
techniques have been devised to observationally measure the amount of
turbulence in discs. This review summarises these techniques, ranging from
attempts at direct detection of turbulence from line broadening, to more
indirect approaches that rely on properties of the dust or consider the
evolution of global disc properties (such as masses, radii and accretion rates)
for large samples, and what their findings are. Multiple lines of evidence
suggest that discs are in fact not as turbulent as thought one decade ago. On
the other hand, direct detection of turbulence in some discs and the finite
radial extent of dust substructures and in some cases the finite vertical
extent strongly indicate that turbulence must be present at some level in
proto-planetary discs. It is still an open question whether this amount of
turbulence is enough to power accretion or if this is instead driven by other
mechanisms, such as MHD winds.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:55:18 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 09:15:07 GMT""}]","2023-04-04"
"2302.01434","Stephan Smeekes","Alain Hecq, Luca Margaritella and Stephan Smeekes","Inference in Non-stationary High-Dimensional VARs",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  In this paper we construct an inferential procedure for Granger causality in
high-dimensional non-stationary vector autoregressive (VAR) models. Our method
does not require knowledge of the order of integration of the time series under
consideration. We augment the VAR with at least as many lags as the suspected
maximum order of integration, an approach which has been proven to be robust
against the presence of unit roots in low dimensions. We prove that we can
restrict the augmentation to only the variables of interest for the testing,
thereby making the approach suitable for high dimensions. We combine this lag
augmentation with a post-double-selection procedure in which a set of initial
penalized regressions is performed to select the relevant variables for both
the Granger causing and caused variables. We then establish uniform asymptotic
normality of a second-stage regression involving only the selected variables.
Finite sample simulations show good performance, an application to investigate
the (predictive) causes and effects of economic uncertainty illustrates the
need to allow for unknown orders of integration.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:56:36 GMT""}]","2023-02-06"
"2302.01435","Tong Lin","Tong Lin, Sijie Chen, Ruchira Basu, Dehu Pei, Xiaolin Cheng and Levent
  Burak Kara","Target specific peptide design using latent space approximate trajectory
  collector",,,,,"cs.CE cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Despite the prevalence and many successes of deep learning applications in de
novo molecular design, the problem of peptide generation targeting specific
proteins remains unsolved. A main barrier for this is the scarcity of the
high-quality training data. To tackle the issue, we propose a novel machine
learning based peptide design architecture, called Latent Space Approximate
Trajectory Collector (LSATC). It consists of a series of samplers on an
optimization trajectory on a highly non-convex energy landscape that
approximates the distributions of peptides with desired properties in a latent
space. The process involves little human intervention and can be implemented in
an end-to-end manner. We demonstrate the model by the design of peptide
extensions targeting Beta-catenin, a key nuclear effector protein involved in
canonical Wnt signalling. When compared with a random sampler, LSATC can sample
peptides with $36\%$ lower binding scores in a $16$ times smaller interquartile
range (IQR) and $284\%$ less hydrophobicity with a $1.4$ times smaller IQR.
LSATC also largely outperforms other common generative models. Finally, we
utilized a clustering algorithm to select 4 peptides from the 100 LSATC
designed peptides for experimental validation. The result confirms that all the
four peptides extended by LSATC show improved Beta-catenin binding by at least
$20.0\%$, and two of the peptides show a $3$ fold increase in binding affinity
as compared to the base peptide.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:56:52 GMT""}]","2023-02-06"
"2302.01436","Marcio Catelan","M. Catelan (PUC-Chile, MAS)","Stellar Variability in Ground-Based Photometric Surveys: An Overview","Invited review, to appear in Mem. Soc. Astr. Italiana",,,,"astro-ph.SR astro-ph.EP astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-resolved ground-based surveys in general, and photometric ones in
particular, have played a crucial role in building up our knowledge of the
properties, physical nature, and the very existence of the many different
classes of variable stars and transient events that are currently known. Here I
provide a brief overview of these developments, discussing some of the
stumbling blocks that had to be overcome along the way, and others that may
still hamper further progress in the area. A compilation of different types of
past, present, and future surveys is also provided.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:57:48 GMT""}]","2023-02-06"
"2302.01437","Hung Nguyen-Kha","Hung Nguyen-Kha, Vu Nguyen Ha, Eva Lagunas, Symeon Chatzinotas, Joel
  Grotz","LEO-to-User Assignment and Resource Allocation for Uplink Transmit Power
  Minimization",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper aims to develop satellite-user association and resource allocation
mechanisms to minimize the total transmit power for integrated terrestrial and
non-terrestrial networks wherein a constellation of LEO satellites provides the
radio access services to both terrestrial base stations (BSs) and the
satellite-enabled users (SUEs). In this work, beside maintaining the
traditional SatCom connection for SUEs, the LEO satellites provide backhaul
links to the BSs to upload the data received from their ground customers.
Taking the individual SUE traffic demands and the aggregated BS demands, we
formulate a mixed integer programming which consists of the binary variables
due to satellite association selection, power control and bandwidth allocation
related variables. To cope with this challenging problem, an iterative
optimization-based algorithm is proposed by relaxing the binary components and
alternating updating all variables. A greedy mechanism is also presented for
comparison purpose. Then, numerical results are presented to confirm the
effectiveness of our proposed algorithms.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:57:59 GMT""}]","2023-02-06"
"2302.01439","Ashwin Rao","Rong-Ching Chang, Ashwin Rao, Qiankun Zhong, Magdalena Wojcieszak and
  Kristina Lerman","#RoeOverturned: Twitter Dataset on the Abortion Rights Controversy","9 pages, 5 figures",,,,"cs.CY cs.SI","http://creativecommons.org/licenses/by/4.0/","  On June 24, 2022, the United States Supreme Court overturned landmark rulings
made in its 1973 verdict in Roe v. Wade. The justices by way of a majority vote
in Dobbs v. Jackson Women's Health Organization, decided that abortion wasn't a
constitutional right and returned the issue of abortion to the elected
representatives. This decision triggered multiple protests and debates across
the US, especially in the context of the midterm elections in November 2022.
Given that many citizens use social media platforms to express their views and
mobilize for collective action, and given that online debate provides tangible
effects on public opinion, political participation, news media coverage, and
the political decision-making, it is crucial to understand online discussions
surrounding this topic. Toward this end, we present the first large-scale
Twitter dataset collected on the abortion rights debate in the United States.
We present a set of 74M tweets systematically collected over the course of one
year from January 1, 2022 to January 6, 2023.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:02:19 GMT""}]","2023-02-06"
"2302.01440","Chengyu Dong","Chengyu Dong","Generalized Uncertainty of Deep Neural Networks: Taxonomy and
  Applications",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks have seen enormous success in various real-world
applications. Beyond their predictions as point estimates, increasing attention
has been focused on quantifying the uncertainty of their predictions. In this
review, we show that the uncertainty of deep neural networks is not only
important in a sense of interpretability and transparency, but also crucial in
further advancing their performance, particularly in learning systems seeking
robustness and efficiency. We will generalize the definition of the uncertainty
of deep neural networks to any number or vector that is associated with an
input or an input-label pair, and catalog existing methods on ``mining'' such
uncertainty from a deep model. We will include those methods from the classic
field of uncertainty quantification as well as those methods that are specific
to deep neural networks. We then show a wide spectrum of applications of such
generalized uncertainty in realistic learning tasks including robust learning
such as noisy learning, adversarially robust learning; data-efficient learning
such as semi-supervised and weakly-supervised learning; and model-efficient
learning such as model compression and knowledge distillation.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:02:33 GMT""}]","2023-02-06"
"2302.01441","Yiren Liu","Yiren Liu, Halil Kilicoglu","Commonsense-Aware Prompting for Controllable Empathetic Dialogue
  Generation","Accepted to Workshop on Knowledge Augmented Methods for Natural
  Language Processing, in conjunction with AAAI 2023",,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Improving the emotional awareness of pre-trained language models is an
emerging important problem for dialogue generation tasks. Although prior
studies have introduced methods to improve empathetic dialogue generation, few
have discussed how to incorporate commonsense knowledge into pre-trained
language models for controllable dialogue generation. In this study, we propose
a novel framework that improves empathetic dialogue generation using
pre-trained language models by 1) incorporating commonsense knowledge through
prompt verbalization, and 2) controlling dialogue generation using a
strategy-driven future discriminator. We conducted experiments to reveal that
both the incorporation of social commonsense knowledge and enforcement of
control over generation help to improve generation performance. Finally, we
discuss the implications of our study for future research.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:04:07 GMT""}]","2023-02-06"
"2302.01442","Valerio Faraoni","Valerio Faraoni and Julien Houle","More on the first-order thermodynamics of scalar-tensor and Horndeski
  gravity","10 pages, LaTeX",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two issues in the first-order thermodynamics of scalar-tensor (including
``viable'' Horndeski) gravity are elucidated. The application of this new
formalism to FLRW cosmology is shown to be fully legitimate and then extended
to all Bianchi universes. It is shown that the formalism holds thanks to the
almost miraculous fact that the constitutive relations of Eckart's
thermodynamics are satisfied, while writing the field equations as effective
Einstein equations with an effective dissipative fluid does not contain new
physics.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:13:08 GMT""}]","2023-02-06"
"2302.01443","Weihua Li","Mengyan Wang, Weihua Li, Jingli Shi, Shiqing Wu and Quan Bai","DOR: A Novel Dual-Observation-Based Approach for News Recommendation
  Systems",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Online social media platforms offer access to a vast amount of information,
but sifting through the abundance of news can be overwhelming and tiring for
readers. personalised recommendation algorithms can help users find information
that interests them. However, most existing models rely solely on observations
of user behaviour, such as viewing history, ignoring the connections between
the news and a user's prior knowledge. This can result in a lack of diverse
recommendations for individuals. In this paper, we propose a novel method to
address the complex problem of news recommendation. Our approach is based on
the idea of dual observation, which involves using a deep neural network with
observation mechanisms to identify the main focus of a news article as well as
the focus of the user on the article. This is achieved by taking into account
the user's belief network, which reflects their personal interests and biases.
By considering both the content of the news and the user's perspective, our
approach is able to provide more personalised and accurate recommendations. We
evaluate the performance of our model on real-world datasets and show that our
proposed method outperforms several popular baselines.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:16:53 GMT""}]","2023-02-06"
"2302.01444","A B M Rafi Sazzad","A. B. M. R. Sazzad, J. Busenitz, A. Piepke, S. Poudel, H. Trewin, A.
  LeViness","Design and characterization of AmLi neutron sources for the LZ
  experiment","20 pages, 13 figures, 4 tables, revised manuscripts after
  accommodating the reviewer's comments","2023 JINST 18 P05006","10.1088/1748-0221/18/05/P05006",,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  In this paper we describe the development, testing, and characterization of
three low-emission rate AmLi neutron sources. The sources are used to calibrate
the nuclear recoil response of the LUX-ZEPLIN (LZ) dark matter experiment. The
sources' neutron emission rate was measured using $^{3}$He proportional tubes.
The sources' gamma emissions were characterized using a high-purity germanium
(HPGe) detector. Source-validated GEANT4 Monte Carlo simulations allowed to
calibrate the Ge and neutron detector responses.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:23:35 GMT""},{""version"":""v2"",""created"":""Sat, 25 Mar 2023 19:26:43 GMT""}]","2023-05-09"
"2302.01445","Krist\'of B\'erczi","Krist\'of B\'erczi and Tam\'as Schwarcz","Partitioning into common independent sets via relaxing strongly base
  orderability","21 pages, 3 figures",,,,"math.CO cs.DM","http://creativecommons.org/licenses/by/4.0/","  The problem of covering the ground set of two matroids by a minimum number of
common independent sets is notoriously hard even in very restricted settings,
i.e.\ when the goal is to decide if two common independent sets suffice or not.
Nevertheless, as the problem generalizes several long-standing open questions,
identifying tractable cases is of particular interest. Strongly base orderable
matroids form a class for which a basis-exchange condition that is much
stronger than the standard axiom is met. As a result, several problems that are
open for arbitrary matroids can be solved for this class. In particular, Davies
and McDiarmid showed that if both matroids are strongly base orderable, then
the covering number of their intersection coincides with the maximum of their
covering numbers.
  Motivated by their result, we propose relaxations of strongly base
orderability in two directions. First we weaken the basis-exchange condition,
which leads to the definition of a new, complete class of matroids with
distinguished algorithmic properties. Second, we introduce the notion of
covering the circuits of a matroid by a graph, and consider the cases when the
graph is ought to be 2-regular or a path. We give an extensive list of results
explaining how the proposed relaxations compare to existing conjectures and
theorems on coverings by common independent sets.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:24:32 GMT""}]","2023-02-06"
"2302.01446","Gaven Martin Prof","Sayed Mohsen Hashemi and Gaven J. Martin","The Generic Failure of Lower-semicontinuity for the Linear Distortion
  Functional","9 figures",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the convexity properties of distortion functionals, particularly
the linear distortion, defined for homeomorphisms of domains in Euclidean
$n$-spaces, $n\geq 3$. The inner and outer distortion functionals are lower
semi-continuous in all dimensions and so for the curve modulus or analytic
definitions of quasiconformality it ifollows that if $ \{ f_{n}
\}_{n=1}^{\infty} $ is a sequence of $K$-quasiconformal mappings (here $K$
depends on the particular distortion functional but is the same for every
element of the sequence) which converges locally uniformly to a mapping $f$,
then this limit function is also $K$-quasiconformal.Despite a widespread belief
that this was also true for the geometric definition of quasiconformality
(defined through the linear distortion $H({f_{n}})$), T. Iwaniec gave a
specific and surprising example to show that the linear distortion functional
is not always lower semicontinuous on uniformly converging sequences of
quasiconformal mappings. Here we show that this failure of lower semicontinuity
is common, perhaps generic in the sense that under mild restrictions on a
quasiconformal $f$, there is a sequence $ \{f_{n} \}_{n=1}^{\infty} $ with $
{f_{n}}\to {f}$ locally uniformly and with $\limsup_{n\to\infty} H( {f_{n}})<H(
{f})$. Our main result shows this is true for affine mappings. Addressing
conjectures of F.W. Gehring and Iwaniec we show the jump up in the limit can be
arbitrarily large and give conjecturally sharp bounds : for each
$\alpha<\sqrt{2}$ there is ${f_{n}}\to {f}$ locally uniformly with $f$ affine
and \[ \alpha \; \limsup_{n\to\infty} H( {f_{n}}) < H( {f}) \] We conjecture
$\sqrt{2}$ to be best possible.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:26:54 GMT""}]","2023-02-06"
"2302.01447","Xuan Li","Xuan Li","Silicon detector R$\&$D for the future Electron-Ion Collider","9 pages, 6 figures, proceeding for the PIXEL2022 conference","PoS(Pixel2022)042","10.22323/1.420.0042","LANL Report: LA-UR-23-20704","physics.ins-det hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  The high-luminosity high-energy Electron-Ion Collider (EIC) to be built at
Brookhaven National Laboratory (BNL) will provide a clean environment to study
several fundamental questions in the high energy and nuclear physics fields. A
high granularity and low material budget silicon vertex and tracking detector
is required to provide precise measurements of primary and displaced vertex and
track reconstruction with good momentum and spatial resolutions. The reference
design of the EIC silicon vertex and tracking detector includes the Monolithic
Active Pixel Sensor (MAPS) based vertex and tracking subsystem and the
AC-Coupled Low Gain Avalanche Diode (AC-LGAD) based outer tracker, and it has
the track reconstruction capability in the pseudorapidity region of -3.5 to 3.5
with full azimuthal coverage. Further detector geometry optimization with a new
magnet based on the EIC project detector reference design are being performed
by the newly formed ePIC collaboration. The latest ePIC vertex and tracking
detector geometry and its performance evaluated in simulation will be
presented. Details of the EIC silicon vertex and tracking detector R$\&$D,
which include the proposed detector technologies, prototype sensor
characterization and detector mechanical design will be discussed as well.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:28:43 GMT""}]","2023-05-09"
"2302.01448","Jatinder Singh","Kornel Lewicki, Michelle Seng Ah Lee, Jennifer Cobbe, Jatinder Singh","Out of Context: Investigating the Bias and Fairness Concerns of
  ""Artificial Intelligence as a Service""","Accepted to CHI '23: ACM Human Factors in Computing, 2023, Hamburg,
  Germany",,"10.1145/3544548.3581463",,"cs.LG cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  ""AI as a Service"" (AIaaS) is a rapidly growing market, offering various
plug-and-play AI services and tools. AIaaS enables its customers (users) - who
may lack the expertise, data, and/or resources to develop their own systems -
to easily build and integrate AI capabilities into their applications. Yet, it
is known that AI systems can encapsulate biases and inequalities that can have
societal impact. This paper argues that the context-sensitive nature of
fairness is often incompatible with AIaaS' 'one-size-fits-all' approach,
leading to issues and tensions. Specifically, we review and systematise the
AIaaS space by proposing a taxonomy of AI services based on the levels of
autonomy afforded to the user. We then critically examine the different
categories of AIaaS, outlining how these services can lead to biases or be
otherwise harmful in the context of end-user applications. In doing so, we seek
to draw research attention to the challenges of this emerging area.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:32:10 GMT""}]","2023-02-06"
"2302.01449","Mohammad Shifat E Rabbi","Mohammad Shifat E Rabbi, Natasha Ironside, John A Ozolek, Rajendra
  Singh, Liron Pantanowitz, Gustavo K Rohde","Transport-based morphometry of nuclear structures of digital pathology
  images in cancers",,,,,"q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alterations in nuclear morphology are useful adjuncts and even diagnostic
tools used by pathologists in the diagnosis and grading of many tumors,
particularly malignant tumors. Large datasets such as TCGA and the Human
Protein Atlas, in combination with emerging machine learning and statistical
modeling methods, such as feature extraction and deep learning techniques, can
be used to extract meaningful knowledge from images of nuclei, particularly
from cancerous tumors. Here we describe a new technique based on the
mathematics of optimal transport for modeling the information content related
to nuclear chromatin structure directly from imaging data. In contrast to other
techniques, our method represents the entire information content of each
nucleus relative to a template nucleus using a transport-based morphometry
(TBM) framework. We demonstrate the model is robust to different staining
patterns and imaging protocols, and can be used to discover meaningful and
interpretable information within and across datasets and cancer types. In
particular, we demonstrate morphological differences capable of distinguishing
nuclear features along the spectrum from benign to malignant categories of
tumors across different cancer tissue types, including tumors derived from
liver parenchyma, thyroid gland, lung mesothelium, and skin epithelium. We
believe these proof of concept calculations demonstrate that the TBM framework
can provide the quantitative measurements necessary for performing meaningful
comparisons across a wide range of datasets and cancer types that can
potentially enable numerous cancer studies, technologies, and clinical
applications and help elevate the role of nuclear morphometry into a more
quantitative science. The source codes implementing our method is available at
https://github.com/rohdelab/nuclear_morphometry.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:36:31 GMT""}]","2023-02-06"
"2302.01450","Yashaswini Murthy","Yashaswini Murthy, Mehrdad Moharrami and R. Srikant","Performance Bounds for Policy-Based Average Reward Reinforcement
  Learning Algorithms","30 pages",,,,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Many policy-based reinforcement learning (RL) algorithms can be viewed as
instantiations of approximate policy iteration (PI), i.e., where policy
improvement and policy evaluation are both performed approximately. In
applications where the average reward objective is the meaningful performance
metric, often discounted reward formulations are used with the discount factor
being close to 1, which is equivalent to making the expected horizon very
large. However, the corresponding theoretical bounds for error performance
scale with the square of the horizon. Thus, even after dividing the total
reward by the length of the horizon, the corresponding performance bounds for
average reward problems go to infinity. Therefore, an open problem has been to
obtain meaningful performance bounds for approximate PI and RL algorithms for
the average-reward setting. In this paper, we solve this open problem by
obtaining the first non-trivial error bounds for average-reward MDPs which go
to zero in the limit where when policy evaluation and policy improvement errors
go to zero.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:37:47 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 23:02:15 GMT""}]","2023-02-17"
"2302.01451","Andrea Gemelli","Andrea Gemelli, Emanuele Vivoli, Simone Marinai","CTE: A Dataset for Contextualized Table Extraction",,,,,"cs.CL cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Relevant information in documents is often summarized in tables, helping the
reader to identify useful facts. Most benchmark datasets support either
document layout analysis or table understanding, but lack in providing data to
apply both tasks in a unified way. We define the task of Contextualized Table
Extraction (CTE), which aims to extract and define the structure of tables
considering the textual context of the document. The dataset comprises 75k
fully annotated pages of scientific papers, including more than 35k tables.
Data are gathered from PubMed Central, merging the information provided by
annotations in the PubTables-1M and PubLayNet datasets. The dataset can support
CTE and adds new classes to the original ones. The generated annotations can be
used to develop end-to-end pipelines for various tasks, including document
layout analysis, table detection, structure recognition, and functional
analysis. We formally define CTE and evaluation metrics, showing which subtasks
can be tackled, describing advantages, limitations, and future works of this
collection of data. Annotations and code will be accessible a
https://github.com/AILab-UniFI/cte-dataset.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:38:23 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 18:22:57 GMT""}]","2023-02-14"
"2302.01452","M. Hammad Mazhar","M. Hammad Mazhar, Li Li, Endadul Hoque, Omar Chowdhury","MAVERICK: An App-independent and Platform-agnostic Approach to Enforce
  Policies in IoT Systems at Runtime","13 pages, full version with material cut from version accepted at ACM
  WiSec 2023",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many solutions have been proposed to curb unexpected behavior of automation
apps installed on programmable IoT platforms by enforcing safety policies at
runtime. However, all prior work addresses a weaker version of the actual
problem due to a simpler, unrealistic threat model. These solutions are not
general enough as they are heavily dependent on the installed apps and catered
to specific IoT platforms. Here, we address a stronger version of the problem
via a realistic threat model, where (i) undesired cyber actions can come from
not only automation platform backends (e.g., SmartThings) but also
close-sourced third-party services (e.g., IFTTT), and (ii) physical actions
(e.g., user interactions) on devices can move the IoT system to an undesirable
state. We propose a runtime mechanism, dubbed Maverick, which employs an
app-independent, platform-agnostic mediator to enforce policies against all
undesired cyber actions and applies corrective-actions to bring the IoT system
back to a safe state from an unsafe state transition. Maverick is equipped with
a policy language capable of expressing rich temporal invariants and an
automated toolchain that includes a policy synthesizer and a policy analyzer
for user assistance. We implemented Maverick in a prototype and showed its
efficacy in both physical and virtual testbeds, incurring minimal overhead.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:39:48 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 16:45:46 GMT""}]","2023-04-19"
"2302.01453","Paolo Russotto","P. Russotto, M.D. Cozma, E. De Filippo, A. Le F\`evre, Y. Leifels, J.
  {\L}ukasik","Studies of the equation-of-state of nuclear matter by heavy-ion
  collisions at intermediate energy in the multi-messenger era","79 pages, 25 figures","La Rivista del Nuovo Cimento volume 46, pages 1-70 (2023)","10.1007/s40766-023-00039-4",,"nucl-ex nucl-th","http://creativecommons.org/licenses/by/4.0/","  The study of the equation-of-state (EoS) describing the properties of nuclear
matter away from the normal conditions is a relevant and intriguing topic of
modern nuclear physics. The last decades have witnessed a substantial
experimental progress in derivation of the symmetric matter term of the EoS and
of the so-called symmetry energy for the asymmetric matter, especially at
densities below the saturation point. But it is only in recent years that the
opening of the multi-messenger astronomy era, triggered by detection of
gravitational waves due to the neutron star mergers, has renewed and enlarged
the interest in high-density EoS, being the main ingredient for determining the
structure and properties of neutron stars. In this paper we review our
knowledge obtained from heavy-ion collisions up to the 1 GeV/nucleon regime, on
the EoS above nuclear saturation density. Special emphasis is given on the
still few results on symmetry energy at high densities and their
interconnections with multi-messenger astronomy findings.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:42:31 GMT""}]","2023-03-09"
"2302.01454","Kensuke Inaba","Kensuke Inaba, Yasuhiro Yamada, Hiroki Takesue","Thermodynamic quantities of two-dimensional Ising models obtained by
  noisy mean field annealing and coherent Ising machine","6 pages, 6 figures",,,,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noisy mean field annealing (NMFA) is an algorithm that mimics a coherent
Ising machine (CIM), which is an optical system for solving Ising problems. The
NMFA has reproduced the solver performance of the CIM for systems of limited
size even though it simplifies the interaction between spins with a mean-field
approximation. However, recent experiments observing various thermodynamic
quantities have revealed that the CIM can capture the phase transitions of the
two-dimensional Ising models that the mean field cannot capture. This situation
leads to a fundamental question as to how well the NMFA can capture the
features of the thermodynamic quantities around the phase transition. This
paper answers that the NMFA reproduces the thermodynamic features of the mean
field, but cannot reproduce the CIM results. This suggests that, in terms of
sampling, the level of performance of the CIM is beyond that of the NMFA.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:47:12 GMT""}]","2023-02-06"
"2302.01455","Wyatt Felt","Wyatt Felt","Reconsidering Fascicles in Soft Pneumatic Actuator Packs",,,,,"cs.RO","http://creativecommons.org/licenses/by/4.0/","  This paper discusses and contests the claims of ``Soft Pneumatic Actuator
Fascicles for High Force and Reliability'' a research article which was
originally published in the March 2017 issue of the Journal Soft Robotics. The
original paper claims that the summed forces of multiple thin-walled extending
McKibben muscles are greater than a volumetrically equivalent actuator of the
same length at the same pressure. The original paper also claims that the
purported benefit becomes more pronounced as the number of smaller actuators is
increased. Using reasonable assumptions, the analysis of this paper shows that
the claims of the original paper violate the law of conservation of energy.
This paper also identifies errors in the original methodology that may have led
to the erroneous conclusions of the original paper. The goal of this paper is
to correct the record and to provide a more accurate framework for considering
fascicles used in soft pneumatic actuator packs.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:56:25 GMT""}]","2023-02-06"
"2302.01456","Farhad Billimoria","Farhad Billimoria, Filiberto Fele, Iacopo Savelli, Thomas Morstyn,
  Malcolm McCulloch","An Insurance Paradigm for Improving Power System Resilience via
  Distributed Investment","10 pages",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Extreme events, exacerbated by climate change, pose significant risks to the
energy system and its consumers. However there are natural limits to the degree
of protection that can be delivered from a centralised market architecture.
Distributed energy resources provide resilience to the energy system, but their
value remains inadequately recognized by regulatory frameworks. We propose an
insurance framework to align residual outage risk exposure with locational
incentives for distributed investment. We demonstrate that leveraging this
framework in large-scale electricity systems could improve consumer welfare
outcomes in the face of growing risks from extreme events via investment in
distributed energy.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:57:59 GMT""}]","2023-02-06"
"2302.01457","Wenliang Zhang","Wenliang Zhang, Teguh Citra Asmara, Yi Tseng, Junbo Li, Yimin Xiong,
  Vladimir N. Strocov, Y. Soh, Thorsten Schmitt, and Gabriel Aeppli","Spin waves in a ferromagnetic topological metal",,,,,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In most metals, charges and spins can hop rapidly between atoms, yielding
strong dispersion of their energy versus momentum. There are, however, special
arrangements of atoms, such as twisted graphene bilayers or lattices which
resemble woven bamboo ""kagome"" mats, so that particle motion with strong
hopping between neighbours becomes nearly or even completely dispersionless.
Such flat bands are interesting because the interactions between the heavy
particles inhabiting them will become much more important than for strong
dispersion, resulting in novel quantum solid and liquid states, particularly
when topology enters on account of significant spin-orbit coupling for the
underlying electrons. Nonetheless, spectroscopic evidence for flat bands
engendered by lattice geometry rather than weak hopping is rare, particularly
for metallic single crystals. Here we report the discovery, using circularly
polarized X-Rays in resonant absorption and inelastic scattering (RIXS) for the
unambiguous isolation of magnetic signals, of a flat spin wave band and large
orbital moment for the metallic kagome ferromagnet Fe$_3$Sn$_2$, which has a
topologically non-trivial electronic band structure controllable by modest
external magnetic fields. The flat mode energy is consistent with the high
Curie temperature ($T_C$ ~ 640 K) as well as the strong acoustic mode
dispersion, implying, together with the substantial spin-orbit coupling
indicated by the large orbital moment, that the mode is topological. The
measured properties of the spin waves are highly unconventional, and include
very severe damping as well as the flat mode amplitude which is maximized in
the long wavelength limit where it is ordinarily expected to vanish. Our
results open the topic of interactions of topological bosons (spin waves) and
fermions (electrons) with the very specific target of explaining boson
lifetimes and amplitudes.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:58:26 GMT""}]","2023-02-06"
"2302.01458","Valerio Faraoni","Valerio Faraoni and Sonia Jose","Cosmological analogies for geophysical flows, Lagrangians, and new
  analogue gravity systems","8 pages, latex, to appear in Eur. Phys. J. C",,"10.1140/epjc/s10052-023-11292-6",,"gr-qc physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Formal analogies between the ordinary differential equations describing
geophysical flows and Friedmann cosmology are developed. As a result, one
obtains Lagrangian and Hamiltonian formulations of these equations, while
laboratory experiments aimed at testing geophysical flows are shown to
constitute analogue gravity systems for cosmology.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:02:22 GMT""}]","2023-03-01"
"2302.01459","Mohammad Shifat E Rabbi","Mohammad Shifat E Rabbi, Abu Hasnat Mohammad Rubaiyat, Yan Zhuang,
  Gustavo K Rohde","A sliced-Wasserstein distance-based approach for
  out-of-class-distribution detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There exist growing interests in intelligent systems for numerous medical
imaging, image processing, and computer vision applications, such as face
recognition, medical diagnosis, character recognition, and self-driving cars,
among others. These applications usually require solving complex classification
problems involving complex images with unknown data generative processes. In
addition to recent successes of the current classification approaches relying
on feature engineering and deep learning, several shortcomings of them, such as
the lack of robustness, generalizability, and interpretability, have also been
observed. These methods often require extensive training data, are
computationally expensive, and are vulnerable to out-of-distribution samples,
e.g., adversarial attacks. Recently, an accurate, data-efficient,
computationally efficient, and robust transport-based classification approach
has been proposed, which describes a generative model-based problem formulation
and closed-form solution for a specific category of classification problems.
However, all these approaches lack mechanisms to detect test samples outside
the class distributions used during training. In real-world settings, where the
collected training samples are unable to exhaust or cover all classes, the
traditional classification schemes are unable to handle the unseen classes
effectively, which is especially an important issue for safety-critical
systems, such as self-driving and medical imaging diagnosis. In this work, we
propose a method for detecting out-of-class distributions based on the
distribution of sliced-Wasserstein distance from the Radon Cumulative
Distribution Transform (R-CDT) subspace. We tested our method on the MNIST and
two medical image datasets and reported better accuracy than the
state-of-the-art methods without an out-of-class distribution detection
procedure.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:03:51 GMT""}]","2023-02-06"
"2302.01460","Mortaza Abtahi Dr.","F. Zaj and M. Abtahi","Algebras of Polynomials Generated by Linear Operators",,"Carpathian Mathematical Publications (2023)",,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $E$ be a Banach space and $A$ be a commutative Banach algebra with
identity. Let ${P}(E, A)$ be the space of $A$-valued polynomials on $E$
generated by bounded linear operators (an $n$-homogenous polynomial in
${P}(E,A)$ is of the form $P=\sum_{i=1}^\infty T^n_i$, where $T_i:E\to A$
($1\leq i <\infty$) are bounded linear operators and $\sum_{i=1}^\infty
\|T_i\|^n < \infty$). For a compact set $K$ in $E$, we let ${P}(K, A)$ be the
closure in $C(K,A)$ of the restrictions $P|_K$ of polynomials $P$ in
${P}(E,A)$. It is proved that ${P}(K, A)$ is an $A$-valued uniform algebra and
that, under certain conditions, it is isometrically isomorphic to the injective
tensor product $\mathcal{P}_N(K)\hat\otimes_\epsilon A$, where
$\mathcal{P}_N(K)$ is the uniform algebra on $K$ generated by nuclear
scalar-valued polynomials. The character space of ${P}(K, A)$ is then
identified with $\hat{K}_N\times \mathfrak{M}(A)$, where $\hat K_N$ is the
nuclear polynomially convex hull of $K$ in $E$, and $\mathfrak{M}(A)$ is the
character space of $A$.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:13:02 GMT""}]","2023-02-06"
"2302.01461","Cecilia Mondaini","Nathan E. Glatt-Holtz, Cecilia F. Mondaini","Long-term accuracy of numerical approximations of SPDEs with the
  stochastic Navier-Stokes equations as a paradigm","72 pages",,,,"math.NA cs.NA math-ph math.AP math.MP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work introduces a general framework for establishing the long time
accuracy for approximations of Markovian dynamical systems on separable Banach
spaces. Our results illuminate the role that a certain uniformity in
Wasserstein contraction rates for the approximating dynamics bears on long time
accuracy estimates. In particular, our approach yields weak consistency bounds
on $\mathbb{R}^+$ while providing a means to sidestepping a commonly occurring
situation where certain higher order moment bounds are unavailable for the
approximating dynamics. Additionally, to facilitate the analytical core of our
approach, we develop a refinement of certain `weak Harris theorems'. This
extension expands the scope of applicability of such Wasserstein contraction
estimates to a variety of interesting SPDE examples involving weaker
dissipation or stronger nonlinearity than would be covered by the existing
literature.
  As a guiding and paradigmatic example, we apply our formalism to the
stochastic 2D Navier-Stokes equations and to a semi-implicit in time and
spectral Galerkin in space numerical approximation of this system. In the case
of a numerical approximation, we establish quantitative estimates on the
approximation of invariant measures as well as prove weak consistency on
$\mathbb{R}^+$. To develop these numerical analysis results, we provide a
refinement of $L^2_x$ accuracy bounds in comparison to the existing literature
which are results of independent interest.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:21:31 GMT""}]","2023-02-06"
"2302.01462","Benedikt Hampel","Benedikt Hampel, Daniel H. Slichter, Dietrich Leibfried, Richard P.
  Mirin, Sae Woo Nam, Varun B. Verma","Trap-Integrated Superconducting Nanowire Single-Photon Detectors with
  Improved RF Tolerance for Trapped-Ion Qubit State Readout","6 pages, 4 figures. The following article has been submitted to
  Applied Physics Letters","Appl. Phys. Lett. 122, 174001 (2023)","10.1063/5.0145077",,"quant-ph cond-mat.supr-con physics.app-ph physics.atom-ph physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  State readout of trapped-ion qubits with trap-integrated detectors can
address important challenges for scalable quantum computing, but the strong rf
electric fields used for trapping can impact detector performance. Here, we
report on NbTiN superconducting nanowire single-photon detectors (SNSPDs)
employing grounded aluminum mirrors as electrical shielding that are integrated
into linear surface-electrode rf ion traps. The shielded SNSPDs can be
successfully operated at applied rf trapping potentials of up to
$\mathrm{54\,V_{peak}}$ at $\mathrm{70\,MHz}$ and temperatures of up to
$\mathrm{6\,K}$, with a maximum system detection efficiency of
$\mathrm{68\,\%}$. This performance should be sufficient to enable parallel
high-fidelity state readout of a wide range of trapped ion species in typical
cryogenic apparatus.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:22:39 GMT""}]","2023-06-01"
"2302.01463","Anastasiia Koloskova","Anastasia Koloskova, Ryan McKenna, Zachary Charles, Keith Rush,
  Brendan McMahan","Convergence of Gradient Descent with Linearly Correlated Noise and
  Applications to Differentially Private Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stochastic optimization with linearly correlated noise. Our study is
motivated by recent methods for optimization with differential privacy (DP),
such as DP-FTRL, which inject noise via matrix factorization mechanisms. We
propose an optimization problem that distils key facets of these DP methods and
that involves perturbing gradients by linearly correlated noise. We derive
improved convergence rates for gradient descent in this framework for convex
and non-convex loss functions. Our theoretical analysis is novel and might be
of independent interest. We use these convergence rates to develop new,
effective matrix factorizations for differentially private optimization, and
highlight the benefits of these factorizations theoretically and empirically.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:32:24 GMT""}]","2023-02-06"
"2302.01464","Frank Neumann","Frank Neumann, Aneta Neumann, Chao Qian, Viet Anh Do, Jacob de Nobel,
  Diederick Vermetten, Saba Sadeghi Ahouei, Furong Ye, Hao Wang, Thomas B\""ack","Benchmarking Algorithms for Submodular Optimization Problems Using
  IOHProfiler",,,,,"cs.AI cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Submodular functions play a key role in the area of optimization as they
allow to model many real-world problems that face diminishing returns.
Evolutionary algorithms have been shown to obtain strong theoretical
performance guarantees for a wide class of submodular problems under various
types of constraints while clearly outperforming standard greedy approximation
algorithms. This paper introduces a setup for benchmarking algorithms for
submodular optimization problems with the aim to provide researchers with a
framework to enhance and compare the performance of new algorithms for
submodular problems. The focus is on the development of iterative search
algorithms such as evolutionary algorithms with the implementation provided and
integrated into IOHprofiler which allows for tracking and comparing the
progress and performance of iterative search algorithms. We present a range of
submodular optimization problems that have been integrated into IOHprofiler and
show how the setup can be used for analyzing and comparing iterative search
algorithms in various settings.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:36:23 GMT""}]","2023-02-06"
"2302.01465","Fabrice Roncoroni","Fabrice Roncoroni, Ana Sanz-Matias, Siddharth Sundararaman, David
  Prendergast","Unsupervised learning of representative local atomic arrangements in
  molecular dynamics data","15 pages, 12 figures",,"10.1039/D3CP00525A",,"cond-mat.mtrl-sci physics.chem-ph physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Molecular dynamics (MD) simulations present a data-mining challenge, given
that they can generate a considerable amount of data but often rely on limited
or biased human interpretation to examine their information content. By not
asking the right questions of MD data we may miss critical information hidden
within it. We combine dimensionality reduction (UMAP) and unsupervised
hierarchical clustering (HDBSCAN) to quantitatively characterize the
coordination environment of chemical species within MD data. By focusing on
local coordination, we significantly reduce the amount of data to be analyzed
by extracting all distinct molecular formulas within a given coordination
sphere. We then efficiently combine UMAP and HDBSCAN with alignment or
shape-matching algorithms to classify these formulas into distinct structural
isomer families. The outcome is a quantitative mapping of the multiple
coordination environments present in the MD data. The method was employed to
reveal details of cation coordination in electrolytes based on molecular
liquids.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:37:19 GMT""}]","2023-05-09"
"2302.01466","Mitia Duerinckx","Mitia Duerinckx","Semi-dilute rheology of particle suspensions: derivation of Doi-type
  models","47 pages",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is devoted to the large-scale rheology of suspensions of
non-Brownian inertialess rigid particles, possibly self-propelling, suspended
in Stokes flow. Starting from a hydrodynamic model, we derive a semi-dilute
mean-field description in form of a Doi-type model, which is given by a
'macroscopic' effective Stokes equation coupled with a 'microscopic' Vlasov
equation for the statistical distribution of particle positions and
orientations. This accounts for some non-Newtonian effects since the viscosity
in the effective Stokes equation depends on the local distribution of particle
orientations via Einstein's formula. The main difficulty is the detailed
analysis of multibody hydrodynamic interactions between the particles, which we
perform by means of a cluster expansion combined with a multipole expansion in
a suitable dilute regime.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:50:22 GMT""},{""version"":""v2"",""created"":""Mon, 29 May 2023 05:09:50 GMT""}]","2023-05-30"
"2302.01467","Motoki Asano","Motoki Asano, Hiroshi Yamaguchi, and Hajime Okamoto","Cavity optomechanical mass sensor in water with sub-femtogram resolution",,,"10.35848/1882-0786/acbd0d",,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sub-femtogram resolution of an in-liquid cavity optomechanical mass sensor
based on the twin-microbottle glass resonator is demonstrated. An evaluation of
the frequency stability using an optomechanical phase-locked loop reveals that
this cavity optomechanical sensor has the highest mass resolution of
$(7.0\times2.0)\times 10^{-16}$ g in water, which is four orders of magnitude
better than that in our first-generation setup [Sci. Adv. 8, eabq2502 (2022)].
This highly sensitive mass sensor provides a free-access optomechanical probe
in liquid and could thus be extended to a wide variety of in-situ chemical and
biological metrology applications.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:53:21 GMT""}]","2023-03-15"
"2302.01468","Yang Yang","J\""urgen Fuchs, Christoph Schweigert, Yang Yang","String-net models for pivotal bicategories","64 pages, several tikz figures",,,"ZMP-HH/23-1, Hamburger Beitr\""age zur Mathematik Nr. 937","math.QA hep-th math-ph math.CT math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a string-net construction of a modular functor whose algebraic
input is a pivotal bicategory; this extends the standard construction based on
a spherical fusion category. An essential ingredient in our construction is a
graphical calculus for pivotal bicategories, which we express in terms of a
category of colored corollas. The globalization of this calculus to oriented
surfaces yields the bicategorical string-net spaces as colimits. We show that
every rigid separable Frobenius functor between strictly pivotal bicategories
induces linear maps between the corresponding bicategorical string-net spaces
that are compatible with the mapping class group actions and with sewing. Our
results are inspired by and have applications to the description of correlators
in two-dimensional conformal field theories.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:59:03 GMT""}]","2023-02-06"
"2302.01469","Nathan Babcock","N. S. Babcock, G. Montes-Cabrera, K. E. Oberhofer, M. Chergui, G. L.
  Celardo, P. Kurian","Ultraviolet superradiance from mega-networks of tryptophan in biological
  architectures",,,,,"quant-ph cond-mat.mes-hall physics.bio-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Networks of tryptophan -- an aromatic amino acid with strong fluorescent
response -- are ubiquitous in biological systems, forming diverse architectures
in transmembrane proteins, cytoskeletal filaments, sub-neuronal elements,
photoreceptor complexes, virion capsids, and other cellular structures. We
analyze the cooperative effects induced by ultraviolet (UV) excitation of
several biologically relevant tryptophan mega-networks, thus giving insight
into novel mechanisms for cellular signalling and control. Our theoretical
analysis in the single-excitation manifold predicts the formation of strongly
superradiant states due to collective interactions among organized arrangements
of up to more than $10^5$ tryptophan UV-excited transition dipoles in
microtubule architectures, which leads to an enhancement of the fluorescence
quantum yield that is confirmed by our experiments. We demonstrate the observed
consequences of this superradiant behavior in the fluorescence quantum yield
for hierarchically organized tubulin structures, which increases in different
geometric regimes at thermal equilibrium before saturation -- highlighting the
effect's persistence in the presence of disorder.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:03:59 GMT""}]","2023-02-06"
"2302.01470","Qingfeng Lan","Qingfeng Lan, A. Rupam Mahmood, Shuicheng Yan, Zhongwen Xu","Learning to Optimize for Reinforcement Learning",,,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  In recent years, by leveraging more data, computation, and diverse tasks,
learned optimizers have achieved remarkable success in supervised learning
optimization, outperforming classical hand-designed optimizers. However, in
practice, these learned optimizers fail to generalize to reinforcement learning
tasks due to unstable and complex loss landscapes. Moreover, neither
hand-designed optimizers nor learned optimizers have been specifically designed
to address the unique optimization properties in reinforcement learning. In
this work, we take a data-driven approach to learn to optimize for
reinforcement learning using meta-learning. We introduce a novel optimizer
structure that significantly improves the training efficiency of learned
optimizers, making it possible to learn an optimizer for reinforcement learning
from scratch. Although trained in toy tasks, our learned optimizer demonstrates
its generalization ability to unseen complex tasks. Finally, we design a set of
small gridworlds to train the first general-purpose optimizer for reinforcement
learning.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:11:02 GMT""}]","2023-02-06"
"2302.01471","Wenhan Yu","Wenhan Yu, Terence Jie Chua, Jun Zhao","User-centric Heterogeneous-action Deep Reinforcement Learning for
  Virtual Reality in the Metaverse over Wireless Networks","The paper appears in IEEE Transactions on Wireless Communications
  (TWC), 2023",,,,"cs.NI cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The Metaverse is emerging as maturing technologies are empowering the
different facets. Virtual Reality (VR) technologies serve as the backbone of
the virtual universe within the Metaverse to offer a highly immersive user
experience. As mobility is emphasized in the Metaverse context, VR devices
reduce their weights at the sacrifice of local computation abilities. In this
paper, for a system consisting of a Metaverse server and multiple VR users, we
consider two cases of (i) the server generating frames and transmitting them to
users, and (ii) users generating frames locally and thus consuming device
energy. Moreover, in our multi-user VR scenario for the Metaverse, users have
different characteristics and demands for Frames Per Second (FPS). Then the
channel access arrangement (including the decisions on frame generation
location), and transmission powers for the downlink communications from the
server to the users are jointly optimized to improve the utilities of users.
This joint optimization is addressed by deep reinforcement learning (DRL) with
heterogeneous actions. Our proposed user-centric DRL algorithm is called
User-centric Critic with Heterogenous Actors (UCHA). Extensive experiments
demonstrate that our UCHA algorithm leads to remarkable results under various
requirements and constraints.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:12:12 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 17:42:11 GMT""}]","2023-05-23"
"2302.01472","Johan Briones","J. Briones, M. Weber, B. Stadtm\""uller, H. C. Schneider and B.
  Rethfeld","Effect of iron thicknesses on spin transport in a Fe/Au bilayer system",,,,,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with a theoretical analysis of the behavior of
optically excited spin currents in bilayer and multilayer systems of
ferromagnetic and normal metals. As the propagation, control and manipulation
of the spin currents created in ferromagnets by femtosecond optical pulses is
of particular interest, we examine the influence of different thicknesses of
the constituent layers for the case of electrons excited several electronvolts
above the Fermi level. Using a Monte-Carlo simulation framework for such highly
excited electrons, we first examine the spatio-temporal characteristics of the
spin current density driven in a Fe layer, where the absorption profile of the
light pulses plays an important role. Further, we examine how the combination
of light absorption profiles, spin-dependent transmission probabilities, and
iron layer thicknesses affect spin current density in a Fe/Au bilayer system.
For high-energy electrons studied here, the interface and secondary electron
generation have a small influence on spin transport in the bilayer system.
However, we find that spin injection from one layer to another is most
effective within a certain range of iron layer thicknesses.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:17:19 GMT""}]","2023-02-06"
"2302.01473","Brian Jefferies","Brian Jefferies","Holomorphic functions on the lie ball and their monogenic counterparts",,,,,"math.CV math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Cauchy integral formula in Clifford analysis allows us to associate a
holomorphic function $\tilde f:L_n\to \C$ on the Lie ball $L_n$ in $\C^n$ with
its monogenic counterpart $f:B_1(0)\to \C^{n+1}$ via the formula $\tilde f(z) =
\int_{S^n}G_\om(z)\bs n(\om)f(\om)\,d\mu(\om)$, $z\in L_n.$ The inverse map
$\tilde f\mapsto f$ is constructed here using the Cauchy-Hua formula for the
Lie ball following the work of M. Morimoto \cite{Mori2}.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:18:26 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 00:32:26 GMT""}]","2023-03-14"
"2302.01474","Hyoungwook Nam","Hyoungwook Nam, Raghavendra Pradyumna Pothukuchi, Bo Li, Nam Sung Kim,
  Josep Torrellas","Defensive ML: Defending Architectural Side-channels with Adversarial
  Obfuscation","Submitted to ICML 2023",,,,"cs.CR cs.AR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Side-channel attacks that use machine learning (ML) for signal analysis have
become prominent threats to computer security, as ML models easily find
patterns in signals. To address this problem, this paper explores using
Adversarial Machine Learning (AML) methods as a defense at the computer
architecture layer to obfuscate side channels. We call this approach Defensive
ML, and the generator to obfuscate signals, defender. Defensive ML is a
workflow to design, implement, train, and deploy defenders for different
environments. First, we design a defender architecture given the physical
characteristics and hardware constraints of the side-channel. Next, we use our
DefenderGAN structure to train the defender. Finally, we apply defensive ML to
thwart two side-channel attacks: one based on memory contention and the other
on application power. The former uses a hardware defender with ns-level
response time that attains a high level of security with half the performance
impact of a traditional scheme; the latter uses a software defender with
ms-level response time that provides better security than a traditional scheme
with only 70% of its power overhead.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:41:01 GMT""}]","2023-02-06"
"2302.01475","Quoc Thong Le Gia","Q. T. Le Gia and H. N. Mhaskar","Numerical solutions to an inverse problem for a non-linear Helmholtz
  equation","10 pages, 2 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we construct numerical solutions to an inverse problem of a
nonlinear Helmholtz equation defined in a spherical shell between two
concentric spheres centered at the origin.Assuming that the values of the
forward problem are known at sufficiently many points, we would like to
determine the form of the non-linear term on the right-hand side of the
equation via its Chebyshev coefficients.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 00:56:37 GMT""}]","2023-02-06"
"2302.01476","Lauren Cappiello","Analisa Flores, Lauren Cappiello, Isaac Quintanilla Salinas","Challenges and Successes of Emergency Online Teaching in Statistics
  Courses",,,,,"stat.OT","http://creativecommons.org/licenses/by/4.0/","  As the COVID-19 pandemic took hold in early months of 2020, education at all
levels was pushed to emergency fully remote, online formats. This emergency
shift affected all aspects of teaching and learning with very little notice and
often with limited resources. Educators were required to convert entire courses
online and shift to remote instructional approaches practically overnight.
Students found themselves enrolled in online courses without choice and
struggling to adjust to their new learning environments. This article
highlights some of the challenges and successes of teaching emergency online
undergraduate statistics courses. In particular, we discuss challenges and
successes related to (1) technology, (2) classroom community and feedback, and
(3) student-content engagement. We also reflect on the opportunity to continue
to enhance and enrich the learning experiences of our students by utilizing
some of the lessons learned from emergency online teaching as new permanent
online statistics courses are developed and/or moved back into the classroom.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:00:27 GMT""}]","2023-02-06"
"2302.01477","Yunchang Yang","Yunchang Yang, Han Zhong, Tianhao Wu, Bin Liu, Liwei Wang, Simon S. Du","A Reduction-based Framework for Sequential Decision Making with Delayed
  Feedback",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study stochastic delayed feedback in general multi-agent sequential
decision making, which includes bandits, single-agent Markov decision processes
(MDPs), and Markov games (MGs). We propose a novel reduction-based framework,
which turns any multi-batched algorithm for sequential decision making with
instantaneous feedback into a sample-efficient algorithm that can handle
stochastic delays in sequential decision making. By plugging different
multi-batched algorithms into our framework, we provide several examples
demonstrating that our framework not only matches or improves existing results
for bandits, tabular MDPs, and tabular MGs, but also provides the first line of
studies on delays in sequential decision making with function approximation. In
summary, we provide a complete set of sharp results for multi-agent sequential
decision making with delayed feedback.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:16:09 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 05:09:49 GMT""}]","2023-02-07"
"2302.01478","Guangda Huzhang","Yizhou Chen, Guangda Huzhang, Anxiang Zeng, Qingtao Yu, Hui Sun,
  Heng-yi Li, Jingyi Li, Yabo Ni, Han Yu, Zhiming Zhou","Clustered Embedding Learning for Recommender Systems",,,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, recommender systems have advanced rapidly, where embedding
learning for users and items plays a critical role. A standard method learns a
unique embedding vector for each user and item. However, such a method has two
important limitations in real-world applications: 1) it is hard to learn
embeddings that generalize well for users and items with rare interactions on
their own; and 2) it may incur unbearably high memory costs when the number of
users and items scales up. Existing approaches either can only address one of
the limitations or have flawed overall performances. In this paper, we propose
Clustered Embedding Learning (CEL) as an integrated solution to these two
problems. CEL is a plug-and-play embedding learning framework that can be
combined with any differentiable feature interaction model. It is capable of
achieving improved performance, especially for cold users and items, with
reduced memory cost. CEL enables automatic and dynamic clustering of users and
items in a top-down fashion, where clustered entities jointly learn a shared
embedding. The accelerated version of CEL has an optimal time complexity, which
supports efficient online updates. Theoretically, we prove the identifiability
and the existence of a unique optimal number of clusters for CEL in the context
of nonnegative matrix factorization. Empirically, we validate the effectiveness
of CEL on three public datasets and one business dataset, showing its
consistently superior performance against current state-of-the-art methods. In
particular, when incorporating CEL into the business model, it brings an
improvement of $+0.6\%$ in AUC, which translates into a significant revenue
gain; meanwhile, the size of the embedding table gets $2650$ times smaller.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:20:49 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 06:37:21 GMT""}]","2023-02-13"
"2302.01479","Vigneshwaran Krishnamurthy","Vigneshwaran Krishnamurthy, Teruyuki Hirano, Eric Gaidos, Bunei Sato,
  Ravi Kopparapu, Thomas Barclay, Katherine Garcia-Sage, Hiroki Harakawa, Klaus
  Hodapp, Shane Jacobson, Mihoko Konishi, Takayuki Kotani, Tomoyuki Kudo,
  Takashi Kurokawa, Masayuki Kuzuhara, Eric Lopez, Jun Nishikawa, Masashi
  Omiya, Joshua E. Schlieder, Takuma Serizawa, Motohide Tamura, Akitoshi Ueda,
  Sebastien Vievard","Absence of extended atmospheres in low-mass star radius-gap planets GJ
  9827 b, GJ 9827 d and TOI-1235 b","Published for MNRAS. 12 pages, 15 figures",,"10.1093/mnras/stad404",,"astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  \textit{Kepler} showed a paucity of planets with radii of 1.5 - 2 $\mathrm
R_{\oplus}$ around solar mass stars but this radius-gap has not been well
studied for low-mass star planets. Energy-driven escape models like
photoevaporation and core-powered mass-loss predict opposing transition regimes
between rocky and non-rocky planets when compared to models depicting planets
forming in gas-poor environments. Here we present transit observations of three
super-Earth sized planets in the radius-gap around low-mass stars using
high-dispersion InfraRed Doppler (IRD) spectrograph on the Subaru 8.2m
telescope. The planets GJ 9827 b and d orbit around a K6V star and TOI-1235 b
orbits a M0.5 star. We limit any planet-related absorption in the 1083.3 nm
lines of triplet He I by placing an upper-limit on the equivalent width of
14.71 m{\AA}, 18.39 m{\AA}, and 1.44 m{\AA}, for GJ 9827 b (99% confidence), GJ
9827 d (99% confidence) and TOI-1235 b (95% confidence) respectively. Using a
Parker wind model, we cap the mass-loss at $>$0.25 $\mathrm M_{\oplus}$
Gyr$^{-1}$ and $>$0.2 $\mathrm M_{\oplus}$ Gyr$^{-1}$ for GJ 9827 b and d,
respectively (99% confidence), and $>$0.05 $\mathrm M_{\oplus}$ Gyr$^{-1}$ for
TOI-1235 b (95\% confidence) for a representative wind temperature of 5000 K.
Our observed results for the three planets are more consistent with the
predictions from photoevaporation and/or core-powered mass-loss models than the
gas-poor formation models. However, more planets in the radius-gap regime
around the low-mass stars are needed to robustly predict the atmospheric
evolution in planets around low-mass stars.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:21:20 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 19:04:17 GMT""}]","2023-03-22"
"2302.01480","Jiace Sun","Jiace Sun, Austin J. Minnich","Transport and noise of hot electrons in GaAs using a semi-analytical
  model of two-phonon polar optical phonon scattering","28 pages (including 5 pages appendix), 3 figures, submitted to
  Physical Review B",,"10.1103/PhysRevB.107.205201",,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent ab-initio studies of electron transport in GaAs have reported that
electron-phonon (e-ph) interactions beyond the lowest order play a fundamental
role in charge transport and noise phenomena. Inclusion of the
next-leading-order process in which an electron scatters with two phonons was
found to yield good agreement for the high-field drift velocity, but the
characteristic non-monotonic trend of the power spectral density of current
fluctuations (PSD) with electric field was not predicted. The high
computational cost of the ab-initio approach necessitated various
approximations to the two-phonon scattering term, which were suggested as
possible origins of the discrepancy. Here, we report a semi-analytical
transport model of two-phonon electron scattering via the Fr\""ohlich mechanism,
allowing a number of the approximations in the ab-initio treatment to be lifted
while retaining the accuracy to within a few percent. We compare the calculated
and experimental transport and noise properties as well as scattering rates
measured by photoluminescence experiments. We find quantitative agreement
within 15% for the drift velocity and 25% for the $\Gamma$ valley scattering
rates, and agreement with the $\Gamma-L$ intervalley scattering rates within a
factor of two. Considering these results and prior studies of current noise in
GaAs, we conclude that the most probable origin of the non-monotonic PSD trend
versus electric field is the formation of space charge domains rather than
intervalley scattering as has been assumed.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:32:50 GMT""}]","2023-05-17"
"2302.01481","Thomas Koberda","Sang-hyun Kim, Thomas Koberda, and J. de la Nuez Gonz\'alez","First order rigidity of homeomorphism groups of manifolds","56 pages, three figures. Submitted version",,,,"math.GR math.GT math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For every compact, connected manifold $M$, we prove the existence of a
sentence $\phi_M$ in the language of groups such that the homeomorphism group
of another compact manifold $N$ satisfies $\phi_M$ if and only if $N$ is
homeomorphic to $M$. We prove the analogous statement for groups of
homeomorphisms preserving an Oxtoby--Ulam probability measure.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:32:55 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 14:44:57 GMT""}]","2023-04-06"
"2302.01482","Matthew Spotnitz","Matthew Em. Spotnitz, Nai-Hang Kwong, Rolf Binder","Collective terahertz fluctuation modes in a polariton laser","23 pages, 13 figures","Phys. Rev. B 107, 125309 (2023)","10.1103/PhysRevB.107.125309",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A polariton Bardeen-Cooper-Schrieffer (BCS) state in a semiconductor
microcavity is an example of symmetry-broken states in open systems.
Fluctuations of the order parameter are an important tool to characterize such
a state. With the condensate formed by composite particles, the set of
zero-momentum fluctuations spans an infinite-dimensional electron-hole mode
subspace. We show that collective fluctuation modes with orbital angular
momentum different from that of the order parameter can be obtained with
terahertz radiation, and that a physical manifestation of such modes, which are
not Higgs modes, can be terahertz gain.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:33:11 GMT""}]","2023-04-04"
"2302.01483","Arun Nair","John Harvill, Jarred Barber, Arun Nair, Ramin Pishehvar","SPADE: Self-supervised Pretraining for Acoustic DisEntanglement",,,,,"cs.LG cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Self-supervised representation learning approaches have grown in popularity
due to the ability to train models on large amounts of unlabeled data and have
demonstrated success in diverse fields such as natural language processing,
computer vision, and speech. Previous self-supervised work in the speech domain
has disentangled multiple attributes of speech such as linguistic content,
speaker identity, and rhythm. In this work, we introduce a self-supervised
approach to disentangle room acoustics from speech and use the acoustic
representation on the downstream task of device arbitration. Our results
demonstrate that our proposed approach significantly improves performance over
a baseline when labeled training data is scarce, indicating that our
pretraining scheme learns to encode room acoustic information while remaining
invariant to other attributes of the speech signal.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:36:38 GMT""}]","2023-02-06"
"2302.01484","Benjamin Nasmith","Benjamin Nasmith","Rational Angle Sets and Tight t-Designs","11 pages",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Given a finite subset of a sphere or projective space, known as a design, we
can compute the strength and angle set of that design. When the strength and
angle set meet certain bounds, the design is called tight. Hoggar sought to
prove that, aside from certain known cases, the angle sets of tight projective
designs must be rational. Lyubich found a counter-example and provided a repair
for Hoggar's proof but excluded the exceptional octonion projective cases. This
note extends Lyubich's repair of Hoggar's proof to the remaining projective
cases and extends the proof to all spherical cases. It does so by using Jordan
algebra primitive idempotents to treat all of the cases simultaneously. We
thereby confirm that tight spherical and projective designs have rational angle
sets except in specific cases.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:37:26 GMT""}]","2023-02-06"
"2302.01485","Xiangdong Zhang","Ling-Jun Kong, Yifan Sun, Furong Zhang, Jingfeng Zhang, and Xiangdong
  Zhang","High-dimensional entanglement-enabled holography for quantum encryption",,"Phys. Rev. Lett. 130, 053602 (2023)",,,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As an important imaging technique, holography has been realized with
different physical dimensions of light,including polarization, wavelength, and
time. Recently, quantum holography has been realized by utilizing polarization
entangled state with the advantages of high robustness and enhanced spatial
resolution, comparing with classical one. However, the polarization is only a
two-dimensional degree of freedom, which greatly limits the capacity of quantum
holography. Here, we propose a method to realize high-dimensional quantum
holography by using high-dimensional orbital angular momentum (OAM)
entanglement. A high capacity OAM-encoded quantum holographic system can be
obtained by multiplexing a wide range of OAM-dependent holographic images.
Proof-of-principle experiments with four- and six-dimensional OAM entangled
states have been implemented and verify the feasibility of our idea. Our
experimental results also demonstrate that the high-dimensional quantum
holography shows a high robustness to classical noise. Furthermore,
OAMselective holographic scheme for quantum encryption is proposed and
demonstrated. Comparing with the previous schemes, the level of security of
holographic imaging encryption system can be greatly improved in our
high-dimensional quantum holography.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:39:01 GMT""}]","2023-02-06"
"2302.01486","Junwen Bai","Junwen Bai, Yuanqi Du, Yingheng Wang, Shufeng Kong, John Gregoire,
  Carla Gomes","Xtal2DoS: Attention-based Crystal to Sequence Learning for Density of
  States Prediction","Accepted to NeurIPS 2022 AI for Science Workshop",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Modern machine learning techniques have been extensively applied to materials
science, especially for property prediction tasks. A majority of these methods
address scalar property predictions, while more challenging spectral properties
remain less emphasized. We formulate a crystal-to-sequence learning task and
propose a novel attention-based learning method, Xtal2DoS, which decodes the
sequential representation of the material density of states (DoS) properties by
incorporating the learned atomic embeddings through attention networks.
Experiments show Xtal2DoS is faster than the existing models, and consistently
outperforms other state-of-the-art methods on four metrics for two fundamental
spectral properties, phonon and electronic DoS.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:46:03 GMT""}]","2023-02-06"
"2302.01487","Wei-Liang Sun","Liang-Chung Hsia, Hua-Chieh Li and Wei-Liang Sun","Conflict-Avoiding Codes of Prime Lengths and Cyclotomic Numbers",,,,,"math.NT cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem to construct optimal conflict-avoiding codes of even lengths and
the Hamming weight $3$ is completely settled. On the contrary, it is still open
for odd lengths. It turns out that the prime lengths are the fundamental cases
needed to be constructed. In the article, we study conflict-avoiding codes of
prime lengths and give a connection with the so-called cyclotomic numbers. By
having some nonzero cyclotomic numbers, a well-known algorithm for constructing
optimal conflict-avoiding codes will work for certain prime lengths. As a
consequence, we are able to answer the size of optimal conflict-avoiding code
for a new class of prime lengths.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:49:19 GMT""}]","2023-02-06"
"2302.01488","Ali Reza Ibrahimzada","Ali Reza Ibrahimzada, Yigit Varli, Dilara Tekinoglu, Reyhaneh
  Jabbarvand","Perfect is the enemy of test oracle","Published in ESEC/FSE 2022",,"10.1145/3540250.3549086",,"cs.SE cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Automation of test oracles is one of the most challenging facets of software
testing, but remains comparatively less addressed compared to automated test
input generation. Test oracles rely on a ground-truth that can distinguish
between the correct and buggy behavior to determine whether a test fails
(detects a bug) or passes. What makes the oracle problem challenging and
undecidable is the assumption that the ground-truth should know the exact
expected, correct, or buggy behavior. However, we argue that one can still
build an accurate oracle without knowing the exact correct or buggy behavior,
but how these two might differ. This paper presents SEER, a learning-based
approach that in the absence of test assertions or other types of oracle, can
determine whether a unit test passes or fails on a given method under test
(MUT). To build the ground-truth, SEER jointly embeds unit tests and the
implementation of MUTs into a unified vector space, in such a way that the
neural representation of tests are similar to that of MUTs they pass on them,
but dissimilar to MUTs they fail on them. The classifier built on top of this
vector representation serves as the oracle to generate ""fail"" labels, when test
inputs detect a bug in MUT or ""pass"" labels, otherwise. Our extensive
experiments on applying SEER to more than 5K unit tests from a diverse set of
open-source Java projects show that the produced oracle is (1) effective in
predicting the fail or pass labels, achieving an overall accuracy, precision,
recall, and F1 measure of 93%, 86%, 94%, and 90%, (2) generalizable, predicting
the labels for the unit test of projects that were not in training or
validation set with negligible performance drop, and (3) efficient, detecting
the existence of bugs in only 6.5 milliseconds on average.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:49:33 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 23:32:13 GMT""}]","2023-04-07"
"2302.01489","Atsuyoshi Kita","Atsuyoshi Kita, Nobuhiro Suenari, Masashi Okada, Tadahiro Taniguchi","Online Re-Planning and Adaptive Parameter Update for Multi-Agent Path
  Finding with Stochastic Travel Times","9 pages, 5 figures",,,,"cs.RO cs.MA","http://creativecommons.org/licenses/by/4.0/","  This study explores the problem of Multi-Agent Path Finding with continuous
and stochastic travel times whose probability distribution is unknown. Our
purpose is to manage a group of automated robots that provide package delivery
services in a building where pedestrians and a wide variety of robots coexist,
such as delivery services in office buildings, hospitals, and apartments. It is
often the case with these real-world applications that the time required for
the robots to traverse a corridor takes a continuous value and is randomly
distributed, and the prior knowledge of the probability distribution of the
travel time is limited. Multi-Agent Path Finding has been widely studied and
applied to robot management systems; however, automating the robot operation in
such environments remains difficult. We propose 1) online re-planning to update
the action plan of robots while it is executed, and 2) parameter update to
estimate the probability distribution of travel time using Bayesian inference
as the delay is observed. We use a greedy heuristic to obtain solutions in a
limited computation time. Through simulations, we empirically compare the
performance of our method to those of existing methods in terms of the conflict
probability and the actual travel time of robots. The simulation results
indicate that the proposed method can find travel paths with at least 50% fewer
conflicts and a shorter actual total travel time than existing methods. The
proposed method requires a small number of trials to achieve the performance
because the parameter update is prioritized on the important edges for path
planning, thereby satisfying the requirements of quick implementation of robust
planning of automated delivery services.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:52:18 GMT""}]","2023-02-06"
"2302.01490","Guoqi Yan","Guoqi Yan","The $RO(C_{2^n})$-graded homotopy of $H\underline{\mathbb{F}_2}$","12 pages",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give an explicit formula for the $RO(C_{2^n})$-graded homotopy of
$H\underline{\mathbb{F}_2}$.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:56:56 GMT""}]","2023-02-06"
"2302.01491","Palash Chatterjee","Palash Chatterjee, Ashutosh Chapagain, Weizhe Chen and Roni Khardon","DiSProD: Differentiable Symbolic Propagation of Distributions for
  Planning","International Joint Conference on Artificial Intelligence (IJCAI)
  2023. For project website, see https://pecey.github.io/DiSProD/",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  The paper introduces DiSProD, an online planner developed for environments
with probabilistic transitions in continuous state and action spaces. DiSProD
builds a symbolic graph that captures the distribution of future trajectories,
conditioned on a given policy, using independence assumptions and approximate
propagation of distributions. The symbolic graph provides a differentiable
representation of the policy's value, enabling efficient gradient-based
optimization for long-horizon search. The propagation of approximate
distributions can be seen as an aggregation of many trajectories, making it
well-suited for dealing with sparse rewards and stochastic environments. An
extensive experimental evaluation compares DiSProD to state-of-the-art planners
in discrete-time planning and real-time control of robotic systems. The
proposed method improves over existing planners in handling stochastic
environments, sensitivity to search depth, sparsity of rewards, and large
action spaces. Additional real-world experiments demonstrate that DiSProD can
control ground vehicles and surface vessels to successfully navigate around
obstacles.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:58:46 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 23:45:24 GMT""},{""version"":""v3"",""created"":""Thu, 18 May 2023 21:47:34 GMT""}]","2023-05-22"
"2302.01492","Brad Ramshaw","Yawen Fang, Yang Xu, Kaifei Kang, Benyamin Davaji, Kenji Watanabe,
  Takashi Taniguchi, Amit Lal, Kin Fai Mak, Jie Shan, and B. J. Ramshaw","Quantum Transport in Graphene Using Surface Acoustic Wave Resonators","2 figures",,,,"cond-mat.mes-hall cond-mat.str-el","http://creativecommons.org/licenses/by-sa/4.0/","  Surface acoustic waves (SAWs) provide a contactless method for measuring the
wavevector-dependent conductivity. This technique has been used to discover
emergent length scales in the fractional quantum Hall regime of traditional,
semiconductor-based heterostructures. SAWs would appear to be an ideal match
for van der Waals (vdW) heterostructures, but the right combination of
substrate and experimental geometry to allow access to the quantum transport
regime has not yet been found. We demonstrate that SAW resonant cavities
fabricated on LiNbO$_3$ substrates can be used to access the quantum Hall
regime of high-mobility, hexagonal boron nitride (hBN) encapsulated graphene
heterostructures. Our work establishes SAW resonant cavities as a viable
platform for performing contactless conductivity measurements in the quantum
transport regime of vdW materials.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:59:06 GMT""}]","2023-02-06"
"2302.01493","Anjali Balagopal","Anjali Balagopal, Michael Dohopolski, Young Suk Kwon, Steven Montalvo,
  Howard Morgan, Ti Bai, Dan Nguyen, Xiao Liang, Xinran Zhong, Mu-Han Lin, Neil
  Desai, Steve Jiang","Deep Learning (DL)-based Automatic Segmentation of the Internal Pudendal
  Artery (IPA) for Reduction of Erectile Dysfunction in Definitive Radiotherapy
  of Localized Prostate Cancer",,,,,"eess.IV cs.CV physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background and purpose: Radiation-induced erectile dysfunction (RiED) is
commonly seen in prostate cancer patients. Clinical trials have been developed
in multiple institutions to investigate whether dose-sparing to the
internal-pudendal-arteries (IPA) will improve retention of sexual potency. The
IPA is usually not considered a conventional organ-at-risk (OAR) due to
segmentation difficulty. In this work, we propose a deep learning (DL)-based
auto-segmentation model for the IPA that utilizes CT and MRI or CT alone as the
input image modality to accommodate variation in clinical practice. Materials
and methods: 86 patients with CT and MRI images and noisy IPA labels were
recruited in this study. We split the data into 42/14/30 for model training,
testing, and a clinical observer study, respectively. There were three major
innovations in this model: 1) we designed an architecture with
squeeze-and-excite blocks and modality attention for effective feature
extraction and production of accurate segmentation, 2) a novel loss function
was used for training the model effectively with noisy labels, and 3) modality
dropout strategy was used for making the model capable of segmentation in the
absence of MRI. Results: The DSC, ASD, and HD95 values for the test dataset
were 62.2%, 2.54mm, and 7mm, respectively. AI segmented contours were
dosimetrically equivalent to the expert physician's contours. The observer
study showed that expert physicians' scored AI contours (mean=3.7) higher than
inexperienced physicians' contours (mean=3.1). When inexperienced physicians
started with AI contours, the score improved to 3.7. Conclusion: The proposed
model achieved good quality IPA contours to improve uniformity of segmentation
and to facilitate introduction of standardized IPA segmentation into clinical
trials and practice.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:00:06 GMT""}]","2023-02-06"
"2302.01494","Xiangdong Zhang","Xiaoqi Zhou, Weixuan Zhang, Houjun Sun, and Xiangdong Zhang","Observation of flat-band localization and topological edge states
  induced by effective strong interactions in electrical circuit networks",,"Phys. Rev. B 107, 035152 (2023)","10.1103/PhysRevB.107.035152",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Flat-band topologies and localizations in non-interacting systems are
extensively studied in different quantum and classical-wave systems. Recently,
the exploration on the novel physics of flat-band localizations and topologies
in interacting systems has aroused great interest. In particular, it is
theoretically shown that the strong-interaction could drive the formation of
nontrivial topological flat bands, even dispersive trivial bands dominate the
single-particle counterparts. However, the experimental observation of those
interesting phenomena is still lacking. Here, we experimentally simulate the
interaction-induced flat-band localizations and topological edge states in
electrical circuit networks. We directly map the eigenstates of two correlated
bosons in one-dimensional Aharonov Bohm cages to modes of two-dimensional
circuit lattices.In this case, the two-boson flat-bands and topological edge
states are detected by measuring frequency-dependent impedance responses and
voltage dynamics in the time domain. Our finding suggests a flexible platform
to simulate the interaction-induced flat-band topology, and may possess
potential applications in designing novel electronic devices.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:02:37 GMT""}]","2023-02-08"
"2302.01495","Hsuan-Hao Lu","Hsuan-Hao Lu, Nicholas A. Peters, Andrew M. Weiner, Joseph M. Lukens","Characterization of Quantum Frequency Processors",,,"10.1109/JSTQE.2023.3266662",,"quant-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  Frequency-bin qubits possess unique synergies with wavelength-multiplexed
lightwave communications, suggesting valuable opportunities for quantum
networking with the existing fiber-optic infrastructure. Although the coherent
manipulation of frequency-bin states requires highly controllable
multi-spectral-mode interference, the quantum frequency processor (QFP)
provides a scalable path for gate synthesis leveraging standard telecom
components. Here we summarize the state of the art in experimental QFP
characterization. Distinguishing between physically motivated ''open box''
approaches that treat the QFP as a multiport interferometer, and ''black box''
approaches that view the QFP as a general quantum operation, we highlight the
assumptions and results of multiple techniques, including quantum process
tomography of a tunable beamsplitter -- to our knowledge the first full process
tomography of any frequency-bin operation. Our findings should inform future
characterization efforts as the QFP increasingly moves beyond
proof-of-principle tabletop demonstrations toward integrated devices and
deployed quantum networking experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:08:07 GMT""}]","2023-06-06"
"2302.01496","Junwen Bai","Bo Li, Dongseong Hwang, Zhouyuan Huo, Junwen Bai, Guru Prakash, Tara
  N. Sainath, Khe Chai Sim, Yu Zhang, Wei Han, Trevor Strohman, Francoise
  Beaufays","Efficient Domain Adaptation for Speech Foundation Models",,,,,"cs.CL cs.LG cs.SD eess.AS","http://creativecommons.org/licenses/by/4.0/","  Foundation models (FMs), that are trained on broad data at scale and are
adaptable to a wide range of downstream tasks, have brought large interest in
the research community. Benefiting from the diverse data sources such as
different modalities, languages and application domains, foundation models have
demonstrated strong generalization and knowledge transfer capabilities. In this
paper, we present a pioneering study towards building an efficient solution for
FM-based speech recognition systems. We adopt the recently developed
self-supervised BEST-RQ for pretraining, and propose the joint finetuning with
both source and unsupervised target domain data using JUST Hydra. The FM
encoder adapter and decoder are then finetuned to the target domain with a
small amount of supervised in-domain data. On a large-scale YouTube and Voice
Search task, our method is shown to be both data and model parameter efficient.
It achieves the same quality with only 21.6M supervised in-domain data and
130.8M finetuned parameters, compared to the 731.1M model trained from scratch
on additional 300M supervised in-domain data.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:10:35 GMT""}]","2023-02-06"
"2302.01497","Buru Chang","Byounggyu Lew, Donghyun Son, Buru Chang","Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained
  Models",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain generalization aims to build generalized models that perform well on
unseen domains when only source domains are available for model optimization.
Recent studies have demonstrated that large-scale pre-trained models could play
an important role in domain generalization by providing their generalization
power. However, large-scale pre-trained models are not fully equipped with
target task-specific knowledge due to a discrepancy between the pre-training
objective and the target task. Although the task-specific knowledge could be
learned from source domains by fine-tuning, this hurts the generalization power
of the pre-trained models because of gradient bias toward the source domains.
To address this issue, we propose a new domain generalization method that
estimates unobservable gradients that reduce potential risks in unseen domains,
using a large-scale pre-trained model. Our proposed method allows the
pre-trained model to learn task-specific knowledge further while preserving its
generalization ability with the estimated gradients. Experimental results show
that our proposed method outperforms baseline methods on DomainBed, a standard
benchmark in domain generalization. We also provide extensive analyses to
demonstrate that the estimated unobserved gradients relieve the gradient bias,
and the pre-trained model learns the task-specific knowledge without
sacrificing its generalization power.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:12:09 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 08:02:20 GMT""}]","2023-02-09"
"2302.01498","Bingyan Han","Erhan Bayraktar and Bingyan Han","Equilibrium transport with time-inconsistent costs: An application to
  matching problems in the job market","42 pages, 10 figures, 15 tables. Comments are welcome!",,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given two probability measures on sequential data, we investigate the
transport problem with time-inconsistent preferences under a discrete-time
setting. Motivating examples are nonlinear objectives, state-dependent costs,
and regularized optimal transport with general $f$-divergence. Under the
bi-causal constraint, we introduce the concept of equilibrium transport and
provide a characterization. We apply our framework to study inertia of two job
markets, top-ranking executives and academia. The empirical analysis shows that
a job market with stronger inertia is less efficient. The University of
California (UC) postdoc job market has the strongest inertia even than that of
executives, while there is no evidence of inertia in the UC faculty job market.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:22:25 GMT""}]","2023-02-06"
"2302.01499","Yang Zhao","Hanwei Wang, Joshua Yu, Xiaodong Ye, Yun-Sheng Chen, Yang Zhao","Qi standard metasurface for free-positioning and multi-device supportive
  wireless power transfer",,,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  Free-positioning and multi-user supportive wireless power transfer systems
represent the next-generation technology for wireless charging under the Qi
standard. Traditional approaches employ multiple transmitting coils and
multi-channel driving circuits with active control algorithms to achieve these
goals. However, these traditional approaches are significantly limited by cost,
weight, and heating due to their relatively low efficiency. Here, we
demonstrate an innovative approach by using a metasurface to achieve
free-positioning and multi-user compatibility. The metasurface works as a
passive device to reform the magnetic field and enables high-efficiency
free-positioning wireless power transfer with only a single transmitting coil.
It shows up to 4.6 times improvement in efficiency. The metasurface also
increases the coverage area from around 5 cm by 5 cm with over 40% efficiency
to around 10 cm by 10 cm with over 70% efficiency. We further show that the
system can support multiple receivers. Besides increasing the overall
efficiency, we demonstrate tuning the power division between the multiple
receivers, enabling compensation of receivers of different sizes to achieve
their desired power.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:29:56 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 05:37:26 GMT""},{""version"":""v3"",""created"":""Mon, 17 Apr 2023 20:46:08 GMT""}]","2023-04-19"
"2302.01500","Kazuma Suetake","Kazuma Suetake, Takuya Ushimaru, Ryuji Saiin, Yoshihide Sawada","Spiking Synaptic Penalty: Appropriate Penalty Term for Energy-Efficient
  Spiking Neural Networks","19 pages, 5 figures",,,,"cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spiking neural networks (SNNs) are energy-efficient neural networks because
of their spiking nature. However, as the spike firing rate of SNNs increases,
the energy consumption does as well, and thus, the advantage of SNNs
diminishes. Here, we tackle this problem by introducing a novel penalty term
for the spiking activity into the objective function in the training phase. Our
method is designed so as to optimize the energy consumption metric directly
without modifying the network architecture. Therefore, the proposed method can
reduce the energy consumption more than other methods while maintaining the
accuracy. We conducted experiments for image classification tasks, and the
results indicate the effectiveness of the proposed method, which mitigates the
dilemma of the energy--accuracy trade-off.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:30:00 GMT""}]","2023-02-06"
"2302.01501","Hamed Rahimi","Hamed Rahimi, Hubert Naacke, Camelia Constantin, Bernd Amann","ANTM: An Aligned Neural Topic Model for Exploring Evolving Topics",,,,,"cs.IR cs.AI cs.LG cs.NE cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents an algorithmic family of dynamic topic models called
Aligned Neural Topic Models (ANTM), which combine novel data mining algorithms
to provide a modular framework for discovering evolving topics. ANTM maintains
the temporal continuity of evolving topics by extracting time-aware features
from documents using advanced pre-trained Large Language Models (LLMs) and
employing an overlapping sliding window algorithm for sequential document
clustering. This overlapping sliding window algorithm identifies a different
number of topics within each time frame and aligns semantically similar
document clusters across time periods. This process captures emerging and
fading trends across different periods and allows for a more interpretable
representation of evolving topics. Experiments on four distinct datasets show
that ANTM outperforms probabilistic dynamic topic models in terms of topic
coherence and diversity metrics. Moreover, it improves the scalability and
flexibility of dynamic topic models by being accessible and adaptable to
different types of algorithms. Additionally, a Python package is developed for
researchers and scientists who wish to study the trends and evolving patterns
of topics in large-scale textual data.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:31:12 GMT""},{""version"":""v2"",""created"":""Sun, 4 Jun 2023 16:23:00 GMT""}]","2023-06-06"
"2302.01502","ByeongRok Ko","Andrew K. Yi, Saebyeok Ahn, \c{C}a\u{g}lar Kutlu, JinMyeong Kim,
  Byeong Rok Ko, Boris I. Ivanov, HeeSu Byun, Arjan F. van Loo, SeongTae Park,
  Junu Jeong, Ohjoon Kwon, Yasunobu Nakamura, Sergey V. Uchaikin, Jihoon Choi,
  Soohyung Lee, MyeongJae Lee, Yun Chang Shin, Jinsu Kim, Doyu Lee, Danho Ahn,
  SungJae Bae, Jiwon Lee, Younggeun Kim, Violeta Gkika, Ki Woong Lee, Seonjeong
  Oh, Taehyeon Seong, DongMin Kim, Woohyun Chung, Andrei Matlashov, SungWoo
  Youn, and Yannis K. Semertzidis","First Search for the Sagittarius Tidal Stream of Axion Dark Matter
  around 4.55 $\mu$eV","5 pages, 4 Figures",,,,"hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the first search for the Sagittarius tidal stream of axion dark
matter around 4.55 $\mu$eV using CAPP-12TB haloscope data acquired in March of
2022.
  Our result excluded the Sagittarius tidal stream of
Dine-Fischler-Srednicki-Zhitnitskii and Kim-Shifman-Vainshtein-Zakharov axion
dark matter densities of
  $\rho_a\gtrsim0.15$ and $\gtrsim0.02$~GeV/cm$^{3}$, respectively, over a mass
range from 4.51 to 4.59~$\mu$eV at a 90\% confidence level.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:31:24 GMT""}]","2023-02-06"
"2302.01503","Rui Xue","Rui Xue, Haoyu Han, MohamadAli Torkamani, Jian Pei, Xiaorui Liu","LazyGNN: Large-Scale Graph Neural Networks via Lazy Propagation",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works have demonstrated the benefits of capturing long-distance
dependency in graphs by deeper graph neural networks (GNNs). But deeper GNNs
suffer from the long-lasting scalability challenge due to the neighborhood
explosion problem in large-scale graphs. In this work, we propose to capture
long-distance dependency in graphs by shallower models instead of deeper
models, which leads to a much more efficient model, LazyGNN, for graph
representation learning. Moreover, we demonstrate that LazyGNN is compatible
with existing scalable approaches (such as sampling methods) for further
accelerations through the development of mini-batch LazyGNN. Comprehensive
experiments demonstrate its superior prediction performance and scalability on
large-scale benchmarks. The implementation of LazyGNN is available at
https://github.com/RXPHD/Lazy_GNN.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:33:07 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 00:49:33 GMT""}]","2023-06-02"
"2302.01504","Kun Wang","Kun Wang, Du Li, Jia Wang, Yifei Hao, Hailey Anderson, Li Yang, and
  Xia Hong","Interface-tuning of ferroelectricity and quadruple-well state in
  CuInP$_2$S$_6$ via ferroelectric oxide","18 pages, 5 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ferroelectric van der Waals CuInP$_2$S$_6$ possesses intriguing
quadruple-well states and negative piezoelectricity. Its technological
implementation has been impeded by the relatively low Curie temperature (bulk
$T_C$ ~42 {\deg}C) and the lack of precise domain control. Here we show that
CuInP$_2$S$_6$ can be immune to the finite size effect and exhibits enhanced
ferroelectricity, piezoelectricity, and polar alignment in the ultrathin limit
when interfaced with ferroelectric oxide PbZr$_{0.2}$Ti$_{0.8}$O$_3$ films.
Piezoresponse force microscopy studies reveal that the polar domains in thin
CuInP$_2$S$_6$ fully conform to those of underlying
PbZr$_{0.2}$Ti$_{0.8}$O$_3$, where the piezoelectric coefficient changes sign
and increases sharply with reducing thickness. The $T_C$ of 13 nm
CuInP$_2$S$_6$ on PbZr$_{0.2}$Ti$_{0.8}$O$_3$ exceeds 200 {\deg}C. Density
functional theory modeling and Monte Carlo simulations show that the enhanced
polar alignment and $T_C$ can be attributed to interface-mediated structure
distortion in CuInP$_2$S$_6$. Our study provides a new material strategy to
engineer the polar properties of CuInP$_2$S$_6$ for flexible nanoelectronic,
optoelectronic, and mechanical applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:37:59 GMT""}]","2023-02-06"
"2302.01505","Kashyap Patel","Kashyap Patel, Anton Kovalyov and Issa Panahi","Closed-Form Solution for Scaling a Wireless Acoustic Sensor Network","To be submitted to the Journal of Acoustical Society of America for
  publication",,,,"eess.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This study presents a closed-form solution for localizing and synchronizing
an acoustic sensor node with respect to a Wireless Acoustic Sensor Network
(WASN). The aim is to allow efficient scaling of a WASN by individually
calibrating newly joined sensor nodes instead of recalibrating the entire
array. A key contribution is that the sensor to be calibrated does not need to
include a built-in emitter. The proposed method uses signals emitted from
spatially distributed sources to compute time difference of arrival (TDOA)
measurements between the existing WASN and a new sensor. The problem is then
modeled as a set of multivariate nonlinear TDOA equations. Through a simple
transformation, the nonlinear TDOA equations are converted into a system of
linear equations. Then, weighted least squares (WLS) is applied to find an
accurate estimate of the calibration parameters. Signal sources can either be
known emitters within the existing WASN or arbitrary sources in the
environment, thus allowing for flexible applicability in both active and
passive calibration scenarios. Simulation results under various conditions show
high joint localization and synchronization performance, often comparable to
the Cram\'er-Rao lower bound (CRLB).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:38:58 GMT""}]","2023-02-06"
"2302.01506","Alexander Kiy","Alexander Kiy, Shankar Dutt, Christian Notthoff, Maria E.
  Toimil-Molares, Nigel Kirby, Patrick Kluth","Highly Rectifying Conical Nanopores in Amorphous SiO2 Membranes for
  Nanofluidic Osmotic Power Generation and Electroosmotic Pumps",,,"10.1021/acsanm.3c00960",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Nanopore membranes are a versatile platform for a wide range of applications
ranging from medical sensing to filtration and clean energy generation. To
attain high-flux rectifying ionic flow, it is required to produce short
channels exhibiting asymmetric surface charge distributions. This work reports
on a system of track etched conical nanopores in amorphous SiO$_2$ membranes,
fabricated using the scalable track etch technique. Pores are fabricated by
irradiation of 1 $\mu$m thick SiO$_2$ windows with 2.2 GeV $^{197}$Au ions and
subsequent chemical etching. Structural characterisation is performed using
atomic force microscopy (AFM), scanning electron microscopy (SEM), small angle
X-ray scattering (SAXS), ellipsometry, and surface profiling. Conductometric
characterisation of the pore surface is performed using a membrane containing
16 pores, including an in-depth analysis of ionic transport characteristics.
The pores have a tip radius of (5.7 $\pm$ 0.1) nm, a half-cone angle of (12.6
$\pm$ 0.1)$^{\circ}$, and a length of (710 $\pm$ 5) nm. The $pK_a$, $pK_b$, and
$pI$ are determined to 7.6 $\pm$ 0.1, 1.5 $\pm$ 0.2, and 4.5 $\pm$ 0.1,
respectively, enabling the fine-tuning of the surface charge density between
+100 and -300 mC $m^{-2}$ and allowing to achieve an ionic current
rectification ratio of up to 10. This highly versatile technology addresses
challenges that contemporary nanopore systems face, and offers a platform to
improve the performance of existing applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:39:43 GMT""},{""version"":""v2"",""created"":""Tue, 21 Feb 2023 05:14:25 GMT""},{""version"":""v3"",""created"":""Thu, 4 May 2023 06:13:15 GMT""}]","2023-05-12"
"2302.01507","Chaowei Fang","Chaowei Fang, Dingwen Zhang, Wen Zheng, Xue Li, Le Yang, Lechao Cheng,
  Junwei Han","Revisiting Long-tailed Image Classification: Survey and Benchmarks with
  New Evaluation Metrics",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, long-tailed image classification harvests lots of research
attention, since the data distribution is long-tailed in many real-world
situations. Piles of algorithms are devised to address the data imbalance
problem by biasing the training process towards less frequent classes. However,
they usually evaluate the performance on a balanced testing set or multiple
independent testing sets having distinct distributions with the training data.
Considering the testing data may have arbitrary distributions, existing
evaluation strategies are unable to reflect the actual classification
performance objectively. We set up novel evaluation benchmarks based on a
series of testing sets with evolving distributions. A corpus of metrics are
designed for measuring the accuracy, robustness, and bounds of algorithms for
learning with long-tailed distribution. Based on our benchmarks, we re-evaluate
the performance of existing methods on CIFAR10 and CIFAR100 datasets, which is
valuable for guiding the selection of data rebalancing techniques. We also
revisit existing methods and categorize them into four types including data
balancing, feature balancing, loss balancing, and prediction balancing,
according the focused procedure during the training pipeline.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:40:54 GMT""}]","2023-02-06"
"2302.01508","Fangzhou Wang","Fangzhou Wang and A. Lee Swindlehurst","Applications of Absorptive Reconfigurable Intelligent Surfaces in
  Interference Mitigation and Physical Layer Security","13 pages, 13 figures, submitted for journal publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores the use of reconfigurable intelligent surfaces (RIS) in
mitigating cross-system interference in spectrum sharing and secure wireless
applications. Unlike conventional RIS that can only adjust the phase of the
incoming signal and essentially reflect all impinging energy, or active RIS,
which also amplify the reflected signal at the cost of significantly higher
complexity, noise, and power consumption, an absorptive RIS (ARIS) is
considered. An ARIS can in principle modify both the phase and modulus of the
impinging signal by absorbing a portion of the signal energy, providing a
compromise between its conventional and active counterparts in terms of
complexity, power consumption, and degrees of freedom (DoFs). We first use a
toy example to illustrate the benefit of ARIS, and then we consider three
applications: (1) Spectral coexistence of radar and communication systems,
where a convex optimization problem is formulated to minimize the Frobenius
norm of the channel matrix from the communication base station to the radar
receiver; (2) Spectrum sharing in device-to-device (D2D) communications, where
a max-min scheme that maximizes the worst-case
signal-to-interference-plus-noise ratio (SINR) among the D2D links is developed
and then solved via fractional programming; (3) The physical layer security of
a downlink communication system, where the secrecy rate is maximized and the
resulting nonconvex problem is solved by a fractional programming algorithm
together with a sequential convex relaxation procedure. Numerical results are
then presented to show the significant benefit of ARIS in these applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:41:33 GMT""}]","2023-02-06"
"2302.01509","Tom Hutchcroft","Philip Easo, Tom Hutchcroft, and Jana Kurrek","Double-exponential susceptibility growth in Dyson's hierarchical model
  with $|x-y|^{-2}$ interaction","17 pages",,,,"math.PR math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study long-range percolation on the $d$-dimensional hierarchical lattice,
in which each possible edge $\{x,y\}$ is included independently at random with
inclusion probability $1-\exp ( -\beta \|x-y\|^{-d-\alpha} )$, where $\alpha>0$
is fixed and $\beta\geq 0$ is a parameter. This model is known to have a phase
transition at some $\beta_c<\infty$ if and only if $\alpha<d$. We study the
model in the regime $\alpha \geq d$, in which $\beta_c=\infty$, and prove that
the susceptibility $\chi(\beta)$ (i.e., the expected volume of the cluster at
the origin) satisfies \[
  \chi(\beta) =
  \beta^{\frac{d}{\alpha - d } - o(1)} \qquad \text{as $\beta \to \infty$ if
$\alpha > d$} \qquad \text{and} \qquad
  e^{e^{ \Theta(\beta) }} \qquad \text{as $\beta \to \infty$ if $\alpha = d$.}
  \] This resolves a problem raised by Georgakopoulos and Haslegrave (2020),
who showed that $\chi(\beta)$ grows between exponentially and
double-exponentially when $\alpha=d$. Our results imply that analogous results
hold for a number of related models including Dyson's hierarchical Ising model,
for which the double-exponential susceptibility growth we establish appears to
be a new phenomenon even at the heuristic level.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:43:00 GMT""}]","2023-02-06"
"2302.01510","Yuanfeng Yu","Yuanfeng Yu, Xiaoya Zheng","An AsFem implementation for quasi-static brittle fracture phase field
  model","24 pages, 20 figures",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phase field method has been widely used because of its excellent ability to
simulate fracture problems. At present, the implementation process is mainly
based on commercial software, and the operation process is relatively complex.
In this paper, 2D and 3D phase field models are implemented in the open-source
finite element software package AsFem. Compared with commercial software, it is
simpler to realize phase field fracture model in AsFem. At the same time, a
robust staggered scheme and an efficient monolithic scheme can be used to solve
the displacement field and phase field sub-problem, and the transformation
process is very easy. Several examples are tested to demonstrate the
performance of the current implementation. The simulation results are in good
agreement with the previous work, which shows the feasibility and effectiveness
of implementing the phase field method in AsFem. In the future, more complex
multi-field coupled phase field fracture problems can be solved with AsFem.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:45:41 GMT""}]","2023-02-06"
"2302.01511","Shion Takeno","Shion Takeno, Yu Inatsu, Masayuki Karasuyama","Randomized Gaussian Process Upper Confidence Bound with Tight Bayesian
  Regret Bounds",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Gaussian process upper confidence bound (GP-UCB) is a theoretically promising
approach for black-box optimization; however, the confidence parameter $\beta$
is considerably large in the theorem and chosen heuristically in practice.
Then, randomized GP-UCB (RGP-UCB) uses a randomized confidence parameter, which
follows the Gamma distribution, to mitigate the impact of manually specifying
$\beta$. This study first generalizes the regret analysis of RGP-UCB to a wider
class of distributions, including the Gamma distribution. Furthermore, we
propose improved RGP-UCB (IRGP-UCB) based on a two-parameter exponential
distribution, which achieves tight Bayesian regret bounds. IRGP-UCB does not
require an increase in the confidence parameter in terms of the number of
iterations, which avoids over-exploration in the later iterations. Finally, we
demonstrate the effectiveness of IRGP-UCB through extensive experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:48:48 GMT""}]","2023-02-06"
"2302.01512","Lei Tan","Lei Tan, Pingyang Dai, Qixiang Ye, Mingliang Xu, Yongjian Wu, Rongrong
  Ji","Spectral Aware Softmax for Visible-Infrared Person Re-Identification",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visible-infrared person re-identification (VI-ReID) aims to match specific
pedestrian images from different modalities. Although suffering an extra
modality discrepancy, existing methods still follow the softmax loss training
paradigm, which is widely used in single-modality classification tasks. The
softmax loss lacks an explicit penalty for the apparent modality gap, which
adversely limits the performance upper bound of the VI-ReID task. In this
paper, we propose the spectral-aware softmax (SA-Softmax) loss, which can fully
explore the embedding space with the modality information and has clear
interpretability. Specifically, SA-Softmax loss utilizes an asynchronous
optimization strategy based on the modality prototype instead of the
synchronous optimization based on the identity prototype in the original
softmax loss. To encourage a high overlapping between two modalities,
SA-Softmax optimizes each sample by the prototype from another spectrum. Based
on the observation and analysis of SA-Softmax, we modify the SA-Softmax with
the Feature Mask and Absolute-Similarity Term to alleviate the ambiguous
optimization during model training. Extensive experimental evaluations
conducted on RegDB and SYSU-MM01 demonstrate the superior performance of the
SA-Softmax over the state-of-the-art methods in such a cross-modality
condition.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:57:18 GMT""}]","2023-02-06"
"2302.01513","Shion Takeno","Shion Takeno, Masahiro Nomura, Masayuki Karasuyama","Towards Practical Preferential Bayesian Optimization with Skew Gaussian
  Processes",,,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study preferential Bayesian optimization (BO) where reliable feedback is
limited to pairwise comparison called duels. An important challenge in
preferential BO, which uses the preferential Gaussian process (GP) model to
represent flexible preference structure, is that the posterior distribution is
a computationally intractable skew GP. The most widely used approach for
preferential BO is Gaussian approximation, which ignores the skewness of the
true posterior. Alternatively, Markov chain Monte Carlo (MCMC) based
preferential BO is also proposed. In this work, we first verify the accuracy of
Gaussian approximation, from which we reveal the critical problem that the
predictive probability of duels can be inaccurate. This observation motivates
us to improve the MCMC-based estimation for skew GP, for which we show the
practical efficiency of Gibbs sampling and derive the low variance MC
estimator. However, the computational time of MCMC can still be a bottleneck in
practice. Towards building a more practical preferential BO, we develop a new
method that achieves both high computational efficiency and low sample
complexity, and then demonstrate its effectiveness through extensive numerical
experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:02:38 GMT""}]","2023-02-06"
"2302.01514","Yuhiko Aoyama","Yuhiko Aoyama and Xuening Bai","Three-dimensional Global Simulations of Type-II Planet-disk Interaction
  with a Magnetized Disk Wind: I. Magnetic Flux Concentration and Gap
  Properties","42 pages, 24 figures, Accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/acb81f",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Giant planets embedded in protoplanetary disks (PPDs) can create annulus
density gaps around their orbits in the type-II regime, potentially responsible
for the ubiquity of annular substructures observed in PPDs. Despite of
substantial amount of works studying type-II planet migration and gap
properties, they are almost exclusively conducted under the viscous accretion
disk framework. However, recent studies have established magnetized disk winds
as the primary driving disk accretion and evolution, which can co-exist with
turbulence from the magneto-rotational instability (MRI) in the outer PPDs. We
conduct a series of 3D global non-ideal magneto-hydrodynamic (MHD) simulations
of type-II planet-disk interaction applicable to the outer PPDs. Our
simulations properly resolve the MRI turbulence and accommodate the MHD disk
wind. We found that the planet triggers the poloidal magnetic flux
concentration around its orbit. The concentrated magnetic flux strongly
enhances angular momentum removal in the gap, which is along the inclined
poloidal field through a strong outflow emanating from the disk surface outward
of the planet gap. The resulting planet-induced gap shape is more similar to an
inviscid disk, while being much deeper, which can be understood from a simple
inhomogeneous wind torque prescription. The corotation region is characterized
by a fast trans-sonic accretion flow that is asymmetric in azimuth about the
planet and lacking the horseshoe turns, and the meridional flow is weakened.
The torque acting on the planet generally drives inward migration, though the
migration rate can be affected by the presence of neighboring gaps through
stochastic, planet-free magnetic flux concentration.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:06:32 GMT""}]","2023-03-29"
"2302.01515","Ashish Devaraj","Ashish Devaraj, Prajwel Joseph, C. S. Stalin, Shyam N. Tandon, Swarna
  K. Ghosh","UVIT observations of the Small Magellanic Cloud: Point source catalogue",,,"10.3847/1538-4357/acba9c",,"astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three fields in the outskirts of the Small Magellanic Cloud were observed by
the Ultra-Violet Imaging Telescope (UVIT) on board AstroSat, during 31 December
2017 and 01 January 2018. The observations were carried out on a total of seven
filters, three in the far ultra-violet (FUV; 1300$-$1800 \r{A}) band and four
in the near ultra-violet (NUV; 2000$-$3000 \r{A}) band. We carried out
photometry of these observations that have a spatial resolution better than
1.5$^{\prime\prime}$. We present here the first results of this work, which is
a matched catalogue of 11,241 sources detected in three FUV and four NUV
wavelengths. We make the catalogue available online, which would be of use to
the astronomical community to address a wide variety of astrophysical problems.
We provide an expression to estimate the total count rate in the full point
spread function of UVIT that also incorporate the effect of saturation.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:07:09 GMT""}]","2023-04-05"
"2302.01516","Pengcheng Xu","Pengcheng Xu, Boyu Wang, Charles Ling","Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation",,"AAAI2023 Oral",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Current methods of blended targets domain adaptation (BTDA) usually infer or
consider domain label information but underemphasize hybrid categorical feature
structures of targets, which yields limited performance, especially under the
label distribution shift. We demonstrate that domain labels are not directly
necessary for BTDA if categorical distributions of various domains are
sufficiently aligned even facing the imbalance of domains and the label
distribution shift of classes. However, we observe that the cluster assumption
in BTDA does not comprehensively hold. The hybrid categorical feature space
hinders the modeling of categorical distributions and the generation of
reliable pseudo labels for categorical alignment. To address these, we propose
a categorical domain discriminator guided by uncertainty to explicitly model
and directly align categorical distributions $P(Z|Y)$. Simultaneously, we
utilize the low-level features to augment the single source features with
diverse target styles to rectify the biased classifier $P(Y|Z)$ among diverse
targets. Such a mutual conditional alignment of $P(Z|Y)$ and $P(Y|Z)$ forms a
mutual reinforced mechanism. Our approach outperforms the state-of-the-art in
BTDA even compared with methods utilizing domain labels, especially under the
label distribution shift, and in single target DA on DomainNet. Source codes
are available at
\url{https://github.com/Pengchengpcx/Class-overwhelms-Mutual-Conditional-Blended-Target-Domain-Adaptation}.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:08:31 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 22:58:21 GMT""}]","2023-03-10"
"2302.01517","Jonathan Schneider","Christoph Dann, Yishay Mansour, Mehryar Mohri, Jon Schneider,
  Balasubramanian Sivan","Pseudonorm Approachability and Applications to Regret Minimization","To appear at ALT 2023",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blackwell's celebrated approachability theory provides a general framework
for a variety of learning problems, including regret minimization. However,
Blackwell's proof and implicit algorithm measure approachability using the
$\ell_2$ (Euclidean) distance. We argue that in many applications such as
regret minimization, it is more useful to study approachability under other
distance metrics, most commonly the $\ell_\infty$-metric. But, the time and
space complexity of the algorithms designed for $\ell_\infty$-approachability
depend on the dimension of the space of the vectorial payoffs, which is often
prohibitively large. Thus, we present a framework for converting
high-dimensional $\ell_\infty$-approachability problems to low-dimensional
pseudonorm approachability problems, thereby resolving such issues. We first
show that the $\ell_\infty$-distance between the average payoff and the
approachability set can be equivalently defined as a pseudodistance between a
lower-dimensional average vector payoff and a new convex set we define. Next,
we develop an algorithmic theory of pseudonorm approachability, analogous to
previous work on approachability for $\ell_2$ and other norms, showing that it
can be achieved via online linear optimization (OLO) over a convex set given by
the Fenchel dual of the unit pseudonorm ball. We then use that to show, modulo
mild normalization assumptions, that there exists an
$\ell_\infty$-approachability algorithm whose convergence is independent of the
dimension of the original vectorial payoff. We further show that that algorithm
admits a polynomial-time complexity, assuming that the original
$\ell_\infty$-distance can be computed efficiently. We also give an
$\ell_\infty$-approachability algorithm whose convergence is logarithmic in
that dimension using an FTRL algorithm with a maximum-entropy regularizer.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:19:14 GMT""}]","2023-02-06"
"2302.01518","Jian Cheng Wong","Jian Cheng Wong, Pao-Hsiung Chiu, Chinchun Ooi, My Ha Dao, Yew-Soon
  Ong","LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex
  Geometry","11 pages, 7 figures",,,,"cs.LG cs.CE physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We present a novel loss formulation for efficient learning of complex
dynamics from governing physics, typically described by partial differential
equations (PDEs), using physics-informed neural networks (PINNs). In our
experiments, existing versions of PINNs are seen to learn poorly in many
problems, especially for complex geometries, as it becomes increasingly
difficult to establish appropriate sampling strategy at the near boundary
region. Overly dense sampling can adversely impede training convergence if the
local gradient behaviors are too complex to be adequately modelled by PINNs. On
the other hand, if the samples are too sparse, existing PINNs tend to overfit
the near boundary region, leading to incorrect solution. To prevent such
issues, we propose a new Boundary Connectivity (BCXN) loss function which
provides linear local structure approximation (LSA) to the gradient behaviors
at the boundary for PINN. Our BCXN-loss implicitly imposes local structure
during training, thus facilitating fast physics-informed learning across entire
problem domains with order of magnitude sparser training samples. This LSA-PINN
method shows a few orders of magnitude smaller errors than existing methods in
terms of the standard L2-norm metric, while using dramatically fewer training
samples and iterations. Our proposed LSA-PINN does not pose any requirement on
the differentiable property of the networks, and we demonstrate its benefits
and ease of implementation on both multi-layer perceptron and convolutional
neural network versions as commonly used in current PINN literature.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:26:08 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 15:36:08 GMT""}]","2023-03-03"
"2302.01519","C. Ward Henson","Alexander Berenstein and C. Ward Henson","Model theory of probability spaces","58 pages; to appear in the volume ""Model theory of operator algebras""
  as part of DeGruyter's Logic and its Application Series",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This expository paper treats the model theory of probability spaces using the
framework of continuous $[0,1]$-valued first order logic. The metric structures
discussed, which we call probability algebras, are obtained from probability
spaces by identifying two measurable sets if they differ by a set of measure
zero. The class of probability algebras is axiomatizable in continuous first
order logic; we denote its theory by $Pr$. We show that the existentially
closed structures in this class are exactly the ones in which the underlying
probability space is atomless. This subclass is also axiomatizable; its theory
$APA$ is the model companion of $Pr$. We show that $APA$ is separably
categorical (hence complete), has quantifier elimination, is $\omega$-stable,
and has built-in canonical bases, and we give a natural characterization of its
independence relation. For general probability algebras, we prove that the set
of atoms (enlarged by adding $0$) is a definable set, uniformly in models of
$Pr$. We use this fact as a basis for giving a complete treatment of the model
theory of arbitrary probability spaces. The core of this paper is an extensive
presentation of the main model theoretic properties of $APA$. We discuss
Maharam's structure theorem for probability algebras, and indicate the close
connections between the ideas behind it and model theory. We show how
probabilistic entropy provides a rank connected to model theoretic forking in
probability algebras. In the final section we mention some open problems.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:26:20 GMT""}]","2023-02-06"
"2302.01520","Ronghao Dang","Ronghao Dang, Lu Chen, Liuyi Wang, Zongtao He, Chengju Liu, Qijun Chen","Multiple Thinking Achieving Meta-Ability Decoupling for Object
  Navigation","17 pages",,,,"cs.RO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a meta-ability decoupling (MAD) paradigm, which brings together
various object navigation methods in an architecture system, allowing them to
mutually enhance each other and evolve together. Based on the MAD paradigm, we
design a multiple thinking (MT) model that leverages distinct thinking to
abstract various meta-abilities. Our method decouples meta-abilities from three
aspects: input, encoding, and reward while employing the multiple thinking
collaboration (MTC) module to promote mutual cooperation between thinking. MAD
introduces a novel qualitative and quantitative interpretability system for
object navigation. Through extensive experiments on AI2-Thor and RoboTHOR, we
demonstrate that our method outperforms state-of-the-art (SOTA) methods on both
typical and zero-shot object navigation tasks.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:29:41 GMT""}]","2023-02-06"
"2302.01521","Melissa Lee","Melissa Lee","Primitive almost simple IBIS groups with sporadic socle","5 pages",,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An irredundant base $B$ for a permutation group $G\leq \mathrm{Sym}(\Omega)$
is an ordered subset of $\Omega$ with trivial stabiliser such that no base
point is fixed by the stabiliser of its predecessors. Groups whose irredundant
bases all have the same size are termed Irredundant Bases of Invariant Size
(IBIS) groups, and were introduced by Cameron and Fon-Der-Flaass. In this
paper, we contribute to the classification of primitive IBIS groups by
classifying those that are almost simple with sporadic socle.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:30:16 GMT""}]","2023-02-06"
"2302.01522","Alexander Kushkuley","Alexander Kushkuley and Joshua Correa","Improving Recommendation Relevance by simulating User Interest",,,,,"math.NA cs.IR cs.LG cs.NA stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most if not all on-line item-to-item recommendation systems rely on
estimation of a distance like measure (rank) of similarity between items. For
on-line recommendation systems, time sensitivity of this similarity measure is
extremely important. We observe that recommendation ""recency"" can be
straightforwardly and transparently maintained by iterative reduction of ranks
of inactive items. The paper briefly summarizes algorithmic developments based
on this self-explanatory observation. The basic idea behind this work is
patented in a context of online recommendation systems.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:35:28 GMT""}]","2023-02-06"
"2302.01523","Jason Cheuk Nam Liang","Yuan Deng, Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang,
  Vahab Mirrokni","Multi-channel Autobidding with Budget and ROI Constraints",,,,,"cs.GT cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In digital online advertising, advertisers procure ad impressions
simultaneously on multiple platforms, or so-called channels, such as Google
Ads, Meta Ads Manager, etc., each of which consists of numerous ad auctions. We
study how an advertiser maximizes total conversion (e.g. ad clicks) while
satisfying aggregate return-on-investment (ROI) and budget constraints across
all channels. In practice, an advertiser does not have control over, and thus
cannot globally optimize, which individual ad auctions she participates in for
each channel, and instead authorizes a channel to procure impressions on her
behalf: the advertiser can only utilize two levers on each channel, namely
setting a per-channel budget and per-channel target ROI. In this work, we first
analyze the effectiveness of each of these levers for solving the advertiser's
global multi-channel problem. We show that when an advertiser only optimizes
over per-channel ROIs, her total conversion can be arbitrarily worse than what
she could have obtained in the global problem. Further, we show that the
advertiser can achieve the global optimal conversion when she only optimizes
over per-channel budgets. In light of this finding, under a bandit feedback
setting that mimics real-world scenarios where advertisers have limited
information on ad auctions in each channels and how channels procure ads, we
present an efficient learning algorithm that produces per-channel budgets whose
resulting conversion approximates that of the global optimal problem. Finally,
we argue that all our results hold for both single-item and multi-item auctions
from which channels procure impressions on advertisers' behalf.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:38:19 GMT""},{""version"":""v2"",""created"":""Mon, 13 Feb 2023 18:26:35 GMT""}]","2023-02-14"
"2302.01524","Yunchong Song","Yunchong Song, Chenghu Zhou, Xinbing Wang, Zhouhan Lin","Ordered GNN: Ordering Message Passing to Deal with Heterophily and
  Over-smoothing","Published as a conference paper at ICLR 2023",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Most graph neural networks follow the message passing mechanism. However, it
faces the over-smoothing problem when multiple times of message passing is
applied to a graph, causing indistinguishable node representations and prevents
the model to effectively learn dependencies between farther-away nodes. On the
other hand, features of neighboring nodes with different labels are likely to
be falsely mixed, resulting in the heterophily problem. In this work, we
propose to order the messages passing into the node representation, with
specific blocks of neurons targeted for message passing within specific hops.
This is achieved by aligning the hierarchy of the rooted-tree of a central node
with the ordered neurons in its node representation. Experimental results on an
extensive set of datasets show that our model can simultaneously achieve the
state-of-the-art in both homophily and heterophily settings, without any
targeted design. Moreover, its performance maintains pretty well while the
model becomes really deep, effectively preventing the over-smoothing problem.
Finally, visualizing the gating vectors shows that our model learns to behave
differently between homophily and heterophily settings, providing an
explainable graph neural model.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:38:50 GMT""}]","2023-02-06"
"2302.01525","Yan Zhou Dr.","Yan Zhou, Shi Zhou, Shun Wan, Bo Zou, Yuxia Feng, Rui Mei, Heng Wu,
  Pingheng Tan, Naoteru Shigekawa, Jianbo Liang and Martin Kuball","Tuning the Interlayer Microstructure and Residual Stress of Buffer-Free
  Direct Bonding GaN/Si Heterostructures","15 pages, 3 figures",,"10.1063/5.0135138",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The direct integration of GaN with Si can boost great potential for low-cost,
large-scale, and high-power device applications. However, it is still
challengeable to directly grow GaN on Si without using thick strain relief
buffer layers due to their large lattice and thermal-expansion-coefficient
mismatches. In this work, a GaN/Si heterointerface without any buffer layer is
successfully fabricated at room temperature via surface activated bonding
(SAB). The residual stress states and interfacial microstructures of GaN/Si
heterostructures were systematically investigated through micro-Raman
spectroscopy and transmission electron microscopy. Compared to the large
compressive stress that existed in GaN layers grown-on-Si by MOCVD, a
significantly relaxed and uniform small tensile stress was observed in GaN
layers bonded-to-Si by SAB; this is mainly ascribed to the amorphous layer
formed at the bonding interface. In addition, the interfacial microstructure
and stress states of bonded GaN/Si heterointerfaces was found can be
significantly tuned by appropriate thermal annealing. This work moves an
important step forward directly integrating GaN to the present Si CMOS
technology with high quality thin interfaces, and brings great promises for
wafer-scale low-cost fabrication of GaN electronics.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:42:39 GMT""}]","2023-03-08"
"2302.01526","Shin-Nosuke Ishikawa","Shin-nosuke Ishikawa, Masato Todo, Masato Taki, Yasunobu Uchiyama,
  Kazunari Matsunaga, Peihsuan Lin, Taiki Ogihara, Masao Yasui","Example-Based Explainable AI and its Application for Remote Sensing
  Image Classification","10 pages, 4 figures, accepted for publication in International
  Journal of Applied Earth Observation and Geoinformation",,,,"cs.AI cs.CV cs.LG physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a method of explainable artificial intelligence (XAI), ""What I
Know (WIK)"", to provide additional information to verify the reliability of a
deep learning model by showing an example of an instance in a training dataset
that is similar to the input data to be inferred and demonstrate it in a remote
sensing image classification task. One of the expected roles of XAI methods is
verifying whether inferences of a trained machine learning model are valid for
an application, and it is an important factor that what datasets are used for
training the model as well as the model architecture. Our data-centric approach
can help determine whether the training dataset is sufficient for each
inference by checking the selected example data. If the selected example looks
similar to the input data, we can confirm that the model was not trained on a
dataset with a feature distribution far from the feature of the input data.
With this method, the criteria for selecting an example are not merely data
similarity with the input data but also data similarity in the context of the
model task. Using a remote sensing image dataset from the Sentinel-2 satellite,
the concept was successfully demonstrated with reasonably selected examples.
This method can be applied to various machine-learning tasks, including
classification and regression.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:48:43 GMT""}]","2023-02-06"
"2302.01527","Andrew Nemec","Andrew Nemec","Quantum Data-Syndrome Codes: Subsystem and Impure Code Constructions","9 pages, 3 figures",,,,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum error correction requires the use of error syndromes derived from
measurements that may be unreliable. Recently, quantum data-syndrome (QDS)
codes have been proposed as a possible approach to protect against both data
and syndrome errors, in which a set of linearly dependent stabilizer
measurements are performed to increase redundancy. Motivated by wanting to
reduce the total number of measurements performed, we introduce QDS subsystem
codes, and show that they can outperform similar QDS stabilizer codes derived
from them. We also give a construction of single-error-correcting QDS
stabilizer codes from impure stabilizer codes, and show that any such code must
satisfy a variant of the quantum Hamming bound for QDS codes. Finally, we use
this bound to prove a new bound that applies to impure, but not pure,
stabilizer codes that may be of independent interest.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 03:57:19 GMT""}]","2023-02-06"
"2302.01528","Gordana Popovic","Gordana Popovic, Tanya J. Mason, Tiago A. Marques, Joanne Potts,
  Szymon M. Drobniak, Roc\'io Joo, Res Altwegg, Carolyn C. I. Burns, Michael A.
  McCarthy, Alison Johnston, Shinichi Nakagawa, Louise McMillan, Kadambari
  Devarajan, Patrick l. Taggart, Alison C. Wunderlich, Magdalena M. Mair, Juan
  Andr\'es Mart\'inez-Lanfranco, Malgorzata Lagisz, Patrice P. Pottier","Four principles for improved statistical ecology","19 pages, 2 figures",,,,"stat.ME q-bio.PE stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Increasing attention has been drawn to the misuse of statistical methods over
recent years, with particular concern about the prevalence of practices such as
poor experimental design, cherry-picking and inadequate reporting. These
failures are largely unintentional and no more common in ecology than in other
scientific disciplines, with many of them easily remedied given the right
guidance.
  Originating from a discussion at the 2020 International Statistical Ecology
Conference, we show how ecologists can build their research following four
guiding principles for impactful statistical research practices: 1. Define a
focused research question, then plan sampling and analysis to answer it; 2.
Develop a model that accounts for the distribution and dependence of your data;
3. Emphasise effect sizes to replace statistical significance with ecological
relevance; 4. Report your methods and findings in sufficient detail so that
your research is valid and reproducible.
  Listed in approximate order of importance, these principles provide a
framework for experimental design and reporting that guards against unsound
practices. Starting with a well-defined research question allows researchers to
create an efficient study to answer it, and guards against poor research
practices that lead to false positives and poor replicability. Correct and
appropriate statistical models give sound conclusions, good reporting practices
and a focus on ecological relevance make results impactful and replicable.
  Illustrated with an example from a recent study into the impact of
disturbance on upland swamps, this paper explains the rationale for the
selection and use of effective statistical practices and provides practical
guidance for ecologists seeking to improve their use of statistical methods.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:01:58 GMT""}]","2023-02-06"
"2302.01529","Liang Yan","Zhiwei Gao, Tao Tang, Liang Yan, Tao Zhou","Failure-informed adaptive sampling for PINNs, Part II: combining with
  re-sampling and subset simulation",,,,,"math.NA cs.NA stat.ML","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This is the second part of our series works on failure-informed adaptive
sampling for physic-informed neural networks (FI-PINNs). In our previous work
\cite{gao2022failure}, we have presented an adaptive sampling framework by
using the failure probability as the posterior error indicator, where the
truncated Gaussian model has been adopted for estimating the indicator. In this
work, we present two novel extensions to FI-PINNs. The first extension consist
in combining with a re-sampling technique, so that the new algorithm can
maintain a constant training size. This is achieved through a cosine-annealing,
which gradually transforms the sampling of collocation points from uniform to
adaptive via training progress. The second extension is to present the subset
simulation algorithm as the posterior model (instead of the truncated Gaussian
model) for estimating the error indicator, which can more effectively estimate
the failure probability and generate new effective training points in the
failure region. We investigate the performance of the new approach using
several challenging problems, and numerical experiments demonstrate a
significant improvement over the original algorithm.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:05:06 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 10:18:01 GMT""}]","2023-03-01"
"2302.01530","Jongwoo Ko","Jongwoo Ko, Seungjoon Park, Minchan Jeong, Sukjin Hong, Euijai Ahn,
  Du-Seong Chang, Se-Young Yun","Revisiting Intermediate Layer Distillation for Compressing Language
  Models: An Overfitting Perspective","The 17th Conference of the European Chapter of the Association for
  Computational Linguistics (Findings)",,,,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  Knowledge distillation (KD) is a highly promising method for mitigating the
computational problems of pre-trained language models (PLMs). Among various KD
approaches, Intermediate Layer Distillation (ILD) has been a de facto standard
KD method with its performance efficacy in the NLP field. In this paper, we
find that existing ILD methods are prone to overfitting to training datasets,
although these methods transfer more information than the original KD. Next, we
present the simple observations to mitigate the overfitting of ILD: distilling
only the last Transformer layer and conducting ILD on supplementary tasks.
Based on our two findings, we propose a simple yet effective
consistency-regularized ILD (CR-ILD), which prevents the student model from
overfitting the training dataset. Substantial experiments on distilling BERT on
the GLUE benchmark and several synthetic datasets demonstrate that our proposed
ILD method outperforms other KD techniques. Our code is available at
https://github.com/jongwooko/CR-ILD.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:09:22 GMT""}]","2023-02-06"
"2302.01531","Yohsuke Enomoto","Yohsuke Enomoto, Takahiro Nishimichi, Atsushi Taruya","Universal multi-stream radial structures of cold dark matter halos","7 pages, 4 figures",,,"YITP-22-163","astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Virialized halos of cold dark matter generically exhibit multi-stream
structures of accreted dark matter within an outermost radial caustic known as
the splashback radius. By tracking the particle trajectories that accrete onto
the halos in cosmological $N$-body simulations, we count their number of
apocenter passages ($p$), and use them to characterize the multi-stream
structure of dark matter particles. We find that the radial density profile for
each stream, classified by the number of apocenter passages, exhibits universal
features, and can be described by a double power-law function comprising inner
shallow and outer steep slopes of indices of $-1$ and $-8$, respectively.
Surprisingly, these properties hold over a wide range of halo masses. The
double-power law feature is persistent when dividing the sample by
concentration or accretion rate. The dependence of the characteristic scale and
amplitude of the profile on $p$ cannot be replicated by known self-similar
solutions, requiring consideration of complexities such as the distribution of
angular momentum or mergers.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:09:57 GMT""}]","2023-02-06"
"2302.01532","Shengze Wang","Shengze Wang, Alexey Supikov, Joshua Ratcliff, Henry Fuchs, Ronald
  Azuma","INV: Towards Streaming Incremental Neural Videos",,,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent works in spatiotemporal radiance fields can produce photorealistic
free-viewpoint videos. However, they are inherently unsuitable for interactive
streaming scenarios (e.g. video conferencing, telepresence) because have an
inevitable lag even if the training is instantaneous. This is because these
approaches consume videos and thus have to buffer chunks of frames (often
seconds) before processing. In this work, we take a step towards interactive
streaming via a frame-by-frame approach naturally free of lag. Conventional
wisdom believes that per-frame NeRFs are impractical due to prohibitive
training costs and storage. We break this belief by introducing Incremental
Neural Videos (INV), a per-frame NeRF that is efficiently trained and
streamable. We designed INV based on two insights: (1) Our main finding is that
MLPs naturally partition themselves into Structure and Color Layers, which
store structural and color/texture information respectively. (2) We leverage
this property to retain and improve upon knowledge from previous frames, thus
amortizing training across frames and reducing redundant learning. As a result,
with negligible changes to NeRF, INV can achieve good qualities (>28.6db) in
8min/frame. It can also outperform prior SOTA in 19% less training time.
Additionally, our Temporal Weight Compression reduces the per-frame size to
0.3MB/frame (6.6% of NeRF). More importantly, INV is free from buffer lag and
is naturally fit for streaming. While this work does not achieve real-time
training, it shows that incremental approaches like INV present new
possibilities in interactive 3D streaming. Moreover, our discovery of natural
information partition leads to a better understanding and manipulation of MLPs.
Code and dataset will be released soon.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:15:51 GMT""}]","2023-02-06"
"2302.01533","Rick Danielson","Richard E. Danielson and Hui Shen and Jing Tao and William Perrie","Dependence of ocean surface filaments on wind speed: An observational
  study of North Atlantic right whale habitat","17 pages, 8 figures, accepted paper at Remote Sensing of Environment",,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Coherent filaments at the ocean surface often appear to be transient
watermass boundaries, where currents converge, surfactants accumulate, and
frontal structure at depth can possibly delineate enhanced biological activity
in the upper water column. Spaceborne synthetic aperture radar (SAR) permits
filaments to be observed at O[1-km] resolution, but extensive coherent
structures are more apparent in weaker winds. A wind speed adjustment is
proposed for filaments (i.e., contiguous SAR contrasts) of at least 10 km in
length. Measures of dependence (distance correlation and the linear and
nonlinear components of Pearson correlation) are examined to identify a broad
peak in the relationship between filament contrast and weak or moderate values
of surface wind speed, where a variable wind speed exponent is employed to
maximize these measures.
  Three locations of recent North Atlantic right whale (Eubalaena glacialis)
sightings in the Gulf of St. Lawrence are sampled between 2008 and 2020 by 324
Radarsat-2 SAR scenes and 10-m wind speed from the ERA5 reanalysis. The inverse
relationship between SAR contrast magnitude and wind speed is quantified, and a
reduced correlation is obtained for all three domains when SAR contrast is
weighted by wind speed to the power of 0.8. A more uniform emphasis on ocean
surface structure within a SAR scene, or across multiple scenes, can thus be
considered in the search for prey aggregations of the North Atlantic right
whale.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:16:18 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 02:32:17 GMT""}]","2023-02-09"
"2302.01534","Yijun Zhang","Yijun Zhang, Ziyi Yin, Oscar Lopez, Ali Siahkoohi, Mathias Louboutin,
  Rajiv Kumar, Felix J. Herrmann","Optimized time-lapse acquisition design via spectral gap ratio
  minimization",,,,,"physics.geo-ph","http://creativecommons.org/licenses/by/4.0/","  Modern-day reservoir management and monitoring of geological carbon storage
increasingly call for costly time-lapse seismic data collection. In this
letter, we show how techniques from graph theory can be used to optimize
acquisition geometries for low-cost sparse 4D seismic. Based on midpoint-offset
domain connectivity arguments, the proposed algorithm automatically produces
sparse non-replicated time-lapse acquisition geometries that favor wavefield
recovery.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:17:10 GMT""}]","2023-02-06"
"2302.01535","Hanbyul Lee","Hanbyul Lee, Qifan Song, Jean Honorio","Support Recovery in Sparse PCA with Non-Random Missing Data","arXiv admin note: text overlap with arXiv:2205.15215",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze a practical algorithm for sparse PCA on incomplete and noisy data
under a general non-random sampling scheme. The algorithm is based on a
semidefinite relaxation of the $\ell_1$-regularized PCA problem. We provide
theoretical justification that under certain conditions, we can recover the
support of the sparse leading eigenvector with high probability by obtaining a
unique solution. The conditions involve the spectral gap between the largest
and second-largest eigenvalues of the true data matrix, the magnitude of the
noise, and the structural properties of the observed entries. The concepts of
algebraic connectivity and irregularity are used to describe the structural
properties of the observed entries. We empirically justify our theorem with
synthetic and real data analysis. We also show that our algorithm outperforms
several other sparse PCA approaches especially when the observed entries have
good structural properties. As a by-product of our analysis, we provide two
theorems to handle a deterministic sampling scheme, which can be applied to
other matrix-related problems.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:20:25 GMT""}]","2023-02-06"
"2302.01536","Feier Chang","Feier Chang and Jay Krishnan and Jillian H Hurst and Michael E
  Yarrington and Deverick J Anderson and Emily C O'Brien and Benjamin A
  Goldstein","Using natural language processing and structured medical data to
  phenotype patients hospitalized due to COVID-19","21 pages, 2 figures, 3 tables, 1 supplemental figure, 2 supplemental
  tables",,,,"cs.CL cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  To identify patients who are hospitalized because of COVID-19 as opposed to
those who were admitted for other indications, we compared the performance of
different computable phenotype definitions for COVID-19 hospitalizations that
use different types of data from the electronic health records (EHR), including
structured EHR data elements, provider notes, or a combination of both data
types. And conduct a retrospective data analysis utilizing chart review-based
validation. Participants are 586 hospitalized individuals who tested positive
for SARS-CoV-2 during January 2022. We used natural language processing to
incorporate data from provider notes and LASSO regression and Random Forests to
fit classification algorithms that incorporated structured EHR data elements,
provider notes, or a combination of structured data and provider notes.
Results: Based on a chart review, 38% of 586 patients were determined to be
hospitalized for reasons other than COVID-19 despite having tested positive for
SARS-CoV-2. A classification algorithm that used provider notes had
significantly better discrimination than one that used structured EHR data
elements (AUROC: 0.894 vs 0.841, p < 0.001), and performed similarly to a model
that combined provider notes with structured data elements (AUROC: 0.894 vs
0.893). Assessments of hospital outcome metrics significantly differed based on
whether the population included all hospitalized patients who tested positive
for SARS-CoV-2 versus those who were determined to have been hospitalized due
to COVID-19. This work demonstrates the utility of natural language processing
approaches to derive information related to patient hospitalizations in cases
where there may be multiple conditions that could serve as the primary
indication for hospitalization.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:22:29 GMT""}]","2023-02-06"
"2302.01537","Songyang Ge","Songyang Ge and Tsung-Hui Chang","Gradient and Variable Tracking with Multiple Local SGD for Decentralized
  Non-Convex Learning","46 pages, 6 figures",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic distributed optimization methods that solve an optimization
problem over a multi-agent network have played an important role in a variety
of large-scale signal processing and machine leaning applications. Among the
existing methods, the gradient tracking (GT) method is found robust against the
variance between agents' local data distribution, in contrast to the
distributed stochastic gradient descent (SGD) methods which have a slowed
convergence speed when the agents have heterogeneous data distributions.
However, the GT method can be communication expensive due to the need of a
large number of iterations for convergence. In this paper, we intend to reduce
the communication cost of the GT method by integrating it with the local SGD
technique. Specifically, we propose a new local stochastic GT (LSGT) algorithm
where, within each communication round, the agents perform multiple SGD updates
locally. Theoretically, we build the convergence conditions of the LSGT
algorithm and show that it can have an improved convergence rate of
$\mathcal{O}(1/\sqrt{ET})$, where $E$ is the number of local SGD updates and
$T$ is the number of communication rounds. We further extend the LSGT algorithm
to solve a more complex learning problem which has linearly coupled variables
inside the objective function. Experiment results demonstrate that the proposed
algorithms have significantly improved convergence speed even under
heterogeneous data distribution.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:23:40 GMT""}]","2023-02-06"
"2302.01538","Yizheng Wang","Yizheng Wang, Jia Sun, Zaiyuan Lu, Pipi Hu, Yinghua Liu","DCM: Deep complementary energy method based on the principle of minimum
  complementary energy","46 pages, 23 figures",,,,"cs.LG cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The principle of minimum potential and complementary energy are the most
important variational principles in solid mechanics.
  The deep energy method (DEM), which has received much attention, is based on
the principle of minimum potential energy, but it lacks the important form of
minimum complementary energy. To fill the gap, we propose a deep complementary
energy method (DCM) based on the principle of minimum complementary energy. The
output function of DCM is the stress function that naturally satisfies the
equilibrium equation. We extend the proposed DCM algorithm to DCM-Plus (DCM-P),
adding the terms that naturally satisfy the biharmonic equation in the Airy
stress function. We combine operator learning with physical equations and
propose a deep complementary energy operator method (DCM-O), including branch
net, trunk net, basis net, and particular net. DCM-O first combines existing
high-fidelity numerical results to train DCM-O through data. Then the
complementary energy is used to train the branch net and trunk net in DCM-O. To
analyze DCM performance, we present the numerical result of the most common
stress functions, the Prandtl and Airy stress function. The proposed method DCM
is used to model the representative mechanical problems with different types of
boundary conditions. We compare DCM with the existing PINNs and DEM algorithms.
The result shows the advantage of the proposed DCM is suitable for dealing with
problems of dominated displacement boundary conditions, which is proved by
mathematical derivations, as well as with numerical experiments. DCM-P and
DCM-O can improve the accuracy and efficiency of DCM. DCM is an essential
supplementary energy form to the deep energy method. Operator learning based on
the energy method can balance data and physical equations well, giving
computational mechanics broad research prospects.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:24:49 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 10:18:03 GMT""},{""version"":""v3"",""created"":""Mon, 13 Feb 2023 12:07:28 GMT""}]","2023-02-14"
"2302.01539","Yasong Feng","Yasong Feng, Weijian Luo, Yimin Huang, Tianyu Wang","A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization","Some preliminaries and backgrounds are drawn from arXiv:2110.09722 by
  the first author and the last author, and their coauthor Z. Huang",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most critical problems in machine learning is HyperParameter
Optimization (HPO), since choice of hyperparameters has a significant impact on
final model performance. Although there are many HPO algorithms, they either
have no theoretical guarantees or require strong assumptions. To this end, we
introduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes
Lipschitz continuity of the objective function. BLiE exploits the landscape of
the objective function to adaptively search over the hyperparameter space.
Theoretically, we show that $(i)$ BLiE finds an $\epsilon$-optimal
hyperparameter with $\mathcal{O} \left( \epsilon^{-(d_z + \beta)}\right)$ total
budgets, where $d_z$ and $\beta$ are problem intrinsic; $(ii)$ BLiE is highly
parallelizable. Empirically, we demonstrate that BLiE outperforms the
state-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to
search for noise schedule of diffusion models. Comparison with the default
schedule shows that BLiE schedule greatly improves the sampling speed.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:30:17 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 05:14:27 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jun 2023 15:05:18 GMT""}]","2023-06-09"
"2302.01540","Dongsheng Xu","Dongsheng Xu, Qingbao Huang, Feng Shuang, Yi Cai","DEVICE: DEpth and VIsual ConcEpts Aware Transformer for TextCaps","11pages, 7figures. This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text-based image captioning is an important but under-explored task, aiming
to generate descriptions containing visual objects and scene text. Recent
studies have made encouraging progress, but they are still suffering from a
lack of overall understanding of scenes and generating inaccurate captions. One
possible reason is that current studies mainly focus on constructing the
plane-level geometric relationship of scene text without depth information.
This leads to insufficient scene text relational reasoning so that models may
describe scene text inaccurately. The other possible reason is that existing
methods fail to generate fine-grained descriptions of some visual objects. In
addition, they may ignore essential visual objects, leading to the scene text
belonging to these ignored objects not being utilized. To address the above
issues, we propose a DEpth and VIsual ConcEpts Aware Transformer (DEVICE) for
TextCaps. Concretely, to construct three-dimensional geometric relations, we
introduce depth information and propose a depth-enhanced feature updating
module to ameliorate OCR token features. To generate more precise and
comprehensive captions, we introduce semantic features of detected visual
object concepts as auxiliary information. Our DEVICE is capable of generalizing
scenes more comprehensively and boosting the accuracy of described visual
entities. Sufficient experiments demonstrate the effectiveness of our proposed
DEVICE, which outperforms state-of-the-art models on the TextCaps test set. Our
code will be publicly available.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:31:13 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 14:17:27 GMT""},{""version"":""v3"",""created"":""Wed, 1 Mar 2023 12:02:21 GMT""}]","2023-03-02"
"2302.01541","Zihu Wang","Zihu Wang, Yu Wang, Hanbin Hu, Peng Li","Contrastive Learning with Consistent Representations",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Contrastive learning demonstrates great promise for representation learning.
Data augmentations play a critical role in contrastive learning by providing
informative views of the data without needing the labels. However, the
performance of the existing works heavily relies on the quality of the employed
data augmentation (DA) functions, which are typically hand picked from a
restricted set of choices. While exploiting a diverse set of data augmentations
is appealing, the intricacies of DAs and representation learning may lead to
performance degradation. To address this challenge and allow for a systemic use
of large numbers of data augmentations, this paper proposes Contrastive
Learning with Consistent Representations (CoCor). At the core of CoCor is a new
consistency measure, DA consistency, which dictates the mapping of augmented
input data to the representation space such that these instances are mapped to
optimal locations in a way consistent to the intensity of the DA applied.
Furthermore, a data-driven approach is proposed to learn the optimal mapping
locations as a function of DA while maintaining a desired monotonic property
with respect to DA intensity. The proposed techniques give rise to a
semi-supervised learning framework based on bi-level optimization, achieving
new state-of-the-art results for image recognition.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:34:00 GMT""}]","2023-02-06"
"2302.01542","Abubakar Siddique","Abubakar Siddique, Will N. Browne, and Gina M. Grimshaw","Lateralization in Agents' Decision Making: Evidence of Benefits/Costs
  from Artificial Intelligence","13 pages, 14 figures",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lateralization is ubiquitous in vertebrate brains which, as well as its role
in locomotion, is considered an important factor in biological intelligence.
Lateralization has been associated with both poor and good performance. It has
been hypothesized that lateralization has benefits that may counterbalance its
costs. Given that lateralization is ubiquitous, it likely has advantages that
can benefit artificial intelligence. In turn, lateralized artificial
intelligent systems can be used as tools to advance the understanding of
lateralization in biological intelligence. Recently lateralization has been
incorporated into artificially intelligent systems to solve complex problems in
computer vision and navigation domains. Here we describe and test two novel
lateralized artificial intelligent systems that simultaneously represent and
address given problems at constituent and holistic levels. The experimental
results demonstrate that the lateralized systems outperformed state-of-the-art
non-lateralized systems in resolving complex problems. The advantages arise
from the abilities, (i) to represent an input signal at both the constituent
level and holistic level simultaneously, such that the most appropriate
viewpoint controls the system; (ii) to avoid extraneous computations by
generating excite and inhibit signals. The computational costs associated with
the lateralized AI systems are either less than the conventional AI systems or
countered by providing better solutions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:34:44 GMT""}]","2023-02-06"
"2302.01543","Runzhe Wan","Runzhe Wan, Haoyu Wei, Branislav Kveton and Rui Song","Multiplier Bootstrap-based Exploration",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the great interest in the bandit problem, designing efficient
algorithms for complex models remains challenging, as there is typically no
analytical way to quantify uncertainty. In this paper, we propose Multiplier
Bootstrap-based Exploration (MBE), a novel exploration strategy that is
applicable to any reward model amenable to weighted loss minimization. We prove
both instance-dependent and instance-independent rate-optimal regret bounds for
MBE in sub-Gaussian multi-armed bandits. With extensive simulation and real
data experiments, we show the generality and adaptivity of MBE.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:38:00 GMT""}]","2023-02-06"
"2302.01544","Jongyeong Lee","Jongyeong Lee, Junya Honda, Chao-Kai Chiang, Masashi Sugiyama","Optimality of Thompson Sampling with Noninformative Priors for Pareto
  Bandits","49 pages, a preprint",,,,"cs.LG math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the stochastic multi-armed bandit problem, a randomized probability
matching policy called Thompson sampling (TS) has shown excellent performance
in various reward models. In addition to the empirical performance, TS has been
shown to achieve asymptotic problem-dependent lower bounds in several models.
However, its optimality has been mainly addressed under light-tailed or
one-parameter models that belong to exponential families. In this paper, we
consider the optimality of TS for the Pareto model that has a heavy tail and is
parameterized by two unknown parameters. Specifically, we discuss the
optimality of TS with probability matching priors that include the Jeffreys
prior and the reference priors. We first prove that TS with certain probability
matching priors can achieve the optimal regret bound. Then, we show the
suboptimality of TS with other priors, including the Jeffreys and the reference
priors. Nevertheless, we find that TS with the Jeffreys and reference priors
can achieve the asymptotic lower bound if one uses a truncation procedure.
These results suggest carefully choosing noninformative priors to avoid
suboptimality and show the effectiveness of truncation procedures in TS-based
policies.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:47:14 GMT""}]","2023-02-06"
"2302.01545","Aftab Alam","Arindam Sarkar, Debashish Das, Prashant Singh and Aftab Alam","Ligand hole driven metal-insulator Transition in Ca$_2$FeMnO$_6$","7 pages, 4 figures",,,,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ca$_2$FeMnO$_6$ (CFMO) double perovskite was studied using first principles
density functional theory and tight-binding (TB) Hamiltonian modeling using
extended Hubbard model. We have shown by electronic structure analysis that
charge- and magnetic-ordering are driven by charge disproportionation at low
temperature caused by partial localization of O-$2p$ ligand holes at alternate
Fe sites that creates Jahn-Teller distortion, which leads to metal to insulator
transition (MIT) in CFMO. Our results suggests MIT was triggered by negative
charge-transfer energy of self-hole doping, responsible for symmetry lowering
transitions. Notably, the band-gap was found to fundamentally controlled by the
strength of the charge-transfer energy, and not by the Mott-Hubbard
interactions, which can be modeled by composition, pressure or stoichiometry
modulations. The fundamental insights presented in this work will help
understand similar physics and mechanisms in other class of perovskites and
correlated metals.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:48:54 GMT""}]","2023-02-06"
"2302.01546","Shaojie Tang","Jing Yuan, Shaojie Tang","Group Fairness in Non-monotone Submodular Maximization","This article has been accepted for publication in the Journal on
  Combinatorial Optimization",,,,"cs.LG cs.DS","http://creativecommons.org/licenses/by/4.0/","  Maximizing a submodular function has a wide range of applications in machine
learning and data mining. One such application is data summarization whose goal
is to select a small set of representative and diverse data items from a large
dataset. However, data items might have sensitive attributes such as race or
gender, in this setting, it is important to design \emph{fairness-aware}
algorithms to mitigate potential algorithmic bias that may cause over- or
under- representation of particular groups. Motivated by that, we propose and
study the classic non-monotone submodular maximization problem subject to novel
group fairness constraints. Our goal is to select a set of items that maximizes
a non-monotone submodular function, while ensuring that the number of selected
items from each group is proportionate to its size, to the extent specified by
the decision maker. We develop the first constant-factor approximation
algorithms for this problem. We also extend the basic model to incorporate an
additional global size constraint on the total number of selected items.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:51:54 GMT""},{""version"":""v2"",""created"":""Thu, 9 Mar 2023 02:44:15 GMT""}]","2023-03-10"
"2302.01547","Xue Guang Zhang","Zhang XueGuang (GXU), Zheng Qi (NNU)","Evidence to disfavour dual core system leading to double-peaked narrow
  emission lines","6 pages, 1 table, 3 figures, Accepted to be published in MNRAS",,,,"astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this manuscript, an interesting method is proposed to test dual core
system for double-peaked narrow emission lines, through precious dual core
system with double-peaked narrow Balmer lines in one system in main galaxy but
with single-peaked narrow Balmer lines in the other system in companion galaxy.
Under a dual core system, considering narrow Balmer (H$\alpha$ and H$\beta$)
emissions ($f_{e,~\alpha}$ and $f_{e,~\beta}$) from companion galaxy but
covered by SDSS fiber for the main galaxy and narrow Balmer emissions
($f_{c,~\alpha}$ and $f_{c,~\beta}$) from the companion galaxy covered by SDSS
fiber for the companion galaxy, the same flux ratios
$f_{e,~\alpha}/f_{c,~\alpha}=f_{e,~\beta}/f_{c,~\beta}$ can be expected, due to
totally similar physical conditions of each narrow Balmer emission region.
Then, the precious dual core system in SDSS J2219-0938 is discussed. After
subtracting pPXF code determined stellar lights, double-peaked narrow Balmer
emission lines are confirmed in the main galaxy with confidence level higher
than $5\sigma$, but single-peaked narrow Balmer emission lines in the companion
galaxy. Through measured fluxes of emission components,
$f_{e,~\alpha}/f_{c,~\alpha}$ is around 0.82, different from
$f_{e,~\beta}/f_{c,~\beta}\sim0.52$, to disfavour a dual core system for the
double-peaked narrow Balmer emission lines in SDSS J2219-0938.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:53:31 GMT""}]","2023-02-06"
"2302.01548","Tiankuan Liu","L. Zhang, C. Edwards, D. Gong, X. Huang, J. Lee, C. Liu, T. Liu, T.
  Liu, J. Olsen, Q. Sun, J. Wu, J. Ye, W Zhang","An FPGA-based readout chip emulator for the CMS ETL detector upgrade","8 pages, 4 figures",,"10.1088/1748-0221/18/02/C02031",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an FPGA-based readout chip emulator board for the CMS Endcap
Timing Layer (ETL) detector upgrade. The emulator board uses an Intel Cyclone
10 GX FPGA to emulate the digital functions of four Endcap Layer Readout Chips
(ETROCs). Based on the actual ETROC design, the firmware is implemented and
verified. The emulator board is being used for the ETROC digital design
verification and system development.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 04:53:54 GMT""}]","2023-03-01"
"2302.01549","Wei Li","Zhongfeng Ning, Jiahui Qian, Yixin Liu, Fan Chen, Guanqun Zhang, Gang
  Mu, and Wei Li","Evidence for ferromagnetism in KTaO$_3$ heterointerface superconductors","6 pages, 3 figures",,,,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The coexistence of superconductivity and ferromagnetism has been a
long-standing issue in the realm of unconventional superconductivity due to the
antagonistic nature of these two ordered states. Experimentally identifying and
characterizing new fascinating heterointerface superconductors that coexist
with magnetism are challenging. Here, we report the experimental observation of
long-range ferromagnetic order at the verge of two-dimensional
superconductivity at the KTaO$_3$ heterointerfaces. Remarkably, the fingerprint
of ferromagnetism is the existence of in-plane magnetization hysteresis loop
persisting up to room temperature observed in direct current superconducting
quantum interference device measurements. Furthermore, first-principles
calculations suggest that the robust ferromagnetism is attributed to the
presence of oxygen vacancies that localize electrons in nearby Ta 5$d$ states.
Our findings not only unveil the KTaO$_3$ heterointerfaces to be unconventional
superconductors with time-reversal symmetry breaking, but also inject a new
momentum to the study of a delicate interplay of superconductivity and
magnetism boosted by the strong spin-orbit coupling inherent to the heavy Ta in
5$d$ orbitals of KTaO$_3$ heterointerfaces.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:10:43 GMT""}]","2023-02-06"
"2302.01550","Qun Li","Qun Li, Chandra Thapa, Lawrence Ong, Yifeng Zheng, Hua Ma, Seyit A.
  Camtepe, Anmin Fu, Yansong Gao","Vertical Federated Learning: Taxonomies, Threats, and Prospects",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated learning (FL) is the most popular distributed machine learning
technique. FL allows machine-learning models to be trained without acquiring
raw data to a single point for processing. Instead, local models are trained
with local data; the models are then shared and combined. This approach
preserves data privacy as locally trained models are shared instead of the raw
data themselves. Broadly, FL can be divided into horizontal federated learning
(HFL) and vertical federated learning (VFL). For the former, different parties
hold different samples over the same set of features; for the latter, different
parties hold different feature data belonging to the same set of samples. In a
number of practical scenarios, VFL is more relevant than HFL as different
companies (e.g., bank and retailer) hold different features (e.g., credit
history and shopping history) for the same set of customers. Although VFL is an
emerging area of research, it is not well-established compared to HFL. Besides,
VFL-related studies are dispersed, and their connections are not intuitive.
Thus, this survey aims to bring these VFL-related studies to one place.
Firstly, we classify existing VFL structures and algorithms. Secondly, we
present the threats from security and privacy perspectives to VFL. Thirdly, for
the benefit of future researchers, we discussed the challenges and prospects of
VFL in detail.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:13:40 GMT""}]","2023-02-06"
"2302.01551","Vinay Kumar Gupta","Himanshi, Anirudh Singh Rana and Vinay Kumar Gupta","Fundamental solutions of an extended hydrodynamic model in two
  dimensions: derivation, theory and applications","14 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The inability of the Navier-Stokes-Fourier equations to capture rarefaction
effects motivates us to adopt the extended hydrodynamic equations. In the
present work, a hydrodynamic model comprised of the conservation laws closed
with the recently propounded coupled constitutive relations (CCR) -- referred
to as the CCR model -- adequate for describing moderately rarefied gas is
utilized. A numerical framework based on the method of fundamental solutions is
developed and employed to solve the CCR model in two dimensions. To this end,
the fundamental solutions of the linearized CCR model are derived in two
dimensions. The significance of deriving the two-dimensional fundamental
solutions is that they cannot be deduced from their three-dimensional
counterparts that do exist in literature. As applications, the developed
numerical framework based on the derived fundamental solutions is used to
simulate (i) a rarefied gas flow confined between two coaxial cylinders with
evaporating walls and (ii) a temperature-driven rarefied gas flow between two
non-coaxial cylinders. The results for both problems have been validated
against those obtained with the other classical approaches. Through this, it is
shown that the method of fundamental solutions is an efficient tool for
addressing two-dimensional multiphase microscale gas flow problems at a low
computational cost. Moreover, the findings also show that the CCR model solved
with the method of fundamental solutions depicts rarefaction effects, like
transpiration flows and thermal stress, generally well.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:15:20 GMT""}]","2023-02-06"
"2302.01552","Nathan Brownlowe","Nathan Brownlowe, David Robertson","Self-similar quantum groups",,,,,"math.OA math.QA","http://creativecommons.org/licenses/by/4.0/","  We introduce the notion of self-similarity for compact quantum groups. For a
finite set $X$, we introduce a $C^*$-algebra $\mathbb{A}_X$, which is the
quantum automorphism group of the infinite homogeneous rooted tree $X^*$.
Self-similar quantum groups are then certain quantum subgroups of
$\mathbb{A}_X$. Our main class of examples are called finitely-constrained
self-similar quantum groups, and we find a class of these examples that can be
described as quantum wreath products by subgroups of the quantum permutation
group.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:21:08 GMT""}]","2023-02-06"
"2302.01553","Jason D. Chadwick","Jason D. Chadwick and Frederic T. Chong","Efficient control pulses for continuous quantum gate families through
  coordinated re-optimization","9 pages, 6 figures, 2 tables; comments welcome",,,,"quant-ph cs.ET","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a general method to quickly generate high-fidelity control pulses
for any continuously-parameterized set of quantum gates after calibrating a
small number of reference pulses. We find that interpolating between optimized
control pulses for different quantum operations does not immediately yield a
high-fidelity intermediate operation. To solve this problem, we propose a
method to optimize control pulses specifically to provide good interpolations.
We pick several reference operations in the gate family of interest and
optimize pulses that implement these operations, then iteratively re-optimize
the pulses to guide their shapes to be similar for operations that are closely
related. Once this set of reference pulses is calibrated, we can use a
straightforward linear interpolation method to instantly obtain high-fidelity
pulses for arbitrary gates in the continuous operation space.
  We demonstrate this procedure on the three-parameter Cartan decomposition of
two-qubit gates to obtain control pulses for any arbitrary two-qubit gate (up
to single-qubit operations) with consistently high fidelity. Compared to
previous neural network approaches, the method is 7.7x more computationally
efficient to calibrate the pulse space for the set of all single-qubit gates.
Our technique generalizes to any number of gate parameters and could easily be
used with advanced pulse optimization algorithms to allow for better
translation from simulation to experiment.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:23:16 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 17:29:58 GMT""},{""version"":""v3"",""created"":""Mon, 1 May 2023 23:58:04 GMT""}]","2023-05-03"
"2302.01554","Titus K Mathew","Nandhida Krishnan.P and Titus K Mathew","Emergence of cosmic space with Barrow entropy, in non-equilibrium
  thermodynamic conditions","15 pages",,,,"gr-qc","http://creativecommons.org/publicdomain/zero/1.0/","  Recently, Barrow accounts for the quantum gravitational effects to the black
hole surface. Thus the conventional area-entropy relation has modified,
$S=(A/A_{0})^{1+\Delta/2},$ with an exponent $\Delta$, ranges $0\le\Delta\le1$,
quantifies the amount of quantum gravitational deformation effect to the black
hole surface. In recent literature, this horizon entropy has been extended to
the cosmological context. Following this, we consider an n+1 dimensional
non-flat universe with an apparent horizon as the boundary with appropriate
temperature and associated entropy is Barrow entropy. We derived the modified
form of the law of emergence from the equilibrium and non-equilibrium
thermodynamic principles. Later studied the entropy maximization condition due
to the modified law of emergence. On distinguishing the obtained result, it
speculates that in order to hold the energy-momentum conservation, the universe
with Barrow entropy as the horizon entropy should have non-equilibrium
behaviour with an additional entropy production. However, the additional
entropy production rate decreases over time, so the system eventually
approaches equilibrium. Because of this, the constraint relation for entropy
maximization looks similar for both equilibrium and non-equilibrium approaches.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:23:53 GMT""}]","2023-02-06"
"2302.01555","Chuan Zhang","Chuan Zhang, Daoxin Zhang, Ruixiu Zhang, Jiawei Li, Jianke Zhu","Bridging the Emotional Semantic Gap via Multimodal Relevance Estimation",,,,,"cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human beings have rich ways of emotional expressions, including facial
action, voice, and natural languages. Due to the diversity and complexity of
different individuals, the emotions expressed by various modalities may be
semantically irrelevant. Directly fusing information from different modalities
may inevitably make the model subject to the noise from semantically irrelevant
modalities. To tackle this problem, we propose a multimodal relevance
estimation network to capture the relevant semantics among modalities in
multimodal emotions. Specifically, we take advantage of an attention mechanism
to reflect the semantic relevance weights of each modality. Moreover, we
propose a relevant semantic estimation loss to weakly supervise the semantics
of each modality. Furthermore, we make use of contrastive learning to optimize
the similarity of category-level modality-relevant semantics across different
modalities in feature space, thereby bridging the semantic gap between
heterogeneous modalities. In order to better reflect the emotional state in the
real interactive scenarios and perform the semantic relevance analysis, we
collect a single-label discrete multimodal emotion dataset named SDME, which
enables researchers to conduct multimodal semantic relevance research with
large category bias. Experiments on continuous and discrete emotion datasets
show that our model can effectively capture the relevant semantics, especially
for the large deviations in modal semantics. The code and SDME dataset will be
publicly available.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:27:52 GMT""}]","2023-02-06"
"2302.01556","Jun Jie Tong","J.J. Tong, W. Zhang, F. Liao, C.F. Li, Y.F. Zhang","Machine Learning for UAV Propeller Fault Detection based on a Hybrid
  Data Generation Model",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper describes the development of an on-board data-driven system that
can monitor and localize the fault in a quadrotor unmanned aerial vehicle (UAV)
and at the same time, evaluate the degree of damage of the fault under real
scenarios. To achieve offline training data generation, a hybrid approach is
proposed for the development of a virtual data-generative model using a
combination of data-driven models as well as well-established dynamic models
that describe the kinematics of the UAV. To effectively represent the drop in
performance of a faulty propeller, a variation of the deep neural network, a
LSTM network is proposed. With the RPM of the propeller as input and based on
the fault condition of the propeller, the proposed propeller model estimates
the resultant torque and thrust. Then, flight datasets of the UAV under various
fault scenarios are generated via simulation using the developed
data-generative model. Lastly, a fault classifier using a CNN model is proposed
to identify as well as evaluate the degree of damage to the damaged propeller.
The scope of this paper focuses on the identification of faulty propellers and
classification of the fault level for quadrotor UAVs using RPM as well as
flight data. Doing so allows for early minor fault detection to prevent serious
faults from occurring if the fault is left unrepaired. To further validate the
workability of this approach outside of simulation, a real-flight test is
conducted indoors. The real flight data is collected and a simulation to real
sim-real test is conducted. Due to the imperfections in the build of our
experimental UAV, a slight calibration approach to our simulation model is
further proposed and the experimental results obtained show that our trained
model can identify the location of propeller fault as well as the degree/type
of damage. Currently, the diagnosis accuracy on the testing set is over 80%.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:28:02 GMT""}]","2023-02-06"
"2302.01557","Fernando Pi\~nero Gonz\'alez","Austin Allen and Eric Pab\'on-Cancel and Fernando Pi\~nero-Gonz\'alez
  and Lesley Polanco","Improving the dimension bound of Hermitian Lifted Codes",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we improve the dimension and minimum distance bound of the
the Hermitian Lifted Codes LRCs construction from L\'opez, Malmskog, Matthews,
Pi\~nero and Wooters via elementary univariarte polynomial division. They gave
an asymptotic rate estimate of $0.007$. We improve the rate estimate to $0.1$
using univariate polynomial division
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:40:25 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 16:07:05 GMT""},{""version"":""v3"",""created"":""Fri, 10 Feb 2023 00:38:54 GMT""},{""version"":""v4"",""created"":""Tue, 28 Feb 2023 22:36:56 GMT""}]","2023-03-02"
"2302.01558","Br Chen","Beiran Chen, Frank Slyne and Marco Ruffini","Energy Efficient SDN and SDR Joint Adaptation of CPU Utilization Based
  on Experimental Data Analytics",,,,,"cs.NI cs.AR","http://creativecommons.org/licenses/by/4.0/","  In this paper we propose a hybrid softwarized architecture of Network
Function Virtualization (NFV) where Software-Defined Networking (SDN) and
Software-Defined Radio (SDR) components are integrated to form a cloud-based
communication system. We analyze CPU utilization and power consumption in the
OpenIreland testbed for different parameter settings and use case scenarios of
this NFV architecture. The experiment results show different behaviour between
SDN data plane switching and SDR in terms of CPU utilization and
parallelization, which provides insights for processing aggregation and power
savings when integrating them together in a cloud-based system. We then propose
a power saving scheme with flexible CPU allocation that can reduce the overall
power consumption of the system. Our results show that our proposed NFV
architecture and its power saving scheme can save up to 20% power consumption
compared to conventional scheme where SDN and SDR are separately deployed.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:46:27 GMT""}]","2023-02-06"
"2302.01559","Nicholas Weadock","Nicholas Weadock (1 and 2), Tyler Sterling (3), Julian Vigil (4 and
  5), Aryeh Gold-Parker (5), Ian Smith (5), Ballal Ahammed (6), Matthew
  Krogstad (7), Feng Ye (8), David Voneshen (9 and 10), Peter Gehring (11),
  Hans-Georg Steinr\""uck (12), Elif Ertekin (6), Hemamala Karunadasa (5 and
  13), Dmitry Reznik (3), Michael Toney (1 and 2 and 14) ((1) Materials Science
  and Engineering, University of Colorado, Boulder, (2) Department of Chemical
  and Biological Engineering, University of Colorado, Boulder, (3) Department
  of Physics, University of Colorado, Boulder, (4) Department of Chemical
  Engineering, Stanford University, (5) Department of Chemistry, Stanford
  University (6) Department of Mechanical Science and Engineering, University
  of Illinois at Urbana-Champaign, (7) Advanced Photon Source, Argonne National
  Laboratory, (8) Neutron Scattering Division, Oak Ridge National Laboratory,
  (9) ISIS Facility, Rutherford Appleton Laboratory, (10) Department of
  Physics, Royal Holloway University of London, (11) NIST Center for Neutron
  Research, National Institute of Standards and Technology, (12) Department
  Chemie, Universt\""at Paderborn, (13) Stanford Institute for Materials and
  Energy Sciences, SLAC National Accelerator Laboratory, (14) Renewable and
  Sustainable Energy Institute (RASEI), University of Colorado, Boulder)","The nature of dynamic local order in CH$_3$NH$_3$PbI$_3$ and
  CH$_3$NH$_3$PbBr$_3$",,,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Hybrid lead halide perovskites (LHPs) are a class of semiconductor with novel
properties that are distinctively governed by structural fluctuations.
Diffraction experiments sensitive to average, long-range order reveal a cubic
structure in the device-relevant, high-temperature phase. Local probes find
additional short-range order with lower symmetry that may govern the
structure-function relationships of LHPs. However, the dimensionality,
participating atoms, and dynamics of this short-range order are unresolved,
impeding our understanding of technologically relevant properties including
long carrier lifetimes and facile halide migration. Here, we determine the true
structure of two prototypical hybrid LHPs, CH$_3$NH$_3$PbI$_3$ and
CH$_3$NH$_3$PbBr$_3$, using a combination of single-crystal X-ray and neutron
diffuse scattering, neutron inelastic spectroscopy, and molecular dynamics
simulations. The remarkable collective dynamics we found are not suggested by
previous studies and consist of a network of local two-dimensional, circular
pancake-like regions of dynamically tilting lead halide octahedra (lower
symmetry) that induce longer range intermolecular correlations within the
CH$_3$NH$_3^+$ sublattice. The dynamic local structure can introduce transient
ferroelectric or antiferroelectric domains that increase charge carrier
lifetimes, and strongly affect the halide migration, a poorly understood
degradation mechanism. Our approach of co-analyzing single-crystal X-ray and
neutron diffuse scattering data with MD simulations will provide unparalleled
insights into the structure of hybrid materials and materials with engineered
disorder.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 05:52:52 GMT""}]","2023-02-06"
"2302.01560","Zihao Wang","Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, Yitao Liang","Describe, Explain, Plan and Select: Interactive Planning with Large
  Language Models Enables Open-World Multi-Task Agents",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In this paper, we study the problem of planning in Minecraft, a popular,
democratized yet challenging open-ended environment for developing multi-task
embodied agents. We've found two primary challenges of empowering such agents
with planning: 1) planning in an open-ended world like Minecraft requires
precise and multi-step reasoning due to the long-term nature of the tasks, and
2) as vanilla planners do not consider the proximity to the current agent when
ordering parallel sub-goals within a complicated plan, the resulting plan could
be inefficient. To this end, we propose ""Describe, Explain, Plan and Select""
(DEPS), an interactive planning approach based on Large Language Models (LLMs).
Our approach helps with better error correction from the feedback during the
long-haul planning, while also bringing the sense of proximity via goal
Selector, a learnable module that ranks parallel sub-goals based on the
estimated steps of completion and improves the original plan accordingly. Our
experiments mark the milestone of the first multi-task agent that can robustly
accomplish 70+ Minecraft tasks and nearly doubles the overall performances.
Finally, the ablation and exploratory studies detail how our design beats the
counterparts and provide a promising update on the $\texttt{ObtainDiamond}$
grand challenge with our approach. The code is released at
https://github.com/CraftJarvis/MC-Planner.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:06:27 GMT""}]","2023-02-06"
"2302.01561","Michael Beukman","Michael Beukman, Manuel Fokam, Marcel Kruger, Guy Axelrod, Muhammad
  Nasir, Branden Ingram, Benjamin Rosman, Steven James","Hierarchically Composing Level Generators for the Creation of Complex
  Structures","Code is available at https://github.com/Michael-Beukman/MCHAMR. This
  work has been submitted to the IEEE for possible publication. Copyright may
  be transferred without notice, after which this version may no longer be
  accessible",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Procedural content generation (PCG) is a growing field, with numerous
applications in the video game industry, and great potential to help create
better games at a fraction of the cost of manual creation. However, much of the
work in PCG is focused on generating relatively straightforward levels in
simple games, as it is challenging to design an optimisable objective function
for complex settings. This limits the applicability of PCG to more complex and
modern titles, hindering its adoption in industry. Our work aims to address
this limitation by introducing a compositional level generation method, which
recursively composes simple, low-level generators together to construct large
and complex creations. This approach allows for easily-optimisable objectives
and the ability to design a complex structure in an interpretable way by
referencing lower-level components. We empirically demonstrate that our method
outperforms a non-compositional baseline by more accurately satisfying a
designer's functional requirements in several tasks. Finally, we provide a
qualitative showcase (in Minecraft) illustrating the large and complex, but
still coherent, structures that were generated using simple base generators.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:08:28 GMT""}]","2023-02-06"
"2302.01562","Jit Wu Yap","Jit Wu Yap","Uniform Bounds on S-Integral Preperiodic Points for Power and Latt\`es
  Maps","Comments are welcome!",,,,"math.NT math.DS","http://creativecommons.org/licenses/by/4.0/","  Let $K$ be a number field, $S$ a finite set of places and $\varphi:
\mathbb{P}^1 \to \mathbb{P}^1$ a rational map of degree $d \geq 2$ defined over
$K$. When $\varphi$ is a power of Latt\`es map, we establish uniformity results
on the number of $S$-integral preperiodic points relative to a non-preperiodic
point $\beta$, as $\beta$ varies over number fields of bounded degree.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:08:51 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 02:35:00 GMT""},{""version"":""v3"",""created"":""Wed, 29 Mar 2023 04:01:12 GMT""}]","2023-03-30"
"2302.01563","Jing Ji","Fanglan Zheng, Menghan Wang, Kun Li, Jiang Tian, Xiaojia Xiang","Causal Inference Based Single-branch Ensemble Trees For Uplift Modeling",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this manuscript (ms), we propose causal inference based single-branch
ensemble trees for uplift modeling, namely CIET. Different from standard
classification methods for predictive probability modeling, CIET aims to
achieve the change in the predictive probability of outcome caused by an action
or a treatment. According to our CIET, two partition criteria are specifically
designed to maximize the difference in outcome distribution between the
treatment and control groups. Next, a novel single-branch tree is built by
taking a top-down node partition approach, and the remaining samples are
censored since they are not covered by the upper node partition logic.
Repeating the tree-building process on the censored data, single-branch
ensemble trees with a set of inference rules are thus formed. Moreover, CIET is
experimentally demonstrated to outperform previous approaches for uplift
modeling in terms of both area under uplift curve (AUUC) and Qini coefficient
significantly. At present, CIET has already been applied to online personal
loans in a national financial holdings group in China. CIET will also be of use
to analysts applying machine learning techniques to causal inference in broader
business domains such as web advertising, medicine and economics.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:22:00 GMT""}]","2023-02-06"
"2302.01564","Hrishikesh Chakrabarty","Hrishikesh Chakrabarty, Auttakit Chatrabhuti, Daniele Malafarina,
  Bhuddhanubhap Silasan, Takol Tangphati","Effects of gravitational lensing by Kaluza-Klein black holes on neutrino
  oscillations","13 pages, 6 figures",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We study gravitational lensing of neutrinos in a Kaluza-Klein black hole
spacetime and compare the oscillation probabilities of neutrinos with the case
of lensing by black holes in General Relativity. We show that measuring
neutrino oscillations in curved spacetimes may allow us to distinguish the two
kinds of black holes. This promises to become an useful tool for future
measurements of the properties of black hole candidates and possibly help to
constrain the validity of alternative theories of gravity.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:24:34 GMT""}]","2023-02-06"
"2302.01565","Timofei Snegirev","Timofei Snegirev","Hamiltonian formulation for perfect fluid equations with the l-conformal
  Galilei symmetry","9 pages",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Hamiltonian formulation for perfect fluid equations with the l-conformal
Galilei symmetry is proposed. For an arbitrary half-integer value of the
parameter l, the Hamilton and non-canonical Poisson brackets are found, in
terms of which the original higher derivative equations of motion take the
conventional Hamiltonian form. The full set of conserved charges is found and
their algebra is established.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:24:56 GMT""}]","2023-02-06"
"2302.01566","Andrii Natochii","A. Natochii, T. E. Browder, L. Cao, G. Cautero, S. Dreyer, A. Frey, A.
  Gabrielli, D. Giuressi, T. Ishibashi, Y. Jin, K. Kojima, T. Kraetzschmar, L.
  Lanceri, Z. Liptak, D. Liventsev, C. Marinas, L. Massaccesi, K. Matsuoka, F.
  Meier, C. Miller, H. Nakayama, C. Niebuhr, A. Novosel, K. Parham, I. Popov,
  G. Rizzo, J. M. Roney, S. Y. Ryu, L. Santelj, S. Schneider, J. Schueler, B.
  Schwenker, X. D. Shi, F. Simon, S. Stefkova, M. Takahashi, H. Tanigawa, N.
  Taniguchi, S. Terui, S. E. Vahsen, L. Vitale, A. Vossen, Z. Wang, J.
  Wiechczynski, H. Windel, K. Yoshihara","Measured and projected beam backgrounds in the Belle II experiment at
  the SuperKEKB collider","28 pages, 17 figures, 9 tables",,,,"hep-ex physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  The Belle II experiment at the SuperKEKB electron-positron collider aims to
collect an unprecedented data set of $50~{\rm ab}^{-1}$ to study $CP$-violation
in the $B$-meson system and to search for Physics beyond the Standard Model.
SuperKEKB is already the world's highest-luminosity collider. In order to
collect the planned data set within approximately one decade, the target is to
reach a peak luminosity of $\rm 6.3 \times 10^{35}~cm^{-2}s^{-1}$ by further
increasing the beam currents and reducing the beam size at the interaction
point by squeezing the betatron function down to $\beta^{*}_{\rm y}=\rm
0.3~mm$. To ensure detector longevity and maintain good reconstruction
performance, beam backgrounds must remain well controlled. We report on current
background rates in Belle II and compare these against simulation. We find that
a number of recent refinements have significantly improved the background
simulation accuracy. Finally, we estimate the safety margins going forward. We
predict that backgrounds should remain high but acceptable until a luminosity
of at least $\rm 2.8 \times 10^{35}~cm^{-2}s^{-1}$ is reached for
$\beta^{*}_{\rm y}=\rm 0.6~mm$. At this point, the most vulnerable Belle II
detectors, the Time-of-Propagation (TOP) particle identification system and the
Central Drift Chamber (CDC), have predicted background hit rates from
single-beam and luminosity backgrounds that add up to approximately half of the
maximum acceptable rates.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:26:49 GMT""}]","2023-02-06"
"2302.01567","Seyyedamirhossein Saeidi","Seyyedamirhossein Saeidi and Forouzan Fallah and Saeed
  Samieezafarghandi and Hamed Farbeh","Deep Reinforcement Learning for Online Error Detection in Cyber-Physical
  Systems","There are some problems in the paper, so the authors decide to
  withdraw the paper",,,,"cs.LG cs.AI cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Reliability is one of the major design criteria in Cyber-Physical Systems
(CPSs). This is because of the existence of some critical applications in CPSs
and their failure is catastrophic. Therefore, employing strong error detection
and correction mechanisms in CPSs is inevitable. CPSs are composed of a variety
of units, including sensors, networks, and microcontrollers. Each of these
units is probable to be in a faulty state at any time and the occurred fault
can result in erroneous output. The fault may cause the units of CPS to
malfunction and eventually crash. Traditional fault-tolerant approaches include
redundancy time, hardware, information, and/or software. However, these
approaches impose significant overheads besides their low error coverage, which
limits their applicability. In addition, the interval between error occurrence
and detection is too long in these approaches. In this paper, based on Deep
Reinforcement Learning (DRL), a new error detection approach is proposed that
not only detects errors with high accuracy but also can perform error detection
at the moment due to very low inference time. The proposed approach can
categorize different types of errors from normal data and predict whether the
system will fail. The evaluation results illustrate that the proposed approach
has improved more than 2x in terms of accuracy and more than 5x in terms of
inference time compared to other approaches.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:28:54 GMT""},{""version"":""v2"",""created"":""Tue, 2 May 2023 20:10:46 GMT""},{""version"":""v3"",""created"":""Mon, 5 Jun 2023 20:18:01 GMT""}]","2023-06-07"
"2302.01568","Minkyoung Cho","Minkyoung Cho and Kang G. Shin","DynaMIX: Resource Optimization for DNN-Based Real-Time Applications on a
  Multi-Tasking System","13 pages, 9 figures, 5 tables",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As deep neural networks (DNNs) prove their importance and feasibility, more
and more DNN-based apps, such as detection and classification of objects, have
been developed and deployed on autonomous vehicles (AVs). To meet their growing
expectations and requirements, AVs should ""optimize"" use of their limited
onboard computing resources for multiple concurrent in-vehicle apps while
satisfying their timing requirements (especially for safety). That is,
real-time AV apps should share the limited on-board resources with other
concurrent apps without missing their deadlines dictated by the frame rate of a
camera that generates and provides input images to the apps. However, most, if
not all, of existing DNN solutions focus on enhancing the concurrency of their
specific hardware without dynamically optimizing/modifying the DNN apps'
resource requirements, subject to the number of running apps, owing to their
high computational cost. To mitigate this limitation, we propose DynaMIX
(Dynamic MIXed-precision model construction), which optimizes the resource
requirement of concurrent apps and aims to maximize execution accuracy. To
realize a real-time resource optimization, we formulate an optimization problem
using app performance profiles to consider both the accuracy and worst-case
latency of each app. We also propose dynamic model reconfiguration by lazy
loading only the selected layers at runtime to reduce the overhead of loading
the entire model. DynaMIX is evaluated in terms of constraint satisfaction and
inference accuracy for a multi-tasking system and compared against
state-of-the-art solutions, demonstrating its effectiveness and feasibility
under various environmental/operating conditions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:33:28 GMT""}]","2023-02-06"
"2302.01569","Fei Qi","Hongmin Cai, Fei Qi, Junyu Li, Yu Hu, Yue Zhang, Yiu-ming Cheung, and
  Bin Hu","Uniform tensor clustering by jointly exploring sample affinities of
  various orders",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventional clustering methods based on pairwise affinity usually suffer
from the concentration effect while processing huge dimensional features yet
low sample sizes data, resulting in inaccuracy to encode the sample proximity
and suboptimal performance in clustering. To address this issue, we propose a
unified tensor clustering method (UTC) that characterizes sample proximity
using multiple samples' affinity, thereby supplementing rich spatial sample
distributions to boost clustering. Specifically, we find that the triadic
tensor affinity can be constructed via the Khari-Rao product of two affinity
matrices. Furthermore, our early work shows that the fourth-order tensor
affinity is defined by the Kronecker product. Therefore, we utilize
arithmetical products, Khatri-Rao and Kronecker products, to mathematically
integrate different orders of affinity into a unified tensor clustering
framework. Thus, the UTC jointly learns a joint low-dimensional embedding to
combine various orders. Finally, a numerical scheme is designed to solve the
problem. Experiments on synthetic datasets and real-world datasets demonstrate
that 1) the usage of high-order tensor affinity could provide a supplementary
characterization of sample proximity to the popular affinity matrix; 2) the
proposed method of UTC is affirmed to enhance clustering by exploiting
different order affinities when processing high-dimensional data.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:43:08 GMT""}]","2023-02-06"
"2302.01570","Jacopo Tagliabue","Piero Molino, Jacopo Tagliabue","Witgenstein's influence on artificial intelligence","English pre-print of a Chapter first appeared in Spanish in
  CENTENARIO DEL SILENCIO (2021)",,,,"cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  We examine how much of the contemporary progress in artificial intelligence
(and, specifically, in natural language processing), can be, more or less
directly, traced back to the seminal work and ideas of the Austrian-British
philosopher Ludwig Wittgenstein, with particular focus on his late views.
Discussing Wittgenstein's original theses will give us the chance to survey the
state of artificial intelligence, and comment on both its strengths and
weaknesses. A similar text appeared first in Spanish as a chapter of CENTENARIO
DEL SILENCIO (2021), a book celebrating 100 years since the publication of the
Tractatus.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:47:20 GMT""}]","2023-02-06"
"2302.01571","Jin-Hwa Kim","Hwan Heo, Taekyung Kim, Jiyoung Lee, Jaewon Lee, Soohyun Kim, Hyunwoo
  J. Kim, Jin-Hwa Kim","Robust Camera Pose Refinement for Multi-Resolution Hash Encoding",,,,,"cs.CV cs.AI cs.GR cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Multi-resolution hash encoding has recently been proposed to reduce the
computational cost of neural renderings, such as NeRF. This method requires
accurate camera poses for the neural renderings of given scenes. However,
contrary to previous methods jointly optimizing camera poses and 3D scenes, the
naive gradient-based camera pose refinement method using multi-resolution hash
encoding severely deteriorates performance. We propose a joint optimization
algorithm to calibrate the camera pose and learn a geometric representation
using efficient multi-resolution hash encoding. Showing that the oscillating
gradient flows of hash encoding interfere with the registration of camera
poses, our method addresses the issue by utilizing smooth interpolation
weighting to stabilize the gradient oscillation for the ray samplings across
hash grids. Moreover, the curriculum training procedure helps to learn the
level-wise hash encoding, further increasing the pose refinement. Experiments
on the novel-view synthesis datasets validate that our learning frameworks
achieve state-of-the-art performance and rapid convergence of neural rendering,
even when initial camera poses are unknown.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:49:27 GMT""}]","2023-02-06"
"2302.01572","Yingying Zhu","Yingying Zhu, Hongji Yang, Yuxin Lu and Qiang Huang","Simple, Effective and General: A New Backbone for Cross-view Image
  Geo-localization","Under Review",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we aim at an important but less explored problem of a simple
yet effective backbone specific for cross-view geo-localization task. Existing
methods for cross-view geo-localization tasks are frequently characterized by
1) complicated methodologies, 2) GPU-consuming computations, and 3) a stringent
assumption that aerial and ground images are centrally or orientation aligned.
To address the above three challenges for cross-view image matching, we propose
a new backbone network, named Simple Attention-based Image Geo-localization
network (SAIG). The proposed SAIG effectively represents long-range
interactions among patches as well as cross-view correspondence with multi-head
self-attention layers. The ""narrow-deep"" architecture of our SAIG improves the
feature richness without degradation in performance, while its shallow and
effective convolutional stem preserves the locality, eliminating the loss of
patchify boundary information. Our SAIG achieves state-of-the-art results on
cross-view geo-localization, while being far simpler than previous works.
Furthermore, with only 15.9% of the model parameters and half of the output
dimension compared to the state-of-the-art, the SAIG adapts well across
multiple cross-view datasets without employing any well-designed feature
aggregation modules or feature alignment algorithms. In addition, our SAIG
attains competitive scores on image retrieval benchmarks, further demonstrating
its generalizability. As a backbone network, our SAIG is both easy to follow
and computationally lightweight, which is meaningful in practical scenario.
Moreover, we propose a simple Spatial-Mixed feature aggregation moDule (SMD)
that can mix and project spatial information into a low-dimensional space to
generate feature descriptors... (The code is available at
https://github.com/yanghongji2007/SAIG)
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:50:51 GMT""}]","2023-02-06"
"2302.01573","Vladimir Zolotarev","M.F. Bessmertny\u{\i} and V.A. Zolotarev","$p$-Hyperbolic Zolotarev Functions in Boundary Value Problems for a
  $p\,$th order Differential Operator",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For the self-adjoint operator of the $p$th derivative, a system of
fundamental solutions is constructed. This system is analogues to the classical
system of sines and cosines. The properties of such functions are studied.
Classes of self-adjoint boundary conditions are described. For the operator of
the third derivative, the resolvent is calculated and an orthonormal basis of
eigenfunctions is given.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:59:03 GMT""}]","2023-02-06"
"2302.01574","Brian Hsu","Brian Hsu, Xiaotong Chen, Ying Han, Hongseok Namkoong, Kinjal Basu","An Operational Perspective to Fairness Interventions: Where and How to
  Intervene",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  As AI-based decision systems proliferate, their successful operationalization
requires balancing multiple desiderata: predictive performance, disparity
across groups, safeguarding sensitive group attributes (e.g., race), and
engineering cost. We present a holistic framework for evaluating and
contextualizing fairness interventions with respect to the above desiderata.
The two key points of practical consideration are \emph{where} (pre-, in-,
post-processing) and \emph{how} (in what way the sensitive group data is used)
the intervention is introduced. We demonstrate our framework with a case study
on predictive parity. In it, we first propose a novel method for achieving
predictive parity fairness without using group data at inference time via
distibutionally robust optimization. Then, we showcase the effectiveness of
these methods in a benchmarking study of close to 400 variations across two
major model types (XGBoost vs. Neural Net), ten datasets, and over twenty
unique methodologies. Methodological insights derived from our empirical study
inform the practical design of ML workflow with fairness as a central concern.
We find predictive parity is difficult to achieve without using group data, and
despite requiring group data during model training (but not inference),
distributionally robust methods we develop provide significant Pareto
improvement. Moreover, a plain XGBoost model often Pareto-dominates neural
networks with fairness interventions, highlighting the importance of model
inductive bias.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:04:33 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 21:20:38 GMT""}]","2023-03-27"
"2302.01575","Aviv Karnieli","Aviv Karnieli and Shanhui Fan","Jaynes-Cummings interaction between low energy free-electrons and cavity
  photons","18 pages, including Supplementary Material, 3 figures",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  The Jaynes-Cummings Hamiltonian is at the core of cavity quantum
electrodynamics, and is ubiquitous in a variety of quantum technologies. The
ability to implement and control the various aspects of this Hamiltonian is
thus of paramount importance. However, conventional implementations relying on
bound-electron systems are fundamentally limited by the Coulomb potential that
bounds the electron, in addition to suffering from practical limitations such
as requiring cryogenic temperatures for operation and fabrication
inhomogeneity. In this work, we propose theoretically a new approach to realize
the Jaynes-Cummings Hamiltonian using low energy free-electrons coupled to
dielectric microcavities, and exemplify several quantum technologies made
possible by this approach. Our approach utilizes quantum recoil, which causes a
large detuning that inhibits the emission of multiple consecutive photons,
effectively transforming the free-electron into a two-level system coupled to
the cavity mode. We show that this approach can be used for generation of
single photons with unity efficiency and high fidelity. We then generalize the
concept to achieve a multiple-level quantum emitter through a suitable design
of cavity modes, allowing for deterministic photon-pair generation and even a
quantum SWAP gate between a cavity photon and a free-electron qubit. An
increase in coupling strength by a factor of \sqrt(N) can be achieved when an
entangled symmetric state of N electrons is used to drive the cavity. Tunable
by their kinetic energy and phase-matching to light waves, quantum
free-electrons are inherently versatile emitters with an engineerable emission
wavelength. As such, they pave the way towards new possibilities for quantum
interconnects between photonic platforms at disparate spectral regimes.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:06:51 GMT""}]","2023-02-06"
"2302.01576","Zitong Yang","Zitong Yang, Michal Lukasik, Vaishnavh Nagarajan, Zonglin Li, Ankit
  Singh Rawat, Manzil Zaheer, Aditya Krishna Menon, Sanjiv Kumar","ResMem: Learn what you can and memorize the rest",,,,,"cs.LG cs.AI stat.ME stat.ML","http://creativecommons.org/licenses/by/4.0/","  The impressive generalization performance of modern neural networks is
attributed in part to their ability to implicitly memorize complex training
patterns. Inspired by this, we explore a novel mechanism to improve model
generalization via explicit memorization. Specifically, we propose the
residual-memorization (ResMem) algorithm, a new method that augments an
existing prediction model (e.g. a neural network) by fitting the model's
residuals with a $k$-nearest neighbor based regressor. The final prediction is
then the sum of the original model and the fitted residual regressor. By
construction, ResMem can explicitly memorize the training labels. Empirically,
we show that ResMem consistently improves the test set generalization of the
original prediction model across various standard vision and natural language
processing benchmarks. Theoretically, we formulate a stylized linear regression
problem and rigorously show that ResMem results in a more favorable test risk
over the base predictor.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:12:55 GMT""}]","2023-02-06"
"2302.01577","Koustav Roy","Koustav Roy and Saurabh Basu","Topological properties of a periodically driven Creutz ladder","10 pages, 19 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We have investigated a periodically driven Creutz ladder in presence of two
different driving protocols, namely, a sinusoidal drive and a $\delta$-kick
imparted to the ladder at regular intervals of time. Specifically, we have
studied the topological properties corresponding to the trivial and the
non-trivial limits of the static (undriven) case via computing suitable
topological invariants. Corresponding to the case where the chiral symmetry is
intact, in addition to the zero energy modes, $\pi$ energy modes appear in both
these cases. Further, two different frequency regimes of the driving protocol
emerge, where Floquet-Magnus expansion is particularly employed to study the
high frequency regime for the sinusoidal drive. Apart from the physics being
identical in the high frequency and the static scenarios, the zero energy modes
show distinctive features at low and high frequencies. For the sinusoidal
drive, there exists a sharp frequency threshold beyond which the zero energy
mode only exists in the topological limit, while in the trivial limit, it
exists only upto the threshold frequency. In presence of the $\delta$-kick, the
Creutz ladder demonstrates higher values of the topological invariant, and as a
consequence the system possesses large number of edge modes.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:14:41 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 08:08:34 GMT""},{""version"":""v3"",""created"":""Wed, 8 Feb 2023 18:47:36 GMT""}]","2023-02-09"
"2302.01578","Taoan Huang","Taoan Huang, Aaron Ferber, Yuandong Tian, Bistra Dilkina, Benoit
  Steiner","Searching Large Neighborhoods for Integer Linear Programs with
  Contrastive Learning",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Integer Linear Programs (ILPs) are powerful tools for modeling and solving a
large number of combinatorial optimization problems. Recently, it has been
shown that Large Neighborhood Search (LNS), as a heuristic algorithm, can find
high quality solutions to ILPs faster than Branch and Bound. However, how to
find the right heuristics to maximize the performance of LNS remains an open
problem. In this paper, we propose a novel approach, CL-LNS, that delivers
state-of-the-art anytime performance on several ILP benchmarks measured by
metrics including the primal gap, the primal integral, survival rates and the
best performing rate. Specifically, CL-LNS collects positive and negative
solution samples from an expert heuristic that is slow to compute and learns a
new one with a contrastive loss. We use graph attention networks and a richer
set of features to further improve its performance.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:15:37 GMT""}]","2023-02-06"
"2302.01579","Tianxiang Ma","Tianxiang Ma, Bingchuan Li, Qian He, Jing Dong, Tieniu Tan","Semantic 3D-aware Portrait Synthesis and Manipulation Based on
  Compositional Neural Radiance Field","Accepted by AAAI2023 Oral",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently 3D-aware GAN methods with neural radiance field have developed
rapidly. However, current methods model the whole image as an overall neural
radiance field, which limits the partial semantic editability of synthetic
results. Since NeRF renders an image pixel by pixel, it is possible to split
NeRF in the spatial dimension. We propose a Compositional Neural Radiance Field
(CNeRF) for semantic 3D-aware portrait synthesis and manipulation. CNeRF
divides the image by semantic regions and learns an independent neural radiance
field for each region, and finally fuses them and renders the complete image.
Thus we can manipulate the synthesized semantic regions independently, while
fixing the other parts unchanged. Furthermore, CNeRF is also designed to
decouple shape and texture within each semantic region. Compared to
state-of-the-art 3D-aware GAN methods, our approach enables fine-grained
semantic region manipulation, while maintaining high-quality 3D-consistent
synthesis. The ablation studies show the effectiveness of the structure and
loss function used by our method. In addition real image inversion and cartoon
portrait 3D editing experiments demonstrate the application potential of our
method.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:17:46 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 12:37:59 GMT""}]","2023-04-11"
"2302.01580","Chikun Ding","Chikun Ding, Yu Shi, Jun Chen, Yuebing Zhou, Changqing Liu, Yuehua
  Xiao","Rotating BTZ-like black hole and central charges in Einstein-bumblebee
  gravity","12 pages, no figure. arXiv admin note: text overlap with
  arXiv:2201.06683",,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We obtain an exact rotating BTZ-like black hole solution by solving the
corresponding gravitational field equations in Einstein-bumblebee gravity
theory. Result is presented for the purely radial Lorentz symmetry violating
and can only exist with a linear functional potential of the bumblebee field.
This black hole has two horizons and an ergosphere which are dependent on the
bumblebee coupling constant $\ell$. We study the AdS/CFT correspondence of this
black hole, find that the entropy product of its inner and outer horizons is
universal. So the central charges of the dual CFT on the boundary can be
obtained via the thermodynamic method, and they can reappear black hole mass
and angular momentum in the bulk.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:18:04 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 07:43:15 GMT""}]","2023-03-30"
"2302.01581","Zihan Zhou","Zihan Zhou and Tianshu Yu","Learning to Decouple Complex Systems",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  A complex system with cluttered observations may be a coupled mixture of
multiple simple sub-systems corresponding to latent entities. Such sub-systems
may hold distinct dynamics in the continuous-time domain; therein, complicated
interactions between sub-systems also evolve over time. This setting is fairly
common in the real world but has been less considered. In this paper, we
propose a sequential learning approach under this setting by decoupling a
complex system for handling irregularly sampled and cluttered sequential
observations. Such decoupling brings about not only subsystems describing the
dynamics of each latent entity but also a meta-system capturing the interaction
between entities over time. Specifically, we argue that the meta-system
evolving within a simplex is governed by projected differential equations
(ProjDEs). We further analyze and provide neural-friendly projection operators
in the context of Bregman divergence. Experimental results on synthetic and
real-world datasets show the advantages of our approach when facing complex and
cluttered sequential data compared to the state-of-the-art.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:24:58 GMT""}]","2023-02-06"
"2302.01582","Richard Johansson","Manuj Malik and Richard Johansson","Controlling for Stereotypes in Multimodal Language Model Evaluation",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We propose a methodology and design two benchmark sets for measuring to what
extent language-and-vision language models use the visual signal in the
presence or absence of stereotypes. The first benchmark is designed to test for
stereotypical colors of common objects, while the second benchmark considers
gender stereotypes. The key idea is to compare predictions when the image
conforms to the stereotype to predictions when it does not.
  Our results show that there is significant variation among multimodal models:
the recent Transformer-based FLAVA seems to be more sensitive to the choice of
image and less affected by stereotypes than older CNN-based models such as
VisualBERT and LXMERT. This effect is more discernible in this type of
controlled setting than in traditional evaluations where we do not know whether
the model relied on the stereotype or the visual signal.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:27:50 GMT""}]","2023-02-06"
"2302.01583","Rohit Dilip Holkar Dr","Rohit Dilip Holkar, Md Amir Hossain","Topological fundamental groupoid. I","25 pages, 1 figure",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the fundamental groupoid~\(\Pi_1(X)\) of a locally path
connected semilocally simply connected space~\(X\) can be equipped with a
\emph{natural} topology so that it becomes a topological groupoid; we also
justify the necessity and minimality of these two hypotheses on~\(X\) in order
to topologise the fundamental groupoid. We find that contrary to a belief --
especially among the Operator Algebraists -- the fundamental groupoid is not
{\etale}. Further, we prove that the fundamental groupoid of a topological
group, in particular a Lie group, is a \emph{transformation groupoid}; again,
this result disproves a standard belief that the fundamental groupoids are
\emph{far} away from being transformation groupoids. We also discuss the
point-set topology on the fundamental groupoid with the intention of making it
a locally compact groupoid.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:31:29 GMT""}]","2023-02-06"
"2302.01584","Adrien Benamira","Adrien Benamira, Tristan Gu\'erand, Thomas Peyrin, Sayandeep Saha","TT-TFHE: a Torus Fully Homomorphic Encryption-Friendly Neural Network
  Architecture",,,,,"cs.CR cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents TT-TFHE, a deep neural network Fully Homomorphic
Encryption (FHE) framework that effectively scales Torus FHE (TFHE) usage to
tabular and image datasets using a recent family of convolutional neural
networks called Truth-Table Neural Networks (TTnet). The proposed framework
provides an easy-to-implement, automated TTnet-based design toolbox with an
underlying (python-based) open-source Concrete implementation (CPU-based and
implementing lookup tables) for inference over encrypted data. Experimental
evaluation shows that TT-TFHE greatly outperforms in terms of time and accuracy
all Homomorphic Encryption (HE) set-ups on three tabular datasets, all other
features being equal. On image datasets such as MNIST and CIFAR-10, we show
that TT-TFHE consistently and largely outperforms other TFHE set-ups and is
competitive against other HE variants such as BFV or CKKS (while maintaining
the same level of 128-bit encryption security guarantees). In addition, our
solutions present a very low memory footprint (down to dozens of MBs for
MNIST), which is in sharp contrast with other HE set-ups that typically require
tens to hundreds of GBs of memory per user (in addition to their communication
overheads). This is the first work presenting a fully practical solution of
private inference (i.e. a few seconds for inference time and a few dozens MBs
of memory) on both tabular datasets and MNIST, that can easily scale to
multiple threads and users on server side.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:32:23 GMT""}]","2023-02-06"
"2302.01585","Daniel Gritzner","Daniel Gritzner, J\""orn Ostermann","SegForestNet: Spatial-Partitioning-Based Aerial Image Segmentation","This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Aerial image analysis, specifically the semantic segmentation thereof, is the
basis for applications such as automatically creating and updating maps,
tracking city growth, or tracking deforestation. In true orthophotos, which are
often used in these applications, many objects and regions can be approximated
well by polygons. However, this fact is rarely exploited by state-of-the-art
semantic segmentation models. Instead, most models allow unnecessary degrees of
freedom in their predictions by allowing arbitrary region shapes. We therefore
present a refinement of our deep learning model which predicts binary space
partitioning trees, an efficient polygon representation. The refinements
include a new feature decoder architecture and a new differentiable BSP tree
renderer which both avoid vanishing gradients. Additionally, we designed a
novel loss function specifically designed to improve the spatial partitioning
defined by the predicted trees. Furthermore, our expanded model can predict
multiple trees at once and thus can predict class-specific segmentations.
Taking all modifications together, our model achieves state-of-the-art
performance while using up to 60% fewer model parameters when using a small
backbone model or up to 20% fewer model parameters when using a large backbone
model.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:35:53 GMT""}]","2023-02-06"
"2302.01586","Xu Shen","Xu Shen, Francesco Borrelli","Reinforcement Learning and Distributed Model Predictive Control for
  Conflict Resolution in Highly Constrained Spaces",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work presents a distributed algorithm for resolving cooperative
multi-vehicle conflicts in highly constrained spaces. By formulating the
conflict resolution problem as a Multi-Agent Reinforcement Learning (RL)
problem, we can train a policy offline to drive the vehicles towards their
destinations safely and efficiently in a simplified discrete environment.
During the online execution, each vehicle first simulates the interaction among
vehicles with the trained policy to obtain its strategy, which is used to guide
the computation of a reference trajectory. A distributed Model Predictive
Controller (MPC) is then proposed to track the reference while avoiding
collisions. The preliminary results show that the combination of RL and
distributed MPC has the potential to guide vehicles to resolve conflicts safely
and smoothly while being less computationally demanding than the centralized
approach.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:44:56 GMT""}]","2023-02-06"
"2302.01587","Sandi Klav\v{z}ar","Sandi Klav\v{z}ar and Elif Tan and Jing Tian","Extremal edge general position sets in some graphs",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  A set of edges $X\subseteq E(G)$ of a graph $G$ is an edge general position
set if no three edges from $X$ lie on a common shortest path. The edge general
position number ${\rm gp}_{\rm e}(G)$ of $G$ is the cardinality of a largest
edge general position set in $G$. Graphs $G$ with ${\rm gp}_{\rm e}(G) = |E(G)|
- 1$ and with ${\rm gp}_{\rm e}(G) = 3$ are respectively characterized. Sharp
upper and lower bounds on ${\rm gp}_{\rm e}(G)$ are proved for block graphs $G$
and exact values are determined for several specific block graphs.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 07:54:25 GMT""}]","2023-02-06"
"2302.01588","Li Fang","Li Fang, Qingyu Chen, Chih-Hsuan Wei, Zhiyong Lu, Kai Wang","Bioformer: an efficient transformer language model for biomedical text
  mining",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Pretrained language models such as Bidirectional Encoder Representations from
Transformers (BERT) have achieved state-of-the-art performance in natural
language processing (NLP) tasks. Recently, BERT has been adapted to the
biomedical domain. Despite the effectiveness, these models have hundreds of
millions of parameters and are computationally expensive when applied to
large-scale NLP applications. We hypothesized that the number of parameters of
the original BERT can be dramatically reduced with minor impact on performance.
In this study, we present Bioformer, a compact BERT model for biomedical text
mining. We pretrained two Bioformer models (named Bioformer8L and Bioformer16L)
which reduced the model size by 60% compared to BERTBase. Bioformer uses a
biomedical vocabulary and was pre-trained from scratch on PubMed abstracts and
PubMed Central full-text articles. We thoroughly evaluated the performance of
Bioformer as well as existing biomedical BERT models including BioBERT and
PubMedBERT on 15 benchmark datasets of four different biomedical NLP tasks:
named entity recognition, relation extraction, question answering and document
classification. The results show that with 60% fewer parameters, Bioformer16L
is only 0.1% less accurate than PubMedBERT while Bioformer8L is 0.9% less
accurate than PubMedBERT. Both Bioformer16L and Bioformer8L outperformed
BioBERTBase-v1.1. In addition, Bioformer16L and Bioformer8L are 2-3 fold as
fast as PubMedBERT/BioBERTBase-v1.1. Bioformer has been successfully deployed
to PubTator Central providing gene annotations over 35 million PubMed abstracts
and 5 million PubMed Central full-text articles. We make Bioformer publicly
available via https://github.com/WGLab/bioformer, including pre-trained models,
datasets, and instructions for downstream use.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:04:59 GMT""}]","2023-02-06"
"2302.01589","Andr\'e Kaup","Daniela Lanz, Franz Schilling, Andr\'e Kaup","Scalable Lossless Coding of Dynamic Medical CT Data Using Motion
  Compensated Wavelet Lifting with Denoised Prediction and Update",,"Picture Coding Symposium (PCS), Ningbo, China, 2019, pp. 1-5",,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Professional applications like telemedicine often require scalable lossless
coding of sensitive data. 3-D subband coding has turned out to offer good
compression results for dynamic CT data and additionally provides a scalable
representation in terms of low- and highpass subbands. To improve the visual
quality of the lowpass subband, motion compensation can be incorporated into
the lifting structure, but leads to inferior compression results at the same
time. Prior work has shown that a denoising filter in the update step can
improve the compression ratio. In this paper, we present a new processing order
of motion compensation and denoising in the update step and additionally
introduce a second denoising filter in the prediction step. This allows for
reducing the overall file size by up to 4.4%, while the visual quality of the
lowpass subband is kept nearly constant.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:05:49 GMT""}]","2023-02-06"
"2302.01590","Lewis Williamson","L. A. Williamson and Matthew J. Davis","Many-body enhancement in a spin-chain quantum heat engine","4 pages + refs + supplement, 3 figures",,,,"quant-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We show that ferromagnetic interactions can enhance the adiabatic performance
of a quantum spin chain engine at low temperatures. The enhancement in work
output is particular pronounced, increasing exponentially with interaction
strength. The performance enhancement occurs in the paramagnetic phase and is
qualitatively explained by considering just the ground and first excited state,
in which case the system exhibits bipartite entanglement. As the temperature is
increased, thermal occupation of higher energy levels diminishes performance.
We find that these thermal fluctuations are smallest for long-range
interactions, resulting in the highest efficiency. Diabatic work extraction
degrades performance due to quantum friction. We identify an approximate,
experimentally realisable counterdiabatic drive that can mitigate friction for
weak interactions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:05:50 GMT""}]","2023-02-07"
"2302.01591","Rui Yu","Zhu Wang, Xu-Tao Zeng, Yuanchuan Biao, Zhongbo Yan, Rui Yu","Realization of a Hopf insulator in circuit systems",,,"10.1103/PhysRevLett.130.057201",,"cond-mat.mes-hall cond-mat.other","http://creativecommons.org/licenses/by/4.0/","  Three-dimensional (3D) two-band Hopf insulators are a paradigmatic example of
topological phases beyond the topological classifications based on powerful
methods like $K$-theory and symmetry indicators.Since this class of topological
insulating phases was theoretically proposed in 2008, they have attracted
significant interest owing to their conceptual novelty, connection to knot
theory, and many fascinating physical properties. However, because their
realization requires special forms of long-range spin-orbit coupling (SOC),
they have not been achieved in any 3D system yet. Here we report the first
experimental realization of the long-sought-after Hopf insulator in a 3D
circuit system. To implement the Hopf insulator, we construct basic pseudo-spin
modules and connection modules that can realize $2\times2$-matrix elements and
then design the circuit network according to a tight-binding Hopf insulator
Hamiltonian constructed by the Hopf map. By simulating the band structure of
the designed circuit network and calculating the Hopf invariant, we find that
the circuit realizes a Hopf insulator with Hopf invariant equaling $4$.
Experimentally, we measure the band structure of a printed circuit board and
find the observed properties of the bulk bands and topological surface states
(TSS) are in good agreement with the theoretical predictions, verifying the
bulk-boundary correspondence of the Hopf insulator. Our scheme brings the
experimental study of Hopf insulators to reality and opens the door to the
implementation of more unexplored topological phases beyond the known
topological classifications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:07:02 GMT""}]","2023-02-06"
"2302.01592","Andr\'e Kaup","Daniela Lanz, Andr\'e Kaup","Graph-Based Compensated Wavelet Lifting for Scalable Lossless Coding of
  Dynamic Medical Data",,"IEEE Transactions on Image Processing, vol. 29, pp. 2439-2451,
  2020","10.1109/TIP.2019.2947138",,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lossless compression of dynamic 2D+t and 3D+t medical data is challenging
regarding the huge amount of data, the characteristics of the inherent noise,
and the high bit depth. Beyond that, a scalable representation is often
required in telemedicine applications. Motion Compensated Temporal Filtering
works well for lossless compression of medical volume data and additionally
provides temporal, spatial, and quality scalability features. To achieve a high
quality lowpass subband, which shall be used as a downscaled representative of
the original data, graph-based motion compensation was recently introduced to
this framework. However, encoding the motion information, which is stored in
adjacency matrices, is not well investigated so far. This work focuses on
coding these adjacency matrices to make the graph-based motion compensation
feasible for data compression. We propose a novel coding scheme based on
constructing so-called motion maps. This allows for the first time to compare
the performance of graph-based motion compensation to traditional block- and
mesh-based approaches. For high quality lowpass subbands our method is able to
outperform the block- and mesh-based approaches by increasing the visual
quality in terms of PSNR by 0.53dB and 0.28dB for CT data, as well as 1.04dB
and 1.90dB for MR data, respectively, while the bit rate is reduced at the same
time.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:10:02 GMT""}]","2023-02-08"
"2302.01593","Jie Yang","Jie Yang, Ailing Zeng, Shilong Liu, Feng Li, Ruimao Zhang, Lei Zhang","Explicit Box Detection Unifies End-to-End Multi-Person Pose Estimation","Accepted to ICLR 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel end-to-end framework with Explicit box Detection
for multi-person Pose estimation, called ED-Pose, where it unifies the
contextual learning between human-level (global) and keypoint-level (local)
information. Different from previous one-stage methods, ED-Pose re-considers
this task as two explicit box detection processes with a unified representation
and regression supervision. First, we introduce a human detection decoder from
encoded tokens to extract global features. It can provide a good initialization
for the latter keypoint detection, making the training process converge fast.
Second, to bring in contextual information near keypoints, we regard pose
estimation as a keypoint box detection problem to learn both box positions and
contents for each keypoint. A human-to-keypoint detection decoder adopts an
interactive learning strategy between human and keypoint features to further
enhance global and local feature aggregation. In general, ED-Pose is
conceptually simple without post-processing and dense heatmap supervision. It
demonstrates its effectiveness and efficiency compared with both two-stage and
one-stage methods. Notably, explicit box detection boosts the pose estimation
performance by 4.5 AP on COCO and 9.9 AP on CrowdPose. For the first time, as a
fully end-to-end framework with a L1 regression loss, ED-Pose surpasses
heatmap-based Top-down methods under the same backbone by 1.2 AP on COCO and
achieves the state-of-the-art with 76.6 AP on CrowdPose without bells and
whistles. Code is available at https://github.com/IDEA-Research/ED-Pose.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:18:34 GMT""}]","2023-02-06"
"2302.01594","Andr\'e Kaup","Wolfgang Schnurrer, Thomas Richter, J\""urgen Seiler, Andr\'e Kaup","Analysis of mesh-based motion compensation in wavelet lifting of
  dynamical 3-D+t CT data",,"IEEE 14th International Workshop on Multimedia Signal Processing
  (MMSP), Banff, AB, Canada, 2012, pp. 152-157",,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Factorized in the lifting structure, the wavelet transform can easily be
extended by arbitrary compensation methods. Thereby, the transform can be
adapted to displacements in the signal without losing the ability of perfect
reconstruction. This leads to an improvement of scalability. In temporal
direction of dynamic medical 3-D+t volumes from Computed Tomography,
displacement is mainly given by expansion and compression of tissue. We show
that these smooth movements can be well compensated with a mesh-based method.
We compare the properties of triangle and quadrilateral meshes. We also show
that with a mesh-based compensation approach coding results are comparable to
the common slice wise coding with JPEG 2000 while a scalable representation in
temporal direction can be achieved.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:20:20 GMT""}]","2023-02-06"
"2302.01595","Arnab Bhattacharya","Ashutosh Dutta, Samrat Chatterjee, Arnab Bhattacharya, Mahantesh
  Halappanavar","Deep Reinforcement Learning for Cyber System Defense under Dynamic
  Adversarial Uncertainties",,,,,"cs.LG cs.AI cs.MA","http://creativecommons.org/licenses/by/4.0/","  Development of autonomous cyber system defense strategies and action
recommendations in the real-world is challenging, and includes characterizing
system state uncertainties and attack-defense dynamics. We propose a
data-driven deep reinforcement learning (DRL) framework to learn proactive,
context-aware, defense countermeasures that dynamically adapt to evolving
adversarial behaviors while minimizing loss of cyber system operations. A
dynamic defense optimization problem is formulated with multiple protective
postures against different types of adversaries with varying levels of skill
and persistence. A custom simulation environment was developed and experiments
were devised to systematically evaluate the performance of four model-free DRL
algorithms against realistic, multi-stage attack sequences. Our results suggest
the efficacy of DRL algorithms for proactive cyber defense under multi-stage
attack profiles and system uncertainties.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:33:33 GMT""}]","2023-02-06"
"2302.01596","Kaijie Xu","Kaijie Xu","A Novel Fuzzy Bi-Clustering Algorithm with AFS for Identification of
  Co-Regulated Genes",,,,,"cs.LG cs.NA math.NA stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The identification of co-regulated genes and their transcription-factor
binding sites (TFBS) are the key steps toward understanding transcription
regulation. In addition to effective laboratory assays, various bi-clustering
algorithms for detection of the co-expressed genes have been developed.
Bi-clustering methods are used to discover subgroups of genes with similar
expression patterns under to-be-identified subsets of experimental conditions
when applied to gene expression data. By building two fuzzy partition matrices
of the gene expression data with the Axiomatic Fuzzy Set (AFS) theory, this
paper proposes a novel fuzzy bi-clustering algorithm for identification of
co-regulated genes. Specifically, the gene expression data is transformed into
two fuzzy partition matrices via sub-preference relations theory of AFS at
first. One of the matrices is considering the genes as the universe and the
conditions as the concept, the other one is considering the genes as the
concept and the conditions as the universe. The identification of the
co-regulated genes (bi-clusters) is carried out on the two partition matrices
at the same time. Then, a novel fuzzy-based similarity criterion is defined
based on the partition matrixes, and a cyclic optimization algorithm is
designed to discover the significant bi-clusters at expression level. The above
procedures guarantee that the generated bi-clusters have more significant
expression values than that of extracted by the traditional bi-clustering
methods. Finally, the performance of the proposed method is evaluated with the
performance of the three well-known bi-clustering algorithms on publicly
available real microarray datasets. The experimental results are in agreement
with the theoretical analysis and show that the proposed algorithm can
effectively detect the co-regulated genes without any prior knowledge of the
gene expression data.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:35:49 GMT""}]","2023-02-06"
"2302.01597","C\'esar Jes\'us-Valls","C\'esar Jes\'us-Valls, Federico S\'anchez","Lead perovskites as CE$\nu$NS detectors",,,,,"physics.ins-det hep-ex","http://creativecommons.org/licenses/by/4.0/","  The recent discovery of Coherent Elastic neutrino-Nucleus Scattering
(CE$\nu$NS) has created new opportunities to detect and study neutrinos. The
interaction cross-section in CE$\nu$NS scales quadratically with the number of
neutrons, making heavy-nuclei targets such as active lead-based detectors
ideal. In this Letter, we discuss for the first time the potential of
semiconductor lead perovskites for building neutrino detectors. Lead
perovskites have emerged in the last decade as revolutionary materials for
radiation detection due to their heavy and flexible element composition and
their unique optoelectronic properties that result in an excellent energy
resolution at an economic cost. While dedicated research and development will
be necessary, we find great benefits and no inherent obstacles for the
development of lead perovskites as CE$\nu$NS detectors.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:39:22 GMT""},{""version"":""v2"",""created"":""Tue, 14 Feb 2023 09:30:28 GMT""}]","2023-02-15"
"2302.01598","Stefan Schreieder","Stefan Schreieder","Geometric retract rationality of norm varieties","6 pages, v2: minor changes",,,,"math.AG math.KT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $k$ be a field of characteristic zero. We show that the norm variety
associated to a symbol $\alpha\in K^M_n(k)/\ell$ in Milnor K-theory modulo
$\ell$ is geometrically retract rational for any prime $\ell$. This generalizes
a recent result of Balwe-Hogadi-Sawant, where geometric $\mathbb
A^1$-connectedness (an a priori weaker notion) had been proven.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:41:11 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 14:04:09 GMT""}]","2023-02-13"
"2302.01599","Mengxuan Li","Mengxuan Li, Peng Peng, Jingxin Zhang, Hongwei Wang, Weiming Shen","SCCAM: Supervised Contrastive Convolutional Attention Mechanism for
  Ante-hoc Interpretable Fault Diagnosis with Limited Fault Samples",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In real industrial processes, fault diagnosis methods are required to learn
from limited fault samples since the procedures are mainly under normal
conditions and the faults rarely occur. Although attention mechanisms have
become popular in the field of fault diagnosis, the existing attention-based
methods are still unsatisfying for the above practical applications. First,
pure attention-based architectures like transformers need a large number of
fault samples to offset the lack of inductive biases thus performing poorly
under limited fault samples. Moreover, the poor fault classification dilemma
further leads to the failure of the existing attention-based methods to
identify the root causes. To address the aforementioned issues, we innovatively
propose a supervised contrastive convolutional attention mechanism (SCCAM) with
ante-hoc interpretability, which solves the root cause analysis problem under
limited fault samples for the first time. The proposed SCCAM method is tested
on a continuous stirred tank heater and the Tennessee Eastman industrial
process benchmark. Three common fault diagnosis scenarios are covered,
including a balanced scenario for additional verification and two scenarios
with limited fault samples (i.e., imbalanced scenario and long-tail scenario).
The comprehensive results demonstrate that the proposed SCCAM method can
achieve better performance compared with the state-of-the-art methods on fault
classification and root cause analysis.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:43:55 GMT""},{""version"":""v2"",""created"":""Fri, 17 Feb 2023 12:02:33 GMT""}]","2023-02-20"
"2302.01600","Yang Qinglin","Taotao Li, Changlin Yang, Qinglin Yang, Siqi Zhou, Huawei Huang, Zibin
  Zheng","MetaOpera: A Cross-Metaverse Interoperability Protocol",,,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the rapid evolution of metaverse technologies, numerous metaverse
applications have arisen for various purposes and scenarios. This makes
interoperability across metaverses becomes one of the fundamental technology
enablers in the metaverse space. The aim of interoperability is to provide a
seamless experience for users to interact with metaverses. However, the
development of cross-metaverse interoperability is still in its initial stage
in both industry and academia. In this paper, we review the state-of-the-art
cross-metaverse interoperability schemes. These schemes are designed for
specific interoperating scenarios and do not generalize for all types of
metaverses. To this end, we propose MetaOpera, a generalized cross-metaverse
interoperability protocol. By connecting to the MetaOpera, users, and objects
in metaverses that rely on centralized servers or decentralized blockchains are
able to interoperate with each other. We also develop a proof-of-concept
implementation for MetaOpera, evaluate its performance, and compare it with a
state-of-the-art cross-metaverse scheme based on Sidechains. Simulation results
demonstrate that the size of cross-metaverse proof and the average time of
cross-metaverse transactions using the proposed solution are respectively about
eight times and three times smaller than the Sidechains scheme. This paper also
suggests a number of open issues and challenges faced by cross-metaverse
interoperability that may inspire future research.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:50:25 GMT""}]","2023-02-06"
"2302.01601","Markus Sch\""obinger","Markus Sch\""obinger and Karl Hollaus","An Equilibrated Error Estimator for the 2D/1D MSFEM T-Formulation of the
  Eddy Current Problem",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  The 2D/1D multiscale finite element method (MSFEM) is an efficient way to
simulate rotating machines in which each iron sheet is exposed to the same
field. It allows the reduction of the three dimensional sheet to a two
dimensional cross-section by resolving the dependence along the thickness of
the sheet with a polynomial expansion. This work presents an equilibrated error
estimator based on flux equilibration and the theorem of Prager and Synge for
the T-formulation of the eddy current problem in a 2D/1D MSFEM setting. The
estimator is shown to give both a good approximation of the total error and to
allow for adaptive mesh refinement by correctly estimating the local error
distribution.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:50:45 GMT""}]","2023-02-06"
"2302.01602","Ashkan Parsi","Ashkan Parsi, David O'Callaghan, Joseph Lemley","A Feature Selection Method for Driver Stress Detection Using Heart Rate
  Variability and Breathing Rate","In Proceedings of the 15th International Conference on Machine Vision
  (ICMV), Romem Italy, 18-20 November 2022. arXiv admin note: text overlap with
  arXiv:2206.03222",,,,"cs.LG cs.CV cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Driver stress is a major cause of car accidents and death worldwide.
Furthermore, persistent stress is a health problem, contributing to
hypertension and other diseases of the cardiovascular system. Stress has a
measurable impact on heart and breathing rates and stress levels can be
inferred from such measurements. Galvanic skin response is a common test to
measure the perspiration caused by both physiological and psychological stress,
as well as extreme emotions. In this paper, galvanic skin response is used to
estimate the ground truth stress levels. A feature selection technique based on
the minimal redundancy-maximal relevance method is then applied to multiple
heart rate variability and breathing rate metrics to identify a novel and
optimal combination for use in detecting stress. The support vector machine
algorithm with a radial basis function kernel was used along with these
features to reliably predict stress. The proposed method has achieved a high
level of accuracy on the target dataset.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:54:55 GMT""}]","2023-02-06"
"2302.01603","Martin Kroll","Timo Schmalofski and Martin Kroll and Holger Dette and Rebecca Janisch","Towards active learning: A stopping criterion for the sequential
  sampling of grain boundary degrees of freedom",,,,,"cond-mat.mtrl-sci stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many materials processes and properties depend on the anisotropy of the
energy of grain boundaries, i.e. on the fact that this energy is a function of
the five geometric degrees of freedom (DOF) of the grain boundaries. To access
this parameter space in an efficient way and discover energy cusps in
unexplored regions, a method was recently established, which combines atomistic
simulations with statistical methods 10.1002/adts.202100615. This sequential
sampling technique is now extended in the spirit of an active learning
algorithm by adding a criterion to decide when the sampling is advanced enough
to stop. To this instance, two parameters to analyse the sampling results on
the fly are introduced: the number of cusps, which correspond to the most
interesting and important regions of the energy landscape, and the maximum
change of energy between two sequential iterations. Monitoring these two
quantities provides valuable insight into how the subspaces are energetically
structured. The combination of both parameters provides the necessary
information to evaluate the sampling of the 2D subspaces of grain boundary
plane inclinations of even non-periodic, low angle grain boundaries. With a
reasonable number of datapoints in the initial design, only a few sequential
iterations already influence the accuracy of the sampling substantially and the
new algorithm outperforms regular high-throughput sampling.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:55:39 GMT""}]","2023-02-06"
"2302.01604","Li Chen","Li Chen","Convex hypersurfaces of prescribed curvatures in hyperbolic space","13 pages. arXiv admin note: substantial text overlap with
  arXiv:2301.01128",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a smooth, closed and uniformly $h$-convex hypersurface $M$ in
$\mathbb{H}^{n+1}$, the horospherical Gauss map $G: M \rightarrow \mathbb{S}^n$
is a diffeomorphism. We consider the problem of finding a smooth, closed and
uniformly $h$-convex hypersurface $M\subset \mathbb{H}^{n+1}$ whose $k$-th
shifted mean curvature $\widetilde{H}_{k}$ ($1\leq k\leq n$) is prescribed as a
positive function $\tilde{f}(x)$ defined on $\mathbb{S}^n$, i.e.
\begin{eqnarray*} \widetilde{H}_{k}(G^{-1}(x))=\tilde{f}(x). \end{eqnarray*} We
can prove the existence of solution to this problem if the given function
$\tilde{f}$ is even. The similar problem has been considered by Guan-Guan for
convex hypersurfaces in Euclidean space two decades ago.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:01:16 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 00:57:43 GMT""}]","2023-02-21"
"2302.01605","Chao Yu","Chao Yu, Jiaxuan Gao, Weilin Liu, Botian Xu, Hao Tang, Jiaqi Yang, Yu
  Wang, Yi Wu","Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased","The first two authors share equal contributions. This paper is
  accepted by ICLR 2023",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  There is a recent trend of applying multi-agent reinforcement learning (MARL)
to train an agent that can cooperate with humans in a zero-shot fashion without
using any human data. The typical workflow is to first repeatedly run self-play
(SP) to build a policy pool and then train the final adaptive policy against
this pool. A crucial limitation of this framework is that every policy in the
pool is optimized w.r.t. the environment reward function, which implicitly
assumes that the testing partners of the adaptive policy will be precisely
optimizing the same reward function as well. However, human objectives are
often substantially biased according to their own preferences, which can differ
greatly from the environment reward. We propose a more general framework,
Hidden-Utility Self-Play (HSP), which explicitly models human biases as hidden
reward functions in the self-play objective. By approximating the reward space
as linear functions, HSP adopts an effective technique to generate an augmented
policy pool with biased policies. We evaluate HSP on the Overcooked benchmark.
Empirical results show that our HSP method produces higher rewards than
baselines when cooperating with learned human models, manually scripted
policies, and real humans. The HSP policy is also rated as the most assistive
policy based on human feedback.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:06:42 GMT""}]","2023-02-06"
"2302.01606","Julia Thampy Thomas","Julia Thampy Thomas, Mahesh Kumar","Design of generalized fuzzy multiple deferred state (GFMDS) sampling
  plan for attributes",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  . A sampling plan is a pilot tool for a supply and demand chain quality check
strategy. These plans proved to be economically viable for the quality
inspection processes but the uncertainty in the plan parameters challenged the
reliability of the application of traditional acceptance sampling plans. This
study proposes a generalized fuzzy multiple deferred state (GFMDS) sampling
plan for attributes that consider the ambiguity in determining the exact value
of the percentage of defectives in a batch. The performance measures have been
derived and the plan is designed in terms of a minimum average sample number. A
comparison study is done over the existing fuzzy acceptance sampling plans for
attributes and a pertinent observation is made regarding the efficiency of the
GFMDS scheme. The effect of inspection errors on the sampling procedure is
analyzed and the drop in the acceptance criteria of the plan is observed
corresponding to the intensified inspection errors. Several numerical examples
are presented to validate the results
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:09:00 GMT""}]","2023-02-06"
"2302.01607","Santtu Tikka","Santtu Tikka and Jouni Helske","dynamite: An R Package for Dynamic Multivariate Panel Models",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  dynamite is an R package for Bayesian inference of intensive panel (time
series) data comprising of multiple measurements per multiple individuals
measured in time. The package supports joint modeling of multiple response
variables, time-varying and time-invariant effects, a wide range of discrete
and continuous distributions, group-specific random effects, latent factors,
and customization of prior distributions of the model parameters. Models in the
package are defined via a user-friendly formula interface, and estimation of
the posterior distribution of the model parameters takes advantage of
state-of-the-art Markov chain Monte Carlo methods. The package enables
efficient computation of both individual-level and summarized predictions and
offers a comprehensive suite of tools for visualization and model diagnostics.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:10:31 GMT""}]","2023-02-06"
"2302.01608","Tianxiang Ma","Tianxiang Ma, Bingchuan Li, Wei Liu, Miao Hua, Jing Dong, Tieniu Tan","CFFT-GAN: Cross-domain Feature Fusion Transformer for Exemplar-based
  Image Translation","Accepted by AAAI2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exemplar-based image translation refers to the task of generating images with
the desired style, while conditioning on certain input image. Most of the
current methods learn the correspondence between two input domains and lack the
mining of information within the domains. In this paper, we propose a more
general learning approach by considering two domain features as a whole and
learning both inter-domain correspondence and intra-domain potential
information interactions. Specifically, we propose a Cross-domain Feature
Fusion Transformer (CFFT) to learn inter- and intra-domain feature fusion.
Based on CFFT, the proposed CFFT-GAN works well on exemplar-based image
translation. Moreover, CFFT-GAN is able to decouple and fuse features from
multiple domains by cascading CFFT modules. We conduct rich quantitative and
qualitative experiments on several image translation tasks, and the results
demonstrate the superiority of our approach compared to state-of-the-art
methods. Ablation studies show the importance of our proposed CFFT. Application
experimental results reflect the potential of our method.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:11:50 GMT""}]","2023-02-06"
"2302.01609","Lothar Sebastian Krapp","Lothar Sebastian Krapp","Embedding the prime model of real exponentiation into o-minimal
  exponential fields","11 pages",,,,"math.LO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Motivated by the decidability question for the theory of real exponentiation
and by the Transfer Conjecture for o-minimal exponential fields, we show that,
under the assumption of Schanuel's Conjecture, the prime model of real
exponentiation is embeddable into any o-minimal exponential field. This is
deduced from a more general unconditional result on the embeddability of
exponential algebraic closures in o-minimal exponential fields.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:15:14 GMT""}]","2023-02-06"
"2302.01610","Marco Salvalaglio","Jean-Benoit Claude, Mohammed Bouabdellaoui, Jerome Wenger, Monica
  Bollani, Marco Salvalaglio, Marco Abbarchi","Germanium-based nearly hyperuniform nanoarchitectures by ion beam impact","7 pages, 4 figures",,,,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the fabrication of nano-architectures by impacting thin layers of
amorphous Ge deposited on SiO$_{2}$ with a Ga$^{+}$ ion beam and investigate
the structural and optical properties of the resulting patterns. By adjusting
beam current and scanning parameters, different classes of nano-architectures
can be formed, from elongated and periodic structures to disordered ones with a
footprint of a few tens of nm. The latter disordered case features a
significant suppression of large length scale fluctuations that are
conventionally observed in ordered systems and exhibits a nearly hyperuniform
character, as shown by the analysis of the spectral density at small wave
vectors. It deviates from conventional random fields as accounted for by the
analysis of Minkowski functionals. A proof of concept for potential
applications is given by showing peculiar reflection properties of the
resulting nano-structured films that exhibit colorization and enhanced light
absorption with respect to the flat Ge layer counterpart (up to one order of
magnitude at some wavelength). This fabrication method for disordered
hyperuniform structures does not depend on the beam size. Being ion beam
technology widely adopted in semiconductor foundries over 200 mm wafers, our
work provides a viable pathway for obtaining disordered, nearly-hyperuniform
materials by self-assembly with a footprint of tens of nanometers for
electronic and photonic devices, energy storage and sensing.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:20:36 GMT""}]","2023-02-06"
"2302.01611","Nafie Tairi","Tim Seynnaeve and Nafie Tairi and Alejandro Vargas","One-quasihomomorphisms from the integers into symmetric matrices","6 pages, 4 figures, comments welcome",,,,"math.CO math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A function $f$ from $\mathbb{Z}$ to the symmetric matrices over an arbitrary
field $K$ of characteristic $0$ is a $1$-quasihomomorphism if the matrix
$f(x+y) - f(x) - f(y)$ has rank at most $1$ for all $x,y \in \mathbb{Z}$. We
show that any such $1$-quasihomomorphism has distance at most $2$ from an
actual group homomorphism. This gives a positive answer to a special case of a
problem posed by Kazhdan and Ziegler.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:21:25 GMT""}]","2023-02-06"
"2302.01612","Naoto Harada","Naoto Harada, Kazuki Tokuda, Hayao Yamasaki, Asako Sato, Mitsuki
  Omura, Shingo Hirano, Toshikazu Onishi, Kengo Tachihara, Masahiro N. Machida","Crescent-Shaped Molecular Outflow from the Intermediate-mass Protostar
  DK Cha Revealed by ALMA","Accepted for publication in ApJ. 12 pages, 5 figures",,"10.3847/1538-4357/acb930",,"astro-ph.GA astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We report on an Atacama Large Millimeter/submillimeter Array (ALMA) study of
the Class I or II intermediate-mass protostar DK Cha in the Chamaeleon II
region. The 12CO (J=2-1) images have an angular resolution of ~1'' (~250 au)
and show high-velocity blueshifted (>70 km s-1) and redshifted (>50 km s-1)
emissions which have 3000 au scale crescent-shaped structures around the
protostellar disk traced in the 1.3mm continuum. Because the high-velocity
components of the CO emission are associated with the protostar, we concluded
that the emission traces the pole-on outflow. The blueshifted outflow lobe has
a clear layered velocity gradient with a higher velocity component located on
the inner side of the crescent shape, which can be explained by a model of an
outflow with a higher velocity in the inner radii. Based on the directly driven
outflow scenario, we estimated the driving radii from the observed outflow
velocities and found that the driving region extends over two orders of
magnitude. The 13CO emission traces a complex envelope structure with arc-like
substructures with lengths of ~1000au. We identified the arc-like structures as
streamers because they appear to be connected to a rotating infalling envelope.
DK Cha is useful for understanding characteristics that are visible by looking
at nearly face-on configurations of young protostellar systems, providing an
alternative perspective for studying the star-formation process.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:23:57 GMT""}]","2023-03-15"
"2302.01613","Sebastien Palcoux Dr.","Max A. Alekseyev, Winfried Bruns, Sebastien Palcoux, Fedor V. Petrov","Classification of modular data of integral modular fusion categories up
  to rank 12","23 pages. Upgraded to rank 12; added partial result for simple rank
  13, and for MNSD up to rank 25. Comments are welcome!",,,,"math.QA math-ph math.CT math.MP math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify all the modular data of integral modular fusion categories up to
rank 12. The types come from the Egyptians fractions with squared denominators,
listed using SageMath. The fusion rings come from solving the dimension and
associativity equations, using Normaliz. The S-matrices come from making the
character table self-transpose. The T-matrices come from solving the
Anderson-Moore-Vafa equations. Finally, we keep what satisfies the definition
of a modular data. We get that every perfect integral modular fusion category
up to rank 12 is trivial. We also prove that every simple integral modular
fusion category of rank 13 is pointed, up to 12 types (in progress). Finally,
we prove that every odd-dimensional perfect modular fusion category up to rank
25 is trivial, up to 21 types (of rank 25).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:24:46 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 11:01:01 GMT""},{""version"":""v3"",""created"":""Thu, 25 May 2023 03:09:20 GMT""}]","2023-05-26"
"2302.01614","Pol van Rijn","Pol van Rijn, Yue Sun, Harin Lee, Raja Marjieh, Ilia Sucholutsky,
  Francesca Lanzarini, Elisabeth Andr\'e, Nori Jacoby","Around the world in 60 words: A generative vocabulary test for online
  research",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conducting experiments with diverse participants in their native languages
can uncover insights into culture, cognition, and language that may not be
revealed otherwise. However, conducting these experiments online makes it
difficult to validate self-reported language proficiency. Furthermore, existing
proficiency tests are small and cover only a few languages. We present an
automated pipeline to generate vocabulary tests using text from Wikipedia. Our
pipeline samples rare nouns and creates pseudowords with the same low-level
statistics. Six behavioral experiments (N=236) in six countries and eight
languages show that (a) our test can distinguish between native speakers of
closely related languages, (b) the test is reliable ($r=0.82$), and (c)
performance strongly correlates with existing tests (LexTale) and self-reports.
We further show that test accuracy is negatively correlated with the linguistic
distance between the tested and the native language. Our test, available in
eight languages, can easily be extended to other languages.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:27:12 GMT""}]","2023-02-06"
"2302.01615","Francesco Grandi","Francesco Grandi, Armando Consiglio, Michael A. Sentef, Ronny Thomale,
  Dante M. Kennes","Theory of nematic charge orders in kagome metals","16 pages, 4 figures + supplemental material (2 pages)","Physical Review B 107, 155131 (2023)","10.1103/PhysRevB.107.155131",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Kagome metals $A$V$_3$Sb$_5$ ($A=$K, Rb, Cs) exhibit an exotic charge order
(CO), involving three order parameters, with broken translation and
time-reversal symmetries compatible with the presence of orbital currents. The
properties of this phase are still intensely debated, and it is unclear if the
origin of the CO is mainly due to electron-electron or electron-phonon
interactions. Most of the experimental studies confirm the nematicity of this
state, a feature that might be enhanced by electronic correlations. However, it
is still unclear whether the nematic CO becomes stable at a temperature equal
to ($T_{\text{nem}} = T_\text{C}$) or lower than ($T_{\text{nem}} <
T_\text{C}$) the one of the CO itself. Here, we systematically characterize
several CO configurations, some proposed for the new member of the family
ScV$_6$Sn$_6$, by combining phenomenological Ginzburg-Landau theories, valid
irrespective of the specific ordering mechanism, with mean-field analysis. We
find a few configurations for the CO that are in agreement with most of the
experimental findings to date and that are described by different
Ginzburg-Landau potentials. We propose to use resonant ultrasound spectroscopy
to experimentally characterize the order parameters of the CO, such as the
number of their components and their relative amplitude, and provide an
analysis of the corresponding elastic tensors. This might help understand which
mean-field configuration found in our study is the most representative for
describing the CO state of kagome metals, and it can provide information
regarding the nematicity onset temperature $T_\text{nem}$ with respect to
$T_\text{C}$.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:28:11 GMT""},{""version"":""v2"",""created"":""Tue, 18 Apr 2023 14:56:36 GMT""}]","2023-04-19"
"2302.01616","Pierrick Chatillon","Pierrick Chatillon, Yann Gousseau, Sidonie Lefebvre","A geometrically aware auto-encoder for multi-texture synthesis",,,,,"cs.CV cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an auto-encoder architecture for multi-texture synthesis. The
approach relies on both a compact encoder accounting for second order neural
statistics and a generator incorporating adaptive periodic content. Images are
embedded in a compact and geometrically consistent latent space, where the
texture representation and its spatial organisation are disentangled. Texture
synthesis and interpolation tasks can be performed directly from these latent
codes. Our experiments demonstrate that our model outperforms state-of-the-art
feed-forward methods in terms of visual quality and various texture related
metrics.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:28:39 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 14:26:11 GMT""}]","2023-03-09"
"2302.01617","Marc Ditzhaus","Takeshi Emura, Marc Ditzhaus, Dennis Dobler, Kenta Murotani","Factorial survival analysis for treatment effects under dependent
  censoring",,,,,"stat.ME math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Factorial analyses offer a powerful nonparametric means to detect main or
interaction effects among multiple treatments. For survival outcomes, e.g. from
clinical trials, such techniques can be adopted for comparing reasonable
quantifications of treatment effects. The key difficulty to solve in survival
analysis concerns the proper handling of censoring. So far, all existing
factorial analyses for survival data were developed under the independent
censoring assumption, which is too strong for many applications. As a solution,
the central aim of this article is to develop new methods in factorial survival
analyses under quite general dependent censoring regimes. This will be
accomplished by combining existing results for factorial survival analyses with
techniques developed for survival copula models. As a result, we will present
an appealing F-test that exhibits sound performance in our simulation study.
The new methods are illustrated in real data analysis. We implement the
proposed method in an R function surv.factorial(.) in the R package
compound.Cox.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:28:58 GMT""}]","2023-02-06"
"2302.01618","bajkova","V. V. Bobylev, A. T. Bajkova","3-D kinematics of classical Cepheids according to Gaia, EDR3 catalog","20 pages, 4 figures, 3 tables. Accepted to be published in Research
  in Astronomy and Astrophysics",,"10.1088/1674-4527/acb878",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The kinematics of about 2000 classical Cepheids of the Milky Way with data
from Gaia\,EDR3 catalog has been studied. For some of these stars, there are
line-of-sight velocities. On the basis of the nonlinear rotation model, the
parameters of the rotation curve of the Galaxy were determined. The circular
linear rotation velocity of the near-solar neighborhood around the Galaxy
center was $V_0=236\pm 3$~km s$^{-1}$ for the assumed Sun's galactocentric
distance $R_0=8.1\pm0.1$~kpc. Analysis of residual velocities of Cepheids based
on the linear Ogorodnikov-Milne model showed the presence of the following
significantly different from zero gradients: $\partial U/\partial x,$ $\partial
U/\partial z,$ $\partial V/\partial x,$ $\partial V/\partial z$ and $\partial
W/\partial x,$ which behaves differently depending on the selection radius. The
most interesting is the gradient $\partial W/\partial x\sim-0.5\pm0.1$~km
s$^{-1}$ kpc$^{-1}$ (positive rotation of this star system around the galactic
axis $y$, $\Omega_y$) since the velocities $W$ are free of galactic rotation.
Here we have an indirect influence of various effects leading to a perturbation
of the vertical velocities of the galactic disk stars. Based on a simpler
model, a more accurate estimate of this rotation is obtained,
$\Omega_y=0.51\pm0.07$~km s$^{-1}$ kpc$^{-1}$.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:35:15 GMT""}]","2023-04-05"
"2302.01619","Wenkang Xu","Wenkang Xu, Yongbo Xiao, An Liu, Minjian Zhao","Joint Scattering Environment Sensing and Channel Estimation for
  Integrated Sensing and Communication",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers an integrated sensing and communication system, where
some radar targets also serve as communication scatterers. A location domain
channel modeling method is proposed based on the position of targets and
scatterers in the scattering environment, and the resulting radar and
communication channels exhibit a partially common sparsity. By exploiting this,
we propose a joint scattering environment sensing and channel estimation scheme
to enhance the target/scatterer localization and channel estimation performance
simultaneously. Specifically, the base station (BS) first transmits downlink
pilots to sense the targets in the scattering environment. Then the user
transmits uplink pilots to estimate the communication channel. Finally, joint
scattering environment sensing and channel estimation are performed at the BS
based on the reflected downlink pilot signal and received uplink pilot signal.
A message passing based algorithm is designed by combining the turbo approach
and the expectation maximization method. The advantages of our proposed scheme
are verified in the simulations.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:42:14 GMT""}]","2023-02-06"
"2302.01620","Seblu Humne Negu","Berikol Tekeste Gebreyesus, Seblu Humne Negu","Physical parameters of W UMa type contact binaries and its stability of
  mass transfer","Accepted for publication in Research in Astronomy and Astrophysics.
  19 pages, 19 figures",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we determined the physical parameters of W UMa type contact
binaries and its stability of mass transfer with different stellar mass ranges
over a broad space by applying the basic dynamical evolution equations of the W
UMa type contact binaries using accretor and donor masses between 0.079 and
2.79 $M_{\odot}$. In these systems, we have studied the three sub-classes of
the W UMa system such as A-, B- and W-type of W UMa contact binaries using the
initial and final mass ranges and we investigated different stellar and orbital
parameters for the sub-classes of W UMa systems. We examined the stability of
the W UMa type contact binaries using the orbital parameters such as critical
mass ratio, Roche lobe radius of the donor star, and mass ratio of these
systems. Thus, we computed the observed and calculated physical parameters of
A-, B- and W-type of W UMa systems. Although, we determined the combined and
color temperatures to classify the three subclasses of the systems. Also, we
have presented the result of the internal stellar structure and evolution of W
UMa type contact binaries by using the polytropic model.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:46:03 GMT""}]","2023-02-06"
"2302.01621","Dimitris Korobilis Prof","Luca Gambetti, Dimitris Korobilis, John Tsoukalas, Francesco Zanetti","Agreed and Disagreed Uncertainty",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  When agents' information is imperfect and dispersed, existing measures of
macroeconomic uncertainty based on the forecast error variance have two
distinct drivers: the variance of the economic shock and the variance of the
information dispersion. The former driver increases uncertainty and reduces
agents' disagreement (agreed uncertainty). The latter increases both
uncertainty and disagreement (disagreed uncertainty). We use these implications
to identify empirically the effects of agreed and disagreed uncertainty shocks,
based on a novel measure of consumer disagreement derived from survey
expectations. Disagreed uncertainty has no discernible economic effects and is
benign for economic activity, but agreed uncertainty exerts significant
depressing effects on a broad spectrum of macroeconomic indicators.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:47:41 GMT""}]","2023-02-06"
"2302.01622","Soroosh Tayebi Arasteh","Soroosh Tayebi Arasteh, Alexander Ziller, Christiane Kuhl, Marcus
  Makowski, Sven Nebelung, Rickmer Braren, Daniel Rueckert, Daniel Truhn,
  Georgios Kaissis","Private, fair and accurate: Training large-scale, privacy-preserving AI
  models in medical imaging","3 tables, 5 figures, 11 supplementary materials",,,,"eess.IV cs.AI cs.CR cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Artificial intelligence (AI) models are increasingly used in the medical
domain. However, as medical data is highly sensitive, special precautions to
ensure its protection are required. The gold standard for privacy preservation
is the introduction of differential privacy (DP) to model training. Prior work
indicates that DP has negative implications on model accuracy and fairness,
which are unacceptable in medicine and represent a main barrier to the
widespread use of privacy-preserving techniques. In this work, we evaluated the
effect of privacy-preserving training of AI models for chest radiograph
diagnosis regarding accuracy and fairness compared to non-private training. For
this, we used a large dataset (N=193,311) of high quality clinical chest
radiographs, which were retrospectively collected and manually labeled by
experienced radiologists. We then compared non-private deep convolutional
neural networks (CNNs) and privacy-preserving (DP) models with respect to
privacy-utility trade-offs measured as area under the
receiver-operator-characteristic curve (AUROC), and privacy-fairness
trade-offs, measured as Pearson's r or Statistical Parity Difference. We found
that the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over
all labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted
in an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to
non-private training. Furthermore, we found the privacy-preserving training not
to amplify discrimination against age, sex or co-morbidity. Our study shows
that -- under the challenging realistic circumstances of a real-life clinical
dataset -- the privacy-preserving training of diagnostic deep learning models
is possible with excellent diagnostic accuracy and fairness.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:49:13 GMT""},{""version"":""v2"",""created"":""Tue, 7 Mar 2023 10:00:43 GMT""}]","2023-03-08"
"2302.01623","Chao-Shang Huang","Chao-Shang Huang","Majorana CP violating phases","4 pages, 3 tables",,,,"hep-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In the frame of the magic Majorana neutrino mass matrix, we have obtained the
Majorana CP-violating phases only using the nowadays knowledge from experiments
and observations. By using gotten the Majorana CP-violating phases, we have
also computed the effective Majorana neutrino mass mee which is agreed with the
upper limit, 0.061-0.165, obtained in the neutrinoless double beta decay
($0\nu\beta\beta$) experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:50:36 GMT""}]","2023-02-06"
"2302.01624","Fran\c{c}ois Couchot","Fran\c{c}ois Couchot, Arache Djannati-Ata\""i, Scott Robertson, Xavier
  Sarazin and Marcel Urban","Gravitational effects of free-falling quantum vacuum","15 pages, 13 figures",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model that builds ``dark matter""-like halo density profiles from
free-falling zero-point vacuum fluctuations. It does not require a modification
of Newton's laws, nor the existence of as-yet-undiscovered dark matter
particles. The 3D halos predicted by our model are fully constrained by the
baryonic mass distribution, and are generally far from spherical. The model
introduces a new fundamental constant of vacuum, T, having the dimensions of
time. We deduce the associated formalism from some basic assumptions, and
adjust the model successfully on several spiral galaxy rotation data while
comparing our results to the existing analyses. We believe our approach opens
up a new paradigm that is worth further exploration, and that would benefit
from checks relating to other phenomena attributed to dark matter at all time
and distance scales. Following such a program would allow the present model to
evolve, and if successful it would make vacuum fluctuations responsible for the
typical manifestations of dark matter.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:51:38 GMT""}]","2023-02-06"
"2302.01625","Sebastian M\""uller","Sebastian M\""uller, Isabel Amigo, Alexandre Reiffers-Masson, Santiago
  Ruano-Rinc\'on","Stability of local tip pool sizes","6 figures",,,,"math.PR cs.DC","http://creativecommons.org/licenses/by/4.0/","  In distributed ledger technologies (DLTs) with a directed acyclic graph (DAG)
data structure, a block-issuing node can decide where to append new blocks and,
consequently, how the DAG grows. This DAG data structure is typically
decomposed into two pools of blocks, dependent on whether another block already
references them. The unreferenced blocks are called the tips. Due to network
delay, nodes can perceive the set of tips differently, giving rise to local tip
pools.
  We present a new mathematical model to analyse the stability of the different
local perceptions of the tip pools and allow heterogeneous and random network
delay in the underlying peer-to-peer communication layer. Under natural
assumptions, we prove that the number of tips is ergodic, converges to a
stationary distribution, and provide quantitative bounds on the tip pool sizes.
We conclude our study with agent-based simulations to illustrate the
convergence of the tip pool sizes and the pool sizes' dependence on the
communication delay and degree of centralization.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:52:58 GMT""}]","2023-02-06"
"2302.01626","Shunyu Zhang","Shunyu Zhang, Yaobo Liang, Ming Gong, Daxin Jiang, Nan Duan","Modeling Sequential Sentence Relation to Improve Cross-lingual Dense
  Retrieval","Published at ICLR 2023",,,,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently multi-lingual pre-trained language models (PLM) such as mBERT and
XLM-R have achieved impressive strides in cross-lingual dense retrieval.
Despite its successes, they are general-purpose PLM while the multilingual PLM
tailored for cross-lingual retrieval is still unexplored. Motivated by an
observation that the sentences in parallel documents are approximately in the
same order, which is universal across languages, we propose to model this
sequential sentence relation to facilitate cross-lingual representation
learning. Specifically, we propose a multilingual PLM called masked sentence
model (MSM), which consists of a sentence encoder to generate the sentence
representations, and a document encoder applied to a sequence of sentence
vectors from a document. The document encoder is shared for all languages to
model the universal sequential sentence relation across languages. To train the
model, we propose a masked sentence prediction task, which masks and predicts
the sentence vector via a hierarchical contrastive loss with sampled negatives.
Comprehensive experiments on four cross-lingual retrieval tasks show MSM
significantly outperforms existing advanced pre-training models, demonstrating
the effectiveness and stronger cross-lingual retrieval capabilities of our
approach. Code and model will be available.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:54:27 GMT""}]","2023-02-06"
"2302.01627","Tetsuya Nomoto","Tetsuya Nomoto, Chengchao Zhong, Hiroshi Kageyama, Yoko Suzuki,
  Marcelo Jaime, Yoshiaki Hashimoto, Shingo Katsumoto, Naofumi Matsuyama, Chao
  Dong, Akira Matsuo, Koichi Kindo, Koichi Izawa, and Yoshimitsu Kohama","Simultaneous measurement of specific heat and thermal conductivity in
  pulsed magnetic fields","9 pages, 7 figures",,"10.1063/5.0143875",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report an experimental setup for simultaneously measuring specific heat
and thermal conductivity in feedback-controlled pulsed magnetic fields of 50
msec duration at cryogenic temperatures. A stabilized magnetic field pulse
obtained by the feedback control, which dramatically improves the thermal
stability of the setup and sample, is used in combination with the flash method
to obtain absolute values of thermal properties up to 37.2 T in the 2 K to 16 K
temperature range. We describe the experimental setup and demonstrate the
performance of the present method with measurements on single crystal samples
of the geometrically frustrated quantum spin-dimer system SrCu$_2$(BO$_3$)$_2$.
Our proof-of-principle results show excellent agreement with data taken using a
standard steady-state method, confirming the validity and convenience of the
present approach.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:55:13 GMT""}]","2023-05-17"
"2302.01628","Alexander Von M\""uller","Karl Lackner, Sina Fietz, Alexander v. M\""uller","Comments to ""High current ionic flows via ultra-fast lasers for fusion
  applications"" by H. Ruhl and G. Korn (Marvel Fusion, Munich)","5 pages, no figures",,,,"physics.plasm-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We comment on Marvel Fusion's proposal to use ultra-short, intensive laser
pulses impinging on nanostructured targets for the production of hot ions, with
the ultimate aim of energy production through the p-11B fusion reaction. We
show how a minimum requirement on the line density of the heated region arises
also for such schemes aiming at ignition or just beam-energy amplification,
which already for the D-T reaction are prohibitive if no pre-compression of the
target is foreseen. We conclude that advanced ultra-short laser pulses can be
of use for fusion applications only if the fusion reaction time can be brought
down to sufficiently short values. This can happen only via strong
pre-compression of the target, which appears difficult to reconcile with a
nanostructured target and in particular with the fuel assembly geometries shown
by the proponents.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:57:51 GMT""}]","2023-02-06"
"2302.01629","Simone Bombari","Simone Bombari, Shayan Kiyani, Marco Mondelli","Beyond the Universal Law of Robustness: Sharper Laws for Random Features
  and Neural Tangent Kernels","Second arxiv version, updated to the icml23 version of the paper",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by/4.0/","  Machine learning models are vulnerable to adversarial perturbations, and a
thought-provoking paper by Bubeck and Sellke has analyzed this phenomenon
through the lens of over-parameterization: interpolating smoothly the data
requires significantly more parameters than simply memorizing it. However, this
""universal"" law provides only a necessary condition for robustness, and it is
unable to discriminate between models. In this paper, we address these gaps by
focusing on empirical risk minimization in two prototypical settings, namely,
random features and the neural tangent kernel (NTK). We prove that, for random
features, the model is not robust for any degree of over-parameterization, even
when the necessary condition coming from the universal law of robustness is
satisfied. In contrast, for even activations, the NTK model meets the universal
lower bound, and it is robust as soon as the necessary condition on
over-parameterization is fulfilled. This also addresses a conjecture in prior
work by Bubeck, Li and Nagaraj. Our analysis decouples the effect of the kernel
of the model from an ""interaction matrix"", which describes the interaction with
the test data and captures the effect of the activation. Our theoretical
results are corroborated by numerical evidence on both synthetic and standard
datasets (MNIST, CIFAR-10).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:58:31 GMT""},{""version"":""v2"",""created"":""Sat, 27 May 2023 07:24:49 GMT""}]","2023-05-30"
"2302.01630","Federico Milano","Taulant Kerci, Manuel Hurtado, Mariglen Gjergji, Simon Tweed, Eoin
  Kennedy, Federico Milano","Frequency Quality in Low-Inertia Power Systems",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper analyses the issue of frequency quality in low-inertia power
systems. The analysis is based on a real-world large-scale low-inertia power
system namely, the All-Island transmission system (AITS) of Ireland and
Northern Ireland currently accommodating up to 75% of non-synchronous
generation. The paper is motivated by a recent trend of some frequency quality
parameters such as the standard frequency deviation and the slow frequency
restoration. The paper first discusses the frequency control services currently
in place to ensure frequency quality in the AITS. An analysis of the frequency
quality parameters of the AITS is then presented based on actual data. The
paper also discusses, through an illustrative example, the effectiveness of
automatic generation control as a potential approach to keep frequency within
the operational range.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:59:25 GMT""}]","2023-02-06"
"2302.01631","Peter W. Michor","Martin Bauer, Philipp Harms, Peter W. Michor","Regularity and completeness of half-Lie groups","41 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Half Lie groups exist only in infinite dimensions: They are smooth manifolds
and topological groups such that right translations are smooth, but left
translations are merely required to be continuous. The main examples are groups
of $H^s$ or $C^k$ diffeomorphisms and semidirect products of a Lie group with
kernel an infinite dimensional representation space. Here, we investigate
mainly Banach half-Lie groups, the groups of their $C^k$-elements, extensions,
and right invariant strong Riemannian metrics on them: surprisingly the full
Hopf--Rinow theorem holds, which is wrong in general even for Hilbert
manifolds.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:02:04 GMT""}]","2023-02-06"
"2302.01632","Marks Ruziboev","Marks Ruziboev, Khudoyor Mamayusupov, Gafurjan Ibragimov, Adkham
  Khaitmetov","On a linear differential game in the Hilbert space $\ell^2$",,,,,"math.OC math.FA","http://creativecommons.org/licenses/by/4.0/","  Two-player pursuit-evasion differential game and time optimal zero control
problem in $\ell^2$ are considered. Optimal control for the corresponding zero
control problem is found. A strategy for the pursuer that guarantees the
solution for the pursuit problem is constructed.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:04:19 GMT""}]","2023-02-06"
"2302.01633","Yipeng Li","Yipeng Li and Xinchen Lyu","Convergence Analysis of Sequencial Split Learning on Heterogeneous Data",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Federated Learning (FL) and Split Learning (SL) are two popular paradigms of
distributed machine learning. By offloading the computation-intensive portions
to the server, SL is promising for deep model training on resource-constrained
devices, yet still lacking of rigorous convergence analysis. In this paper, we
derive the convergence guarantees of Sequential SL (SSL, the vanilla case of SL
that conducts the model training in sequence) for strongly/general/non-convex
objectives on heterogeneous data. Notably, the derived guarantees suggest that
SSL is better than Federated Averaging (FedAvg, the most popular algorithm in
FL) on heterogeneous data. We validate the counterintuitive analysis result
empirically on extremely heterogeneous data.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:04:44 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 13:54:02 GMT""}]","2023-06-08"
"2302.01634","Samuel Tomlinson","Samuel D. Tomlinson, Fran\c{c}ois Peaudecerf, Fernando
  Temprano-Coleto, Frederic Gibou, Paolo Luzzatto-Fegiz, Oliver E. Jensen,
  Julien R. Landel","A model for slip and drag in turbulent flows over superhydrophobic
  surfaces with surfactant",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Superhydrophobic surfaces (SHSs) can reduce the friction drag in turbulent
flows. In the laminar regime, it has been shown that trace amounts of
surfactant can negate this drag reduction, at times rendering these surfaces no
better than solid walls (Peaudecerf et al., Proc. Natl. Acad. Sci. USA 114(28),
7254-9, 2017). However, surfactant effects on the drag-reducing properties of
SHSs have not yet been studied under turbulent flow conditions, where
predicting the effects of surfactant in direct numerical simulations remains
expensive by today's standards. We present a model for turbulent flow inclusive
of surfactant, in either a channel or boundary-layer configuration, over long
but finite-length streamwise ridges that are periodic in the spanwise
direction, with period $P$ and gas fraction $\varphi$. We adopt a technique
based on a shifted log law to acquire an expression for the drag reduction. The
average streamwise and spanwise slip lengths are derived by introducing a local
laminar model within the viscous sublayer, whereby the effect of surfactant is
modelled by modifying the average streamwise and spanwise slip lengths. Our
model agrees with available laboratory experimental data from the literature
when conditions are clean (surfactant-free), or when there are low surfactant
levels. However, we find an appreciable drag increase for larger background
surfactant concentrations that are characteristic of turbulent flows over SHSs
for marine applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:05:15 GMT""}]","2023-02-06"
"2302.01635","Ariane Ernst","Ariane Ernst, Nathalie Unger, Christof Sch\""utte, Alexander Walter,
  Stefanie Winkelmann","Rate-limiting recovery processes in neurotransmission under sustained
  stimulation","30 pages, 12 Figures",,,,"math.DS","http://creativecommons.org/licenses/by-nc-sa/4.0/","  At chemical synapses, an arriving electric signal induces the fusion of
vesicles with the presynaptic membrane, thereby releasing neurotransmitters
into the synaptic cleft. After a fusion event, both the release site and the
vesicle undergo a recovery process before becoming available for reuse again.
Of central interest is the question which of the two restoration steps acts as
the limiting factor during neurotransmission under high-frequency sustained
stimulation. In order to investigate this question, we introduce a novel
non-linear reaction network which involves explicit recovery steps for both the
vesicles and the release sites, and includes the induced time-dependent output
current. The associated reaction dynamics are formulated by means of ordinary
differential equations (ODEs), as well as via the associated stochastic jump
process. While the stochastic jump model describes a single release site, the
average over many release sites is close to the ODE solution and shares its
periodic structure. The reason for this can be traced back to the insight that
recovery dynamics of vesicles and release sites are statistically almost
independent. A sensitivity analysis on the recovery rates based on the ODE
formulation reveals that neither the vesicle nor the release site recovery step
can be identified as the essential rate-limiting step but that the
rate-limiting feature changes over the course of stimulation. Under sustained
stimulation the dynamics given by the ODEs exhibit transient changes leading
from an initial depression of the postsynaptic response to an asymptotic
periodic orbit, while the individual trajectories of the stochastic jump model
lack the oscillatory behavior and asymptotic periodicity of the ODE-solution.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:05:52 GMT""}]","2023-02-06"
"2302.01636","Nadezhda Semenova Dr.","Tatyana Bogatenko, Konstantin Sergeev, Andrei Slepnev, J\""urgen
  Kurths, Nadezhda Semenova","Symbiosis of an artificial neural network and models of biological
  neurons: training and testing","6 pages, 7 figures, 2 tables",,,,"cs.NE nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show the possibility of creating and identifying the
features of an artificial neural network (ANN) which consists of mathematical
models of biological neurons. The FitzHugh--Nagumo (FHN) system is used as an
example of model demonstrating simplified neuron activity. First, in order to
reveal how biological neurons can be embedded within an ANN, we train the ANN
with nonlinear neurons to solve a a basic image recognition problem with MNIST
database; and next, we describe how FHN systems can be introduced into this
trained ANN. After all, we show that an ANN with FHN systems inside can be
successfully trained and its accuracy becomes larger. What has been done above
opens up great opportunities in terms of the direction of analog neural
networks, in which artificial neurons can be replaced by biological ones.
\end{abstract}
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:06:54 GMT""}]","2023-02-06"
"2302.01637","Hossein Teimoori Faal","Hossein Teimoori Faal and Hasan Khodakarami","Khayyam-Pascal Determinantal Arrays, Star of David Rule and
  Log-Concavity","11 pages",,,,"math.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this paper we develop a new geometric method to answer the log-concavity
questions related to a nice class of combinatorial sequences arising from the
Pascal triangle.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:13:21 GMT""}]","2023-02-06"
"2302.01638","Shashanka Kulamarva","Manu Basavaraju, Suresh Manjanath Hegde and Shashanka Kulamarva","Acyclic Chromatic Index of Chordless Graphs",,,"10.1016/j.disc.2023.113434",,"math.CO cs.DM","http://creativecommons.org/licenses/by/4.0/","  An acyclic edge coloring of a graph is a proper edge coloring in which there
are no bichromatic cycles. The acyclic chromatic index of a graph $G$ denoted
by $a'(G)$, is the minimum positive integer $k$ such that $G$ has an acyclic
edge coloring with $k$ colors. It has been conjectured by Fiam\v{c}\'{\i}k that
$a'(G) \le \Delta+2$ for any graph $G$ with maximum degree $\Delta$. Linear
arboricity of a graph $G$, denoted by $la(G)$, is the minimum number of linear
forests into which the edges of $G$ can be partitioned. A graph is said to be
chordless if no cycle in the graph contains a chord. Every $2$-connected
chordless graph is a minimally $2$-connected graph. It was shown by Basavaraju
and Chandran that if $G$ is $2$-degenerate, then $a'(G) \le \Delta+1$. Since
chordless graphs are also $2$-degenerate, we have $a'(G) \le \Delta+1$ for any
chordless graph $G$. Machado, de Figueiredo and Trotignon proved that the
chromatic index of a chordless graph is $\Delta$ when $\Delta \ge 3$. They also
obtained a polynomial time algorithm to color a chordless graph optimally. We
improve this result by proving that the acyclic chromatic index of a chordless
graph is $\Delta$, except when $\Delta=2$ and the graph has a cycle, in which
case it is $\Delta+1$. We also provide the sketch of a polynomial time
algorithm for an optimal acyclic edge coloring of a chordless graph. As a
byproduct, we also prove that $la(G) = \lceil \frac{\Delta }{2} \rceil$, unless
$G$ has a cycle with $\Delta=2$, in which case $la(G) = \lceil
\frac{\Delta+1}{2} \rceil = 2$. To obtain the result on acyclic chromatic
index, we prove a structural result on chordless graphs which is a refinement
of the structure given by Machado, de Figueiredo and Trotignon for this class
of graphs. This might be of independent interest.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:14:53 GMT""}]","2023-04-27"
"2302.01639","Bruno Ebner","Dennis Dobler and Bruno Ebner","Is the Gompertz family a good fit to your data?","18 pages, 3 figures, 6 tables",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  That data follow a Gompertz distribution is a widely used assumption in
diverse fields of applied sciences, e.g., in biology or when analysing survival
times. Since misspecified models may lead to false conclusions, assessing the
fit of the data to an underlying model is of central importance. We propose a
new family of characterisation-based weighted $L^2$-type tests of fit to the
family of Gompertz distributions, hence tests for the composite hypothesis when
the parameters are unknown. The characterisation is motivated by distributional
transforms connected to Stein's method of distributional approximation. We
provide the limit null distribution of the test statistics in a Hilbert space
setting and, since the limit distribution depends on the unknown parameters, we
propose a parametric bootstrap procedure. Consistency of the testing procedure
is shown. An extensive simulation study as well as applications to real data
examples show practical benefits of the procedures: the first data set we
analyse consists of lifetimes of fruitflies, the second has been synthetically
generated from life tables for women born in Germany in 1948.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:16:30 GMT""}]","2023-02-06"
"2302.01640","Himanshu Shukla","Himanshu Shukla, Michael Stoll","The Cassels-Tate pairing on 2-Selmer groups of elliptic curves","20 pages",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We explicitly compute the Cassels-Tate pairing on the 2-Selmer group of an
elliptic curve using the Albanese-Albanese definition of the pairing given by
Poonen and Stoll. This leads to a new proof that a pairing defined by Cassels
on the 2-Selmer groups of elliptic curves agrees with the Cassels-Tate pairing.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:30:14 GMT""}]","2023-02-06"
"2302.01641","Mohamed Ouchemhou","B. Ait Ouazghour, R. Benbrik, E. Ghourmin, M. Ouchemhou, and L. Rahili","Consistency of New CDF-II W Boson Mass with 123-Model","16 pages, 3 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the recent update measurement of the W boson mass performed by the
CDF-II experiment at Fermilab which indicates $7\sigma$ deviation from the SM
prediction. As a consequence, the open question is whether there are extensions
of the SM that can carry such a remarkable deviation or what phenomenological
repercussions this has. In this paper, we investigate what the theoretical
constraints reveal about the \ott model. Also, we study the consistency of a
CDF W boson mass measurement with the 123-model expectations, taking into
account theoretical and experimental constraints. Both fit results of $S$ and
$T$ parameters before and after $m_{W}^{\rm{CDF}}$ measurement are, moreover,
considered in this study. Under these conditions, we found that the 123-model
prediction is consistent with the measured $m_{W}^{\rm{CDF}}$ at a $95\%$
Confidence Level (CL).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:31:01 GMT""}]","2023-02-06"
"2302.01642","Ljubisa Stankovic","Zhenpeng Feng, Hongbing Ji, Milos Dakovic, Xiyang Cui, Mingzhe Zhu,
  Ljubisa Stankovic","Cluster-CAM: Cluster-Weighted Visual Interpretation of CNNs' Decision in
  Image Classification","10 pages",,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by/4.0/","  Despite the tremendous success of convolutional neural networks (CNNs) in
computer vision, the mechanism of CNNs still lacks clear interpretation.
Currently, class activation mapping (CAM), a famous visualization technique to
interpret CNN's decision, has drawn increasing attention. Gradient-based CAMs
are efficient while the performance is heavily affected by gradient vanishing
and exploding. In contrast, gradient-free CAMs can avoid computing gradients to
produce more understandable results. However, existing gradient-free CAMs are
quite time-consuming because hundreds of forward interference per image are
required. In this paper, we proposed Cluster-CAM, an effective and efficient
gradient-free CNN interpretation algorithm. Cluster-CAM can significantly
reduce the times of forward propagation by splitting the feature maps into
clusters in an unsupervised manner. Furthermore, we propose an artful strategy
to forge a cognition-base map and cognition-scissors from clustered feature
maps. The final salience heatmap will be computed by merging the above
cognition maps. Qualitative results conspicuously show that Cluster-CAM can
produce heatmaps where the highlighted regions match the human's cognition more
precisely than existing CAMs. The quantitative evaluation further demonstrates
the superiority of Cluster-CAM in both effectiveness and efficiency.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:38:20 GMT""}]","2023-02-06"
"2302.01643","Arvind Rajpurohit Dr","Vipin Kumar, A. S. Rajpurohit, Mudit K. Srivastava","Exploring the short-term variability of H{\alpha} and H\b{eta} emissions
  in a sample of M Dwarfs","5 pages, 5 figures, submitted to the proceedings of The 21th
  Cambridge Workshop on Cool Stars, Stellar Systems, and the Sun",,,,"astro-ph.SR astro-ph.EP","http://creativecommons.org/publicdomain/zero/1.0/","  Activities in M dwarfs show spectroscopic variability over various time
scales ranging from a few seconds to several hours. The time scales of such
variability can be related to internal dynamics of M dwarfs like magnetic
activity, energetic flaring events, their rotation periods, etc. The time
variability in the strengths of prominent emission lines (particularly
H{\alpha} ) is mostly taken as a proxy of such dynamic behavior. In this study,
we have performed the spectroscopic monitoring of 83 M dwarfs (M0-M6.5) to
study the variations in H{\alpha} and H\b{eta} emissions on short-time scales.
Low-resolution (resolution around 5.7 angstroms) spectral time series of 3-5
minutes cadence over 0.7-2.3 hours were obtained with MFOSC-P instrument on PRL
1.2m Mt. Abu telescope, covering H\b{eta} and H{\alpha} wavelengths. Coupled
with the data available in the literature and archival photometric data from
TESS and Kepler/K2 archives, various variability parameters are explored for
any plausible systematics with respect to their spectral types, and rotation
periods. Though about 64% of our sample shows statistically significant
variability, it is not uniform across the spectral type and rotation period.
H{\alpha} activity strength (LH{\alpha}/Lbol) is also derived and explored for
such distributions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:38:24 GMT""}]","2023-02-06"
"2302.01644","Nikolaj Glazunov","Nikolaj Glazunov","On packing of Minkowski balls. II","9 pages. Direct limits of direct systems of Minkowski balls and
  domains and their critical lattices are calculated., typos corrected",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  This is the continuation of the author's ArXiv presentation ""On packing of
Minkowski balls. I"". In section 2 we investigate lattice packings of Minkowski
balls and domains. By results of the proof of Minkowski conjecture about the
critical determinant we devide the balls and domains on 3 classes: Minkowski,
Davis and Chebyshev-Cohn. The optimal lattice packings of the balls and domains
are obtained. The minimum areas of hexagons inscribed in the balls and domains
and circumscribed around their are given. Direct limits of direct systems of
Minkowski balls and domains and their critical lattices are calculated.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:39:04 GMT""},{""version"":""v2"",""created"":""Thu, 2 Mar 2023 19:47:36 GMT""},{""version"":""v3"",""created"":""Sat, 25 Mar 2023 09:04:03 GMT""}]","2023-03-28"
"2302.01645","Alessandro Ratti","Javier Mazzitelli, Alessandro Ratti, Marius Wiesemann, Giulia
  Zanderighi","B-hadron production at the LHC from bottom-quark pair production at
  NNLO+PS","16 pages, 7 figures, 1 table",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The production of B hadrons is among the most abundant fundamental QCD
processes measured at the LHC. We present for the first time predictions for
this process accurate to next-to-next-to-leading order in QCD perturbation
theory by simulating bottom-quark pair production at this accuracy matched to
parton showers. Our novel results are in good agreement with experimental data
for the production of different types of B hadrons from ATLAS, CMS and LHCb at
7 TeV and/or 13 TeV, including various fiducial cross sections as well as
single- and double-differential distributions, and 13 TeV/7 TeV cross-section
ratios.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:42:01 GMT""}]","2023-02-06"
"2302.01646","Alex Kaltenbach","S\""oren Bartels and Alex Kaltenbach","Error analysis for a Crouzeix-Raviart approximation of the obstacle
  problem","31 pages, 6 figures, 2 tables",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the present paper, we study a Crouzeix-Raviart approximation of the
obstacle problem, which imposes the obstacle constraint in the midpoints (i.e.,
barycenters) of the elements of a triangulation. We establish a priori error
estimates imposing natural regularity assumptions, which are optimal, and the
reliability and efficiency of a primal-dual type a posteriori error estimator
for general obstacles and involving data oscillation terms stemming only from
the right-hand side. Numerical experiments are carried out to support the
theoretical findings.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:42:58 GMT""},{""version"":""v2"",""created"":""Thu, 23 Mar 2023 15:41:39 GMT""}]","2023-03-24"
"2302.01647","Shoaib Ahmed Siddiqui","Shoaib Ahmed Siddiqui, David Krueger, Yann LeCun, St\'ephane Deny","Blockwise Self-Supervised Learning at Scale",,,,,"cs.CV cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Current state-of-the-art deep networks are all powered by backpropagation. In
this paper, we explore alternatives to full backpropagation in the form of
blockwise learning rules, leveraging the latest developments in self-supervised
learning. We show that a blockwise pretraining procedure consisting of training
independently the 4 main blocks of layers of a ResNet-50 with Barlow Twins'
loss function at each block performs almost as well as end-to-end
backpropagation on ImageNet: a linear probe trained on top of our blockwise
pretrained model obtains a top-1 classification accuracy of 70.48%, only 1.1%
below the accuracy of an end-to-end pretrained network (71.57% accuracy). We
perform extensive experiments to understand the impact of different components
within our method and explore a variety of adaptations of self-supervised
learning to the blockwise paradigm, building an exhaustive understanding of the
critical avenues for scaling local learning rules to large networks, with
implications ranging from hardware design to neuroscience.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:48:24 GMT""}]","2023-02-06"
"2302.01648","Pierrick Chatillon","Pierrick Chatillon, Yann Gousseau, Sidonie Lefebvre","A statistically constrained internal method for single image
  super-resolution",,"2022 26th International Conference on Pattern Recognition (ICPR),
  Montreal, QC, Canada, 2022, pp. 1322-1328","10.1109/ICPR56361.2022.9956498",,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning based methods for single-image super-resolution (SR) have drawn
a lot of attention lately. In particular, various papers have shown that the
learning stage can be performed on a single image, resulting in the so-called
internal approaches. The SinGAN method is one of these contributions, where the
distribution of image patches is learnt on the image at hand and propagated at
finer scales. Now, there are situations where some statistical a priori can be
assumed for the final image. In particular, many natural phenomena yield images
having power law Fourier spectrum, such as clouds and other texture images. In
this work, we show how such a priori information can be integrated into an
internal super-resolution approach, by constraining the learned up-sampling
procedure of SinGAN. We consider various types of constraints, related to the
Fourier power spectrum, the color histograms and the consistency of the
upsampling scheme. We demonstrate on various experiments that these constraints
are indeed satisfied, but also that some perceptual quality measures can be
improved by the proposed approach.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:48:31 GMT""}]","2023-02-06"
"2302.01649","Zaixiang Zheng","Zaixiang Zheng, Yifan Deng, Dongyu Xue, Yi Zhou, Fei YE, and Quanquan
  Gu","Structure-informed Language Models Are Protein Designers","10 pages; ver.2 update: added image credit to RFdiffusion (Watson et
  al., 2022) in Fig. 1F, and fixed some small presentation errors",,,,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper demonstrates that language models are strong structure-based
protein designers. We present LM-Design, a generic approach to reprogramming
sequence-based protein language models (pLMs), that have learned massive
sequential evolutionary knowledge from the universe of natural protein
sequences, to acquire an immediate capability to design preferable protein
sequences for given folds. We conduct a structural surgery on pLMs, where a
lightweight structural adapter is implanted into pLMs and endows it with
structural awareness. During inference, iterative refinement is performed to
effectively optimize the generated protein sequences. Experiments show that
LM-Design improves the state-of-the-art results by a large margin, leading to
up to 4% to 12% accuracy gains in sequence recovery (e.g., 55.65%/56.63% on
CATH 4.2/4.3 single-chain benchmarks, and >60% when designing protein
complexes). We provide extensive and in-depth analyses, which verify that
LM-Design can (1) indeed leverage both structural and sequential knowledge to
accurately handle structurally non-deterministic regions, (2) benefit from
scaling data and model size, and (3) generalize to other proteins (e.g.,
antibodies and de novo proteins)
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:49:52 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 14:14:05 GMT""}]","2023-02-10"
"2302.01650","Lanqing Guo","Lanqing Guo, Siyu Huang, Ding Liu, Hao Cheng, Bihan Wen","ShadowFormer: Global Context Helps Image Shadow Removal","Accepted by AAAI2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent deep learning methods have achieved promising results in image shadow
removal. However, most of the existing approaches focus on working locally
within shadow and non-shadow regions, resulting in severe artifacts around the
shadow boundaries as well as inconsistent illumination between shadow and
non-shadow regions. It is still challenging for the deep shadow removal model
to exploit the global contextual correlation between shadow and non-shadow
regions. In this work, we first propose a Retinex-based shadow model, from
which we derive a novel transformer-based network, dubbed ShandowFormer, to
exploit non-shadow regions to help shadow region restoration. A multi-scale
channel attention framework is employed to hierarchically capture the global
information. Based on that, we propose a Shadow-Interaction Module (SIM) with
Shadow-Interaction Attention (SIA) in the bottleneck stage to effectively model
the context correlation between shadow and non-shadow regions. We conduct
extensive experiments on three popular public datasets, including ISTD, ISTD+,
and SRD, to evaluate the proposed method. Our method achieves state-of-the-art
performance by using up to 150X fewer model parameters.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:54:52 GMT""}]","2023-02-06"
"2302.01651","Leonardo Vaglini","Paolo Perinotti, Alessandro Tosini, Leonardo Vaglini","Which entropy for general physical theories?","15 pages. arXiv admin note: text overlap with arXiv:2112.12689",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We address the problem of quantifying the information content of a source for
an arbitrary information theory, where the information content is defined in
terms of the asymptotic achievable compression rate. The functions that solve
this problem in classical and quantum theory are Shannon's and von Neumann's
entropy, respectively. However, in a general information theory there are three
different functions that extend the notion of entropy, and this opens the
question as to whether any of them can universally play the role of the
quantifier for the information content. Here we answer the question in the
negative, by evaluating the information content as well as the various entropic
functions in a toy theory called Bilocal Classical Theory.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:55:13 GMT""}]","2023-02-06"
"2302.01652","Nicolas Rougemaille","M. Alfonso-Moro, V. Guisset, P. David, B. Canals, J. Coraux, and N.
  Rougemaille","Corrugation in a molecular C60 monolayer as a frustrated magnet","10 pages, 8 figures",,,,"cond-mat.mes-hall cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Under certain experimental conditions, the deposition of C60 molecules onto
an atomically flat copper surface gives rise to the formation of corrugated
islands. This corrugation, which reflects a molecular displacement
perpendicular to the surface plane, presents an astonishing pattern: it is well
described by a frustrated Ising spin Hamiltonian whose thermodynamics is
compatible with a spin liquid about to transit towards an ordered zigzag state.
Here we study the statistical properties of such a molecular corrugation using
tools generally employed in frustrated magnetism. More specifically, the real
and reciprocal space analysis of pairwise molecule correlations allows us to
demonstrate that the C60/Cu system, in which magnetism is totally absent, has
all the characteristics of a triangular Ising antiferromagnet. Our results
indicate that the organization of two-dimensional matter, at the molecular
length scale, sometimes turns out to be particularly close to that encountered
in highly frustrated magnets.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:56:18 GMT""}]","2023-02-06"
"2302.01653","Marco Bertolini","Marco Bertolini, Van-Khoa Le, Jake Pencharz, Andreas Poehlmann,
  Djork-Arn\'e Clevert, Santiago Villalba, Floriane Montanari","From slides (through tiles) to pixels: an explainability framework for
  weakly supervised models in pre-clinical pathology","18 pages, 9 figures",,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  In pre-clinical pathology, there is a paradox between the abundance of raw
data (whole slide images from many organs of many individual animals) and the
lack of pixel-level slide annotations done by pathologists. Due to time
constraints and requirements from regulatory authorities, diagnoses are instead
stored as slide labels. Weakly supervised training is designed to take
advantage of those data, and the trained models can be used by pathologists to
rank slides by their probability of containing a given lesion of interest. In
this work, we propose a novel contextualized eXplainable AI (XAI) framework and
its application to deep learning models trained on Whole Slide Images (WSIs) in
Digital Pathology. Specifically, we apply our methods to a
multi-instance-learning (MIL) model, which is trained solely on slide-level
labels, without the need for pixel-level annotations. We validate
quantitatively our methods by quantifying the agreements of our explanations'
heatmaps with pathologists' annotations, as well as with predictions from a
segmentation model trained on such annotations. We demonstrate the stability of
the explanations with respect to input shifts, and the fidelity with respect to
increased model performance. We quantitatively evaluate the correlation between
available pixel-wise annotations and explainability heatmaps. We show that the
explanations on important tiles of the whole slide correlate with tissue
changes between healthy regions and lesions, but do not exactly behave like a
human annotator. This result is coherent with the model training strategy.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:57:21 GMT""}]","2023-02-06"
"2302.01654","Stefano Negro","Sergei Dubovsky, Stefano Negro and Massimo Porrati","Topological Gauging and Double Current Deformations","28 pages",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We study solvable deformations of two-dimensional quantum field theories
driven by a bilinear operator constructed from a pair of conserved $U(1)$
currents $J^a$. We propose a quantum formulation of these deformations, based
on the gauging of the corresponding symmetries in a path integral. This
formalism leads to an exact dressing of the $S$-matrix of the system, similarly
as what happens in the case of a $\mathrm{T}\overline{\mathrm{T}}$ deformation.
For conformal theories the deformations under study are expected to be exactly
marginal. Still, a peculiar situation might arise when the conserved currents
$J^a$ are not well-defined local operators in the original theory. A simple
example of this kind of system is provided by rotation currents in a theory of
multiple free, massless, non-compact bosons. We verify that, somewhat
unexpectedly, such a theory is indeed still conformal after deformation and
that it coincides with a TsT transformation of the original system. We then
extend our formalism to the case in which the conserved currents are
non-Abelian and point out its connection with Deformed T-dual Models and
homogeneous Yang-Baxter deformations. In this case as well the deformation is
based on a gauging of the symmetries involved and it turns out to be
non-trivial only if the symmetry group admits a non-trivial central extension.
Finally we apply what we learned by relating the
$\mathrm{T}\overline{\mathrm{T}}$ deformation to the central extension of the
two-dimensional Poincar\'{e} algebra.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:02:48 GMT""}]","2023-02-06"
"2302.01655","Sean Eberhard","Sean Eberhard and Daniele Garzoni","Conjugacy classes of derangements in finite groups of Lie type","35 pages",,,,"math.GR math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a finite almost simple group of Lie type acting faithfully and
primitively on a set $\Omega$. We prove an analogue of the Boston--Shalev
conjecture for conjugacy classes: the proportion of conjugacy classes of $G$
consisting of derangements is bounded away from zero. This answers a question
of Guralnick and Zalesski. The proof is based on results on the anatomy of
palindromic polynomials over finite fields (with either reflective symmetry or
conjugate-reflective symmetry).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:08:08 GMT""}]","2023-02-06"
"2302.01656","Christoph Dittel","Christoph Dittel, Niklas Neubrand, Felix Thiel, Andreas Buchleitner","First-detection-time statistics in many-body quantum transport","Comments are welcome",,"10.1103/PhysRevA.107.052206",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the transport of many partially distinguishable and possibly
interacting particles under the action of repeated projective measurements on a
target space and investigate how the particles' interference affects the mean
first detection time. We contrast the detection of exactly $n$ versus at least
$n$ particles, explain divergences in the mean first detection time through
spectral properties of the generating evolution operator, and illustrate our
findings by an example.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:08:44 GMT""},{""version"":""v2"",""created"":""Tue, 9 May 2023 07:05:04 GMT""}]","2023-05-10"
"2302.01657","Virginie Uhlmann","Si\^an Culley, Alicia Cuber Caballero, Jemima J Burden, Virginie
  Uhlmann","Made to measure: an introduction to quantification in microscopy data","23 pages, 5 figures, 2 tables",,,,"q-bio.QM","http://creativecommons.org/licenses/by/4.0/","  Images are at the core of most modern biological experiments and are used as
a major source of quantitative information. Numerous algorithms are available
to process images and make them more amenable to be measured. Yet the nature of
the quantitative output that is useful for a given biological experiment is
uniquely dependent upon the question being investigated. Here, we discuss the 3
main types of visual information that can be extracted from microscopy data:
intensity, morphology, and object counts or categorical labels. For each, we
describe where they come from, how they can be measured, and what may affect
the relevance of these measurements in downstream data analysis. Acknowledging
that what makes a measurement ""good"" is ultimately down to the biological
question being investigated, this review aims at providing readers with a
toolkit to challenge how they quantify their own data and be critical of
conclusions drawn from quantitative bioimage analysis experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:14:13 GMT""}]","2023-02-06"
"2302.01658","Markus Bachmayr","Markus Bachmayr and Manfred Faldum","A space-time adaptive low-rank method for high-dimensional parabolic
  partial differential equations","62 pages, 5 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An adaptive method for parabolic partial differential equations that combines
sparse wavelet expansions in time with adaptive low-rank approximations in the
spatial variables is constructed and analyzed. The method is shown to converge
and satisfy similar complexity bounds as existing adaptive low-rank methods for
elliptic problems, establishing its suitability for parabolic problems on
high-dimensional spatial domains. The construction also yields computable
rigorous a posteriori error bounds for such problems. The results are
illustrated by numerical experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:17:09 GMT""}]","2023-02-06"
"2302.01659","Zhaofeng Liu","Yujiang Bi, Ying Chen, Ming Gong, Fangcheng He, Keh-Fei Liu, Zhaofeng
  Liu, Yi-Bo Yang, Dian-Jun Zhao","RI/(S)MOM renormalizations of overlap quark bilinears with different
  levels of hypercubic smearing","32 pages, 13 figures",,,,"hep-lat","http://creativecommons.org/licenses/by/4.0/","  On configurations with 2+1-flavor dynamical domain-wall fermions, we
calculate the RI/(S)MOM renormalization constants (RC) of overlap quark
bilinears. Hypercubic (HYP) smearing is used to construct the overlap Dirac
operator. We investigate the possible effects of the smearing on discretization
errors in the RCs by varying the level of smearing from 0 to 1 and 2. The
lattice is of size $32^3\times64$ and with lattice spacing $1/a=2.383(9)$ GeV.
The RCs in the $\overline{\rm MS}$ scheme at 2 GeV are given at the end, with
the uncertainty of $Z_T$ reaching $\le1$% for the tensor current. Results of
the renormalized quark masses and hadron matrix elements show that the
renormalization procedure suppresses the $\sim$ 30% difference of the bare
quantities with or without HYP smearing into 3-5% level.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:17:11 GMT""}]","2023-02-06"
"2302.01660","Ioannis Siglidis","Ioannis Siglidis, Nicolas Gonthier, Julien Gaubil, Tom Monnier and
  Mathieu Aubry","The Learnable Typewriter: A Generative Approach to Text Analysis","For the code and a quick-overview visit the project webpage at
  http://imagine.enpc.fr/~siglidii/learnable-typewriter",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  We present a generative document-specific approach to character analysis and
recognition in text lines. Our main idea is to build on unsupervised
multi-object segmentation methods and in particular those that reconstruct
images based on a limited amount of visual elements, called sprites. Taking as
input a set of text lines with similar font or handwriting, our approach can
learn a large number of different characters and leverage line-level
annotations when available. Our contribution is twofold. First, we provide the
first adaptation and evaluation of a deep unsupervised multi-object
segmentation approach for text line analysis. Since these methods have mainly
been evaluated on synthetic data in a completely unsupervised setting,
demonstrating that they can be adapted and quantitatively evaluated on real
images of text and that they can be trained using weak supervision are
significant progresses. Second, we show the potential of our method for new
applications, more specifically in the field of paleography, which studies the
history and variations of handwriting, and for cipher analysis. We demonstrate
our approach on three very different datasets: a printed volume of the
Google1000 dataset, the Copiale cipher and historical handwritten charters from
the 12th and early 13th century.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:17:59 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 16:46:38 GMT""},{""version"":""v3"",""created"":""Fri, 14 Apr 2023 14:08:29 GMT""}]","2023-04-17"
"2302.01661","Nicholas Sedlmayr","Hadi Cheraghi and Nicholas Sedlmayr","Dynamical Quantum Phase Transitions Following Double Quenches:
  Persistence of the Initial State vs Dynamical Phases",,,,,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dynamical quantum phase transitions can occur following quenches in quantum
systems when the rate function, a dynamical analogue of the free energy,
becomes non-analytic at critical times. Here we exhaustively investigate in an
exemplary model how the dynamically evolving state responds to a second quench.
We demonstrate that for quenches where the initial and final Hamiltonian belong
to different phases always result in dynamical quantum phase transitions,
irrespective of the intermediate quench and dynamics or the time of the second
quench. However, if the initial and final Hamiltonian belong to the same
equilibrium phase then the intermediate Hamiltonian must belong to a different
phase. In this case, the second quench time in relation to the critical times
of the first quench becomes crucial to the existence of dynamical quantum phase
transitions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:23:13 GMT""}]","2023-02-06"
"2302.01662","Deepu Kumar","Deepu Kumar, Nasaru Khan, Rahul Kumar, Mahesh Kumar, Pradeep Kumar","Tunable Resonance and Electron-Phonon Coupling in Layered MoS2",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resonance Raman scattering, a very effective and sensitive technique for
atomically thin semiconducting transition metal dichalcogenide, can be used to
observe the phonons from the entire Brillouin zone. In addition to the
significance of resonance effect on the Raman spectrum it may also be used to
probe the electron-phonon coupling. Our study is devoted to understand the
phonons in layered MoS2, especially for very low frequency range (i.e. below
100 cm-1), as a function of temperature under the resonance effect.
Understanding the phonon-phonon and electron-phonon coupling and the effects of
temperature on the Raman spectrum are the central points of the present study.
We observe the anomalous softening and broadening of a very low frequency
phonon mode P3 (~34 cm-1) at low temperature ( i.e below 150 K). We attributed
the observed anomalous trend in frequency and linewidth of this low frequency
phonon to the electron-phonon coupling. Furthermore, our work also highlights
the temperature induced tuning of resonance condition via understanding the
intensity of phonon modes as a function of temperature.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:33:12 GMT""}]","2023-02-06"
"2302.01663","Andrew Macpherson","Andrew W. Macpherson","Adversarial blockchain queues and trading on a CFMM","20 pages. Keywords: queue, blockchain, mempool, cfmm, mev, dex,
  priority discipline, model, sandwich, slippage",,,,"math.PR cs.GT q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We describe a plausible probabilistic model for a blockchain queueing
environment in which rational, profit-maximising schedulers impose adversarial
disciplines on incoming messages containing a payload that encodes a state
transition in a machine. The model can be specialised to apply to chains with
fixed or variable block times, traditional priority queue disciplines with
`honest' schedulers, or adversarial public mempools. We find conditions under
which the model behaves as a bulk-service queue with priority discipline and
derive practical expressions for the relative block and message number of a
transaction.
  We study this setup in the context of orders to a CFMM DEX where the
execution price a user receives may be quite sensitive to its positioning in
the chain -- in particular, to a string of transactions scheduled for prior
execution which is not knowable at the time of order creation. We derive
statistical models for the price impact of this order flow both in the presence
and absence of MEV extraction activity.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:33:13 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 10:12:29 GMT""}]","2023-02-17"
"2302.01664","Felix Reichel","Felix Reichel and Beyza B\""uy\""ukurganc{\i}","Effective viscosity of methyl cellulose solutions in phosphate buffered
  saline in real-time deformability cytometry",,,,,"cond-mat.soft physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Here, we derive the equations to calculate the effective viscosity of
solutions of methyl cellulose (MC) dissolved in phosphate buffered saline (PBS)
in real-time deformability cytometry (RT-DC) experiments. The calculations are
based on the rheometer measurements described by B\""uy\""ukurganci et al.
(2022). We outline how to get the final equations and compare the results to
the current viscosity model from Herold (2017). These viscosity functions will
be used to determine the Young's moduli of biological cells and other soft
materials from RT-DC experiments.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:35:17 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 20:10:20 GMT""}]","2023-02-09"
"2302.01665","Junyi Ma","Junyi Ma, Guangming Xiong, Jingyi Xu, Xieyuanli Chen","CVTNet: A Cross-View Transformer Network for Place Recognition Using
  LiDAR Data",,,,,"cs.CV cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LiDAR-based place recognition (LPR) is one of the most crucial components of
autonomous vehicles to identify previously visited places in GPS-denied
environments. Most existing LPR methods use mundane representations of the
input point cloud without considering different views, which may not fully
exploit the information from LiDAR sensors. In this paper, we propose a
cross-view transformer-based network, dubbed CVTNet, to fuse the range image
views (RIVs) and bird's eye views (BEVs) generated from the LiDAR data. It
extracts correlations within the views themselves using intra-transformers and
between the two different views using inter-transformers. Based on that, our
proposed CVTNet generates a yaw-angle-invariant global descriptor for each
laser scan end-to-end online and retrieves previously seen places by descriptor
matching between the current query scan and the pre-built database. We evaluate
our approach on three datasets collected with different sensor setups and
environmental conditions. The experimental results show that our method
outperforms the state-of-the-art LPR methods with strong robustness to
viewpoint changes and long-time spans. Furthermore, our approach has a good
real-time performance that can run faster than the typical LiDAR frame rate.
The implementation of our method is released as open source at:
https://github.com/BIT-MJY/CVTNet.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:37:20 GMT""}]","2023-02-06"
"2302.01666","Cristina Bedoya","G. Abbiendi, J. Alcaraz Maestre, A. \'Alvarez Fern\'andez, B.
  \'Alvarez Gonz\'alez, N. Amapane, I. Bachiller, L. Barcellan, C. Baldanza, C.
  Battilana, M. Bellato, G. Bencze, M. Benettoni, N. Beni, A. Benvenuti, A.
  Bergnoli, L. C. Blanco Ramos, L. Borgonovi, A. Bragagnolo, V. Cafaro, A.
  Calderon, E. Calvo, R. Carlin, C. A. Carrillo Montoya, F. R. Cavallo, J. M.
  Cela Ruiz, M. Cepeda, M. Cerrada, P. Checchia, L. Ciano, N. Colino, D. Corti,
  G. Cotto, A. Crupano, S. Cuadrado Calzada, J. Cuevas, M. Cuffiani, G. M.
  Dallavalle, D. Dattola, B. De La Cruz, C. I. de Lara Rodr\'iguez, P. De
  Remigis, C. Erice Cid, D. Eliseev, F. Fabbri, A. Fanfani, D. Fasanella, C. F.
  Bedoya, J. F. de Troc\'oniz, D. Fern\'andez del Val, J. Fern\'andez
  Men\'endez, J. P. Fern\'andez Ramos, S. Folgueras, M. C. Fouz, D. Francia
  Ferrero, J. Garc\'ia Romero, F. Gasparini, U. Gasparini, V. Giordano, F.
  Gonella, I. Gonz\'alez Caballero, J. R. Gonz\'alez Fern\'andez, O. Gonz\'alez
  L\'opez, S. Goy L\'opez, A. Gozzelino, A. Griggio, G. Grosso, C. Guandalini,
  L. Guiducci, M. Gulmini, T. Hebbeker, K. Hoepfner, R. Isocrate, M. I. Josa,
  B. Kiani, J. Le\'on Holgado, S. Lo Meo, E. Lusiani, L. Lunerti, S.
  Marcellini, M. Margoni, C. Mariotti, I. Mart\'in Mart\'in, J. J. Mart\'inez
  Morales, S. Maselli, G. Masetti, A. T. Meneguzzo, M. Merschmeyer, M.
  Migliorini, L. Modenese, J. Molnar, F. Montecassiano, J. Mora Mart\'inez, D.
  Moran, S. Mukherjee, J. J. Navarrete, F. Navarria, A. Navarro Tobar, F.
  Nowotny, E. Palencia Cortez\'on, M. Passaseo, J. Pazzini, M. Pelliccioni, A.
  Perrotta, B. Philipps, J. Piedra Gomez, F. Primavera, J. Puerta Pelayo, J. C.
  Puras S\'anchez, C. Ram\'on \'Alvarez, I. Redondo, D. D. Redondo Ferrero, H.
  Reithler, R. Reyes-Almanza, V. Rodr\'iguez Bouza, P. Ronchese, A. M. Rossi,
  R. Rossin, F. Rotondo, T. Rovelli, S. S\'anchez Cruz, S. S\'anchez Navas, J.
  Sastre, A. Sharma, F. Simonetto, A. Soto Rodr\'iguez, A. Staiano, Z.
  Szillasi, D. F. Teyssier, N. Toniolo, G. Torromeo, A. Trapote, N. Trevisani,
  A. Triossi, D. Trocino, B. Ujvari, G. Umoret, L. Urda G\'omez, B. Uwe, S.
  Ventura, C. Vico Villalba, S. Wiedenbeck, M. Zanetti, F. P. Zantis, G.
  Zilizi, P. Zotto, A. Zucchetta","The Analytical Method algorithm for trigger primitives generation at the
  LHC Drift Tubes detector","16 pages, 11 figures",,"10.1016/j.nima.2023.168103",,"hep-ex physics.ins-det","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The Compact Muon Solenoid (CMS) experiment prepares its Phase-2 upgrade for
the high-luminosity era of the LHC operation (HL-LHC). Due to the increase of
occupancy, trigger latency and rates, the full electronics of the CMS Drift
Tube (DT) chambers will need to be replaced. In the new design, the time bin
for the digitisation of the chamber signals will be of around 1~ns, and the
totality of the signals will be forwarded asynchronously to the service cavern
at full resolution. The new backend system will be in charge of building the
trigger primitives of each chamber. These trigger primitives contain the
information at chamber level about the muon candidates position, direction, and
collision time, and are used as input in the L1 CMS trigger. The added
functionalities will improve the robustness of the system against ageing. An
algorithm based on analytical solutions for reconstructing the DT trigger
primitives, called Analytical Method, has been implemented both as a software
C++ emulator and in firmware. Its performance has been estimated using the
software emulator with simulated and real data samples, and through hardware
implementation tests. Measured efficiencies are 96 to 98\% for all qualities
and time and spatial resolutions are close to the ultimate performance of the
DT chambers. A prototype chain of the HL-LHC electronics using the Analytical
Method for trigger primitive generation has been installed during Long Shutdown
2 of the LHC and operated in CMS cosmic data taking campaigns in 2020 and 2021.
Results from this validation step, the so-called Slice Test, are presented.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:38:18 GMT""}]","2023-02-06"
"2302.01667","Xiao Hu","Jianxiong Li, Xiao Hu, Haoran Xu, Jingjing Liu, Xianyuan Zhan,
  Qing-Shan Jia, Ya-Qin Zhang","Mind the Gap: Offline Policy Optimization for Imperfect Rewards","Accept by ICLR2023. The first two authors contributed equally",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reward function is essential in reinforcement learning (RL), serving as the
guiding signal to incentivize agents to solve given tasks, however, is also
notoriously difficult to design. In many cases, only imperfect rewards are
available, which inflicts substantial performance loss for RL agents. In this
study, we propose a unified offline policy optimization approach, \textit{RGM
(Reward Gap Minimization)}, which can smartly handle diverse types of imperfect
rewards. RGM is formulated as a bi-level optimization problem: the upper layer
optimizes a reward correction term that performs visitation distribution
matching w.r.t. some expert data; the lower layer solves a pessimistic RL
problem with the corrected rewards. By exploiting the duality of the lower
layer, we derive a tractable algorithm that enables sampled-based learning
without any online interactions. Comprehensive experiments demonstrate that RGM
achieves superior performance to existing methods under diverse settings of
imperfect rewards. Further, RGM can effectively correct wrong or inconsistent
rewards against expert preference and retrieve useful information from biased
rewards.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:39:50 GMT""}]","2023-02-06"
"2302.01668","Shunya Chomei","Shunya Chomei","Empirical analysis in limit order book modeling for Nikkei 225 Stocks
  with Cox-type intensities","13 pages, 3 figures",,,,"q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we build on the analysis of Muni Toke and Yoshida (2020) and
conduct several empirical studies using high-frequency financial data. Muni
Toke and Yoshida (2020) showed the consistency and asymptotic behavior of the
Cox-type model estimators for relative intensities of orders in the limit order
book, and then by using high-frequency trading data for 36 stocks traded on the
Paris Stock Exchange, they carry out model selection and trading sign
prediction. In this study, we add new covariates and carry out model selection
and trading sign prediction using high-frequency trading data for 222 stocks
traded on the Tokyo Stock Exchange. We not only show that the Cox-type model
performs well in the Japanese market as well as in the Euronext Paris market,
but also present the key factors for more accurate estimation. We also suggest
how often the covariates should be calibrated.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:42:02 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 13:47:37 GMT""}]","2023-02-17"
"2302.01669","Oleg Skoromnik","I. D. Feranchuk and N. Q. San and O. D. Skoromnik","All-coupling solution for the continuous polaron problem in the
  Schr\""{o}dinger representation","6 pages, 3 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The solution for the large-radius Fr\""{o}hlich polaron in the Schr\""{o}dinger
representation of the quantum theory is constructed in the entire range of
variation of the coupling constant. The energy and the effective mass of the
polaron are calculated by simple algebraic transformations and are analogous to
the results found by Feynman on the basis of the variational principle for the
path-integrals of this system. It allows us to solve the long-lived problem of
the inequalities of the functional and operator approaches for the polaron
problem. The developed method is important for other models of particle-field
interaction including those ones for which the standard perturbation theory is
divergent.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:45:38 GMT""}]","2023-02-06"
"2302.01670","Polona Oblak","Jephian C.-H. Lin, Polona Oblak, Helena \v{S}migoc","The liberation set in the inverse eigenvalue problem of a graph",,,,,"math.CO","http://creativecommons.org/licenses/by-sa/4.0/","  The inverse eigenvalue problem of a graph $G$ is the problem of
characterizing all lists of eigenvalues of real symmetric matrices whose
off-diagonal pattern is prescribed by the adjacencies of $G$. The strong
spectral property is a powerful tool in this problem, which identifies matrices
whose entries can be perturbed while controlling the pattern and preserving the
eigenvalues. The Matrix Liberation Lemma introduced by Barrett et al.~in 2020
advances the notion to a more general setting. In this paper we revisit the
Matrix Liberation Lemma and prove an equivalent statement, that reduces some of
the technical difficulties in applying the result.
  We test our method on matrices of the form $M=A \oplus B$ and show how this
new approach supplements the results that can be obtained from the strong
spectral property only. While extending this notion to the direct sums of
graphs, we discover a surprising connection with the zero forcing game on
Cartesian products of graphs.
  Throughout the paper we apply our results to resolve a selection of open
cases for the inverse eigenvalue problem of a graph on six vertices.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:48:35 GMT""},{""version"":""v2"",""created"":""Tue, 6 Jun 2023 11:27:47 GMT""}]","2023-06-07"
"2302.01671","Dennis Meier","L. Richarz, J. He, U. Ludacka, E. Bourret, Z. Yan, A.T.J. van
  Helvoort, and D. Meier","Moir\'e Fringes in Conductive Atomic Force Microscopy",,,"10.1063/5.0145173",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Moir\'e physics plays an important role for the characterization of
functional materials and the engineering of physical properties in general,
ranging from strain-driven transport phenomena to superconductivity. Here, we
report the observation of moir\'e fringes in conductive atomic force microscopy
(cAFM) scans gained on the model ferroelectric Er(Mn,Ti)O$_3$. By performing a
systematic study of the impact of key experimental parameters on the emergent
moir\'e fringes, such as scan angle and pixel density, we demonstrate that the
observed fringes arise due to a superposition of the applied raster scanning
and sample-intrinsic properties, classifying the measured modulation in
conductance as a scanning moir\'e effect. Our findings are important for the
investigation of local transport phenomena in moir\'e engineered materials by
cAFM, providing a general guideline for distinguishing extrinsic from intrinsic
moir\'e effects. Furthermore, the experiments provide a possible pathway for
enhancing the sensitivity, pushing the resolution limit of local transport
measurements by probing conductance variations at the spatial resolution limit
via more long-ranged moir\'e patterns.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:49:02 GMT""}]","2023-05-03"
"2302.01672","Van Phuc Bui","Van-Phuc Bui, Shashi Raj Pandey, Federico Chiariotti, Petar Popovski","Game Networking Principles for Real-Time Social Networking in the
  Metaverse",,,,,"eess.SP cs.NI","http://creativecommons.org/licenses/by/4.0/","  The sixth generation (6G) of wireless technology is seen as one of the
enablers of real-time fusion of the physical and digital realms, as in the
Metaverse, eXtended reality (XR), or Digital Twin (DT). This would allow people
to interact, work, and entertain themselves in an immersive social network of
online 3D~virtual environments. From the viewpoint of communication and
networking, this will represent an evolution of the game networking technology,
designed to interconnect massive users in real-time online gaming environments.
This article presents the basic principles of game networking and discusses
their evolution towards meeting the requirements of the Metaverse and similar
applications. Several open research challenges are provided, along with
possible solutions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:53:03 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 11:47:04 GMT""}]","2023-06-09"
"2302.01673","Enric Pardo","Enric Pardo, Anang Dadhich","Electro-thermal modelling by novel variational methods: racetrack coil
  in short-circuit","17 pages, 6 figures","IEEE Trans. Appl. Supercond. (2023)","10.1109/TASC.2023.3252492",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The design of superconducting applications containing windings of
superconducting wires or tapes requires electro-thermal quench modelling. In
this article, we present a reliable numerical method based on a variational
principle and we benchmark it to a conventional finite difference method that
we implemented in C++. As benchmark problem, we consider a racetrack coil made
of REBCO superconducting tape under short circuit, approximated as a DC voltage
that appears at the initial time. Results show that both models agree with each
other and analytical limits. Since both models take screening currents into
account, they are promising for the design of magnets (especially fast-ramp
magnets) and power applications, such as the stator windings of superconducting
motors or generators.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:55:22 GMT""}]","2023-03-27"
"2302.01674","Yajun Wang","Xiaofei Guan, Lijian Jiang, Yajun Wang and Zihao Yang","A coupling generalized multiscale finite element method for coupled
  thermomechanical problems","27 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is crucial to build multiscale modeling for the coupling effects between
microstructure and the physical mechanisms in multiphysics problems. In the
paper, we develop a coupling formulation of the generalized multiscale finite
element method (GMsFEM) to solve coupled thermomechanical problems, and it is
referred as the coupling generalized multiscale finite element method
(CGMsFEM). The approach consists in defining the coupling multiscale basis
functions through local coupling spectral problems in each coarse-grid block,
which can be solved by a novel design of two relaxation parameters. Compared to
the standard GMsFEM, the proposed strategy can not only accurately capture the
multiscale coupling correlation effects of multiphysics problems, but also
greatly improve the computational efficiency with fewer multiscale basis
functions. In addition, the convergence analysis is also established, and the
optimal error estimates are derived, where the upper bound of errors is
independent of the magnitude of the relaxation coefficient. Several numerical
examples for periodic, random microstructure, and random material coefficients
are presented to validate the theoretical analysis. The numerical results show
that the CGMsFEM approach shows better robustness and efficiency than uncoupled
GMsFEM.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:55:57 GMT""}]","2023-02-06"
"2302.01675","Ben Perach","Ben Perach, Ronny Ronen, Shahar Kvatinsky","Enabling Relational Database Analytical Processing in Bulk-Bitwise
  Processing-In-Memory",,,,,"cs.AR","http://creativecommons.org/licenses/by/4.0/","  Bulk-bitwise processing-in-memory (PIM), an emerging computational paradigm
utilizing memory arrays as computational units, has been shown to benefit
database applications. This paper demonstrates how GROUP-BY and JOIN, database
operations not supported by previous works, can be performed efficiently in
bulk-bitwise PIM used for relational database analytical processing. We develop
a gem5 simulator and show that our hardware modifications, on the Star Schema
Benchmark and compared to previous works, improve, on average, execution time
by $1.83\times$, energy by $4.31\times$, and the system's lifetime by
$3.21\times$. We also achieved a speedup of $4.65\times$ over MonetDB, a modern
state-of-the-art in-memory database.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:56:09 GMT""}]","2023-02-06"
"2302.01676","Andrea Tagarelli","Davide Costa, Lucio La Cava, Andrea Tagarelli","Show me your NFT and I tell you how it will perform: Multimodal
  representation learning for NFT selling price prediction","Accepted paper at The ACM Web Conference 2023, April 30--May 04,
  2023, Austin, Texas, USA",,"10.1145/3543507.3583520",,"cs.LG cs.AI cs.CL cs.CV cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-Fungible Tokens (NFTs) represent deeds of ownership, based on blockchain
technologies and smart contracts, of unique crypto assets on digital art forms
(e.g., artworks or collectibles). In the spotlight after skyrocketing in 2021,
NFTs have attracted the attention of crypto enthusiasts and investors intent on
placing promising investments in this profitable market. However, the NFT
financial performance prediction has not been widely explored to date.
  In this work, we address the above problem based on the hypothesis that NFT
images and their textual descriptions are essential proxies to predict the NFT
selling prices. To this purpose, we propose MERLIN, a novel multimodal deep
learning framework designed to train Transformer-based language and visual
models, along with graph neural network models, on collections of NFTs' images
and texts. A key aspect in MERLIN is its independence on financial features, as
it exploits only the primary data a user interested in NFT trading would like
to deal with, i.e., NFT images and textual descriptions. By learning dense
representations of such data, a price-category classification task is performed
by MERLIN models, which can also be tuned according to user preferences in the
inference phase to mimic different risk-return investment profiles.
Experimental evaluation on a publicly available dataset has shown that MERLIN
models achieve significant performances according to several financial
assessment criteria, fostering profitable investments, and also beating
baseline machine-learning classifiers based on financial features.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:56:38 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 10:44:21 GMT""}]","2023-02-07"
"2302.01677","Zeyu Qin","Zeyu Qin, Liuyi Yao, Daoyuan Chen, Yaliang Li, Bolin Ding, Minhao
  Cheng","Revisiting Personalized Federated Learning: Robustness Against Backdoor
  Attacks","KDD 2023",,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  In this work, besides improving prediction accuracy, we study whether
personalization could bring robustness benefits to backdoor attacks. We conduct
the first study of backdoor attacks in the pFL framework, testing 4 widely used
backdoor attacks against 6 pFL methods on benchmark datasets FEMNIST and
CIFAR-10, a total of 600 experiments. The study shows that pFL methods with
partial model-sharing can significantly boost robustness against backdoor
attacks. In contrast, pFL methods with full model-sharing do not show
robustness. To analyze the reasons for varying robustness performances, we
provide comprehensive ablation studies on different pFL methods. Based on our
findings, we further propose a lightweight defense method, Simple-Tuning, which
empirically improves defense performance against backdoor attacks. We believe
that our work could provide both guidance for pFL application in terms of its
robustness and offer valuable insights to design more robust FL methods in the
future. We open-source our code to establish the first benchmark for black-box
backdoor attacks in pFL:
https://github.com/alibaba/FederatedScope/tree/backdoor-bench.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:58:14 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 08:35:02 GMT""}]","2023-06-06"
"2302.01678","Hermine Landt","Hermine Landt, Jake A. J. Mitchell, Martin J. Ward, Paul Mercatoris,
  J\""org-Uwe Pott, Keith Horne, Juan V. Hern\'andez Santisteban, Daksh
  Malhotra, Edward M. Cackett, Michael R. Goad, Encarni Romero Colmenero,
  Hartmut Winkler","A complex dust morphology in the high-luminosity AGN Mrk 876","18 pages, 7 figures; accepted to ApJ",,"10.3847/1538-4357/acb92d",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Recent models for the inner structure of active galactic nuclei (AGN)
advocate the presence of a radiatively accelerated, dusty outflow launched from
the outer regions of the accretion disk. Here we present the first
near-infrared (near-IR) variable (rms) spectrum for the high-luminosity, nearby
AGN Mrk 876. We find that it tracks the accretion disk spectrum out to longer
wavelengths than the mean spectrum due to a reduced dust emission. The implied
outer accretion disk radius is consistent with the infrared results predicted
by a contemporaneous optical accretion disk reverberation mapping campaign and
much larger than the self-gravity radius. The reduced flux variability of the
hot dust could be either due to the presence of a secondary, constant dust
component in the mean spectrum or introduced by the destructive superposition
of the dust and accretion disk variability signals or some combination of both.
Assuming thermal equilibrium for optically thin dust, we derive the
luminosity-based dust radius for different grain properties using our
measurement of the temperature. We find that in all cases considered the values
are significantly larger than the dust response time measured by IR photometric
monitoring campaigns, with the least discrepancy present relative to the result
for a wavelength-independent dust emissivity law, i.e. a blackbody, which is
appropriate for large grain sizes. This result can be well explained by
assuming a flared, disk-like structure for the hot dust.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:00:28 GMT""}]","2023-03-15"
"2302.01679","Mathieu Dutour Sikiri\'c","Mathieu Dutour Sikiri\'c and Klaus Hulek","Moduli of polarized Enriques surfaces -- computational aspects","39 pages, 1 figure, 6 Tables",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Moduli spaces of (polarized) Enriques surfaces can be described as open
subsets of modular varieties of orthogonal type. It was shown by Gritsenko and
Hulek that there are, up to isomorphism, only finitely many different moduli
spaces of polarized Enriques surfaces. Here we investigate the possible
arithmetic groups and show that there are exactly $87$ such groups up to
conjugacy. We also show that all moduli spaces are dominated by a moduli space
of polarized Enriques surfaces of degree $1240$. Ciliberto, Dedieu, Galati, and
Knutsen have also investigated moduli spaces of polarized Enriques surfaces in
detail. We discuss how our enumeration relates to theirs. We further compute
the Tits building of the groups in question. Our computation is based on groups
and indefinite quadratic forms and the algorithms used are explained.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:02:52 GMT""}]","2023-02-06"
"2302.01680","Qingpeng Cai","Qingpeng Cai, Zhenghai Xue, Chi Zhang, Wanqi Xue, Shuchang Liu, Ruohan
  Zhan, Xueliang Wang, Tianyou Zuo, Wentao Xie, Dong Zheng, Peng Jiang, Kun Gai","Two-Stage Constrained Actor-Critic for Short Video Recommendation","arXiv admin note: substantial text overlap with arXiv:2205.13248","The Web Conference 2023",,,"cs.LG cs.IR","http://creativecommons.org/publicdomain/zero/1.0/","  The wide popularity of short videos on social media poses new opportunities
and challenges to optimize recommender systems on the video-sharing platforms.
Users sequentially interact with the system and provide complex and
multi-faceted responses, including watch time and various types of interactions
with multiple videos. One the one hand, the platforms aims at optimizing the
users' cumulative watch time (main goal) in long term, which can be effectively
optimized by Reinforcement Learning. On the other hand, the platforms also
needs to satisfy the constraint of accommodating the responses of multiple user
interactions (auxiliary goals) such like, follow, share etc. In this paper, we
formulate the problem of short video recommendation as a Constrained Markov
Decision Process (CMDP). We find that traditional constrained reinforcement
learning algorithms can not work well in this setting. We propose a novel
two-stage constrained actor-critic method: At stage one, we learn individual
policies to optimize each auxiliary signal. At stage two, we learn a policy to
(i) optimize the main signal and (ii) stay close to policies learned at the
first stage, which effectively guarantees the performance of this main policy
on the auxiliaries. Through extensive offline evaluations, we demonstrate
effectiveness of our method over alternatives in both optimizing the main goal
as well as balancing the others. We further show the advantage of our method in
live experiments of short video recommendations, where it significantly
outperforms other baselines in terms of both watch time and interactions. Our
approach has been fully launched in the production system to optimize user
experiences on the platform.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:02:54 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 13:02:12 GMT""}]","2023-02-07"
"2302.01681","Stephan Naunheim","Stephan Naunheim, Yannick Kuhl, David Schug, Volkmar Schulz, Florian
  Mueller","Improving the Timing Resolution of Positron Emission Tomography
  Detectors using Boosted Learning -- A Residual Physics Approach",,,,,"cs.LG physics.ins-det physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial intelligence is finding its way into medical imaging, usually
focusing on image reconstruction or enhancing analytical reconstructed images.
However, optimizations along the complete processing chain, from detecting
signals to computing data, enable significant improvements. Thus, we present an
approach toward detector optimization using boosted learning by exploiting the
concept of residual physics. In our work, we improve the coincidence time
resolution (CTR) of positron emission tomography (PET) detectors. PET enables
imaging of metabolic processes by detecting {\gamma}-photons with scintillation
detectors. Current research exploits light-sharing detectors, where the
scintillation light is distributed over and digitized by an array of readout
channels. While these detectors demonstrate excellent performance parameters,
e.g., regarding spatial resolution, extracting precise timing information for
time-of-flight (TOF) becomes more challenging due to deteriorating effects
called time skews. Conventional correction methods mainly rely on analytical
formulations, theoretically capable of covering all time skew effects, e.g.,
caused by signal runtimes or physical effects. However, additional effects are
involved for light-sharing detectors, so finding suitable analytical
formulations can become arbitrarily complicated. The residual physics-based
strategy uses gradient tree boosting (GTB) and a physics-informed data
generation mimicking an actual imaging process by shifting a radiation source.
We used clinically relevant detectors with a height of 19 mm, coupled to
digital photosensor arrays. All trained models improved the CTR significantly.
Using the best model, we achieved CTRs down to 198 ps (185 ps) for energies
ranging from 300 keV to 700 keV (450 keV to 550 keV).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:10:24 GMT""}]","2023-02-06"
"2302.01682","Ahmet M. Elbir","Ahmet M. Elbir, Kumar Vijay Mishra and Symeon Chatzinotas","NBA-OMP: Near-field Beam-Split-Aware Orthogonal Matching Pursuit for
  Wideband THz Channel Estimation","Accepted Paper in 2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sixth-generation networks envision the terahertz (THz) band as one of the
key enabling technologies because of its ultrawide bandwidth. To combat the
severe attenuation, the THz wireless systems employ large arrays, wherein the
near-field beam-split (NB) severely degrades the accuracy of channel
acquisition. Contrary to prior works that examine only either narrowband
beamforming or far-field models, we estimate the wideband THz channel via an
NB-aware orthogonal matching pursuit (NBA-OMP) approach. We design an NBA
dictionary of near-field steering vectors by exploiting the corresponding
angular and range deviation. Our OMP algorithm accounts for this deviation
thereby ipso facto mitigating the effect of NB. Numerical experiments
demonstrate the effectiveness of the proposed channel estimation technique for
wideband THz systems.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:12:24 GMT""},{""version"":""v2"",""created"":""Thu, 16 Feb 2023 06:00:17 GMT""}]","2023-02-17"
"2302.01683","Tzee-Ming Huang","Yu-Hsiang Cheng, Tzee-Ming Huang","A mixture logistic model for panel data with a Markov structure","7 pages",,,,"stat.ME","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In this study, we propose a mixture logistic regression model with a Markov
structure, and consider the estimation of model parameters using maximum
likelihood estimation. We also provide a forward type variable selection
algorithm to choose the important explanatory variables to reduce the number of
parameters in the proposed model.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:12:52 GMT""}]","2023-02-06"
"2302.01684","Miguel Angel Valbuena","Beatriz Mu\~niz Cano, Yago Ferreiros, Pierre A. Pantale\'on, Ji Dai,
  Massimo Tallarida, Adriana I. Figueroa, Vera Marinova, Kevin Garc\'ia D\'iez,
  Aitor Mugarza, Sergio O. Valenzuela, Rodolfo Miranda, Julio Camarero,
  Francisco Guinea, Jose Angel Silva-Guill\'en and Miguel A. Valbuena","Experimental demonstration of a magnetically induced warping transition
  in a topological insulator mediated by rare-earth surface dopants",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Magnetic topological insulators (MTI) constitute a novel class of materials
where the topologically protected band structure coexists with long-range
ferromagnetic order, which can lead to the breaking of time-reversal symmetry
(TRS), introducing a bandgap in the Dirac cone-shaped topological surface state
(TSS). The gap opening in MITs has been predicted to be accompanied by a
distortion in the TSS, evolving its warped shape from hexagonal to trigonal. In
this work, we demonstrate such a transition by means of angle-resolved
photoemission spectroscopy after the deposition of low concentrations of
magnetic rare earths, namely Er and Dy, on the ternary three-dimensional
prototypical topological insulator Bi$_2$Se$_2$Te. Signatures of the gap
opening occurring as a consequence of the TRS breaking have also been observed,
whose existence is supported by the observation of the aforementioned
transition. Moreover, increasing the Er coverage results in a tunable p-type
doping of the TSS. As a consequence, the Fermi level (E$_{\textrm{F}}$) of our
Bi$_2$Se$_2$Te crystals can be gradually tuned towards the TSS Dirac point, and
therefore to the magnetically induced bandgap; thus fulfilling two of the
necessary prerequisites for the realization of the quantum anomalous Hall
effect (QAHE) in this system. The experimental results are rationalized by a
theoretical model where a magnetic Zeeman out-of-plane term is introduced in
the hamiltonian governing the TSS band dispersion. Our results offer new
strategies to control magnetic interactions with TSSs based on a simple
approach and open up viable routes for the realization of the QAHE.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:15:46 GMT""}]","2023-02-06"
"2302.01685","Zurab Aghdgomelashvili","Zurab Aghdgomelashvili","On some interesting tasks from classical theory of numbers",,,,,"math.GM","http://creativecommons.org/licenses/by/4.0/","  Expressions of type $(p^q-1)/(p-1)$ and $a^2+ab+b^2$, where $a, b$ are
natural and $p, q$ are prime numbers, are studied.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:17:45 GMT""}]","2023-02-06"
"2302.01686","Yuchong Zhang","Yuchong Zhang, Yueming Xuan, Rahul Yadav, Adel Omrani, Morten Fjeld","Playing with Data: An Augmented Reality Approach to Interact with
  Visualizations of Industrial Process Tomography",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Industrial process tomography (IPT) is a specialized imaging technique widely
used in industrial scenarios for process supervision and control. Today,
augmented/mixed reality (AR/MR) is increasingly being adopted in many
industrial occasions, even though there is still an obvious gap when it comes
to IPT. To bridge this gap, we propose the first systematic AR approach using
optical see-through (OST) head mounted displays (HMDs) with comparative
evaluation for domain users towards IPT visualization analysis. The
proof-of-concept was demonstrated by a within-subject user study (n=20) with
counterbalancing design. Both qualitative and quantitative measurements were
investigated. The results showed that our AR approach outperformed conventional
settings for IPT data visualization analysis in bringing higher
understandability, reduced task completion time, lower error rates for domain
tasks, increased usability with enhanced user experience, and a better
recommendation level. We summarize the findings and suggest future research
directions for benefiting IPT users with AR/MR.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:19:01 GMT""}]","2023-02-06"
"2302.01687","Ling Pan","Ling Pan, Nikolay Malkin, Dinghuai Zhang, Yoshua Bengio","Better Training of GFlowNets with Local Credit and Incomplete
  Trajectories",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Flow Networks or GFlowNets are related to Monte-Carlo Markov chain
methods (as they sample from a distribution specified by an energy function),
reinforcement learning (as they learn a policy to sample composed objects
through a sequence of steps), generative models (as they learn to represent and
sample from a distribution) and amortized variational methods (as they can be
used to learn to approximate and sample from an otherwise intractable
posterior, given a prior and a likelihood). They are trained to generate an
object $x$ through a sequence of steps with probability proportional to some
reward function $R(x)$ (or $\exp(-\mathcal{E}(x))$ with $\mathcal{E}(x)$
denoting the energy function), given at the end of the generative trajectory.
Like for other RL settings where the reward is only given at the end, the
efficiency of training and credit assignment may suffer when those trajectories
are longer. With previous GFlowNet work, no learning was possible from
incomplete trajectories (lacking a terminal state and the computation of the
associated reward). In this paper, we consider the case where the energy
function can be applied not just to terminal states but also to intermediate
states. This is for example achieved when the energy function is additive, with
terms available along the trajectory. We show how to reparameterize the
GFlowNet state flow function to take advantage of the partial reward already
accrued at each state. This enables a training objective that can be applied to
update parameters even with incomplete trajectories. Even when complete
trajectories are available, being able to obtain more localized credit and
gradients is found to speed up training convergence, as demonstrated across
many simulations.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:19:42 GMT""}]","2023-02-06"
"2302.01688","Andrey Panov","Andrey V. Panov","Optical Kerr nonlinearity of dielectric nanohole array metasurfaces with
  different hole shapes near anapole state",,,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At present, optical anapole resonances in nanostructures have attracted
increasing attention due to the strong field confinement and substantially
suppressed scattering. This study provides the results of three-dimensional
finite-difference time-domain simulations exhibiting the possibility of the
anapole state in high refractive index dielectric nanohole array metasurfaces
having different profiles of the holes (square, hexagon and octagon). Behavior
of the effective optical Kerr nonlinearity of the metasurfaces in the vicinity
of the anapole state is investigated. Depending on the geometry, the absolute
value of the effective nonlinear Kerr coefficient of the metasurface may be up
to three orders of magnitude greater than that of the unstructured film. A
square transverse section of the nanohole is preferable for the optical Kerr
effect in the holey metasurfaces. The effect of the random rotation of the
square holes representing the metasurface irregularity on the optical
nonlinearity is examined.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:31:06 GMT""}]","2023-02-06"
"2302.01689","Leela Elpida Koutsantoniou","Leela Elpida Koutsantoniou","Algorithms and radiation dynamics for the vicinity of black holes. II.
  Results","18 pages, 16 figures, 3 tables, v2: minor restatement of Figure 12
  caption for improvement, v3: minor restatements of Figs. 8, 9, 14 captions,
  improved numbering and placement of Figs. 7, 8, 9",,,,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of our studies on accretion disks in the proximity of
astrophysical black holes. These disks can be of varying degrees of opacity,
geometrical shapes, sizes, and volumes. The central compact object is a
Schwarzschild or a Kerr black hole of various spin parameters. We describe the
environment and the physics of the systems under examination and the disk
models considered. We first investigate the effects of the {spacetime} rotation
on photon trajectories. We then examine the radiation forces recorded at
various points of the arrangement inside and outside the disk material, and in
the inner, outer, and off-equatorial material orbits. We document and explore
the radiation effects, which are revealed to be significant and {positively}
consequential. Afterward, we inspect the possible imaging outcome of various
types of black hole and accretion disk configurations, and we show our results
for plots that could be used to estimate the central black hole spin in a
system. Finally, we show results regarding the disk material orbit degradation
due to its thermal radiation.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:37:13 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 09:43:56 GMT""},{""version"":""v3"",""created"":""Fri, 24 Feb 2023 00:50:13 GMT""}]","2023-02-27"
"2302.01690","Yuchong Zhang","Yuchong Zhang, Adam Nowak, Yueming Xuan, Andrzej Romanowski, Morten
  Fjeld","See or Hear? Exploring the Effect of Visual and Audio Hints and
  Gaze-assisted Task Feedback for Visual Search Tasks in Augmented Reality",,,,,"cs.HC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Augmented reality (AR) is emerging in visual search tasks for increasingly
immersive interactions with virtual objects. We propose an AR approach
providing visual and audio hints along with gaze-assisted instant post-task
feedback for search tasks based on mobile head-mounted display (HMD). The
target case was a book-searching task, in which we aimed to explore the effect
of the hints together with the task feedback with two hypotheses. H1: Since
visual and audio hints can positively affect AR search tasks, the combination
outperforms the individuals. H2: The gaze-assisted instant post-task feedback
can positively affect AR search tasks. The proof-of-concept was demonstrated by
an AR app in HMD and a comprehensive user study (n=96) consisting of two
sub-studies, Study I (n=48) without task feedback and Study II (n=48) with task
feedback. Following quantitative and qualitative analysis, our results
partially verified H1 and completely verified H2, enabling us to conclude that
the synthesis of visual and audio hints conditionally improves the AR visual
search task efficiency when coupled with task feedback.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:37:14 GMT""}]","2023-02-06"
"2302.01691","Hyunjae Kim","Seongyun Lee, Hyunjae Kim, Jaewoo Kang","LIQUID: A Framework for List Question Answering Dataset Generation","AAAI 2023",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Question answering (QA) models often rely on large-scale training datasets,
which necessitates the development of a data generation framework to reduce the
cost of manual annotations. Although several recent studies have aimed to
generate synthetic questions with single-span answers, no study has been
conducted on the creation of list questions with multiple, non-contiguous spans
as answers. To address this gap, we propose LIQUID, an automated framework for
generating list QA datasets from unlabeled corpora. We first convert a passage
from Wikipedia or PubMed into a summary and extract named entities from the
summarized text as candidate answers. This allows us to select answers that are
semantically correlated in context and is, therefore, suitable for constructing
list questions. We then create questions using an off-the-shelf question
generator with the extracted entities and original passage. Finally, iterative
filtering and answer expansion are performed to ensure the accuracy and
completeness of the answers. Using our synthetic data, we significantly improve
the performance of the previous best list QA models by exact-match F1 scores of
5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ
benchmarks.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:42:45 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 08:04:56 GMT""}]","2023-02-07"
"2302.01692","Eduardo de Rafael","David Greynat and Eduardo de Rafael","On the Time Momentum Representation of Hadronic Vacuum Polarization and
  $\boldsymbol{g_{\mu}-2}$","28 pages, 13 figures, 2 tables. A new paragraph added in section 5.2
  . Version published in JHEP",,"10.1007/JHEP03(2023)248",,"hep-ph hep-lat","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a new set of model independent approximants adapted to the time
momentum representation (TMR) of hadronic vacuum polarization (HVP) and its
contribution to $g_{\mu}-2$. They provide a way to extrapolate lattice QCD
(LQCD) results obtained in an optimal time-region, to the full range required
for an evaluation of the HVP contribution to $g_{\mu}-2$. They offer as well a
new way to confront LQCD results in restricted TMR regions, with the full
contribution obtained from data driven determinations.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:45:40 GMT""},{""version"":""v2"",""created"":""Fri, 14 Apr 2023 08:22:00 GMT""}]","2023-04-19"
"2302.01693","Esther Denecke","Esther Denecke and Pavel Grigoriev and Roland Rau","Evaluation of small-area estimation methods for mortality schedules",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mortality patterns at a subnational level or across subpopulations are often
used to examine the health of a population. In small populations, however,
death counts are erratic. To deal with this problem, demographers have proposed
different methods but it is unclear how these methods relate to each other. We
aim to provide guidance. First, we review recent demographic small-area methods
for mortality schedules. Second, we evaluate three methodological approaches
using simulated data. We show that there is considerable variability in the
performance across ages and subpopulations/regions and that this performance
can depend on the choice of incorporated demographic knowledge.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:45:47 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 21:37:37 GMT""}]","2023-03-21"
"2302.01694","Larry Bull","Larry Bull","Coevolving Boolean and Multi-Valued Regulatory Networks","arXiv admin note: text overlap with arXiv:2102.11667",,,,"q-bio.MN cs.NE","http://creativecommons.org/licenses/by/4.0/","  Random Boolean networks have been used widely to explore aspects of gene
regulatory networks. A modified form of the model through which to
systematically explore the effects of increasing the number of gene states has
previously been introduced. In this paper, these discrete dynamical networks
are coevolved within coupled, rugged fitness landscapes to explore their
behaviour. Results suggest the general properties of the Boolean model remain
with higher valued logic regardless of the update scheme or fitness sampling
method. Introducing topological asymmetry in the coevolving networks is seen to
alter behaviour.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:48:33 GMT""}]","2023-02-06"
"2302.01695","Jan N\""oller","Jan N\""oller, Otfried G\""uhne, Mariami Gachechiladze","Symmetric hypergraph states: Entanglement quantification and robust Bell
  nonlocality","39 pages, 4 figures, comments welcome",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum hypergraph states are the natural generalization of graph states.
Here we investigate and analytically quantify entanglement and nonlocality for
large classes of quantum hypergraph states. More specifically, we connect the
geometric measure of entanglement of symmetric hypergraphs to their local Pauli
stabilizers. As a result we recognize the resemblance between symmetric graph
states and symmetric hypergraph states, which explains both, exponentially
increasing violation of local realism for infinitely many classes of hypergraph
states and its robustness towards particle loss.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:49:32 GMT""}]","2023-02-06"
"2302.01696","Qi Wu","Qi Wu, Yan-Ke Chen, Gang Li, Shi-Dong Liu and Dian-Yong Chen","Hunting for the hidden-charm molecular states with strange quark in $B$
  and $B_s$ decays","12 pages, 4 figures and 6 tables, accepted by Phys. Rev. D",,,,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  In the present work, we investigate the productions of the molecular states
composed of $D^{(*)}_s \bar{D}^{(*)}$ and $D^{(*)}_s \bar{D}^{(*)}_s$ in the
$B$ and $B_s$ decays by using an effective Lagrangian approach. The branching
ratios in terms of the model parameter $\alpha$ and the binding energy $\Delta
E$ are estimated. Our estimations indicate that the branching fractions are of
the order of $10^{-4}$ and the relative ratios are very weakly dependent on the
model parameter $\alpha$ and the binding energy $\Delta E$. The predicted
ratios are helpful for searching the hidden-charm molecular states with strange
quark in the future experiments at Belle II and LHCb.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:51:04 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 02:58:01 GMT""}]","2023-03-20"
"2302.01697","Ke Xu","Jie Hu, Ke Xu, Luping Xiang and Kun Yang","Orthogonal-Time-Frequency-Space Signal Design for Integrated Data and
  Energy Transfer: Benefits from Doppler Offsets",,,"10.1109/LWC.2023.3239742",,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Integrated data and energy transfer (IDET) is an advanced technology for
enabling energy sustainability for massively deployed low-power electronic
consumption components. However, the existing work of IDET using the
orthogonal-frequency-division-multiplexing (OFDM) waveforms is designed for
static scenarios, which would be severely affected by the destructive Doppler
offset in high-mobility scenarios. Therefore, we proposed an IDET system based
on orthogonal-time-frequency-space (OTFS) waveforms with the imperfect channel
assumption, which is capable of counteracting the Doppler offset in
high-mobility scenarios. At the transmitter, the OTFS-IDET system superimposes
the random data signals and deterministic energy signals in the delay-Doppler
(DD) domain with optimally designed amplitudes. The receiver optimally splits
the received signal in the power domain for achieving the best IDET
performance. After formulating a non-convex optimisation problem, it is
transformed into a geometric programming (GP) problem through inequality
relaxations to obtain the optimal solution. The simulation demonstrates that a
higher amount of energy can be harvested when employing our proposed OTFS-IDET
waveforms than the conventional OFDM-IDET ones in high mobility scenarios.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:51:16 GMT""}]","2023-02-06"
"2302.01698","Marta De Le\'on-Contreras","Jorge J. Betancor and Marta De Le\'on-Contreras","Variation and oscillation for semigroups associated with discrete Jacobi
  operators",,,,,"math.CA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove weighted $\ell^p$-inequalities for variation and
oscillation operators defined by semigroups of operators associated with
discrete Jacobi operators. Also, we establish that certain maximal operators
involving sums of differences of discrete Jacobi semigroups are bounded on
weighted $\ell^p$-spaces. $\ell^p$-boundedness properties for the considered
operators provide information about the convergence of the semigroup of
operators defining them.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:52:29 GMT""}]","2023-02-06"
"2302.01699","Shuo Liu","Shuo Liu, Hui Wang, Annie-Claude Bayeul-Lain\'e, Cheng Li, Joseph
  Katz, Olivier Coutier-Delgosha","Wave Statistics and Energy Dissipation of Breaking Waves Generated by a
  Wave Plate",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The present study focuses on direct numerical simulations of breaking waves
generated by a wave plate at constant water depths. The aim is to quantify the
dynamics and kinematics in the breaking process, together with the air
entrainment and energy dissipation due to breaking. Good agreement is achieved
between numerical and experimental results in terms of free-surface profiles,
energy budget, and bubble statistics during wave breaking. A parametric study
was conducted to examine the effects of wave properties and initial conditions
on breaking features. According to research on the Bond number ($Bo$, the ratio
of gravitational to surface tension forces), a larger surface tension produces
more significant parasitic capillaries at the forward face of the wave profile
and a thicker plunging jet, which causes a delayed breaking time and is tightly
correlated with the main cavity size. A close relationship between wave
statistics and the initial conditions of the wave plate is discovered, showing
that breaker types can be classified according to the ratio of wave height to
water depth, $H/d$. Moreover, the energy dissipation rate due to breaking can
be related to the initial conditions of the wave plate by applying the
conventional dissipation scaling of turbulence theory, and further correlated
with the local breaking crest geometry using inertial-scaling arguments. The
proposed scaling of the dissipation rate during the active breaking period is
found to be in good agreement with our numerical results.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:54:47 GMT""}]","2023-02-06"
"2302.01700","Shanwen Tan","Shanwen Tan (School of Architecture and Civil Engineering, Xihua
  University, China)","A new turbulence model based on scale decomposition","13 pages 9 figures",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the characteristics of the multi-scale and similarity at different
scales in turbulent flow, we propose a scale decomposition for solving the
turbulence problem of incompressible Newtonian fluid. The solution domain is
decomposed into two-level scales, the large scale component represents mean
flow and large scale eddies, and the small scale one represents the turbulent
fluctuations. The problem is solved in large scale by the equations of motion
and the effect of the turbulent fluctuations on the mean flow is evaluated
approximately by using equivalent eddy. Furthermore, the effect of equivalent
eddy is decomposed into two parts including convective effect and diffusion
effect, which is expressed as a function of mean quantities in large scale. The
modified Naiver-Stokes equations are established, there ensures the closure of
the equations in large scale. Finally, the modified Naiver-Stokes equations is
verified by the numerical simulation. Flow around cylinder is numerically
investigated and able to obtain flow behavior from low to high Reynolds
numbers. A general-purpose turbulence model is established in this study, which
is worthy of engineering application.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:55:03 GMT""}]","2023-02-21"
"2302.01701","Daniele Zambon","Daniele Zambon, Cesare Alippi","Where and How to Improve Graph-based Spatio-temporal Predictors",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a novel residual correlation analysis, called
AZ-analysis, to assess the optimality of spatio-temporal predictive models. The
proposed AZ-analysis constitutes a valuable asset for discovering and
highlighting those space-time regions where the model can be improved with
respect to performance. The AZ-analysis operates under very mild assumptions
and is based on a spatio-temporal graph that encodes serial and functional
dependencies in the data; asymptotically distribution-free summary statistics
identify existing residual correlation in space and time regions, hence
localizing time frames and/or communities of sensors, where the predictor can
be improved.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:55:08 GMT""}]","2023-02-06"
"2302.01702","Emil Knudstrup","Emil Knudstrup, Simon H. Albrecht, Davide Gandolfi, Marcus L.
  Marcussen, Elisa Goffo, Luisa M. Serrano, Fei Dai, Seth Redfield, Teruyuki
  Hirano, Szil\'ard Csizmadia, William D. Cochran, Hans J. Deeg, Malcolm
  Fridlund, Kristine W. F. Lam, John H. Livingston, Rafael Luque, Norio Narita,
  Enric Palle, Carina M. Persson, and Vincent Van Eylen","The low density, hot Jupiter TOI-640 b is on a polar orbit","15 pages, 12 figures, accepted for publication in A&A, in press","A&A 671, A164 (2023)","10.1051/0004-6361/202245301",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  TOI-640 b is a hot, puffy Jupiter with a mass of $0.57 \pm 0.02$ M$_{\rm J}$
and radius of $1.72 \pm 0.05$ R$_{\rm J}$, orbiting a slightly evolved F-type
star with a separation of $6.33^{+0.07}_{-0.06}$ R$_\star$. Through
spectroscopic in-transit observations made with the HARPS spectrograph, we
measured the Rossiter-McLaughlin effect, analysing both in-transit radial
velocities and the distortion of the stellar spectral lines. From these
observations, we find the host star to have a projected obliquity of
$\lambda=184\pm3^\circ$. From the TESS light curve, we measured the stellar
rotation period, allowing us to determine the stellar inclination,
$i_\star=23^{+3\circ}_{-2}$, meaning we are viewing the star pole-on. Combining
this with the orbital inclination allowed us to calculate the host star
obliquity, $\psi=104\pm2^\circ$. TOI-640 b joins a group of planets orbiting
over stellar poles within the range $80^\circ-125^\circ$. The origin of this
orbital configuration is not well understood.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:58:53 GMT""}]","2023-03-29"
"2302.01703","Tony Han","Fuzhang Han, Han Zheng, Wenjun Huang, Rong Xiong, Yue Wang, Yanmei
  Jiao","DAMS-LIO: A Degeneration-Aware and Modular Sensor-Fusion LiDAR-inertial
  Odometry",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With robots being deployed in increasingly complex environments like
underground mines and planetary surfaces, the multi-sensor fusion method has
gained more and more attention which is a promising solution to state
estimation in the such scene. The fusion scheme is a central component of these
methods. In this paper, a light-weight iEKF-based LiDAR-inertial odometry
system is presented, which utilizes a degeneration-aware and modular
sensor-fusion pipeline that takes both LiDAR points and relative pose from
another odometry as the measurement in the update process only when
degeneration is detected. Both the Cramer-Rao Lower Bound (CRLB) theory and
simulation test are used to demonstrate the higher accuracy of our method
compared to methods using a single observation. Furthermore, the proposed
system is evaluated in perceptually challenging datasets against various
state-of-the-art sensor-fusion methods. The results show that the proposed
system achieves real-time and high estimation accuracy performance despite the
challenging environment and poor observations.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:01:55 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 14:09:06 GMT""},{""version"":""v3"",""created"":""Thu, 23 Mar 2023 06:02:59 GMT""}]","2023-03-24"
"2302.01704","Ismail Nejjar","Ismail Nejjar, Fabian Geissmann, Mengjie Zhao, Cees Taal, Olga Fink","Domain Adaptation via Alignment of Operation Profile for Remaining
  Useful Lifetime Prediction","18 pages,11 figures",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Effective Prognostics and Health Management (PHM) relies on accurate
prediction of the Remaining Useful Life (RUL). Data-driven RUL prediction
techniques rely heavily on the representativeness of the available
time-to-failure trajectories. Therefore, these methods may not perform well
when applied to data from new units of a fleet that follow different operating
conditions than those they were trained on. This is also known as domain
shifts. Domain adaptation (DA) methods aim to address the domain shift problem
by extracting domain invariant features. However, DA methods do not distinguish
between the different phases of operation, such as steady states or transient
phases. This can result in misalignment due to under- or over-representation of
different operation phases. This paper proposes two novel DA approaches for RUL
prediction based on an adversarial domain adaptation framework that considers
the different phases of the operation profiles separately. The proposed
methodologies align the marginal distributions of each phase of the operation
profile in the source domain with its counterpart in the target domain. The
effectiveness of the proposed methods is evaluated using the New Commercial
Modular Aero-Propulsion System (N-CMAPSS) dataset, where sub-fleets of turbofan
engines operating in one of the three different flight classes (short, medium,
and long) are treated as separate domains. The experimental results show that
the proposed methods improve the accuracy of RUL predictions compared to
current state-of-the-art DA methods.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:02:27 GMT""}]","2023-02-06"
"2302.01705","Peter Gladbach","Peter Gladbach and Heiner Olbermann","Consistent and convergent discretizations of Helfrich-type energies on
  general meshes",,,,,"math.AP cs.NA math.DG math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that integral curvature energies on surfaces of the type $E_0(M) :=
\int_M f(x,n_M(x),D n_M(x))\,d\mathcal{H}^2(x)$ have discrete versions for
triangular complexes, where the shape operator $D n_M$ is replaced by the
piecewise gradient of a piecewise affine edge director field. We combine an
ansatz-free asymptotic lower bound for any uniform approximation of a surface
with triangular complexes and a recovery sequence consisting of any regular
triangulation of the limit sequence and an almost optimal choice of edge
director.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:02:30 GMT""}]","2023-02-06"
"2302.01706","Zilong Zhao","Zilong Zhao, Han Wu, Aad Van Moorsel and Lydia Y. Chen","GTV: Generating Tabular Data via Vertical Federated Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative Adversarial Networks (GANs) have achieved state-of-the-art results
in tabular data synthesis, under the presumption of direct accessible training
data. Vertical Federated Learning (VFL) is a paradigm which allows to
distributedly train machine learning model with clients possessing unique
features pertaining to the same individuals, where the tabular data learning is
the primary use case. However, it is unknown if tabular GANs can be learned in
VFL. Demand for secure data transfer among clients and GAN during training and
data synthesizing poses extra challenge. Conditional vector for tabular GANs is
a valuable tool to control specific features of generated data. But it contains
sensitive information from real data - risking privacy guarantees. In this
paper, we propose GTV, a VFL framework for tabular GANs, whose key components
are generator, discriminator and the conditional vector. GTV proposes an unique
distributed training architecture for generator and discriminator to access
training data in a privacy-preserving manner. To accommodate conditional vector
into training without privacy leakage, GTV designs a mechanism
training-with-shuffling to ensure that no party can reconstruct training data
with conditional vector. We evaluate the effectiveness of GTV in terms of
synthetic data quality, and overall training scalability. Results show that GTV
can consistently generate high-fidelity synthetic tabular data of comparable
quality to that generated by centralized GAN algorithm. The difference on
machine learning utility can be as low as to 2.7%, even under extremely
imbalanced data distributions across clients and different number of clients.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:04:12 GMT""}]","2023-02-06"
"2302.01707","Thomas Durieux","Thomas Durieux","Parfum: Detection and Automatic Repair of Dockerfile Smells",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Docker is a popular tool for developers and organizations to package, deploy,
and run applications in a lightweight, portable container. One key component of
Docker is the Dockerfile, a simple text file that specifies the steps needed to
build a Docker image. While Dockerfiles are easy to create and use, creating an
optimal image is complex in particular since it is easy to not follow the best
practices, when it happens we call it Docker smell. To improve the quality of
Dockerfiles, previous works have focused on detecting Docker smells, but they
do not offer suggestions or repair the smells. In this paper, we propose,
Parfum, a tool that detects and automatically repairs Docker smells while
producing minimal patches. Parfum is based on a new Dockerfile AST parser
called Dinghy. We evaluate the effectiveness of Parfum by analyzing and
repairing a large set of Dockerfiles and comparing it against existing tools.
We also measure the impact of the repair on the Docker image in terms of build
failure and image size. Finally, we opened 35 pull requests to collect
developers' feedback and ensure that the repairs and the smells are meaningful.
Our results show that Parfum is able to repair 806 245 Docker smells and have a
significant impact on the Docker image size, and finally, developers are
welcoming the patches generated by Parfum while merging 20 pull requests.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:04:47 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 15:05:28 GMT""}]","2023-02-10"
"2302.01708","Yumin Zhang","Yumin Zhang, Yajun Gao, Hongliu Li, Ating Yin, Duzhen Zhang, Xiuyi
  Chen","Crucial Semantic Classifier-based Adversarial Learning for Unsupervised
  Domain Adaptation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised Domain Adaptation (UDA), which aims to explore the transferrable
features from a well-labeled source domain to a related unlabeled target
domain, has been widely progressed. Nevertheless, as one of the mainstream,
existing adversarial-based methods neglect to filter the irrelevant semantic
knowledge, hindering adaptation performance improvement. Besides, they require
an additional domain discriminator that strives extractor to generate confused
representations, but discrete designing may cause model collapse. To tackle the
above issues, we propose Crucial Semantic Classifier-based Adversarial Learning
(CSCAL), which pays more attention to crucial semantic knowledge transferring
and leverages the classifier to implicitly play the role of domain
discriminator without extra network designing. Specifically, in
intra-class-wise alignment, a Paired-Level Discrepancy (PLD) is designed to
transfer crucial semantic knowledge. Additionally, based on classifier
predictions, a Nuclear Norm-based Discrepancy (NND) is formed that considers
inter-class-wise information and improves the adaptation performance. Moreover,
CSCAL can be effortlessly merged into different UDA methods as a regularizer
and dramatically promote their performance.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:06:14 GMT""}]","2023-02-06"
"2302.01709","Daniela Gaul","Hayk Asatryan, Daniela Gaul, Hanno Gottschalk, Kathrin Klamroth,
  Michael Stiglmayr","Ridepooling and public bus services: A comparative case-study",,,,,"cs.DM cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This case-study aims at a comparison of the service quality of time-tabled
buses as compared to on-demand ridepooling cabs in the late evening hours in
the city of Wuppertal, Germany. To evaluate the efficiency of ridepooling as
compared to bus services, and to simulate bus rides during the evening hours,
transport requests are generated using a predictive simulation. To this end, a
framework in the programming language R is created, which automatedly combines
generalized linear models for count regression to model the demand at each bus
stop. Furthermore, we use classification models for the prediction of trip
destinations. To solve the resulting dynamic dial-a-ride problem, a
rolling-horizon algorithm based on the iterative solution of Mixed-Integer
Linear Programming Models (MILP) is used. A feasible-path heuristic is used to
enhance the performance of the algorithm in presence of high request densities.
This allows an estimation of the number of cabs needed depending on the weekday
to realize the same or a better general service quality as the bus system.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:07:01 GMT""}]","2023-02-06"
"2302.01710","Tapas Mondal","Tapas Mondal, Akshay Kumar Ojha, Sabyasachi Pani","Geometric Programming Problems with Triangular and Trapezoidal Two-fold
  Uncertainty Distributions",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Geometric programming (GP) is a well-known optimization tool for dealing with
a wide range of nonlinear optimization and engineering problems. In general, it
is assumed that the parameters of a GP problem are deterministic and accurate.
However, in the real-world GP problem, the parameters are frequently inaccurate
and ambiguous. This paper investigates the GP problem in an uncertain
environment, with the coefficients as triangular and trapezoidal two-fold
uncertain variables. In this paper, we introduce uncertain measures in a
generalized version and focus on more complicated two-fold uncertainties to
propose triangular and trapezoidal two-fold uncertain variables within the
context of uncertainty theory. We develop three reduction methods to convert
triangular and trapezoidal two-fold uncertain variables into single-fold
uncertain variables using optimistic, pessimistic, and expected value criteria.
Reduction methods are used to convert the GP problem with two-fold uncertainty
into the GP problem with single-fold uncertainty. Furthermore, the
chance-constrained uncertain-based framework is used to solve the reduced
single-fold uncertain GP problem. Finally, a numerical example is provided to
demonstrate the effectiveness of the procedures.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:07:23 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 06:16:17 GMT""}]","2023-02-10"
"2302.01711","Huanchao Zhou","Huanchao Zhou, Jiang Hu, Zhidong Bai, Jack W. Silverstein","Analysis of the limiting spectral distribution of large dimensional
  General information-plus-noise type matrices",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we derive the analytical behavior of the limiting spectral
distribution of non-central covariance matrices of the ""general
information-plus-noise"" type, as studied in [14]. Through the equation defining
its Stieltjes transform, it is shown that the limiting distribution has a
continuous derivative away from zero, the derivative being analytic wherever it
is positive, and we show the determination criterion for its support. We also
extend the result in [14] to allow for all possible ratios of row to column of
the underlying random matrix.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:08:06 GMT""}]","2023-02-06"
"2302.01712","William Li","William F. Li, Gaurav Arya, Charles Roques-Carmes, Zin Lin, Steven G.
  Johnson, Marin Solja\v{c}i\'c","Transcending shift-invariance in the paraxial regime via end-to-end
  inverse design of freeform nanophotonics",,,,,"physics.optics eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditional optical elements and conventional metasurfaces obey
shift-invariance in the paraxial regime. For imaging systems obeying paraxial
shift-invariance, a small shift in input angle causes a corresponding shift in
the sensor image. Shift-invariance has deep implications for the design and
functionality of optical devices, such as the necessity of free space between
components (as in compound objectives made of several curved surfaces). We
present a method for nanophotonic inverse design of compact imaging systems
whose resolution is not constrained by paraxial shift-invariance. Our method is
end-to-end, in that it integrates density-based full-Maxwell topology
optimization with a fully iterative elastic-net reconstruction algorithm. By
the design of nanophotonic structures that scatter light in a
non-shift-invariant manner, our optimized nanophotonic imaging system overcomes
the limitations of paraxial shift-invariance, achieving accurate, noise-robust
image reconstruction beyond shift-invariant resolution.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:09:24 GMT""}]","2023-02-06"
"2302.01713","Niklas K\""uhl Prof Dr","Jan Bode, Niklas K\""uhl, Dominik Kreuzberger, Sebastian Hirschl,
  Carsten Holtmann","Data Mesh: Motivational Factors, Challenges, and Best Practices",,,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  With the increasing importance of data and artificial intelligence,
organizations strive to become more data-driven. However, current data
architectures are not necessarily designed to keep up with the scale and scope
of data and analytics use cases. In fact, existing architectures often fail to
deliver the promised value associated with them. Data mesh is a socio-technical
concept that includes architectural aspects to promote data democratization and
enables organizations to become truly data-driven. As the concept of data mesh
is still novel, it lacks empirical insights from the field. Specifically, an
understanding of the motivational factors for introducing data mesh, the
associated challenges, best practices, its business impact, and potential
archetypes, is missing. To address this gap, we conduct 15 semi-structured
interviews with industry experts. Our results show, among other insights, that
industry experts have difficulties with the transition toward federated
governance associated with the data mesh concept, the shift of responsibility
for the development, provision, and maintenance of data products, and the
concept of a data product model. In our work, we derive multiple best practices
and suggest organizations embrace elements of data fabric, observe the data
product usage, create quick wins in the early phases, and favor small dedicated
teams that prioritize data products. While we acknowledge that organizations
need to apply best practices according to their individual needs, we also
deduct two archetypes that provide suggestions in more detail. Our findings
synthesize insights from industry experts and provide researchers and
professionals with guidelines for the successful adoption of data mesh.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:09:57 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 19:43:27 GMT""}]","2023-04-07"
"2302.01714","Rick Fritschek","Muah Kim, Rick Fritschek, Rafael F. Schaefer","Learning End-to-End Channel Coding with Diffusion Models","6 pages, WSA/SCC 2023",,,,"cs.IT cs.LG math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is a known problem that deep-learning-based end-to-end (E2E) channel
coding systems depend on a known and differentiable channel model, due to the
learning process and based on the gradient-descent optimization methods. This
places the challenge to approximate or generate the channel or its derivative
from samples generated by pilot signaling in real-world scenarios. Currently,
there are two prevalent methods to solve this problem. One is to generate the
channel via a generative adversarial network (GAN), and the other is to, in
essence, approximate the gradient via reinforcement learning methods. Other
methods include using score-based methods, variational autoencoders, or
mutual-information-based methods. In this paper, we focus on generative models
and, in particular, on a new promising method called diffusion models, which
have shown a higher quality of generation in image-based tasks. We will show
that diffusion models can be used in wireless E2E scenarios and that they work
as good as Wasserstein GANs while having a more stable training procedure and a
better generalization ability in testing.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:11:57 GMT""}]","2023-02-06"
"2302.01715","Christian Brand","Christian Brand (1), Alfred Hucht (1 and 2), Giriraj Jnawali (1),
  Jonas D. Fortmann (1), Bj\""orn Sothmann (1 and 2), Hamid Mehdipour (1), Peter
  Kratzer (1 and 2), Ralf Sch\""utzhold (3 and 4), Michael Horn-von Hoegen (1
  and 2) ((1) Faculty of Physics, University of Duisburg-Essen, 47057 Duisburg,
  Germany, (2) Center for Nanointegration (CENIDE), University of
  Duisburg-Essen, 47057 Duisburg, Germany, (3) Institute of Theoretical
  Physics, Dresden University of Technology, 01062 Dresden, Germany, (4)
  Helmholtz-Zentrum Dresden-Rossendorf, 01328 Dresden, Germany)","Dimer Coupling Energies of the Si(001) Surface","Accepted for publication at Physical Review Letters on 02Feb23",,"10.1103/PhysRevLett.130.126203",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The coupling energies between the buckled dimers of the Si(001) surface were
determined through analysis of the anisotropic critical behavior of its
order-disorder phase transition. Spot profiles in high-resolution low-energy
electron diffraction as a function of temperature were analyzed within the
framework of the anisotropic two-dimensional Ising model. The validity of this
approach is justified by the large ratio of correlation lengths,
$\xi_\parallel^+/\xi_\perp^+ = 5.2$ of the fluctuating $c(4 {\times} 2)$
domains above the critical temperature $T_\mathrm{c} = (190.6 \pm 10)$ K. We
obtain effective couplings $J_\parallel = (-24.9 \pm 1.3)$ meV along the dimer
rows and $J_\perp = (-0.8 \pm 0.1)$ meV across the dimer rows, i.e.,
antiferromagnetic-like coupling of the dimers with $c(4 {\times} 2)$ symmetry.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:13:01 GMT""}]","2023-04-05"
"2302.01716","Ehsan Khalili","Ehsan Khalili, C'ecile Daversin-Catty, Andy L. Olivares, Jordi Mill,
  Oscar Camara, Kristian Valen-Sendstad","On The Importance of Fundamental Computational Fluid Dynamics Towards a
  Robust and Reliable Model of Left Atrial Flows: Is There More Than Meets the
  Eye?","24 pages, 14 figures, journal paper",,,,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational fluid dynamics (CFD) studies of left atrial flows have reached
a sophisticated level, e.g., revealing plausible relationships between
hemodynamics and stresses with atrial fibrillation. However, little focus has
been on fundamental fluid modelling of LA flows. The purpose of this study was
to investigate the spatiotemporal convergence, along with the differences
between high- (HR) versus normal-resolution/accuracy (NR) solution strategies,
respectively. CFD simulations on 12 patient-specific left atrial geometries,
obtained from computed tomography scans, were performed by using a second-order
accurate and space/time centered solver. The convergence studies showed an
average variability of around 30\% and 55\% for time averaged wall shear stress
(WSS), oscillatory shear index (OSI), relative residence time (RRT), and
endothelial cell activation potential (ECAP), even between intermediate spatial
and temporal resolutions, in the left atrium (LA) and left atrial appendage
(LAA), respectively. The comparison between HR and NR simulations showed good
correlation in the LA for WSS, RRT, and ECAP (R^2 > 0.9), but not for OSI (R^2
= 0.63). However, there were poor correlations in the LAA especially for OSI,
RRT, and ECAP (R^2 = 0.55, 0.63, and 0.61, respectively), except for WSS (R^2 =
0.81). The errors are comparable to differences previously reported with
disease correlations. To robustly predict atrial hemodynamics and stresses,
numerical resolutions of 10M elements and 10k time-steps per cycle seem
necessary (i.e., one order of magnitude higher than normally used in both space
and time). In conclusion, attention to fundamental numerical aspects is
essential towards establishing a plausible, robust, and reliable model of LA
flows.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:13:18 GMT""}]","2023-02-06"
"2302.01717","Stephan Baier","Stephan Baier and Esrafil Ali Molla","Diophantine approximation with prime denominator in real quadratic
  function fields","27 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the thirties of the last century, I. M. Vinogradov proved that the
inequality $||p\alpha||\le p^{-1/5+\varepsilon}$ has infinitely prime solutions
$p$, where $||.||$ denotes the distance to a nearest integer. This result has
subsequently been improved by many authors. In particular, Vaughan (1978)
replaced the exponent $1/5$ by $1/4$ using his celebrated identity for the von
Mangoldt function and a refinement of Fourier analytic arguments. The current
record is due to Matom\""aki (2009) who showed the infinitude of prime solutions
of the inequality $||p\alpha||\le p^{-1/3+\varepsilon}$. This exponent $1/3$ is
considered the limit of the current technology. Recently, in \cite{BaMo}, the
authors established an analogue of Matom\""aki's result for imaginary quadratic
extensions of the function field $k=\mathbb{F}_q(T)$. In this paper, we
consider the case of real quadratic extensions of $k$ of class number 1, for
which we prove a function field analogue of Vaughan's above-mentioned result
(exponent $\theta=1/4$). Our method uses versions of Vaughan's identity and the
Dirichlet approximation theorem for function fields. The latter was established
by Arijit Ganguly in the appendix to our previous paper \cite{BaMo} on the
imaginary quadratic case. We also simplify arguments in the paper \cite{BM} on
the same problem for real quadratic number fields by D. Mazumder and the
first-named author.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:13:54 GMT""}]","2023-02-06"
"2302.01718","Zhi-Gang Wang","Xiao-Song Yang, Qi Xin, Zhi-Gang Wang","Analysis of the $T_{c\bar{s}}(2900)$ and related tetraquark states with
  the QCD sum rules","20 pages, 7 figures",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this research, we tentatively assign the $T_{c\bar{s}}(2900)$ as the
$A\bar{A}$-type tetraquark state, and study the mass spectrum of the tetraquark
states with strange and doubly strange, which have the spin-parity $J^P = 0^+$,
$1^+$ and $2^+$, in the framework of the QCD sum rules in details, where the
$A$ denotes the axialvector diquark state. The predicted mass
$M=2.92\pm0.12\,\rm{GeV}$ is in consistent with the experimental values
$M=2.892\pm0.014\pm0.015\,\rm{GeV}$ and $2.921\pm0.017\pm0.020\,\rm{GeV}$ from
the LHCb collaboration and supports assigning the $T_{c\bar{s}}(2900)$ to be
the $A\bar{A}$-type scalar $c\bar{s}q\bar{q}$ tetraquark state. The predictions
for other tetraquark states can be confronted to the experimental data in the
future to diagnose the nature of the fully open flavor exotic states.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:14:43 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 13:45:41 GMT""}]","2023-04-18"
"2302.01719","Yang-Hao Chan","Y.-H. Chan, Diana Y. Qiu, Felipe H. da Jornada, and Steven G. Louie","Giant self-driven exciton-Floquet signatures in time-resolved
  photoemission spectroscopy of MoS$_2$ from time-dependent GW approach","11 pages, 4 figures",,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Time-resolved, angle-resolved photoemission spectroscopy (TR-ARPES) is a
one-particle spectroscopic technique that can probe excitons (two-particle
excitations) in momentum space. We present an ab initio, time-domain GW
approach to TR-ARPES and apply it to monolayer MoS$_2$. We show that
photoexcited excitons may be measured and quantified as satellite bands, as
well as leading to the renormalization of the quasiparticle bands. These
features are explained in terms of an exciton- Floquet phenomenon induced by an
exciton time-dependent bosonic field, which is orders of magnitude stronger
than laser field induced Floquet bands in low-dimensional semiconductors. Our
findings open a door to understanding the behavior of optical-field driven
materials.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:15:29 GMT""}]","2023-02-06"
"2302.01720","Antonio Bueno","Antonio Bueno, Rafael L\'opez","Compact surfaces with boundary with prescribed mean curvature depending
  on the Gauss map",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a $C^1$ function $\mathcal{H}$ defined in the unit sphere
$\mathbb{S}^2$, an $\mathcal{H}$-surface $M$ is a surface in the Euclidean
space $\mathbb{R}^3$ whose mean curvature $H_M$ satisfies
$H_M(p)=\mathcal{H}(N_p)$, $p\in M$, where $N$ is the Gauss map of $M$. Given a
closed simple curve $\Gamma\subset\mathbb{R}^3$ and a function $\mathcal{H}$,
in this paper we investigate the geometry of compact $\mathcal{H}$-surfaces
spanning $\Gamma$ in terms of $\Gamma$. Under mild assumptions on
$\mathcal{H}$, we prove non-existence of closed $\mathcal{H}$-surfaces, in
contrast with the classical case of constant mean curvature. We give conditions
on $\mathcal{H}$ that ensure that if $\Gamma$ is a circle, then $M$ is a
rotational surface. We also establish the existence of estimates of the area of
$\mathcal{H}$-surfaces in terms of the height of the surface.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:18:33 GMT""}]","2023-02-06"
"2302.01721","Elad Richardson","Elad Richardson, Gal Metzer, Yuval Alaluf, Raja Giryes, Daniel
  Cohen-Or","TEXTure: Text-Guided Texturing of 3D Shapes","Project page available at
  https://texturepaper.github.io/TEXTurePaper/",,,,"cs.CV cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present TEXTure, a novel method for text-guided generation,
editing, and transfer of textures for 3D shapes. Leveraging a pretrained
depth-to-image diffusion model, TEXTure applies an iterative scheme that paints
a 3D model from different viewpoints. Yet, while depth-to-image models can
create plausible textures from a single viewpoint, the stochastic nature of the
generation process can cause many inconsistencies when texturing an entire 3D
object. To tackle these problems, we dynamically define a trimap partitioning
of the rendered image into three progression states, and present a novel
elaborated diffusion sampling process that uses this trimap representation to
generate seamless textures from different views. We then show that one can
transfer the generated texture maps to new 3D geometries without requiring
explicit surface-to-surface mapping, as well as extract semantic textures from
a set of images without requiring any explicit reconstruction. Finally, we show
that TEXTure can be used to not only generate new textures but also edit and
refine existing textures using either a text prompt or user-provided scribbles.
We demonstrate that our TEXTuring method excels at generating, transferring,
and editing textures through extensive evaluation, and further close the gap
between 2D image generation and 3D texturing.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:18:45 GMT""}]","2023-02-06"
"2302.01722","Bowen Tian","Bowen Tian, Qinliang Su, Jianxing Yu","Leveraging Contaminated Datasets to Learn Clean-Data Distribution with
  Purified Generative Adversarial Networks",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generative adversarial networks (GANs) are known for their strong abilities
on capturing the underlying distribution of training instances. Since the
seminal work of GAN, many variants of GAN have been proposed. However, existing
GANs are almost established on the assumption that the training dataset is
clean. But in many real-world applications, this may not hold, that is, the
training dataset may be contaminated by a proportion of undesired instances.
When training on such datasets, existing GANs will learn a mixture distribution
of desired and contaminated instances, rather than the desired distribution of
desired data only (target distribution). To learn the target distribution from
contaminated datasets, two purified generative adversarial networks (PuriGAN)
are developed, in which the discriminators are augmented with the capability to
distinguish between target and contaminated instances by leveraging an extra
dataset solely composed of contamination instances. We prove that under some
mild conditions, the proposed PuriGANs are guaranteed to converge to the
distribution of desired instances. Experimental results on several datasets
demonstrate that the proposed PuriGANs are able to generate much better images
from the desired distribution than comparable baselines when trained on
contaminated datasets. In addition, we also demonstrate the usefulness of
PuriGAN on downstream applications by applying it to the tasks of
semi-supervised anomaly detection on contaminated datasets and PU-learning.
Experimental results show that PuriGAN is able to deliver the best performance
over comparable baselines on both tasks.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:18:52 GMT""}]","2023-02-06"
"2302.01723","Z\'ephyr Salvy","William Fleurat and Z\'ephyr Salvy","A phase transition in block-weighted random maps","59 pages, 14 figures",,,,"math.PR math.CO","http://creativecommons.org/licenses/by/4.0/","  We consider the model of random planar maps of size $n$ biased by a weight
$u>0$ per $2$-connected block, and the closely related model of random planar
quadrangulations of size $n$ biased by a weight $u>0$ per simple component. We
exhibit a phase transition at the critical value $u_C=9/5$. If $u<u_C$, a
condensation phenomenon occurs: the largest block is of size $\Theta(n)$.
Moreover, for quadrangulations we show that the diameter is of order $n^{1/4}$,
and the scaling limit is the Brownian sphere. When $u > u_C$, the largest block
is of size $\Theta(\log(n))$, the scaling order for distances is $n^{1/2}$, and
the scaling limit is the Brownian tree. Finally, for $u=u_C$, the largest block
is of size $\Theta(n^{2/3})$, the scaling order for distances is $n^{1/3}$, and
the scaling limit is the stable tree of parameter $3/2$.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:19:51 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 12:45:57 GMT""}]","2023-04-12"
"2302.01724","Qingpeng Cai","Qingpeng Cai, Shuchang Liu, Xueliang Wang, Tianyou Zuo, Wentao Xie,
  Bin Yang, Dong Zheng, Peng Jiang, Kun Gai","Reinforcing User Retention in a Billion Scale Short Video Recommender
  System",,"The Web Conference 2023 Industry Track",,,"cs.LG cs.IR","http://creativecommons.org/publicdomain/zero/1.0/","  Recently, short video platforms have achieved rapid user growth by
recommending interesting content to users. The objective of the recommendation
is to optimize user retention, thereby driving the growth of DAU (Daily Active
Users). Retention is a long-term feedback after multiple interactions of users
and the system, and it is hard to decompose retention reward to each item or a
list of items. Thus traditional point-wise and list-wise models are not able to
optimize retention. In this paper, we choose reinforcement learning methods to
optimize the retention as they are designed to maximize the long-term
performance. We formulate the problem as an infinite-horizon request-based
Markov Decision Process, and our objective is to minimize the accumulated time
interval of multiple sessions, which is equal to improving the app open
frequency and user retention. However, current reinforcement learning
algorithms can not be directly applied in this setting due to uncertainty,
bias, and long delay time incurred by the properties of user retention. We
propose a novel method, dubbed RLUR, to address the aforementioned challenges.
Both offline and live experiments show that RLUR can significantly improve user
retention. RLUR has been fully launched in Kuaishou app for a long time, and
achieves consistent performance improvement on user retention and DAU.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:25:43 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 04:12:02 GMT""},{""version"":""v3"",""created"":""Sun, 12 Feb 2023 07:02:19 GMT""}]","2023-02-14"
"2302.01725","Konstantin Herb","Laura A. V\""olker, Konstantin Herb, Erika Janitz, Christian L. Degen,
  John M. Abendroth","Towards Quantum Sensing of Chiral-Induced Spin Selectivity: Probing
  Donor-Bridge-Acceptor Molecules with NV Centers in Diamond","7 pages and 4 pages appendix including an extensive description of
  the initial spin state of photo-generated radical pairs","J. Chem. Phys. 28 April 2023; 158 (16): 161103","10.1063/5.0145466",,"quant-ph cond-mat.mes-hall physics.bio-ph physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  Photoexcitable donor-bridge-acceptor (D-B-A) molecules that support
intramolecular charge transfer are ideal platforms to probe the influence of
chiral-induced spin selectivity (CISS) in electron transfer and resulting
radical pairs. In particular, the extent to which CISS influences spin
polarization or spin coherence in the initial state of spin-correlated radical
pairs following charge transfer through a chiral bridge remains an open
question. Here, we introduce a quantum sensing scheme to measure directly the
hypothesized spin polarization in radical pairs using shallow nitrogen-vacancy
(NV) centers in diamond at the single- to few-molecule level. Importantly, we
highlight the perturbative nature of the electron spin-spin dipolar coupling
within the radical pair, and demonstrate how Lee-Goldburg decoupling can
preserve spin polarization in D-B-A molecules for enantioselective detection by
a single NV center. The proposed measurements will provide fresh insight into
spin selectivity in electron transfer reactions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:33:30 GMT""}]","2023-04-27"
"2302.01726","Filipe Mena","Christian L\""ubbe, Filipe C. Mena","Asymptotic structure and stability of spatially homogeneous space-times
  with a positive cosmological constant","43 pages",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  We investigate the future asymptotics of spatially homogeneous space-times
with a positive cosmological constant by using and further developing geometric
conformal methods in General Relativity. For a large class of source fields,
including fluids with anisotropic stress, we prove that the space-times are
future asymptotically simple and geometrically conformally regular. We use that
result in order to show the global conformal regularity of the Einstein-Maxwell
system as well as the Einstein-radiation, Einstein-dust, massless
Einstein-Vlasov and particular Einstein-scalar field systems for Bianchi
space-times. Taking into account previous results, this implies the future
non-linear stability of some of those space-times in the sense that, for small
perturbations, the space-times approach locally the de Sitter solution
asymptotically in time. This extends some cosmic no-hair theorems to almost
spatially homogeneous space-times. However, we find that the conformal Einstein
field equations preserve the Bianchi type even at conformal infinity, so the
resulting asymptotic space-times have conformal hair.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:37:02 GMT""}]","2023-02-06"
"2302.01727","Calvin Tsay","Jaime Sabal Berm\'udez and Antonio del Rio Chanona and Calvin Tsay","Distributional constrained reinforcement learning for supply chain
  optimization","6 pages, 4 figures",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work studies reinforcement learning (RL) in the context of multi-period
supply chains subject to constraints, e.g., on production and inventory. We
introduce Distributional Constrained Policy Optimization (DCPO), a novel
approach for reliable constraint satisfaction in RL. Our approach is based on
Constrained Policy Optimization (CPO), which is subject to approximation errors
that in practice lead it to converge to infeasible policies. We address this
issue by incorporating aspects of distributional RL into DCPO. Specifically, we
represent the return and cost value functions using neural networks that output
discrete distributions, and we reshape costs based on the associated
confidence. Using a supply chain case study, we show that DCPO improves the
rate at which the RL policy converges and ensures reliable constraint
satisfaction by the end of training. The proposed method also improves
predictability, greatly reducing the variance of returns between runs,
respectively; this result is significant in the context of policy gradient
methods, which intrinsically introduce significant variance during training.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:43:02 GMT""}]","2023-02-06"
"2302.01728","Xingyu Zhao","Yi Dong, Zhongguo Li, Xingyu Zhao, Zhengtao Ding, Xiaowei Huang","Decentralised and Cooperative Control of Multi-Robot Systems through
  Distributed Optimisation","Accepted by AAMAS'23",,,,"eess.SY cs.DC cs.SY","http://creativecommons.org/licenses/by/4.0/","  Multi-robot cooperative control has gained extensive research interest due to
its wide applications in civil, security, and military domains. This paper
proposes a cooperative control algorithm for multi-robot systems with general
linear dynamics. The algorithm is based on distributed cooperative optimisation
and output regulation, and it achieves global optimum by utilising only
information shared among neighbouring robots. Technically, a high-level
distributed optimisation algorithm for multi-robot systems is presented, which
will serve as an optimal reference generator for each individual agent. Then,
based on the distributed optimisation algorithm, an output regulation method is
utilised to solve the optimal coordination problem for general linear dynamic
systems. The convergence of the proposed algorithm is theoretically proved.
Both numerical simulations and real-time physical robot experiments are
conducted to validate the effectiveness of the proposed cooperative control
algorithms.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:45:17 GMT""}]","2023-02-06"
"2302.01729","Shreya Das","Shreya Das, Ranjeet Kumar Tiwari, and Shovan Bhaumik","Resolving Left-Right Ambiguity During Bearing Only Tracking of an
  Underwater Target Using Towed Array","6 pages, 10 figures, correspondence paper",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  In bearing only tracking using a towed array, the array can sense the bearing
angle of the target but is unable to differentiate whether the target is on the
left or the right side of the array. Thus, the traditional tracking algorithm
generates tracks in both the sides of the array which create difficulties when
interception is required. In this paper, we propose a method based on
likelihood of measurement which along with the estimators can resolve
left-right ambiguity and track the target. A case study has been presented
where the target moves (a) in a straight line with a near constant velocity,
(b) maneuvers with a turn, and observer takes a `U'-like maneuver. The method
along with the various estimators has been applied which successfully resolves
the ambiguity and tracks the target. Further, the tracking results are compared
in terms of the root mean square error in position and velocity, bias norm, \%
of track loss and the relative execution time.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:45:20 GMT""}]","2023-02-06"
"2302.01730","Clara Rojas","Sebastian Valladares and Clara Rojas","The superradiance phenomenon in spin-one particles","12 pages, 4 figures",,"10.1142/S0217751X23500203",,"quant-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we solve the Duffin--Kemmer--Petiau (DKP) equation in the
presence of hyperbolic tangent potential for spin-one particles. By
partitioning the spin-one spinor, we show that the DKP equation is equivalent
to the Klein--Gordon equation formalism. The scattering solutions are derived
in terms of hypergeometric functions. The reflection $R$ and transmission $T$
coefficients are calculated in terms of the Gamma functions. The results show
the presence of the superradiance phenomenon when $R$ for a specific region in
the potential becomes greater than one.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:46:01 GMT""}]","2023-05-03"
"2302.01731","Tulin Altunoz","Tulin Altunoz, Mehmetcik Pamuk and Oguz Yildiz","Generators of the Mapping Class Group of a Nonorientable Punctured
  Surface","9 pages, 10 figures. Any comments or suggestions are welcome",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\textrm{Mod}(N_{g, p})$ denote the mapping class group of a
nonorientable surface of genus $g$ with $p$ punctures. For $g\geq14$, we show
that $\textrm{Mod}(N_{g, p})$ can be generated by five elements or by six
involutions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:47:15 GMT""}]","2023-02-06"
"2302.01732","Xuefei Yang","Xuefei Yang and Emilia Fridman","A Robust Time-Delay Approach to Extremum Seeking via ISS Analysis of the
  Averaged System",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For N-dimensional (ND) static quadratic map, we present a time-delay approach
to gradient-based extremum seeking (ES) both, in the continuous and, for the
first time, the discrete domains. As in the recently introduced (for 2D maps in
the continuous domain), we transform the system to the time-delay one (neutral
type system in the form of Hale in the continuous case). This system is
O($\varepsilon$)-perturbation of the averaged linear ODE system, where
$\varepsilon$ is a period of averaging. We further explicitly present the
neutral system as the linear ODE, where O($\varepsilon$)-terms are considered
as disturbances with distributed delays of the length of the small parameter
$\varepsilon$. Regional input-to-state stability (ISS) analysis is provided by
employing a variation of constants formula that greatly simplifies the
previously used analysis via Lyapunov-Krasovskii (L-K) method, simplifies the
conditions and improves the results. Examples from the literature illustrate
the efficiency of the new approach, allowing essentially large uncertainty of
the Hessian matrix with bounds on $\varepsilon$ that are not too small.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:48:51 GMT""}]","2023-02-06"
"2302.01733","Quang Cao","Quang Cao, Hong Yen Tran, Son Hoang Dau, Xun Yi, Emanuele Viterbo,
  Chen Feng, Yu-Chih Huang, Jingge Zhu, Stanislav Kruglik, and Han Mao Kiah","Committed Private Information Retrieval",,,,,"cs.CR cs.DB cs.IR","http://creativecommons.org/licenses/by/4.0/","  A private information retrieval (PIR) scheme allows a client to retrieve a
data item $x_i$ among $n$ items $x_1,x_2,...,x_n$ from $k$ servers, without
revealing what $i$ is even when $t < k$ servers collude and try to learn $i$.
Such a PIR scheme is said to be $t$-private. A PIR scheme is $v$-verifiable if
the client can verify the correctness of the retrieved $x_i$ even when $v \leq
k$ servers collude and try to fool the client by sending manipulated data. Most
of the previous works in the literature on PIR assumed that $v < k$, leaving
the case of all-colluding servers open. We propose a generic construction that
combines a linear map commitment (LMC) and an arbitrary linear PIR scheme to
produce a $k$-verifiable PIR scheme, termed a committed PIR scheme. Such a
scheme guarantees that even in the worst scenario, when all servers are under
the control of an attacker, although the privacy is unavoidably lost, the
client won't be fooled into accepting an incorrect $x_i$. We demonstrate the
practicality of our proposal by implementing the committed PIR schemes based on
the Lai-Malavolta LMC and three well-known PIR schemes using the GMP library
and \texttt{blst}, the current fastest C library for elliptic curve pairings.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:48:59 GMT""}]","2023-02-06"
"2302.01734","Ilyas Fatkhullin","Ilyas Fatkhullin and Anas Barakat and Anastasia Kireeva and Niao He","Stochastic Policy Gradient Methods: Improved Sample Complexity for
  Fisher-non-degenerate Policies","This work was initially submitted in October 2022",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, the impressive empirical success of policy gradient (PG) methods
has catalyzed the development of their theoretical foundations. Despite the
huge efforts directed at the design of efficient stochastic PG-type algorithms,
the understanding of their convergence to a globally optimal policy is still
limited. In this work, we develop improved global convergence guarantees for a
general class of Fisher-non-degenerate parameterized policies which allows to
address the case of continuous state action spaces. First, we propose a
Normalized Policy Gradient method with Implicit Gradient Transport (N-PG-IGT)
and derive a $\tilde{\mathcal{O}}(\varepsilon^{-2.5})$ sample complexity of
this method for finding a global $\varepsilon$-optimal policy. Improving over
the previously known $\tilde{\mathcal{O}}(\varepsilon^{-3})$ complexity, this
algorithm does not require the use of importance sampling or second-order
information and samples only one trajectory per iteration. Second, we further
improve this complexity to $\tilde{ \mathcal{\mathcal{O}} }(\varepsilon^{-2})$
by considering a Hessian-Aided Recursive Policy Gradient ((N)-HARPG) algorithm
enhanced with a correction based on a Hessian-vector product. Interestingly,
both algorithms are $(i)$ simple and easy to implement: single-loop, do not
require large batches of trajectories and sample at most two trajectories per
iteration; $(ii)$ computationally and memory efficient: they do not require
expensive subroutines at each iteration and can be implemented with memory
linear in the dimension of parameters.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:50:23 GMT""}]","2023-02-06"
"2302.01735","Chenyu You","Chenyu You, Weicheng Dai, Yifei Min, Fenglin Liu, David A. Clifton, S
  Kevin Zhou, Lawrence Hamilton Staib, James S Duncan","Rethinking Semi-Supervised Medical Image Segmentation: A
  Variance-Reduction Perspective",,,,,"cs.CV cs.AI cs.LG eess.IV","http://creativecommons.org/licenses/by/4.0/","  For medical image segmentation, contrastive learning is the dominant practice
to improve the quality of visual representations by contrasting semantically
similar and dissimilar pairs of samples. This is enabled by the observation
that without accessing ground truth labels, negative examples with truly
dissimilar anatomical features, if sampled, can significantly improve the
performance. In reality, however, these samples may come from similar
anatomical regions and the models may struggle to distinguish the minority
tail-class samples, making the tail classes more prone to misclassification,
both of which typically lead to model collapse. In this paper, we propose ARCO,
a semi-supervised contrastive learning (CL) framework with stratified group
theory for medical image segmentation. In particular, we first propose building
ARCO through the concept of variance-reduced estimation and show that certain
variance-reduction techniques are particularly beneficial in pixel/voxel-level
segmentation tasks with extremely limited labels. Furthermore, we theoretically
prove these sampling techniques are universal in variance reduction. Finally,
we experimentally validate our approaches on eight benchmarks, i.e., five 2D/3D
medical and three semantic segmentation datasets, with different label
settings, and our methods consistently outperform state-of-the-art
semi-supervised methods. Additionally, we augment the CL frameworks with these
sampling techniques and demonstrate significant gains over previous methods. We
believe our work is an important step towards semi-supervised medical image
segmentation by quantifying the limitation of current self-supervision
objectives for accomplishing such challenging safety-critical tasks.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:50:25 GMT""},{""version"":""v2"",""created"":""Tue, 7 Feb 2023 06:05:05 GMT""},{""version"":""v3"",""created"":""Sat, 11 Mar 2023 04:19:13 GMT""},{""version"":""v4"",""created"":""Wed, 24 May 2023 16:11:28 GMT""}]","2023-05-25"
"2302.01736","Corentin Puffay","Corentin Puffay, Bernd Accou, Lies Bollens, Mohammad Jalilpour Monesi,
  Jonas Vanthornhout, Hugo Van hamme, Tom Francart","Relating EEG to continuous speech using deep neural networks: a review",,,,,"eess.AS cs.SD","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Objective. When a person listens to continuous speech, a corresponding
response is elicited in the brain and can be recorded using
electroencephalography (EEG). Linear models are presently used to relate the
EEG recording to the corresponding speech signal. The ability of linear models
to find a mapping between these two signals is used as a measure of neural
tracking of speech. Such models are limited as they assume linearity in the
EEG-speech relationship, which omits the nonlinear dynamics of the brain. As an
alternative, deep learning models have recently been used to relate EEG to
continuous speech, especially in auditory attention decoding (AAD) and
single-speech-source paradigms. Approach. This paper reviews and comments on
deep-learning-based studies that relate EEG to continuous speech in AAD and
single-speech-source paradigms. We point out recurrent methodological pitfalls
and the need for a standard benchmark of model analysis. Main results. We
gathered 29 studies. The main methodological issues we found are biased
cross-validations, data leakage leading to over-fitted models, or
disproportionate data size compared to the model's complexity. In addition, we
address requirements for a standard benchmark model analysis, such as public
datasets, common evaluation metrics, and good practices for the match-mismatch
task. Significance. We are the first to present a review paper summarizing the
main deep-learning-based studies that relate EEG to speech while addressing
methodological pitfalls and important considerations for this newly expanding
field. Our study is particularly relevant given the growing application of deep
learning in EEG-speech decoding.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:51:01 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 09:05:07 GMT""},{""version"":""v3"",""created"":""Wed, 26 Apr 2023 12:26:37 GMT""}]","2023-04-27"
"2302.01737","Weijun Xie","Nan Jiang and Weijun Xie","ALSO-X#: Better Convex Approximations for Distributionally Robust Chance
  Constrained Programs",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies distributionally robust chance constrained programs
(DRCCPs), where the uncertain constraints must be satisfied with at least a
probability of a prespecified threshold for all probability distributions from
the Wasserstein ambiguity set. As DRCCPs are often nonconvex and challenging to
solve optimally, researchers have been developing various convex inner
approximations. Recently, ALSO-X has been proven to outperform the conditional
value-at-risk (CVaR) approximation of a regular chance constrained program when
the deterministic set is convex. In this work, we relax this assumption by
introducing a new ALSO-X\# method for solving DRCCPs. Namely, in the bilevel
reformulations of ALSO-X and CVaR approximation, we observe that the
lower-level ALSO-X is a special case of the lower-level CVaR approximation and
the upper-level CVaR approximation is more restricted than the one in ALSO-X.
This observation motivates us to propose the ALSO-X\#, which still resembles a
bilevel formulation -- in the lower-level problem, we adopt the more general
CVaR approximation, and for the upper-level one, we choose the less restricted
ALSO-X. We show that ALSO-X\# can always be better than the CVaR approximation
and can outperform ALSO-X under regular chance constrained programs and type
$\infty-$Wasserstein ambiguity set. We also provide new sufficient conditions
under which ALSO-X\# outputs an optimal solution to a DRCCP. We apply the
proposed ALSO-X\# to a wireless communication problem and numerically
demonstrate that the solution quality can be even better than the exact method.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:52:59 GMT""}]","2023-02-06"
"2302.01738","Coen de Vente MSc","Coen de Vente, Koenraad A. Vermeer, Nicolas Jaccard, He Wang, Hongyi
  Sun, Firas Khader, Daniel Truhn, Temirgali Aimyshev, Yerkebulan Zhanibekuly,
  Tien-Dung Le, Adrian Galdran, Miguel \'Angel Gonz\'alez Ballester, Gustavo
  Carneiro, Devika R G, Hrishikesh P S, Densen Puthussery, Hong Liu, Zekang
  Yang, Satoshi Kondo, Satoshi Kasai, Edward Wang, Ashritha Durvasula,
  J\'onathan Heras, Miguel \'Angel Zapata, Teresa Ara\'ujo, Guilherme Aresta,
  Hrvoje Bogunovi\'c, Mustafa Arikan, Yeong Chan Lee, Hyun Bin Cho, Yoon Ho
  Choi, Abdul Qayyum, Imran Razzak, Bram van Ginneken, Hans G. Lemij, Clara I.
  S\'anchez","AIROGS: Artificial Intelligence for RObust Glaucoma Screening Challenge","19 pages, 8 figures, 3 tables",,,,"eess.IV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The early detection of glaucoma is essential in preventing visual impairment.
Artificial intelligence (AI) can be used to analyze color fundus photographs
(CFPs) in a cost-effective manner, making glaucoma screening more accessible.
While AI models for glaucoma screening from CFPs have shown promising results
in laboratory settings, their performance decreases significantly in real-world
scenarios due to the presence of out-of-distribution and low-quality images. To
address this issue, we propose the Artificial Intelligence for Robust Glaucoma
Screening (AIROGS) challenge. This challenge includes a large dataset of around
113,000 images from about 60,000 patients and 500 different screening centers,
and encourages the development of algorithms that are robust to ungradable and
unexpected input data. We evaluated solutions from 14 teams in this paper, and
found that the best teams performed similarly to a set of 20 expert
ophthalmologists and optometrists. The highest-scoring team achieved an area
under the receiver operating characteristic curve of 0.99 (95% CI: 0.98-0.99)
for detecting ungradable images on-the-fly. Additionally, many of the
algorithms showed robust performance when tested on three other publicly
available datasets. These results demonstrate the feasibility of robust
AI-enabled glaucoma screening.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:55:30 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 10:23:42 GMT""}]","2023-02-13"
"2302.01739","Placido Mursia","Placido Mursia, Sendy Phang, Vincenzo Sciancalepore, Gabriele Gradoni,
  and Marco Di Renzo","SARIS: Scattering Aware Reconfigurable Intelligent Surface model and
  Optimization for Complex Propagation Channels","Submitted for publication",,,,"cs.IT math.IT math.OC","http://creativecommons.org/licenses/by/4.0/","  The reconfigurable intelligent surface (RIS) is an emerging technology that
changes how wireless networks are perceived, therefore its potential benefits
and applications are currently under intense research and investigation. In
this letter, we focus on electromagnetically consistent models for RISs
inheriting from a recently proposed model based on mutually coupled loaded wire
dipoles. While existing related research focuses on free-space wireless
channels thereby ignoring interactions between RIS and scattering objects
present in the propagation environment, we introduce an RIS-aided channel model
that is applicable to more realistic scenarios, where the scattering objects
are modeled as loaded wire dipoles. By adjusting the parameters of the wire
dipoles, the properties of general natural and engineered material objects can
be modeled. Based on this model, we introduce a provably convergent and
efficient iterative algorithm that jointly optimizes the RIS and transmitter
configurations to maximize the system sum-rate. Extensive numerical results
show the net performance improvement provided by the proposed method compared
with existing optimization algorithms.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:57:10 GMT""},{""version"":""v2"",""created"":""Wed, 17 May 2023 14:42:45 GMT""}]","2023-05-18"
"2302.01740","Gorka Abad","Gorka Abad, Jing Xu, Stefanos Koffas, Behrad Tajalli, Stjepan Picek,
  Mauro Conti","SoK: A Systematic Evaluation of Backdoor Trigger Characteristics in
  Image Classification",,,,,"cs.CV cs.CR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning achieves outstanding results in many machine learning tasks.
Nevertheless, it is vulnerable to backdoor attacks that modify the training set
to embed a secret functionality in the trained model. The modified training
samples have a secret property, i. e., a trigger. At inference time, the secret
functionality is activated when the input contains the trigger, while the model
functions correctly in other cases. While there are many known backdoor attacks
(and defenses), deploying a stealthy attack is still far from trivial.
Successfully creating backdoor triggers depends on numerous parameters.
Unfortunately, research has not yet determined which parameters contribute most
to the attack performance.
  This paper systematically analyzes the most relevant parameters for the
backdoor attacks, i.e., trigger size, position, color, and poisoning rate.
Using transfer learning, which is very common in computer vision, we evaluate
the attack on state-of-the-art models (ResNet, VGG, AlexNet, and GoogLeNet) and
datasets (MNIST, CIFAR10, and TinyImageNet). Our attacks cover the majority of
backdoor settings in research, providing concrete directions for future works.
Our code is publicly available to facilitate the reproducibility of our
results.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:00:05 GMT""},{""version"":""v2"",""created"":""Fri, 21 Apr 2023 09:01:24 GMT""}]","2023-04-24"
"2302.01741","Yongfeng Yang","Mi-Ji Liang, Yong-Feng Yang, Chen Cheng, and Rubem Mondaini","Disorder in interacting quasi-one-dimensional systems: flat and
  dispersive bands","10 pages, 13 figures",,,,"cond-mat.str-el cond-mat.dis-nn cond-mat.supr-con","http://creativecommons.org/licenses/by/4.0/","  We investigate the superconductor-insulator transition (SIT) in disordered
quasi-one dimensional systems using the density-matrix renormalization group
method. Focusing on the case of an interacting spinful Hamiltonian at
quarter-filling, we contrast the differences arising in the SIT when the parent
non-interacting model features either flat or dispersive bands. Furthermore, by
comparing disorder distributions that preserve or not SU(2)-symmetry, we unveil
the critical disorder amplitude that triggers insulating behavior. While
scaling analysis suggests the transition to be of a
Berezinskii-Kosterlitz-Thouless type for all models (two lattices and two
disorder types), only in the flat-band model with Zeeman-like disorder the
critical disorder is nonvanishing. In this sense, the flat-band structure does
strengthen superconductivity. For both flat and dispersive band models, i) in
the presence of SU(2)-symmetric random chemical potentials, the
disorder-induced transition is from superconductor to insulator of singlet
pairs; ii) for the Zeeman-type disorder, the transition is from superconductor
to insulator of unpaired fermions. In all cases, our numerical results suggest
no intermediate disorder-driven metallic phase.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:04:11 GMT""}]","2023-02-06"
"2302.01742","Andrei Manolescu","Hadi Rezaie Heris, Kristjan Ottar Klausen, Anna Sitek, Sigurdur Ingi
  Erlingsson, Andrei Manolescu","Charge and heat currents in prismatic tubular nanowires","International Semiconductor Conference - CAS 2022, Romania",,"10.1109/CAS56377.2022.9934669",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate electronic charge and heat transport in tubular nanowires
generated by a temperature gradient or a chemical potential bias. These
nanowires correspond to semiconductor core-shell nanowires with insulating
(undoped) core and conductive (doped) shell, such that the conduction takes
place only in the shell. The cross section of such nanowires is typically
polygonal. We study the influence of the cross section shape and shell
thickness on the electric and heat conduction of the shell. We use the
Landauer-B\""uttiker approach to calculate the electric and heat currents as a
non-linear function of temperature and chemical potential bias beyond the
linear regime.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:04:55 GMT""}]","2023-02-06"
"2302.01746","Anargyros Michaloliakos","Anargyros Michaloliakos, Chongan Wang, Alexander F. Vakakis","Machine Learning Extreme Acoustic Non-reciprocity in a Linear Waveguide
  with Multiple Nonlinear Asymmetric Gates",,,,,"eess.AS cs.LG cs.SD","http://creativecommons.org/licenses/by/4.0/","  This work is a study of acoustic non-reciprocity exhibited by a passive
one-dimensional linear waveguide incorporating two local strongly nonlinear,
asymmetric gates. Two local nonlinear gates break the symmetry and linearity of
the waveguide, yielding strong global non-reciprocal acoustics, in the way that
extremely different acoustical responses occur depending on the side of
application of harmonic excitation. To the authors' best knowledge that the
present two-gated waveguide is capable of extremely high acoustic
non-reciprocity, at a much higher level to what is reported by active or
passive devices in the current literature; moreover, this extreme performance
combines with acceptable levels of transmissibility in the desired direction of
wave propagation. Machine learning is utilized for predictive design of this
gated waveguide in terms of the measures of transmissibility and
non-reciprocity, with the aim of reducing the required computational time for
high-dimensional parameter space analysis. The study sheds new light into the
physics of these media and considers the advantages and limitations of using
neural networks to analyze this type of physical problems. In the predicted
desirable parameter space for intense non-reciprocity, the maximum
transmissibility reaches as much as 40%, and the transmitted energy from
upstream to downstream varies up to nine orders of magnitude, depending on the
direction of wave transmission. The machine learning tools along with the
numerical methods of this work can inform predictive designs of practical
non-reciprocal waveguides and acoustic metamaterials that incorporate local
nonlinear gates. The current paper shows that combinations of nonlinear gates
can lead to extremely high non-reciprocity while maintaining desired levels of
transmissibility.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:28:04 GMT""}]","2023-02-06"
"2302.01748","Nicola Rizzo","Nicola Rizzo, Manuel C\'aceres, Veli M\""akinen","Chaining of Maximal Exact Matches in Graphs","19 pages, 1 figure",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of finding maximal exact matches (MEMs) between a query
string $Q$ and a labeled directed acyclic graph (DAG) $G=(V,E,\ell)$ and
subsequently co-linearly chaining these matches. We show that it suffices to
compute MEMs between node labels and $Q$ (node MEMs) to encode full MEMs. Node
MEMs can be computed in linear time and we show how to co-linearly chain them
to solve the Longest Common Subsequence (LCS) problem between $Q$ and $G$. Our
chaining algorithm is the first to consider a symmetric formulation of the
chaining problem in graphs and runs in $O(k^2|V| + |E| + kN\log N)$ time, where
$k$ is the width (minimum number of paths covering the nodes) of $G$, and $N$
is the number of node MEMs. We then consider the problem of finding MEMs when
the input graph is an indexable elastic founder graph (subclass of labeled DAGs
studied by Equi et al., Algorithmica 2022). For arbitrary input graphs, the
problem cannot be solved in truly sub-quadratic time under SETH (Equi et al.,
ICALP 2019). We show that we can report all MEMs between $Q$ and an indexable
elastic founder graph in time $O(nH^2 + m + M_\kappa)$, where $n$ is the total
length of node labels, $H$ is the maximum number of nodes in a block of the
graph, $m = |Q|$, and $M_\kappa$ is the number of MEMs of length at least
$\kappa$. The results extend to the indexing problem, where the graph is
preprocessed and a set of queries is processed as a batch.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:10:33 GMT""},{""version"":""v2"",""created"":""Wed, 15 Feb 2023 18:35:38 GMT""}]","2023-02-16"
"2302.01754","Dario Dennst\""adt","Thomas Berger, Dario Dennst\""adt, Lukas Lanza, Karl Worthmann","Robust Funnel MPC for nonlinear systems with relative degree one",,,,,"math.OC","http://creativecommons.org/licenses/by-sa/4.0/","  We propose a novel Model Predictive Control scheme for robust output
reference tracking with prescribed performance for nonlinear multi-input
multi-output systems of relative degree one with stable internal dynamics.
Combining funnel MPC with the model-free adaptive funnel controller, the new
robust funnel MPC algorithm guarantees output tracking of reference signals
within predefined boundaries even in the presence of unknown disturbances and a
structural model-plant mismatch. Initial and recursive feasibility of the
control scheme is shown without imposing terminal conditions or requirements on
the length of the prediction horizon. To this end, we propose a proper
initialization strategy; and to ensure that the feedback controller does not
contribute unnecessarily much, we introduce an activation function for the
latter.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:15:01 GMT""}]","2023-02-06"
"2302.01755","Thomas P\""ahtz","Jiafeng Xie, Peng Hu, Chenlin Zhu, Zhaosheng Yu, Thomas P\""ahtz","Turbidity currents propagating down an inclined slope: particle
  auto-suspension",,"Journal of Fluid Mechanics 954, A44 (2023)","10.1017/jfm.2022.1041",,"physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Turbidity current (TC), a ubiquitous fluid-particle coupled phenomenon in
the natural environment and engineering, can transport over long distances on
an inclined terrain due to the suspension mechanism. A large-eddy simulation
and discrete element method coupled model is employed to simulate the
particle-laden gravity currents over the inclined slope in order to investigate
the auto-suspension mechanism from a Lagrangian perspective. The particle
Reynolds number in our TC simulation is $0.01\sim0.1$ and the slope angle is
$1/20 \sim 1/5$. The influences of initial particle concentration and terrain
slope on the particle flow regimes, particle movement patterns, fluid-particle
interactions, energy budget and auto-suspension index are explored. The results
indicate that the auto-suspension particles predominantly appear near the
current head and their number increases and then decreases during the current
evolution, which is positively correlated with the coherent structures around
the head. When the turbidity current propagates downstream, the average
particle Reynolds number of the auto-suspension particles remains basically
unchanged, and is higher than that of other transported particles. The average
particle Reynolds number of the transported particles exhibits a negative
correlation with the Reynolds number of the current. Furthermore, the increase
in particle concentration will enhance the particle velocity, which allows the
turbidity current to advance faster and improves the perpendicular support,
thereby increasing the turbidity current auto-suspension capacity. Increasing
slope angle will result in a slightly larger front velocity, while the effect
of that on the total force is insignificant.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:15:24 GMT""}]","2023-02-06"
"2302.01761","Hsiang-nan Li","Hsiang-nan Li","Dispersive constraints on fermion masses","20 pages, 14 figures, journal version, estimates on theoretical
  uncertainties included",,"10.1103/PhysRevD.107.094007",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate that fermion masses in the Standard Model (SM) can be
constrained by the dispersion relations obeyed by hadronic and semileptonic
decay widths of a fictitious heavy quark $Q$ with an arbitrary mass. These
relations, imposing stringent connections between the high-mass and low-mass
behaviors of decay widths, correlate a heavy quark mass and the chiral symmetry
breaking scale. Given the known input from leading-order heavy quark expansion
and a hadronic threshold for decay products, we solve for a physical heavy
quark decay width. It is shown that the charm (bottom) quark mass $m_c= 1.35$
GeV ($m_b= 4.0$ GeV) can be determined by the dispersion relation for the $Q\to
du\bar d$ ($Q\to c\bar ud$) decay with the threshold $2m_\pi$ ($m_\pi+m_D$),
where $m_\pi$ ($m_D$) denotes the pion ($D$ meson) mass. Requiring that the
dispersion relation for the $Q\to su\bar d$ ($Q\to d\mu^+\nu_\mu$, $Q\to
u\tau^-\bar\nu_\tau$) decay with the threshold $m_\pi+m_K$ ($m_\pi+m_\mu$,
$m_\pi+m_\tau$) yields the same heavy quark mass, $m_K$ being the kaon mass, we
constrain the strange quark (muon, $\tau$ lepton) mass to be $m_s= 0.12$ GeV
($m_\mu=0.11$ GeV, $m_\tau= 2.0$ GeV). Moreover, all the predicted decay widths
corresponding to the above masses agree with the data. It is pointed out that
our formalism is similar to QCD sum rules for probing resonance properties, and
that the Pauli interference (weak annihilation) provides the higher-power
effect necessary for establishing the solutions of the hadronic (semilaptonic)
decay widths. This work suggests that the parameters in the SM may not be free,
but arranged properly to achieve internal dynamical consistency.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:20:37 GMT""},{""version"":""v2"",""created"":""Tue, 2 May 2023 16:41:37 GMT""}]","2023-05-17"
"2302.01765","Joan Soto","Joan Soto and Sandra Tom\`as Valls","On the hyperfine splittings of heavy quarkonium hybrids","10 pages, 2 figures, 5 tables",,,,"hep-ph hep-lat","http://creativecommons.org/licenses/by/4.0/","  In the framework of the Born-Oppenheimer Effective Field Theory, the
hyperfine structure of heavy quarkonium hybrids at leading order in the 1/m Q
expansion is determined by two potentials. We estimate those potentials by
interpolating between the known short distance behavior and the long distance
behavior calculated in the QCD Effective String Theory. The long distance
behavior depends, at leading order, on two parameters which can be obtained
from the long distance behavior of the heavy quarkonium potentials (up to sign
ambiguities). The short distance behavior depends, at leading order, on two
extra paramentes, which are obtained from a lattice calculation of the lower
lying charmonium hybrid multiplets. This allows us to predict the hyperfine
splitting both of bottomonium hybrids and of higher multiplets of charmonium
hybrids. We carry out a careful error analysis and compare with other
approaches.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:25:27 GMT""}]","2023-02-06"
"2302.01767","Benedikt Zerulla","Benedikt Zerulla, Chun Li, Dominik Beutel, Simon O{\ss}wald, Christof
  Holzer, Jochen B\""urck, Stefan Br\""ase, Christof W\""oll, Ivan
  Fernandez-Corbaton, Lars Heinke, Carsten Rockstuhl and Marjan Krsti\'c","Exploring Functional Photonic Devices made from a Chiral Metal-Organic
  Framework Material by a Multiscale Computational Method",,,,,"cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electronic circular dichroism is an important optical phenomenon offering
insights into chiral molecular materials. On the other hand, metal-organic
frameworks (MOFs) are a novel group of crystalline porous thin-film materials
that provide tailor-made chemical and physical properties by carefully
selecting their building units. Combining these two aspects of contemporary
material research and integrating chiral molecules into MOFs promises devices
with unprecedented functionality. However, considering the nearly unlimited
degrees of freedom concerning the choice of materials and the geometrical
details of the possibly structured films, we urgently need to complement
advanced experimental methods with equally strong modeling techniques. Most
notably, these modeling techniques must cope with the challenge that the
material and devices thereof cover size scales from {\AA}ngstr\""oms to mm. In
response to that need, we outline a computational workflow that seamlessly
combines quantum chemical methods to capture the properties of individual
molecules with optical simulations to capture the properties of functional
devices made from these molecular materials. We concentrate on chiral
properties and apply our work to UiO-67-BINOL MOFs, for which experimental
results are available to benchmark the results of our simulations and explore
the optical properties of cavities and metasurfaces made from that chiral
material.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:26:09 GMT""}]","2023-02-06"
"2302.01770","Carmine Monetta","Valentina Grazian and Carmine Monetta","A conjecture related to the nilpotency of groups with isomorphic
  non-commuting graphs",,,,,"math.GR math.CO","http://creativecommons.org/licenses/by/4.0/","  In this work we discuss whether the non-commuting graph of a finite group can
determine its nilpotency. More precisely, Abdollahi, Akbari and Maimani
conjectured that if $G$ and $H$ are finite groups with isomorphic non-commuting
graphs and $G$ is nilpotent, then $H$ must be nilpotent as well (Conjecture 2).
We pose a new conjecture (Conjecture 3) that, together with the assumption
$|Z(G)|\geq|Z(H)|$, implies Conjecture 2 and we prove it for groups in which
all centralizers of non-central elements are abelian.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:28:26 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 16:28:55 GMT""}]","2023-02-07"
"2302.01771","Jose Gonz\'alez-Abad","Jose Gonz\'alez-Abad, Jorge Ba\~no-Medina, Jos\'e Manuel Guti\'errez","Using Explainability to Inform Statistical Downscaling Based on Deep
  Learning Beyond Standard Validation Approaches","Under review for Journal of Advances in Modeling Earth Systems",,,,"stat.ML cs.LG stat.AP","http://creativecommons.org/licenses/by/4.0/","  Deep learning (DL) has emerged as a promising tool to downscale climate
projections at regional-to-local scales from large-scale atmospheric fields
following the perfect-prognosis (PP) approach. Given their complexity, it is
crucial to properly evaluate these methods, especially when applied to changing
climatic conditions where the ability to extrapolate/generalise is key. In this
work, we intercompare several DL models extracted from the literature for the
same challenging use-case (downscaling temperature in the CORDEX North America
domain) and expand standard evaluation methods building on eXplainable
artifical intelligence (XAI) techniques. We show how these techniques can be
used to unravel the internal behaviour of these models, providing new
evaluation dimensions and aiding in their diagnostic and design. These results
show the usefulness of incorporating XAI techniques into statistical
downscaling evaluation frameworks, especially when working with large regions
and/or under climate change conditions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:29:31 GMT""}]","2023-02-06"
"2302.01772","Youssef Allouah","Youssef Allouah, Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta,
  Rafael Pinot, John Stephan","Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity","Accepted paper at AISTATS 2023",,,,"cs.LG cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Byzantine machine learning (ML) aims to ensure the resilience of distributed
learning algorithms to misbehaving (or Byzantine) machines. Although this
problem received significant attention, prior works often assume the data held
by the machines to be homogeneous, which is seldom true in practical settings.
Data heterogeneity makes Byzantine ML considerably more challenging, since a
Byzantine machine can hardly be distinguished from a non-Byzantine outlier. A
few solutions have been proposed to tackle this issue, but these provide
suboptimal probabilistic guarantees and fare poorly in practice. This paper
closes the theoretical gap, achieving optimality and inducing good empirical
results. In fact, we show how to automatically adapt existing solutions for
(homogeneous) Byzantine ML to the heterogeneous setting through a powerful
mechanism, we call nearest neighbor mixing (NNM), which boosts any standard
robust distributed gradient descent variant to yield optimal Byzantine
resilience under heterogeneity. We obtain similar guarantees (in expectation)
by plugging NNM in the distributed stochastic heavy ball method, a practical
substitute to distributed gradient descent. We obtain empirical results that
significantly outperform state-of-the-art Byzantine ML solutions.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:30:25 GMT""}]","2023-02-06"
"2302.01773","Kai Phillip Schmidt","R. Wiedmann, L. Lenke., M. M\""uhlhauser, K.P. Schmidt","Absence of fractal quantum criticality in the quantum Newman-Moore model","8 pages, 4 figures",,,,"cond-mat.str-el quant-ph","http://creativecommons.org/licenses/by/4.0/","  The quantum phase transition between the low-field fracton phase with type-II
fracton excitations and the high-field polarized phase is investigated in the
two-dimensional self-dual quantum Newman-Moore model. We apply perturbative and
numerical linked-cluster expansions to calculate the ground-state energy per
site in the thermodynamic limit revealing a level crossing at the self-dual
point. In addition, high-order series expansions of the relevant low-energy
gaps are determined using perturbative continuous unitary transformations
indicating no gap-closing. Our results therefore predict a first-order phase
transition between the low-field fracton and the high-field polarized phase at
the self-dual point.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:31:19 GMT""}]","2023-02-06"
"2302.01774","Takeshi Suzuki","Kento Nakada, Takeshi Suzuki, Yoshitaka Toyosawa","Poset Structure concerning Cylindric Diagrams",,,,,"math.CO math.QA math.RT","http://creativecommons.org/licenses/by/4.0/","  The purpose of the present paper is to give a realization of a cylindric
diagram as a subset of root systems of type $A_{\kappa-1}^{(1)}$ and several
characterization of its poset structure. Furthermore, the set of order ideals
of a cylindric diagram is described as a weak Bruhat interval of the Weyl
group.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:32:32 GMT""}]","2023-02-06"
"2302.01775","Matthew Baker","Matthew J. Baker","Using bayesmixedlogit and bayesmixedlogitwtp in Stata",,,,,"econ.EM","http://creativecommons.org/licenses/by/4.0/","  This document presents an overview of the bayesmixedlogit and
bayesmixedlogitwtp Stata packages. It mirrors closely the helpfile obtainable
in Stata (i.e., through help bayesmixedlogit or help bayesmixedlogitwtp).
Further background for the packages can be found in Baker(2014).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:33:25 GMT""}]","2023-02-06"
"2302.01776","Jerome Beugnon","G. Chauveau, C. Maury, F. Rabec, C. Heintze, G. Brochier, S.
  Nascimbene, J. Dalibard, J. Beugnon, S.M. Roccuzzo, and S. Stringari","Superfluid fraction in an interacting spatially modulated Bose-Einstein
  condensate",,"Phys. Rev. Lett. 130 226003 (2023)","10.1103/PhysRevLett.130.226003",,"cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  At zero temperature, a Galilean-invariant Bose fluid is expected to be fully
superfluid. Here we investigate theoretically and experimentally the quenching
of the superfluid density of a dilute Bose-Einstein condensate due to the
breaking of translational (and thus Galilean) invariance by an external 1D
periodic potential. Both Leggett's bound fixed by the knowledge of the total
density and the anisotropy of the sound velocity provide a consistent
determination of the superfluid fraction. The use of a large-period lattice
emphasizes the important role of two-body interactions on superfluidity.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:34:13 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 10:03:17 GMT""}]","2023-06-06"
"2302.01777","Jinyi Yang","Jinyi Yang, Xiaohui Fan, Ansh Gupta, Adam Myers, Nathalie
  Palanque-Delabrouille, Feige Wang, Christophe Y\`eche, Jessica Nicole
  Aguilar, Steven Ahlen, David Alexander, David Brooks, Kyle Dawson, Axel de la
  Macorra, Arjun Dey, Govinda Dhungana, Kevin Fanning, Andreu Font-Ribera,
  Satya Gontcho, Julien Guy, Klaus Honscheid, Stephanie Juneau, Theodore
  Kisner, Anthony Kremin, Laurent Le Guillou, Michael Levi, Christophe
  Magneville, Paul Martini, Aaron Meisner, Ramon Miquel, John Moustakas, Jundan
  Nie, Will Percival, Claire Poppett, Francisco Prada, Edward Schlafly, Gregory
  Tarl\'e, Mariana Vargas Magana, Benjamin Alan Weaver, Risa Wechsler, Rongpu
  Zhou, Zhimin Zhou, Hu Zou","DESI z >~ 5 Quasar Survey. I. A First Sample of 400 New Quasars at z ~
  4.7-6.6","28 pages, 9 figures, and 2 tables; submitted to AAS",,,,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the first results of a high-redshift ($z$ >~ 5) quasar survey using
the Dark Energy Spectroscopic Instrument (DESI). As a DESI secondary target
program, this survey is designed to carry out a systematic search and
investigation of quasars at $z$ >~ 5, up to redshift 6.8. The target selection
is based on the DESI Legacy Imaging Surveys (the Legacy Surveys) DR9
photometry, combined with the Pan-STARRS1 data and $J$-band photometry from
public surveys. A first quasar sample has been constructed from the DESI Survey
Validation 3 (SV3) and first-year observations until May 2022. This sample
includes more than 400 new quasars at redshift 4.7 <= $z$ < 6.6, down to 21.5
magnitude in the $z$ band, discovered from 35% of the entire target sample.
Remarkably, there are 220 new quasars identified at $z$ >= 5, more than one
third of existing quasars previously published at this redshift. The
observations so far result in an average success rate of 23% at $z$ > 4.7. The
current spectral dataset has already allowed analysis of interesting individual
objects (e.g., quasars with damped Ly$\alpha$ absorbers and broad absorption
line features), and statistical analysis will follow the survey's completion. A
set of science projects will be carried out leveraging this program, including
quasar luminosity function, quasar clustering, intergalactic medium, quasar
spectral properties, intervening absorbers, and properties of early
supermassive black holes. Additionally, a sample of 38 new quasars at $z$ ~
3.8-5.7 discovered from a pilot survey in the DESI SV1 is also published in
this paper.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:34:18 GMT""}]","2023-02-06"
"2302.01778","Andrew Madison","Andrew C. Madison, Adam L. Pintar, Craig R. Copeland, Natalia Farkas,
  and Samuel M. Stavis","Letter to the Editor Concerning Simultaneous, Single-Particle
  Measurements of Size and Loading Give Insights into the Structure of
  Drug-Delivery Nanoparticles","Peer reviewed and pending acceptance by ACS Nano",,,,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  The vexing error of excess variance in the sizing of single particles
degrades accuracy in applications ranging from quality control of nanoparticle
products to hazard assessment of nanoplastic byproducts. The particular
importance of lipid nanoparticles for vaccine and medicine delivery motivates
this comment on a publication$^{\textrm{1}}$ in ACS Nano. In Reference 1, the
benchmark measurements of a nanoparticle standard manifest large errors of the
size distribution that contradict the claim of validation. Such errors can bias
the correlation of fluorescence intensity as an optical proxy for the molecular
loading of lipid nanoparticles and give misleading insights from power-law
models of intensity$-$size data. Looking forward, measurement error models have
the potential to address this widespread issue.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:35:00 GMT""}]","2023-02-06"
"2302.01779","Karen Hatsagortsyan","Michael Klaiber, Karen Z. Hatsagortsyan, and Christoph H. Keitel","Relativistic analytical R-matrix (ARM) theory for strong-field
  ionization",,,"10.1103/PhysRevA.107.023107",,"physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The analytical R-matrix (ARM) theory has been known for an efficient
description of the Coulomb effects of the atomic core in strong-field
ionization in the nonrelativistic regime. We generalize the ARM theory into the
relativistic domain aiming at the application to strong-field ionization of
highly-charged ions in ultrastrong laser fields. Comparison with the
relativistic Coulomb-corrected strong field approximations (SFA) is provided,
highlighting the advantages and disadvantages. The weakly relativistic
asymptotics and its accordance with the nondipole Coulomb-corrected SFA are
examined. As an example of a physical application of the relativistic ARM, the
Coulomb enhancement of tunneling ionization probability for highly-charged ions
at the cutoff of the direct channel is discussed.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:35:25 GMT""}]","2023-03-01"
"2302.01780","Andreas Fl\""ors","A. Fl\""ors (1), R. F. Silva (2,3), J. Deprince (4,5), H. Carvajal
  Gallego (5), G. Leck (1,6), G. Mart\'inez-Pinedo (1,6,7), J. M. Sampaio
  (2,3), P. Amaro (8), J. P. Marques (2,3), S. Goriely (4), P. Quinet (5,9), P.
  Palmeri (5), M. Godefroid (10) ((1) GSI Helmholtzzentrum f\""ur
  Schwerionenforschung, Darmstadt, (2) Laborat\'orio de Instrumenta\c{c}\~ao e
  F\'isica Experimental de Part\'iculas (LIP), Lisboa, (3) Faculdade de
  Ci\^encias da Universidade de Lisboa, (4) Institut d'Astronomie et
  d'Astrophysique, Universit\'e Libre de Bruxelles, (5) Physique Atomique et
  Astrophysique, Universit\'e de Mons, (6) Institut f\""ur Kernphysik
  (Theoriezentrum), Fachbereich Physik, Technische Universit\""at Darmstadt, (7)
  Helmholtz Forschungsakademie Hessen f\""ur FAIR, GSI Helmholtzzentrum f\""ur
  Schwerionenforschung, Darmstadt (8) Laboratory for Instrumentation,
  Biomedical Engineering and Radiation Physics (LIBPhys-UNL), Caparica (9)
  IPNAS, Universit\'e de Li\`ege (10) Spectroscopy, Quantum Chemistry and
  Atmospheric Remote Sensing, Universit\'e Libre de Bruxelles)","Opacities of Singly and Doubly Ionised Neodymium and Uranium for
  Kilonova Emission Modeling","20 pages, 13 figures, submitted to MNRAS",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2017, the electromagnetic counterpart AT2017gfo to the binary neutron star
merger GW170817 was observed by all major telescopes on Earth. While it was
immediately clear that the transient following the merger event, is powered by
the radioactive decay of r-process nuclei, only a few tentative identifications
of light r-process elements have been made so far. One of the major limitations
for the identification of heavy nuclei based on light curves or spectral
features is incomplete or missing atomic data. While some progress has been
made on lanthanide atomic data over the last few years, for actinides very
little atomic data is available. We perform atomic structure calculations of
neodymium ($Z = 60$) as well as the corresponding actinide uranium ($Z = 92$).
Using two different codes (FAC and HFR) for the calculation of the atomic data,
we investigate the accuracy of the calculated data (energy levels and electric
dipole transitions) and their effect on kilonova opacities. For the FAC
calculations, we optimise the local central potential and the number of
included configurations and use a dedicated calibration technique to improve
the agreement between theoretical and available experimental atomic energy
levels (AELs). For ions with vast amounts of experimental data available, the
presented opacities agree quite well with previous estimations. On the other
hand, the optimisation and calibration method cannot be used for ions with only
a few available AELs. For these cases, where no experimental nor benchmarked
calculations are available, a large spread in the opacities estimated from the
atomic data obtained with the various atomic structure codes is observed, most
likely due to the uncertainty in the density of low-lying levels predicted by
theory. We find that the opacity of uranium is almost double the neodymium
opacity.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:36:02 GMT""}]","2023-02-06"
"2302.01781","Hans-Christian Herbig","Hans-Christian Herbig and Ana Mar\'ia Chaparro Casta\~neda","Higher Form Brackets for even Nambu-Poisson Algebras","29 pages",,,,"math.AG math.AC math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\boldsymbol{k}$ be a field of characteristic zero and
$A=\boldsymbol{k}[x_{1},...,x_{n}]/I$ with $I=(f_{1},...,f_{k})$ be an affine
algebra. We study Nambu-Poisson brackets on $A$ of arity $m\geq 2$, focusing on
the case when $m$ is even. We construct an $L_{\infty}$-algebroid on the
cotangent complex $\mathbb{L}_{A|\boldsymbol{k}}$, generalizing previous work
on the case when $A$ is a Poisson algebra. This structure is referred to as the
higher form brackets. The main tool is a $P_{\infty}$-structure on a resolvent
$R$ of $A$. These $P_{\infty}$- and $L_{\infty}$-structures are merely $\mathbb
Z_2$-graded for $m\neq 2$. We discuss several examples and propose a method to
obtain new ones that we call the outer tensor product. We compare our higher
form brackets with the form bracket of Vaisman. We introduce the notion of a
Lie-Rinehart $m$-algebra, the form bracket of a Nambu-Poisson bracket of even
arity being an example. We find a flat Nambu connection on the conormal module.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:36:46 GMT""}]","2023-02-06"
"2302.01782","Jin Liu","Xueshi Li, Shunfa Liu, Yuming Wei, Jiantao Ma, Changkun Song, Ying Yu,
  Rongbin Su, Wei Geng, Haiqiao Ni, Hanqing Liu, Xiangbin Su, Zhichuan Niu,
  Youling Chen and Jin Liu","Bright Semiconductor Single-Photon Sources Pumped by Heterogeneously
  Integrated Micropillar lasers with Electrical Injections",,,,,"quant-ph physics.optics","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The emerging hybrid integrated quantum photonics combines advantages of
different functional components into a single chip to meet the stringent
requirements for quantum information processing. Despite the tremendous
progress in hybrid integrations of III-V quantum emitters with silicon-based
photonic circuits and superconducting single-photon detectors, on-chip optical
excitations of quantum emitters via miniaturized lasers towards single-photon
sources (SPSs) with low power consumptions, small device footprints and
excellent coherence properties is highly desirable yet illusive. In this work,
we present realizations of bright semiconductor singe-photon sources
heterogeneously integrated with on-chip electrically-injected microlasers.
Different from previous one-by-one transfer printing technique implemented in
hybrid quantum dot (QD) photonic devices, multiple deterministically coupled
QD-circular Bragg Grating (CBG) SPSs were integrated with electrically-injected
micropillar lasers at one time via a potentially scalable transfer printing
process assisted by the wide-field photoluminescence (PL) imaging technique.
Optically pumped by electrically-injected microlasers, pure single photons are
generated with a high-brightness of a count rate of 3.8 M/s and an extraction
efficiency of 25.44%. Such a high-brightness is due to the enhancement by the
cavity mode of the CBG, which is confirmed by a Purcell factor of 2.5. Our work
provides a powerful tool for advancing hybrid integrated quantum photonics in
general and boosts the developments for realizing highly-compact,
energy-efficient and coherent SPSs in particular.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:37:56 GMT""}]","2023-02-06"
"2302.01783","Paolo Leonetti","Paolo Leonetti and Florian Luca","On the iterates of shifted Euler's function",,,,,"math.NT math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\varphi$ be the Euler's function and fix an integer $k\ge 0$. We show
that, for every initial value $x_1\ge 1$, the sequence of positive integers
$(x_n)_{n\ge 1}$ defined by $x_{n+1}=\varphi(x_n)+k$ for all $n\ge 1$ is
eventually periodic. Similarly, for every initial value $x_1,x_2\ge 1$, the
sequence of positive integers $(x_n)_{n\ge 1}$ defined by
$x_{n+2}=\varphi(x_{n+1})+\varphi(x_n)+k$ for all $n\ge 1$ is eventually
periodic, provided that $k$ is even.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:42:14 GMT""}]","2023-02-06"
"2302.01784","Satyabrata Mahapatra","Satyabrata Mahapatra (1), Rabindra N. Mohapatra (2) and Narendra Sahu
  (1) ((1) Indian Institute of Technology Hyderabad, (2) University of
  Maryland)","Gauged $L_e-L_{\mu}-L_{\tau}$ symmetry, fourth generation, neutrino mass
  and dark matter","31 pages, 10 captioned figures, Accepted for publication in Phys.
  Lett. B",,,,"hep-ph astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present two models where the familiar leptonic symmetry $L_e-L_\mu-L_\tau$
is a gauge symmetry. We show how anomaly cancellation constrains the allowed
theories, with one of them requiring a fourth sequential chiral standard model
fermion generation and a second one with three generations, requiring gauging
of $(L_e-L_\mu-L_\tau)-(B_1-B_2-B_3)$ with $B_a$ representing the baryon number
of the $a$th generation quarks. Unlike global $L_e-L_\mu-L_\tau$ models which
always leads to inverted mass hierarchy for neutrinos, the gauged version can
lead to normal hierarchy. We show how to construct realistic models in both the
cases and discuss the dark matter candidate in both. In our model, the breaking
of $U(1)_{L_e-L_\mu-L_\tau}$ is responsible for neutrino mass via type-I
mechanism whereas the real part of $U(1)_{L_e-L_\mu-L_\tau}$ breaking scalar
field (called $\phi$ here) plays the role of freeze-in dark matter candidate.
Since $\phi$ is unstable, for it to qualify as dark matter, its lifetime must
be larger than the age of the Universe, implying that the relic of $\phi$ is
generated through freeze-in mechanism and its mass must be less than an MeV. We
also discuss the possibility of explaining both muon and electron $(g-2)$ while
being consistent with the dark matter relic density and lifetime constraints.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:42:49 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 17:54:20 GMT""},{""version"":""v3"",""created"":""Wed, 7 Jun 2023 08:23:25 GMT""}]","2023-06-08"
"2302.01785","Magdalena Siwek","Magdalena Siwek, Rainer Weinberger, Lars Hernquist","Orbital Evolution of Binaries in Circumbinary Disks","12 pages, 8 figures. Submitted to MNRAS",,"10.1093/mnras/stad1131",,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We present the to-date largest parameter space exploration of binaries in
circumbinary disks (CBDs), deriving orbital evolution prescriptions for
eccentric, unequal mass binaries from our suite of hydrodynamic simulations. In
all cases, binary eccentricities evolve towards steady state values that
increase with mass ratio, and saturate at an equilibrium eccentricity $e_{\rm
b, eq} \sim 0.5$ in the large mass ratio regime, in line with resonant theory.
For binaries accreting at their combined Eddington limit, a steady state
eccentricity can be achieved within a few Megayears. Once at their steady state
eccentricities, binaries with $q_{\rm b} \gtrsim 0.3$ evolve towards
coalescence, while lower mass ratio systems expand due to CBD torques. We
discuss implications for population studies of massive black hole binaries,
protostars in binary systems, and post-common envelope binaries observed by
ground-based gravitational wave detectors.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:43:58 GMT""}]","2023-04-26"
"2302.01786","Mahmoud Kasem","Mahmoud SalahEldin Kasem, Mohamed Hamada, Islam Taj-Eddin","Customer Profiling, Segmentation, and Sales Prediction using AI in
  Direct Marketing",,,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  In an increasingly customer-centric business environment, effective
communication between marketing and senior management is crucial for success.
With the rise of globalization and increased competition, utilizing new data
mining techniques to identify potential customers is essential for direct
marketing efforts. This paper proposes a data mining preprocessing method for
developing a customer profiling system to improve sales performance, including
customer equity estimation and customer action prediction. The RFM-analysis
methodology is used to evaluate client capital and a boosting tree for
prediction. The study highlights the importance of customer segmentation
methods and algorithms to increase the accuracy of the prediction. The main
result of this study is the creation of a customer profile and forecast for the
sale of goods.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:45:09 GMT""}]","2023-02-06"
"2302.01787","Vincent Wolff","Vincent Wolff","From the Lie operad to the Grothendieck-Teichm\""uller group","16 pages Added two references Corrected some misprints and added some
  details",,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the deformation complex of the standard morphism from the degree $d$
shifted Lie operad to its polydifferential version, and prove that it is
quasi-isomorphic to the Kontsevich graph complex $\mathbf{GC}_d$. In
particular, we show that in the case $d=2$ the Grothendieck-Teichm\""uller group
$\mathbf{GRT_1}$ is a symmetry group (up to homotopy) of the aforementioned
morphism. We also prove that in the case $d=1$ corresponding to the usual Lie
algebras the standard morphism admits a unique homotopy non-trivial deformation
which is described explicitly with the help of the universal enveloping
construction. Finally we prove the rigidity of the strongly homotopy version of
the universal enveloping functor in the Lie theory.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:28:23 GMT""},{""version"":""v2"",""created"":""Fri, 10 Feb 2023 07:58:43 GMT""},{""version"":""v3"",""created"":""Fri, 21 Apr 2023 11:45:38 GMT""}]","2023-04-24"
"2302.01788","Tianyu Zhang","Tianyu Zhang, Tao Tan, Luyi Han, Xin Wang, Yuan Gao, Jonas Teuwen,
  Regina Beets-Tan, Ritse Mann","IMPORTANT-Net: Integrated MRI Multi-Parameter Reinforcement Fusion
  Generator with Attention Network for Synthesizing Absent Data",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic resonance imaging (MRI) is highly sensitive for lesion detection in
the breasts. Sequences obtained with different settings can capture the
specific characteristics of lesions. Such multi-parameter MRI information has
been shown to improve radiologist performance in lesion classification, as well
as improving the performance of artificial intelligence models in various
tasks. However, obtaining multi-parameter MRI makes the examination costly in
both financial and time perspectives, and there may be safety concerns for
special populations, thus making acquisition of the full spectrum of MRI
sequences less durable. In this study, different than naive input fusion or
feature concatenation from existing MRI parameters, a novel
$\textbf{I}$ntegrated MRI $\textbf{M}$ulti-$\textbf{P}$arameter
reinf$\textbf{O}$rcement fusion generato$\textbf{R}$ wi$\textbf{T}$h
$\textbf{A}$tte$\textbf{NT}$ion Network (IMPORTANT-Net) is developed to
generate missing parameters. First, the parameter reconstruction module is used
to encode and restore the existing MRI parameters to obtain the corresponding
latent representation information at any scale level. Then the multi-parameter
fusion with attention module enables the interaction of the encoded information
from different parameters through a set of algorithmic strategies, and applies
different weights to the information through the attention mechanism after
information fusion to obtain refined representation information. Finally, a
reinforcement fusion scheme embedded in a $V^{-}$-shape generation module is
used to combine the hierarchical representations to generate the missing MRI
parameter. Results showed that our IMPORTANT-Net is capable of generating
missing MRI parameters and outperforms comparable state-of-the-art networks.
Our code is available at
https://github.com/Netherlands-Cancer-Institute/MRI_IMPORTANT_NET.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:56:10 GMT""}]","2023-02-06"
"2302.01789","Dr Peter J. Bentley","Soo Ling Lim, Peter J. Bentley","The Agent-based Modelling for Human Behaviour Special Issue","extended version with references","Artificial Life Journal 29:1 2023",,,"cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  If human societies are so complex, then how can we hope to understand them?
Artificial Life gives us one answer. The field of Artificial Life comprises a
diverse set of introspective studies that largely ask the same questions,
albeit from many different perspectives: Why are we here? Who are we? Why do we
behave as we do? Starting with the origins of life provides us with fascinating
answers to some of these questions. However, some researchers choose to bring
their studies closer to the present day. We are after all, human. It has been a
few billion years since our ancestors were self-replicating molecules. Thus,
more direct studies of ourselves and our human societies can reveal truths that
may lead to practical knowledge. The papers in this special issue bring
together scientists who choose to perform this kind of research.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:56:22 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 16:35:47 GMT""}]","2023-02-07"
"2302.01790","Annika Reinke","Annika Reinke, Minu D. Tizabi, Michael Baumgartner, Matthias
  Eisenmann, Doreen Heckmann-N\""otzel, A. Emre Kavur, Tim R\""adsch, Carole H.
  Sudre, Laura Acion, Michela Antonelli, Tal Arbel, Spyridon Bakas, Arriel
  Benis, Matthew Blaschko, Florian B\""uttner, M. Jorge Cardoso, Veronika
  Cheplygina, Jianxu Chen, Evangelia Christodoulou, Beth A. Cimini, Gary S.
  Collins, Keyvan Farahani, Luciana Ferrer, Adrian Galdran, Bram van Ginneken,
  Ben Glocker, Patrick Godau, Robert Haase, Daniel A. Hashimoto, Michael M.
  Hoffman, Merel Huisman, Fabian Isensee, Pierre Jannin, Charles E. Kahn,
  Dagmar Kainmueller, Bernhard Kainz, Alexandros Karargyris, Alan
  Karthikesalingam, Hannes Kenngott, Jens Kleesiek, Florian Kofler, Thijs Kooi,
  Annette Kopp-Schneider, Michal Kozubek, Anna Kreshuk, Tahsin Kurc, Bennett A.
  Landman, Geert Litjens, Amin Madani, Klaus Maier-Hein, Anne L. Martel, Peter
  Mattson, Erik Meijering, Bjoern Menze, Karel G.M. Moons, Henning M\""uller,
  Brennan Nichyporuk, Felix Nickel, Jens Petersen, Susanne M. Rafelski, Nasir
  Rajpoot, Mauricio Reyes, Michael A. Riegler, Nicola Rieke, Julio
  Saez-Rodriguez, Clara I. S\'anchez, Shravya Shetty, Maarten van Smeden,
  Ronald M. Summers, Abdel A. Taha, Aleksei Tiulpin, Sotirios A. Tsaftaris, Ben
  Van Calster, Ga\""el Varoquaux, Manuel Wiesenfarth, Ziv R. Yaniv, Paul F.
  J\""ager, Lena Maier-Hein","Understanding metric-related pitfalls in image analysis validation",,,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Validation metrics are key for the reliable tracking of scientific progress
and for bridging the current chasm between artificial intelligence (AI)
research and its translation into practice. However, increasing evidence shows
that particularly in image analysis, metrics are often chosen inadequately in
relation to the underlying research problem. This could be attributed to a lack
of accessibility of metric-related knowledge: While taking into account the
individual strengths, weaknesses, and limitations of validation metrics is a
critical prerequisite to making educated choices, the relevant knowledge is
currently scattered and poorly accessible to individual researchers. Based on a
multi-stage Delphi process conducted by a multidisciplinary expert consortium
as well as extensive community feedback, the present work provides the first
reliable and comprehensive common point of access to information on pitfalls
related to validation metrics in image analysis. Focusing on biomedical image
analysis but with the potential of transfer to other fields, the addressed
pitfalls generalize across application domains and are categorized according to
a newly created, domain-agnostic taxonomy. To facilitate comprehension,
illustrations and specific examples accompany each pitfall. As a structured
body of information accessible to researchers of all levels of expertise, this
work enhances global comprehension of a key topic in image analysis validation.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:57:40 GMT""},{""version"":""v2"",""created"":""Thu, 9 Feb 2023 16:00:45 GMT""}]","2023-02-10"
"2302.01791","Jiayu Jiao Jr","Jiayu Jiao, Yu-Ming Tang, Kun-Yu Lin, Yipeng Gao, Jinhua Ma, Yaowei
  Wang and Wei-Shi Zheng","DilateFormer: Multi-Scale Dilated Transformer for Visual Recognition","Accepted to IEEE Transaction on Multimedia, 2023 (Submission date:
  22-Sep-2022)","IEEE Transaction on Multimedia, 2023",,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a de facto solution, the vanilla Vision Transformers (ViTs) are encouraged
to model long-range dependencies between arbitrary image patches while the
global attended receptive field leads to quadratic computational cost. Another
branch of Vision Transformers exploits local attention inspired by CNNs, which
only models the interactions between patches in small neighborhoods. Although
such a solution reduces the computational cost, it naturally suffers from small
attended receptive fields, which may limit the performance. In this work, we
explore effective Vision Transformers to pursue a preferable trade-off between
the computational complexity and size of the attended receptive field. By
analyzing the patch interaction of global attention in ViTs, we observe two key
properties in the shallow layers, namely locality and sparsity, indicating the
redundancy of global dependency modeling in shallow layers of ViTs.
Accordingly, we propose Multi-Scale Dilated Attention (MSDA) to model local and
sparse patch interaction within the sliding window. With a pyramid
architecture, we construct a Multi-Scale Dilated Transformer (DilateFormer) by
stacking MSDA blocks at low-level stages and global multi-head self-attention
blocks at high-level stages. Our experiment results show that our DilateFormer
achieves state-of-the-art performance on various vision tasks. On ImageNet-1K
classification task, DilateFormer achieves comparable performance with 70%
fewer FLOPs compared with existing state-of-the-art models. Our
DilateFormer-Base achieves 85.6% top-1 accuracy on ImageNet-1K classification
task, 53.5% box mAP/46.1% mask mAP on COCO object detection/instance
segmentation task and 51.1% MS mIoU on ADE20K semantic segmentation task.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:59:31 GMT""}]","2023-02-09"
"2302.01792","Marvin Bechtold","Marvin Bechtold, Johanna Barzen, Frank Leymann, Alexander Mandl,
  Julian Obst, Felix Truger, Benjamin Weder","Investigating the effect of circuit cutting in QAOA for the MaxCut
  problem on NISQ devices",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Noisy Intermediate-Scale Quantum (NISQ) devices are restricted by their
limited number of qubits and their short decoherence times. An approach
addressing these problems is quantum circuit cutting. It decomposes the
execution of a large quantum circuit into the execution of multiple smaller
quantum circuits with additional classical postprocessing. Since these smaller
quantum circuits require fewer qubits and gates, they are more suitable for
NISQ devices. To investigate the effect of quantum circuit cutting in a quantum
algorithm targeting NISQ devices, we design two experiments using the Quantum
Approximate Optimization Algorithm (QAOA) for the Maximum Cut (MaxCut) problem
and conduct them on state-of-the-art superconducting devices. Our first
experiment studies the influence of circuit cutting on the objective function
of QAOA, and the second evaluates the quality of results obtained by the whole
algorithm with circuit cutting. The results show that circuit cutting can
reduce the effects of noise in QAOA, and therefore, the algorithm yields better
solutions on NISQ devices.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:02:28 GMT""}]","2023-02-06"
"2302.01793","Ali Ghanbarzade","Ali Ghanbarzade and Hossein Soleimani","Self-Supervised In-Domain Representation Learning for Remote Sensing
  Image Scene Classification",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Transferring the ImageNet pre-trained weights to the various remote sensing
tasks has produced acceptable results and reduced the need for labeled samples.
However, the domain differences between ground imageries and remote sensing
images cause the performance of such transfer learning to be limited. Recent
research has demonstrated that self-supervised learning methods capture visual
features that are more discriminative and transferable than the supervised
ImageNet weights. We are motivated by these facts to pre-train the in-domain
representations of remote sensing imagery using contrastive self-supervised
learning and transfer the learned features to other related remote sensing
datasets. Specifically, we used the SimSiam algorithm to pre-train the
in-domain knowledge of remote sensing datasets and then transferred the
obtained weights to the other scene classification datasets. Thus, we have
obtained state-of-the-art results on five land cover classification datasets
with varying numbers of classes and spatial resolutions. In addition, By
conducting appropriate experiments, including feature pre-training using
datasets with different attributes, we have identified the most influential
factors that make a dataset a good choice for obtaining in-domain features. We
have transferred the features obtained by pre-training SimSiam on remote
sensing datasets to various downstream tasks and used them as initial weights
for fine-tuning. Moreover, we have linearly evaluated the obtained
representations in cases where the number of samples per class is limited. Our
experiments have demonstrated that using a higher-resolution dataset during the
self-supervised pre-training stage results in learning more discriminative and
general representations.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:03:07 GMT""}]","2023-02-06"
"2302.01794","Thomas Granzer","K. G. Strassmeier, M. Weber, D. Gruner, I. Ilyin, M. Steffen, M.
  Baratella, S. J\""arvinen, T. Granzer, S. A. Barnes, T. A. Carroll, M.
  Mallonn, D. Sablowski, P. Gabor, D. Brown, C. Corbally, and M. Franz","VPNEP: Detailed characterization of TESS targets around the Northern
  Ecliptic Pole",,"A&A 671, A7 (2023)","10.1051/0004-6361/202245255",,"astro-ph.SR astro-ph.EP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We embarked on a high-resolution optical spectroscopic survey of bright
Transiting Exoplanet Survey Satellite (TESS) stars around the Northern Ecliptic
Pole (NEP), dubbed the Vatican-Potsdam-NEP (VPNEP) survey. Our NEP coverage
comprises 1067 stars, of which 352 are bona fide dwarf stars and 715 are giant
stars, all cooler than spectral type F0 and brighter than V=8. m 5. Our aim is
to characterize these stars for the benefit of future studies in the community.
We analyzed the spectra via comparisons with synthetic spectra. Particular line
profiles were analyzed by means of eigen-profiles, equivalent widths, and
relative emission-line fluxes (when applicable). Two R=200 000 spectra were
obtained for each of the dwarf stars with the Vatican Advanced Technology
Telescope (VATT) and the Potsdam Echelle Polarimetric and Spectroscopic
Instrument (PEPSI), with typically three R=55 000 spectra obtained for the
giant stars with STELLA and the STELLA Echelle Spectrograph (SES). Combined
with V-band magnitudes, Gaia eDR3 parallaxes, and isochrones from the Padova
and Trieste Stellar Evolutionary Code, the spectra can be used to obtain radial
velocities, effective temperatures, gravities, rotational and turbulence
broadenings, stellar masses and ages, and abundances for 27 chemical elements,
as well as isotope ratios for lithium and carbon, line bisector spans,
convective blue-shifts (when feasible), and levels of magnetic activity from
H{\alpha}, H{\beta}, and the Ca ii infrared triplet. In this initial paper, we
discuss our analysis tools and biases, presenting our first results from a
pilot sub-sample of 54 stars (27 bona-fide dwarf stars observed with VATT+PEPSI
and 27 bona-fide giant stars observed with STELLA+SES) and making all reduced
spectra available to the community.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:03:10 GMT""}]","2023-03-01"
"2302.01795","Sirshendu Bhattacharyya","Protyush Nandi, Sirshendu Bhattacharyya and Subinay Dasgupta","Signature of quantum phase transition manifested in quantum fidelity at
  zero and finite temperatures","10 pages, 14 figures",,,,"cond-mat.stat-mech quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The signature of quantum phase transition is generally wiped out at finite
temperature. A few quantities that has been observed to carry this signature
through a non-analytic behavior are also limited to low temperatures only.
However, we have recently constructed a function from the quantum fidelity
which has the potential to bear a non-analytic signature at the quantum
critical point beyond low temperature regime. We demonstrate the behavior of
the corresponding rate function and the robustness of the non-analyticity over
a number of many-body Hamiltonians in different dimensions. We have also shown
that our rate function reduces to that used in the demonstration of the
dynamical quantum phase transition (DQPT) at zero temperature. It has been
further observed that, unlike DQPT, the long time limit of the rate function
can faithfully detect the equilibrium quantum phase transition as well.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:06:25 GMT""}]","2023-02-06"
"2302.01796","Shiqi Xia","Shiqi Xia, Yongsheng Liang, Liqin Tang, Daohong Song, Jingjun Xu,
  Zhigang Chen","Photonic realization of a generic type of graphene edge states
  exhibiting topological flat band","13 pages, 4 figures",,,,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cutting a honeycomb lattice (HCL) can end up with three types of edges
(zigzag, bearded and armchair), as is well known in the study of graphene edge
states. Here we theoretically investigate and experimentally demonstrate a
class of graphene edges, namely, the twig-shaped edges, using a photonic
platform, thereby observing edge states distinctive from those observed before.
Our main findings are: (i) the twig edge is a generic type of HCL edges
complementary to the armchair edge, formed by choosing the right primitive cell
rather than simple lattice cutting or Klein edge modification; (ii) the twig
edge states form a complete flat band across the Brillouin zone with
zero-energy degeneracy, characterized by nontrivial topological winding of the
lattice Hamiltonian; (iii) the twig edge states can be elongated or compactly
localized along the boundary, manifesting both flat band and topological
features. Such new edge states are realized in a laser-written photonic
graphene and well corroborated by numerical simulations. Our results may
broaden the understanding of graphene edge states, bringing about new
possibilities for wave localization in artificial Dirac-like materials.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:06:51 GMT""}]","2023-02-06"
"2302.01797","Georgios Grekas","Georgios Grekas, Patricia-Lia Pop-Ghe, Eckhard Quand, Richard D. James","Theory of intermediate twinning and spontaneous polarization in the
  phase transformations of ferroelectric potassium sodium niobate",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Potassium sodium niobate is considered a prominent material system as a
substitute for toxic lead-containing ferroelectric materials. It exhibits
first-order phase transformations and ferroelectricity with potential
applications ranging from energy conversion to innovative cooling technologies,
hereby addressing urgent societal challenges. However, a major obstacle in the
application of potassium sodium niobate is its multi-scale heterogeneity and
the lack of understanding of its phase transition pathway and microstructure.
This can be seen from the findings of Pop-Ghe 2021 et al. [1] which also reveal
the occurrence of intermediate twinning during the phase transition. Here we
show that intermediate twinning is a consequence of energy minimization. We
employ a geometrically nonlinear electroelastic energy function for potassium
sodium niobate, including the cubic-tetragonal-orthorhombic transformations and
ferroelectricity. The construction of the minimizers is based on compatibility
conditions which ensure continuous deformations and pole-free interfaces. These
minimizers agree with the experimental observations, including laminates
between the tetragonal variants under the cubic to tetragonal transformation,
crossing twins under the tetragonal to orthorhombic transformation,
intermediate twinning and spontaneous polarization. This shows how the full
nonlinear electroelastic model provides a powerful tool in understanding,
exploring and tailoring the electromechanical properties of complex
ferroelectric ceramics.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:07:22 GMT""}]","2023-02-06"
"2302.01798","Huan-Hsin Tseng","Huan-Hsin Tseng, Hsin-Yi Lin, Kuo-Hsuan Hung and Yu Tsao","Interpretations of Domain Adaptations via Layer Variational Analysis","Published at ICLR 2023",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transfer learning is known to perform efficiently in many applications
empirically, yet limited literature reports the mechanism behind the scene.
This study establishes both formal derivations and heuristic analysis to
formulate the theory of transfer learning in deep learning. Our framework
utilizing layer variational analysis proves that the success of transfer
learning can be guaranteed with corresponding data conditions. Moreover, our
theoretical calculation yields intuitive interpretations towards the knowledge
transfer process. Subsequently, an alternative method for network-based
transfer learning is derived. The method shows an increase in efficiency and
accuracy for domain adaptation. It is particularly advantageous when new domain
data is sufficiently sparse during adaptation. Numerical experiments over
diverse tasks validated our theory and verified that our analytic expression
achieved better performance in domain adaptation than the gradient descent
method.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:10:17 GMT""},{""version"":""v2"",""created"":""Sun, 12 Mar 2023 02:19:57 GMT""},{""version"":""v3"",""created"":""Thu, 4 May 2023 03:04:11 GMT""},{""version"":""v4"",""created"":""Tue, 9 May 2023 16:28:12 GMT""}]","2023-05-10"
"2302.01799","Giovanni Pireddu","Th\^e Hoang Ngoc Minh, Jeongmin Kim, Giovanni Pireddu, Iurii Chubak,
  Swetha Nair and Benjamin Rotenberg","Electrical noise in electrolytes: a theoretical perspective",,,,,"physics.chem-ph cond-mat.stat-mech physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Seemingly unrelated experiments such as electrolyte transport through
nanotubes, nano-scale electrochemistry, NMR relaxometry and Surface Force
Balance measurements, all probe electrical fluctuations: of the electric
current, the charge and polarization, the field gradient (for quadrupolar
nuclei) and the coupled mass/charge densities. The fluctuations of such various
observables arise from the same underlying microscopic dynamics of the ions and
solvent molecules. In principle, the relevant length and time scales of these
dynamics are encoded in the dynamic structure factors. However modelling the
latter for frequencies and wavevectors spanning many orders of magnitude
remains a great challenge to interpret the experiments in terms of physical
process such as solvation dynamics, diffusion, electrostatic and hydrodynamic
interactions between ions, interactions with solid surfaces, etc. Here, we
highlight the central role of the charge-charge dynamic structure factor in the
fluctuations of electrical observables in electrolytes and offer a unifying
perspective over a variety of complementary experiments. We further analyze
this quantity in the special case of an aqueous NaCl electrolyte, using
simulations with explicit ions and an explicit or implicit solvent. We discuss
the ability of the standard Poisson-Nernst-Planck theory to capture the
simulation results, and how the predictions can be improved. We finally discuss
the contributions of ions and water to the total charge fluctuations. This work
illustrates an ongoing effort towards a comprehensive understanding of
electrical fluctuations in bulk and confined electrolytes, in order to enable
experimentalists to decipher the microscopic properties encoded in the measured
electrical noise.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:11:28 GMT""}]","2023-02-06"
"2302.01800","Kaleb Phipps","Kaleb Phipps and Benedikt Heidrich and Marian Turowski and Moritz
  Wittig and Ralf Mikut and Veit Hagenmeyer","Creating Probabilistic Forecasts from Arbitrary Deterministic Forecasts
  using Conditional Invertible Neural Networks","Preprint submitted to the International Journal of Forecasting",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In various applications, probabilistic forecasts are required to quantify the
inherent uncertainty associated with the forecast. However, numerous modern
forecasting methods are still designed to create deterministic forecasts.
Transforming these deterministic forecasts into probabilistic forecasts is
often challenging and based on numerous assumptions that may not hold in
real-world situations. Therefore, the present article proposes a novel approach
for creating probabilistic forecasts from arbitrary deterministic forecasts. In
order to implement this approach, we use a conditional Invertible Neural
Network (cINN). More specifically, we apply a cINN to learn the underlying
distribution of the data and then combine the uncertainty from this
distribution with an arbitrary deterministic forecast to generate accurate
probabilistic forecasts. Our approach enables the simple creation of
probabilistic forecasts without complicated statistical loss functions or
further assumptions. Besides showing the mathematical validity of our approach,
we empirically show that our approach noticeably outperforms traditional
methods for including uncertainty in deterministic forecasts and generally
outperforms state-of-the-art probabilistic forecasting benchmarks.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:11:39 GMT""}]","2023-02-06"
"2302.01801","Andrei Moroianu","Adri\'an Andrada, Viviana del Barco, Andrei Moroianu","Locally conformally product structures on solvmanifolds","34 pages",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study left invariant locally conformally product structures on simply
connected Lie groups and give their complete description in the solvable
unimodular case. Based on previous classification results, we then obtain the
complete list of solvable unimodular Lie algebras up to dimension 5 which carry
LCP structures, and study the existence of lattices in the corresponding simply
connected Lie groups.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:12:17 GMT""}]","2023-02-06"
"2302.01802","Ali Girayhan \""Ozbay","Ali Girayhan \""Ozbay and Sylvain Laizet","FR3D: Three-dimensional Flow Reconstruction and Force Estimation for
  Unsteady Flows Around Arbitrary Bluff Bodies via Conformal Mapping Aided
  Convolutional Autoencoders","29 pages, 10 figures. Under review at International Journal of Heat
  and Fluid Flow",,,,"physics.flu-dyn cs.AI physics.comp-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In many practical fluid dynamics experiments, measuring variables such as
velocity and pressure is possible only at a limited number of sensor locations,
or for a few two-dimensional planes in the flow. However, knowledge of the full
fields is necessary to understand the dynamics of many flows. Deep learning
reconstruction of full flow fields from sparse measurements has recently
garnered significant research interest, as a way of overcoming this limitation.
This task is referred to as the flow reconstruction (FR) task. In the present
study, we propose a convolutional autoencoder based neural network model,
dubbed FR3D, which enables FR to be carried out for three-dimensional flows
around extruded 3D objects with arbitrary cross-sections. An innovative mapping
approach, whereby multiple fluid domains are mapped to an annulus, enables FR3D
to generalize its performance to objects not encountered during training. We
conclusively demonstrate this generalization capability using a dataset
composed of 80 training and 20 testing geometries, all randomly generated. We
show that the FR3D model reconstructs pressure and velocity components with a
few percentage points of error. Additionally, using these predictions, we
accurately estimate the Q-criterion fields as well lift and drag forces on the
geometries.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:13:57 GMT""}]","2023-02-06"
"2302.01803","Pablo D. Esquinazi","Markus Stiller and Pablo D. Esquinazi","Defect-induced magnetism in TiO$_2$: An example of quasi 2D magnetic
  order with perpendicular anisotropy","6 pages, 3 figures","Front. Phys., Volume 11, 01 February 2023","10.3389/fphy.2023.1124924",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic order at room temperature induced by atomic lattice defects, like
vacancies, interstitials or pairs of them, has been observed in a large number
of different nonmagnetic hosts, such as pure graphite, oxides and silicon-based
materials. High Curie temperatures and time independent magnetic response at
room temperature indicate the extraordinary robustness of this new phenomenon
in solid state magnetism. In this work, we review experimental and theoretical
results in pure TiO$_2$ (anatase), which magnetic order can be triggered by
low-energy ion irradiation. In particular, we discuss the systematic
observation of an ultrathin magnetic layer with perpendicular magnetic
anisotropy at the surface of this oxide.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:16:09 GMT""}]","2023-02-06"
"2302.01804","Frank Haberl","F. Haberl, C. Maitra, D. Kaltenbrunner, D.A.H. Buckley, I.M. Monageng,
  A. Udalski, V. Doroshenko, L. Ducci, I. Kreykenbohm, P. Maggi, A. Rau, G.
  Vasilopoulos, P. Weber, J. Wilms","SRG/eROSITA-triggered XMM-Newton observations of three Be/X-ray binaries
  in the LMC: Discovery of X-ray pulsations","Accepted for publication in Astronomy & Astrophysics","A&A 671, A90 (2023)","10.1051/0004-6361/202245807",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using data from eROSITA, the soft X-ray instrument aboard
Spectrum-Roentgen-Gamma (SRG), we report the discovery of two new hard
transients, eRASSU J050810.4-660653 and eRASSt J044811.1-691318, in the Large
Magellanic Cloud. We also report the detection of the Be/X-ray binary RX
J0501.6-7034 in a bright state. We initiated follow-up observations to
investigate the nature of the new transients and to search for X-ray pulsations
coming from RX J0501.6-7034. We analysed the X-ray spectra and light curves
from our XMM-Newton observations, obtained optical spectra using the South
African Large Telescope to look for Balmer emission lines and utilised the
archival data from the Optical Gravitational Lensing Experiment (OGLE) for the
long-term monitoring of the optical counterparts. We find X-ray pulsations for
eRASSU J050810.4-660653, RX J0501.6-7034, and eRASSt J044811.1-691318 of 40.6
s, 17.3 s, and 784 s, respectively. The Halpha emission lines with equivalent
widths of -10.4 A (eRASSU J050810.4-660653) and -43.9 A (eRASSt
J044811.1-691318) were measured, characteristic for a circumstellar disc around
Be stars. The OGLE I- and V-band light curves of all three systems exhibit
strong variability. A regular pattern of deep dips in the light curves of RX
J0501.6-7034 suggests an orbital period of ~451 days. We identify the two new
hard eROSITA transients eRASSU J050810.4-660653 and eRASSt J044811.1-691318 and
the known Be/X-ray binary RX J0501.6-7034 as Be/X-ray binary pulsars.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:17:00 GMT""}]","2023-03-15"
"2302.01805","Hans De Raedt","Hans De Raedt, Mikhail I. Katsnelson, Manpreet S. Jattana, Vrinda
  Mehta, Madita Willsch, Dennis Willsch, Kristel Michielsen, Fengping Jin","Model-free inequality for data of Einstein-Podolsky-Rosen-Bohm
  experiments","Extended version of Annals of Physics, Volume 453, 169314, 2023
  (https://doi.org/10.1016/j.aop.2023.169314)",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  We present a new inequality constraining correlations obtained when
performing Einstein-Podolsky-Rosen-Bohm experiments. The proof does not rely on
mathematical models that are imagined to have produced the data and is
therefore ``model-free''. The new inequality contains the model-free version of
the well-known Bell-CHSH inequality as a special case. A violation of the
latter implies that not all the data pairs in four data sets can be reshuffled
to create quadruples. This conclusion provides a new perspective on the
implications of the violation of Bell-type inequalities by experimental data.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:17:07 GMT""}]","2023-05-31"
"2302.01806","Hoang Nguyen Hung Van","Hoang Van","Mitigating Data Scarcity for Large Language Models","155 pages, 26 tables, 11 figures",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, pretrained neural language models (PNLMs) have taken the
field of natural language processing by storm, achieving new benchmarks and
state-of-the-art performances. These models often rely heavily on annotated
data, which may not always be available. Data scarcity are commonly found in
specialized domains, such as medical, or in low-resource languages that are
underexplored by AI research. In this dissertation, we focus on mitigating data
scarcity using data augmentation and neural ensemble learning techniques for
neural language models. In both research directions, we implement neural
network algorithms and evaluate their impact on assisting neural language
models in downstream NLP tasks. Specifically, for data augmentation, we explore
two techniques: 1) creating positive training data by moving an answer span
around its original context and 2) using text simplification techniques to
introduce a variety of writing styles to the original training data. Our
results indicate that these simple and effective solutions improve the
performance of neural language models considerably in low-resource NLP domains
and tasks. For neural ensemble learning, we use a multilabel neural classifier
to select the best prediction outcome from a variety of individual pretrained
neural language models trained for a low-resource medical text simplification
task.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:17:53 GMT""}]","2023-02-06"
"2302.01807","Elena Kozlikin","Elena Kozlikin, Robert Lilow, Martin Pauly, Alexander Schuckert, Andre
  Salzinger, Matthias Bartelmann and Matthias Weidem\""uller","Ultracold plasmas from strongly anti-correlated Rydberg gases in the
  Kinetic Field Theory formalism",,,,,"cond-mat.quant-gas cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamics of correlated systems is relevant in many fields ranging from
cosmology to plasma physics. However, they are challenging to predict and
understand even for classical systems due to the typically large numbers of
particles involved. Here, we study the evolution of an ultracold, correlated
many-body system with repulsive interactions and initial correlations set by
the Rydberg blockade using the analytical framework of Kinetic Field Theory
(KFT). The KFT formalism is based on the path-integral formulation for
classical mechanics and was first developed and successfully used in cosmology
to describe structure formation in Dark Matter. The theoretical framework
offers a high flexibility regarding the initial configuration and interactions
between particles and, in addition, is computationally cheap. More importantly,
the analytic approach allows us to gain better insight into the processes which
dominate the dynamics. In this work we show that KFT can be applied in a much
more general context and study the evolution of a correlated ion plasma. We
find good agreement between the analytical KFT results for the evolution of the
correlation function and results obtained from numerical simulations. We use
the correlation functions obtained with KFT to compute the temperature increase
in the ionic system due to disorder-induced heating. For certain choices of
parameters we observe that the effect can be reversed, leading to correlation
cooling. Due to its numerical efficiency as compared to numerical simulations,
a detailed study using KFT can help to constrain parameter spaces where
disorder-induced heating is minimal in order to reach the regime of strong
coupling.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:18:58 GMT""}]","2023-02-06"
"2302.01808","Sandra Albrechtsen","Sandra Albrechtsen","Refining trees of tangles in abstract separation systems I: Inessential
  parts","This is the journal version of this paper. An extended version
  containing additional examples is available in this ArXiv thread as v1",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Robertson and Seymour proved two fundamental theorems about tangles in
graphs: the tree-of-tangles theorem, which says that every graph has a
tree-decomposition such that distinguishable tangles live in different nodes of
the tree, and the tangle-tree duality theorem, which says that graphs without a
$k$-tangle have a tree-decomposition that witnesses the non-existence of such
tangles, in that $k$-tangles would have to live in a node but no node is large
enough to accommodate one.
  Erde combined these two fundamental theorems into one, by constructing a
single tree-decomposition such that every node either accommodates a single
$k$-tangle or is too small to accommodate one. Such a tree-decomposition thus
shows at a glance how many $k$-tangles a graph has and where they are.
  The two fundamental theorems have since been extended to abstract separation
systems, which support tangles in more general discrete structures. In this
paper we extend Erde's unified theorem to such general systems.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:21:10 GMT""},{""version"":""v2"",""created"":""Mon, 6 Feb 2023 13:34:32 GMT""}]","2023-02-07"
"2302.01809","Alejandro Yacomotti","Kaiwen Ji, Bruno Garbin, Melissa Hedir, Juan A. Levenson, and
  Alejandro Yacomotti","Non-Hermitian zero mode laser in a nanophotonic trimer","5 pages, 4 figures",,,,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symmetry-protected zero modes in arrays of coupled optical elements have
attracted considerable attention because they are expected to be robust against
coupling disorders. In the Hermitian limit, zero modes are dark ones, i.e. the
intensity in one sublattice vanishes; yet, in a non-Hermitian counterpart, zero
modes can be bright and feature {\pi}/2 phase difference between sublattices.
In this work, we report on the direct observation of a lasing zero mode in a
non-Hermitian three coupled nanocavity array. We show efficient excitation for
nearly equal pump power in the two extreme cavities. Furthermore, its
efficiency can be dynamically controlled by pumping the center cavity. The
realization of zero mode lasing in large arrays of coupled nanolasers has
potential applications in laser-mode engineering and it opens up promising
avenues in optical computing.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:21:44 GMT""}]","2023-02-06"
"2302.01810","Fabian Heldmann","Fabian Heldmann, Sarah Berkhahn, Matthias Ehrhardt, Kathrin Klamroth","PINN Training using Biobjective Optimization: The Trade-off between Data
  Loss and Residual Loss","47 pages",,,,"cs.LG cs.AI math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physics informed neural networks (PINNs) have proven to be an efficient tool
to represent problems for which measured data are available and for which the
dynamics in the data are expected to follow some physical laws. In this paper,
we suggest a multiobjective perspective on the training of PINNs by treating
the data loss and the residual loss as two individual objective functions in a
truly biobjective optimization approach. As a showcase example, we consider
COVID-19 predictions in Germany and built an extended
susceptibles-infected-recovered (SIR) model with additionally considered
leaky-vaccinated and hospitalized populations (SVIHR model) to model the
transition rates and to predict future infections. SIR-type models are
expressed by systems of ordinary differential equations (ODEs). We investigate
the suitability of the generated PINN for COVID-19 predictions and compare the
resulting predicted curves with those obtained by applying the method of
non-standard finite differences to the system of ODEs and initial data. The
approach is applicable to various systems of ODEs that define dynamical
regimes. Those regimes do not need to be SIR-type models, and the corresponding
underlying data sets do not have to be associated with COVID-19.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:27:50 GMT""}]","2023-02-06"
"2302.01811","Arunkumar Bhattar","Liyi Li, Arunkumar Bhattar, Le Chang, Mingwei Zhu, and Aravind Machiry","CheckedCBox: Type Directed Program Partitioning with Checked C for
  Incremental Spatial Memory Safety","Liyi Li and Arunkumar Bhattar contributed equally to this work",,,,"cs.CR cs.PL","http://creativecommons.org/licenses/by/4.0/","  Spatial memory safety violation is still a major issue for C programs.
Checked-C is a safe dialect of C and extends it with Checked pointer types and
annotations that guarantee spatial memory safety in a backward-compatible
manner, allowing the mix of checked pointers and regular (unchecked) pointer
types. However, unchecked code vulnerabilities can violate the checked code's
spatial safety guarantees. We present CheckedCBox, which adds a flexible,
type-directed program partitioning mechanism to Checked-C, by enhancing the
Checked-C type system with tainted types that enable flexible partitioning of
the program into checked and unchecked regions, in a manner such that unchecked
region code does not affect the spatial safety in the checked region. We
formalize our type system and prove the non-crashing and non-exposure
properties of a well-typed CheckedCBox program. We implemented CheckedCBox in a
configurable manner, which enables us to use existing sandbox mechanisms (eg
WebAssembly) to execute programs. Consequently, in doing so, CheckedCBox has
prevented four known vulnerabilities by efficiently partitioning the program.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:31:35 GMT""}]","2023-02-06"
"2302.01812","Duanduan Wan","Zichen Qin, Tao Liu, Duanduan Wan","Effects of orientational and positional randomness of particles on
  photonic band gap",,,"10.1103/PhysRevB.107.174110",,"cond-mat.soft physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A recent work [PRL, 126, 208002 (2021)] has explored how thermal
noise-induced randomness in a self-assembled photonic crystal affects photonic
band gaps (PBGs). For the system of a two-dimensional photonic crystal composed
of a self-assembled array of rods with square cross sections, it was found that
its PBGs can exist over an extensive range of packing densities.
Counterintuitively, at intermediate packing densities, the transverse magnetic
(TM) band gap of the self-assembled system can be larger than that of its
corresponding perfect system (rods arranged in a perfect square lattice and
having identical orientations). Due to shape anisotropicity, the randomness in
the self-assembled system contains two kinds of randomness, i.e., positional
and orientational randomness of the particles. In this work, we further
investigate how PBGs are influenced solely by positional or orientational
randomness. We find that compared to the perfect situation, the introduction of
only orientational randomness decreases the transverse electric (TE) band gap
while having no obvious effects on the transverse magnetic (TM) band gap. In
contrast, the introduction of only positional randomness decreases the TE band
gap significantly, while it can widen or narrow the TM band gap, depending on
the parameter range. We also discuss the thermal (i.e., self-assembled) system
where two kinds of randomness are present. Our study contributes to a better
understanding of the role orientational randomness and positional randomness
play on PBGs, and may benefit the PBG engineering of photonic crystals through
self-assembly approaches.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:34:47 GMT""}]","2023-05-31"
"2302.01813","Miriam H\""agele","Miriam H\""agele and Johannes Eschrich and Lukas Ruff and Maximilian
  Alber and Simon Schallenberg and Adrien Guillot and Christoph Roderburg and
  Frank Tacke and Frederick Klauschen","Leveraging weak complementary labels to improve semantic segmentation of
  hepatocellular carcinoma and cholangiocarcinoma in H&E-stained slides",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we present a deep learning segmentation approach to classify
and quantify the two most prevalent primary liver cancers - hepatocellular
carcinoma and intrahepatic cholangiocarcinoma - from hematoxylin and eosin
(H&E) stained whole slide images. While semantic segmentation of medical images
typically requires costly pixel-level annotations by domain experts, there
often exists additional information which is routinely obtained in clinical
diagnostics but rarely utilized for model training. We propose to leverage such
weak information from patient diagnoses by deriving complementary labels that
indicate to which class a sample cannot belong to. To integrate these labels,
we formulate a complementary loss for segmentation. Motivated by the medical
application, we demonstrate for general segmentation tasks that including
additional patches with solely weak complementary labels during model training
can significantly improve the predictive performance and robustness of a model.
On the task of diagnostic differentiation between hepatocellular carcinoma and
intrahepatic cholangiocarcinoma, we achieve a balanced accuracy of 0.91 (CI
95%: 0.86 - 0.95) at case level for 165 hold-out patients. Furthermore, we also
show that leveraging complementary labels improves the robustness of
segmentation and increases performance at case level.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:35:54 GMT""}]","2023-02-06"
"2302.01814","Dan Huang","Dan Huang, Shanshan Chen","Dynamics of a delayed population patch model with the dispersion matrix
  incorporating population loss","31pages, 10 figures",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we consider a general single population model with delay and
patch structure, which could model the population loss during the dispersal. It
is shown that the model admits a unique positive equilibrium when the dispersal
rate is smaller than a critical value. The stability of the positive
equilibrium and associated Hopf bifurcation are investigated when the dispersal
rate is small or near the critical value. Moreover, we show the effect of
network topology on Hopf bifurcation values for a delayed logistic population
model.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:37:36 GMT""}]","2023-02-06"
"2302.01815","Jiehua Chen","Jiehua Chen and Gergely Cs\'aji","Optimal Capacity Modification for Many-To-One Matching Problems","Extended abstract accepted at AAMAS 2023",,,,"cs.GT cs.MA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider many-to-one matching problems, where one side consists of
students and the other side of schools with capacity constraints. We study how
to optimally increase the capacities of the schools so as to obtain a stable
and perfect matching (i.e., every student is matched) or a matching that is
stable and Pareto-efficient for the students. We consider two common optimality
criteria, one aiming to minimize the sum of capacity increases of all schools
(abbrv. as MinSum) and the other aiming to minimize the maximum capacity
increase of any school (abbrv. as MinMax). We obtain a complete picture in
terms of computational complexity: Except for stable and perfect matchings
using the MinMax criteria which is polynomial-time solvable, all three
remaining problems are NP-hard. We further investigate the parameterized
complexity and approximability and find that achieving stable and
Pareto-efficient matchings via minimal capacity increases is much harder than
achieving stable and perfect matchings.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:37:53 GMT""}]","2023-02-06"
"2302.01816","Jaros{\l}aw Gruszka","Jaros{\l}aw Gruszka, Janusz Szwabi\'nski","Portfolio Optimisation via the Heston Model Calibrated to Real Asset
  Data","24 pages, 4 figures",,,,"q-fin.PM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The debate between active and passive investment strategies has been ongoing
for many years and is far from being over. In this paper, we show that the
choice of an optimal portfolio management strategy depends on an investment
climate, which we measure via the parameters of the Heston model calibrated to
the real stock market data. Depending on the values of those parameters, the
passive strategy may namely outperform the active ones or vice versa. The
method is tested on three stock market indices: S\&P500, DAX and WIG20.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:47:30 GMT""}]","2023-02-06"
"2302.01817","Leonardo Maria Millefiori","Giovanni Soldi, Domenico Gaglione, Simone Raponi, Nicola Forti, Enrica
  d'Afflisio, Pawe{\l} Kowalski, Leonardo M. Millefiori, Dimitris Zissis, Paolo
  Braca, Peter Willett, Alain Maguer, Sandro Carniel, Giovanni Sembenini,
  Catherine Warner","Monitoring of Underwater Critical Infrastructures: the Nord Stream and
  Other Recent Case Studies",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The explosions on September 26th, 2022, which damaged the gas pipelines of
Nord Stream 1 and Nord Stream 2, have highlighted the need and urgency of
improving the resilience of Underwater Critical Infrastructures (UCIs).
Comprising gas pipelines and power and communication cables, these connect
countries worldwide and are critical for the global economy and stability. An
attack targeting multiple of such infrastructures simultaneously could
potentially cause significant damage and greatly affect various aspects of
daily life. Due to the increasing number and continuous deployment of UCIs,
existing underwater surveillance solutions, such as Autonomous Underwater
Vehicles (AUVs) or Remotely Operated Vehicles (ROVs), are not adequate enough
to ensure thorough monitoring. We show that the combination of information from
both underwater and above-water surveillance sensors enables achieving
Seabed-to-Space Situational Awareness (S3A), mainly thanks to Artificial
Intelligence (AI) and Information Fusion (IF) methodologies. These are designed
to process immense volumes of information, fused from a variety of sources and
generated from monitoring a very large number of assets on a daily basis. The
learned knowledge can be used to anticipate future behaviors, identify threats,
and determine critical situations concerning UCIs. To illustrate the
capabilities and importance of S3A, we consider three events that occurred in
the second half of 2022: the aforementioned Nord Stream explosions, the cutoff
of the underwater communication cable SHEFA-2 connecting the Shetland Islands
and the UK mainland, and the suspicious activity of a large vessel in the
Adriatic Sea. Specifically, we provide analyses of the available data, from
Automatic Identification System (AIS) and satellite data, integrated with
possible contextual information, e.g., bathymetry, weather conditions, and
human intelligence.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:49:23 GMT""}]","2023-02-06"
"2302.01818","Ivan Kostyuk","Ivan Kostyuk, Robert Lilow and Matthias Bartelmann","Baryon-photon interactions in Resummed Kinetic Field Theory","16 pages, 3 figures",,,,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore how interactions between baryons and photons can be incorporated
into Kinetic Field Theory (KFT), a description of cosmic structure formation
based on classical Hamiltonian particle dynamics. In KFT, baryons are described
as effective mesoscopic particles which represent fluid elements governed by
the hydrodynamic equations. In this paper, we modify the mesoscopic particle
model to include pressure effects exerted on baryonic matter through
interactions with photons. As a proof of concept, we use this extended
mesoscopic model to describe the tightly coupled baryon-photon fluid between
matter-radiation equality and recombination. We show that this model can
qualitatively reproduce the formation of baryon-acoustic oscillations in the
cosmological power spectrum.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:53:53 GMT""}]","2023-02-06"
"2302.01819","Mehrdad Shafiei Dizaji","Mehrdad Shafiei Dizaji","A Hybrid Training Algorithm for Continuum Deep Learning Neuro-Skin
  Neural Network","9 pages, 5 figures. arXiv admin note: substantial text overlap with
  arXiv:2007.04796",,,,"cs.NE","http://creativecommons.org/licenses/by/4.0/","  In this brief paper, a learning algorithm is developed for Deep Learning
NeuroSkin Neural Network to improve their learning properties. Neuroskin is a
new type of neural network presented recently by the authors. It is comprised
of a cellular membrane which has a neuron attached to each cell. The neuron is
the cells nucleus. A neuroskin is modelled using finite elements. Each element
of the finite element represents a cell. Each cells neuron has dendritic fibers
which connects it to the nodes of the cell. On the other hand, its axon is
connected to the nodes of a number of different neurons. The neuroskin is
trained to contract upon receiving an input. The learning takes place during
updating iterations using sensitivity analysis. It is shown that while the
neuroskin cannot present the desirable response, it improves gradually to the
desired level.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:54:06 GMT""}]","2023-02-06"
"2302.01820","Thomas Nindel","Thomas K. Nindel, Mohcen Hafidi, Tom\'a\v{s} Iser and Alexander Wilkie","Automatic inference of a anatomically meaningful solid wood texture from
  a single photograph",,,,,"cs.GR","http://creativecommons.org/licenses/by/4.0/","  Wood is a volumetric material with a very large appearance gamut that is
further enlarged by numerous finishing techniques. Computer graphics has made
considerable progress in creating sophisticated and flexible appearance models
that allow convincing renderings of wooden materials.
  However, these do not yet allow fully automatic appearance matching to a
concrete exemplar piece of wood, and have to be fine-tuned by hand. More
general appearance matching strategies are incapable of reconstructing
anatomically meaningful volumetric information. This is essential for
applications where the internal structure of wood is significant, such as
non-planar furniture parts machined from a solid block of wood, translucent
appearance of thin wooden layers, or in the field of dendrochronology.
  In this paper, we provide the two key ingredients for automatic matching of a
procedural wood appearance model to exemplar photographs: a good
initialization, built on detecting and modelling the ring structure, and a
phase-based loss function that allows to accurately recover growth ring
deformations and gives anatomically meaningful results.
  Our ring-detection technique is based on curved Gabor filters, and robustly
works for a considerable range of wood types.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:54:24 GMT""}]","2023-02-06"
"2302.01821","Ryo Kainuma","Ryo Kainuma, Keita Matsumoto, Toshimitsu Ito and Takuya Satoh","Sub-millimeter propagation of antiferromagnetic magnons via
  magnon-photon coupling","16 pages, 2 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  For the realization of magnon-based current-free technologies, referred to as
magnonics, all-optical control of magnons is an important technique for
fundamental research and application. Magnon-polariton is a coupled state of
magnon and photon in a magnetic medium, which is expected to exhibit a
magnon-like controllability and a photon-like high-speed propagation. Recent
studies have observed magnon-polaritons as modulation of the incident terahertz
wave; however, the influence of magnon-photon coupling on the magnon
propagation property has not been explored. This study aimed to observe the
spatiotemporal dynamics of coherent magnon-polariton through time-resolved
imaging measurements. $\mathrm{BiFeO_3}$ was chosen as the sample, because it
is expected to exhibit strong coupling between the magnon and photon. The
observed dynamics suggested that antiferromagnetic magnons can propagate over
long distances up to hundreds of micrometers through strong coupling with the
photons. The results shed light on the understanding of the optical control of
the magnonic systems thereby paving the way for terahertz opto-magnonics.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:55:53 GMT""}]","2023-02-06"
"2302.01822","Peter Tennant","Peter W.G. Tennant, Georgia D. Tomova, Eleanor J. Murray, Kellyn F.
  Arnold, Matthew P. Fox, Mark S. Gilthorpe","Lord's 'paradox' explained: the 50-year warning on the use of 'change
  scores' in observational data",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  BACKGROUND: In 1967, Frederick Lord posed a conundrum that has confused
scientists for over 50-years. Subsequently named Lord's 'paradox', the puzzle
centres on the observation that two common approach to analyses of 'change'
between two time-points can produce radically different results. Approach 1
involves analysing the follow-up minus baseline (i.e., 'change score') and
Approach 2 involves analysing the follow-up conditional on baseline. METHODS:
At the heart of Lord's 'paradox' lies another puzzle concerning the use of
'change scores' in observational data. Using directed acyclic graphs and data
simulations, we introduce, explore, and explain the 'paradox', consider the
philosophy of change, and discuss the warnings and lessons of this 50-year
puzzle. RESULTS: Understanding Lord's 'paradox' starts with recognising that a
variable may change for three reasons: (A) 'endogenous change', which
represents simple changes in scale, (B) 'random change', which represents
change due to random processes, and (C) 'exogenous change', which represents
all non-endogenous, non-random change. Unfortunately, in observational data,
neither Approach 1 nor Approach 2 are able to reliably estimate the causes of
'exogenous change'. Approach 1 evaluates obscure estimands with little, if any,
real-world interpretation. Approach 2 is susceptible to mediator-outcome
confounding and cannot distinguish exogenous change from random change. Valid
and precise estimates of a useful causal estimand instead require appropriate
multivariate methods (such as g-methods) and more than two measures of the
outcome. CONCLUSION: Lord's 'paradox' reiterates the dangers of analysing
change scores in observational data and highlights the importance of
considering causal questions within a causal framework.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:56:30 GMT""}]","2023-02-06"
"2302.01823","Pawan Kumar Rajpoot","Nikita Katyal, Pawan Kumar Rajpoot","Lexical Simplification using multi level and modular approach",,,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Text Simplification is an ongoing problem in Natural Language Processing,
solution to which has varied implications. In conjunction with the TSAR-2022
Workshop @EMNLP2022 Lexical Simplification is the process of reducing the
lexical complexity of a text by replacing difficult words with easier to read
(or understand) expressions while preserving the original information and
meaning. This paper explains the work done by our team ""teamPN"" for English sub
task. We created a modular pipeline which combines modern day transformers
based models with traditional NLP methods like paraphrasing and verb sense
disambiguation. We created a multi level and modular pipeline where the target
text is treated according to its semantics(Part of Speech Tag). Pipeline is
multi level as we utilize multiple source models to find potential candidates
for replacement, It is modular as we can switch the source models and their
weight-age in the final re-ranking.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:57:54 GMT""}]","2023-02-06"
"2302.01824","Alexandre Zalesski E","Alexandre Zalesski","Upper bounds for eigenvalue multiplicities of almost cyclic elements in
  irreducible representations of simple algebraic groups","1 figure",,,,"math.GR","http://creativecommons.org/publicdomain/zero/1.0/","  We study the irreducible representations of simple algebraic groups in which
some non-central semisimple element has at most one eigenvalue of multiplicity
greater than 1. We bound the multiplicity of this eigenvalue in terms of the
rank of the group.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:59:34 GMT""},{""version"":""v2"",""created"":""Sun, 12 Mar 2023 18:55:08 GMT""}]","2023-03-14"
"2302.01932","Yingbin Zhang","Yingbin Zhang and Luc Paquette","Sequential pattern mining in educational data: The application context,
  potential, strengths, and limitations","This is a preprint of the following chapter: Yingbin Zhang & Luc
  Paquette (2023). Sequential pattern mining in educational data: The
  application context, potential, strengths, and limitations. In Alejandro
  Pe\~na-Ayala (Eds), Educational Data Science: Essentials, Approaches, and
  Tendencies. Springer. https://link.springer.com/book/9789819900251",,"10.1007/978-981-99-0026-8_6",,"cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Increasingly, researchers have suggested the benefits of temporal analysis to
improve our understanding of the learning process. Sequential pattern mining
(SPM), as a pattern recognition technique, has the potential to reveal the
temporal aspects of learning and can be a valuable tool in educational data
science. However, its potential is not well understood and exploited. This
chapter addresses this gap by reviewing work that utilizes sequential pattern
mining in educational contexts. We identify that SPM is suitable for mining
learning behaviors, analyzing and enriching educational theories, evaluating
the efficacy of instructional interventions, generating features for prediction
models, and building educational recommender systems. SPM can contribute to
these purposes by discovering similarities and differences in learners'
activities and revealing the temporal change in learning behaviors. As a
sequential analysis method, SPM can reveal unique insights about learning
processes and be powerful for self-regulated learning research. It is more
flexible in capturing the relative arrangement of learning events than the
other sequential analysis methods. Future research may improve its utility in
educational data science by developing tools for counting pattern occurrences
as well as identifying and removing unreliable patterns. Future work needs to
establish a systematic guideline for data preprocessing, parameter setting, and
interpreting sequential patterns.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:56:31 GMT""}]","2023-05-02"
"2302.01935","Wang Zikun","Pan Gao, Donghong Han, Rui Zhou, Xuejiao Zhang, Zikun Wang","CAB: Empathetic Dialogue Generation with Cognition, Affection and
  Behavior",,,,,"cs.CL cs.HC","http://creativecommons.org/licenses/by/4.0/","  Empathy is an important characteristic to be considered when building a more
intelligent and humanized dialogue agent. However, existing methods did not
fully comprehend empathy as a complex process involving three aspects:
cognition, affection and behavior. In this paper, we propose CAB, a novel
framework that takes a comprehensive perspective of cognition, affection and
behavior to generate empathetic responses. For cognition, we build paths
between critical keywords in the dialogue by leveraging external knowledge.
This is because keywords in a dialogue are the core of sentences. Building the
logic relationship between keywords, which is overlooked by the majority of
existing works, can improve the understanding of keywords and contextual logic,
thus enhance the cognitive ability. For affection, we capture the emotional
dependencies with dual latent variables that contain both interlocutors'
emotions. The reason is that considering both interlocutors' emotions
simultaneously helps to learn the emotional dependencies. For behavior, we use
appropriate dialogue acts to guide the dialogue generation to enhance the
empathy expression. Extensive experiments demonstrate that our
multi-perspective model outperforms the state-of-the-art models in both
automatic and manual evaluation.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:31:17 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 00:45:26 GMT""}]","2023-02-23"
"2302.01936","Timothy H. Boyer","Timothy H. Boyer","Classical Electromagnetic Interaction of a Charge with a Solenoid or
  Toroid","34 pages",,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Aharonov-Bohm phase shift in a particle interference pattern when
electrons pass a long solenoid is identical in form with the optical
interference pattern shift when a piece of retarding glass is introduced into
one path of a two-beam optical interference pattern. The particle
interference-pattern deflection is a relativistic effect of order 1/c^2, though
this relativity aspect is rarely mentioned in the literature. Here we give a
thorough analysis of the classical electromagnetic aspects of the interaction
between a solenoid or toroid and a charged particle. We point out the magnetic
Lorentz force which the solenoid or toroid experiences due to a passing charge.
Although analysis in the rest frame of the solenoid or toroid will involve back
Faraday fields on the charge, the analysis in the inertial frame in which the
charge is initially at rest involves forces due to only electric fields where
forces are equal in magnitude and opposite in direction. The classical analysis
is made using the Darwin Lagrangian. We point out that the classical analysis
suggests an angular deflection independent of Planck's constant where the
deflection magnitude is identical with that given by the traditional quantum
analysis, but where the deflection direction is unambiguous.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:14:28 GMT""}]","2023-02-07"
"2302.01937","Timothy H. Boyer","Timothy H. Boyer","The Classical Aharonov-Bohm Interaction as a Relativity Paradox","16 pages","European Journal of Physics 44,035202 (2023)","10.1088/1361-6404/acc0e6",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The situation of a charged particle passing down the symmetry axis through a
magnetic toroid presents a relativity paradox; different inertial frames
suggest different forces on the charge and on the toroid due to the unperturbed
systems. We review the charge-toroid interaction and suggest that the magnetic
Aharonov-Bohm situation is misunderstood because of unfamiliarity with the
acceleration fields following from the Darwin Lagrangian, which go unmentioned
in recent textbooks of classical electromagnetism.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:37:35 GMT""}]","2023-06-06"
"2302.01954","Yuri Makeenko","Yuri Makeenko","Pauli-Villars' regularization of ghosts in path-integral string
  formulation","13 pages, 2 figures; v2: Appendix added; v3: to appear in JHEP",,"10.1007/JHEP05(2023)085",,"hep-th hep-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  I consider Pauli-Villars' regulators for the ghosts in the path-integral
string formulation and show how they preserve conformal invariance. I calculate
the regulator contributions to the effective action and to the central charge
and demonstrate the consistency of the mean-field quantization of the
Nambu-Goto string in $2<d\leq26$. The higher-derivative corrections to the
Liouville action are briefly considered for the Pauli-Villars and proper-time
regularizations.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 16:38:19 GMT""},{""version"":""v2"",""created"":""Mon, 20 Feb 2023 16:53:51 GMT""},{""version"":""v3"",""created"":""Mon, 8 May 2023 18:24:17 GMT""}]","2023-05-31"
"2302.02759","Ziyi Chen","Ziyi Chen, Ren Yang, Sunyang Fu, Nansu Zong, Hongfang Liu, Ming Huang","Detecting Reddit Users with Depression Using a Hybrid Neural Network",,,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Depression is a widespread mental health issue, affecting an estimated 3.8%
of the global population. It is also one of the main contributors to disability
worldwide. Recently it is becoming popular for individuals to use social media
platforms (e.g., Reddit) to express their difficulties and health issues (e.g.,
depression) and seek support from other users in online communities. It opens
great opportunities to automatically identify social media users with
depression by parsing millions of posts for potential interventions. Deep
learning methods have begun to dominate in the field of machine learning and
natural language processing (NLP) because of their ease of use, efficient
processing, and state-of-the-art results on many NLP tasks. In this work, we
propose a hybrid deep learning model which combines a pretrained sentence BERT
(SBERT) and convolutional neural network (CNN) to detect individuals with
depression with their Reddit posts. The sentence BERT is used to learn the
meaningful representation of semantic information in each post. CNN enables the
further transformation of those embeddings and the temporal identification of
behavioral patterns of users. We trained and evaluated the model performance to
identify Reddit users with depression by utilizing the Self-reported Mental
Health Diagnoses (SMHD) data. The hybrid deep learning model achieved an
accuracy of 0.86 and an F1 score of 0.86 and outperformed the state-of-the-art
documented result (F1 score of 0.79) by other machine learning models in the
literature. The results show the feasibility of the hybrid model to identify
individuals with depression. Although the hybrid model is validated to detect
depression with Reddit posts, it can be easily tuned and applied to other text
classification tasks and different clinical applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 06:22:18 GMT""}]","2023-02-07"
"2302.02761","Arikatla Satyanarayana Reddy","Shrinit Singh and A. Satyanarayana Reddy","Achiral words","7 pages",,,,"math.GR math.CO","http://creativecommons.org/licenses/by/4.0/","  A word $w$ in a free group is {\em achiral} if for every group $G,$
$G_w=G_{w^{-1}},$ where $G_w$ is the image of the word map $w$ on $G.$ We will
give few classes of examples of achiral words. Cocke and Ho asked whether Engel
words are achiral or not. We will prove that it is enough to apply Whitehead's
algorithm to check the same.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 17:46:24 GMT""}]","2023-02-07"
"2302.02795","Juan M. Tiz\'on","Juan M. Tiz\'on, Nicol\'as Becerra, Daniel Bercebal, Claus P.Grabowsky","Trimpack: Unstructured Triangular Mesh Generation Library",,,,,"cs.MS cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trimpack is a library of routines written in Fortran that allow to create
unstructured triangular meshes in any domain and with an user-defined size
distribution. The user must write a program that uses the elements of the
library as if it were a mathematical tool. First, the domain must be defined,
using point-defined boundaries, which the user provides. The library internally
uses splines to mesh the boundaries with the node distribution function
provided by the user. Several meshing methods are available, from simple
Dalaunay mesh creation from a point cloud, an incremental Steiner-type
algorithm that also generates Dalaunay meshes to an efficient advancing-front
type algorithm. This report carries out a bibliographic review of the state of
the art in mesh generation corresponding to the period in which Trimpack was
written for the first time, which is a very fruitful period in the development
of this type of algorithms. Next, MeshGen is described in detail, which is a
program written in C ++ that exploits the possibilities of the Trimpack library
for the generation of unstructured triangular meshes and that has a powerful
graphical interface. Finally, it also explains in detail the content of the
Trimpack library that is available under GNU Public license for anyone who
wants to use or improve it.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:49:38 GMT""}]","2023-02-07"
"2302.02801","Belinda Z. Li","Belinda Z. Li, William Chen, Pratyusha Sharma, Jacob Andreas","LaMPP: Language Models as Probabilistic Priors for Perception and Action","12 pages, 4 tables, 4 figures",,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Language models trained on large text corpora encode rich distributional
information about real-world environments and action sequences. This
information plays a crucial role in current approaches to language processing
tasks like question answering and instruction generation. We describe how to
leverage language models for *non-linguistic* perception and control tasks. Our
approach casts labeling and decision-making as inference in probabilistic
graphical models in which language models parameterize prior distributions over
labels, decisions and parameters, making it possible to integrate uncertain
observations and incomplete background knowledge in a principled way. Applied
to semantic segmentation, household navigation, and activity recognition tasks,
this approach improves predictions on rare, out-of-distribution, and
structurally novel inputs.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:14:04 GMT""}]","2023-02-07"
"2302.02815","Sofia Magkiriadou","Luis S. Froufe-P\'erez (1), Geoffroy Aubry (1, 2), Frank Scheffold
  (1), and Sofia Magkiriadou (1) ((1) Department of Physics, University of
  Fribourg, 1700 Fribourg, Switzerland, (2) Universit\'e C\^ote d'Azur, CNRS,
  Institut de Physique de Nice -- INPHYNI, France)","Bandgap fluctuations and robustness in two-dimensional hyperuniform
  dielectric materials","7 pages, 4 figures. Luis S. Froufe-P\'erez, Geoffroy Aubry, and Frank
  Scheffold have equal first authorship",,"10.1364/OE.484232",,"physics.class-ph physics.optics","http://creativecommons.org/licenses/by/4.0/","  We numerically study the statistical fluctuations of photonic band gaps in
ensembles of stealthy hyperuniform disordered patterns. We find that at low
stealthiness, where correlations are weak, band gaps of different system
realizations appear over a wide frequency range, are narrow, and generally do
not overlap. Interestingly, above a critical value of stealthiness $\chi
\gtrsim 0.35$, the bandgaps become large and overlap significantly from
realization to realization, while a second gap appears. These observations
extend our understanding of photonic bandgaps in disordered systems and provide
information on the robustness of gaps in practical applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:11:08 GMT""}]","2023-05-31"
"2302.02822","Andrey Ryabichev","Andrey Ryabichev","Immersions of manifolds","12 pages, in Russian language, 82 figures",,,,"math.HO math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This text is based on my talk at the popular science conference ``Dark
geometry fest'' which was related to geometric methods and their applications,
July 17, 2022. We will move towards the Smale-Hirsch theorem. To this end we
will deal with the simplest partial case of this theorem -- the
Whitney-Graustein theorem on regular curves in the plane.
  The text is written in an accessible and sometimes informal way, it is
intended primarily for people who are interested in mathematics, but have not
yet studied it deeply enough.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:19:35 GMT""}]","2023-02-07"
"2302.02823","Umberto Lucia","Umberto Lucia and Giulia Grisolia","Non-holonomic constraints: Considerations on the least action principle
  also from a thermodynamic viewpoint","12 pages. arXiv admin note: substantial text overlap with
  arXiv:1102.2888","Results in Physics, Volume 48, May 2023, 106429","10.1016/j.rinp.2023.106429",,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The principle of least action seems not to lead to equations describing the
motion consistent with the physical behaviour, for non-holonomic constraints.
Here, a response is proposed for this fundamental problem in Mathematical
Physics. Some considerations are also developed, based on the first and second
law of thermodynamics.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 23:48:23 GMT""}]","2023-04-10"
"2302.03495","Shuai Wang","Shuai Wang, Harrisen Scells, Bevan Koopman, Guido Zuccon","Can ChatGPT Write a Good Boolean Query for Systematic Review Literature
  Search?",,,,,"cs.IR cs.AI","http://creativecommons.org/licenses/by/4.0/","  Systematic reviews are comprehensive reviews of the literature for a highly
focused research question. These reviews are often treated as the highest form
of evidence in evidence-based medicine, and are the key strategy to answer
research questions in the medical field. To create a high-quality systematic
review, complex Boolean queries are often constructed to retrieve studies for
the review topic. However, it often takes a long time for systematic review
researchers to construct a high quality systematic review Boolean query, and
often the resulting queries are far from effective. Poor queries may lead to
biased or invalid reviews, because they missed to retrieve key evidence, or to
extensive increase in review costs, because they retrieved too many irrelevant
studies. Recent advances in Transformer-based generative models have shown
great potential to effectively follow instructions from users and generate
answers based on the instructions being made. In this paper, we investigate the
effectiveness of the latest of such models, ChatGPT, in generating effective
Boolean queries for systematic review literature search. Through a number of
extensive experiments on standard test collections for the task, we find that
ChatGPT is capable of generating queries that lead to high search precision,
although trading-off this for recall. Overall, our study demonstrates the
potential of ChatGPT in generating effective Boolean queries for systematic
review literature search. The ability of ChatGPT to follow complex instructions
and generate queries with high precision makes it a valuable tool for
researchers conducting systematic reviews, particularly for rapid reviews where
time is a constraint and often trading-off higher precision for lower recall is
acceptable.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 01:28:25 GMT""},{""version"":""v2"",""created"":""Wed, 8 Feb 2023 06:23:35 GMT""},{""version"":""v3"",""created"":""Thu, 9 Feb 2023 11:53:43 GMT""}]","2023-02-10"
"2302.03599","Simone Donadello","Simone Donadello, Elio K. Bertacco, Davide Calonico and Cecilia
  Clivati","Embedded digital phase noise analyzer for optical frequency metrology",,,,,"eess.SP physics.ins-det physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Digital signal processing is supporting novel in-field applications of
optical interferometry, such as in laser ranging and distributed acoustic
sensing. While the highest performances are achieved with field-programmable
gated arrays, their complexity and cost are often too high for many tasks.
Here, we describe an alternative solution for processing optical signals in
real-time, based on a dual-core 32-bit microcontroller. We implemented in-phase
and quadrature demodulation of optical beat-notes resulting from the
interference of independent laser sources, phase noise analysis of deployed
optical fibers covering intercity distances, and synchronization of remote
acquisitions via optical trigger signals. The embedded architecture can
efficiently accomplish a large variety of tasks in the context of optical
signal processing, being also easily configurable, compact and upgradable.
These features make it attractive for applications that require long-term,
remotely-operated, and field-deployed instrumentation.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 15:37:37 GMT""}]","2023-02-08"
"2302.03600","Ondrej Rokos","O. Roko\v{s}, R.H.J. Peerlings, J.P.M. Hoefnagels, M.G.D. Geers","Integrated Digital Image Correlation for Micro-Mechanical Parameter
  Identification in Multiscale Experiments","44 pages, 16 figures, 4 tables, 7 procedures, abstract shortened to
  fulfil 1920 character limit","International Journal of Solids and Structures 112130 (2023)","10.1016/j.ijsolstr.2023.112130",,"cond-mat.soft","http://creativecommons.org/licenses/by/4.0/","  Micromechanical constitutive parameters are important for many engineering
materials, typically in microelectronic applications and material design. Their
accurate identification poses a three-fold experimental challenge: (i)
deformation of the microstructure is observable only at small scales, requiring
SEM or other microscopy techniques; (ii) external loadings are applied at a
(larger) engineering or device scale; and (iii) material parameters typically
depend on the applied manufacturing process, necessitating measurements on
material produced with the same process. In this paper, micromechanical
parameter identification in heterogeneous solids is addressed through
multiscale experiments combined with Integrated Digital Image Correlation
(IDIC) in conjunction with various possible computational homogenization
schemes. To this end, some basic concepts underlying multiscale approaches
available in the literature are first reviewed, discussing their respective
advantages and disadvantages from the computational as well as experimental
point of view. A link is made with recently introduced uncoupled methods, which
allow for identification of material parameter ratios at the microscale, still
lacking a proper normalization. Two multiscale methods are analysed, allowing
to bridge the gap between microstructural kinematics and macroscopically
measured forces, providing the required normalization. It is shown that an
integrated experimental--computational scheme provides relaxed requirements on
scale separation. The accuracy and performance of the discussed techniques are
analysed by means of virtual experimentation under plane strain and large
strain assumptions for unidirectional fibre-reinforced composites. The
robustness against image noise is also assessed.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:04:40 GMT""}]","2023-02-08"
"2302.03606","Hristos Tyralis","Hristos Tyralis, Georgia Papacharalampous, Nikolaos Doulamis,
  Anastasios Doulamis","Merging satellite and gauge-measured precipitation using LightGBM with
  an emphasis on extreme quantiles","25 pages, 7 figures",,,,"eess.SP cs.LG","http://creativecommons.org/licenses/by/4.0/","  Knowing the actual precipitation in space and time is critical in
hydrological modelling applications, yet the spatial coverage with rain gauge
stations is limited due to economic constraints. Gridded satellite
precipitation datasets offer an alternative option for estimating the actual
precipitation by covering uniformly large areas, albeit related estimates are
not accurate. To improve precipitation estimates, machine learning is applied
to merge rain gauge-based measurements and gridded satellite precipitation
products. In this context, observed precipitation plays the role of the
dependent variable, while satellite data play the role of predictor variables.
Random forests is the dominant machine learning algorithm in relevant
applications. In those spatial predictions settings, point predictions (mostly
the mean or the median of the conditional distribution) of the dependent
variable are issued. Here we propose, issuing probabilistic spatial predictions
of precipitation using Light Gradient Boosting Machine (LightGBM). LightGBM is
a boosting algorithm, highlighted by prize-winning entries in prediction and
forecasting competitions. To assess LightGBM, we contribute a large-scale
application that includes merging daily precipitation measurements in
contiguous US with PERSIANN and GPM-IMERG satellite precipitation data. We
focus on extreme quantiles of the probability distribution of the dependent
variable, where LightGBM outperforms quantile regression forests (QRF, a
variant of random forests) in terms of quantile score. LightGBM and QRF show
similar performance when predicting functionals at the centre of the
conditional probability distribution, including the conditional median. Our
study offers understanding of probabilistic predictions in spatial settings
using machine learning.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 20:03:21 GMT""}]","2023-02-08"
"2302.03745","Yang Lou Dr","Yang Lou and Lin Wang and Guanrong Chen","Structural Robustness of Complex Networks: A Survey of A Posteriori
  Measures",,"IEEE Circuits and Systems Magazine, Volume 23, Issue 1, 2023","10.1109/MCAS.2023.3236659",,"cs.SI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Network robustness is critical for various industrial and social networks
against malicious attacks, which has various meanings in different research
contexts and here it refers to the ability of a network to sustain its
functionality when a fraction of the network fail to work due to attacks. The
rapid development of complex networks research indicates special interest and
great concern about the network robustness, which is essential for further
analyzing and optimizing network structures towards engineering applications.
This comprehensive survey distills the important findings and developments of
network robustness research, focusing on the a posteriori structural robustness
measures for single-layer static networks. Specifically, the a posteriori
robustness measures are reviewed from four perspectives: 1) network
functionality, including connectivity, controllability and communication
ability, as well as their extensions; 2) malicious attacks, including
conventional and computation-based attack strategies; 3) robustness estimation
methods using either analytical approximation or machine learning-based
prediction; 4) network robustness optimization. Based on the existing measures,
a practical threshold of network destruction is introduced, with the suggestion
that network robustness should be measured only before reaching the threshold
of destruction. Then, a posteriori and a priori measures are compared
experimentally, revealing the advantages of the a posteriori measures. Finally,
prospective research directions with respect to a posteriori robustness
measures are recommended.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 13:59:49 GMT""}]","2023-02-09"
"2302.05338","Cameron Smith","Ximo Pechuan-Jorge, Raymond S. Puzio, Cameron Smith","Algebraic structure of hierarchic first-order reaction networks
  applicable to models of clone size distribution and stochastic gene
  expression","9 pages",,,,"q-bio.MN math-ph math.MP math.PR q-bio.PE q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In biology, stochastic branching processes with a two-stage, hierarchical
structure arise in the study of population dynamics, gene expression, and
phylogenetic inference. These models have been commonly analyzed using
generating functions, the method of characteristics and various perturbative
approximations. Here we describe a general method for analyzing hierarchic
first-order reaction networks using Lie theory. Crucially, we identify the fact
that the Lie group associated to hierarchic reaction networks decomposes as a
wreath product of the groups associated to the subnetworks of the independent
and dependent types. After explaining the general method, we illustrate it on a
model of population dynamics and the so-called two-state or telegraph model of
single-gene transcription. Solutions to such processes provide essential input
to downstream methods designed to attempt to infer parameters of these and
related models.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 21:19:12 GMT""}]","2023-02-13"
"2302.06425","Miloslav Capek","Miloslav Capek and Lukas Jelinek","Fundamental Bound on Maximum Gain as a Sum of Lossy Characteristic Modes
  and Its Feasibility","9 pages, 10 figures",,,,"physics.app-ph physics.class-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The fundamental bound on maximum antenna gain is expressed as a sum of lossy
characteristic modes, specifically, as a sum of characteristic far fields
squared. The procedure combines the favorable properties of Harrington's
classical approach to maximum gain and current-density-based approaches. The
decomposition into modes makes it possible to study the degrees of freedom of
an obstacle, classify its radiation into normal or super-directive currents and
determine their compatibility with a given excitation. The bound considers an
arbitrary shape of the design region and specific material distribution. The
cost in Q-factor and radiation efficiency is also studied. The extra constraint
of a self-resonance current is imposed for an electrically small antenna. The
example verifies the developed theory, demonstrates the procedure's utility,
and provides helpful insight to antenna designers.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 09:57:36 GMT""}]","2023-02-14"
"2302.07101","Mikhail Basov","Mikhail Basov","Pressure Sensor Chip with New Electrical Circuit for 10 kPa Range","13 pages, 6 figures, 5 tables, 38 references",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  Characteristics of high sensitivity MEMS pressure sensor chip for 10 kPa
utilizing a novel electrical circuit are presented. The electrical circuit uses
piezosensitive differential amplifier with negative feedback loop (PDA-NFL)
based on two bipolar-junction transistors (BJT). The BJT has a vertical
structure of n-p-n type (V-NPN) formed on a non-deformable chip area. The
circuit contains eight piezoresistors located on a profiled membrane in the
areas of maximum mechanical stresses. The experimental results prove that
pressure sensor chip PDA-NFL with 4.0x4.0 mm2 chip area has sensitivity S =
7.8...12.4 mV/V/kPa with nonlinearity of 2KNL = 0.14...0.38 %/FS (pressure is
applied from the back side of pressure sensor chip).
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 10:17:52 GMT""}]","2023-02-15"
"2302.07138","Achille Felicetti","Franco Niccolucci, B\'eatrice Markhoff, Maria Theodoridou, Achille
  Felicetti, Sorin Hermon","The Heritage Digital Twin: a bicycle made for two. The integration of
  digital methodologies into cultural heritage research","Submitted to Open Research Europe. 30 pages, 9 figures",,,,"cs.CY cs.CL cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The paper concerns the definition of a novel ontology for cultural heritage
based on the concept of digital twin. The ontology, called Heritage Digital
Twin ontology, is a compatible extension of the well-known CIDOC CRM ISO
standard for cultural heritage documentation and incorporates all the different
documentation systems presently in use for cultural heritage documentation. In
the authors' view, it supports documentation interoperability at a higher level
than the ones currently in use and enables effective cooperation among
different users.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:36:37 GMT""}]","2023-02-15"
"2302.07831","Bendong Lou","Bendong Lou, Xiaoliu Wang and Lixia Yuan","A Mean Curvature Flow Propagating in a Cylinder at Exponential Speed",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the long time behaviour of mean curvature flow in a
cylinder with Robin boundary conditions. Such a boundary condition can force
the solution to have a singular behaviour at the boundary when $t\to \infty$.
The planar version of this problem has been investigated in an existing
literature, where the curve shortening flow in $2$-dimensional band with Robin
boundary conditions is shown to converge to a translating Grim Reaper with
finite speed and fixed profile. By considering a radially symmetric mean
curvature flow, denoted by $u(|x|,t)$, in $(N+1)$-dimensional cylinder ($N\geq
2$), we find in the present paper a new feature of the flow: both the interior
gradients and the propagating speed of the flow increase to infinity
exponentially, $Du/u\sim x$ and $ u\sim C_0 e^{(N-1)t}e^{\frac{|x|^2}{2}}$ as
$t\to \infty$ for some $C_0>0$, which is completely different from the
2-dimensional case.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:38:42 GMT""}]","2023-02-16"
"2302.09067","Chenguang Lu","Chenguang Lu","Causal Confirmation Measures: From Simpson's Paradox to COVID-19","21 pages, 4 figures","Entropy, 2023,25(1), 143","10.3390/e25010143",,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  When we compare the influences of two causes on an outcome, if the conclusion
from every group is against that from the conflation, we think there is
Simpson's Paradox. The Existing Causal Inference Theory (ECIT) can make the
overall conclusion consistent with the grouping conclusion by removing the
confounder's influence to eliminate the paradox. The ECIT uses relative risk
difference Pd = max(0, (R - 1)/R) (R denotes the risk ratio) as the probability
of causation. In contrast, Philosopher Fitelson uses confirmation measure D
(posterior probability minus prior probability) to measure the strength of
causation. Fitelson concludes that from the perspective of Bayesian
confirmation, we should directly accept the overall conclusion without
considering the paradox. The author proposed a Bayesian confirmation measure b*
similar to Pd before. To overcome the contradiction between the ECIT and
Bayesian confirmation, the author uses the semantic information method with the
minimum cross-entropy criterion to deduce causal confirmation measure Cc = (R
-1)/max(R, 1). Cc is like Pd but has normalizing property (between -1 and 1)
and cause symmetry. It especially fits cases where a cause restrains an
outcome, such as the COVID-19 vaccine controlling the infection. Some examples
(about kidney stone treatments and COVID-19) reveal that Pd and Cc are more
reasonable than D; Cc is more useful than Pd.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 02:44:27 GMT""}]","2023-02-21"
"2302.10183","Jean-Pierre Fouque","Alessandro Doldi, Yichen Feng, Jean-Pierre Fouque, Marco Frittelli","Multivariate Systemic Risk Measures and Deep Learning Algorithms","4 figures, 5 tables",,,,"cs.LG math.PR","http://creativecommons.org/licenses/by/4.0/","  In this work we propose deep learning-based algorithms for the computation of
systemic shortfall risk measures defined via multivariate utility functions. We
discuss the key related theoretical aspects, with a particular focus on the
fairness properties of primal optima and associated risk allocations. The
algorithms we provide allow for learning primal optimizers, optima for the dual
representation and corresponding fair risk allocations. We test our algorithms
by comparison to a benchmark model, based on a paired exponential utility
function, for which we can provide explicit formulas. We also show evidence of
convergence in a case for which explicit formulas are not available.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 22:16:49 GMT""}]","2023-02-22"
"2302.10771","Chu Wang","Chu Wang, Manfeng Dou, Zhongliang Li, Rachid Outbib, Dongdong Zhao,
  Jian Zuo, Yuanlin Wang, Bin Liang, Peng Wang","Data-driven prognostics based on time-frequency analysis and symbolic
  recurrent neural network for fuel cells under dynamic load",,,"10.1016/j.ress.2023.109123",,"cs.LG cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Data-centric prognostics is beneficial to improve the reliability and safety
of proton exchange membrane fuel cell (PEMFC). For the prognostics of PEMFC
operating under dynamic load, the challenges come from extracting degradation
features, improving prediction accuracy, expanding the prognostics horizon, and
reducing computational cost. To address these issues, this work proposes a
data-driven PEMFC prognostics approach, in which Hilbert-Huang transform is
used to extract health indicator in dynamic operating conditions and
symbolic-based gated recurrent unit model is used to enhance the accuracy of
life prediction. Comparing with other state-of-the-art methods, the proposed
data-driven prognostics approach provides a competitive prognostics horizon
with lower computational cost. The prognostics performance shows consistency
and generalizability under different failure threshold settings.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 12:52:49 GMT""}]","2023-02-22"
"2302.12185","Siddharth Agrawal Mr.","Siddharth Agrawal","Scaling Up Computer Vision Neural Networks Using Fast Fourier Transform",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep Learning-based Computer Vision field has recently been trying to explore
larger kernels for convolution to effectively scale up Convolutional Neural
Networks. Simultaneously, new paradigm of models such as Vision Transformers
find it difficult to scale up to larger higher resolution images due to their
quadratic complexity in terms of input sequence. In this report, Fast Fourier
Transform is utilised in various ways to provide some solutions to these
issues.
","[{""version"":""v1"",""created"":""Thu, 2 Feb 2023 19:19:10 GMT""}]","2023-02-24"
"2303.08068","Suguru Yasutomi","Suguru Yasutomi, Toshihisa Tanaka","Style Feature Extraction Using Contrastive Conditioned Variational
  Autoencoders with Mutual Information Constraints",,,,,"cs.CV cs.LG stat.ML","http://creativecommons.org/licenses/by-sa/4.0/","  Extracting fine-grained features such as styles from unlabeled data is
crucial for data analysis. Unsupervised methods such as variational
autoencoders (VAEs) can extract styles that are usually mixed with other
features. Conditional VAEs (CVAEs) can isolate styles using class labels;
however, there are no established methods to extract only styles using
unlabeled data. In this paper, we propose a CVAE-based method that extracts
style features using only unlabeled data. The proposed model consists of a
contrastive learning (CL) part that extracts style-independent features and a
CVAE part that extracts style features. The CL model learns representations
independent of data augmentation, which can be viewed as a perturbation in
styles, in a self-supervised manner. Considering the style-independent features
from the pretrained CL model as a condition, the CVAE learns to extract only
styles. Additionally, we introduce a constraint based on mutual information
between the CL and VAE features to prevent the CVAE from ignoring the
condition. Experiments conducted using two simple datasets, MNIST and an
original dataset based on Google Fonts, demonstrate that the proposed method
can efficiently extract style features. Further experiments using real-world
natural image datasets were also conducted to illustrate the method's
extendability.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 08:38:11 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 08:59:44 GMT""}]","2023-03-20"
"2303.11164","Simone Maurizio La Cava","Simone Maurizio La Cava, Giulia Orr\`u, Tom\'a\v{s} Goldmann, Martin
  Drahansky, Gian Luca Marcialis","3D Face Reconstruction for Forensic Recognition -- A Survey",,,"10.1109/ICPR56361.2022.9956031",,"cs.CV cs.AI eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D face reconstruction algorithms from images and videos are applied to many
fields, from plastic surgery to the entertainment sector, thanks to their
advantageous features. However, when looking at forensic applications, 3D face
reconstruction must observe strict requirements that still make unclear its
possible role in bringing evidence to a lawsuit. Shedding some light on this
matter is the goal of the present survey, where we start by clarifying the
relation between forensic applications and biometrics. To our knowledge, no
previous work adopted this relation to make the point on the state of the art.
Therefore, we analyzed the achievements of 3D face reconstruction algorithms
from surveillance videos and mugshot images and discussed the current obstacles
that separate 3D face reconstruction from an active role in forensic
applications.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 11:29:04 GMT""}]","2023-03-21"
"2304.11096","Saif Alnairat","Saif Alnairat, Benjamin Wohlfeil, Stevan Djordjevic and Bernhard
  Schmauss","Silicon Photonics Wavelength-Independent C-Band Tunable Optical Filter
  With Feasible Thermal Tuning Requirements","This work has been partially funded by the German Ministry of
  Education and Research under the grant agreement 13N14937 (PEARLS)","European Conference on Optical Communication (ECOC) 2022,
  Technical Digest Series (Optica Publishing Group, 2022), paper We5.12",,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A filter design based on Vernier microrings and wideband directional couplers
is proposed for ASE noise suppression in next generation DCI applications. We
demonstrate a 40 nm FSR-free filter with > 20.5 dB average ER and 3dB-BW of 75
GHz, achieving wavelength-independent performance and full tunability with a
maximum tuning temperature of 75 K.
","[{""version"":""v1"",""created"":""Fri, 3 Feb 2023 14:16:40 GMT""}]","2023-04-24"
