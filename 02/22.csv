"2302.10750","Chun Wang","Martin B. Haugh and Chun Wang","An Empirical Bayes Approach for Estimating Skill Models for Professional
  Darts Players","arXiv admin note: text overlap with arXiv:2011.11031",,,,"stat.AP","http://creativecommons.org/licenses/by/4.0/","  We perform an exploratory data analysis on a data-set for the top 16
professional players from the 2019 season. The goal is to use this data-set to
fit player skill models which can then be used in dynamic zero-sum games (ZSGs)
that model real-world matches between players. We identify several problems
that arise due to natural limitations in the data and propose an empirical
Bayesian approach - the Dirichlet-Multinomial (DM) model - that overcomes some
of these problems. We explain how the remaining problems can be finessed using
the DM model with a limited action set in the ZSGs.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:01:00 GMT""}]","2023-02-22"
"2302.10751","Vladimir Pokrovskii","Vladimir Pokrovskii","The Pareto distribution as a disguised Gauss distribution","10 pages, 2 figure",,,,"physics.bio-ph physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  A simple heuristic model, including the multiple exchanges between economic
agents, is used to explain the mechanism of emerging and maintenance of social
inequality in the market economy. The model allows calculating a density
function of the population distribution over income. The function can be
considered as a strongly deformed Gauss distribution function, whereas, at
large incomes, it coincides with the Pareto distribution. The external, in
relation to the model under consideration, force is necessary to maintain the
strong non-equilibrium in a stationary state, and this force is the
non-equivalence of elementary exchanges: the agent who already receives the
higher income has the advantage: it provokes the rich to be getting more rich
and the poor to be getting pauper.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:01:16 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 07:21:36 GMT""},{""version"":""v3"",""created"":""Wed, 15 Mar 2023 11:26:07 GMT""}]","2023-03-16"
"2302.10752","Anna Childs","Anna C. Childs, Rebecca G. Martin, Stephen Lepp, Stephen H. Lubow, and
  Aaron M. Geller","Coplanar circumbinary planets can be unstable to large tilt oscillations
  in the presence of an inner polar planet","Accepted for publication in ApJL. 7 pages and 4 figures",,"10.3847/2041-8213/acbcc9",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mutually misaligned circumbinary planets may form in a warped or broken gas
disc or from later planet-planet interactions. With numerical simulations and
analytic estimates we explore the dynamics of two circumbinary planets with a
large mutual inclination. A coplanar inner planet causes prograde apsidal
precession of the binary and the stationary inclination for the outer planet is
higher for larger outer planet orbital radius. In this case a coplanar outer
planet always remains coplanar. On the other hand, a polar inner planet causes
retrograde apsidal precession of the binary orbit and the stationary
inclination is smaller for larger outer planet orbital radius. For a range of
outer planet semi-major axes, an initially coplanar orbit is librating meaning
that the outer planet undergoes large tilt oscillations. Circumbinary planets
that are highly inclined to the binary are difficult to detect -- it is
unlikely for a planet to have an inclination below the transit detection limit
in the presence of a polar inner planet. These results suggest that there could
be a population of circumbinary planets that are undergoing large tilt
oscillations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:01:38 GMT""}]","2023-03-08"
"2302.10759","Massimiliano d'Aquino","Massimiliano d'Aquino, Salvatore Perna, Matteo Pancaldi, Riccardo
  Hertel, Stefano Bonetti and Claudio Serpico","Micromagnetic study of inertial spin waves in ferromagnetic nanodots","The following article has been accepted by Physical Review B. After
  it is published, it will be found at https://journals.aps.org/prb/. Revised
  version, 9 pages, 6 figures. Changes made in v2: added some references, minor
  edits and corrections",,"10.1103/PhysRevB.107.144412",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  Here we report the possibility to excite ultra-short spin waves in
ferromagnetic thin-films by using time-harmonic electromagnetic fields with
terahertz frequency. Such ultra-fast excitation requires to include inertial
effects in the description of magnetization dynamics. In this respect, we
consider the inertial Landau-Lifshitz-Gilbert (iLLG) equation and develop
analytical theory for exchange-dominated inertial spin waves. The theory
predicts a finite limit for inertial spin wave propagation velocity, as well as
spin wave spatial decay and lifetime as function of material parameters. Then,
guided by the theory, we perform numerical micromagnetic simulations that
demonstrate the excitation of ultra-short inertial spin waves (20 nm long)
propagating at finite speed in a confined magnetic nanodot. The results are in
agreement with the theory and provide the order of magnitude of quantities
observable in realistic ultra-fast dynamics experiments.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:04:14 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 14:10:13 GMT""}]","2023-04-19"
"2302.10762","Luca Foffano","L. Foffano, V. Vittorini, M. Tavani, E. Menegoni","Absorption features in gamma-ray spectra of BL Lac objects","Accepted for publication, 7th Heidelberg International Symposium on
  High-Energy Gamma-Ray Astronomy (Gamma2022). arXiv admin note: substantial
  text overlap with arXiv:2201.02454",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The production site of gamma rays in blazars is closely related to their
interaction with the photon fields surrounding the active galactic nucleus. In
this work we discuss an indirect method that may help to unveil the presence of
ambient structures in BL Lacs through the analysis of their gamma-ray spectrum.
Passing through structures at different distances from the black hole, gamma
rays interact with the corresponding photon fields via gamma-gamma pair
production, producing absorption features in their spectral energy
distribution. An interaction of the gamma-ray photons with a putative
broad-line region may reduce the gamma-ray flux only if its production site
were very close to the central engine. On the other hand, if jet photons
interact with optical-UV seed photons produced by a pc-scale narrow-line
region, the consequent gamma-gamma process may cause absorption features at a
few hundreds GeV. Sources with spectra reaching TeV energies, such as HBLs and
EHBLs (extreme blazars), may represent exceptional probes to investigate this
topic. In this regard, we discuss recent observations of sources which may show
evidence of such absorption features in their gamma-ray spectra. Finally, we
discuss how sub-TeV absorption features in the spectra of BL Lacs may affect
their broadband modeling, and eventually represent a powerful diagnostic tool
to constrain the gamma-ray production site and the jet environment.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:05:35 GMT""}]","2023-02-22"
"2302.10766","Balint Gyevnar","Balint Gyevnar, Nick Ferguson, and Burkhard Schafer","Get Your Act Together: A Comparative View on Transparency in the AI Act
  and Technology",,,,,"cs.AI cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The European Union has proposed the Artificial Intelligence Act which
introduces a proportional risk-based approach to AI regulation including
detailed requirements for transparency and explainability. Many of these
requirements may be addressed in practice by the field of explainable AI (XAI),
however, there are fundamental differences between XAI and the Act regarding
what transparency and explainability are. These basic definitions should be
aligned to assure that regulation continually translates into appropriate
technical practices. To facilitate this alignment, we first give an overview of
how XAI and European regulation view basic definitions of transparency with a
particular focus on the AI Act and the related General Data Protection
Regulation (GDPR). We then present a comparison of XAI and regulatory
approaches to identify the main points that would improve alignment between the
fields: clarification of the scope of transparency, the legal status of XAI,
oversight issues in conformity assessments, and dataset-related transparency.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:06:48 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 16:26:49 GMT""},{""version"":""v3"",""created"":""Tue, 9 May 2023 19:18:25 GMT""},{""version"":""v4"",""created"":""Thu, 11 May 2023 01:26:21 GMT""}]","2023-05-12"
"2302.10767","Yihuang Xiong","Yihuang Xiong, Milena Mathew, Sin\'ead M. Griffin, Alp Sipahigil,
  Geoffroy Hautier","Midgap state requirements for optically active quantum defects",,,,,"quant-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optically active quantum defects play an important role in quantum sensing,
computing, and communication. The electronic structure and the single-particle
energy levels of these quantum defects in the semiconducting host have been
used to understand their opto-electronic properties. Optical excitations that
are central for their initialization and readout are linked to transitions
between occupied and unoccupied single-particle states. It is commonly assumed
that only quantum defects introducing levels well within the band gap and far
from the band edges are of interest for quantum technologies as they mimic an
isolated atom embedded in the host. In this perspective, we contradict this
common assumption and show that optically active defects with energy levels
close to the band edges can display similar properties. We highlight quantum
defects that are excited through transitions to or from a band-like level
(bound exciton), such as the T center and Se$\rm _{Si}^+$ in silicon. We also
present how defects such as the silicon divacancy in diamond can involve
transitions between localized levels that are above the conduction band or
below the valence band. Loosening the commonly assumed requirement on the
electronic structure of quantum defects offers opportunities in quantum defects
design and discovery, especially in smaller band gap hosts such as silicon. We
discuss the challenges in terms of operating temperature for photoluminescence
or radiative lifetime in this regime. We also highlight how these alternative
type of defects bring their own needs in terms of theoretical developments and
fundamental understanding. This perspective clarifies the electronic structure
requirement for quantum defects and will facilitate the identification and
design of new color centers for quantum applications especially driven by first
principles computations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:07:04 GMT""}]","2023-02-22"
"2302.10769","Zineb Benhmidouch","Zineb Benhmidouch, Saad Moufid, Aissam Ait Omar","A comparative study of human inverse kinematics techniques for lower
  limbs","17 pages and 17 figures",,,,"cs.RO cs.AI","http://creativecommons.org/licenses/by/4.0/","  Inverse Kinematics (IK) has been an active research topic and many methods
have been introduced to provide a fast and accurate solution. However, high
computational cost and the generation of unrealistic positions constitute the
weak points in most existing IK methods. In this paper, a comparative study was
established to analyze the performance of popular IK techniques applied to the
human leg. The objective is to determine the most efficient method in terms of
computation time and to reach the desired position with a realistic human
posture while respecting the range of motion and joint comfort zones of every
joint.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:07:19 GMT""},{""version"":""v2"",""created"":""Wed, 22 Feb 2023 08:42:57 GMT""}]","2023-02-23"
"2302.10773","Zhi Zhou","Siyu Cen, Bangti Jin, Qimeng Quan, Zhi Zhou","Hybrid Neural-Network FEM Approximation of Diffusion Coefficient in
  Elliptic and Parabolic Problems","28 pages",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we investigate the numerical identification of the diffusion
coefficient in elliptic and parabolic problems using neural networks. The
numerical scheme is based on the standard output least-squares formulation
where the Galerkin finite element method (FEM) is employed to approximate the
state and neural networks (NNs) act as a smoothness prior to approximate the
unknown diffusion coefficient. A projection operation is applied to the NN
approximation in order to preserve the physical box constraint on the unknown
coefficient. The hybrid approach enjoys both rigorous mathematical foundation
of the FEM and inductive bias / approximation properties of NNs. We derive
\textsl{a priori} error estimates in the standard $L^2(\Omega)$ norm for the
numerical reconstruction, under a positivity condition which can be verified
for a large class of problem data. The error bounds depend explicitly on the
noise level, regularization parameter and discretization parameters (e.g.,
spatial mesh size, time step size, and depth, upper bound and number of nonzero
parameters of NNs). We also provide extensive numerical experiments, indicating
that the hybrid method is very robust for large noise when compared with the
pure FEM approximation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:08:40 GMT""}]","2023-02-22"
"2302.10781","Xiaodong Wang","Xiaodong Wang, Chenfei Wu, Shengming Yin, Minheng Ni, Jianfeng Wang,
  Linjie Li, Zhengyuan Yang, Fan Yang, Lijuan Wang, Zicheng Liu, Yuejian Fang,
  Nan Duan","Learning 3D Photography Videos via Self-supervised Diffusion on Single
  Images","10 pages, 7 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D photography renders a static image into a video with appealing 3D visual
effects. Existing approaches typically first conduct monocular depth
estimation, then render the input frame to subsequent frames with various
viewpoints, and finally use an inpainting model to fill those missing/occluded
regions. The inpainting model plays a crucial role in rendering quality, but it
is normally trained on out-of-domain data. To reduce the training and inference
gap, we propose a novel self-supervised diffusion model as the inpainting
module. Given a single input image, we automatically construct a training pair
of the masked occluded image and the ground-truth image with random
cycle-rendering. The constructed training samples are closely aligned to the
testing instances, without the need of data annotation. To make full use of the
masked images, we design a Masked Enhanced Block (MEB), which can be easily
plugged into the UNet and enhance the semantic conditions. Towards real-world
animation, we present a novel task: out-animation, which extends the space and
time of input objects. Extensive experiments on real datasets show that our
method achieves competitive results with existing SOTA methods.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:18:40 GMT""}]","2023-02-22"
"2302.10782","Federico Vazzoler","Simone Amoroso, Mauro Chiesa, Clara Lavinia Del Pio, Katerina Lipka,
  Fulvio Piccinini, Federico Vazzoler, Alessandro Vicini","Probing the weak mixing angle at high energies at the LHC and HL-LHC",,,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  Measurements of neutral current Drell-Yan production at large invariant
dilepton masses can be used to test the energy scale dependence (running) of
the electroweak mixing angle. In this work, we make use of a novel
implementation of the full next-to-leading order electroweak radiative
corrections to the Drell-Yan process using the $\overline{\mathrm{MS}}$
renormalization scheme for the electroweak mixing angle. The potential of
future analyses using proton-proton collisions at $\sqrt{s}=13.6~\mathrm{TeV}$
in the Run 3 and High-Luminosity phases of the LHC is explored. In this way,
the Standard Model predictions for the $\overline{\mathrm{MS}}$ running at
$\mathrm{TeV}$ scales can be probed.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:18:41 GMT""}]","2023-02-22"
"2302.10786","George Boateng","George Boateng, Samuel John, Samuel Boateng, Philemon Badu, Patrick
  Agyeman-Budu and Victor Kumbol","Real-World Deployment and Evaluation of Kwame for Science, An AI
  Teaching Assistant for Science Education in West Africa","18 pages, under review at International Journal on Artificial
  Intelligence in Education",,,,"cs.CL cs.CY cs.HC cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Africa has a high student-to-teacher ratio which limits students' access to
teachers for learning support such as educational question answering. In this
work, we extended Kwame, our previous AI teaching assistant for coding
education, adapted it for science education, and deployed it as a web app.
Kwame for Science provides passages from well-curated knowledge sources and
related past national exam questions as answers to questions from students
based on the Integrated Science subject of the West African Senior Secondary
Certificate Examination (WASSCE). Furthermore, students can view past national
exam questions along with their answers and filter by year, question type
(objectives, theory, and practicals), and topics that were automatically
categorized by a topic detection model which we developed (91% unweighted
average recall). We deployed Kwame for Science in the real world over 8 months
and had 750 users across 32 countries (15 in Africa) and 1.5K questions asked.
Our evaluation showed an 87.2% top 3 accuracy (n=109 questions) implying that
Kwame for Science has a high chance of giving at least one useful answer among
the 3 displayed. We categorized the reasons the model incorrectly answered
questions to provide insights for future improvements. We also share challenges
and lessons with the development, deployment, and human-computer interaction
component of such a tool to enable other researchers to deploy similar tools.
With a first-of-its-kind tool within the African context, Kwame for Science has
the potential to enable the delivery of scalable, cost-effective, and quality
remote education to millions of people across Africa.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:20:17 GMT""}]","2023-02-22"
"2302.10788","Pranay Bhardwaj","Pranay Bhardwaj and S.M. Zafaruddin","Exact Performance Analysis of THz Link Under Transceiver Hardware
  Impairments","This work has been submitted to the IEEE for possible publication",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transceiver hardware impairment (THI) is inevitable for high-date rate
terahertz (THz) communication. Existing statistical analysis either neglects
THI's effect or provides approximate results when analyzing the performance of
the THz system combined with channel fading and antenna misalignment. In this
paper, we develop exact analytical expressions for the average signal-to-noise
ratio (SNR), ergodic capacity, and average bit-error-rate (BER) performance of
a THz wireless link under the combined effect of $\alpha$-$\mu$ fading channel,
zero-boresight pointing errors, and the Gaussian distributed THI. We also
derive asymptotic expressions for the outage probability and average BER, which
shows that the diversity order of the THz link is independent of THI's
parameters. Simulations validate the derived analytical results and demonstrate
the impact of the THI parameters on the THz performance.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:20:26 GMT""}]","2023-02-22"
"2302.10789","Christian Boudreault","Christian Boudreault, Solomon A. Owerre, Manu B. Paranjape","Frustration, solitons, and entanglement in spin chains","13 pages, 9 figures, additional material and figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Defects in frustrated antiferromagnetic spin chains are universally present
in geometrically frustrated systems. We consider the defects of the
one-dimensional, spin-$s$ XXZ chain with single-ion anisotropy on a periodic
chain with $N$ sites that was famously studied by Haldane. For $N$ odd the
antiferromagnetic model is frustrated, and the ground state must include a
soliton defect. We consider the Heisenberg interaction perturbatively and
determine the corresponding perturbative solitonic ground state. Then we
compute the entanglement spectrum, entanglement entropy (EE), capacity of
entanglement (CE), and spin correlations in the solitonic ground state. For
weak frustration, we find an algebraic violation of the area law for the EE
consistent with recent results on weakly frustrated chains. Our analysis then
moves beyond the weak frustration regime, and we obtain a novel extensive
scaling law for the EE when strong frustration prevails, signalling large
entanglement, and failure of the quasiparticle interpretation in this regime.
Enhanced frustration results in less total correlations, but relatively more
nonlocal correlations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:20:44 GMT""}]","2023-02-22"
"2302.10795","J\'er\^ome Casse","J\'er\^ome Casse","Siblings in d-dimensional nearest neighbour trees","29 pages, 6 figures",,,,"math.PR math.MG","http://creativecommons.org/licenses/by/4.0/","  Pick a sequence of uniform points on the $d$-dimensional sphere. Then, link
the $n$th point to its closest one that arrives in the past. This constructs a
labelled tree called the nearest neighbour tree on the $d$-dimensional sphere.
These trees share some properties with the random recursive tree: the height of
the last arrival node, the mean degree of the root, etc. On the contrary, the
number of leaves seems to depend on dimension $d$, but no such properties have
been proved yet. In this article, we prove that the mean number of siblings
depends on $d$.
  In particular, we give explicit calculations of this number. In dimension
$1$, it is $1 + \ln 2$ and, in any dimension $d$, it has an explicit integral
form, but unfortunately, it does not give an explicit number. Nevertheless, we
show that it converges to $2$ when $d \to \infty$ exponentially quick at a rate
of $\sqrt{3}/2$.
  To prove these results, we look at the local limit of those trees and we do
some fine computations about the intersection of two balls in dimension $d$. In
particular, we obtain a non-trivial upper bound for those intersections in some
precise cases.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:22:20 GMT""}]","2023-02-22"
"2302.10796","Han Zhong","Han Zhong, Jiachen Hu, Yecheng Xue, Tongyang Li, Liwei Wang","Provably Efficient Exploration in Quantum Reinforcement Learning with
  Logarithmic Worst-Case Regret",,,,,"quant-ph cs.AI cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While quantum reinforcement learning (RL) has attracted a surge of attention
recently, its theoretical understanding is limited. In particular, it remains
elusive how to design provably efficient quantum RL algorithms that can address
the exploration-exploitation trade-off. To this end, we propose a novel
UCRL-style algorithm that takes advantage of quantum computing for tabular
Markov decision processes (MDPs) with $S$ states, $A$ actions, and horizon $H$,
and establish an $\mathcal{O}(\mathrm{poly}(S, A, H, \log T))$ worst-case
regret for it, where $T$ is the number of episodes. Furthermore, we extend our
results to quantum RL with linear function approximation, which is capable of
handling problems with large state spaces. Specifically, we develop a quantum
algorithm based on value target regression (VTR) for linear mixture MDPs with
$d$-dimensional linear representation and prove that it enjoys
$\mathcal{O}(\mathrm{poly}(d, H, \log T))$ regret. Our algorithms are variants
of UCRL/UCRL-VTR algorithms in classical RL, which also leverage a novel
combination of lazy updating mechanisms and quantum estimation subroutines.
This is the key to breaking the $\Omega(\sqrt{T})$-regret barrier in classical
RL. To the best of our knowledge, this is the first work studying the online
exploration in quantum RL with provable logarithmic worst-case regret.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:23:11 GMT""}]","2023-02-22"
"2302.10805","Federico Fusco","Nicol\`o Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni, Federico
  Fusco, Stefano Leonardi","Repeated Bilateral Trade Against a Smoothed Adversary",,,,,"cs.LG cs.DS cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study repeated bilateral trade where an adaptive $\sigma$-smooth adversary
generates the valuations of sellers and buyers. We provide a complete
characterization of the regret regimes for fixed-price mechanisms under
different feedback models in the two cases where the learner can post either
the same or different prices to buyers and sellers. We begin by showing that
the minimax regret after $T$ rounds is of order $\sqrt{T}$ in the full-feedback
scenario. Under partial feedback, any algorithm that has to post the same price
to buyers and sellers suffers worst-case linear regret. However, when the
learner can post two different prices at each round, we design an algorithm
enjoying regret of order $T^{3/4}$ ignoring log factors. We prove that this
rate is optimal by presenting a surprising $T^{3/4}$ lower bound, which is the
main technical contribution of the paper.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:30:10 GMT""}]","2023-02-22"
"2302.10806","Midia Reshadi","Midia Reshadi, David Gregg","Dynamic Resource Partitioning for Multi-Tenant Systolic Array Based DNN
  Accelerator",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNN) have become significant applications in both
cloud-server and edge devices. Meanwhile, the growing number of DNNs on those
platforms raises the need to execute multiple DNNs on the same device. This
paper proposes a dynamic partitioning algorithm to perform concurrent
processing of multiple DNNs on a systolic-array-based accelerator. Sharing an
accelerator's storage and processing resources across multiple DNNs increases
resource utilization and reduces computation time and energy consumption. To
this end, we propose a partitioned weight stationary dataflow with a minor
modification in the logic of the processing element. We evaluate the energy
consumption and computation time with both heavy and light workloads.
Simulation results show a 35% and 62% improvement in energy consumption and 56%
and 44% in computation time under heavy and light workloads, respectively,
compared with single tenancy.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:30:11 GMT""}]","2023-02-22"
"2302.10807","Pedro Tradacete","Enrique Garc\'ia-S\'anchez, David de Hevia, Pedro Tradacete","Free objects in Banach space theory",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We survey recent progress on three relevant instances of free objects related
to Banach spaces: Lipschitz free spaces generated by metric spaces, holomorphic
free spaces generated by open sets and free Banach lattices generated by Banach
spaces. Our emphasis will be on the parallelisms among these developments.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:31:58 GMT""}]","2023-02-22"
"2302.10808","Lu Liu","Lu Liu, Lei Zhou, Yuhan Dong","Bokeh Rendering Based on Adaptive Depth Calibration Network","6 pages, 6 figures",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Bokeh rendering is a popular and effective technique used in photography to
create an aesthetically pleasing effect. It is widely used to blur the
background and highlight the subject in the foreground, thereby drawing the
viewer's attention to the main focus of the image. In traditional digital
single-lens reflex cameras (DSLRs), this effect is achieved through the use of
a large aperture lens. This allows the camera to capture images with shallow
depth-of-field, in which only a small area of the image is in sharp focus,
while the rest of the image is blurred. However, the hardware embedded in
mobile phones is typically much smaller and more limited than that found in
DSLRs. Consequently, mobile phones are not able to capture natural shallow
depth-of-field photos, which can be a significant limitation for mobile
photography. To address this challenge, in this paper, we propose a novel
method for bokeh rendering using the Vision Transformer, a recent and powerful
deep learning architecture. Our approach employs an adaptive depth calibration
network that acts as a confidence level to compensate for errors in monocular
depth estimation. This network is used to supervise the rendering process in
conjunction with depth information, allowing for the generation of high-quality
bokeh images at high resolutions. Our experiments demonstrate that our proposed
method outperforms state-of-the-art methods, achieving about 24.7% improvements
on LPIPS and obtaining higher PSNR scores.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:33:51 GMT""}]","2023-02-22"
"2302.10809","Balint Gyevnar","Balint Gyevnar, Cheng Wang, Christopher G. Lucas, Shay B. Cohen,
  Stefano V. Albrecht","Causal Explanations for Stochastic Sequential Multi-Agent
  Decision-Making",,,,,"cs.AI cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present CEMA: Causal Explanations for Multi-Agent decision-making; a
system to generate causal explanations for agents' decisions in stochastic
sequential multi-agent environments. The core of CEMA is a novel causal
selection method which, unlike prior work that assumes a specific causal
structure, is applicable whenever a probabilistic model for predicting future
states of the environment is available. We sample counterfactual worlds with
this model which are used to identify and rank the salient causes behind
decisions. We also designed CEMA to meet the requirements of social explainable
AI. It can generate contrastive explanations based on selected causes and it
works as an interaction loop with users to assure relevance and intelligibility
for them. We implement CEMA for motion planning for autonomous driving and test
it in four diverse simulated scenarios. We show that CEMA correctly and
robustly identifies the relevant causes behind decisions and delivers relevant
explanations to users' queries.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:34:07 GMT""},{""version"":""v2"",""created"":""Tue, 9 May 2023 18:52:51 GMT""}]","2023-05-11"
"2302.10810","Nora Agah","Nora Agah, Brian Evans, Xiao Meng, Haiqing Xu","A Local Machine Learning Approach for Fingerprint-based Indoor
  Localization","To be published in IEEE SoutheastCon 2023 conference proceedings",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Machine learning (ML) solutions to indoor localization problems have become
popular in recent years due to high positioning accuracy and low cost of
implementation. This paper proposes a novel local nonparametric approach for
solving localizations from high-dimensional Received Signal Strength Indicator
(RSSI) values. Our approach consists of a sequence of classification algorithms
that sequentially narrows down the possible space for location solutions into
smaller neighborhoods. The idea of this sequential classification method is
similar to the decision tree algorithm, but a key difference is our splitting
of the dataset at each node is not based on features of input (i.e. RSSI
values), but some discrete-valued variables generated from the output variable
(i.e. the 3D real-world coordinates). The strength of our localization solution
can be tuned to problem specifics by the appropriate choice of how to
sequentially partition the the space of location into smaller neighborhoods.
Using the publicly available indoor localization dataset UJIIndoorLoc, we
evaluate our proposed method vs. the global ML algorithms for the dataset. The
primary contribution of this paper is to introduce a novel local ML solution
for indoor localization problems.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:35:53 GMT""}]","2023-02-22"
"2302.10811","Christoph Zollitsch","Christoph W. Zollitsch, Stefan Ruloff, Yan Fett, Haakon T. A.
  Wiedemann, Rudolf Richter, Jonathan D. Breeze, and Christopher W. M. Kay","Maser Threshold Characterization by Resonator Q-Factor Tuning",,,,,"cond-mat.mtrl-sci physics.optics quant-ph","http://creativecommons.org/licenses/by/4.0/","  The concepts for microwave amplification by stimulated emission of radiation
(maser) closely followed by the optical analogue, the laser, were developed in
the 1950s. Whereas the laser is now a ubiquitous technology, used in
fundamental science, industry and everyday life, applications for the maser
remain highly specialized e.g., for deep-space communication and astronomy.
Although the excellent low-noise microwave amplification properties of the
maser made it an attractive candidate for a broad range of applications, the
original maser systems required cryogenic temperatures and/or high vacuum
environments; both are major barriers for widespread applications. Thus, the
recent realization of a continuous-wave room-temperature maser, using NV$^-$
centers in diamond, reinvigorated the maser as an intriguing platform for
microwave research and development. Building on this work, we designed and
constructed an optimized setup in order to characterize the operating space of
a maser using NV$^-$ centers. Here we focus on the interplay of two key
parameters for continuous emission of microwave photons: the quality factor of
the microwave resonator and the degree of spin-level-inversion. We
characterized the performance of the maser as a function of these two
parameters, identified the parameter space of operation and could, thereby,
highlight the requirements for maximal continuous microwave emission.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:38:29 GMT""}]","2023-02-22"
"2302.10812","Saikat Chakraborty","Aniketh Malyala and Katelyn Zhou and Baishakhi Ray and Saikat
  Chakraborty","On ML-Based Program Translation: Perils and Promises","5 pages, 2 figures. Accepted at ICSE 2023 NIER - New Ideas and
  Emerging Results",,,,"cs.PL cs.AI cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the advent of new and advanced programming languages, it becomes
imperative to migrate legacy software to new programming languages.
Unsupervised Machine Learning-based Program Translation could play an essential
role in such migration, even without a sufficiently sizeable reliable corpus of
parallel source code. However, these translators are far from perfect due to
their statistical nature. This work investigates unsupervised program
translators and where and why they fail. With in-depth error analysis of such
failures, we have identified that the cases where such translators fail follow
a few particular patterns. With this insight, we develop a rule-based program
mutation engine, which pre-processes the input code if the input follows
specific patterns and post-process the output if the output follows certain
patterns. We show that our code processing tool, in conjunction with the
program translator, can form a hybrid program translator and significantly
improve the state-of-the-art. In the future, we envision an end-to-end program
translation tool where programming domain knowledge can be embedded into an
ML-based translation pipeline using pre- and post-processing steps.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:42:20 GMT""}]","2023-02-22"
"2302.10813","Zeyu Xiong","Zeyu Xiong, Daizong Liu, Pan Zhou, Jiahao Zhu","Tracking Objects and Activities with Attention for Temporal Sentence
  Grounding","accepted by ICASSP2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal sentence grounding (TSG) aims to localize the temporal segment which
is semantically aligned with a natural language query in an untrimmed
video.Most existing methods extract frame-grained features or object-grained
features by 3D ConvNet or detection network under a conventional TSG framework,
failing to capture the subtle differences between frames or to model the
spatio-temporal behavior of core persons/objects. In this paper, we introduce a
new perspective to address the TSG task by tracking pivotal objects and
activities to learn more fine-grained spatio-temporal behaviors. Specifically,
we propose a novel Temporal Sentence Tracking Network (TSTNet), which contains
(A) a Cross-modal Targets Generator to generate multi-modal templates and
search space, filtering objects and activities, and (B) a Temporal Sentence
Tracker to track multi-modal targets for modeling the targets' behavior and to
predict query-related segment. Extensive experiments and comparisons with
state-of-the-arts are conducted on challenging benchmarks: Charades-STA and
TACoS. And our TSTNet achieves the leading performance with a considerable
real-time speed.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:42:52 GMT""}]","2023-02-22"
"2302.10814","Nantel Bergeron","Nantel Bergeron and Lucas Gagnon","The excedance quotient of the Bruhat order, Quasisymmetric Varieties and
  Temperley-Lieb algebras","23 pages. Final draft (all proofs are complete)",,,,"math.CO math.AG math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $R_n=\mathbb{Q}[x_1,x_2,\ldots,x_n]$ be the ring of polynomial in $n$
variables and consider the ideal $\langle \mathrm{QSym}_{n}^{+}\rangle\subseteq
R_n$ generated by quasisymmetric polynomials without constant term. It was
shown by J.~C.~Aval, F.~Bergeron and N.~Bergeron that $\dim\big(R_n\big/\langle
\mathrm{QSym}_{n}^{+} \rangle\big)=C_n$ the $n$th Catalan number. In the
present work, we explain this phenomenon by defining a set of permutations
$\mathrm{QSV}_{n}$ with the following properties: first, $\mathrm{QSV}_{n}$ is
a basis of the Temperley--Lieb algebra $\mathsf{TL}_{n}(2)$, and second, when
considering $\mathrm{QSV}_{n}$ as a collection of points in $\mathbb{Q}^{n}$,
the top-degree homogeneous component of the vanishing ideal
$\mathbf{I}(\mathrm{QSV}_{n})$ is $\langle \mathrm{QSym}_{n}^{+}\rangle$.
  Our construction has a few byproducts which are independently noteworthy. We
define an equivalence relation $\sim$ on the symmetric group $S_{n}$ using weak
excedances and show that its equivalence classes are naturally indexed by
noncrossing partitions. Each equivalence class is an interval in the Bruhat
order between an element of $\mathrm{QSV}_{n}$ and a $321$-avoiding
permutation. Furthermore, the Bruhat order induces a well-defined order on
$S_{n}\big/\!\!\sim$. Finally, we show that any section of the quotient
$S_{n}\big/\!\!\sim$ gives an (often novel) basis for $\mathsf{TL}_{n}(2)$.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:44:10 GMT""}]","2023-02-22"
"2302.10815","William T. Reach","William T. Reach, Paul G. Lucey, Casey I. Honniball, Anicia Arredondo,
  Erick R. Malaret","The Distribution of Molecular Water in the Lunar South Polar Region
  based upon 6-micron Spectroscopic Imaging","accepted to Planetary Science Journal on 2/20/2023",,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  The amount and distribution of water on the lunar surface are related to the
input and production of water by solar wind and meteoroid bombardment, balanced
by photodestruction and mobility across the surface. Using the Stratospheric
Observatory for Infrared Astronomy (SOFIA), we imaged the 6.1 micron feature
that uniquely traces molecular water, covering 1/4 of the lunar nearside
surface south of -60 degrees latitude with 5 km resolution on 2022 Feb 17 UTC.
The water feature strength varies significantly across the region, being drier
at +28 degrees longitude to more wet (~170 ppm) at -7 degrees longitude, and
also decreasing toward the pole. Significant local enhancements are found,
associated with south-facing, high-altitude topographic features. This includes
relatively high H2O concentration in a ""wet ridge"" just north of Curtius
crater; the south-facing, northern, inner rims of most prominent craters; the
south face of the central peak of Moretus crater; and permanently-shadowed
polar regions.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:48:27 GMT""}]","2023-02-22"
"2302.10816","Walid Maalej","Walid Maalej, Yen Dieu Pham and Larissa Chazette","Tailoring Requirements Engineering for Responsible AI","To appear in IEEE Computer, Special Issue on Software Engineering for
  Responsible AI",,"10.1109/MC.2023.3243182",,"cs.AI cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Requirements Engineering (RE) is the discipline for identifying, analyzing,
as well as ensuring the implementation and delivery of user, technical, and
societal requirements. Recently reported issues concerning the acceptance of
Artificial Intelligence (AI) solutions after deployment, e.g. in the medical,
automotive, or scientific domains, stress the importance of RE for designing
and delivering Responsible AI systems. In this paper, we argue that RE should
not only be carefully conducted but also tailored for Responsible AI. We
outline related challenges for research and practice.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:48:59 GMT""}]","2023-02-22"
"2302.10817","Vivek Mallampati","Vivek Mallampati and Harish Ravichandar","Inferring Implicit Trait Preferences for Task Allocation in
  Heterogeneous Teams","8 pages, 5 figures, to be published as extended abstract in AAMAS
  2023",,,,"cs.RO cs.MA","http://creativecommons.org/licenses/by/4.0/","  Task allocation in heterogeneous multi-agent teams often requires reasoning
about multi-dimensional agent traits (i.e., capabilities) and the demands
placed on them by tasks. However, existing methods tend to ignore the fact that
not all traits equally contribute to a given task. Ignoring such inherent
preferences or relative importance can lead to unintended sub-optimal
allocations of limited agent resources that do not necessarily contribute to
task success. Further, reasoning over a large number of traits can incur a
hefty computational burden. To alleviate these concerns, we propose an
algorithm to infer task-specific trait preferences implicit in expert
demonstrations. We leverage the insight that the consistency with which an
expert allocates a trait to a task across demonstrations reflects the trait's
importance to that task. Inspired by findings in psychology, we account for the
fact that the inherent diversity of a trait in the dataset influences the
dataset's informativeness and, thereby, the extent of the inferred preference
or the lack thereof. Through detailed numerical simulations and evaluations of
a publicly-available soccer dataset (FIFA 20), we demonstrate that we can
successfully infer implicit trait preferences and that accounting for the
inferred preferences leads to more computationally efficient and effective task
allocation, compared to a baseline approach that treats all traits equally.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:53:57 GMT""}]","2023-02-22"
"2302.10818","Paul Voyles","Debaditya Chatterjee, Shuoyuan Huang, Kaichen Gu, Jianzhu Ju, Junguang
  Yu, Harald Bock, Lian Yu, M. D. Ediger, and Paul M. Voyles","Using 4D STEM to probe mesoscale order in molecular glass films prepared
  by physical vapor deposition",,,"10.1021/acs.nanolett.3c00197",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physical vapor deposition can be used to prepare highly stable organic glass
systems where the molecules show orientational and translational ordering at
the nanoscale. We have used low-dose four-dimensional scanning transmission
electron microscopy (4D STEM), enabled by a fast direct electron detector, to
map columnar order in glassy samples of a discotic mesogen using a 2 nm probe.
Both vapor deposited and liquid cooled glassy films show domains of similar
orientation, but their size varies from tens to hundreds of nanometers,
depending on processing. Domain sizes are consistent with surface diffusion
mediated ordering during film deposition. These results demonstrate the ability
of low-dose 4D STEM to characterize mesoscale structure in a molecular glass
system which may be relevant to organic electronics.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:55:19 GMT""}]","2023-03-07"
"2302.10819","Konstantin L. Metlov","Konstantin L. Metlov","Topological magnetic memory with multiply-connected planar magnetic
  nanoelements","5 pages, 2 figures",,,,"cond-mat.mes-hall physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A coding scheme is introduced, allowing to store a set of linked bit strings
in planar magnetic nanoelements with holes. Analytical expressions for the
corresponding magnetization distributions are developed up to a homotopy and
the specific examples are given for doubly- and triply-connected cases. The
energy barriers, protecting the information-bearing states, are discussed.
Compared to a set of disparate simply-connected nanoelements of the same total
connectivity, the nanoelements with holes can hold much more information due to
the possibility of linking the individual bits.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:55:28 GMT""}]","2023-02-22"
"2302.10820","Penghao Jiang","Penghao Jiang, Xuanchen Hou, Yinsi Zhou","Device Tuning for Multi-Task Large Model","AAAI Conference on Artificial Intelligence Deployable AI (DAI) 2023",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Unsupervised pre-training approaches have achieved great success in many
fields such as Computer Vision (CV), Natural Language Processing (NLP) and so
on. However, compared to typical deep learning models, pre-training or even
fine-tuning the state-of-the-art self-attention models is extremely expensive,
as they require much more computational and memory resources. It severely
limits their applications and success in a variety of domains, especially for
multi-task learning. To improve the efficiency, we propose Device Tuning for
the efficient multi-task model, which is a massively multitask framework across
the cloud and device and is designed to encourage learning of representations
that generalize better to many different tasks. Specifically, we design Device
Tuning architecture of a multi-task model that benefits both cloud modelling
and device modelling, which reduces the communication between device and cloud
by representation compression. Experimental results demonstrate the
effectiveness of our proposed method.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:55:48 GMT""}]","2023-02-22"
"2302.10821","Jiacheng Tian","Jiacheng Tian, Paul J. Tackley, Diogo L. Louren\c{c}o","The Tectonics and Volcanism of Venus: New Modes Facilitated by Realistic
  Crustal Rheology and Intrusive Magmatism","Minor changes to previous version. Accepted by Icarus. Main text 54
  pages, 17 figures, abstract abbreviated",,"10.1016/j.icarus.2023.115539",,"astro-ph.EP physics.geo-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  To explain Venus' young surface age and lack of plate tectonics, Venus'
tectonic regime has often been proposed to be either an episodic-lid regime
with global lithospheric overturns, or an equilibrium resurfacing regime with
numerous volcanic and tectonic activities. Here, we use global 2-D
thermochemical convection models with realistic parameters, including rheology
(dislocation creep, diffusion creep, and plastic yielding), an experiment-based
plagioclase (An$_{75}$) crustal rheology, and intrusive magmatism, to
investigate the tectonics and mantle evolution of Venus. We find that surface
tectonics is strongly affected by crustal rheology. With a ''weak''
plagioclase-rheology crust, models exhibit episodic overturns but with
continuously high surface mobility and high distributed surface strain rates
between overturns, leading to a new tectonic regime that we name ''deformable
episodic lid''. On the other hand, olivine-crustal-rheology models exhibit
either standard episodic-lid tectonics, i.e. with mobility that is high during
overturns and near zero between overturns, or stagnant-lid tectonics, i.e. with
near-zero mobility over the entire model time. Also, a combination of
plagioclase crustal rheology and dislocation creep can weaken the lithosphere
sufficiently to facilitate lithospheric overturns without applying plastic
yielding. Internally, the composition-dependent density profile results in a
''basalt barrier'' at the mantle transition zone, which strongly affects Venus'
mantle evolution. Only strong plumes can penetrate this basalt barrier and
cause global lithospheric overturns. This basalt barrier also causes global
internal episodic overturns that generate global volcanic resurfacing in
stagnant-lid models, which suggests a new resurfacing mechanism (we name it
''stagnant episodic-volcanic-resurfacing'') that does not involve lithospheric
overturns.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:57:26 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 21:06:38 GMT""}]","2023-04-19"
"2302.10822","Martin Keller","Martin Keller (1), Abderrezak Belabbes (1 and 2), J\""urgen
  Furthm\""uller (1), Friedhelm Bechstedt (1), Silvana Botti (1) ((1)
  Friedrich-Schiller-Universit\""at Jena, Institut f\""ur Festk\""orpertheorie und
  -optik, Germany, (2) Department of Physics, Sultan Qaboos University, Muscat,
  Oman)","First-principles insight in structure-property relationships of
  hexagonal Si and Ge polytypes","37 pages, 7 figures, submitted to Physical Review Materials",,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hexagonal SiGe is a promising material for combining electronic and photonic
technologies. In this work, the energetic, structural, elastic and electronic
properties of the hexagonal polytypes (2$H$, 4$H$ and 6$H$) of silicon and
germanium are thoroughly analyzed under equilibrium conditions. For this
purpose, we apply state-of-the-art density functional theory. The phase
diagram, obtained in the framework of a generalized Ising model, shows that the
diamond structure is the most stable under ambient conditions, but hexagonal
modifications are close to the phase boundary, especially for Si. Our
band-structure calculations using the MBJLDA and HSE06 exchange correlation
functionals predict significant changes in electronic states with hexagonality.
While Si crystals are always semiconductors with indirect band gaps, the
hexagonal Ge polytypes have direct band gaps. The branch point energies for Ge
crystals are below the valence band maxima, and therefore the formation of hole
gases on Ge surfaces is favoured. Band alignment based on the branch point
energy leads to type-I heterocrystalline interfaces between Ge polytypes, where
electrons and holes can be trapped in the layer with the higher hexagonality.
In contrast, the energy shift of the indirect conduction band minima of Si
polytypes is rather weak, leading to delocalization of excited electrons at
interfaces, while only holes can localize in the layer with higher
hexagonality.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:59:44 GMT""}]","2023-02-22"
"2302.10823","Jorge L. Cervantes-Cota Dr.","Salvador Galindo-Uribarri and Jorge L. Cervantes-Cota","On Einstein's last bid to keep a stationary cosmology","11 pages","The Sixteenth Marcel Grossmann Meeting, pp. 3519-3535 (2023)","10.1142/9789811269776_0294",,"physics.hist-ph gr-qc","http://creativecommons.org/licenses/by/4.0/","  It is commonly known that the steady-state model of the universe was proposed
and championed in a series of influential papers around mid-twenty century by
Fred Hoyle, Hermann Bondi, and Thomas Gold. In contrast it is little known
that, many years before, Albert Einstein briefly explored the same idea; that
is of a 'dynamic steady state' universe. In 1931 during his first visit to
Caltech, Einstein tried to develop a model where the universe expanded and
where matter was supposed to be continuously created. This latter process was
proposed by him to keep the matter density of the universe constant. However,
Einstein shortly abandoned the idea. The whole event has already been described
and analyzed by C. O'Raifeartaigh and colleagues in 2014. It is the purpose of
this brief note to point out what might have prompted Einstein to consider a
continuous creation of matter and the prevailing circumstances at that time
that drove Einstein's intent.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:59:45 GMT""}]","2023-02-23"
"2302.10825","Jiong Li","Jiong Li, Pratik Gajane","Curiosity-driven Exploration in Sparse-reward Multi-agent Reinforcement
  Learning",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sparsity of rewards while applying a deep reinforcement learning method
negatively affects its sample-efficiency. A viable solution to deal with the
sparsity of rewards is to learn via intrinsic motivation which advocates for
adding an intrinsic reward to the reward function to encourage the agent to
explore the environment and expand the sample space. Though intrinsic
motivation methods are widely used to improve data-efficient learning in the
reinforcement learning model, they also suffer from the so-called detachment
problem. In this article, we discuss the limitations of intrinsic curiosity
module in sparse-reward multi-agent reinforcement learning and propose a method
called I-Go-Explore that combines the intrinsic curiosity module with the
Go-Explore framework to alleviate the detachment problem.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:00:05 GMT""}]","2023-02-22"
"2302.10826","Federico Della Croce","Roberto Bargetto, Federico Della Croce, Rosario Scatamacchia","ITERATED INSIDE OUT: a new exact algorithm for the transportation
  problem",,,,,"math.OC cs.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a novel exact algorithm for the transportation problem, one of the
paradigmatic network optimization problems. The algorithm, denoted Iterated
Inside Out, requires in input a basic feasible solution and is composed by two
main phases that are iteratively repeated until an optimal basic feasible
solution is reached. In the first ""inside"" phase, the algorithm progressively
improves upon a given basic solution by increasing the value of several
non-basic variables with negative reduced cost. This phase typically outputs a
non-basic feasible solution interior to the constraints set polytope. The
second ""out"" phase moves in the opposite direction by iteratively setting to
zero several variables until a new improved basic feasible solution is reached.
Extensive computational tests show that the proposed approach strongly
outperforms all versions of network and linear programming algorithms available
in the commercial solvers Cplex and Gurobi and other exact algorithms available
in the literature.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:03:22 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 13:52:45 GMT""}]","2023-03-30"
"2302.10827","Yuan Sun","Yuan Sun, Qiurong Song, Xinning Gui, Fenglong Ma, Ting Wang","AutoML in The Wild: Obstacles, Workarounds, and Expectations","In Proceedings of the 2023 CHI Conference on Human Factors in
  Computing Systems, April 23-28, 2023, Hamburg, Germany. ACM, New York, NY,
  USA, 15 Pages",,"10.1145/3544548.3581082",,"cs.HC cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Automated machine learning (AutoML) is envisioned to make ML techniques
accessible to ordinary users. Recent work has investigated the role of humans
in enhancing AutoML functionality throughout a standard ML workflow. However,
it is also critical to understand how users adopt existing AutoML solutions in
complex, real-world settings from a holistic perspective. To fill this gap,
this study conducted semi-structured interviews of AutoML users (N = 19)
focusing on understanding (1) the limitations of AutoML encountered by users in
their real-world practices, (2) the strategies users adopt to cope with such
limitations, and (3) how the limitations and workarounds impact their use of
AutoML. Our findings reveal that users actively exercise user agency to
overcome three major challenges arising from customizability, transparency, and
privacy. Furthermore, users make cautious decisions about whether and how to
apply AutoML on a case-by-case basis. Finally, we derive design implications
for developing future AutoML solutions.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:06:46 GMT""}]","2023-02-22"
"2302.10828","Bhuvanesh Sundar","Bhuvanesh Sundar, Diego Barberena, Ana Maria Rey, Asier Pineiro Orioli","Squeezing multilevel atoms in dark states via cavity superradiance","4.5 pages, 3 figures + Supplement",,,,"quant-ph cond-mat.quant-gas","http://creativecommons.org/licenses/by/4.0/","  We describe a method to create and store scalable and long-lived entangled
spin-squeezed states within a manifold of many-body cavity dark states using
collective emission of light from multilevel atoms inside an optical cavity. We
show that the system can be tuned to generate squeezing in a dark state where
it will be immune to superradiance. We also show more generically that
squeezing can be generated using a combination of superradiance and coherent
driving in a bright state, and subsequently be transferred via single-particle
rotations to a dark state where squeezing can be stored. Our findings, readily
testable in current optical cavity experiments with alkaline-earth-like atoms,
can open a path for dissipative generation and storage of metrologically useful
states in optical transitions.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:07:32 GMT""}]","2023-02-22"
"2302.10829","Mario Fern\'andez Navarro","Mario Fern\'andez Navarro","Flavour hierarchies and $B$-anomalies in a twin Pati-Salam theory of
  flavour","8 pages + references, 4 figures, Contribution to the Proceedings of
  the 8th Symposium on Prospects in the Physics of Discrete Symmetries
  (DISCRETE 2022), 7-11 November 2022, Baden-Baden, Germany, v2: A few
  references added",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  In this manuscript, based on arXiv:2209.00276, I present a model which can
simultaneously explain and connect the flavour hierarchies of the Standard
Model with flavour anomalies in $B$-physics. I will briefly introduce the model
and highlight the main features, including a common origin of Yukawa couplings
and vector leptoquark $U_{1}$ couplings to Standard Model fermions. A GIM-like
mechanism allows for large leptoquark couplings which can explain the
$B$-anomalies, while protecting from the most dangerous FCNCs that could be
mediated by a heavy coloron and $Z'$. Finally, I will highlight some of the
most promising signals at low energy processes which can test the model in the
upcoming future. The analysis has been updated with the late 2022 measurements
of $R_{K^{(*)}}$ by LHCb.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:08:42 GMT""},{""version"":""v2"",""created"":""Thu, 9 Mar 2023 12:50:08 GMT""}]","2023-03-10"
"2302.10830","Andrew Papanicolaou","Negash Medhin, Andrew Papanicolaou, Marwen Zrida","Partial-Information Q-Learning for General Two-Player Stochastic Games",,,,,"cs.GT math.OC","http://creativecommons.org/licenses/by/4.0/","  In this article we analyze a partial-information Nash Q-learning algorithm
for a general 2-player stochastic game. Partial information refers to the
setting where a player does not know the strategy or the actions taken by the
opposing player. We prove convergence of this partially informed algorithm for
general 2-player games with finitely many states and actions, and we confirm
that the limiting strategy is in fact a full-information Nash equilibrium. In
implementation, partial information offers simplicity because it avoids
computation of Nash equilibria at every time step. In contrast,
full-information Q-learning uses the Lemke-Howson algorithm to compute Nash
equilibria at every time step, which can be an effective approach but requires
several assumptions to prove convergence and may have runtime error if
Lemke-Howson encounters degeneracy. In simulations, the partial information
results we obtain are comparable to those for full-information Q-learning and
fictitious play.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:09:51 GMT""}]","2023-02-22"
"2302.10831","Thomas Kleine Buening","Thomas Kleine Buening, Christos Dimitrakakis, Hannes Eriksson, Divya
  Grover, Emilio Jorge","Minimax-Bayes Reinforcement Learning",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While the Bayesian decision-theoretic framework offers an elegant solution to
the problem of decision making under uncertainty, one question is how to
appropriately select the prior distribution. One idea is to employ a worst-case
prior. However, this is not as easy to specify in sequential decision making as
in simple statistical estimation problems. This paper studies (sometimes
approximate) minimax-Bayes solutions for various reinforcement learning
problems to gain insights into the properties of the corresponding priors and
policies. We find that while the worst-case prior depends on the setting, the
corresponding minimax policies are more robust than those that assume a
standard (i.e. uniform) prior.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:10:21 GMT""}]","2023-02-22"
"2302.10832","Giulia Maniccia","Giulia Maniccia and Giovanni Montani and Stefano Antonini","QFT in Curved Spacetime from Quantum Gravity: proper WKB decomposition
  of the gravitational component","8 pages. Title updated and discussion expanded; matches published
  version","Phys. Rev. D 107 (2023) L061901","10.1103/PhysRevD.107.L061901",,"gr-qc hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from a re-analysis of previous work, we construct the proper low
energy quantum field theory (QFT) limit of a full quantum gravity theory in the
Born-Oppenheimer approach. We separate the gravitational sector into a
classical background, given by a vacuum diagonal Bianchi I cosmology, and its
quantum perturbations represented by the two graviton degrees of freedom; we
further include quantum matter in the form of a test scalar field. We then
implement a Born-Oppenheimer separation, where the gravitons and matter play
the role of ""slow"" and ""fast"" quantum components respectively, and perform a
Wentzel-Kramers-Brillouin (WKB) expansion in a Planckian parameter. The
functional Schr\""odinger evolution for matter is recovered after averaging over
quantum gravitational effects, provided that a condition is imposed on the
gravitons' wave functional. Such a condition fixes the graviton dynamics and is
equivalent to the purely gravitational Wheeler-DeWitt constraint imposed in
previous approaches. The main accomplishment of the present work is to clarify
that QFT in curved spacetime can be recovered in the low energy limit of
quantum gravity only after averaging over the graviton degrees of freedom, in
the spirit of effective field theory. Furthermore, it justifies a posteriori
the implementation of the gravitational Wheeler-DeWitt equation on the ""slow""
gravitons' wave functional rather than assuming its validity a priori.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:24:24 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 09:07:14 GMT""}]","2023-03-17"
"2302.10833","Johan Mazoyer","Rapha\""el Galicher and Johan Mazoyer","Imaging exoplanets with coronagraphic instruments","Accepted for publication in Comptes Rendus Physique. 48 pages
  (including 12 pages of references). 16 figures","Comptes Rendus. Physique, Online first (2023), pp. 1-45","10.5802/crphys.133",,"astro-ph.EP astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Exoplanetary science is a very active field of astronomy nowadays, with
questions still opened such as how planetary systems form and evolve
(occurrence, process), why such a diversity of exoplanets is observed (mass,
radius, orbital parameters, temperature, composition), and what are the
interactions between planets, circumstellar disk and their host star. Several
complementary methods are used for the detection of exoplanets. Among these,
imaging aims at the direct detection of the light reflected, scattered or
emitted by exoplanets and circumstellar disks. This allows their spectral and
polarimetric characterization. Such imaging remains challenging because of the
large luminosity ratio (1e4-1e10$) and the small angular separation (fraction
of an arcsecond) between the star and its environment. Over the past two
decades, numerous techniques, including coronagraphy, have been developed to
make exoplanet imaging a reality.
  This review gives a broad overview of the subsystems that make up a
coronagraphic instrument for imaging exoplanetary systems. It is especially
intended for non-specialists or newcomers in the field. We explain the
principle of coronagraphy and propose a formalism to understand their behavior.
We discuss the impact of wavefront aberrations on the performance of
coronagraphs and how they induce stellar speckles in the scientific image.
Finally, we present instrumental and signal processing techniques used for
on-sky minimization or a posteriori calibration of these speckles in order to
improve the performance of coronagraphs.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:26:24 GMT""}]","2023-03-07"
"2302.10834","Sanat Ramesh","Sanat Ramesh, Diego Dall'Alba, Cristians Gonzalez, Tong Yu, Pietro
  Mascagni, Didier Mutter, Jacques Marescaux, Paolo Fiorini, and Nicolas Padoy","Weakly Supervised Temporal Convolutional Networks for Fine-grained
  Surgical Activity Recognition",,,"10.1109/TMI.2023.3262847",,"cs.CV","http://creativecommons.org/licenses/by-sa/4.0/","  Automatic recognition of fine-grained surgical activities, called steps, is a
challenging but crucial task for intelligent intra-operative computer
assistance. The development of current vision-based activity recognition
methods relies heavily on a high volume of manually annotated data. This data
is difficult and time-consuming to generate and requires domain-specific
knowledge. In this work, we propose to use coarser and easier-to-annotate
activity labels, namely phases, as weak supervision to learn step recognition
with fewer step annotated videos. We introduce a step-phase dependency loss to
exploit the weak supervision signal. We then employ a Single-Stage Temporal
Convolutional Network (SS-TCN) with a ResNet-50 backbone, trained in an
end-to-end fashion from weakly annotated videos, for temporal activity
segmentation and recognition. We extensively evaluate and show the
effectiveness of the proposed method on a large video dataset consisting of 40
laparoscopic gastric bypass procedures and the public benchmark CATARACTS
containing 50 cataract surgeries.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:26:49 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 13:55:28 GMT""}]","2023-04-12"
"2302.10835","Keith Mills Mr.","Fred X. Han, Keith G. Mills, Fabian Chudak, Parsa Riahi, Mohammad
  Salameh, Jialin Zhang, Wei Lu, Shangling Jui, Di Niu","A General-Purpose Transferable Predictor for Neural Architecture Search","Accepted to SDM2023; version includes supplementary material; 12
  Pages, 3 Figures, 6 Tables",,"10.1137/1.9781611977653.ch81",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding and modelling the performance of neural architectures is key to
Neural Architecture Search (NAS). Performance predictors have seen widespread
use in low-cost NAS and achieve high ranking correlations between predicted and
ground truth performance in several NAS benchmarks. However, existing
predictors are often designed based on network encodings specific to a
predefined search space and are therefore not generalizable to other search
spaces or new architecture families. In this paper, we propose a
general-purpose neural predictor for NAS that can transfer across search
spaces, by representing any given candidate Convolutional Neural Network (CNN)
with a Computation Graph (CG) that consists of primitive operators. We further
combine our CG network representation with Contrastive Learning (CL) and
propose a graph representation learning procedure that leverages the structural
information of unlabeled architectures from multiple families to train CG
embeddings for our performance predictor. Experimental results on
NAS-Bench-101, 201 and 301 demonstrate the efficacy of our scheme as we achieve
strong positive Spearman Rank Correlation Coefficient (SRCC) on every search
space, outperforming several Zero-Cost Proxies, including Synflow and Jacov,
which are also generalizable predictors across search spaces. Moreover, when
using our proposed general-purpose predictor in an evolutionary neural
architecture search algorithm, we can find high-performance architectures on
NAS-Bench-101 and find a MobileNetV3 architecture that attains 79.2% top-1
accuracy on ImageNet.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:28:05 GMT""}]","2023-04-19"
"2302.10836","Maude Wagner","Ana W Capuano and Maude Wagner","nlive: an R Package to facilitate the application of the sigmoidal and
  random changepoint mixed models",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  The use of mixed effect models with a specific functional form such as the
Sigmoidal Mixed Model and the Piecewise Mixed Model (or Changepoint Mixed
Model) with abrupt or smooth random change allow the interpretation of the
defined parameters to understand longitudinal trajectories. Currently, there
are no interface R packages that can easily fit the Sigmoidal Mixed Model
allowing the inclusion of covariates or incorporate recent developments to fit
the Piecewise Mixed Model with random change. To facilitate the modeling of the
Sigmoidal Mixed Model, and Piecewise Mixed Model with abrupt or smooth random
change, we have created an R package called nlive. All needed pieces such as
functions, covariance matrices, and initials generation were programmed. The
package was implemented with recent developments such as the polynomial smooth
transition of piecewise mixed model with improved properties over Bacon-Watts,
and the stochastic approximation expectation-maximization (SAEM) for efficient
estimation. It was designed to help interpretation of the output by providing
features such as annotated output, warnings, and graphs. Functionality,
including time and convergence, was tested using simulations. We provided a
data example to illustrate the package use and output features and
interpretation. The package implemented in the R software is available from the
Comprehensive R Archive Network (CRAN) at
https://CRAN.R-project.org/package=nlive. The nlive package for R fits the
Sigmoidal Mixed Model and the Piecewise Mixed: abrupt and smooth. The nlive
allows fitting these models with only five mandatory arguments that are
intuitive enough to the less sophisticated users.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:35:12 GMT""}]","2023-02-22"
"2302.10837","Anastasia Lavrukhina","Anastasia Lavrukhina, Konstantin Malanchev","Performant feature extraction for photometric time series","4 pages, 3 figures. EAS 2022 proceeding, to be published in Memorie
  della SAIt",,,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Astronomy is entering the era of large surveys of the variable sky such as
Zwicky Transient Facility (ZTF) and the forthcoming Legacy Survey of Space and
Time (LSST) which are intended to produce up to a million alerts per night.
Such an amount of photometric data requires efficient light-curve
pre-processing algorithms for the purposes of subsequent data quality cuts,
classification, and characterization analysis. In this work, we present the new
library ""light-curve"" for Python and Rust, which is intended for feature
extraction from light curves of variable astronomical sources. The library is
suitable for machine learning classification problems: it provides a fast
implementation of feature extractors, which outperforms other public available
codes, and consists of dozens features describing shape, magnitude
distribution, and periodic properties of light curves. It includes not only
features which had been shown to provide a high performance in classification
tasks, but also new features we developed to improve classification quality of
selected types of objects. The ""light-curve"" library is currently used by the
ANTARES, AMPEL, and Fink broker systems for analyzing the ZTF alert stream, and
has been selected for use with the LSST.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:39:28 GMT""}]","2023-02-22"
"2302.10838","Vladimir Bozhilov","Vladimir Bozhilov, Desislava Antonova, Melissa J. Hobson, Rafael
  Brahm, Andres Jordan, Thomas Henning, Jan Eberhardt, Felipe I. Rojas,
  Konstantin Batygin, Pascal Torres-Miranda, Keivan G. Stassun, Sarah C.
  Millholland, Denitza Stoeva, Milen Minev, Nestor Espinoza, George R. Ricker,
  David W. Latham, Diana Dragomir, Michelle Kunimoto, Jon M. Jenkins, Eric B.
  Ting, Sara Seager, Joshua N. Winn, Jesus Noel Villasenor, Luke G. Bouma,
  Jennifer Medina, and Trifon Trifonov","A 2:1 Mean-Motion Resonance Super-Jovian pair revealed by TESS, FEROS,
  and HARPS","Published in the ApJL","ApJL 946 L36 (2023)","10.3847/2041-8213/acbd4f",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of a super-Jovian 2:1 mean-motion resonance (MMR)
pair around the G-type star TIC 279401253, whose dynamical architecture is a
prospective benchmark for planet formation and orbital evolution analysis. The
system was discovered thanks to a single transit event recorded by the
Transiting Exoplanet Survey Satellite (TESS) mission, which pointed to a
Jupiter-sized companion with poorly constrained orbital parameters. We began
ground-based precise radial velocity (RV) monitoring with HARPS and FEROS
within the Warm gIaNts with tEss (WINE) survey to constrain the transiting
body's period, mass, and eccentricity. The RV measurements revealed not one but
two massive planets with periods of 76.80$_{-0.06}^{+0.06}$ days and
155.3$_{-0.7}^{+0.7}$ days, respectively. A combined analysis of transit and RV
data yields an inner transiting planet with a mass of 6.14$_{-0.42}^{+0.39}$
M$_{\rm Jup}$ and a radius of 1.00$_{-0.04}^{+0.04}$ R$_{\rm Jup}$, and an
outer planet with a minimum mass of 8.02$_{-0.18}^{+0.18}$ M$_{\rm Jup}$,
indicating a massive giant pair. A detailed dynamical analysis of the system
reveals that the planets are locked in a strong first-order, eccentricity-type
2:1 MMR, which makes TIC 279401253 one of the rare examples of truly resonant
architectures supporting disk-induced planet migration. The bright host star,
$V \approx$ 11.9 mag, the relatively short orbital period ($P_{\rm b}$ =
76.80$_{-0.06}^{+0.06}$ d) and pronounced eccentricity (e
=0.448$_{-0.029}^{+0.028}$) make the transiting planet a valuable target for
atmospheric investigation with the James Webb Space Telescope (JWST) and
ground-based extremely-large telescopes.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:39:47 GMT""},{""version"":""v2"",""created"":""Thu, 11 May 2023 15:45:00 GMT""}]","2023-05-12"
"2302.10839","Dominic Breit","Dominic Breit and Andrea Cianchi","Inclusion relations among fractional Orlicz-Sobolev spaces and a
  Littlewood-Paley characterization",,,,,"math.FA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Embeddings among fractional Orlicz-Sobolev spaces with different smoothness
are characterized. The equivalence of their Gagliardo-Slobodeckij norms to
norms defined via Littlewood-Paley decompostions, via oscillations, or via
Besov type difference quotients is also established. These equivalences, of
independent interest, are a key tool in the proof of the relevant embeddings.
They also rest upon a new optimal inequality for convolutions in Orlicz spaces.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:41:13 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 08:59:47 GMT""},{""version"":""v3"",""created"":""Thu, 13 Apr 2023 07:34:27 GMT""}]","2023-04-14"
"2302.10840","Neil Dey","Neil Dey, Jonathan P. Williams","Valid Inference for Machine Learning Model Parameters","25 pages, 5 figures",,,,"stat.ML cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  The parameters of a machine learning model are typically learned by
minimizing a loss function on a set of training data. However, this can come
with the risk of overtraining; in order for the model to generalize well, it is
of great importance that we are able to find the optimal parameter for the
model on the entire population -- not only on the given training sample. In
this paper, we construct valid confidence sets for this optimal parameter of a
machine learning model, which can be generated using only the training data
without any knowledge of the population. We then show that studying the
distribution of this confidence set allows us to assign a notion of confidence
to arbitrary regions of the parameter space, and we demonstrate that this
distribution can be well-approximated using bootstrapping techniques.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:46:08 GMT""}]","2023-02-22"
"2302.10841","Byron Chin","Byron Chin, Ankur Moitra, Elchanan Mossel, Colin Sandon","The Power of an Adversary in Glauber Dynamics","12 pages, added section about the optimization perspective",,,,"math.PR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Glauber dynamics are a natural model of dynamics of dependent systems. While
originally introduced in statistical physics, they have found important
applications in the study of social networks, computer vision and other
domains. In this work, we introduce a model of corrupted Glauber dynamics
whereby instead of updating according to the prescribed conditional
probabilities, some of the vertices and their updates are controlled by an
adversary. We study the effect of such corruptions on global features of the
system. Among the questions we study are: How many nodes need to be controlled
in order to change the average statistics of the system in polynomial time? And
how many nodes are needed to obstruct approximate convergence of the dynamics?
  Our results can be viewed as studying the robustness of classical sampling
methods and are thus related to robust inference. The proofs connect to
classical theory of Glauber dynamics from statistical physics.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:49:34 GMT""},{""version"":""v2"",""created"":""Mon, 1 May 2023 15:39:22 GMT""}]","2023-05-02"
"2302.10842","Yi Liu","Yi Liu","DSL-Assembly: A Robust and Safe Assembly Strategy","4 pages, 8 figures",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A reinforcement learning (RL) based method that enables the robot to
accomplish the assembly-type task with safety regulations is proposed. The
overall strategy consists of grasping and assembly, and this paper mainly
considers the assembly strategy. Force feedback is used instead of visual
feedback to perceive the shape and direction of the hole in this paper.
Furthermore, since the emergency stop is triggered when the force output is too
large, a force-based dynamic safety lock (DSL) is proposed to limit the
pressing force of the robot. Finally, we train and test the robot model with a
simulator and build ablation experiments to illustrate the effectiveness of our
method. The models are independently tested 500 times in the simulator, and we
get an 88.57% success rate with a 4mm gap. These models are transferred to the
real world and deployed on a real robot. We conducted independent tests and
obtained a 79.63% success rate with a 4mm gap. Simulation environments:
https://github.com/0707yiliu/peg-in-hole-with-RL.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:49:38 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 15:18:37 GMT""}]","2023-03-15"
"2302.10843","Kuangyi Xu","Kuangyi Xu, Zachery B. Harris and M. Hassan Arbab","Polarization Imaging of Back-Scattered Terahertz Speckle Fields",,,,,"physics.optics","http://creativecommons.org/licenses/by/4.0/","  Speckle patterns observed in coherent optical imaging reflect important
characteristic information of the scattering object. To capture speckle
patterns, angular resolved or oblique illumination geometries are usually
employed in combination with Rayleigh statistical models. We present a portable
and handheld 2-channel polarization-sensitive imaging instrument to directly
resolve terahertz (THz) speckle fields in a collocated telecentric
back-scattering geometry. The polarization state of the THz light is measured
using two orthogonal photoconductive antennas and can be presented in the form
of the Stokes vectors of the THz beam upon interaction with the sample. We
report on the validation of the method in surface scattering from gold-coated
sandpapers, demonstrating a strong dependence of the polarization state on the
surface roughness and the frequency of the broadband THz illumination. We also
demonstrate non-Rayleigh first-order and second-order statistical parameters,
such as degree of polarization uniformity (DOPU) and phase difference, for
quantifying the randomness of polarization. This technique provides a fast
method for broadband THz polarimetric measurement in the field and has the
potential for detecting light depolarization in applications ranging from
biomedical imaging to non-destructive testing.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:49:54 GMT""}]","2023-02-22"
"2302.10844","Gleb Novikov","Gleb Novikov, David Steurer, Stefan Tiegel","Robust Mean Estimation Without a Mean: Dimension-Independent Error in
  Polynomial Time for Symmetric Distributions",,,,,"cs.DS cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we study the problem of robustly estimating the mean/location
parameter of distributions without moment bounds. For a large class of
distributions satisfying natural symmetry constraints we give a sequence of
algorithms that can efficiently estimate its location without incurring
dimension-dependent factors in the error. Concretely, suppose an adversary can
arbitrarily corrupt an $\varepsilon$-fraction of the observed samples. For
every $k \in \mathbb{N}$, we design an estimator using time and samples
$\tilde{O}({d^k})$ such that the dependence of the error on the corruption
level $\varepsilon$ is an additive factor of $O(\varepsilon^{1-\frac{1}{2k}})$.
The dependence on other problem parameters is also nearly optimal. Our class
contains products of arbitrary symmetric one-dimensional distributions as well
as elliptical distributions, a vast generalization of the Gaussian
distribution. Examples include product Cauchy distributions and multi-variate
$t$-distributions. In particular, even the first moment might not exist.
  We provide the first efficient algorithms for this class of distributions.
Previously, such results where only known under boundedness assumptions on the
moments of the distribution and in particular, are provably impossible in the
absence of symmetry [KSS18, CTBJ22]. For the class of distributions we
consider, all previous estimators either require exponential time or incur
error depending on the dimension. Our algorithms are based on a generalization
of the filtering technique [DK22]. We show how this machinery can be combined
with Huber-loss-based approach to work with projections of the noise. Moreover,
we show how sum-of-squares proofs can be used to obtain algorithmic guarantees
even for distributions without first moment. We believe that this approach may
find other application in future works.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:52:23 GMT""}]","2023-02-22"
"2302.10845","Baihan Lin","Baihan Lin, Stefan Zecevic, Djallel Bouneffouf, Guillermo Cecchi","TherapyView: Visualizing Therapy Sessions with Temporal Topic Modeling
  and AI-Generated Arts","This work extends our prior empirical work on topic modeling
  (arxiv:2204.10189) to now provide an interpretable and interactive data
  visualization platform with AI-generated artworks as a concrete user scenario
  for therapists",,,,"cs.CL cs.AI cs.HC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the TherapyView, a demonstration system to help therapists
visualize the dynamic contents of past treatment sessions, enabled by the
state-of-the-art neural topic modeling techniques to analyze the topical
tendencies of various psychiatric conditions and deep learning-based image
generation engine to provide a visual summary. The system incorporates temporal
modeling to provide a time-series representation of topic similarities at a
turn-level resolution and AI-generated artworks given the dialogue segments to
provide a concise representations of the contents covered in the session,
offering interpretable insights for therapists to optimize their strategies and
enhance the effectiveness of psychotherapy. This system provides a proof of
concept of AI-augmented therapy tools with e in-depth understanding of the
patient's mental state and enabling more effective treatment.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:53:45 GMT""}]","2023-02-22"
"2302.10846","Khaled Mustafa","Khaled A. Mustafa, Oscar de Groot, Xinwei Wang, Jens Kober, and Javier
  Alonso-Mora","Probabilistic Risk Assessment for Chance-Constrained Collision Avoidance
  in Uncertain Dynamic Environments","Accepted for presentation at the 2023 IEEE International Conference
  on Robotics and Automation (ICRA)",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Balancing safety and efficiency when planning in crowded scenarios with
uncertain dynamics is challenging where it is imperative to accomplish the
robot's mission without incurring any safety violations. Typically, chance
constraints are incorporated into the planning problem to provide probabilistic
safety guarantees by imposing an upper bound on the collision probability of
the planned trajectory. Yet, this results in overly conservative behavior on
the grounds that the gap between the obtained risk and the specified upper
limit is not explicitly restricted. To address this issue, we propose a
real-time capable approach to quantify the risk associated with planned
trajectories obtained from multiple probabilistic planners, running in
parallel, with different upper bounds of the acceptable risk level. Based on
the evaluated risk, the least conservative plan is selected provided that its
associated risk is below a specified threshold. In such a way, the proposed
approach provides probabilistic safety guarantees by attaining a closer bound
to the specified risk, while being applicable to generic uncertainties of
moving obstacles. We demonstrate the efficiency of our proposed approach, by
improving the performance of a state-of-the-art probabilistic planner, in
simulations and experiments using a mobile robot in an environment shared with
humans.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:54:25 GMT""}]","2023-02-22"
"2302.10847","Mikhail Anokhin","Mikhail Anokhin","There Are No Post-Quantum Weakly Pseudo-Free Families in Any Nontrivial
  Variety of Expanded Groups","25 pages, 1 figure",,,,"cs.CR cs.CC","http://creativecommons.org/licenses/by/4.0/","  Let $\Omega$ be a finite set of finitary operation symbols and let $\mathfrak
V$ be a nontrivial variety of $\Omega$-algebras. Assume that for some set
$\Gamma\subseteq\Omega$ of group operation symbols, all $\Omega$-algebras in
$\mathfrak V$ are groups under the operations associated with the symbols in
$\Gamma$. In other words, $\mathfrak V$ is assumed to be a nontrivial variety
of expanded groups. In particular, $\mathfrak V$ can be a nontrivial variety of
groups or rings. Our main result is that there are no post-quantum weakly
pseudo-free families in $\mathfrak V$, even in the worst-case setting and/or
the black-box model. In this paper, we restrict ourselves to families
$(H_d\mathbin|d\in D)$ of computational and black-box $\Omega$-algebras (where
$D\subseteq\{0,1\}^*$) such that for every $d\in D$, each element of $H_d$ is
represented by a unique bit string of length polynomial in the length of $d$.
We use straight-line programs to represent nontrivial relations between
elements of $\Omega$-algebras in our main result. Note that under certain
conditions, this result depends on the classification of finite simple groups.
Also, we define and study some types of weak pseudo-freeness for families of
computational and black-box $\Omega$-algebras.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:55:42 GMT""}]","2023-02-22"
"2302.10848","Stefan Boettcher","Stefan Boettcher (Emory U)","Deep reinforced learning heuristic tested on spin-glass ground states:
  The larger picture","3 pages, 2 figures, comment on arXiv:2109.14411, related information
  can be found at https://physics.emory.edu/faculty/boettcher/",,,,"cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Changjun Fan et al. [Nature Communications
https://doi.org/10.1038/s41467-023-36363-w (2023)], the authors present a deep
reinforced learning approach to augment combinatorial optimization heuristics.
In particular, they present results for several spin glass ground state
problems, for which instances on non-planar networks are generally NP-hard, in
comparison with several Monte Carlo based methods, such as simulated annealing
(SA) or parallel tempering (PT). Indeed, those results demonstrate that the
reinforced learning improves the results over those obtained with SA or PT, or
at least allows for reduced runtimes for the heuristics before results of
comparable quality have been obtained relative to those other methods. To
facilitate the conclusion that their method is ''superior'', the authors pursue
two basic strategies: (1) A commercial GUROBI solver is called on to procure a
sample of exact ground states as a testbed to compare with, and (2) a
head-to-head comparison between the heuristics is given for a sample of larger
instances where exact ground states are hard to ascertain. Here, we put these
studies into a larger context, showing that the claimed superiority is at best
marginal for smaller samples and becomes essentially irrelevant with respect to
any sensible approximation of true ground states in the larger samples. For
example, this method becomes irrelevant as a means to determine stiffness
exponents $\theta$ in $d>2$, as mentioned by the authors, where the problem is
not only NP-hard but requires the subtraction of two almost equal ground-state
energies and systemic errors in each of $\approx 1\%$ found here are
unacceptable. This larger picture on the method arises from a straightforward
finite-size corrections study over the spin glass ensembles the authors employ,
using data that has been available for decades.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:59:10 GMT""}]","2023-02-22"
"2302.10849","Carl Schmidt","Carl Schmidt, Mikhail Sharov, Katherine de Kleer, Nick Schneider, Imke
  de Pater, Phillip H. Phipps, Albert Conrad, Luke Moore, Paul Withers, John
  Spencer, Jeff Morgenthaler, Ilya Ilyin, Klaus Strassmeier, Christian Veillet,
  John Hill, and Mike Brown","Io's Optical Aurorae in Jupiter's Shadow",,"The Planetary Science Journal, February 2023, Vol. 4, 36","10.3847/PSJ/ac85b0",,"astro-ph.EP physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Decline and recovery timescales surrounding eclipse are indicative of the
controlling physical processes in Io's atmosphere. Recent studies have
established that the majority of Io's molecular atmosphere, SO2 and SO,
condenses during its passage through Jupiter's shadow. The eclipse response of
Io's atomic atmosphere is less certain, having been characterized solely by
ultraviolet aurorae. Here we explore the response of optical aurorae for the
first time. We find oxygen to be indifferent to the changing illumination, with
[O I] brightness merely tracking the plasma density at Io's position in the
torus. In shadow, line ratios confirm sparse SO2 coverage relative to O, since
their collisions would otherwise quench the emission. Io's sodium aurora mostly
disappears in eclipse and e-folding timescales, for decline and recovery differ
sharply: ~10 minutes at ingress and nearly 2 hr at egress. Only ion chemistry
can produce such a disparity; Io's molecular ionosphere is weaker at egress due
to rapid recombination. Interruption of a NaCl+ photochemical pathway best
explains Na behavior surrounding eclipse, implying that the role of electron
impact ionization is minor relative to photons. Auroral emission is also
evident from potassium, confirming K as the major source of far red emissions
seen with spacecraft imaging at Jupiter. In all cases, direct electron impact
on atomic gas is sufficient to explain the brightness without invoking
significant dissociative excitation of molecules. Surprisingly, the nonresponse
of O and rapid depletion of Na is opposite the temporal behavior of their SO2
and NaCl parent molecules during Io's eclipse phase.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:00:28 GMT""}]","2023-02-22"
"2302.10850","Dhawal Gupta","Dhawal Gupta, Yinlam Chow, Mohammad Ghavamzadeh, Craig Boutilier","Offline Reinforcement Learning for Mixture-of-Expert Dialogue Management",,,,,"cs.LG cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning (RL) has shown great promise for developing dialogue
management (DM) agents that are non-myopic, conduct rich conversations, and
maximize overall user satisfaction. Despite recent developments in RL and
language models (LMs), using RL to power conversational chatbots remains
challenging, in part because RL requires online exploration to learn
effectively, whereas collecting novel human-bot interactions can be expensive
and unsafe. This issue is exacerbated by the combinatorial action spaces facing
these algorithms, as most LM agents generate responses at the word level. We
develop a variety of RL algorithms, specialized to dialogue planning, that
leverage recent Mixture-of-Expert Language Models (MoE-LMs) -- models that
capture diverse semantics, generate utterances reflecting different intents,
and are amenable for multi-turn DM. By exploiting MoE-LM structure, our methods
significantly reduce the size of the action space and improve the efficacy of
RL-based DM.
  We evaluate our methods in open-domain dialogue to demonstrate their
effectiveness w.r.t.\ the diversity of intent in generated utterances and
overall DM performance.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:02:20 GMT""}]","2023-02-22"
"2302.10851","Sambaran Banerjee Dr.","Sambaran Banerjee, Aleksandra Olejak, Krzysztof Belczynski","Symmetry breaking in merging binary black holes from young massive
  clusters and isolated binaries","13 pages including Appendix. 4 figures, 2 tables. Submitted to AAS
  Journals. Comments are welcome",,,,"astro-ph.HE astro-ph.GA astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Properties of the to-date-observed binary black hole (BBH) merger events
suggest a preference towards spin-orbit aligned mergers. Naturally, this has
caused widespread interest and speculations regrading implications on various
merger formation channels. Here we show that (i) not only the BBH-merger
population from isolated binaries, but also (ii) BBH population formed in young
massive clusters (YMC) would possess an asymmetry in favour of aligned mergers,
in the distribution of the events' effective spin parameter ($\chi_{\rm eff}$).
In our analysis, we utilize BBH-merger outcomes from state-of-the-art N-body
evolutionary models of YMCs and isolated binary population synthesis. We
incorporate, for the first time in such an analysis, misalignments due to both
natal kicks and dynamical encounters. The YMC $\chi_{\rm eff}$ distribution has
a mean (an anti-aligned merger fraction) of $\langle\chi_{\rm
eff}\rangle\leq0.05$ ($f_X-\approx40\%$) which is smaller (larger) than but
consistent with the observed asymmetry of $\langle\chi_{\rm
eff}\rangle\approx0.06$ ($f_X-\approx28\%$). In contrast, isolated binaries
alone tend to produce a much stronger asymmetry; for the tested physical
models, $\langle\chi_{\rm eff}\rangle\approx0.25$ and $f_X-\lesssim7\%$.
Although the YMC $\chi_{\rm eff}$ distribution is more similar to the observed
counterpart, none of the channels correctly reproduce the observed
distribution. Our results suggest that further extensive model explorations for
both isolated-binary and dynamical channels as well as better observational
constraints are necessary to understand the physics of 'the symmetry breaking'
of the BBH-merger population.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:03:02 GMT""}]","2023-02-22"
"2302.10852","Dennis Huang","T. F. Schweizer, U. Niemann, X. Que, Q. He, L. Zhou, M. Kim, H.
  Takagi, D. Huang","Epitaxial growth and scanning tunneling microscopy of LiV$_2$O$_4$ thin
  films on SrTiO$_3$(111)","6 pages, 4 figures + SM","APL Mater. 11, 021109 (2023)","10.1063/5.0140576",,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  LiV$_2$O$_4$ is a mixed-valent spinel oxide and one of a few transition-metal
compounds to host a heavy fermion phase at low temperatures. While numerous
experimental studies have attempted to elucidate how its 3$d$ electrons undergo
giant mass renormalization, spectroscopic probes that may provide crucial
hints, such as scanning tunneling microscopy (STM), remain to be applied. A
prerequisite is atomically flat and pristine surfaces, which, in the case of
LiV$_2$O$_4$, are difficult to obtain by cleavage of small, three-dimensional
crystals. We report the epitaxial growth of LiV$_2$O$_4$ thin films with
bulklike properties on SrTiO$_3$(111) via pulsed laser deposition and stable
STM imaging of the LiV$_2$O$_4$(111) surface. The as-grown films were
transferred $ex$ $situ$ to a room-temperature STM, where subsequent annealing
with optional sputtering in ultrahigh vacuum enabled compact islands with
smooth surfaces and a hexagonal 1$\times$1 atomic lattice to be resolved. Our
STM measurements provide insights into growth mechanisms of LiV$_2$O$_4$ on
SrTiO$_3$(111), as well as demonstrate the feasibility of performing
surface-sensitive measurements of this heavy fermion compound.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:03:10 GMT""}]","2023-02-22"
"2302.10853","F Shojai","R. Hassannejad, A. Sadeghi and F. Shojai","On the gravitational collapse in 4-dimensional Einstein-Gauss-Bonnet
  gravity","9 pages, 2 figures","Classical and Quantum Gravity, 2023","10.1088/1361-6382/acbd81",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we treat 4-dimensional Einstein-Gauss-Bonnet gravity as
general relativity with an effective stress-energy tensor. We will study the
modified Oppenheimer-Snyder-Datt model of the gravitational collapse of a star
in a 4-dimensional Einstein-Gauss-Bonnet black hole. The inside geometry of the
star is described by the spatially flat Friedmann-Robertson-Walker metric and
the matter is distributed uniformly without any pre-assumption about its
equation of state. The exterior Einstein-Gauss-Bonnet black hole is smoothly
matched to the interior geometry without the requirement of any thin shell.
This gives the energy density, pressure, and the equation of state of
collapsing matter. At the end, we study the time evolution of event and
apparent horizons.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:07:36 GMT""}]","2023-02-22"
"2302.10854","Andrii Sotnikov","Valeriia Bilokon, Elvira Bilokon, Mari Carmen Ba\~nuls, Agnieszka
  Cichy, and Andrii Sotnikov","Many-body correlations in one-dimensional optical lattices with
  alkaline-earth(-like) atoms","8 pages, 5 figures",,,,"cond-mat.quant-gas cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the rich nature of correlations in the ground state of ultracold
atoms trapped in state-dependent optical lattices. In particular, we consider
interacting fermionic ytterbium or strontium atoms, realizing a two-orbital
Hubbard model with two spin components. We analyze the model in one-dimensional
setting with the experimentally relevant hierarchy of tunneling and interaction
amplitudes by means of exact diagonalization and matrix product states
approaches, and study the correlation functions in density, spin, and orbital
sectors as functions of variable densities of atoms in the ground and
metastable excited states. We show that in certain ranges of densities these
atomic systems demonstrate strong density-wave, ferro- and antiferromagnetic,
as well as antiferroorbital correlations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:09:12 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 16:48:45 GMT""}]","2023-03-07"
"2302.10855","Adam Shaw","Adam L. Shaw, Pascal Scholl, Ran Finklestein, Ivaylo S. Madjarov,
  Brandon Grinkemeyer, and Manuel Endres","Dark-state enhanced loading of an optical tweezer array",,"Phys. Rev. Lett. 130, 193402 (2023)","10.1103/PhysRevLett.130.193402",,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutral atoms and molecules trapped in optical tweezers have become a
prevalent resource for quantum simulation, computation, and metrology. However,
the maximum achievable system sizes of such arrays are often limited by the
stochastic nature of loading into optical tweezers, with a typical loading
probability of only 50%. Here we present a species-agnostic method for
dark-state enhanced loading (DSEL) based on real-time feedback, long-lived
shelving states, and iterated array reloading. We demonstrate this technique
with a 95-tweezer array of $^{88}$Sr atoms, achieving a maximum loading
probability of 84.02(4)% and a maximum array size of 91 atoms in one dimension.
Our protocol is complementary to, and compatible with, existing schemes for
enhanced loading based on direct control over light-assisted collisions, and we
predict it can enable close-to-unity filling for arrays of atoms or molecules.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:10:29 GMT""}]","2023-05-31"
"2302.10856","Amifa Raj","Michael D. Ekstrand, Graham McDonald, Amifa Raj, Isaac Johnson","Overview of the TREC 2021 Fair Ranking Track","Published in The Thirtieth Text REtrieval Conference Proceedings
  (TREC 2021). arXiv admin note: substantial text overlap with arXiv:2302.05558",,,,"cs.IR","http://creativecommons.org/licenses/by-sa/4.0/","  The TREC Fair Ranking Track aims to provide a platform for participants to
develop and evaluate novel retrieval algorithms that can provide a fair
exposure to a mixture of demographics or attributes, such as ethnicity, that
are represented by relevant documents in response to a search query. For
example, particular demographics or attributes can be represented by the
documents' topical content or authors. The 2021 Fair Ranking Track adopted a
resource allocation task. The task focused on supporting Wikipedia editors who
are looking to improve the encyclopedia's coverage of topics under the purview
of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for
Wikipedia documents that are in need of editing to improve the quality of the
article. The 2021 Fair Ranking track aimed to ensure that documents that are
about, or somehow represent, certain protected characteristics receive a fair
exposure to the Wikipedia editors, so that the documents have an fair
opportunity of being improved and, therefore, be well-represented in Wikipedia.
The under-representation of particular protected characteristics in Wikipedia
can result in systematic biases that can have a negative human, social, and
economic impact, particularly for disadvantaged or protected societal groups.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:13:06 GMT""}]","2023-02-22"
"2302.10857","Jason Miller","Konstantinos Kavvadias, Jason Miller, Lukas Schoug","Conformal removability of non-simple Schramm-Loewner evolutions","71 pages, 6 figures",,,,"math.PR math-ph math.CV math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Schramm-Loewner evolution (SLE$_\kappa$) for $\kappa \in
(4,8)$, which is the regime that the curve is self-intersecting but not
space-filling. We let ${\mathcal K}$ be the set of $\kappa \in (4,8)$ for which
the adjacency graph of connected components of the complement of an
SLE$_\kappa$ is a.s. connected, meaning that for every pair of complementary
components $U, V$ there exist complementary components $U_1,\ldots,U_n$ with
$U_1 = U$, $U_n = V$, and $\partial U_i \cap \partial U_{i+1} \neq \emptyset$
for each $1 \leq i \leq n-1$. We show that the range of an SLE$_\kappa$ for
$\kappa \in {\mathcal K}$ is a.s. conformally removable, which answers a
question of Sheffield. As a step in the proof, we construct the canonical
conformally covariant volume measure on the cut points of an SLE$_\kappa$ for
$\kappa \in (4,8)$ and establish a precise upper bound on the measure that it
assigns to any Borel set in terms of its diameter.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:14:47 GMT""}]","2023-02-22"
"2302.10858","Friedemann Kemm","Friedemann Kemm","Why Majority Judgement is not yet the solution for political elections,
  but can help finding it",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Like many other voting systems, Majority Judgement suffers from the
weaknesses of the underlying mathematical model: Elections as problem of choice
or ranking. We show how the model can be enhanced to take into account the
complete process starting from the whole set of persons having passive
electoral rights and even the aspect of reelection. By a new view on
abstentions from voting and an adaption of Majority Judgement with three
grades, we are able to describe a complete process for an election that can be
easily put into legislation and sets suitable incentives for politicians who
want to be reelected.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:15:39 GMT""},{""version"":""v2"",""created"":""Fri, 24 Mar 2023 10:20:02 GMT""}]","2023-03-27"
"2302.10859","Rafsanjany Kushol","Rafsanjany Kushol, Collin C. Luk, Avyarthana Dey, Michael Benatar,
  Hannah Briemberg, Annie Dionne, Nicolas Dupr\'e, Richard Frayne, Angela
  Genge, Summer Gibson, Simon J. Graham, Lawrence Korngut, Peter Seres, Robert
  C. Welsh, Alan Wilman, Lorne Zinman, Sanjay Kalra, Yee-Hong Yang","SF2Former: Amyotrophic Lateral Sclerosis Identification From
  Multi-center MRI Data Using Spatial and Frequency Fusion Transformer","17 pages, 8 figures",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Amyotrophic Lateral Sclerosis (ALS) is a complex neurodegenerative disorder
involving motor neuron degeneration. Significant research has begun to
establish brain magnetic resonance imaging (MRI) as a potential biomarker to
diagnose and monitor the state of the disease. Deep learning has turned into a
prominent class of machine learning programs in computer vision and has been
successfully employed to solve diverse medical image analysis tasks. However,
deep learning-based methods applied to neuroimaging have not achieved superior
performance in ALS patients classification from healthy controls due to having
insignificant structural changes correlated with pathological features.
Therefore, the critical challenge in deep models is to determine useful
discriminative features with limited training data. By exploiting the
long-range relationship of image features, this study introduces a framework
named SF2Former that leverages vision transformer architecture's power to
distinguish the ALS subjects from the control group. To further improve the
network's performance, spatial and frequency domain information are combined
because MRI scans are captured in the frequency domain before being converted
to the spatial domain. The proposed framework is trained with a set of
consecutive coronal 2D slices, which uses the pre-trained weights on ImageNet
by leveraging transfer learning. Finally, a majority voting scheme has been
employed to those coronal slices of a particular subject to produce the final
classification decision. Our proposed architecture has been thoroughly assessed
with multi-modal neuroimaging data using two well-organized versions of the
Canadian ALS Neuroimaging Consortium (CALSNIC) multi-center datasets. The
experimental results demonstrate the superiority of our proposed strategy in
terms of classification accuracy compared with several popular deep
learning-based techniques.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:16:20 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 20:33:45 GMT""}]","2023-03-02"
"2302.10860","Yangxin Fan","Yangxin Fan, Xuanji Yu, Raymond Wieser, David Meakin, Avishai Shaton,
  Jean-Nicolas Jaubert, Robert Flottemesch, Michael Howell, Jennifer Braid,
  Laura S.Bruckman, Roger French, Yinghui Wu","Spatio-Temporal Denoising Graph Autoencoders with Data Augmentation for
  Photovoltaic Timeseries Data Imputation","ACM SIGMOD Conference on Management of Data (SIGMOD)",,,,"cs.LG stat.AP","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The integration of the global Photovoltaic (PV) market with real time
data-loggers has enabled large scale PV data analytical pipelines for power
forecasting and long-term reliability assessment of PV fleets. Nevertheless,
the performance of PV data analysis heavily depends on the quality of PV
timeseries data. This paper proposes a novel Spatio-Temporal Denoising Graph
Autoencoder (STD-GAE) framework to impute missing PV Power Data. STD-GAE
exploits temporal correlation, spatial coherence, and value dependencies from
domain knowledge to recover missing data. Experimental results show that
STD-GAE can achieve a gain of 43.14% in imputation accuracy and remains less
sensitive to missing rate, different seasons, and missing scenarios, compared
with state-of-the-art data imputation methods such as MIDA and LRTC-TNN.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:16:52 GMT""}]","2023-02-22"
"2302.10861","Martina Amongero","Martina Amongero, Gianluca Mastrantonio, Stefano De Luca, Mauro
  Gasparini","Estimating the optimal time to perform a PET-PSMA exam in
  prostatectomized patients based on data from clinical practice",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prostatectomized patients are at risk of resurgence: this is the reason why,
during a follow-up period, they are monitored for PSA growth, an indicator of
tumor progression. The presence of tumors can be evaluated with an expensive
exam, called PET-PSMA (Positron Emission Tomography with Prostate-Specific
Membrane Antigen). But, to optimize the benefit/risk ratio, patients should be
referred to this exam only when the evidence is strong. The aim is to estimate
the optimal time to recommend the exam, based on patients' history and
collected data. We build a Hierarchical Bayesian model that describes, jointly,
the PSA growth curve and the probability of a positive PET-PSMA. Our proposal
is to process all information about the patient in order to give an informed
estimate of the optimal time.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:17:52 GMT""}]","2023-02-22"
"2302.10862","Anthony Polloreno","Anthony M. Polloreno and Reuben R. W. Wang and Nikolas A. Tezak","A Note on Noisy Reservoir Computation",,,,,"cs.LG cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this note we extend the definition of the Information Processing Capacity
(IPC) by Dambre et al [1] to include the effects of stochastic reservoir
dynamics. We quantify the degradation of the IPC in the presence of this noise.
[1] Dambre et al. Scientific Reports 2, 514, (2012)
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:20:50 GMT""}]","2023-02-22"
"2302.10863","Eric Zhao","Nika Haghtalab, Michael I. Jordan, and Eric Zhao","A Unifying Perspective on Multi-Calibration: Unleashing Game Dynamics
  for Multi-Objective Learning","25 pages. Authors are ordered alphabetically",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  We provide a unifying framework for the design and analysis of
multi-calibrated and moment-multi-calibrated predictors. Placing the
multi-calibration problem in the general setting of \emph{multi-objective
learning} -- where learning guarantees must hold simultaneously over a set of
distributions and loss functions -- we exploit connections to game dynamics to
obtain state-of-the-art guarantees for a diverse set of multi-calibration
learning problems. In addition to shedding light on existing multi-calibration
guarantees, and greatly simplifying their analysis, our approach yields a
$1/\epsilon^2$ improvement in the number of oracle calls compared to the
state-of-the-art algorithm of Jung et al. 2021 for learning deterministic
moment-calibrated predictors and an exponential improvement in $k$ compared to
the state-of-the-art algorithm of Gopalan et al. 2022 for learning a $k$-class
multi-calibrated predictor. Beyond multi-calibration, we use these game
dynamics to address existing and emerging considerations in the study of group
fairness and multi-distribution learning.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:24:17 GMT""}]","2023-02-22"
"2302.10864","Jishnudeep Kar","Jishnudeep Kar, He Bai, Aranya Chakrabortty","Reinforcement Learning-based Control of Nonlinear Systems using Carleman
  Approximation: Structured and Unstructured Designs","18 pages, extended version, Automatica paper",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop data-driven reinforcement learning (RL) control designs for
input-affine nonlinear systems. We use Carleman linearization to express the
state-space representation of the nonlinear dynamical model in the Carleman
space, and develop a real-time algorithm that can learn nonlinear
state-feedback controllers using state and input measurements in the
infinite-dimensional Carleman space. Thereafter, we study the practicality of
having a finite-order truncation of the control signal, followed by its
closed-loop stability analysis. Finally, we develop two additional designs that
can learn structured as well as sparse representations of the RL-based
nonlinear controller, and provide theoretical conditions for ensuring their
closed-loop stability. We present numerical examples to show how our proposed
method generates closed-loop responses that are close to the optimal
performance of the nonlinear plant. We also compare our designs to other
data-driven nonlinear RL control methods such as those based on neural
networks, and illustrate their relative advantages and drawbacks.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:25:08 GMT""}]","2023-02-22"
"2302.10865","Gergely Ambrus","Gergely Ambrus, Rainie Bozzai","Colorful Vector Balancing","20 pages, 1 figure",,,,"math.MG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We extend classical estimates for the vector balancing constant of
$\mathbb{R}^d$ equipped with the Euclidean and the maximum norms proved in the
1980's by showing that for $p =2$ and $p=\infty$, given vector families $V_1,
\ldots, V_n \subset B_p^d$ with $0 \in \sum_{i=1}^n \mathrm{conv} \, V_i$, one
may select vectors $v_i \in V_i$ with \[ \| v_1 + \ldots + v_n \|_2 \leq
\sqrt{d} \] for $p=2$, and \[ \| v_1 + \ldots + v_n \|_\infty \leq O(\sqrt{d})
\] for $p = \infty$. These bounds are sharp and asymptotically sharp,
respectively, for $n \geq d$, and they significantly strengthen the estimate of
B\'ar\'any and Grinberg for general norms on $\mathbb{R}^d$. The proofs combine
linear algebraic and probabilistic methods with a Gaussian random walk
argument.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:26:38 GMT""}]","2023-02-22"
"2302.10866","Michael Poli","Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y. Fu, Tri Dao,
  Stephen Baccus, Yoshua Bengio, Stefano Ermon, Christopher R\'e","Hyena Hierarchy: Towards Larger Convolutional Language Models","Additional details",,,,"cs.LG cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent advances in deep learning have relied heavily on the use of large
Transformers due to their ability to learn at scale. However, the core building
block of Transformers, the attention operator, exhibits quadratic cost in
sequence length, limiting the amount of context accessible. Existing
subquadratic methods based on low-rank and sparse approximations need to be
combined with dense attention layers to match Transformers, indicating a gap in
capability. In this work, we propose Hyena, a subquadratic drop-in replacement
for attention constructed by interleaving implicitly parametrized long
convolutions and data-controlled gating. In recall and reasoning tasks on
sequences of thousands to hundreds of thousands of tokens, Hyena improves
accuracy by more than 50 points over operators relying on state-spaces and
other implicit and explicit methods, matching attention-based models. We set a
new state-of-the-art for dense-attention-free architectures on language
modeling in standard datasets (WikiText103 and The Pile), reaching Transformer
quality with a 20% reduction in training compute required at sequence length
2K. Hyena operators are twice as fast as highly optimized attention at sequence
length 8K, and 100x faster at sequence length 64K.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:29:25 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 01:26:15 GMT""},{""version"":""v3"",""created"":""Wed, 19 Apr 2023 20:08:39 GMT""}]","2023-04-21"
"2302.10867","Takuma Hayashi","Takuma Hayashi","Algebraic approach to contraction families","The arbitrary base change property of the contraction algebras for
  smooth algebras was proved (Theorem 2.17 (1)). The connectivity assumption of
  $G$ in Theorem 1.8 was removed (see also Lemma 2.20). A technical condition
  in Theorem 4.25 was simplified",,,,"math.AG math.AC math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we give a purely algebraic approach to the contraction group
scheme predicted by Bernstein--Higson--Subag and constructed by
Barbasch--Higson--Subag. We also compare quotient schemes of contraction group
schemes with other related schemes, equipped with actions of contraction group
schemes in the cases of symmetric and $\theta$-stable parabolic subgroups.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:29:55 GMT""},{""version"":""v2"",""created"":""Sun, 19 Mar 2023 15:10:00 GMT""}]","2023-03-21"
"2302.10868","Yi-Xian Chen","Yi-Xian Chen, Yan-Fei Jiang, Jeremy Goodman and Eve C. Ostriker","3D Radiation Hydrodynamic Simulations of Gravitational Instability in
  AGN Accretion Disks: Effects of Radiation Pressure","26 pages, 19 figures, ApJ in Press",,"10.3847/1538-4357/acc023",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform 3D radiation hydrodynamic local shearing box simulations to study
the outcome of gravitational instability (GI) in optically thick Active
Galactic Nuclei (AGN) accretion disks. GI develops when the Toomre parameter QT
\leq 1, and may lead to turbulent heating that balances radiative cooling.
However, when radiative cooling is too efficient, the disk may undergo runaway
gravitational fragmentation. In the fully gas-pressure-dominated case, we
confirm the classical result that such a thermal balance holds when the
Shakura-Sunyaev viscosity parameter (alpha) due to the gravitationally-driven
turbulence is \sim 0.2, corresponding to dimensionless cooling times Omega
tcool \sim 5. As the fraction of support by radiation pressure increases, the
disk becomes more prone to fragmentation, with a reduced (increased) critical
value of alpha (omega tcool). The effect is already significant when the
radiation pressure exceeds 10% of the gas pressure, while fully
radiation-pressure-dominated disks fragment at Omega tcool <50 . The latter
translates to a maximum turbulence level alpha<0.02, comparable to that
generated by Magnetorotational Instability (MRI). Our results suggest that
gravitationally unstable (QT \sim 1) outer regions of AGN disks with
significant radiation pressure (likely for high/near- Eddington accretion
rates) should always fragment into stars, and perhaps black holes.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:31:54 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 12:25:37 GMT""}]","2023-05-24"
"2302.10869","Elias Katsoulis","Evgenios Kakariadis, Elias Katsoulis and Xin Li","Stable isomorphisms of operator algebras","17 pages",,,,"math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\A$ and $\B$ be operator algebras with $c_0$-isomorphic diagonals and
let $\K$ denote the compact operators. We show that if $\A\otimes\K$ and
$\B\otimes\K$ are isometrically isomorphic, then $\A$ and $\B$ are
isometrically isomorphic. If the algebras $\A$ and $\B$ satisfy an extra
analyticity condition a similar result holds with $\K$ being replaced by any
operator algebra containing the compact operators. For non-selfadjoint graph
algebras this implies that the graph is a complete invariant for various types
of isomorphisms, including stable isomorphisms, thus strengthening a recent
result of Dor-On, Eilers and Geffen. Similar results are proven for algebras
whose diagonals satisfy cancellation and have $K_0$-groups isomorphic to
$\bbZ$. This has implications in the study of stable isomorphisms between
various semicrossed products.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:33:23 GMT""}]","2023-02-22"
"2302.10870","Nikhil Vyas","Nikhil Vyas, Sham Kakade, Boaz Barak","Provable Copyright Protection for Generative Models",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a growing concern that learned conditional generative models may
output samples that are substantially similar to some copyrighted data $C$ that
was in their training set. We give a formal definition of $\textit{near
access-freeness (NAF)}$ and prove bounds on the probability that a model
satisfying this definition outputs a sample similar to $C$, even if $C$ is
included in its training set. Roughly speaking, a generative model $p$ is
$\textit{$k$-NAF}$ if for every potentially copyrighted data $C$, the output of
$p$ diverges by at most $k$-bits from the output of a model $q$ that
$\textit{did not access $C$ at all}$. We also give generative model learning
algorithms, which efficiently modify the original generative model learning
algorithm in a black box manner, that output generative models with strong
bounds on the probability of sampling protected content. Furthermore, we
provide promising experiments for both language (transformers) and image
(diffusion) generative models, showing minimal degradation in output quality
while ensuring strong protections against sampling protected content.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:34:51 GMT""}]","2023-02-22"
"2302.10871","Biao Zhang","Biao Zhang and Barry Haddow and Rico Sennrich","Efficient CTC Regularization via Coarse Labels for End-to-End Speech
  Translation","EACL 2023",,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For end-to-end speech translation, regularizing the encoder with the
Connectionist Temporal Classification (CTC) objective using the source
transcript or target translation as labels can greatly improve quality metrics.
However, CTC demands an extra prediction layer over the vocabulary space,
bringing in nonnegligible model parameters and computational overheads,
although this layer is typically not used for inference. In this paper, we
re-examine the need for genuine vocabulary labels for CTC for regularization
and explore strategies to reduce the CTC label space, targeting improved
efficiency without quality degradation. We propose coarse labeling for CTC
(CoLaCTC), which merges vocabulary labels via simple heuristic rules, such as
using truncation, division or modulo (MOD) operations. Despite its simplicity,
our experiments on 4 source and 8 target languages show that CoLaCTC with MOD
particularly can compress the label space aggressively to 256 and even further,
gaining training efficiency (1.18x ~ 1.77x speedup depending on the original
vocabulary size) yet still delivering comparable or better performance than the
CTC baseline. We also show that CoLaCTC successfully generalizes to CTC
regularization regardless of using transcript or translation for labeling.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:38:41 GMT""}]","2023-02-22"
"2302.10872","Samuel Hsia","Samuel Hsia, Udit Gupta, Bilge Acun, Newsha Ardalani, Pan Zhong,
  Gu-Yeon Wei, David Brooks, Carole-Jean Wu","MP-Rec: Hardware-Software Co-Design to Enable Multi-Path Recommendation",,,,,"cs.AR cs.IR cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep learning recommendation systems serve personalized content under diverse
tail-latency targets and input-query loads. In order to do so, state-of-the-art
recommendation models rely on terabyte-scale embedding tables to learn user
preferences over large bodies of contents. The reliance on a fixed embedding
representation of embedding tables not only imposes significant memory capacity
and bandwidth requirements but also limits the scope of compatible system
solutions. This paper challenges the assumption of fixed embedding
representations by showing how synergies between embedding representations and
hardware platforms can lead to improvements in both algorithmic- and system
performance. Based on our characterization of various embedding
representations, we propose a hybrid embedding representation that achieves
higher quality embeddings at the cost of increased memory and compute
requirements. To address the system performance challenges of the hybrid
representation, we propose MP-Rec -- a co-design technique that exploits
heterogeneity and dynamic selection of embedding representations and underlying
hardware platforms.
  On real system hardware, we demonstrate how matching custom accelerators,
i.e., GPUs, TPUs, and IPUs, with compatible embedding representations can lead
to 16.65x performance speedup. Additionally, in query-serving scenarios, MP-Rec
achieves 2.49x and 3.76x higher correct prediction throughput and 0.19% and
0.22% better model quality on a CPU-GPU system for the Kaggle and Terabyte
datasets, respectively.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:38:45 GMT""}]","2023-02-22"
"2302.10873","Pei Xu","Pei Xu, Jean-Bernard Hayet and Ioannis Karamouzas","Context-Aware Timewise VAEs for Real-Time Vehicle Trajectory Prediction",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Real-time, accurate prediction of human steering behaviors has wide
applications, from developing intelligent traffic systems to deploying
autonomous driving systems in both real and simulated worlds. In this paper, we
present ContextVAE, a context-aware approach for multi-modal vehicle trajectory
prediction. Built upon the backbone architecture of a timewise variational
autoencoder, ContextVAE employs a dual attention mechanism for observation
encoding that accounts for the environmental context information and the
dynamic agents' states in a unified way. By utilizing features extracted from
semantic maps during agent state encoding, our approach takes into account both
the social features exhibited by agents on the scene and the physical
environment constraints to generate map-compliant and socially-aware
trajectories. We perform extensive testing on the nuScenes prediction
challenge, Lyft Level 5 dataset and Waymo Open Motion Dataset to show the
effectiveness of our approach and its state-of-the-art performance. In all
tested datasets, ContextVAE models are fast to train and provide high-quality
multi-modal predictions in real-time.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:42:24 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 00:02:34 GMT""}]","2023-03-22"
"2302.10874","Snir Ben Ovadia","Snir Ben Ovadia, Federico Rodriguez-Hertz","Neutralized Local Entropy",,,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We introduce a notion of a point-wise entropy of measures (i.e local entropy)
called neutralized local entropy, and compare it with the Brin-Katok local
entropy and with the Ledrappier-Young local entropy on unstable leaves. We show
that the neutralized local entropy must coincide with the two other notions of
local entropies, and so all three quantities are equal almost everywhere.
Neutralized local entropy is computed by measuring open sets with a relatively
simple geometric description. Our proof uses a measure density lemma for Bowen
balls, and a version of a Besicovitch covering lemma for Bowen balls. In
particular this gives an elementary proof to the fact that the unstable entropy
carries all entropy.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:42:49 GMT""}]","2023-02-22"
"2302.10876","Md Ibrahim","Md. Roisul Ajom Ruku, Md. Ibrahim, A. S. M. Badrudduza, and Imran
  Shafique Ansari","Effects of Co-channel Interference on RIS Empowered Wireless Networks
  amid Multiple Eavesdropping Attempts","No",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  This letter is concerned with the secrecy performance of reconfigurable
intelligent surfaces (RIS)-aided wireless networks in the existence of multiple
interferers towards the destination. To be more precise, we analyze three
critical issues in the design of secure RIS-assisted networks: 1) How do
interferers affect the performance of secure wireless networks? 2) Which of the
two groups of eavesdroppers (i.e., colluding and non-colluding) is more severe?
3) How can RIS improve network confidentiality? To do so, we develop the
analytical expression of secrecy outage probability in closed-form, along with
asymptotic analysis at high signal-to-noise ratio regime to better understand
the impacts of different system parameters on secrecy performance. Finally, we
validate our analytical results using a computer based Monte-Carlo simulation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:48:57 GMT""}]","2023-02-22"
"2302.10877","Michele Pernice","Michele Pernice","The moduli stack of $A_r$-stable curves","The paper is one of the four papers that compose the author's PhD
  thesis. In particular, it contains Section 1.2 and Section 3.1 of
  arXiv:2211.09793. However, the first section of this paper is new and it
  provides a more detailed discussion about contractions, which helps in the
  proof of several results later in the paper. 30 pages; comments are very
  welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is the first in a series of four papers aiming to describe the
(almost integral) Chow ring of $\bar{\mathcal{M}}_3$, the moduli stack of
stable curves of genus $3$. In this paper, we introduce the moduli stack
$\tilde{\mathcal{M}}_{g,n}^r$ of $n$-pointed $A_r$-stable curves and extend
some classical results about $\bar{\mathcal{M}}_{g,n}$ to
$\tilde{\mathcal{M}}_{g,n}^r$, namely the existence of the contraction
morphism. Moreover, we describe the normalization of the locally closed
substack of $\tilde{\mathcal{M}}_{g,n}^r$ parametrizing curves with
$A_h$-singularities for a fixed $h\leq r$.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:53:13 GMT""}]","2023-02-22"
"2302.10878","Edgar Martinez-Moro","I. \'Alvarez-Barrientos, M. Borges-Quintana, M. A. Borges Trenard, E.
  Mart\'inez Moro, J. A. Ornella","Complete Gr\""obner basis for lattice codes",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work, two algorithms are developed related to lattice codes. In the
first one, an extended complete Gr\""obner basis is computed for the label code
of a lattice. This basis supports all term orderings associated with a total
degree order offering information about de label code of the lattice. The
second one is a decoding algorithm that uses an extended complete Gr\""obner
basis of the label code of the lattice for monomial reduction, this provides
all the lattice vectors that constitute candidates for the solution of the
Close Vector Problem for a given vector.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:54:16 GMT""}]","2023-02-22"
"2302.10879","Yangsibo Huang","Yangsibo Huang, Daogao Liu, Zexuan Zhong, Weijia Shi, Yin Tat Lee","$k$NN-Adapter: Efficient Domain Adaptation for Black-Box Language Models",,,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fine-tuning a language model on a new domain is standard practice for domain
adaptation. However, it can be infeasible when it comes to modern large-scale
language models such as GPT-3, which can only be accessed through APIs, making
it difficult to access the internal parameters of the model. In this paper, we
propose $k$NN-Adapter, a method to effectively adapt these black-box large
language models (LLMs) to a new domain. The $k$NN-Adapter builds on top of the
retrieval-augmented language model, and adaptively learns to interpolate the
output of the language model with retrieval results from a datastore consisting
of the target domain data. Our experiments on four different domains
demonstrate that $k$NN-Adapter significantly improves perplexity, and works
particularly well in settings with limited access to LLMs. Additionally, we
show that $k$NN-Adapter is more effective than fine-tuning when the amount of
training data is limited. We also release a dataset to encourage further study.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:54:21 GMT""}]","2023-02-22"
"2302.10881","Xuan Wei","Ken Xuan Wei, Emily Pritchett, David M. Zajac, David C. McKay, Seth
  Merkel","Characterizing non-Markovian Off-Resonant Errors in Quantum Gates","19 pages, 12 figures, comments welcome",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As quantum gates improve, it becomes increasingly difficult to characterize
the remaining errors. Here we describe a class of coherent non-Markovian errors
-- excitations due to an off-resonant drive -- that occur naturally in quantum
devices that use time-dependent fields to generate gate operations. We show how
these errors are mischaracterized using standard Quantum Computer Verification
and Validation (QCVV) techniques that rely on Markovianity and are therefore
often overlooked or assumed to be incoherent. We first demonstrate off-resonant
errors within a simple toy model of Z-gates created by the AC Stark effect,
then show how off-resonant errors manifest in all gates driven on a
fixed-frequency transmon architecture, a prominent example being incidental
cross-resonance interaction driven during single-qubit gates. Furthermore, the
same methodology can access the errors caused by two-level systems (TLS),
showing evidence of coherent, off-resonant interactions with subsystems that
are not intentional qubits. While we explore these results and their impact on
gate error for fixed-frequency devices, we note that off-resonant excitations
potentially limit any architectures that use frequency selectivity.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:55:24 GMT""}]","2023-02-22"
"2302.10882","Fangyuan Gu","Fangyuan Gu, Jie Wang, Zi-Jian Lang, Wei Ku","Quantum fluctuation of ferroelectric order in polar metals","12 pages, 6 figures in total",,,,"cond-mat.mtrl-sci quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since its discovery a decade ago, ""polar metallic phase"" has ignited
significant research interest, as it further functionalizes the switchable
electric polarization of materials with additional transport capability,
granting them great potential in next-generation electronic devices. The polar
metallic phase is an unusual metallic phase of matter containing long-range
ferroelectric (FE) order in the electronic and atomic structure. Distinct from
the typical FE insulating phase, this phase spontaneously breaks the inversion
symmetry but without global polarization. Unexpectedly, the FE order is found
to be dramatically suppressed by carriers and destroyed at moderate ~10%
carrier density. Here, we propose a general mechanism based on carrier-induced
quantum fluctuations to explain this puzzling phenomenon. Basically, the
quantum kinetic effect would drive the formation of polaronic quasi-particles
made of the carriers and their surrounding dipoles. The disruption in dipolar
directions can therefore weaken or even destroy the FE order. We demonstrate
such polaron formation and the associated FE suppression via a simple model
using exact diagonalization, perturbation, and quantum Monte Carlo approaches.
This quantum mechanism also provides an intuitive picture for many puzzling
experimental findings, thereby facilitating new designs of multifunctional FE
electronic devices augmented with quantum effects.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:58:11 GMT""}]","2023-02-22"
"2302.10883","Mahdi Ghafourian","Mahdi Ghafourian, Bilgesu Sumer, Ruben Vera-Rodriguez, Julian Fierrez,
  Ruben Tolosana, Aythami Moralez, and Els Kindt","Combining Blockchain and Biometrics: A Survey on Technical Aspects and a
  First Legal Analysis",,,,,"cs.CV cs.CR cs.DC cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Biometric recognition as a unique, hard-to-forge, and efficient way of
identification and verification has become an indispensable part of the current
digital world. The fast evolution of this technology has been a strong
incentive for integrating it into many applications. Meanwhile, blockchain, the
very attractive decentralized ledger technology, has been widely received both
by the research and industry in the past years and it is being increasingly
deployed nowadays in many different applications, such as money transfer, IoT,
healthcare, or logistics. Recently, researchers have started to speculate what
would be the pros and cons and what would be the best applications when these
two technologies cross paths. This paper provides a survey of technical
literature research on the combination of blockchain and biometrics and
includes a first legal analysis of this integration to shed light on challenges
and potentials. While this combination is still in its infancy and a growing
body of literature discusses specific blockchain applications and solutions in
an advanced technological set-up, this paper presents a holistic understanding
of blockchains applicability in the biometric sector. This study demonstrates
that combining blockchain and biometrics would be beneficial for novel
applications in biometrics such as the PKI mechanism, distributed trusted
service, and identity management. However, blockchain networks at their current
stage are not efficient and economical for real-time applications. From a legal
point of view, the allocation of accountability remains a main issue, while
other difficulties remain, such as conducting a proper Data Protection Impact
Assessment. Finally, it supplies technical and legal recommendations to reap
the benefits and mitigate the risks of the combination.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:58:32 GMT""}]","2023-02-22"
"2302.10884","Robert Schippa","Robert Schippa","Improved decoupling for the moment curve in three dimensions","15 pages",,,,"math.CA","http://creativecommons.org/licenses/by/4.0/","  By quantifying a bilinear decoupling iteration for the moment curve in three
dimensions due to Guo--Li--Yung--Zorin-Kranich, we show a logarithmic
improvement of the decoupling constant at critical exponent. Correspondingly,
we obtain a logarithmic improvement of Vinogradov's mean-value theorem in the
cubic case.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:58:33 GMT""}]","2023-02-22"
"2302.10885","Melanie Bancilhon","Melanie Bancilhon, R. Jordan Crouser, Alvitta Ottley","Communicating Intel to Decision-Makers: Toward the Integration Text and
  Charts in Reports",,,,,"cs.HC","http://creativecommons.org/licenses/by/4.0/","  Intelligence analysts' roles include analyzing reports, identifying important
information relevant to the current state of affairs, and communicating their
takeaways. These reports are then analyzed and reported to decision-makers or
translated into a presidential brief. While these tasks seem consistent across
analysts, each step differs in its content, level of detail, and format. The
purpose of this research is to gain an understanding of how consumers of
analytic products receive and interact with reports. This was accomplished via
a series of online questions to 22 experts recruited to provide input. Our
analysis provides insight into what makes analytic products effective for
decision-makers, which could improve the quality of reports produced and
alleviate common customer pain points, should recommendations be appropriately
incorporated.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:58:35 GMT""}]","2023-02-22"
"2302.10886","Sidak Pal Singh","Grigory Khromov, Sidak Pal Singh","Some Fundamental Aspects about Lipschitz Continuity of Neural Network
  Functions",,,,,"cs.LG stat.ML","http://creativecommons.org/licenses/by/4.0/","  Lipschitz continuity is a simple yet crucial functional property of any
predictive model for it lies at the core of the model's robustness,
generalisation, as well as adversarial vulnerability. Our aim is to thoroughly
investigate and characterise the Lipschitz behaviour of the functions realised
by neural networks. Thus, we carry out an empirical investigation in a range of
different settings (namely, architectures, losses, optimisers, label noise, and
more) by exhausting the limits of the simplest and the most general lower and
upper bounds. Although motivated primarily by computational hardness results,
this choice nevertheless turns out to be rather resourceful and sheds light on
several fundamental and intriguing traits of the Lipschitz continuity of neural
network functions, which we also supplement with suitable theoretical
arguments. As a highlight of this investigation, we identify a striking double
descent trend in both upper and lower bounds to the Lipschitz constant with
increasing network width -- which tightly aligns with the typical double
descent trend in the test loss. Lastly, we touch upon the seeming
(counter-intuitive) decline of the Lipschitz constant in the presence of label
noise.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:59:40 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 12:13:20 GMT""}]","2023-05-31"
"2302.10925","Nasibe Alipour rad","Somayeh Tarana, Nasibe Alipoura, Kourosh Roknia, S.Hadi Hosseinib,
  Omid Shekoofac, Hossein Safari","Effect of Geomagnetic Storms on a Power Network at Mid Latitudes",,,,,"physics.geo-ph astro-ph.EP physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar activities may disturb the geomagnetic field and impact the power grid
via geomagnetically induced currents. We study active and reactive powers as
well as the power factor of Iran's power grid transformers (230 kV and 400 kV)
and their correlations with geomagnetic disturbances indices (SYM-H < -30 nT
and sizable horizontal geomagnetic field fluctuation) from 19 March 2018 to 20
March 2020. Out of 128,627 cases with a transformer power factor of less than
0.7, we observe that 12,112 samples correlated with SYM-H. Our investigation
shows that about 4 percent of two years, the SYM-H has values less than -30 nT.
Analysis of high-performance transformers (a power factor greater than 0.7 at
95 percent of working time) shows at least a 55 percent correlation of power
factor less than 0.7 and SYM-H less than -30 nT. We observe that the
transformers' power factor of Rafsanjan-Kerman and Sarcheshmeh-Kerman (wye
connection on 230 kV side) substations decreased to less than 0.7 and
correlated with SYM-H. We show that the reactive power of the Sefidrood-Guilan
and Shahid Beheshti-Guilan transformers (wye configurations) increased
considerably on 9 January 2020 and positively correlated with SYM-H may produce
large GICs at this part of the grid. We observe that the increase in reactive
power at the Shahid Beheshti-Guilan substation correlated with the sizable
changes in the horizontal field recorded by the Jaipur station. However, more
details (temperature and current of transformers) need records to estimate the
impact of geomagnetic induction current on the power grid.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:23:46 GMT""}]","2023-02-23"
"2302.10926","Iman Masoumi","Doost Ali Mojdeh, Iman Masoumi","Edge coalitions in graphs",,,,,"math.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  An edge coalition in a graph $G=(V,E)$ consists of two disjoint sets of edges
$E_1$ and $E_2$, neither of which is an edge dominating set but whose union
$E_1\cup E_2$ is an edge dominating set. An edge coalition partition in a graph
$G$ of order $n=|V|$ and size $m$ is an edge partition $\pi=\{E_1,\cdots,E_k\}$
so that every set $E_i$ of $\pi$ either is a singleton edge dominating set, or
is not an edge dominating set but forms an edge coalition with another set
$E_j$ which is not an edge dominating set. In this paper we introduce the
concept of edge coalition and show that there exists edge coalition for some
graphs and trees. The graphs $G$ with small and size number of edge coalition
are characterized. Finally, coalition graphs of special graphs are studied.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:45:21 GMT""}]","2023-02-23"
"2302.10927","Peichao Li","Peichao Li, Muhammad Asad, Conor Horgan, Oscar MacCormac, Jonathan
  Shapey, Tom Vercauteren","Spatial gradient consistency for unsupervised learning of hyperspectral
  demosaicking: Application to surgical imaging",,"International Journal of Computer Assisted Radiology and Surgery,
  2023","10.1007/s11548-023-02865-7",,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Hyperspectral imaging has the potential to improve intraoperative decision
making if tissue characterisation is performed in real-time and with
high-resolution. Hyperspectral snapshot mosaic sensors offer a promising
approach due to their fast acquisition speed and compact size. However, a
demosaicking algorithm is required to fully recover the spatial and spectral
information of the snapshot images. Most state-of-the-art demosaicking
algorithms require ground-truth training data with paired snapshot and
high-resolution hyperspectral images, but such imagery pairs with the exact
same scene are physically impossible to acquire in intraoperative settings. In
this work, we present a fully unsupervised hyperspectral image demosaicking
algorithm which only requires exemplar snapshot images for training purposes.
We regard hyperspectral demosaicking as an ill-posed linear inverse problem
which we solve using a deep neural network. We take advantage of the spectral
correlation occurring in natural scenes to design a novel inter spectral band
regularisation term based on spatial gradient consistency. By combining our
proposed term with standard regularisation techniques and exploiting a standard
data fidelity term, we obtain an unsupervised loss function for training deep
neural networks, which allows us to achieve real-time hyperspectral image
demosaicking. Quantitative results on hyperspetral image datasets show that our
unsupervised demosaicking approach can achieve similar performance to its
supervised counter-part, and significantly outperform linear demosaicking. A
qualitative user study on real snapshot hyperspectral surgical images confirms
the results from the quantitative analysis. Our results suggest that the
proposed unsupervised algorithm can achieve promising hyperspectral
demosaicking in real-time thus advancing the suitability of the modality for
intraoperative use.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:07:14 GMT""}]","2023-03-27"
"2302.10928","Oliver Just","Oliver Just (1,2), Vimal Vijayan (1,3), Zewei Xiong (1), Stephane
  Goriely (4), Theodoros Soultanis (1), Andreas Bauswein (1,5), J\'er\^ome
  Guilet (6), Hans-Thomas Janka (7), Gabriel Mart\'inez-Pinedo (1,5,8) ((1) GSI
  Darmstadt, (2) ABBL RIKEN, (3) Univ. Heidelberg, (4) ULB Brussels, (5) HFHF
  Darmstadt, (6) Univ. Paris-Saclay, (7) MPA Garching, (8) IKP Darmstadt)","End-to-end kilonova models of neutron-star mergers with delayed
  black-hole formation","16 pages, 9 figures, 1 table, accepted to ApJL",,,,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the nucleosynthesis and kilonova properties of binary
neutron-star (NS) merger models which lead to intermediate remnant lifetimes of
~0.1-1seconds until black-hole (BH) formation and describe all components of
material ejected during the dynamical merger phase, NS-remnant evolution, and
final viscous disintegration of the BH torus after gravitational collapse. To
this end we employ a combination of hydrodynamics, nucleosynthesis, and
radiative-transfer tools to achieve a consistent end-to-end modeling of the
system and its observables. We adopt a novel version of the Shakura-Sunyaev
scheme allowing to vary the approximate turbulent viscosity inside the NS
remnant independently of the surrounding disk. We find that asymmetric
progenitors lead to shorter remnant lifetimes and enhanced ejecta masses,
although the viscosity affects the absolute values of these characteristics.
The integrated production of lanthanides and heavier elements in such binary
systems is sub-solar, suggesting that the considered scenarios contribute in a
sub-dominant fashion to r-process enrichment. One reason is that BH-tori formed
after delayed collapse exhibit less neutron-rich conditions than typically
found, and often assumed in previous BH-torus models, for early BH formation.
The outflows in our models feature strong anisotropy as a result of the
lanthanide-poor polar neutrino-driven wind pushing aside lanthanide-rich
dynamical ejecta. Considering the complexity of the models, the estimated
kilonova light curves show promising agreement with AT2017gfo after times of
several days, while the remaining inconsistencies at early times could possibly
be overcome in binary configurations with a more dominant neutrino-driven wind
relative to the dynamical ejecta.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 2 Jun 2023 10:52:24 GMT""}]","2023-06-05"
"2302.10929","Hank Corbett","Hank Corbett and Jonathan Carney and Ramses Gonzalez and Octavi Fors
  and Nathan Galliher and Amy Glazier and Ward S. Howard and Nicholas M. Law
  and Robert Quimby and Jeffrey K. Ratzloff and Alan Vasquez Soto","The Evryscope Fast Transient Engine: Real-Time Detection for Rapidly
  Evolving Transients","28 pages, 18 figures. in press, ApJS",,"10.3847/1538-4365/acbd41",,"astro-ph.IM astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Astrophysical transients with rapid development on sub-hour timescales are
intrinsically rare. Due to their short durations, events like stellar
superflares, optical flashes from gamma-ray bursts, and shock breakouts from
young supernovae are difficult to identify on timescales that enable
spectroscopic followup. This paper presents the Evryscope Fast Transient Engine
(EFTE), a new data reduction pipeline designed to provide low-latency transient
alerts from the Evryscopes, a North-South pair of ultra-wide-field telescopes
with an instantaneous footprint covering 38% of the entire sky, and tools for
building long-term light curves from Evryscope data. EFTE leverages the optical
stability of the Evryscopes by using a simple direct image subtraction routine
suited to continuously monitoring the transient sky at minute cadence.
Candidates are produced within the base Evryscope two-minute cadence for 98.5%
of images, and internally filtered using VetNet, a convolutional neural network
real-bogus classifier. EFTE provides an extensible, robust architecture for
transient surveys probing similar timescales, and serves as the software
testbed for the real-time analysis pipelines and public data distribution
systems for the Argus Array, a next generation all-sky observatory with a data
rate 62x higher than Evryscope.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:00 GMT""}]","2023-04-26"
"2302.10930","Luigi Gallo","Luigi C. Gallo, Jon M. Miller, and Elisa Costantini","Active galactic nuclei with high-resolution X-ray spectroscopy","Invited review chapter for the book High-Resolution X-Ray
  Spectroscopy: Instrumentation, Data Analysis, and Science (Eds. C. Bambi and
  J. Jiang, Springer Singapore, expected in 2023)",,,,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  The imminent launch of XRISM will usher in an era of high-resolution X-ray
spectroscopy. For active galactic nuclei (AGN) this is an exciting epoch that
is full of massive potential for uncovering the ins and outs of supermassive
black hole accretion. In this work, we review AGN research topics that are
certain to advance in the coming years with XRISM and prognosticate the
possibilities with Athena and Arcus. Specifically, our discussion focuses on:
(i) the relatively slow moving ionised winds known as warm absorbers and
obscurers; (ii) the iron emitting from different regions of the inner and outer
disc, broad line region, and torus; and (iii) the ultrafast outflows that may
be the key to understanding AGN feedback.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:01 GMT""}]","2023-02-23"
"2302.10931","Elise Darragh-Ford","Elise Darragh-Ford, Adam B. Mantz, Elena Rasia, Steven W. Allen, R.
  Glenn Morris, Jack Foster, Robert W. Schmidt, Guillermo Wenrich","The Concentration-Mass Relation of Massive, Dynamically Relaxed Galaxy
  Clusters: Agreement Between Observations and $\Lambda$CDM Simulations","10 pages, 10 figures. Accepted by MNRAS",,"10.1093/mnras/stad585",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The relationship linking a galaxy cluster's total mass with the concentration
of its mass profile and its redshift is a fundamental prediction of the Cold
Dark Matter (CDM) paradigm of cosmic structure formation. However, confronting
those predictions with observations is complicated by the fact that simulated
clusters are not representative of observed samples where detailed mass profile
constraints are possible. In this work, we calculate the
Symmetry-Peakiness-Alignment (SPA) morphology metrics for maps of X-ray
emissivity from THE THREE HUNDRED project hydrodynamical simulations of galaxy
clusters at four redshifts, and thereby select a sample of morphologically
relaxed, simulated clusters, using observational criteria. These clusters have
on average earlier formation times than the full sample, confirming that they
are both morphologically and dynamically more relaxed than typical. We
constrain the concentration-mass-redshift relation of both the relaxed and
complete sample of simulated clusters, assuming power-law dependences on mass
($\kappa_m$) and $1+z$ ($\kappa_\zeta$), finding $\kappa_m = -0.12 \pm 0.07$
and $\kappa_\zeta = -0.27 \pm 0.19$ for the relaxed subsample. From an
equivalently selected sample of massive, relaxed clusters observed with ${\it
Chandra}$, we find $\kappa_m = -0.12 \pm 0.08$ and $\kappa_\zeta = -0.48 \pm
0.19$, in good agreement with the simulation predictions. The simulated and
observed samples also agree well on the average concentration at a pivot mass
and redshift providing further validation of the $\Lambda$CDM paradigm in the
properties of the largest gravitationally collapsed structures observed. This
also represents the first clear detection of decreasing concentration with
redshift, a longstanding prediction of simulations, in data.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:01 GMT""}]","2023-03-01"
"2302.10932","Bhagya Subrayan","Bhagya M. Subrayan, Dan Milisavljevic, Ryan Chornock, Raffaella
  Margutti, Kate D. Alexander, Vandana Ramakrishnan, Paul C. Duffell, Danielle
  A. Dickinson, Kyoung-Soo Lee, Dimitrios Giannios, Geoffery Lentner, Mark
  Linvill, Braden Garretson, Matthew J. Graham, Daniel Stern, Daniel Brethauer,
  Tien Duong, Wynn Jacobson-Gal\'an, Natalie LeBaron, David Matthews, Huei
  Sears and Padma Venkatraman","Scary Barbie: An Extremely Energetic, Long-Duration Tidal Disruption
  Event Candidate Without a Detected Host Galaxy at z = 0.995","15 pages, 4 figures, 1 Table; Version as published in The
  Astrophysical Journal Letters. Observations of AT 2021lwx published in the
  paper can be found at https://bsubraya.github.io/research/",,"10.3847/2041-8213/accf1a",,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by-sa/4.0/","  We report multi-wavelength observations and characterization of the
ultraluminous transient AT 2021lwx (ZTF20abrbeie; aka ``Barbie'') identified in
the alert stream of the Zwicky Transient Facility (ZTF) using a Recommender
Engine For Intelligent Transient Tracking (REFITT) filter on the ANTARES alert
broker. From a spectroscopically measured redshift of 0.995, we estimate a peak
observed pseudo-bolometric luminosity of log (L$_{\text{max}} /
[\text{erg}/\text{s}]$) = 45.7 from slowly fading ztf-$\it{g}$ and ztf-$r$
light curves spanning over 1000 observer-frame days. The host galaxy is not
detected in archival Pan-STARRS observations ($g > 23.3$ mag), implying a lower
limit to the outburst amplitude of more than 5 mag relative to the quiescent
host galaxy. Optical spectra from Lick and Keck Observatories exhibit strong
emission lines with narrow cores from the H Balmer series and ultraviolet
semi-forbidden lines of Si III] $\lambda$1892, C III] $\lambda$1909, and C II]
$\lambda$2325. Typical nebular lines in AGN spectra from ions such as [O II]
and [O III] are not detected. These spectral features, along with the smooth
light curve that is unlike most AGN flaring activity, and the luminosity that
exceeds any observed or theorized supernova, lead us to conclude that AT
2021lwx is most likely an extreme tidal disruption event (TDE). Modeling of ZTF
photometry with MOSFiT suggests that the TDE was between a $\approx 14
M_{\odot}$ star and a supermassive black hole of mass $M_{\text{BH}} \sim$
$10^{8} M_{\odot}$. Continued monitoring of the still-evolving light curve
along with deep imaging of the field once AT 2021lwx has faded can test this
hypothesis and potentially detect the host galaxy.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 17:48:12 GMT""},{""version"":""v3"",""created"":""Thu, 8 Jun 2023 15:55:07 GMT""}]","2023-06-09"
"2302.10933","Lento Nagano","Lento Nagano, Aniruddha Bapat, Christian W. Bauer","Quench dynamics of the Schwinger model via variational quantum
  algorithms","11 pages, 4 figures",,,,"hep-ph cond-mat.str-el hep-lat hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the real-time dynamics of the $(1+1)$-dimensional U(1) gauge
theory known as the Schwinger model via variational quantum algorithms.
Specifically, we simulate quench dynamics in the presence of an external
electric field. First, we use a variational quantum eigensolver to obtain the
ground state of the system in the absence of an external field. With this as
the initial state, we perform real-time evolution under an external field via a
fixed-depth, parameterized circuit whose parameters are updated using
McLachlan's variational principle. We use the same Ansatz for initial state
preparation and time evolution, by which we are able to reduce the overall
circuit depth. We test our method with a classical simulator and confirm that
the results agree well with exact diagonalization.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:01 GMT""}]","2023-02-23"
"2302.10934","Katriona Gould","Katriona M. L. Gould, Gabriel Brammer, Francesco Valentino, Katherine
  E. Whitaker, John R. Weaver, Claudia del P. Lagos, Francesca Rizzo,
  Maximilien Franco, Bau-Ching Hseih, Olivier Ilbert, Shuowen Jin, Georgios
  Magdis, Henry J. McCracken, Bahram Mobasher, Marko Shuntov, Charles L.
  Steinhardt, Victoria Strait, Sune Toft","COSMOS2020: Exploring the dawn of quenching for massive galaxies at 3 <
  z < 5 with a new colour selection method","19 pages, 10 figures + appendix. Accepted for publication in AJ. Both
  the GMM model and code to calculate quiescent probabilities from rest frame
  flux densities are made available online at
  https://github.com/kmlgould/GMM-quiescent",,"10.3847/1538-3881/accadc",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We select and characterise a sample of massive
(log(M$_{*}/$M$_{\odot})>10.6$) quiescent galaxies (QGs) at $3<z<5$ in the
latest COSMOS2020 catalogue. QGs are selected using a new rest-frame colour
selection method, based on their probability of belonging to the quiescent
group defined by a Gaussian Mixture Model (GMM) trained on rest-frame colours
($NUV-U, U-V, V-J$) of similarly massive galaxies at $2<z<3$. We calculate the
quiescent probability threshold above which a galaxy is classified as quiescent
using simulated galaxies from the SHARK semi-analytical model. We find that at
$z\geq3$ in SHARK, the GMM/$NUVU-VJ$ method out-performs classical rest-frame
$UVJ$ selection and is a viable alternative. We select galaxies as quiescent
based on their probability in COSMOS2020 at $3<z<5$, and compare the selected
sample to both $UVJ$ and $NUVrJ$ selected samples. We find that although the
new selection matches $UVJ$ and $NUVrJ$ in number, the overlap between colour
selections is only $\sim50-80\%$, implying that rest-frame colour commonly used
at lower redshifts selections cannot be equivalently used at $z>3$. We compute
median rest-frame SEDs for our sample and find the median quiescent galaxy at
$3<z<5$ has a strong Balmer/4000 Angstrom break, and residual $NUV$ flux
indicating recent quenching. We find the number densities of the entire
quiescent population (including post-starbursts) more than doubles from
$3.5\pm2.2\times10^{-6}$ Mpc$^{-3}$ at $4<z<5$ to $1.4\pm0.4\times10^{-5}$
Mpc$^{-3}$ at $3<z<4$, confirming that the onset of massive galaxy quenching
occurs as early as $3<z<5$.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:02 GMT""}]","2023-05-31"
"2302.10935","Elyasaf Yosef Cohen","Elyasaf Y. Cohen, Andrei Alexandru and Snir Gazit","Complex path simulations of geometrically frustrated ladders","10 pages, 7 figures",,,,"cond-mat.str-el hep-lat","http://creativecommons.org/licenses/by/4.0/","  Quantum systems with geometrical frustration remain an outstanding challenge
for numerical simulations due to the infamous numerical sign problem. Here, we
overcome this obstruction via complex path integration in a geometrically
frustrated ladder of interacting bosons at finite density. This enables studies
of the many-body ground state properties, otherwise inaccessible with standard
quantum Monte Carlo methods. Specifically, we study a chemical potential tuned
quantum phase transition, along which we track the emergence of quasi long
range order and critical softening of the single particle gap. We chart future
methodological improvements and applications in generalized geometrically
frustrated lattice models.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:02 GMT""}]","2023-02-23"
"2302.10936","Francesco Valentino","Francesco Valentino, Gabriel Brammer, Katriona M. L. Gould, Vasily
  Kokorev, Seiji Fujimoto, Christian Kragh Jespersen, Aswin P. Vijayan, John R.
  Weaver, Kei Ito, Masayuki Tanaka, Olivier Ilbert, Georgios E. Magdis,
  Katherine E. Whitaker, Andreas L. Faisst, Anna Gallazzi, Steven Gillman,
  Clara Gimenez-Arteaga, Carlos Gomez-Guijarro, Mariko Kubo, Kasper E. Heintz,
  Michaela Hirschmann, Pascal Oesch, Masato Onodera, Francesca Rizzo, Minju
  Lee, Victoria Strait, Sune Toft","An Atlas of Color-selected Quiescent Galaxies at $z>3$ in Public $JWST$
  Fields","15 pages, 6 Figures + Appendix. Accepted for publication in ApJ on
  Feb, 9. Data release: - Reduced HST+JWST mosaics + photometric catalogs and
  Eazy-py modeling:
  https://erda.ku.dk/archives/7166d013c1ca1371aac3c57b9e73190d/published-archive.html
  - Supplementary material and tables:
  https://zenodo.org/record/7614908#.Y-4ZruzMLmE - MAST:
  https://doi.org/10.17909/g3nt-a370 - See also Gould et al. 2023",,"10.3847/1538-4357/acbefa",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present the results of a systematic search for candidate quiescent
galaxies in the distant Universe in eleven $JWST$ fields with publicly
available observations collected during the first three months of operations
and covering an effective sky area of $\sim145$ arcmin$^2$. We homogeneously
reduce the new $JWST$ data and combine them with existing observations from the
$Hubble\,Space\,Telescope$. We select a robust sample of $\sim80$ candidate
quiescent and quenching galaxies at $3 < z < 5$ using two methods: (1) based on
their rest-frame $UVJ$ colors, and (2) a novel quantitative approach based on
Gaussian Mixture Modeling of the $NUV-U$, $U-V$, and $V-J$ rest-frame color
space, which is more sensitive to recently quenched objects. We measure
comoving number densities of massive ($M_\star\geq 10^{10.6} M_\odot$)
quiescent galaxies consistent with previous estimates relying on ground-based
observations, after homogenizing the results in the literature with our mass
and redshift intervals. However, we find significant field-to-field variations
of the number densities up to a factor of $2-3$, highlighting the effect of
cosmic variance and suggesting the presence of overdensities of red quiescent
galaxies at $z>3$, as it could be expected for highly clustered massive
systems. Importantly, $JWST$ enables the robust identification of
quenching/quiescent galaxy candidates at lower masses and higher redshifts than
before, challenging standard formation scenarios. All data products, including
the literature compilation, are made publicly available.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:03 GMT""}]","2023-04-26"
"2302.10937","Georgios Mountrichas Dr.","George Mountrichas","The coevolution of supermassive black holes and galaxies in luminous AGN
  over a wide range of redshift","Accepted for publication in A&A. 8 pages, 7 figures","A&A 672, A98 (2023)","10.1051/0004-6361/202345924",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that supermassive black holes (SMBHs) and their host
galaxies co-evolve. A manifestation of this co-evolution is the correlation
that has been found between the SMBH mass, M$_{BH}$, and the galaxy bulge or
stellar mass, M$_*$. The cosmic evolution of this relation, though, is still a
matter of debate. In this work, we examine the M$_{BH}-$M$_*$ relation, using
687 X-ray luminous (median $\rm log\,[L_{X,2-10keV}(ergs^{-1})]=44.3$), broad
line AGN, at $\rm 0.2<z<4.0$ (median $\rm z\approx 1.4$) that lie in the
XMM-{\it{XXL}} field. Their M$_{BH}$ and M$_*$ range from $\rm
7.5<log\,[M_{BH}\,(M_\odot)]<9.5$ and $\rm 10<log\,[M_*(M_\odot)]<12$,
respectively. Most of the AGN live in star-forming galaxies and their Eddington
ratios range from 0.01 to 1, with a median value of 0.06. Our results show that
M$_{BH}$ and M$_*$ are correlated ($\rm r=0.47\pm0.21$, averaged over different
redshift intervals). Our analysis also shows that the mean ratio of the
M$_{BH}$ and M$_*$ does not evolve with redshift, at least up to $\rm z=2$ and
has a value of $\rm log($M$_{BH}/$M$_*)=-2.44$. The majority of the AGN
($75\%$) are in a SMBH mass growth dominant phase. In these systems, the
M$_{BH}-$M$_*$ correlation is weaker and their M$_*$ tends to be lower (for the
same M$_{BH}$) compared to systems that are in a galaxy mass growth phase. Our
findings suggest that the growth of black hole mass occurs first, while the
early stellar mass assembly may not be so efficient.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:03 GMT""}]","2023-04-12"
"2302.10938","Shahar Hod","Shahar Hod","Comment on: ""Possible Relation between the Cosmological Constant and
  Standard Model Parameters""","2 pages",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  It has recently been proposed [M. P. Hertzberg and A. Loeb, arXiv:2302.09090]
that the observed value of the cosmological constant can be related to the
physical parameters of the Standard Model. In the present compact note we point
out that the derivation of the claimed cosmological-constant-standard-model
relation presented in \cite{HL} is, unfortunately, erroneous.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:08 GMT""}]","2023-02-23"
"2302.10939","Pragati Pradhan","Pragati Pradhan, Carlo Ferrigno, Biswajit Paul, Enrico Bozzo, Ileyk El
  Mellah, David P. Huenemoerder, James F. Steiner, Victoria Grinberg, Felix
  Furst, Chandreyee Maitra, Patrizia Romano, Peter Kretschma, Jamie Kennea,
  Deepto Chakrabarty","Clumpy wind studies and the non-detection of cyclotron line in OAO
  1657-415","32 pages, 11 figures in main text, 7 figures in Appendix, Accepted
  for publication in ApJ",,"10.3847/1538-4357/acb2cb",,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Winds of massive stars are suspected to be inhomogeneous (or clumpy), which
biases the measures of their mass loss rates. In High Mass X-ray Binaries
(HMXBs), the compact object can be used as an orbiting X-ray point source to
probe the wind and constrain its clumpiness. We perform spectro-timing analysis
of the HMXB OAO 1657-415 with non-simultaneous NuSTAR and NICER observations.
We compute the hardness ratio from the energy-resolved light curves, and using
an adaptive rebinning technique, we thus select appropriate time segments to
search for rapid spectral variations on timescales of a few hundreds to
thousands of seconds. Column density and intensity of Iron K$\alpha$ line were
strongly correlated, and the recorded spectral variations were consistent with
accretion from a clumpy wind. We also illustrate a novel framework to measure
clump sizes, masses in HMXBs more accurately based on absorption measurements
and orbital parameters of the source. We then discuss the limitations posed by
current X-ray spacecrafts in such measurements and present prospects with
future X-ray missions. We find that the source pulse profiles show a moderate
dependence on energy. We identify a previously undetected dip in the pulse
profile visible throughout the NuSTAR observation near spin phase 0.15 possibly
caused by intrinsic changes in accretion geometry close to the neutron star. We
do not find any evidence for the debated cyclotron line at $\sim$ 36\,keV in
the time-averaged or the phase-resolved spectra with NuSTAR.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:10 GMT""}]","2023-03-15"
"2302.10940","Surajit Bera","Surajit Bera, Arijit Haldar and Sumilan Banerjee","Dynamical mean-field theory for R\'{e}nyi entanglement entropy and
  mutual Information in Hubbard Model","13 pages, 12 figures",,,,"cond-mat.str-el cond-mat.dis-nn cond-mat.stat-mech hep-th quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum entanglement, lacking any classical counterpart, provides a
fundamental new route to characterize the quantum nature of many-body states.
In this work, we discuss an implementation of a new path integral method [Phys.
Rev. Res. 2, 033505 (2020)] for fermions to compute entanglement for extended
subsystems in the Hubbard model within dynamical mean field theory (DMFT) in
one and two dimensions. The new path integral formulation measures entanglement
by applying a ``kick"" to the underlying interacting fermions. We show that the
R\'{e}nyi entanglement entropy can be extracted efficiently within the DMFT
framework by integrating over the strength of the kick term. Using this method,
we compute the second R\'{e}nyi entropy as a function of subsystem size for
metallic and Mott insulating phases of the Hubbard model. We explore the
thermal entropy to entanglement crossover in the subsystem R\'{e}nyi entropy in
the correlated metallic phase. We show that the subsystem-size scaling of
second R\'{e}nyi entropy is well described by the crossover formula which
interpolates between the volume-law thermal R\'{e}nyi entropy and the universal
boundary-law R\'{e}nyi entanglement entropy with logarithmic violation, as
predicted by conformal field theory. We also study the mutual information
across the Mott metal-insulator transition.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:12 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 10:28:42 GMT""}]","2023-02-24"
"2302.10941","Devon Powell","Devon M. Powell, Simona Vegetti, J. P. McKean, Simon D.M. White, Elisa
  G. M. Ferreira, Simon May, Cristiana Spingola","A lensed radio jet at milli-arcsecond resolution II: Constraints on
  fuzzy dark matter from an extended gravitational arc","5 pages, 2 figures. Accepted in MNRAS Letters",,,,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using a single gravitational lens system observed at $\lesssim5$
milli-arcsecond resolution with very long baseline interferometry (VLBI), we
place a lower bound on the mass of the fuzzy dark matter (FDM) particle, ruling
out $m_\chi \leq 4.4\times10^{-21}~\mathrm{eV}$ with a 20:1 posterior odds
ratio relative to a smooth lens model. We generalize our result to non-scalar
and multiple-field models, such as vector FDM, with $m_{\chi,\mathrm{vec}} >
1.4 \times 10^{-21}~\mathrm{eV}$. Due to the extended source structure and high
angular resolution of the observation, our analysis is directly sensitive to
the presence of granule structures in the main dark matter halo of the lens,
which is the most generic prediction of FDM theories. A model based on
well-understood physics of ultra-light dark matter fields in a gravitational
potential well makes our result robust to a wide range of assumed dark matter
fractions and velocity dispersions in the lens galaxy. Our result is
competitive with other lower bounds on $m_\chi$ from past analyses, which rely
on intermediate modelling of structure formation and/or baryonic effects.
Higher resolution observations taken at 10 to 100 GHz could improve our
constraints by up to 2 orders of magnitude in the future.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:14 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 13:22:57 GMT""}]","2023-06-08"
"2302.10942","David Pere\~n\'iguez Dr","David Pere\~niguez","Black Hole Perturbations and Electric-Magnetic Duality","v1: 4 pages + appendix, no figures. v2: references added, minor edits",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Black holes can be electromagnetically charged, or carry vector charge from
new fundamental fields. Their response to small fluctuations is of paramount
importance to study gravitational wave generation. While isolated dyonic black
holes are connected by electric-magnetic duality to purely electric ones, the
interaction between two or more dyonic black holes is in general not encoded in
the purely electric case. However, the usual scalar and vector sectors of
gravitoelectromagnetic waves couple if a black hole is magnetically charged, a
fact that complicates significantly the perturbative approach. In this paper,
perturbation theory based on harmonic decomposition is extended to have
manifest invariance under electric-magnetic duality. As a result, the equations
decouple into two generalised sectors, each governed by master wave equations
that include the most general coupling to a dyonic source. These can be used to
compute, in a simple manner, the gravitational and electromagnetic radiation
produced during the interaction of the most general spherically symmetric black
holes of the Einstein-Maxwell theory.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:17 GMT""},{""version"":""v2"",""created"":""Fri, 10 Mar 2023 18:08:18 GMT""}]","2023-03-13"
"2302.10943","Daniel Montenegro-Taborda","Daniel Montenegro-Taborda, Vicente Rodriguez-Gomez, Annalisa
  Pillepich, Vladimir Avila-Reese, Laura V. Sales, Aldo Rodr\'iguez-Puebla and
  Lars Hernquist","The growth of brightest cluster galaxies in the TNG300
  simulation:dissecting the contributions from mergers and in situ star
  formation","19 pages, 11 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stad586",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the formation of brightest cluster galaxies (BCGs) in the
TNG300 cosmological simulation of the IllustrisTNG project. Our cluster sample
consists of 700 haloes with $M_{200} \geq 5 \times 10^{13} \,
\mathrm{M}_{\odot}$ at $z=0$, along with their progenitors at earlier epochs.
This includes 280 systems with $M_{200} \geq 10^{14} \, \mathrm{M}_{\odot}$ at
$z=0$, as well as three haloes with $M_{200} \geq 10^{15} \,
\mathrm{M}_{\odot}$. We find that the stellar masses and star formation rates
of our simulated BCGs are in good agreement with observations at $z \lesssim
0.4$, and that they have experienced, on average, $\sim$2 ($\sim$3) major
mergers since $z=1$ ($z=2$). Separating the BCG from the intracluster light
(ICL) by means of a fixed 30 kpc aperture, we find that the fraction of stellar
mass contributed by ex situ (i.e. accreted) stars at $z=0$ is approximately 70,
80, and 90 per cent for the BCG, BCG+ICL, and ICL, respectively. Tracking our
simulated BCGs back in time using the merger trees, we find that they became
dominated by ex situ stars at $z \sim $1-2, and that half of the stars that are
part of the BCG at $z=0$ formed early ($z \sim 3$) in other galaxies, but
`assembled' onto the BCG until later times ($z \approx 0.8$ for the whole
sample, $z \approx 0.5$ for BCGs in $M_{200} \geq 5 \times 10^{14} \,
\mathrm{M}_{\odot}$ haloes). Finally, we show that the stellar mass profiles of
BCGs are often dominated by ex situ stars at all radii, with stars from major
mergers being found closer to the centre, while stars that were tidally
stripped from other galaxies dominate the outer regions.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:23 GMT""}]","2023-03-08"
"2302.10944","Stefan Groote Dr.","Arpan Chatterjee, Marco Frasca, Anish Ghoshal and Stefan Groote","Re-normalisable Non-local Quark-Gluon Interaction: Mass Gap, Chiral
  Symmetry Breaking & Scale Invariance","22 pages, without references, 3 figures, comments are welcome",,,,"hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We derive a Nambu--Jona-Lasinio (NJL) model from a non-local gauge theory and
show that it has confining properties at low energies. In particular, we
present an extended approach to non-local QCD and a complete revision of the
technique of Bender, Milton and Savage applied to non-local theories providing
a set of Dyson--Schwinger equations in differential form. In the local case, we
obtain closed form solutions in the simplest case of the scalar field and
extended it to the Yang--Mills field. In general, for non-local theories, we
use a perturbative technique and a Fourier series and show how higher-order
harmonics are heavily damped due to the presence of the non-local factor. The
spectrum of the theory is analysed for the non-local Yang--Mills sector and
found to be in agreement with the local results on the lattice in the limit of
the non-locality mass parameter running to infinity. In the non-local case, we
contend ourselves to have the non-locality mass sufficiently large compared to
the mass scale arising from the integration of the Dyson--Schwinger equations.
Such a choice grants good agreement, in the proper limit, with the spectrum of
the local theory. We derive the gap equation for the fermions in the theory
that gives some indication of quark confinement also in the non-local NJL case.
This result is really important, as it seems to point to the fact that
confinement (and breaking of scale invariance) could be an ubiquitous effect in
nature that removes some degrees of freedom in a theory in order to favour
others.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:01:15 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 12:25:00 GMT""},{""version"":""v3"",""created"":""Fri, 24 Feb 2023 16:20:28 GMT""}]","2023-02-27"
"2302.10945","Amitabha Lahiri","Riya Barick, Indrajit Ghose, Amitabha Lahiri","Effect of spacetime geometry on neutrino oscillations",,,,,"hep-ph gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Propagation of fermions in spacetime requires a spin connection, which can be
split into a universal gravitational part and a non-universal ``contorsion''
part. The latter is non-dynamical and can be eliminated from the theory,
leaving an effective four-fermion interaction with unknown coupling constants.
The generic form of the contorsion-fermion coupling, and thus the four-fermion
interaction, breaks chiral symmetry. This interaction affects all fermions --
in particular neutrinos passing through matter will notice a contribution to
their effective Hamiltonian, just like the MSW effect coming from weak
interactions. Then there is a possibility that this geometrical contribution is
not negligible for neutrinos passing through normal matter, provided the
coupling constants are not too small. We calculate the matter potential due to
this interaction and thus write the conversion and survival probabilities
including its effect. We plot conversion probabilities of $\nu_\mu$ to $\nu_e$
and $\nu_\tau$ for a baseline of 1300 km (DUNE) with and without the
geometrical interaction. If the geometrical couplings are not too small, it
should be possible to observe this effect.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:01:19 GMT""}]","2023-02-23"
"2302.10946","Rohini Giles","Rohini S. Giles, Vincent Hue, Thomas K. Greathouse, G. Randall
  Gladstone, Joshua A. Kammer, Maarten H. Versteeg, Bertrand Bonfond, Denis G.
  Grodent, Jean-Claude G\'erard, James A. Sinclair, Scott J. Bolton, Steven M.
  Levin","Enhanced C$_2$H$_2$ absorption within Jupiter's southern auroral oval
  from Juno UVS observations","Accepted in JGR: Planets",,"10.1029/2022JE007610",,"astro-ph.EP physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Reflected sunlight observations from the Ultraviolet Spectrograph (UVS) on
the Juno spacecraft were used to study the distribution of acetylene
(C$_2$H$_2$) at Jupiter's south pole. We find that the shape of the C$_2$H$_2$
absorption feature varies significantly across the polar region, and this can
be used to infer spatial variability in the C$_2$H$_2$ abundance. There is a
localized region of enhanced C$_2$H$_2$ absorption which coincides with the
location of Jupiter's southern polar aurora; the C$_2$H$_2$ abundance poleward
of the auroral oval is a factor of 3 higher than adjacent quiescent,
non-auroral longitudes. This builds on previous infrared studies which found
enhanced C$_2$H$_2$ abundances within the northern auroral oval. This suggests
that Jupiter's upper-atmosphere chemistry is being strongly influenced by the
influx of charged auroral particles and demonstrates the necessity of
developing ion-neutral photochemical models of Jupiter's polar regions.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:01:23 GMT""}]","2023-03-15"
"2302.10947","Ethan Schreyer Mr","Ethan Schreyer, James E. Owen, Jessica J. Spake, Zahra Bahroloom and
  Simone Di Giampasquale","Using helium 10830 {\AA} transits to constrain planetary magnetic fields","Submitted to MNRAS",,,,"astro-ph.EP astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Planetary magnetic fields can affect the predicted mass loss rate for
close-in planets that experience large amounts of UV irradiation. In this work,
we present a method to detect the magnetic fields of close-in exoplanets
undergoing atmospheric escape using transit spectroscopy at the 10830 Angstrom
line of helium. Motivated by previous work on hydrodynamic and
magneto-hydrodynamic photoevaporation, we suggest that planets with magnetic
fields that are too weak to control the outflow's topology lead to blue-shifted
transits due to day-to-night-side flows. In contrast, strong magnetic fields
prevent this day-to-night flow, as the gas is forced to follow the magnetic
field's roughly dipolar topology. We post-process existing 2D photoevaporation
simulations to test this concept, computing synthetic transit profiles in
helium. As expected, we find that hydrodynamically dominated outflows lead to
blue-shifted transits on the order of the sound speed of the gas. Strong
surface magnetic fields lead to unshifted or slightly red-shifted transit
profiles. High-resolution observations can distinguish between these profiles;
however, eccentricity uncertainties generally mean that we cannot conclusively
say velocity shifts are due to the outflow for individual planets. The majority
of helium observations are blue-shifted, which could be a tentative indication
that close-in planets generally have surface dipole magnetic field strengths
$\lesssim 0.1$ gauss. More 3D hydrodynamic and magneto-hydrodynamic are needed
to confirm this conclusion robustly.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:02:08 GMT""}]","2023-02-23"
"2302.10948","Elena Kaisina","I. D. Karachentsev, E. I. Kaisina, V. E. Karachentseva","The pride of lions around Messier 105","12 pages, 5 figures, 4 tables, accepted for MNRAS",,"10.1093/mnras/stad593",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We undertook a search for new dwarf galaxies in the Leo-I group using the
data from the DECaLS digital sky survey. Five new presumed members of this
group have been found in a wide vicinity of ${\rm M}\,105 ({\rm NGC}\,3379$).
Currently, the group has a population of $83$ galaxies, $33$ of which have
measured radial velocities. More than half of the group members belong to early
types with no signs of ongoing star formation. About a quarter of the galaxies
are outside the group's virial radius, $R_v = 385$~kpc. The presence of
multiple systems with a size of about 15~kpc is evident in the group, but there
are no noticeable global flat or filamentary substructures. The luminosity
function of the group looks to be deficient in galaxies with absolute
magnitudes in the interval $M_B = [-18, -15]$ mag. The ${\rm M}\,105$ group is
characterized by a radial velocity dispersion of $136$~km~s$^{-1}$, orbital
mass estimate $(5.76\pm1.32)\times 10^{12}~M_{\odot}$, and the total
mass-to-K-band-luminosity ratio $(17.8\pm4.1) M_\odot/L_\odot$. The neighboring
group of galaxies around ${\rm M}\,66 ({\rm NGC}\,3627$) has a similar virial
radius, $390$~kpc, velocity dispersion, $135$~km~s$^{-1}$, and total
mass-to-luminosity ratio, $(15.6\pm3.9) M_\odot/L_\odot$. Both groups in the
Leo constellation are approaching the Local Group with a velocity of about
100~km~s$^{-1}$. In the background of the ${\rm M}\,105$ group, we noted a
group of 6 galaxies with an unusually low virial mass-to-luminosity ratio,
$M_T/L_K = (4.1\pm2.2) M_\odot/L_\odot$.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:06:35 GMT""}]","2023-03-08"
"2302.10949","Christoph S\""underhauf","Christoph S\""underhauf, Earl Campbell, Joan Camps","Block-encoding structured matrices for data input in quantum computing",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cost of data input can dominate the run-time of quantum algorithms. Here,
we consider data input of arithmetically structured matrices via block encoding
circuits, the input model for the quantum singular value transform and related
algorithms. We demonstrate how to construct block encoding circuits based on an
arithmetic description of the sparsity and pattern of repeated values of a
matrix. We present schemes yielding different subnormalisations of the block
encoding; a comparison shows that the best choice depends on the specific
matrix. The resulting circuits reduce flag qubit number according to sparsity,
and data loading cost according to repeated values, leading to an exponential
improvement for certain matrices. We give examples of applying our block
encoding schemes to a few families of matrices, including Toeplitz and
tridiagonal matrices.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:08:49 GMT""}]","2023-02-23"
"2302.10950","Zhiying Li","J.-H. Arling, C. Becot, E. Buchanan, J. Dopke, B. Gallop, J. Kaplon,
  J. S. Keller, J. Kroll, Y. Li, Z. Li, J. Liu, Y. Liu, S. Y. Ng, R. Privara,
  A. Renardi, A. Rodriguez Rodriguez, E. Rossi, F. Ruehr, C. Sawyer, D.
  Sperlich, A. R. Weidberg, D. F. Zhang","Test beam measurement of ATLAS ITk Short Strip module at warm and cold
  operational temperature","Submitted to JINST",,"10.1088/1748-0221/18/03/P03015",,"hep-ex physics.ins-det","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This study is focused on an investigation of the performance of the Short
Strip module developed by the ATLAS Inner Tracker (ITk) strip collaboration
using electron beams of energy 5.4 GeV and 5.8 GeV at the DESY-II Testbeam
Facility. The noise at +30 C and -30 C was measured. The ratio of the two
measurements is compared with a circuit-model calculation. The measured noise
at -30 C is compared with the maximum noise that would correspond to an
acceptable signal-to-noise ratio after the expected radiation damage from
operation at HL-LHC. The measured charge distributions at +30 C and -30 C are
compared with GEANT4 simulations. The detection efficiency and noise-occupancy
were measured as a function of threshold at both +30 C and -30 C. The average
cluster width was measured as a function of threshold. Scans of detection
efficiency versus threshold at different delay settings were used to
reconstruct the pulse shape in time. The resulting pulse shape was compared
with a circuit model calculation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:10:06 GMT""}]","2023-03-22"
"2302.10951","Sebastian Franco","Sebasti\'an Franco, Rak-Kyeong Seong","Twin Theories, Polytope Mutations and Quivers for GTPs","51 pages, 42 figures. v2: typos corrected, references added",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a unified perspective on two sets of objects that usually arise in
the study of bipartite field theories. Each of the sets consists of a polytope,
or equivalently a toric Calabi-Yau, and a quiver theory. We refer to the two
sets of objects as original and twin. In the simplest cases, the two sides of
the correspondence are connected by the graph operation known as untwisting.
The democratic treatment that we advocate raises new questions regarding the
connections between these objects, some of which we explore.
  With this motivation in mind, we establish a correspondence between the
mutations of the original polytope and the twin quiver. This leads us to
propose that non-toric twin quivers are naturally associated to generalized
toric polygons (GTPs) and we explore various aspects of this idea. Supporting
evidence includes global symmetries, the ability of twin quivers to encode the
generalized $s$-rule, and the connection between the mutations of polytopes and
of configurations of webs of 5-branes suspended from 7-branes. We introduce
three methods for constructing twin quivers for GTPs. We also investigate the
connection between twin quivers obtained using different toric phases. Twin
quivers provide a powerful new perspective on GTPs. The ideas presented in this
paper may represent a step towards the generalization of brane tilings to GTPs.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:10:46 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 21:23:35 GMT""}]","2023-03-08"
"2302.10952","Hsu Kiang Ooi","Hang Hu, Hsu Kiang Ooi, Mohammad Sajjad Ghaemi, Anguang Hu","Machine learning for the prediction of safe and biologically active
  organophosphorus molecules",,,,,"cs.LG q-bio.BM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Drug discovery is a complex process with a large molecular space to be
considered. By constraining the search space, the fragment-based drug design is
an approach that can effectively sample the chemical space of interest. Here we
propose a framework of Recurrent Neural Networks (RNN) with an attention model
to sample the chemical space of organophosphorus molecules using the
fragment-based approach. The framework is trained with a ZINC dataset that is
screened for high druglikeness scores. The goal is to predict molecules with
similar biological action modes as organophosphorus pesticides or chemical
warfare agents yet less toxic to humans. The generated molecules contain a
starting fragment of PO2F but have a bulky hydrocarbon side chain limiting its
binding effectiveness to the targeted protein.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:12:35 GMT""}]","2023-02-23"
"2302.10953","Roi Rahin","Roi Rahin and Ehud Behar","A NICER viewing angle on the accretion stream of Vela X-1","Submitted to ApJ",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Vela X-1 is the archetypical eclipsing high-mass X-ray binary, composed of a
neutron star (NS) accreting the B-star wind. It was observed by nearly all
X-ray observatories, often multiple times, featuring a rich spectrum of
variable emission lines. Yet, the precise origin of these lines in the binary
system remains uncertain. We perform a systematic, orbital phase-dependent
analysis of the reflected Fe K$\alpha$ fluorescence line at 6.4 keV using over
100 NICER observations. We resolve the line variability into 500s time bins and
find that it is predominantly due to variation in the ionizing flux, with a
moderate underlying phase dependence over the 9-day orbital period. Our
analysis reveals a significant reflection component that cannot originate from
the companion B-star alone. We also find that an appreciable portion of the
B-star surface is obscured opposite the eclipse, and this obscuration is not
symmetric around the mid-point (phase=0.5). We argue that an accretion stream,
from the B-star to the NS and distorted by the orbital motion, is responsible
for both the additional fluorescence emission component and for obscuring the
B-star.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:18:26 GMT""},{""version"":""v2"",""created"":""Mon, 6 Mar 2023 19:21:55 GMT""}]","2023-03-08"
"2302.10954","Arindam Kundagrami","Souradeep Ghosh, Soumik Mitra, Arindam Kundagrami","Polymer Complexation: Partially Ionizable Asymmetric Polyelectrolytes",,,"10.1063/5.0147323",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Studies of the thermodynamics of complex coacervation of pairs of symmetric,
strongly ionizable, oppositely charged polyelectrolyte chains are abundant. To
generalize such understanding to asymmetric chain lengths and variable
ionizability (chemical charge density), frequently observed in experiments, we
present a theoretical framework to analyze the effective charge and size of the
complex and the thermodynamics of complexation of two polyions as a function of
such asymmetries. The free energy ensuing from the Edwards' Hamiltonian
undergoes variational extremization, and explicitly accounts for the screened
Coulomb and non-electrostatic interactions among monomers within individual
polyions and between two polyions. Assuming maximal ion-pair formation of the
complexed part, the system free energy comprising configurational entropy of
the polyions and free-ion entropy of the small ions is minimized. The
thermodynamic drive for complexation is found to increase with the ionizability
of the symmetric polyions and to be maximum for symmetric chain lengths for
equally ionizable polyions. The effective charge and size of the complex
increase with asymmetry in charge density, where the size can be substantially
larger than a collapsed globule found for symmetric chains. The regimes of
enthalpy- and entropy-driven complexation are found, respectively, for low and
high Coulomb strengths. The crossover strength is found to be strongly
dependent on the dielectric environment and salt, but marginally dependent on
the charge density, thus implying an entropy-driven process at moderate
strengths. The key results match the trends in simulations and experiments, and
are expected to provide insight for asymmetric complexation in real systems.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:18:28 GMT""}]","2023-06-07"
"2302.10955","Neil Lambert","Neil Lambert","Duality and Fluxes in the Sen Formulation of Self-Dual Fields","20 pages, Typos corrected, to appear in PLB",,"10.1016/j.physletb.2023.137888",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  In Sen's formulation of self-dual fields one finds two closed forms:
$H^{(g)}$ and $H^{(s)}$. Only the former couples to sources and the spacetime
metric. The latter has the wrong sign kinetic term but decouples and hence
might be regarded as an unphysical artifact. In this letter we illustrate how
an electromagnetic duality associated to the potential for $H^{(s)}$ gives rise
to a T-like duality in the partition function for $H^{(g)}$. We then compute
the partition function on a (4k+2)-dimensional torus highlighting its
dependence on the choice of flux of $H^{(s)}$. Lastly we compute the two-point
function of Wilson Surface operators.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:20:41 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 12:03:45 GMT""}]","2023-04-26"
"2302.10956","Allison Smith","Allison Smith, D. Anish Roshi","A Search for OH 18-cm Emission from Intermediate-Velocity Gas at High
  Galactic Latitudes",,,"10.3847/1538-4357/acbb71",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present search results of 22 high latitude (b > 25 deg.) sightlines for OH
18-cm emission using the 305-m radio telescope at the Arecibo Observatory.
These sightlines appear in neutral hydrogen emission at intermediate velocities
(V_lsr values ranging from -90 to -20 km/s) and are predicted to have a
sufficient molecular composition so as to be detectable in molecular emission.
Such objects, known as Intermediate-Velocity Molecular Clouds (IVMCs), have
historically been detected through 12CO emission. Recent studies indicate that
IVMCs may be widespread in the Galaxy and have important implications for
models of the interstellar medium and star formation. However, we report
non-detections of OH emission toward the 22 sightlines and provide stringent
upper limits on the OH column density. Using available HI and Av data in
combination with existing state-of-the-art PDR models, we estimate H2 column
densities and find that they are more than an order of magnitude lower than the
predicted values. We also find that the hydrogen volume density of these clouds
is less than roughly 25 per cubic centimeter. In addition, we discuss the known
IVMCs with previous 12CO detections in the context of the PDR models. Our
analysis of these clouds indicates that the structure of molecular material in
IVMCs is morphologically clumpy. These results motivate the need for future
sensitive, on-the-fly searches (rather than targeted searches) for CO emission
from IVMCs with of order roughly 1' resolution. High angular resolution (1') HI
and Av data will also be helpful to better constrain the structure and
composition of IVMCs.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:25:19 GMT""}]","2023-05-10"
"2302.10957","Nina Bonaventura","N. Bonaventura, P. Jakobsen, P. Ferruit, S. Arribas, and G. Giardino","The Near-Infrared Spectrograph (NIRSpec) on the James Webb Space
  Telescope V. Optimal algorithms for planning multi-object spectroscopic
  observations",,"A&A 672, A40 (2023)","10.1051/0004-6361/202245403",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  We present an overview of the capabilities and key algorithms employed in the
so-called eMPT software suite developed for planning scientifically optimized,
multi-object spectroscopic (MOS) observations with the Micro-Shutter Array
(MSA) of the Near-Infrared Spectrograph (NIRSpec) instrument on board the James
Webb Space Telescope (JWST), the first multi-object spectrograph to operate in
space. NIRSpec MOS mode is enabled by a programmable MSA, a regular grid of
~250,000 individual apertures that projects to a static, semi-regular pattern
of available slits on the sky and makes the planning and optimization of an MSA
observation a rather complex task. As such, the eMPT package is offered to the
NIRSpec user community as a supplement to the MSA Planning Tool (MPT) included
in the STScI Astronomer's Proposal Tool (APT) to assist in the planning of
NIRSpec MOS proposals requiring advanced functionality to meet ambitious
science goals. The eMPT produces output that can readily be imported and
incorporated into the user's observing program within the APT to generate a
customized MPT MOS observation. Furthermore, its novel algorithms and modular
approach make it highly flexible and customizable, providing users the option
to finely control the workflow and even insert their own software modules to
tune their MSA slit masks to the particular scientific objectives at hand.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:26:00 GMT""}]","2023-03-29"
"2302.10958","Simon Streib","Simon Streib, Ramon Cardias, Manuel Pereiro, Anders Bergman, Erik
  Sj\""oqvist, Anna Delin, Olle Eriksson, Danny Thonig","Adiabatic magnon spectra with and without constraining field: Benchmark
  against an exact magnon spectrum","10 pages, 3 figures",,,,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The spectrum of magnon excitations in magnetic materials can be obtained
exactly from the transverse dynamic magnetic susceptibility, which is however
in practice numerically expensive. Many ab initio approaches therefore consider
instead the adiabatic magnon spectrum, which assumes a separation of time
scales of magnons and electronic excitations. There exist two alternative
implementations for adiabatic magnon spectra: one based on the magnetic force
theorem (MFT) and the other with a constraining field that enforces static
non-collinear spin configurations. We benchmark both implementations against
the exact magnon spectrum of an exactly solvable mean-field model. While both
adiabatic methods are equally valid in the low magnon energy and strong Stoner
coupling limits, we find that the constraining field method performs better
than the MFT in both the cases of strong Stoner coupling and high magnon
energies,while the MFT performs better for combined weak coupling and low
magnon energies.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:30:58 GMT""}]","2023-02-23"
"2302.10959","Wenqi Cao","Wenqi Cao, Gianluigi Pillonetto","Dealing with Collinearity in Large-Scale Linear System Identification
  Using Gaussian Regression","arXiv admin note: text overlap with arXiv:2203.13633",,,,"stat.ML cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many problems arising in control require the determination of a mathematical
model of the application. This has often to be performed starting from
input-output data, leading to a task known as system identification in the
engineering literature. One emerging topic in this field is estimation of
networks consisting of several interconnected dynamic systems. We consider the
linear setting assuming that system outputs are the result of many correlated
inputs, hence making system identification severely ill-conditioned. This is a
scenario often encountered when modeling complex cybernetics systems composed
by many sub-units with feedback and algebraic loops. We develop a strategy cast
in a Bayesian regularization framework where any impulse response is seen as
realization of a zero-mean Gaussian process. Any covariance is defined by the
so called stable spline kernel which includes information on smooth exponential
decay. We design a novel Markov chain Monte Carlo scheme able to reconstruct
the impulse responses posterior by efficiently dealing with collinearity. Our
scheme relies on a variation of the Gibbs sampling technique: beyond
considering blocks forming a partition of the parameter space, some other
(overlapping) blocks are also updated on the basis of the level of collinearity
of the system inputs. Theoretical properties of the algorithm are studied
obtaining its convergence rate. Numerical experiments are included using
systems containing hundreds of impulse responses and highly correlated inputs.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:35:47 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 05:58:25 GMT""}]","2023-03-01"
"2302.10960","Klaus Dolag","Klaus Dolag, Jenny G. Sorce, Sergey Pilipenko, Elena
  Hern\'andez-Mart\'inez, Milena Valentini, Stefan Gottl\""ober, Nabila Aghanim
  and Ildar Khabibullin","Simulating the LOcal Web (SLOW): I. Anomalies in the local density field","15 pages, 11 figure, submitted to A&A, comments welcome",,,,"astro-ph.CO astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Context: Several observations of the local Universe (LU) point towards the
existence of very prominent structures. The presence of massive galaxy clusters
and local super clusters on the one hand, but also large local voids and
under-densities on the other hand. However, it is highly non trivial to connect
such different observational selected tracers to the underlying dark matter
(DM) distribution. Methods (abridged): We used a 500 Mpc/h large constrained
simulation of the LU with initial conditions based on peculiar velocities
derived from the CosmicFlows-2 catalogue and follow galaxy formation physics
directly in the hydro-dynamical simulations to base the comparison on stellar
masses of galaxies or X-ray luminosity of clusters. We also used the 2668 Mpc/h
large cosmological box from the Magneticum simulations to evaluate the
frequency of finding such anomalies in random patches within simulations.
Results: We demonstrate that haloes and galaxies in our constrained simulation
trace the local DM density field very differently. Thereby, this simulation
reproduces the observed 50% under-density of galaxy clusters and groups within
the sphere of ~100 Mpc when applying the same mass or X-ray luminosity limit
used in the observed cluster sample (CLASSIX), which is consistent with a
~1.5$\sigma$ feature. At the same time, the simulation reproduces the observed
over-density of massive galaxy clusters within the same sphere, which on its
own also corresponds to a ~1.5$\sigma$ feature. Interestingly, we find that
only 44 out of 15635 random realizations (i.e. 0.28%) are matching both
anomalies, making the LU to be a ~3$\sigma$ environment. We finally compared a
mock galaxy catalogue with the observed distribution of galaxies in the LU,
finding also a match to the observed factor of two over-density at ~16 Mpc as
well as the observed 15% under-density at ~40 Mpc distance.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:41:04 GMT""}]","2023-02-23"
"2302.10961","Markus Janson","Markus Janson, Jayshil Patel, Simon C. Ringqvist, Cicero Lu, Isabel
  Rebollido, Tim Lichtenberg, Alexis Brandeker, Daniel Angerhausen, Lena Noack","Imaging of exocomets with infrared interferometry","17 pages, 11 figures, accepted for publication in A&A","A&A 671, A114 (2023)","10.1051/0004-6361/202245402",,"astro-ph.EP astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active comets have been detected in several exoplanetary systems, although so
far only indirectly, when the dust or gas in the extended coma has transited in
front of the stellar disk. The large optical surface and relatively high
temperature of an active cometary coma also makes it suitable to study with
direct imaging, but the angular separation is generally too small to be
reachable with present-day facilities. However, future imaging facilities with
the ability to detect terrestrial planets in the habitable zones of nearby
systems will also be sensitive to exocomets in such systems. Here we examine
several aspects of exocomet imaging, particularly in the context of the Large
Interferometer for Exoplanets (LIFE), which is a proposed space mission for
infrared imaging and spectroscopy through nulling interferometry. We study what
capabilities LIFE would have for acquiring imaging and spectroscopy of
exocomets, based on simulations of the LIFE performance as well as statistical
properties of exocomets that have recently been deduced from transit surveys.
We find that for systems with extreme cometary activities such as beta
Pictoris, sufficiently bright comets may be so abundant that they overcrowd the
LIFE inner field of view. More nearby and moderately active systems such as
epsilon Eridani or Fomalhaut may turn out to be optimal targets. If the
exocomets have strong silicate emission features, such as in comet Hale-Bopp,
it may become possible to study the mineralogy of individual exocometary
bodies. We also discuss the possibility of exocomets as false positives for
planets, with recent deep imaging of alpha Centauri as one hypothetical
example. Such contaminants could be common, primarily among young debris disk
stars, but should be rare among the main sequence population. We discuss
strategies to mitigate the risk of any such false positives.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:41:57 GMT""}]","2023-03-15"
"2302.10962","Jaime Andr\'es Rosales Guzm\'an","J. A. Rosales, R. E. Mennickent, G. Djura\v{s}evi\'c, I. Araya, M.
  Cur\'e, D. R. G. Schleicher, J. Petrovi\'c","V4142 Sgr: a Double Periodic Variable with an accretor surrounded by the
  accretion-disk's atmosphere",,"Astronomy & Astrophysics,670,2023,A94","10.1051/0004-6361/202244046",,"astro-ph.SR","http://creativecommons.org/publicdomain/zero/1.0/","  Context: A detailed study of the close interacting binary V4142\,Sgr based on
photometric and spectroscopic analysis is presented.This system belongs to the
enigmatic class of Algol-like variables showing a long photometric cycle of
unknown nature. Aims: Performing photometric data-mining and spectroscopic
observations covering the orbital cycle, we obtain the orbital parameters and
the stellar properties of the binary system, along with the physical properties
of the accretion disk located around the hot star. Insights on the evolutive
path of the system are obtained. Methods: The light curve was modeled through
an inverse modeling method using a theoretical light curve of the binary
system, considering the light curve contribution of both stars and the
accretion disk of the hot star to obtain the fundamental parameters. To
constrain the main stellar parameters the mass ratio was fixed, as well as the
donor temperature using the obtained values from our spectroscopic analysis
including deblending methods to isolate the spectral lines of the stellar
components. The system parameters were compared with a grid of binary star
evolutive models in order to get insights on the evolutionary history of the
system. Results: The orbital period and the long cycle were re-calculated and
found to be of $30.633 \pm 0.002 ~\mathrm{days}$ and $1201 \pm 14
~\mathrm{days}$. The spectral analysis reveals H$\alpha$ double emission with a
persistent $V \leq R$ asymmetry which is considered evidence of a possible wind
emergin from the hotspot region...
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:46:24 GMT""}]","2023-02-23"
"2302.10963","Jianhao Ma","Jianhao Ma, Salar Fattahi","On the Optimization Landscape of Burer-Monteiro Factorization: When do
  Global Solutions Correspond to Ground Truth?",,,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In low-rank matrix recovery, the goal is to recover a low-rank matrix, given
a limited number of linear and possibly noisy measurements. Low-rank matrix
recovery is typically solved via a nonconvex method called Burer-Monteiro
factorization (BM). If the rank of the ground truth is known, BM is free of
sub-optimal local solutions, and its true solutions coincide with the global
solutions -- that is, the true solutions are identifiable. When the rank of the
ground truth is unknown, it must be over-estimated, giving rise to an
over-parameterized BM. In the noiseless regime, it is recently shown that
over-estimation of the rank leads to progressively fewer sub-optimal local
solutions while preserving the identifiability of the true solutions. In this
work, we show that with noisy measurements, the global solutions of the
over-parameterized BM no longer correspond to the true solutions, essentially
transmuting over-parameterization from blessing to curse. In particular, we
study two classes of low-rank matrix recovery, namely matrix completion and
matrix sensing. For matrix completion, we show that even if the rank is only
slightly over-estimated and with very mild assumptions on the noise, none of
the true solutions are local or global solutions. For matrix sensing, we show
that to guarantee the correspondence between global and true solutions, it is
necessary and sufficient for the number of samples to scale linearly with the
over-estimated rank, which can be drastically larger than its optimal sample
complexity that only scales with the true rank.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:47:31 GMT""}]","2023-02-23"
"2302.10964","Tianjiao Yu","Tianjiao Yu, Sukrit Venkatagiri, Ismini Lourentzou, Kurt Luther","Sedition Hunters: A Quantitative Study of the Crowdsourced Investigation
  into the 2021 U.S. Capitol Attack","This work is accepted by The ACM WebConf (WWW 2023)",,"10.1145/3543507.3583514",,"cs.HC cs.LG cs.SI","http://creativecommons.org/licenses/by/4.0/","  Social media platforms have enabled extremists to organize violent events,
such as the 2021 U.S. Capitol Attack. Simultaneously, these platforms enable
professional investigators and amateur sleuths to collaboratively collect and
identify imagery of suspects with the goal of holding them accountable for
their actions. Through a case study of Sedition Hunters, a Twitter community
whose goal is to identify individuals who participated in the 2021 U.S. Capitol
Attack, we explore what are the main topics or targets of the community, who
participates in the community, and how. Using topic modeling, we find that
information sharing is the main focus of the community. We also note an
increase in awareness of privacy concerns. Furthermore, using social network
analysis, we show how some participants played important roles in the
community. Finally, we discuss implications for the content and structure of
online crowdsourced investigations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:47:43 GMT""}]","2023-02-23"
"2302.10965","Vedran Brdar","Vedran Brdar, Andr\'e de Gouv\^ea, Ying-Ying Li, Pedro A. N. Machado","The Neutrino Magnetic Moment Portal and Supernovae: New Constraints and
  Multimessenger Opportunities","8 pages, 6 figures","Phys. Rev. D 107, 073005 (2023)","10.1103/PhysRevD.107.073005","FERMILAB-PUB-23-063-T, NUHEP-TH/23-01, CERN-TH-2023-024,
  USTC-ICTS/PCFT-23-06","hep-ph astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We scrutinize the hypothesis that gauge singlet fermions -- sterile neutrinos
-- interact with Standard Model particles through the transition magnetic
moment portal. These interactions lead to the production of sterile neutrinos
in supernovae followed by their decay into photons and active neutrinos which
can be detected at $\gamma$-ray telescopes and neutrino detectors,
respectively. We find that the non-observation of active neutrinos and photons
from sterile-neutrino decay associated to SN1987A yields the strongest
constraints to date on magnetic-moment-coupled sterile neutrinos if their
masses are inside a $0.1-100$ MeV window. Assuming a near-future galactic
supernova explosion, we estimate the sensitivity of several present and
near-future experiments, including Fermi-LAT, e-ASTROGAM, DUNE, and
Hyper-Kamiokande, to magnetic-moment-coupled sterile neutrinos. We also study
the diffuse photon and neutrino fluxes produced in the decay of magnetic-moment
coupled sterile neutrinos produced in all past supernova explosions and find
that the absence of these decay daughters yields the strongest constraints to
date for sterile neutrino masses inside a $1-100$ keV window.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:49:43 GMT""},{""version"":""v2"",""created"":""Fri, 21 Apr 2023 15:09:38 GMT""}]","2023-04-24"
"2302.10966","Nuno Barros e S\'a","Nuno Barros e S\'a","Dirac bracket and time dependent constraints","11 pages, 1 figure",,,,"gr-qc math-ph math.MP quant-ph","http://creativecommons.org/licenses/by/4.0/","  We provide a compact derivation of the Dirac bracket and of the equations of
motion for second class constrained systems when the constraints are time
dependent. The examples of Parameterized Mechanics and of General Relativity
after gauge fixing are given, and the need for the use of time dependent gauge
fixing conditions in these examples is illustrated geometrically.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:50:09 GMT""}]","2023-02-23"
"2302.10967","Peter Bruin","Peter Bruin and Irati Manterola Ayala","Counting rational points on weighted projective spaces over number
  fields","27 pages, 2 figures",,,,"math.NT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deng (arXiv:math/9812082) gave an asymptotic formula for the number of
rational points on a weighted projective space over a number field with respect
to a certain height function. We prove a generalization of Deng's result
involving a morphism between weighted projective spaces, allowing us to count
rational points whose image under this morphism has bounded height. This method
provides a more general and simpler proof for a result of the first-named
author and Najman on counting elliptic curves with prescribed level structures
over number fields. We further include some examples of applications to modular
curves.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:52:35 GMT""}]","2023-02-23"
"2302.10968","F. D. M. Haldane","F. D. M. Haldane","Two-dimensional inversion symmetry as the fundamental symmetry of
  incompressible quantum Hall fluids","4 pages",,,,"cond-mat.mes-hall cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two dimensional inversion symmetry ($180^{\circ}$ rotations in the ``Hall
plane'' that hosts the incompressible electron fluid that exhibits the
quantized Hall effect) is identified as its fundamental unbroken symmetry. A
consequence is that the integers $p$ and $q$ which define both the Landau level
filling factor $\nu$ = $p/q$ and the elementary fractional charge $\pm e/q$ of
topological excitations, cannot have a common divisor greater than 2.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:54:28 GMT""}]","2023-02-23"
"2302.10969","Jacquelyn Schmidt","Brooke E. Mason, Jacquelyn Schmidt, Branko Kerkez","Measuring city-scale green infrastructure drawdown dynamics using
  internet-connected sensors in Detroit","12 pages, 6 figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  The impact of green infrastructure (GI) on the urban drainage landscape
remains largely unmeasured at high temporal and spatial scales. To that end, a
data toolchain is introduced, underpinned by a novel wireless sensor network
for continuously measuring real-time water levels in GI. The internet-connected
sensors enable the collection of high-resolution data across large regions. A
case study in Detroit (MI, US) is presented, where the water levels of 14 GI
sites were measured in-situ from June to September 2021. The large dataset is
analyzed using an automated storm segmentation methodology, which automatically
extracts and analyzes individual storms from measurement time series. Storms
are used to parameterize a dynamical system model of GI drawdown dynamics. The
model is completely described by the decay constant {\alpha}, which is directly
proportional to the drawdown rate. The parameter is analyzed across storms to
compare GI dynamics between sites and to determine the major design and
physiographic features that drive drawdown dynamics. A correlation analysis
using Spearman's rank correlation coefficient reveals that depth to
groundwater, imperviousness, longitude, and drainage area to surface area ratio
are the most important features explaining GI drawdown dynamics in Detroit. A
discussion is provided to contextualize these finding and explore the
implications of data-driven strategies for GI design and placement.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:56:12 GMT""}]","2023-02-23"
"2302.10970","Nikita Morozov","Nikita Morozov, Denis Rakitin, Oleg Desheulin, Dmitry Vetrov, Kirill
  Struminsky","Differentiable Rendering with Reparameterized Volume Sampling","Preprint",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In view synthesis, a neural radiance field approximates underlying density
and radiance fields based on a sparse set of scene pictures. To generate a
pixel of a novel view, it marches a ray through the pixel and computes a
weighted sum of radiance emitted from a dense set of ray points. This rendering
algorithm is fully differentiable and facilitates gradient-based optimization
of the fields. However, in practice, only a tiny opaque portion of the ray
contributes most of the radiance to the sum. We propose a simple end-to-end
differentiable sampling algorithm based on inverse transform sampling. It
generates samples according to the probability distribution induced by the
density field and picks non-transparent points on the ray. We utilize the
algorithm in two ways. First, we propose a novel rendering approach based on
Monte Carlo estimates. This approach allows for evaluating and optimizing a
neural radiance field with just a few radiance field calls per ray. Second, we
use the sampling algorithm to modify the hierarchical scheme proposed in the
original NeRF work. We show that our modification improves reconstruction
quality of hierarchical models, at the same time simplifying the training
procedure by removing the need for auxiliary proposal network losses.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:56:50 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 14:15:16 GMT""}]","2023-05-11"
"2302.10971","Ian Gullett","Ian Gullett, Bradford Benson, Robert Besuner, Richard Bihary, John
  Carlstrom, Nick Emerson, Patricio A. Gallardo, Jillian Gomez, Cesiley L.
  King, Jeff Mcmahon, Jared L. May, Johanna M. Nagy, Tyler Natoli, Michael D.
  Niemack, Kate Okun, Stephen Padin, John E. Ruhl, Edward J. Wollack, Jeff
  Zivick","Sidelobe Modeling and Mitigation for a Three Mirror Anastigmat Cosmic
  Microwave Background Telescope","14 pages, 8 figures","Appl. Opt. 62, 4334-4341 (2023)","10.1364/AO.488454",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Telescopes measuring cosmic microwave background (CMB) polarization on large
angular scales require exquisite control of systematic errors to ensure the
fidelity of the cosmological results. In particular, far-sidelobe contamination
from wide angle scattering is a potentially prominent source of systematic
error for large aperture microwave telescopes. Here we describe and demonstrate
a ray-tracing-based modeling technique to predict far sidelobes for a Three
Mirror Anistigmat (TMA) telescope designed to observe the CMB from the South
Pole. Those sidelobes are produced by light scattered in the receiver optics
subsequently interacting with the walls of the surrounding telescope enclosure.
After comparing simulated sidelobe maps and angular power spectra for different
enclosure wall treatments, we propose a highly scattering surface that would
provide more than an order of magnitude reduction in the degree-scale
far-sidelobe contrast compared to a typical reflective surface. We conclude by
discussing the fabrication of a prototype scattering wall panel and presenting
measurements of its angular scattering profile.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:01:57 GMT""},{""version"":""v2"",""created"":""Tue, 7 Mar 2023 15:23:23 GMT""},{""version"":""v3"",""created"":""Fri, 26 May 2023 01:20:32 GMT""}]","2023-06-07"
"2302.10972","Milo\v{s} Stojakovi\'c","Eric Duch\^ene, Valentin Gledel, Fionn Mc Inerney, Nicolas Nisse,
  Nacim Oijid, Aline Parreau, Milo\v{s} Stojakovi\'c","Complexity of Maker-Breaker Games on Edge Sets of Graphs",,,,,"cs.CC cs.DM","http://creativecommons.org/licenses/by/4.0/","  We initiate the study of the algorithmic complexity of Maker-Breaker games
played on edge sets of graphs for general graphs. We mainly consider three of
the big four such games: the connectivity game, perfect matching game, and
$H$-game. Maker wins if she claims the edges of a spanning tree in the first, a
perfect matching in the second, and a copy of a fixed graph $H$ in the third.
We prove that deciding who wins the perfect matching game and the $H$-game is
PSPACE-complete, even for the latter in graphs of small diameter if $H$ is a
tree. Seeking to find the smallest graph $H$ such that the $H$-game is
PSPACE-complete, we also prove that there exists such an $H$ of order 51 and
size 57.
  On the positive side, we show that the connectivity game and arboricity-$k$
game are polynomial-time solvable. We then give several positive results for
the $H$-game, first giving a structural characterization for Breaker to win the
$P_4$-game, which gives a linear-time algorithm for the $P_4$-game. We provide
a structural characterization for Maker to win the $K_{1,\ell}$-game in trees,
which implies a linear-time algorithm for the $K_{1,\ell}$-game in trees.
Lastly, we prove that the $K_{1,\ell}$-game in any graph, and the $H$-game in
trees are both FPT parameterized by the length of the game. We leave the
complexity of the last of the big four games, the Hamiltonicity game, as an
open question.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:10:35 GMT""}]","2023-02-23"
"2302.10973","Luigi Giannelli","Luigi Giannelli, Elisabetta Paladino, Miroslav Grajcar, Gheorghe Sorin
  Paraoanu, and Giuseppe Falci","Detecting virtual photons in ultrastrongly coupled superconducting
  quantum circuits","16 pages, 9 figures",,,,"quant-ph cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Light-matter interaction, and understanding the fundamental physics behind,
is essential for emerging quantum technologies. Solid-state devices may explore
new regimes where coupling strengths are ""ultrastrong"", i.e. comparable to the
energies of the subsystems. New exotic phenomena occur the common root of many
of them being the fact that the entangled vacuum contains virtual photons. They
herald the lack of conservation of the number of excitations which is the
witness of ultrastrong coupling breaking the U(1) symmetry. Despite more than a
decade of research, the detection of ground-state virtual photons still awaits
demonstration. In this work, we provide a solution for this long-standing
problem. Facing the main experimental obstacles, we find a design of an
unconventional ""light fluxonium""-like superconducting quantum circuit
implemented by superinductors and a protocol of coherent amplification which
yields a highly efficient, faithful and selective conversion of virtual photons
into real ones. This enables their detection with resources available to
present-day quantum technologies.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:19:04 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 09:38:32 GMT""}]","2023-05-17"
"2302.10974","Danis Badrtdinov","Danis I. Badrtdinov, Georgy V. Pushkarev, Mikhail I. Katsnelson,
  Alexander N. Rudenko","Electron transport and scattering mechanisms in ferromagnetic monolayer
  Fe$_3$GeTe$_2$","10 pages, 8 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  We study intrinsic charge-carrier scattering mechanisms and determine their
contribution to the transport properties of the two-dimensional ferromagnet
Fe$_3$GeTe$_2$. We use state-of-the-art first-principles calculations combined
with the model approaches to elucidate the role of the electron-phonon and
electron-magnon interactions in the electronic transport. Our findings show
that the charge carrier scattering in Fe$_3$GeTe$_2$ is dominated by the
electron-phonon interaction, while the role of magnetic excitations is
marginal. At the same time, the magnetic ordering is shown to effect
essentially on the electron-phonon coupling and its temperature dependence.
This leads to a sublinear temperature dependence of the electrical resistivity
near the Curie temperature, which is in line with experimental observations.
The room temperature resistivity is estimated to be $\sim$35 $\mu \Omega
\cdot$cm which may be considered as an intrinsic limit for monolayer
Fe$_3$GeTe$_2$.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:20:12 GMT""}]","2023-02-23"
"2302.10975","Felix Fiedler","Felix Fiedler and Sergio Lucia","Improved uncertainty quantification for neural networks with Bayesian
  last layer","12 pages, 6 figures, 2 tables. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible",,,,"cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncertainty quantification is an essential task in machine learning - a task
in which neural networks (NNs) have traditionally not excelled. Bayesian neural
networks (BNNs), in which parameters and predictions are probability
distributions, can be a remedy for some applications, but often require
expensive sampling for training and inference. NNs with Bayesian last layer
(BLL) are simplified BNNs where only the weights in the last layer and the
predictions follow a normal distribution. They are conceptually related to
Bayesian linear regression (BLR) which has recently gained popularity in
learning based-control under uncertainty. Both consider a non-linear feature
space which is linearly mapped to the output, and hyperparameters, for example
the noise variance, For NNs with BLL, these hyperparameters should include the
deterministic weights of all other layers, as these impact the feature space
and thus the predictive performance. Unfortunately, the marginal likelihood is
expensive to evaluate in this setting and prohibits direct training through
back-propagation. In this work, we present a reformulation of the BLL
log-marginal likelihood, which considers weights in previous layers as
hyperparameters and allows for efficient training through back-propagation.
Furthermore, we derive a simple method to improve the extrapolation uncertainty
of NNs with BLL. In a multivariate toy example and in the case of a dynamic
system identification task, we show that NNs with BLL, trained with our
proposed algorithm, outperform standard BLR with NN features.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:23:56 GMT""}]","2023-02-23"
"2302.10978","Sudipta Kar","Christopher Richardson, Sudipta Kar, Anjishnu Kumar, Anand
  Ramachandran, Omar Zia Khan, Zeynab Raeesy, Abhinav Sethy","Learning to Retrieve Engaging Follow-Up Queries","EACL 2023",,,,"cs.CL cs.AI cs.IR cs.LG","http://creativecommons.org/licenses/by-sa/4.0/","  Open domain conversational agents can answer a broad range of targeted
queries. However, the sequential nature of interaction with these systems makes
knowledge exploration a lengthy task which burdens the user with asking a chain
of well phrased questions. In this paper, we present a retrieval based system
and associated dataset for predicting the next questions that the user might
have. Such a system can proactively assist users in knowledge exploration
leading to a more engaging dialog. The retrieval system is trained on a dataset
which contains ~14K multi-turn information-seeking conversations with a valid
follow-up question and a set of invalid candidates. The invalid candidates are
generated to simulate various syntactic and semantic confounders such as
paraphrases, partial entity match, irrelevant entity, and ASR errors. We use
confounder specific techniques to simulate these negative examples on the
OR-QuAC dataset and develop a dataset called the Follow-up Query Bank
(FQ-Bank). Then, we train ranking models on FQ-Bank and present results
comparing supervised and unsupervised approaches. The results suggest that we
can retrieve the valid follow-ups by ranking them in higher positions compared
to confounders, but further knowledge grounding can improve ranking
performance.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:26:23 GMT""}]","2023-02-23"
"2302.10979","Anatoli Afanasjev","A. Taninah and A. V. Afanasjev","Anchor-based optimization of energy density functionals","6 pages, 1 figure and 1 Table, in press as Letter in Phys. Rev. C.
  Includes ""Supplemental-material.pdf"" as a separate file with this submission.
  This file provides technical and numerical details on the anchor-based
  optimization method",,"10.1103/PhysRevC.107.L041301",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  A new anchor-based optimization method of defining the energy density
functionals (EDFs) is proposed. In this approach, the optimization of the
parameters of EDF is carried out for the selected set of spherical anchor
nuclei the physical observables of which are modified by the correction
function which takes into account the global performance of EDF. It is shown
that the use of this approach leads to a substantial improvement in global
description of binding energies for several classes of covariant EDFs. The
computational cost of defining a new functional within this approach is
drastically lower as compared with the one for the optimization which includes
the global experimental data on spherical, transitional and deformed nuclei
into the fitting protocol.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:26:25 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 21:36:13 GMT""}]","2023-04-19"
"2302.10980","Sihui Dai","Sihui Dai, Saeed Mahloujifar, Chong Xiang, Vikash Sehwag, Pin-Yu Chen,
  Prateek Mittal","MultiRobustBench: Benchmarking Robustness Against Multiple Attacks","ICML 2023",,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  The bulk of existing research in defending against adversarial examples
focuses on defending against a single (typically bounded Lp-norm) attack, but
for a practical setting, machine learning (ML) models should be robust to a
wide variety of attacks. In this paper, we present the first unified framework
for considering multiple attacks against ML models. Our framework is able to
model different levels of learner's knowledge about the test-time adversary,
allowing us to model robustness against unforeseen attacks and robustness
against unions of attacks. Using our framework, we present the first
leaderboard, MultiRobustBench, for benchmarking multiattack evaluation which
captures performance across attack types and attack strengths. We evaluate the
performance of 16 defended models for robustness against a set of 9 different
attack types, including Lp-based threat models, spatial transformations, and
color changes, at 20 different attack strengths (180 attacks total).
Additionally, we analyze the state of current defenses against multiple
attacks. Our analysis shows that while existing defenses have made progress in
terms of average robustness across the set of attacks used, robustness against
the worst-case attack is still a big open problem as all existing models
perform worse than random guessing.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:26:39 GMT""},{""version"":""v2"",""created"":""Tue, 23 May 2023 13:54:29 GMT""}]","2023-05-24"
"2302.10982","Kristof Moors","Declan Burke, Dennis Heffels, Kristof Moors, Peter Sch\""uffelgen,
  Detlev Gr\""utzmacher, Malcolm R. Connolly","Robust Majorana bound states in magnetic topological insulator
  nanoribbons with fragile chiral edge channels","5 pages, 4 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnetic topological insulators in the quantum anomalous Hall regime host
ballistic chiral edge channels. When proximitized by an $s$-wave
superconductor, these edge states offer the potential for realizing topological
superconductivity and Majorana bound states without the detrimental effect of
large externally-applied magnetic fields on superconductivity. Realizing
well-separated unpaired Majorana bound states requires magnetic topological
insulator ribbons with width of the order of the transverse extent of the edge
state, however, which brings the required ribbon width down to the sub-100 nm
scale. In this regime, it is known to be extremely difficult to retain the
ballistic nature of chiral edge channels and realize a quantized Hall
conductance. In this work, we study the impact of disorder in such magnetic
topological insulator nanoribbons and compare the fragility of ballistic chiral
edge channels with the stability of Majorana bound states when the ribbon is
covered by a superconducting film. We find that the Majorana bound states
exhibit greater robustness against disorder than the underlying chiral edge
channels.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:30:59 GMT""}]","2023-02-23"
"2302.10984","Ali Norouzifar","Ali Norouzifar and Wil van der Aalst","Discovering Process Models that Support Desired Behavior and Avoid
  Undesired Behavior","Accepted at the SAC 2023 conference
  (https://www.sigapp.org/sac/sac2023/) and to be published in their
  proceedings",,"10.1145/3555776.3577818",,"cs.DB cs.FL","http://creativecommons.org/licenses/by/4.0/","  Process discovery is one of the primary process mining tasks and starting
point for process improvements using event data. Existing process discovery
techniques aim to find process models that best describe the observed behavior.
The focus can be on recall (i.e., replay fitness) or precision. Here, we take a
different perspective. We aim to discover a process model that allows for the
good behavior observed, and does not allow for the bad behavior. In order to do
this, we assume that we have a desirable event log ($L^+$) and an undesirable
event log ($L^-$). For example, the desirable event log consists of the cases
that were handled within two weeks, and the undesirable event log consists of
the cases that took longer. Our discovery approach explores the tradeoff
between supporting the cases in the desirable event log and avoiding the cases
in the undesirable event log. The proposed framework uses a new inductive
mining approach that has been implemented and tested on several real-life event
logs. Experimental results show that our approach outperforms other approaches
that use only the desirable event log ($L^+$). This supports the intuitive
understanding that problematic cases can and should be used to improve
processes.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:35:17 GMT""}]","2023-02-23"
"2302.10985","Maria Tamargo","Kaushini S. Wickramasinghe, Candice Forrester, Maria C. Tamargo","Molecular Beam Epitaxy of Twin-Free Bi2Se3 and Sb2Te3 on
  In2Se3/InP(111)B Virtual Substrates","Main manuscript has 27 pages and 7 figures. Supplementary information
  has 3 pages and 3 figures",,,,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Three-dimensional topological insulators (3D-TIs) are a new generation of
materials with insulating bulk and exotic metallic surface states that
facilitate a wide variety of ground-breaking applications. However, utilization
of the surface channels is often hampered by the presence of crystal defects,
such as antisites, vacancies and twin domains. For terahertz device
applications, twinning is shown to be highly deleterious. Previous attempts to
reduce twins using technologically important InP(111) substrates have been
promising, but have failed to completely suppress twin domains while preserving
high structural quality. Here we report growth of twin-free molecular beam
epitaxial Bi2Se3 and Sb2Te3 structures on ultra-thin In2Se3 layers formed by a
novel selenium passivation technique during the oxide desorption of smooth,
non-vicinal InP(111)B substrates, without the use of an indium source. The
formation of un-twinned In2Se3 provides a favorable template to fully suppress
twin domains in 3D-TIs, greatly broadening novel device applications in the
terahertz regime.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:35:53 GMT""}]","2023-02-23"
"2302.10989","Marc Schiffer","Gustavo P. de Brito, Benjamin Knorr, and Marc Schiffer","On the weak-gravity bound for a shift-symmetric scalar field","32 pages, 23 figures",,,"NORDITA 2023-005","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The weak-gravity bound has been discovered in several asymptotically safe
gravity-matter systems. It limits the strength of gravitational fluctuations
that are compatible with an ultraviolet-complete matter sector, and results
from the collision of two partial fixed points of the matter system as a
function of the strength of the gravitational interactions. In this paper, we
will investigate this mechanism in detail for a shift-symmetric scalar field.
First, we will study the fixed point structure of the scalar system without
gravity. We find indications that the Gaussian fixed point is the only viable
fixed point, suggesting that a weak-gravity bound resulting from the collision
of two partial fixed points is a truncation artefact. We will then couple the
scalar system to gravity and perform different expansions to track the Gaussian
fixed point as gravitational fluctuations become stronger. We also introduce a
new notion of the weak-gravity bound that is based on the number of relevant
operators.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:38:37 GMT""}]","2023-02-23"
"2302.10990","Rodrigo A. H. M. Cabral","Rodrigo A. H. M. Cabral and Severino T. Melo","A characterization of Rieffel's deformed algebra as Heisenberg smooth
  operators","18 pages",,,,"math.OA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $\mathcal{C}$ be a unital C$^*$-algebra and $E_n$ be the Hilbert
$\mathcal{C}$-module defined as the completion of the $\mathcal{C}$-valued
Schwartz function space $\mathcal{S}^\mathcal{C}(\mathbb{R}^n)$ with respect to
the norm $\|f\|_2 := \left\| \int_{\mathbb{R}^n} f(x)^*f(x) \, dx
\right\|_\mathcal{C}^{1 / 2}$. Also, let $\text{Ad }\mathcal{U}$ be the
canonical action of the $(2n + 1)$-dimensional Heisenberg group by conjugation
on the algebra of adjointable operators on $E_n$ and let $J$ be a
skew-symmetric linear transformation on $\mathbb{R}^n$. We characterize the
smooth vectors under $\text{Ad }\mathcal{U}$ which commute with a certain
algebra of right multiplication operators $R_h$, with $h \in
\mathcal{S}^\mathcal{C}(\mathbb{R}^n)$, where the product is ""twisted"" with
respect to $J$ according to a deformation quantization procedure introduced by
M.A. Rieffel. More precisely, we establish that they coincide with the
corresponding algebra of left multiplication operators, as conjectured by
Rieffel.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:38:47 GMT""}]","2023-02-23"
"2302.10991","Elias Gr\""unewald","Elias Gr\""unewald, Johannes M. Halkenh\""au{\ss}er, Nicola Leschke,
  Johanna Washington, Cristina Paupini, Frank Pallas","Enabling Versatile Privacy Interfaces Using Machine-Readable
  Transparency Information","Preprint, accepted to the Privacy Symposium 2023
  https://privacysymposium.org/",,,,"cs.SE cs.CR cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transparency regarding the processing of personal data in online services is
a necessary precondition for informed decisions on whether or not to share
personal data. In this paper, we argue that privacy interfaces shall
incorporate the context of display, personal preferences, and individual
competences of data subjects following the principles of universal design and
usable privacy. Doing so requires -- among others -- to consciously decouple
the provision of transparency information from their ultimate presentation. To
this end, we provide a general model of how transparency information can be
provided from a data controller to data subjects, effectively leveraging
machine-readable transparency information and facilitating versatile
presentation interfaces. We contribute two actual implementations of said
model: 1) a GDPR-aligned privacy dashboard and 2) a chatbot and virtual voice
assistant enabled by conversational AI. We evaluate our model and
implementations with a user study and find that these approaches provide
effective and time-efficient transparency. Consequently, we illustrate how
transparency can be enhanced using machine-readable transparency information
and how data controllers can meet respective regulatory obligations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:40:26 GMT""},{""version"":""v2"",""created"":""Mon, 17 Apr 2023 14:36:49 GMT""}]","2023-04-18"
"2302.10992","Ben Hastings","Ben Hastings, Norbert Langer, Joachim Puls","A model of anisotropic winds from rotating stars for evolutionary
  calculations","Accepted for publication in A&A. 12 pages","A&A 672, A60 (2023)","10.1051/0004-6361/202245281",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Context: The surface properties of rotating stars can vary from pole to
equator, resulting in anisotropic stellar winds which are not included in the
currently available evolutionary models.
  Aims: We develop a formalism to describe the mass and angular momentum loss
of rotating stars which takes into account both the varying surface properties
and distortion due to rotation.
  Methods: Adopting the mass-loss recipe for non-rotating stars, we assigned to
each point on the surface of a rotating star an equivalent non-rotating star,
for which the surface mass flux is given by the recipe. The global mass-loss
and angular momentum loss rates are then given by integrating over the deformed
stellar surface as appropriate. Evolutionary models were computed and our
prescription is compared to the currently used simple mass-loss enhancement
recipes for rotating stars.
  Results: We find that mass-loss rates are largely insensitive to rotation for
models not affected by the bi-stability jump. For those affected by the
bi-stability jump, the increase in mass-loss rates with respect to time is
smoothed. As our prescription considers the variation of physical conditions
over the stellar surface, the region affected by the bi-stability jump is able
to grow gradually instead of the whole star suddenly being affected.
  Conclusion: We have provided an easy to implement and flexible, yet
physically meaningful prescription for calculating mass and angular momentum
loss rates of rotating stars in a one-dimensional stellar evolution code which
compares favourably to more physically comprehensive models.
  The implementation of our scheme in the stellar evolution code MESA is
available online: https://zenodo.org/record/7437006
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:41:48 GMT""}]","2023-03-29"
"2302.10993","Ansgar J\""ungel","Ansgar J\""ungel, Stefan Portisch, and Antoine Zurek","A convergent finite-volume scheme for nonlocal cross-diffusion systems
  for multi-species populations",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An implicit Euler finite-volume scheme for a nonlocal cross-diffusion system
on the one-dimensional torus, arising in population dynamics, is proposed and
analyzed. The kernels are assumed to be in detailed balance and satisfy a weak
cross-diffusion condition. The latter condition allows for negative
off-diagonal coefficients and for kernels defined by an indicator function. The
scheme preserves the nonnegativity of the densities, conservation of mass, and
production of the Boltzmann and Rao entropies. The key idea is to ``translate''
the entropy calculations for the continuous equations to the finite-volume
scheme, in particular to design discretizations of the mobilities, which
guarantee a discrete chain rule even in the presence of nonlocal terms. Based
on this idea, the existence of finite-volume solutions and the convergence of
the scheme are proven. As a by-product, we deduce the existence of weak
solutions to the continuous cross-diffusion system. Finally, we present some
numerical experiments illustrating the behavior of the solutions to the
nonlocal and associated local models.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:44:59 GMT""}]","2023-02-23"
"2302.10995","Omur Arslan","\""Om\""ur Arslan and Aykut \.I\c{s}leyen","Vandermonde Trajectory Bounds for Linear Companion Systems","14 pages, 6 figures, submitted to a journal publication",,,,"eess.SY cs.SY math.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fast and accurate safety assessment and collision checking are essential for
motion planning and control of highly dynamic autonomous robotic systems.
Informative, intuitive, and explicit motion trajectory bounds enable
explainable and time-critical safety verification of autonomous robot motion.
In this paper, we consider feedback linearization of nonlinear systems in the
form of proportional-and-higher-order-derivative (PhD) control corresponding to
companion dynamics. We introduce a novel analytic convex trajectory bound,
called $\textit{Vandermonde simplex}$, for high-order companion systems, that
is given by the convex hull of a finite weighted combination of system
position, velocity, and other relevant higher-order state variables. Our
construction of Vandermonde simplexes is built based on expressing the solution
trajectory of companion dynamics in a newly introduced family of
$\textit{Vandermonde basis functions}$ that offer new insights for
understanding companion system motion compared to the classical exponential
basis functions. In numerical simulations, we demonstrate that Vandermonde
simplexes offer significantly more accurate motion prediction (e.g., at least
an order of magnitude improvement in estimated motion volume) for describing
the motion trajectory of companion systems compared to the standard invariant
Lyapunov ellipsoids as well as exponential simplexes built based on exponential
basis functions.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:54:24 GMT""}]","2023-02-23"
"2302.10996","Brent Austgen","Brent Austgen, Erhan Kutanoglu, John J. Hasenbein","A two-stage stochastic programming model for electric substation flood
  mitigation prior to an imminent hurricane","30 pages, 12 figures",,,,"math.OC cs.SY eess.SY","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We present a stochastic programming model for informing the deployment of
temporary flood mitigation measures to protect electrical substations prior to
an imminent and uncertain hurricane. The first stage captures the deployment of
a fixed number of mitigation resources, and the second stage captures grid
operation during a contingency. The primary objective is to minimize expected
load shed. We develop methods for simulating flooding induced by extreme
rainfall and construct two geographically realistic case studies, one based on
Tropical Storm Imelda and the other on Hurricane Harvey. Applying our model to
those case studies, we investigate the effect of the mitigation budget on the
optimal objective value and solutions. Our results highlight the sensitivity of
the optimal mitigation to the budget, a consequence of those decisions being
discrete. We additionally assess the value of having better mitigation options
and the spatial features of the optimal mitigation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:02:51 GMT""}]","2023-02-23"
"2302.10997","Seyyed Ali Emami","Mohsen Zahmatkesh, Seyyed Ali Emami, Afshin Banazadeh, Paolo Castaldi","Robust Auto-landing Control of an agile Regional Jet Using Fuzzy
  Q-learning","32 pages",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  A robust auto-landing problem of a Truss-braced Wing (TBW) regional jet
aircraft with poor stability characteristics is presented in this study
employing a Fuzzy Reinforcement Learning scheme. Reinforcement Learning (RL)
has seen a recent surge in practical uses in control systems. In contrast to
many studies implementing Deep Learning in RL algorithms to generate continuous
actions, the methodology of this study is straightforward and avoids complex
neural network architectures by applying Fuzzy rules. An innovative, agile
civil aircraft is selected not only to meet future aviation community
expectations but also to demonstrate the robustness of the suggested method. In
order to create a multi-objective RL environment, a Six-degree-of-freedom
(6-DoF) simulation is first developed. By transforming the auto-landing problem
of the aircraft into a Markov Decision Process (MDP) formulation, the problem
is solved by designing a low-level Fuzzy Q-learning (FQL) controller. More
specifically, the well-known Q-learning method, which is a discrete RL
algorithm, is supplemented by Fuzzy rules to provide continuous actions with no
need to complex learning structures. The performance of the proposed system is
then evaluated by extensive flight simulations in different flight conditions
considering severe wind gusts, measurement noises, actuator faults, and model
uncertainties. Besides, the controller effectiveness would be compared with
existing competing techniques such as Dynamic Inversion (DI) and Q-learning.
The simulation results indicate the superior performance of the proposed
control system as a reliable and robust control method to be employed in real
applications.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:04:00 GMT""}]","2023-02-23"
"2302.10998","Nursultan Kuanyshov","Nursultan Kuanyshov","On the LS-category of homomorphisms of groups with torsion","9 pages",,,,"math.AT","http://creativecommons.org/licenses/by/4.0/","  We prove the equality $cat(\phi)=cd(\phi)$ for homomorphisms $\phi:\Gamma\to
\Lambda$ of any finitely generated abelian group $\Gamma$.
  In addition, we prove that the Lusternik-Schnirelmann category and the
cohomological dimension of any nonzero homomorphism of a torsion group cannot
be finite.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:04:46 GMT""}]","2023-02-23"
"2302.10999","Seyed Hamidreza Mirpoorian","Seyed Hamidreza Mirpoorian, Zhuangfei Wang, Levon Pogosian","On validity of the quasi-static approximation in scalar-tensor theories","8 pages + Appendix, 3 figures",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The discovery of cosmic acceleration motivated extensive studies of dynamical
dark energy and modified gravity models. Of particular interest are the
scalar-tensor theories, with a scalar field dark energy non-minimally coupled
to matter. Cosmological constraints on these models often employ the
quasi-static approximation (QSA), in which the dynamics of the scalar field
perturbations is proportional to the perturbation in the matter density. Using
the QSA simplifies the physical interpretation of the phenomenology of
scalar-tensor theories, and results in substantial savings of computing time
when deriving parameter constraints. Focusing on the symmetron model, which is
a well-motivated scalar-tensor theory with a screening mechanism, we compare
the exact solution of the linearly perturbed field equations to those obtained
under the QSA and identify the range of the model parameters for which the QSA
is valid. We find that the evolution of background scalar field is most
important, namely, whether it is dominated by the Hubble friction or the scalar
field potential. This helps us derive a criterion for the symmetron model, but
same argument can be applied to other scalar-tensor theories of generalized
Brans-Dicke type. We consider two scenarios, one where the scalar field is only
coupled to dark matter and where it couples to all of the matter.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:05:18 GMT""}]","2023-02-23"
"2302.11000","Hsu Kiang Ooi","Mohammad Sajjad Ghaemi, Hang Hu, Anguang Hu, Hsu Kiang Ooi","CHA2: CHemistry Aware Convex Hull Autoencoder Towards Inverse Molecular
  Design",,,,,"cs.LG cs.AI q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Optimizing molecular design and discovering novel chemical structures to meet
certain objectives, such as quantitative estimates of the drug-likeness score
(QEDs), is NP-hard due to the vast combinatorial design space of discrete
molecular structures, which makes it near impossible to explore the entire
search space comprehensively to exploit de novo structures with properties of
interest. To address this challenge, reducing the intractable search space into
a lower-dimensional latent volume helps examine molecular candidates more
feasibly via inverse design. Autoencoders are suitable deep learning
techniques, equipped with an encoder that reduces the discrete molecular
structure into a latent space and a decoder that inverts the search space back
to the molecular design. The continuous property of the latent space, which
characterizes the discrete chemical structures, provides a flexible
representation for inverse design in order to discover novel molecules.
However, exploring this latent space requires certain insights to generate new
structures. We propose using a convex hall surrounding the top molecules in
terms of high QEDs to ensnare a tight subspace in the latent representation as
an efficient way to reveal novel molecules with high QEDs. We demonstrate the
effectiveness of our suggested method by using the QM9 as a training dataset
along with the Self- Referencing Embedded Strings (SELFIES) representation to
calibrate the autoencoder in order to carry out the Inverse molecular design
that leads to unfold novel chemical structure.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:05:31 GMT""}]","2023-02-23"
"2302.11001","Jaehyeok Lee","Jaehyeok Lee","Tensor enriched categorical generalization of the Eilenberg-Watts
  theorem",,,,,"math.CT math.AC math.RA","http://creativecommons.org/licenses/by/4.0/","  Given monoids $\mathfrak{b}$, $\mathfrak{b}'$ in a B\'{e}nabou cosmos, we
prove that the category of cocontinuous enriched functors between right module
categories is equivalent to the category of
$(\mathfrak{b},\mathfrak{b}')$-bimodules. When the monoids $\mathfrak{b}$,
$\mathfrak{b}'$ are commutative, we further show that the category of
cocontinuous lax tensor enriched functors between right module categories is
equivalent to the category of commutative monoids over $\mathfrak{b}\otimes
\mathfrak{b}'$.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:07:10 GMT""},{""version"":""v2"",""created"":""Wed, 22 Mar 2023 14:38:27 GMT""}]","2023-03-23"
"2302.11002","Danielle Maddix","Derek Hansen, Danielle C. Maddix, Shima Alizadeh, Gaurav Gupta,
  Michael W. Mahoney","Learning Physical Models that Can Respect Conservation Laws","ICML 2023","Proceedings of the 40th International Conference on Machine
  Learning (ICML 2023), PMLR 202",,,"cs.LG cs.NA math.AP math.NA","http://creativecommons.org/licenses/by/4.0/","  Recent work in scientific machine learning (SciML) has focused on
incorporating partial differential equation (PDE) information into the learning
process. Much of this work has focused on relatively ``easy'' PDE operators
(e.g., elliptic and parabolic), with less emphasis on relatively ``hard'' PDE
operators (e.g., hyperbolic). Within numerical PDEs, the latter problem class
requires control of a type of volume element or conservation constraint, which
is known to be challenging. Delivering on the promise of SciML requires
seamlessly incorporating both types of problems into the learning process. To
address this issue, we propose ProbConserv, a framework for incorporating
conservation constraints into a generic SciML architecture. To do so,
ProbConserv combines the integral form of a conservation law with a Bayesian
update. We provide a detailed analysis of ProbConserv on learning with the
Generalized Porous Medium Equation (GPME), a widely-applicable parameterized
family of PDEs that illustrates the qualitative properties of both easier and
harder PDEs. ProbConserv is effective for easy GPME variants, performing well
with state-of-the-art competitors; and for harder GPME variants it outperforms
other approaches that do not guarantee volume conservation. ProbConserv
seamlessly enforces physical conservation constraints, maintains probabilistic
uncertainty quantification (UQ), and deals well with shocks and
heteroscedasticities. In each case, it achieves superior predictive performance
on downstream tasks.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:08:25 GMT""},{""version"":""v2"",""created"":""Sat, 27 May 2023 06:05:04 GMT""},{""version"":""v3"",""created"":""Tue, 6 Jun 2023 06:49:06 GMT""}]","2023-06-07"
"2302.11003","Kyriakos Akos Matszangosz","Thomas Hudson, \'Akos K. Matszangosz and Matthias Wendt","Chow-Witt rings and topology of flag varieties","58 pages",,,,"math.AG math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper computes the Witt-sheaf cohomology rings of partial flag varieties
in type A in terms of the Pontryagin classes of the subquotient bundles. The
proof is based on a Leray-Hirsch-type theorem for Witt-sheaf cohomology for the
maximal rank cases, and a detailed study of cohomology ring presentations and
annihilators of characteristic classes for the general case. The computations
have consequences for the topology of real flag manifolds: we show that all
torsion in the integral cohomology is 2-torsion, which was not known in full
generality previously. This allows for example to compute the Poincar\'e
polynomials of complete flag varieties for cohomology with twisted integer
coefficients. The computations also allow to describe the Chow-Witt rings of
flag varieties, and we sketch an enumerative application to counting flags
satisfying multiple incidence conditions to given hypersurfaces.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:13:51 GMT""}]","2023-02-23"
"2302.11004","Yukun Yue","Franziska Weber, Yukun Yue","On the Convergence of an IEQ-based first-order Numerical Scheme for the
  Beris-Edwards System",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a convergence analysis of an unconditionally energy-stable
first-order semi-discrete numerical scheme designed for a hydrodynamic Q-tensor
model, the so-called Beris-Edwards system, based on the Invariant Energy
Quadratization Method (IEQ). The model consists of the Navier-Stokes equations
for the fluid flow, coupled to the Q-tensor gradient flow describing the liquid
crystal molecule alignment. By using the Invariant Energy Quadratization
Method, we obtain a linearly implicit scheme, accelerating the computational
speed. However, this introduces an auxiliary variable to replace the bulk
potential energy and it is a priori unclear whether the reformulated system is
equivalent to the Beris-Edward system. In this work, we prove stability
properties of the scheme and show its convergence to a weak solution of the
coupled liquid crystal system. We also demonstrate the equivalence of the
reformulated and original systems in the weak sense.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:15:25 GMT""}]","2023-02-23"
"2302.11005","Ulysses Alvarez","Ulysses Alvarez","A topological space associated to corank 1 tropical phased matroids",,,,,"math.CO math.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A consequence of the Folkman-Lawrence topological representation theorem is
that the geometric realization of the order complex of the poset of non-zero
covectors of a loopless rank $n-1$ oriented matroid on $[n]$ is homeomorphic to
an $(n-2)$-sphere. In this paper, we begin the study of an analogous theorem
for tropical phased matroids by proving that the topological order complex for
a loopless rank $n-1$ tropical phased matroid on $[n]$ is homeomorphic to a
$(2n-3)$-sphere.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:17:08 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 20:13:35 GMT""}]","2023-05-22"
"2302.11006","Dongwei Ye","Dongwei Ye, Valeria Krzhizhanovskaya, Alfons G. Hoekstra","Data-driven reduced-order modelling for blood flow simulations with
  geometry-informed snapshots",,,,,"cs.CE cs.LG physics.bio-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Computational fluid dynamics is a common tool in cardiovascular science and
engineering to simulate, predict and study hemodynamics in arteries. However,
owing to the complexity and scale of cardiovascular flow problems, the
evaluation of the model could be computationally expensive, especially in those
cases where a large number of evaluations are required, such as uncertainty
quantification and design optimisation. In such scenarios, the model may have
to be repeatedly evaluated due to the changes or distinctions of simulation
domains. In this work, a data-driven surrogate model is proposed for the
efficient prediction of blood flow simulations on similar but distinct domains.
The proposed surrogate model leverages surface registration to parameterise
those similar but distinct shapes and formulate corresponding hemodynamics
information into geometry-informed snapshots by the diffeomorphism constructed
between the reference domain and target domain. A non-intrusive reduced-order
model for geometrical parameters is subsequently constructed using proper
orthogonal decomposition, and a radial basis function interpolator is trained
for predicting the reduced coefficients of the reduced-order model based on
reduced coefficients of geometrical parameters of the shape. Two examples of
blood flowing through a stenosis and a bifurcation are presented and analysed.
The proposed surrogate model demonstrates its accuracy and efficiency in
hemodynamics prediction and shows its potential application toward real-time
simulation or uncertainty quantification for complex patient-specific
scenarios.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:18:17 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 21:58:26 GMT""}]","2023-03-10"
"2302.11007","Mohammad Mostafanejad","Mohammad Mostafanejad","Unification of popular artificial neural network activation functions",,,,,"cs.LG cs.AI cs.NE math.FA","http://creativecommons.org/licenses/by/4.0/","  We present a unified representation of the most popular neural network
activation functions. Adopting Mittag-Leffler functions of fractional calculus,
we propose a flexible and compact functional form that is able to interpolate
between various activation functions and mitigate common problems in training
neural networks such as vanishing and exploding gradients. The presented gated
representation extends the scope of fixed-shape activation functions to their
adaptive counterparts whose shape can be learnt from the training data. The
derivatives of the proposed functional form can also be expressed in terms of
Mittag-Leffler functions making it a suitable candidate for gradient-based
backpropagation algorithms. By training LeNet-5 neural network on MNIST and
CIFAR-10 datasets, we demonstrate that adopting a unified gated representation
of activation functions offers a promising and affordable alternative to
individual built-in implementations of activation functions in conventional
machine learning frameworks.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:20:59 GMT""}]","2023-02-23"
"2302.11008","Aleksey Sikstel","Jan Giesselmann, Hrishikesh Joshi, Siegfried M\""uller, Aleksey Sikstel","Model adaptation for hyperbolic balance laws",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  In this work, we devise a model adaptation strategy for a class of model
hierarchies consisting of two levels of model complexity. In particular, the
fine model consists of a system of hyperbolic balance laws with stiff reaction
terms and the coarse model consists of a system of hyperbolic conservation
laws. We employ the relative entropy stability framework to obtain an a
posteriori modeling error estimator. The efficiency of the model adaptation
strategy is demonstrated by conducting simulations for chemically reacting
fluid mixtures in one space dimension.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:21:05 GMT""}]","2023-02-23"
"2302.11009","Poonam Yadav Dr","Vijay Kumar, Sam Gunner, Theodoros Spyridopoulos, Antonis Vafeas,
  James Pope, Poonam Yadav, George Oikonomou, Theo Tryfonas","Challenges in the Design and Implementation of IoT Testbeds in
  Smart-Cities: A Systematic Review","25 pages, under review",,,,"cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Advancements in wireless communication and the increased accessibility to
low-cost sensing and data processing IoT technologies have increased the
research and development of urban monitoring systems. Most smart city research
projects rely on deploying proprietary IoT testbeds for indoor and outdoor data
collection. Such testbeds typically rely on a three-tier architecture composed
of the Endpoint, the Edge, and the Cloud. Managing the system's operation
whilst considering the security and privacy challenges that emerge, such as
data privacy controls, network security, and security updates on the devices,
is challenging. This work presents a systematic study of the challenges of
developing, deploying and managing urban monitoring testbeds, as experienced in
a series of urban monitoring research projects, followed by an analysis of the
relevant literature. By identifying the challenges in the various projects and
organising them under the V-model development lifecycle levels, we provide a
reference guide for future projects. Understanding the challenges early on will
facilitate current and future smart-cities IoT research projects to reduce
implementation time and deliver secure and resilient testbeds.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:22:57 GMT""}]","2023-02-23"
"2302.11010","Jonas Antor","Jonas Antor","Formality in the Deligne-Langlands correspondence","31 pages. v2: minor changes",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Deligne-Langlands correspondence parametrizes irreducible representations
of the affine Hecke algebra $\mathcal{H}^{\text{aff}}$ by certain perverse
sheaves. We show that this can be lifted to an equivalence of triangulated
categories. More precisely, we construct for each central character $\chi$ of
$\mathcal{H}^{\text{aff}}$ an equivalence of triangulated categories between a
perfect derived category of dg-modules
$D_{\text{perf}}(\mathcal{H}^{\text{aff}}/(\text{ker}(\chi)) - \text{dgMod})$
and the triangulated category generated by the corresponding perverse sheaves.
The main step in this construction is a formality result that we prove for a
wide range of `Springer sheaves'.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:23:18 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 13:14:34 GMT""}]","2023-03-17"
"2302.11011","Likun Xie","Likun Xie","On an Instance of the Small Cohen-Macaulay Conjecture","4 pages, Typos corrected",,,,"math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide a simplified proof of a theorem proved by Tavanfar and Shimomoto
which states that a quasi-Gorenstein deformation of a $3$-dimensional
quasi-Gorenstein local ring $(A,m,k)$ with $H^2_m(A)=k$ admits a small
Cohen-Macaulay module.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:23:38 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 16:14:18 GMT""}]","2023-04-21"
"2302.11012","Uddeshya Upadhyay","Uddeshya Upadhyay, Jae Myung Kim, Cordelia Schmidt, Bernhard
  Sch\""olkopf, Zeynep Akata","Posterior Annealing: Fast Calibrated Uncertainty for Regression","11 pages, 6 figures, 2 tables",,,,"cs.LG cs.AI cs.CV","http://creativecommons.org/licenses/by/4.0/","  Bayesian deep learning approaches that allow uncertainty estimation for
regression problems often converge slowly and yield poorly calibrated
uncertainty estimates that can not be effectively used for quantification.
Recently proposed post hoc calibration techniques are seldom applicable to
regression problems and often add overhead to an already slow model training
phase. This work presents a fast calibrated uncertainty estimation method for
regression tasks, called posterior annealing, that consistently improves the
convergence of deep regression models and yields calibrated uncertainty without
any post hoc calibration phase. Unlike previous methods for calibrated
uncertainty in regression that focus only on low-dimensional regression
problems, our method works well on a wide spectrum of regression problems. Our
empirical analysis shows that our approach is generalizable to various network
architectures including, multilayer perceptrons, 1D/2D convolutional networks,
and graph neural networks, on five vastly diverse tasks, i.e., chaotic particle
trajectory denoising, physical property prediction of molecules using 3D
atomistic representation, natural image super-resolution, and medical image
translation using MRI images.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:24:35 GMT""}]","2023-02-23"
"2302.11013","Netta Engelhardt","Lisa Yang and Netta Engelhardt","The Complexity of Learning (Pseudo)random Dynamics of Black Holes and
  Other Chaotic Systems","61+15 pages, 1 figure; v2: typos fixed, clarification added",,,,"hep-th gr-qc quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been recently proposed that the naive semiclassical prediction of
non-unitary black hole evaporation can be understood in the fundamental
description of the black hole as a consequence of ignorance of high-complexity
information. Validity of this conjecture implies that any algorithm which is
polynomially bounded in computational complexity cannot accurately reconstruct
the black hole dynamics. In this work, we prove that such bounded quantum
algorithms cannot accurately predict (pseudo)random unitary dynamics, even if
they are given access to an arbitrary set of polynomially complex observables
under this time evolution; this shows that ""learning"" a (pseudo)random unitary
is computationally hard. We use the common simplification of modeling black
holes and more generally chaotic systems via (pseudo)random dynamics. The
quantum algorithms that we consider are completely general, and their attempted
guess for the time evolution of black holes is likewise unconstrained: it need
not be a linear operator, and may be as general as an arbitrary (e.g.
decohering) quantum channel.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:26:25 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 16:11:09 GMT""}]","2023-02-24"
"2302.11014","Sayak Kundu","Chung-Kuan Cheng, Andrew B. Kahng, Sayak Kundu, Yucheng Wang, Zhiang
  Wang","Assessment of Reinforcement Learning for Macro Placement","There are eight pages and one page for reference. It includes five
  figures and seven tables. This paper has been invited to ISPD 2023",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  We provide open, transparent implementation and assessment of Google Brain's
deep reinforcement learning approach to macro placement and its Circuit
Training (CT) implementation in GitHub. We implement in open source key
""blackbox"" elements of CT, and clarify discrepancies between CT and Nature
paper. New testcases on open enablements are developed and released. We assess
CT alongside multiple alternative macro placers, with all evaluation flows and
related scripts public in GitHub. Our experiments also encompass academic
mixed-size placement benchmarks, as well as ablation and stability studies. We
comment on the impact of Nature and CT, as well as directions for future
research.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:26:28 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 18:01:40 GMT""}]","2023-03-29"
"2302.11015","Adam Kasparek","Danuta Kruk, Adam Kasparek, Elzbieta Masiewicz, Karol Kolodziejski,
  Radoslaw Cybulski and Bartosz Nowak","Water Dynamics in Highly Concentrated Protein Systems -- Insight from
  Nuclear Magnetic Resonance Relaxometry","Grant:European Union, Horizon 2020, FETOPEN-2018-2019-2020-01:
  HIRES-MULTIDYN - Multiscale Dynamics with Ultrafast High-Resolution
  Relaxometry (899683) Publication date: 17 February 2023","Int. J. Mol. Sci. 2023, 24(4), 4093","10.3390/ijms24044093",,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  1H spin-lattice relaxation experiments have been performed for water - Bovine
Serum Al-bumin (BSA) mixtures including 20% wt and 40% wt of BSA. The
experiments have been carried out in a frequency range encompassing three
orders of magnitude, from 10 kHz to 10 MHz, versus temperature. The relaxation
data have been thoroughly analyzed in terms of several relaxation models with
the purpose to reveal the mechanisms of water motion. For this purpose four
relaxation models have been used: the data have been decomposed into relaxation
contributions expressed in terms of Lorentzian spectral densities, then three
dimensional translation diffusion has been assumed, next two dimensional
surface diffusion has been considered and eventually, a model of surface
diffusion mediated by acts of adsorption to the surface has been employed. In
this way it has been demonstrated that the last concept is most plausible.
Parameters describing the dynamics in a quantita-tive manner have been
determined and discussed.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:27:56 GMT""}]","2023-02-23"
"2302.11016","Brian Pardo","Adam K. Leibovich, Brian A. Pardo, Zixin Yang","Radiation Reaction for Non-Spinning Bodies at 4.5PN in the Effective
  Field Theory Approach","23 pages. 1 ancillary file (wl format)",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We calculate the 2 post-Newtonian correction to the radiation reaction
acceleration for non-spinning binary systems, which amounts to the 4.5
post-Newtonian correction to Newtonian acceleration. The calculation is carried
out completely using the effective field theory approach. The center-of-mass
corrections to the results are complicated and are discussed in detail.
Non-trivial consistency checks are performed and we compare with corresponding
results in the literature. Analytic results are supplied in the supplementary
materials.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:28:45 GMT""}]","2023-02-23"
"2302.11017","Thomas M\""obius","Thomas M\""obius, Mira Watermeyer, Oliver Grothe, Felix M\""usgens","Enhancing Energy System Models Using Better Load Forecasts",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-sa/4.0/","  Energy system models require a large amount of technical and economic data,
the quality of which significantly influences the reliability of the results.
Some of the variables on the important data source ENTSO-E transparency
platform, such as transmission system operators' day-ahead load forecasts, are
known to be biased. These biases and high errors affect the quality of energy
system models. We propose a simple time series model that does not require any
input variables other than the load forecast history to significantly improve
the transmission system operators' load forecast data on the ENTSO-E
transparency platform in real-time, i.e., we successively improve each incoming
data point. We further present an energy system model developed specifically
for the short-term day-ahead market. We show that the improved load data as
inputs reduce pricing errors of the model, with strong reductions particularly
in times when prices are high and the market is tight.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:28:53 GMT""}]","2023-02-23"
"2302.11018","Claudio Mannini","Claudio Mannini, Tommaso Massai, Andrea Giachetti, Alessandro Giusti","Aerodynamic loads on groups of offshore wind turbine towers stored on
  quaysides during the pre-assembly phase","29 pages, 31 figures",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Offshore wind turbine towers are pre-assembled and temporarily held in close
proximity to each other in group arrangements on port quaysides. Accurate
estimates of the aerodynamic loads on the individual towers and on the overall
group are essential for the safe and economic design of the quayside's
supporting structures and foundations. Wind tunnel tests represent the main way
to address the problem, but results may lead to overconservative designs due to
inevitable mismatches in the Reynolds number. This crucial issue is dealt with
here using an original engineering solution based on concentrated but
discontinuous surface roughness, which allows, for the first time in the case
of finite-height towers arranged in groups and subjected to an atmospheric
boundary layer flow, the successful simulation of the target high Reynolds
number regime. This case study assumes slender wind turbine towers with a
height of 115 m, and for the sake of generality, the investigations focus
principally on a cylindrical shape rather than the more complex real-world
geometry. The constant diameter of the towers is determined based on the
theoretical equivalence of the mean overturning moment. The rationality of this
procedure is verified a posteriori using a set of measurements on the
real-shape towers. The experiments show a regular behavior of the maximum mean
base shear force and moment for towers arranged in double-row groups, while the
results are more complicated for single-row groups, since biased flow sometimes
occurs in symmetric or nearly-symmetric configurations. Dynamic loads are also
inspected, and gust factors in good agreement with Eurocode 1's prescriptions
are found. Several parametric studies are carried out, the most extensive of
which is devoted to assessing the role of tower height. A complicated
non-monotonic pattern of the load coefficients with the tower height is
encountered.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:30:46 GMT""}]","2023-02-23"
"2302.11019","Ramneet Kaur","Ramneet Kaur, Xiayan Ji, Souradeep Dutta, Michele Caprio, Yahan Yang,
  Elena Bernardis, Oleg Sokolsky, Insup Lee","Using Semantic Information for Defining and Detecting OOD Inputs",,,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by/4.0/","  As machine learning models continue to achieve impressive performance across
different tasks, the importance of effective anomaly detection for such models
has increased as well. It is common knowledge that even well-trained models
lose their ability to function effectively on out-of-distribution inputs. Thus,
out-of-distribution (OOD) detection has received some attention recently. In
the vast majority of cases, it uses the distribution estimated by the training
dataset for OOD detection. We demonstrate that the current detectors inherit
the biases in the training dataset, unfortunately. This is a serious
impediment, and can potentially restrict the utility of the trained model. This
can render the current OOD detectors impermeable to inputs lying outside the
training distribution but with the same semantic information (e.g. training
class labels). To remedy this situation, we begin by defining what should
ideally be treated as an OOD, by connecting inputs with their semantic
information content. We perform OOD detection on semantic information extracted
from the training data of MNIST and COCO datasets and show that it not only
reduces false alarms but also significantly improves the detection of OOD
inputs with spurious features from the training data.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:31:20 GMT""}]","2023-02-23"
"2302.11020","Jesse Gu","Jesse T. Gu, Rebecca A. Fischer, Matthew C. Brennan, Matthew S.
  Clement, Seth A. Jacobson, Nathan A. Kaib, David P. O'Brien, Sean N. Raymond","Comparisons of the core and mantle compositions of earth analogs from
  different terrestrial planet formation scenarios",,,"10.1016/j.icarus.2023.115425",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  The chemical compositions of Earth's core and mantle provide insight into the
processes that led to their formation. N-body simulations, on the other hand,
generally do not contain chemical information, and seek to only reproduce the
masses and orbits of the terrestrial planets. These simulations can be grouped
into four potentially viable scenarios of Solar System formation (Classical,
Annulus, Grand Tack, and Early Instability) for which we compile a total of 433
N-body simulations. We relate the outputs of these simulations to the chemistry
of Earth's core and mantle using a melt-scaling law combined with a multi-stage
model of core formation. We find the compositions of Earth analogs to be
largely governed by the fraction of equilibrating embryo cores and the initial
embryo masses in N-body simulations. Simulation type may be important when
considering magma ocean lifetimes, where Grand Tack simulations have the
largest amounts of material accreted after the last giant impact. However, we
cannot rule out any accretion scenarios or initial embryo masses due to the
sensitivity of Earth's mantle composition to different parameters and the
stochastic nature of N-body simulations. Comparing the last embryo impacts
experienced by Earth analogs to specific Moon-forming scenarios, we find the
characteristics of the Moon-forming impact are dependent on the initial
conditions in N-body simulations where larger initial embryo masses promote
larger and slower Moon-forming impactors. Mars-sized initial embryos are most
consistent with the canonical hit-and-run scenario onto a solid mantle. Our
results suggest that constraining the fraction of equilibrating impactor core
and the initial embryo masses in N-body simulations could be significant for
understanding both Earth's accretion history and characteristics of the
Moon-forming impact.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:33:59 GMT""}]","2023-02-23"
"2302.11021","Ankur Samanta","Ankur Samanta, Mark Karlov, Meghna Ravikumar, Christian McIntosh
  Clarke, Jayakumar Rajadas, Kaveh Hassani","MVMTnet: A Multi-variate Multi-modal Transformer for Multi-class
  Classification of Cardiac Irregularities Using ECG Waveforms and Clinical
  Notes","18 pages, 11 figures, submitted to Artificial Intelligence in
  Medicine journal",,,,"cs.LG cs.AI q-bio.QM","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep learning provides an excellent avenue for optimizing diagnosis and
patient monitoring for clinical-based applications, which can critically
enhance the response time to the onset of various conditions. For
cardiovascular disease, one such condition where the rising number of patients
increasingly outweighs the availability of medical resources in different parts
of the world, a core challenge is the automated classification of various
cardiac abnormalities. Existing deep learning approaches have largely been
limited to detecting the existence of an irregularity, as in binary
classification, which has been achieved using networks such as CNNs and
RNN/LSTMs. The next step is to accurately perform multi-class classification
and determine the specific condition(s) from the inherently noisy multi-variate
waveform, which is a difficult task that could benefit from (1) a more powerful
sequential network, and (2) the integration of clinical notes, which provide
valuable semantic and clinical context from human doctors. Recently,
Transformers have emerged as the state-of-the-art architecture for forecasting
and prediction using time-series data, with their multi-headed attention
mechanism, and ability to process whole sequences and learn both long and
short-range dependencies. The proposed novel multi-modal Transformer
architecture would be able to accurately perform this task while demonstrating
the cross-domain effectiveness of Transformers, establishing a method for
incorporating multiple data modalities within a Transformer for classification
tasks, and laying the groundwork for automating real-time patient condition
monitoring in clinical and ER settings.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:38:41 GMT""}]","2023-02-23"
"2302.11022","Carlos Desa","Carlos Desa","An\'alisis del argumento cosmol\'ogico kalam desde la f\'isica
  contempor\'anea","in Spanish",,,,"physics.hist-ph","http://creativecommons.org/licenses/by/4.0/","  The Kalam cosmological argument, which is logical-philosophical based on its
two premises, affirms that the universe had a cause. We carry out an analysis
from the perspective of current physics to contrast or object to the premises
of said argument. For this purpose, we will use the results found in
contemporary physics literature related to the premises of the Kalam argument.
Analyzing quantum theory and the latest experimental results that prove that
quantum phenomena are indeterministic and therefore not causal. And even in
deterministic theories, such as a space-time with negative curvature, causality
is in doubt. On the other hand, the first moments of the universe require
models that describe states before it to contrast experimental observations,
such as cosmic inflation theories. Thus, we will conclude that both premises of
the Kalam argument are not supported by contemporary physics.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:39:47 GMT""}]","2023-02-23"
"2302.11023","Michael Mendelson","Michael J Mendelson, Mehdi Azabou, Suma Jacob, Nicola Grissom, David
  Darrow, Becket Ebitz, Alexander Herman, Eva L. Dyer","Learning signatures of decision making from many individuals playing the
  same game","4 pages, 2 figures. To be published in IEEE NER",,,,"cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human behavior is incredibly complex and the factors that drive decision
making--from instinct, to strategy, to biases between individuals--often vary
over multiple timescales. In this paper, we design a predictive framework that
learns representations to encode an individual's 'behavioral style', i.e.
long-term behavioral trends, while simultaneously predicting future actions and
choices. The model explicitly separates representations into three latent
spaces: the recent past space, the short-term space, and the long-term space
where we hope to capture individual differences. To simultaneously extract both
global and local variables from complex human behavior, our method combines a
multi-scale temporal convolutional network with latent prediction tasks, where
we encourage embeddings across the entire sequence, as well as subsets of the
sequence, to be mapped to similar points in the latent space. We develop and
apply our method to a large-scale behavioral dataset from 1,000 humans playing
a 3-armed bandit task, and analyze what our model's resulting embeddings reveal
about the human decision making process. In addition to predicting future
choices, we show that our model can learn rich representations of human
behavior over multiple timescales and provide signatures of differences in
individuals.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:41:53 GMT""}]","2023-02-23"
"2302.11024","Daniel Z. Huang","Yifan Chen, Daniel Zhengyu Huang, Jiaoyang Huang, Sebastian Reich,
  Andrew M. Stuart","Gradient Flows for Sampling: Mean-Field Models, Gaussian Approximations
  and Affine Invariance","71 pages, 8 figures (Welcome any feedback!)",,,,"stat.ML cs.NA math.NA","http://creativecommons.org/licenses/by/4.0/","  Sampling a probability distribution with an unknown normalization constant is
a fundamental problem in computational science and engineering. This task may
be cast as an optimization problem over all probability measures, and an
initial distribution can be evolved to the desired minimizer dynamically via
gradient flows. Mean-field models, whose law is governed by the gradient flow
in the space of probability measures, may also be identified; particle
approximations of these mean-field models form the basis of algorithms. The
gradient flow approach is also the basis of algorithms for variational
inference, in which the optimization is performed over a parameterized family
of probability distributions such as Gaussians, and the underlying gradient
flow is restricted to the parameterized family.
  By choosing different energy functionals and metrics for the gradient flow,
different algorithms with different convergence properties arise. In this
paper, we concentrate on the Kullback-Leibler divergence after showing that, up
to scaling, it has the unique property that the gradient flows resulting from
this choice of energy do not depend on the normalization constant. For the
metrics, we focus on variants of the Fisher-Rao, Wasserstein, and Stein
metrics; we introduce the affine invariance property for gradient flows, and
their corresponding mean-field models, determine whether a given metric leads
to affine invariance, and modify it to make it affine invariant if it does not.
We study the resulting gradient flows in both probability density space and
Gaussian space. The flow in the Gaussian space may be understood as a Gaussian
approximation of the flow. We demonstrate that the Gaussian approximation based
on the metric and through moment closure coincide, establish connections
between them, and study their long-time convergence properties showing the
advantages of affine invariance.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:44:08 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 23:40:49 GMT""},{""version"":""v3"",""created"":""Tue, 11 Apr 2023 18:08:07 GMT""}]","2023-04-13"
"2302.11025","Owen Scutt MSc","Owen J. Scutt, Simon J. Murphy, Martin B. Nielsen, Guy R. Davies,
  Timothy R. Bedding, Alexander J. Lyttle","Asteroseismology of $\delta$ Scuti stars: emulating model grids using a
  neural network","9 pages, 9 figures, submitted to Monthly Notices of the Royal
  Astronomical Society 17/02/2023",,,,"astro-ph.SR astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  Young $\delta$ Scuti stars have proven to be valuable asteroseismic targets
but obtaining robust uncertainties on their inferred properties is challenging.
We aim to quantify the random uncertainties in grid-based modelling of $\delta$
Sct stars. We apply Bayesian inference using nested sampling and a neural
network emulator of stellar models, testing our method on both simulated and
real stars. Based on results from simulated stars we demonstrate that our
method can recover plausible posterior probability density estimates while
accounting for both the random uncertainty from the observations and neural
network emulation. We find that the posterior distributions of the fundamental
parameters can be significantly non-Gaussian, multi-modal, and have strong
covariance. We conclude that our method reliably estimates the random
uncertainty in the modelling of $\delta$ Sct stars and paves the way for the
investigation and quantification of the systematic uncertainty.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:47:34 GMT""}]","2023-02-23"
"2302.11026","Khac-Hoang Ngo","Khac-Hoang Ngo, Giuseppe Durisi, Alexandre Graell i Amat, Petar
  Popovski, Anders E. Kalor, and Beatriz Soret","Unsourced Multiple Access with Common Alarm Messages: Network Slicing
  for Massive and Critical IoT","submitted to IEEE Transactions on Communications, extended version of
  a paper presented at Asilomar 2022",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the coexistence of massive and critical Internet of Things
(IoT) services in the context of the unsourced multiple access (UMA) framework
introduced by Polyanskiy (2017), where all users employ a common codebook and
the receiver returns an unordered list of decoded codewords. This setup is
suitably modified to introduce heterogeneous traffic. Specifically, to model
the massive IoT service, a standard message originates independently from each
IoT device as in the standard UMA setup. To model the critical IoT service, we
assume the generation of alarm messages that are common for all devices. This
setup requires a significant redefinition of the error events, i.e.,
misdetections and false positives. We further assume that the number of active
users in each transmission attempt is random and unknown. We derive a
random-coding achievability bound on the misdetection and false positive
probabilities of both standard and alarm messages on the Gaussian multiple
access channel. Using our bound, we demonstrate that orthogonal network slicing
enables massive and critical IoT to coexist under the requirement of high
energy efficiency. On the contrary, we show that nonorthogonal network slicing
is energy inefficient due to the residual interference from the alarm signal
when decoding the standard messages.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:51:22 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 22:49:07 GMT""}]","2023-03-01"
"2302.11027","Tanvir Rahman","Labib Ahmed Siddique, Rabita Junhai, Tanzim Reza, Salman Sayeed Khan,
  and Tanvir Rahman","Analysis of Real-Time Hostile Activitiy Detection from Spatiotemporal
  Features Using Time Distributed Deep CNNs, RNNs and Attention-Based
  Mechanisms",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Real-time video surveillance, through CCTV camera systems has become
essential for ensuring public safety which is a priority today. Although CCTV
cameras help a lot in increasing security, these systems require constant human
interaction and monitoring. To eradicate this issue, intelligent surveillance
systems can be built using deep learning video classification techniques that
can help us automate surveillance systems to detect violence as it happens. In
this research, we explore deep learning video classification techniques to
detect violence as they are happening. Traditional image classification
techniques fall short when it comes to classifying videos as they attempt to
classify each frame separately for which the predictions start to flicker.
Therefore, many researchers are coming up with video classification techniques
that consider spatiotemporal features while classifying. However, deploying
these deep learning models with methods such as skeleton points obtained
through pose estimation and optical flow obtained through depth sensors, are
not always practical in an IoT environment. Although these techniques ensure a
higher accuracy score, they are computationally heavier. Keeping these
constraints in mind, we experimented with various video classification and
action recognition techniques such as ConvLSTM, LRCN (with both custom CNN
layers and VGG-16 as feature extractor) CNNTransformer and C3D. We achieved a
test accuracy of 80% on ConvLSTM, 83.33% on CNN-BiLSTM, 70% on VGG16-BiLstm
,76.76% on CNN-Transformer and 80% on C3D.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:02:39 GMT""}]","2023-02-23"
"2302.11028","Davide Fedele","D. Fedele (INAF, Osservatorio Astrofisico di Arcetri), F. Bollati
  (Universit\`a dell'Insubria), G. Lodato (Universit\`a di Milano)","Kinematics signature of a giant planet in the disk of AS 209","Accepted by A&A",,"10.1051/0004-6361/202244486",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  [abridged] ALMA observations of dust in protoplanetary disks are revealing
the existence of sub-structures such as rings, gaps and cavities. Such
morphology are expected to be the outcome of dynamical interaction between the
disk and planets. However, other mechanisms are able to produce similar dust
sub-structures. A solution is to look at the perturbation induced by the planet
to the gas surface density and/or to the kinematics. In the case of the disk
around AS 209, a prominent gap has been reported in the surface density of CO
at $r \sim 100\,$au. Recently, Bae et al. (2022) detected a localized velocity
perturbation in the $^{12}$CO $J=2-1$ emission along with a clump in $^{13}$CO
$J=2-1$ at nearly 200 au, interpreted as a gaseous circumplanetary disk. We
report a new analysis of ALMA archival observations of $^{12}$CO and $^{13}$CO
J=2-1. A clear kinematics perturbation (kink) is detected in multiple channels
and over a wide azimuth range in both dataset. We compared the observed
perturbation with a semi-analytic model of velocity perturbations due to
planet-disk interaction. The observed kink is not consistent with a planet at
200\,au as this would require a low gas disk scale height ($< 0.05$) in
contradiction with previous estimate ($h/r \sim 0.118$ at $r = 100$ au). When
we fix the disk scale height to 0.118 (at $r = 100$ au) we find instead that a
planet of 3-5 M$_{\rm Jup}$ at 100 au induces a kinematics perturbation similar
to the observed one. Thus, we conclude that a giant protoplanet orbiting at $r
\sim 100\,$au is responsible of the large scale kink as well as of the
perturbed dust and gas surface density previously detected. The position angle
of the planet is constrained to be between 60$^{\circ}$-100$^{\circ}$. Future
observations with high contrast imaging technique in the near- and mid-
infrared are needed to confirm the presence and position of such a planet.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:07:11 GMT""}]","2023-04-19"
"2302.11029","Ian Ochs","I. E. Ochs and N. J. Fisch","Ponderomotive Recoil for Electromagnetic Waves","9 pages, 1 figure","Physics of Plasmas, vol. 30, no. 2, p. 022102, (2023)","10.1063/5.0138384",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When waves damp or amplify on resonant particles in a plasma, the nonresonant
particles experience a recoil force that conserves the total momentum between
the particles and electromagnetic fields. This force is important to
understand, as it can completely negate current drive and rotation drive
mechanisms that are predicted on the basis of only the resonant particles.
Here, the existing electrostatic theory of this recoil force is extended to
electromagnetic waves. While the result bears close similarity to historical
fluid theories of laser-plasma interactions, it now incorporates both resonant
and nonresonant particles, allowing momentum conservation to be
self-consistently proven. Furthermore, the result is shown to be generally
valid for kinetic plasmas, which is verified through single-particle hot-plasma
simulations. The new form of the force provides physical insight into the
nature of the generalized Minkowski (plasmon) momentum of geometrical optics,
which is shown to correspond to the momentum gained by the field and
nonresonant particles as the wave is self-consistently ramped up from vanishing
amplitude.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:10:47 GMT""}]","2023-02-23"
"2302.11030","Heer Zhao","Alessandra Bertapelle, Shanwen Wang, Heer Zhao","Log $p$-divisible groups and semi-stable representations","18 pages",,,,"math.NT math.AG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this article, we investigate the relations between log $p$-divisible
groups, $p$-divisible groups with semi-stable reduction, and semi-stable Galois
representations. In particular, we show that a $p$-divisible group over a
complete discrete valued field of mixed characteristic has semi-stable
reduction (in the sense of de Jong) if and only if it extends to a log
$p$-divisible group over the corresponding log trait, or, equivalently, if and
only if its Galois representation is semi-stable with Hodge-Tate weights in
$[0,1]$. The second equivalence is a generalization of Fontaine's conjecture on
the Galois representation associated with $p$-divisible groups to the setting
of log $p$-divisible groups.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:13:21 GMT""}]","2023-02-23"
"2302.11031","Shunsuke Sakai","Shunsuke Sakai and Makoto Sakuma","Two-parabolic-generator subgroups of hyperbolic 3-manifold groups","47 pages, 22 figures",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a detailed account of Agol's theorem and his proof concerning
two-meridional-generator subgroups of hyperbolic 2-bridge link groups, which is
included in the slide of his talk at the Bolyai conference 2001. We also give a
generalization of the theorem to two-parabolic-generator subgroups of
hyperbolic 3-manifold groups, which gives a refinement of a result due to
Boileau-Weidmann.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:16:35 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 12:13:06 GMT""}]","2023-03-02"
"2302.11032","Zhaoying Lu","Keaton Hamm, Zhaoying Lu, Wenbo Ouyang, Hao Helen Zhang","Boosting Nystr\""{o}m Method",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Nystr\""{o}m method is an effective tool to generate low-rank
approximations of large matrices, and it is particularly useful for
kernel-based learning. To improve the standard Nystr\""{o}m approximation,
ensemble Nystr\""{o}m algorithms compute a mixture of Nystr\""{o}m approximations
which are generated independently based on column resampling. We propose a new
family of algorithms, boosting Nystr\""{o}m, which iteratively generate multiple
``weak'' Nystr\""{o}m approximations (each using a small number of columns) in a
sequence adaptively - each approximation aims to compensate for the weaknesses
of its predecessor - and then combine them to form one strong approximation. We
demonstrate that our boosting Nystr\""{o}m algorithms can yield more efficient
and accurate low-rank approximations to kernel matrices. Improvements over the
standard and ensemble Nystr\""{o}m methods are illustrated by simulation studies
and real-world data analysis.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:20:55 GMT""}]","2023-02-23"
"2302.11033","Jose-Luis Blanco-Claraco","Jos\'e-Luis Blanco-Claraco, Borys Tymchenko, Francisco Jos\'e
  Ma\~nas-Alvarez, Fernando Ca\~nadas-Ar\'anega, \'Angel L\'opez-G\'azquez,
  Jos\'e Carlos Moreno","MultiVehicle Simulator (MVSim): lightweight dynamics simulator for
  multiagents and mobile robotics research","6 pages, 6 figures, submitted",,,,"cs.RO cs.MA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Development of applications related to closed-loop control requires either
testing on the field or on a realistic simulator, with the latter being more
convenient, inexpensive, safe, and leading to shorter development cycles. To
address that need, the present work introduces MVSim, a simulator for multiple
vehicles or robots capable of running dozens of agents in simple scenarios, or
a handful of them in complex scenarios. MVSim employs realistic
physics-grounded friction models for tire-ground interaction, and aims at
accurate and GPU-accelerated simulation of most common modern sensors employed
in mobile robotics and autonomous vehicle research, such as depth and RGB
cameras, or 2D and 3D LiDAR scanners. All depth-related sensors are able to
accurately measure distances to 3D models provided by the user to define custom
world elements. Efficient simulation is achieved by means of focusing on ground
vehicles, which allows the use of a simplified 2D physics engine for body
collisions while solving wheel-ground interaction forces separately. The core
parts of the system are written in C++ for maximum efficiency, while Python,
ROS 1, and ROS 2 wrappers are also offered for easy integration into user
systems. A custom publish/subscribe protocol based on ZeroMQ (ZMQ) is defined
to allow for multiprocess applications to access or modify a running
simulation. This simulator enables and makes easier to do research and
development on vehicular dynamics, autonomous navigation algorithms, and
simultaneous localization and mapping (SLAM) methods.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:22:21 GMT""}]","2023-02-23"
"2302.11034","Shahin Tajik","Maryam Saadat Safa, Tahoura Mosavirik, Shahin Tajik","Counterfeit Chip Detection using Scattering Parameter Analysis",,,,,"cs.CR","http://creativecommons.org/licenses/by/4.0/","  The increase in the number of counterfeit and recycled microelectronic chips
in recent years has created significant security and safety concerns in various
applications. Hence, detecting such counterfeit chips in electronic systems is
critical before deployment in the field. Unfortunately, the conventional
verification tools using physical inspection and side-channel methods are
costly, unscalable, error-prone, and often incompatible with legacy systems.
This paper introduces a generic non-invasive and low-cost counterfeit chip
detection based on characterizing the impedance of the system's power delivery
network (PDN). Our method relies on the fact that the impedance of the
counterfeit and recycled chips differs from the genuine ones. To sense such
impedance variations confidently, we deploy scattering parameters, frequently
used for impedance characterization of RF/microwave circuits. Our proposed
approach can directly be applied to soldered chips on the system's PCB and does
not require any modifications on the legacy systems. To validate our claims, we
perform extensive measurements on genuine and aged samples from two families of
STMicroelectronics chips to assess the effectiveness of the proposed approach.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:26:18 GMT""}]","2023-02-23"
"2302.11035","Kitti Varga","J\'ozsef Pint\'er, Kitti Varga","Color-avoiding connected spanning subgraphs with minimum number of edges",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  We call a (not necessarily properly) edge-colored graph edge-color-avoiding
connected if after the removal of edges of any single color, the graph remains
connected. For vertex-colored graphs, similar definitions of color-avoiding
connectivity can be given. In this article, we investigate the problem of
determining the maximum number of edges that can be removed from a
color-avoiding connected graph so that it remains color-avoiding connected.
First, we prove that this problem is NP-hard, then we give a polynomial-time
approximation algorithm for it. To analyze the approximation factor of this
algorithm, we determine the minimum number of edges of color-avoiding connected
graphs on a given number of vertices and with a given number of colors.
Furthermore, we also consider a generalization of edge-color-avoiding
connectivity to matroids.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:32:01 GMT""}]","2023-02-23"
"2302.11036","Davide Foini","Davide Foini, Magdalena Rzyska, Katharina Baschmakov, Sergio Murino","CrowdLogo: crowd simulation in NetLogo",,,,,"cs.MA","http://creativecommons.org/licenses/by/4.0/","  Planning the evacuation of people from crowded places, such as squares,
stadiums, or indoor arenas during emergency scenarios is a fundamental task
that authorities must deal with. This article summarizes the work of the
authors to simulate an emergency scenario in a square using NetLogo, a
multi-agent programmable modeling environment. The emergency scenario is based
on a real event, which took place in Piazza San Carlo, Turin, on the 3rd of
June 2017. The authors have developed a model and conducted various
experiments, the results of which are presented, discussed and analyzed. The
article concludes by offering suggestions for further research and summarizing
the key takeaways.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:38:04 GMT""}]","2023-02-23"
"2302.11037","Ji Li","The Anh Bui, Xuejing Huo and Ji Li","Sharp estimates for imaginary powers of Bessel operators",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $L f(x):=-\frac{d^2}{dx^2}f(x)-\frac{ r}{x}\frac{d}{dx}f(x),\quad x>0,
r>0$ be the Bessel operator on $((0,\infty), |\cdot|, x^rdx)$. In this paper,
we prove the sharp weak type $(1,1)$ estimate for the imaginary power
$L^{i\alpha}, \alpha\in \mathbb R$, of the Bessel operator.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:43:36 GMT""}]","2023-02-23"
"2302.11038","Kristen Quigley","Kristen G. Quigley, Dustin Hopfe, Madison R. Taylor, Philip
  Pavilionis, Vincentia Owusu-Amankonah, Arthur Islas, Nicholas G. Murray","Preliminary Examination of Guardian Cap Head Impact Data Using
  Instrumented Mouthguards","22 pages, 6 figures",,,,"physics.med-ph","http://creativecommons.org/licenses/by/4.0/","  Purpose The objective of this study is to present preliminary on-field head
kinematics data for NCAA Division I American football players through closely
matched pre-season workouts both with and without Guardian Caps (GCs). Methods
42 NCAA Division I American football players wore instrumented mouthguards
(iMMs) for 6 closely matched workouts, 3 in traditional helmets (PRE) and 3
with GCs (POST) affixed to the exterior of their helmets. This includes 7
players who had consistent data through all workouts. Results There was no
significant difference between the collapsed mean values for the entire sample
between PRE and POST for peak linear acceleration (PLA) (PRE=16.3, POST=17.2Gs;
p=0.20), Peak Angular Acceleration (PAA) (PRE=992.1, POST=1029.4rad/s2; p=0.51
and the total amount of impacts (PRE=9.3, POST=9.7; p=0.72). Similarly, no
difference was observed between PRE and POST for PLA (PRE=16.1, POST=17.2Gs;
p=0.32), PAA (PRE=951.2, POST=1038.0rad/s2; p=0.29 and total impacts (PRE=9.6,
POST=9.7; p=0.32) between sessions for the 7 repeated players. Conclusion These
data suggest no difference in head kinematics data (PLA, PAA and total impacts)
when GCs are worn. This study suggests GCs are not effective in reducing the
magnitude of head impacts experienced by NCAA Division I American football
players.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:44:51 GMT""}]","2023-02-23"
"2302.11039","Yasuhide Numata","Yasuhide Numata","The Lefschetz property for an algebra defined by matchings",,,,,"math.AC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we consider the weighted generating function of matchings in
the complete graph. We define an Artinian Gorenstein algebra as the quotient
ring of a polynomial ring by the annihilator of the generating function. We
show the strong Lefschetz property of the algebra.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:45:06 GMT""}]","2023-02-23"
"2302.11040","Nazanin Abolfazli","Nazanin Abolfazli, Afrooz Jalilzadeh, Erfan Yazdandoost Hamedani","An Accelerated Asynchronous Distributed Method for Convex Constrained
  Optimization Problems",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a class of multi-agent cooperative consensus optimization
problems with local nonlinear convex constraints where only those agents
connected by an edge can directly communicate, hence, the optimal consensus
decision lies in the intersection of these private sets. We develop an
asynchronous distributed accelerated primal-dual algorithm to solve the
considered problem. The proposed scheme is the first asynchronous method with
an optimal convergence guarantee for this class of problems, to the best of our
knowledge. In particular, we provide an optimal convergence rate of
$\mathcal{O(1/K)}$ for suboptimality, infeasibility, and consensus violation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:46:15 GMT""}]","2023-02-23"
"2302.11041","Andr\'es Quilis","Petr H\'ajek and Andr\'es Quilis","Counterexamples in rotundity of norms in Banach spaces","19 pages, 1 figure",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  We study several classical concepts in the topic of strict convexity of norms
in infinite dimensional Banach spaces. Specifically, and in descending order of
strength, we deal with Uniform Rotundity (UR), Weak Uniform Rotundity (WUR) and
Uniform Rotundity in Every Direction (URED). Our first three results show that
we may distinguish between all of these three properties in every Banach space
where such renormings are possible. Specifically, we show that in every
infinite dimensional Banach space which admits a WUR (resp. URED) renorming, we
can find a norm with the same condition and which moreover fails to be UR
(resp. WUR). We prove that these norms can be constructed to be Locally
Uniformly Rotund (LUR) in Banach spaces admitting such renormings.
Additionally, we obtain that in every Banach space with a LUR norm we can find
a LUR renorming which is not URED. These results solve three open problems
posed by A.J. Guirao, V. Montesinos and V. Zizler. The norms we construct in
this first part are dense.
  In the last part of this note, we solve a fourth question posed by the same
three authors by constructing a $C^\infty$-smooth norm in $c_0$ whose dual norm
is not strictly convex.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:47:27 GMT""}]","2023-02-23"
"2302.11042","Tai Nguyen","Tai Nguyen and Eric Wong","In-context Example Selection with Influences",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  In-context learning (ICL) is a powerful paradigm emerged from large language
models (LLMs). Despite its promises, ICL performance is known to be highly
sensitive to input examples. In this work, we use $\textit{in-context
influences}$ to analyze few-shot ICL performance directly from the in-context
examples. Our proposed influence-based example selection method can identify
both positive and negative examples, outperforming several baselines when
evaluated on 9 SuperGLUE tasks. Our analysis uncovers up to a $16.3\%$
performance gap between using the most negative in-context examples compared to
the most positive. In a case study, we apply our influence-based framework to
quantify the phenomena of recency bias in example ordering for few-shot ICL.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:47:45 GMT""},{""version"":""v2"",""created"":""Mon, 5 Jun 2023 17:49:58 GMT""}]","2023-06-06"
"2302.11043","Le\'on Bohn","Le\'on Bohn, Christof L\""oding","Constructing Deterministic Parity Automata from Positive and Negative
  Examples",,,,,"cs.FL","http://creativecommons.org/licenses/by/4.0/","  We present a polynomial time algorithm that constructs a deterministic parity
automaton (DPA) from a given set of positive and negative ultimately periodic
example words. We show that this algorithm is complete for the class of
$\omega$-regular languages, that is, it can learn a DPA for each regular
$\omega$-language. For this purpose, we propose a canonical form of DPA, which
we call precise DPA (of a language), and show that it can be constructed from
the syntactic family of right congruences for that language (introduced by
Maler and Staiger in 1997). The precise DPA can be of exponential size compared
to a minimal DPA for a language, but it can also be a minimal DPA, depending on
the structure of the language. The upper bound that we obtain on the number of
examples required for our algorithm to find a DPA for L is therefore
exponential in the size of a minimal DPA, in general. But we identify two
parameters of regular $\omega$-languages such that fixing these parameters
makes the bound polynomial.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:57:05 GMT""}]","2023-02-23"
"2302.11044","Edith Cohen","Edith Cohen and Xin Lyu","The Target-Charging Technique for Privacy Accounting across Interactive
  Computations",,,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  We propose the \emph{Target Charging Technique} (TCT), a unified privacy
analysis framework for interactive settings where a sensitive dataset is
accessed multiple times using differentially private algorithms. Unlike
traditional composition, where privacy guarantees deteriorate quickly with the
number of accesses, TCT allows computations that don't hit a specified
\emph{target}, often the vast majority, to be essentially free (while incurring
instead a small overhead on those that do hit their targets). TCT generalizes
tools such as the sparse vector technique and top-$k$ selection from private
candidates and extends their remarkable privacy enhancement benefits from noisy
Lipschitz functions to general private algorithms.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:57:14 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 23:59:07 GMT""}]","2023-04-13"
"2302.11045","Tomos Parry","Tomos Parry","A Montgomery-Hooley theorem for the k-fold divisor function",,,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  Let $d_k(n)$ denote the $k$-fold divisor function. For a wide range of large
$q$ the expected bound $$\sum_{n\leq x\atop {n\equiv a(q)}}d_k(n)-\text { main
term }\approx \sqrt {x/q}$$ is shown to be true in an average sense -- for all
$k$. This generalises the work of Pongsriiam and Vaughan [15] who studied
$k=2$, and answers the work of Rodgers and Soundararajan [17], who used the
asymptotic large sieve to study a smoothed version of the problem. We use a
circle method approach as developed by Goldston and Vaughan [7] to study the
unsmoothed problem.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 22:59:40 GMT""}]","2023-02-23"
"2302.11046","Ryo Suzuki","Kyzyl Monteiro, Ritik Vatsal, Neil Chulpongsatorn, Aman Parnami, Ryo
  Suzuki","Teachable Reality: Prototyping Tangible Augmented Reality with Everyday
  Objects by Leveraging Interactive Machine Teaching","CHI 2023",,"10.1145/3544548.3581449",,"cs.HC cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces Teachable Reality, an augmented reality (AR)
prototyping tool for creating interactive tangible AR applications with
arbitrary everyday objects. Teachable Reality leverages vision-based
interactive machine teaching (e.g., Teachable Machine), which captures
real-world interactions for AR prototyping. It identifies the user-defined
tangible and gestural interactions using an on-demand computer vision model.
Based on this, the user can easily create functional AR prototypes without
programming, enabled by a trigger-action authoring interface. Therefore, our
approach allows the flexibility, customizability, and generalizability of
tangible AR applications that can address the limitation of current
marker-based approaches. We explore the design space and demonstrate various AR
prototypes, which include tangible and deformable interfaces, context-aware
assistants, and body-driven AR applications. The results of our user study and
expert interviews confirm that our approach can lower the barrier to creating
functional AR prototypes while also allowing flexible and general-purpose
prototyping experiences.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:03:49 GMT""}]","2023-02-23"
"2302.11047","Boning Zhang","Boning Zhang and Lan Nguyen","Eight-node solid brick element high-order stiffness matrix template",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper, the template will be developed from an assumed Stress Method,
which its formulation is based on the Hellinger-Reissner principle developed
according to Kang's study in 1986. The element stiffness is decomposed into a
basic part that takes care of consistency and mix-ability, and a HO element
stiffness part that takes care of stability (also known as rank sufficient) and
accuracy. In the FE method, the HO stiffness is based on a displacement
formulation, whereas the basis stiffness is method independent. To start, one
should be familiar with the definition of a solid brick element. Solid brick
element is three-dimensional finite elements that can model solid bodies and
structures without any a priori geometric simplification.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:04:52 GMT""}]","2023-02-23"
"2302.11048","Ching-An Cheng","Mohak Bhardwaj, Tengyang Xie, Byron Boots, Nan Jiang, Ching-An Cheng","Adversarial Model for Offline Reinforcement Learning","arXiv admin note: text overlap with arXiv:2211.04538",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel model-based offline Reinforcement Learning (RL) framework,
called Adversarial Model for Offline Reinforcement Learning (ARMOR), which can
robustly learn policies to improve upon an arbitrary reference policy
regardless of data coverage. ARMOR is designed to optimize policies for the
worst-case performance relative to the reference policy through adversarially
training a Markov decision process model. In theory, we prove that ARMOR, with
a well-tuned hyperparameter, can compete with the best policy within data
coverage when the reference policy is supported by the data. At the same time,
ARMOR is robust to hyperparameter choices: the policy learned by ARMOR, with
""any"" admissible hyperparameter, would never degrade the performance of the
reference policy, even when the reference policy is not covered by the dataset.
To validate these properties in practice, we design a scalable implementation
of ARMOR, which by adversarial training, can optimize policies without using
model ensembles in contrast to typical model-based methods. We show that ARMOR
achieves competent performance with both state-of-the-art offline model-free
and model-based RL algorithms and can robustly improve the reference policy
over various hyperparameter choices.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:08:09 GMT""}]","2023-02-23"
"2302.11049","Maxime Gariel","Maxime Gariel, Brian Shimanuki, Rob Timpe, Evan Wilson","Framework for Certification of AI-Based Systems","9 pages, 10 figures",,,,"cs.LG cs.CV cs.SE","http://creativecommons.org/licenses/by/4.0/","  The current certification process for aerospace software is not adapted to
""AI-based"" algorithms such as deep neural networks. Unlike traditional
aerospace software, the precise parameters optimized during neural network
training are as important as (or more than) the code processing the network and
they are not directly mathematically understandable. Despite their lack of
explainability such algorithms are appealing because for some applications they
can exhibit high performance unattainable with any traditional explicit
line-by-line software methods.
  This paper proposes a framework and principles that could be used to
establish certification methods for neural network models for which the current
certification processes such as DO-178 cannot be applied. While it is not a
magic recipe, it is a set of common sense steps that will allow the applicant
and the regulator increase their confidence in the developed software, by
demonstrating the capabilities to bring together, trace, and track the
requirements, data, software, training process, and test results.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:08:37 GMT""}]","2023-02-23"
"2302.11050","Bowen Jin","Bowen Jin, Yu Zhang, Yu Meng, Jiawei Han","Edgeformers: Graph-Empowered Transformers for Representation Learning on
  Textual-Edge Networks","ICLR 2023. (Code: https://github.com/PeterGriffinJin/Edgeformers)",,,,"cs.LG cs.CL cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Edges in many real-world social/information networks are associated with rich
text information (e.g., user-user communications or user-product reviews).
However, mainstream network representation learning models focus on propagating
and aggregating node attributes, lacking specific designs to utilize text
semantics on edges. While there exist edge-aware graph neural networks, they
directly initialize edge attributes as a feature vector, which cannot fully
capture the contextualized text semantics of edges. In this paper, we propose
Edgeformers, a framework built upon graph-enhanced Transformers, to perform
edge and node representation learning by modeling texts on edges in a
contextualized way. Specifically, in edge representation learning, we inject
network information into each Transformer layer when encoding edge texts; in
node representation learning, we aggregate edge representations through an
attention mechanism within each node's ego-graph. On five public datasets from
three different domains, Edgeformers consistently outperform state-of-the-art
baselines in edge classification and link prediction, demonstrating the
efficacy in learning edge and node representations, respectively.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:09:17 GMT""}]","2023-02-23"
"2302.11051","Tiansheng Huang","Tiansheng Huang, Li Shen, Yan Sun, Weiwei Lin, Dacheng Tao","Fusion of Global and Local Knowledge for Personalized Federated Learning","Accepted by TMLR",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Personalized federated learning, as a variant of federated learning, trains
customized models for clients using their heterogeneously distributed data.
However, it is still inconclusive about how to design personalized models with
better representation of shared global knowledge and personalized pattern. To
bridge the gap, we in this paper explore personalized models with low-rank and
sparse decomposition. Specifically, we employ proper regularization to extract
a low-rank global knowledge representation (GKR), so as to distill global
knowledge into a compact representation. Subsequently, we employ a sparse
component over the obtained GKR to fuse the personalized pattern into the
global knowledge. As a solution, we propose a two-stage proximal-based
algorithm named \textbf{Fed}erated learning with mixed \textbf{S}parse and
\textbf{L}ow-\textbf{R}ank representation (FedSLR) to efficiently search for
the mixed models. Theoretically, under proper assumptions, we show that the GKR
trained by FedSLR can at least sub-linearly converge to a stationary point of
the regularized problem, and that the sparse component being fused can converge
to its stationary point under proper settings. Extensive experiments also
demonstrate the superior empirical performance of FedSLR. Moreover, FedSLR
reduces the number of parameters, and lowers the down-link communication
complexity, which are all desirable for federated learning algorithms. Source
code is available in \url{https://github.com/huangtiansheng/fedslr}.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:09:45 GMT""}]","2023-02-23"
"2302.11052","Yunzhong He","Yunzhong He, Yuxin Tian, Mengjiao Wang, Feier Chen, Licheng Yu,
  Maolong Tang, Congcong Chen, Ning Zhang, Bin Kuang, Arul Prakash","Que2Engage: Embedding-based Retrieval for Relevant and Engaging Products
  at Facebook Marketplace","Accepted by WWW'2023",,"10.1145/3543873.3584633",,"cs.IR cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Embedding-based Retrieval (EBR) in e-commerce search is a powerful search
retrieval technique to address semantic matches between search queries and
products. However, commercial search engines like Facebook Marketplace Search
are complex multi-stage systems optimized for multiple business objectives. At
Facebook Marketplace, search retrieval focuses on matching search queries with
relevant products, while search ranking puts more emphasis on contextual
signals to up-rank the more engaging products. As a result, the end-to-end
searcher experience is a function of both relevance and engagement, and the
interaction between different stages of the system. This presents challenges to
EBR systems in order to optimize for better searcher experiences. In this paper
we presents Que2Engage, a search EBR system built towards bridging the gap
between retrieval and ranking for end-to-end optimizations. Que2Engage takes a
multimodal & multitask approach to infuse contextual information into the
retrieval stage and to balance different business objectives. We show the
effectiveness of our approach via a multitask evaluation framework and thorough
baseline comparisons and ablation studies. Que2Engage is deployed on Facebook
Marketplace Search and shows significant improvements in searcher engagement in
two weeks of A/B testing.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:10:16 GMT""}]","2023-02-23"
"2302.11053","Ryo Suzuki","Mehrad Faridan, Bheesha Kumari, Ryo Suzuki","ChameleonControl: Teleoperating Real Human Surrogates through Mixed
  Reality Gestural Guidance for Remote Hands-on Classrooms","CHI 2023",,"10.1145/3544548.3581381",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present ChameleonControl, a real-human teleoperation system for scalable
remote instruction in hands-on classrooms. In contrast to existing video or
AR/VR-based remote hands-on education, ChameleonControl uses a real human as a
surrogate of a remote instructor. Building on existing human-based telepresence
approaches, we contribute a novel method to teleoperate a human surrogate
through synchronized mixed reality hand gestural navigation and verbal
communication. By overlaying the remote instructor's virtual hands in the local
user's MR view, the remote instructor can guide and control the local user as
if they were physically present. This allows the local user/surrogate to
synchronize their hand movements and gestures with the remote instructor,
effectively teleoperating a real human. We deploy and evaluate our system in
classrooms of physiotherapy training, as well as other application domains such
as mechanical assembly, sign language and cooking lessons. The study results
confirm that our approach can increase engagement and the sense of co-presence,
showing potential for the future of remote hands-on classrooms.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:11:41 GMT""}]","2023-02-23"
"2302.11054","Lu Zeng","Sree Hari Krishnan Parthasarathi, Lu Zeng, Dilek Hakkani-Tur","Conversational Text-to-SQL: An Odyssey into State-of-the-Art and
  Challenges Ahead","Accepted for publication at ICASSP 2023",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  Conversational, multi-turn, text-to-SQL (CoSQL) tasks map natural language
utterances in a dialogue to SQL queries. State-of-the-art (SOTA) systems use
large, pre-trained and finetuned language models, such as the T5-family, in
conjunction with constrained decoding. With multi-tasking (MT) over coherent
tasks with discrete prompts during training, we improve over specialized
text-to-SQL T5-family models. Based on Oracle analyses over n-best hypotheses,
we apply a query plan model and a schema linking algorithm as rerankers.
Combining MT and reranking, our results using T5-3B show absolute accuracy
improvements of 1.0% in exact match and 3.4% in execution match over a SOTA
baseline on CoSQL. While these gains consistently manifest at turn level,
context dependent turns are considerably harder. We conduct studies to tease
apart errors attributable to domain and compositional generalization, with the
latter remaining a challenge for multi-turn conversations, especially in
generating SQL with unseen parse trees.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:15:33 GMT""}]","2023-02-23"
"2302.11055","Enric Boix-Adser\`a","Emmanuel Abbe, Enric Boix-Adsera, Theodor Misiakiewicz","SGD learning on neural networks: leap complexity and saddle-to-saddle
  dynamics",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the time complexity of SGD learning on fully-connected neural
networks with isotropic data. We put forward a complexity measure -- the leap
-- which measures how ""hierarchical"" target functions are. For $d$-dimensional
uniform Boolean or isotropic Gaussian data, our main conjecture states that the
time complexity to learn a function $f$ with low-dimensional support is
$\tilde\Theta (d^{\max(\mathrm{Leap}(f),2)})$. We prove a version of this
conjecture for a class of functions on Gaussian isotropic data and 2-layer
neural networks, under additional technical assumptions on how SGD is run. We
show that the training sequentially learns the function support with a
saddle-to-saddle dynamic. Our result departs from [Abbe et al. 2022] by going
beyond leap 1 (merged-staircase functions), and by going beyond the mean-field
and gradient flow approximations that prohibit the full complexity control
obtained here. Finally, we note that this gives an SGD complexity for the full
training trajectory that matches that of Correlational Statistical Query (CSQ)
lower-bounds.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:16:23 GMT""}]","2023-02-23"
"2302.11056","Bowen Hou","Bowen Hou, Dan Wang, Bradford A. Barker, Diana Y. Qiu","Exchange-Driven Intermixing of Bulk and Topological Surface State by
  Chiral Excitons in Bi2Se3","13 pages, 4 figures",,"10.1103/PhysRevLett.130.216402",,"cond-mat.mtrl-sci physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological surface states (TSS) in the prototypical topological insulator
(TI) Bi2Se3 are frequently characterized using optical probes, but
electron-hole interactions and their effect on surface localization and optical
response of the TSS remain unexplored. Here, we use ab initio calculations to
understand excitonic effects in the bulk and surface of Bi2Se3. We identify
multiple series of chiral excitons that exhibit both bulk and TSS character,
due to exchange-driven mixing. Our results address fundamental questions about
the degree to which electron-hole interactions can relax the topological
protection of surface states and dipole selection rules for circularly
polarized light in TIs by elucidating the complex intermixture of bulk and
surface states excited in optical measurements and their coupling to light.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:21:47 GMT""}]","2023-06-07"
"2302.11057","Changyun Yoo","Changyun Yoo, Kenneth W. West, Loren N. Pfeiffer, Chris A. Curwen,
  Jonathan H. Kawamura, Boris S. Karasik, and Mark S. Sherwin","Indium-Bond-And-Stop-Etch (IBASE) Technique for Dual-side Processing of
  Thin High-mobility GaAs/AlGaAs Epitaxial Layers",,,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We present a reliable flip-chip technique for dual-side processing of thin
(<1 micron) high-mobility GaAs/AlGaAs epitaxial layers. The technique allows
the fabrication of small (micron-scale with standard UV photolithography)
patterned back gates and dual-gate structures on the thin GaAs/AlGaAs films
with good alignment accuracy using only frontside alignment. The technique
preserves the high-mobility (>10^6 cm^2 /V-s at 2 K) and most (>95%) of the
charge density of the 2-dimensional electron gas (2DEG) systems, and allows
linear control of the charge density with small (< 1 V) electrostatic gate
bias. Our technique is motivated by a novel THz quantum-well detector based on
intersubband transitions in a single, wide GaAs/AlGaAs quantum well, in which a
symmetric, well-aligned dual-gate structure (with a typical gate dimension of
~5 micron by 5 micron) is required for accurate and precise tuning of the THz
detection frequency. Using our Indium-Bond-And-Stop-Etch (IBASE) technique, we
realize such dual-gate structure on 660-nm thick GaAs/AlGaAs epitaxial layers
that contain a modulation-doped, 40-nm wide, single square quantum well. By
independently controlling the charge density and the DC electric field set
between the gates, we demonstrate robust tuning of the intersubband absorption
behavior of the 40-nm quantum well near 3.44 THz at 30 K.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:25:36 GMT""}]","2023-02-23"
"2302.11058","Shuxian Fan","Shuxian Fan, Li Liu, Jamie Perin, Tyler H. McCormick","Bayesian Age Category Reconciliation for Age- and Cause-specific
  Under-five Mortality Estimates",,,,,"stat.AP stat.ME","http://creativecommons.org/licenses/by/4.0/","  Age-disaggregated health data is crucial for effective public health planning
and monitoring. Monitoring under-five mortality, for example, requires highly
detailed age data since the distribution of potential causes of death varies
substantially within the first few years of life. Comparative researchers often
have to rely on multiple data sources yet, these sources often have ages
aggregated at different levels, making it difficult to combine the data into a
single, coherent picture. To address this challenge in the context of
under-five cause-specific mortality, we propose a Bayesian approach, that
calibrates data with different age structures to produce unified and accurate
estimates of the standardized age group distributions. We consider
age-disaggregated death counts as fully-classified multinomial data and show
that by incorporating partially-classified aggregated data, we can construct an
improved Bayes estimator of the multinomial parameters under the
Kullback-Leibler (KL) loss. We illustrate the method using both synthetic and
real data, demonstrating that the proposed method achieves adequate performance
in imputing incomplete classification. Finally, we present the results of
numerical studies examining the conditions necessary for obtaining improved
estimators. These studies provide insights and interpretations that can be used
to aid future research and inform guidance for practitioners on appropriate
levels of age disaggregation, with the aim of improving the accuracy and
reliability of under-five cause-specific mortality estimates.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:28:37 GMT""}]","2023-02-23"
"2302.11059","Fernando Tadeu Caldeira Brandt","F. T. Brandt, J. Frenkel, D. G. C. McKeon and G. S. S. Sakoda","Loop corrections in a solvable UV-finite model and its effective field
  theory","8 pages, 4 figures",,"10.1103/PhysRevD.107.065008",,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We examine some features of the non-renormalizability induced through the use
of low-energy effective Lagrangians in loop diagrams, in the context of a
scalar model which is ultraviolet finite and partially soluble. In this
framework, one can directly demonstrate the mechanism leading to the
non-renormalizability of the effective theory. This behavior is generated by
approximations that are applicable at low energies but are generally
inappropriate for evaluating loop diagrams that contain virtual high-energy
particles. However, it is explicitly shown that one can match the results
obtained in the renormalized effective theory with those found in the full
theory at low energy. We argue that the infrared sectors of these theories are
inherently similar, independently of the matching procedure. A closed-form
expression is obtained, to leading order in the energy expansion, for the
complete effective Lagrangian at all orders in perturbation theory. The model
may be useful to clarify certain aspects of realistic, but more complex,
effective field theories.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:31:48 GMT""}]","2023-03-29"
"2302.11060","Santosh Neupane","Santosh Neupane, Hong Tang, Adrienn Ruzsinszky","Defect-induced states, defect-induced phase transition and excitonic
  states in bent transition metal dichalcogenide (TMD) nanoribbons: density
  functional vs. many body theory",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional (2D) transition metal dichalcogenide (TMD) materials have
versatile electronic and optical properties. TMD nanoribbons show interesting
properties due to reduced dimensionality, quantum confinement, and edge states.
Tang et al. showed that the edge bands evolved with bending can tune the
optical properties for various widths of TMD nanoribbons. Defects are commonly
present in 2D TMD materials, and can dramatically change the material
properties. In this following work, we investigate the interaction between the
edge and the defect states in WS2 nanoribbons with line defects under different
bending conditions, using density functional theory (DFT). We reveal
interesting semiconducting-to-metallic phase transitions, suggesting potential
applications in nano-electronics or molecular electronics. We also calculate
the optical absorption of the nanoribbons with different defect positions with
the many-body GW-BSE (Bethe-Salpeter equation) approach, revealing a tunable
optical spectrum and diverse exciton states in the defected TMD nanoribbons.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:32:55 GMT""}]","2023-02-23"
"2302.11061","Luis Espath","Luis Espath, Pouria Behnoudfar, and Raul Tempone","Physics-informed Spectral Learning: the Discrete Helmholtz--Hodge
  Decomposition",,,,,"cs.LG cs.NA math.NA physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we further develop the Physics-informed Spectral Learning
(PiSL) by Espath et al. \cite{Esp21} based on a discrete $L^2$ projection to
solve the discrete Hodge--Helmholtz decomposition from sparse data. Within this
physics-informed statistical learning framework, we adaptively build a sparse
set of Fourier basis functions with corresponding coefficients by solving a
sequence of minimization problems where the set of basis functions is augmented
greedily at each optimization problem. Moreover, our PiSL computational
framework enjoys spectral (exponential) convergence. We regularize the
minimization problems with the seminorm of the fractional Sobolev space in a
Tikhonov fashion. In the Fourier setting, the divergence- and curl-free
constraints become a finite set of linear algebraic equations. The proposed
computational framework combines supervised and unsupervised learning
techniques in that we use data concomitantly with the projection onto
divergence- and curl-free spaces. We assess the capabilities of our method in
various numerical examples including the `Storm of the Century' with satellite
data from 1993.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:33:29 GMT""}]","2023-02-23"
"2302.11062","Kyle Rust","Kyle R. Rust and Toby D. Hocking","A Log-linear Gradient Descent Algorithm for Unbalanced Binary
  Classification using the All Pairs Squared Hinge Loss",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Receiver Operating Characteristic (ROC) curves are plots of true positive
rate versus false positive rate which are used to evaluate binary
classification algorithms. Because the Area Under the Curve (AUC) is a constant
function of the predicted values, learning algorithms instead optimize convex
relaxations which involve a sum over all pairs of labeled positive and negative
examples. Naive learning algorithms compute the gradient in quadratic time,
which is too slow for learning using large batch sizes. We propose a new
functional representation of the square loss and squared hinge loss, which
results in algorithms that compute the gradient in either linear or log-linear
time, and makes it possible to use gradient descent learning with large batch
sizes. In our empirical study of supervised binary classification problems, we
show that our new algorithm can achieve higher test AUC values on imbalanced
data sets than previous algorithms, and make use of larger batch sizes than
were previously feasible.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:35:00 GMT""}]","2023-02-23"
"2302.11063","Osvaldo Pablo Santillan","Fernando Chamizo and Osvaldo Santillan","About the quantum Talbot effect on the sphere","Some notions clarified, 22 pages",,,,"quant-ph math-ph math.MP math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Schr\""odinger equation on a circle with an initially localized profile of
the wave function is known to give rise to revivals or replications, where the
probability density of the particle is partially reproduced at rational times.
As a consequence of the convolutional form of the general solution it is
deduced that a piecewise constant initial wave function remains piecewise
constant at rational times as well. For a sphere instead, it is known that this
piecewise revival does not necessarily occur, indeed the wave function becomes
singular at some specific locations at rational times. It may be desirable to
study the same problem, but with an initial condition being a localized Dirac
delta instead of a piecewise constant function, and this is the purpose of the
present work. By use of certain summation formulas for the Legendre polynomials
together with properties of Gaussian sums, it is found that revivals on the
sphere occur at rational times for some specific locations, and the structure
of singularities of the resulting wave function is characterized in detail. In
addition, a partial study of the regions where the density vanishes, named
before valley of shadows in the context of the circle, is initiated here. It is
suggested that, differently from the circle case, these regions are not lines
but instead some specific set of points along the sphere. A conjecture about
the precise form of this set is stated and the intuition behind it is
clarified.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:38:08 GMT""},{""version"":""v2"",""created"":""Thu, 27 Apr 2023 00:48:38 GMT""}]","2023-04-28"
"2302.11064","Burak Kizilkaya","Burak Kizilkaya, Changyang She, Guodong Zhao, Muhammad Ali Imran","Task-Oriented Prediction and Communication Co-Design for Haptic
  Communications","Accepted for publication in the IEEE Transactions on Vehicular
  Technology",,,,"cs.RO cs.LG cs.NI cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  Prediction has recently been considered as a promising approach to meet
low-latency and high-reliability requirements in long-distance haptic
communications. However, most of the existing methods did not take features of
tasks and the relationship between prediction and communication into account.
In this paper, we propose a task-oriented prediction and communication
co-design framework, where the reliability of the system depends on prediction
errors and packet losses in communications. The goal is to minimize the
required radio resources subject to the low-latency and high-reliability
requirements of various tasks. Specifically, we consider the just noticeable
difference (JND) as a performance metric for the haptic communication system.
We collect experiment data from a real-world teleoperation testbed and use
time-series generative adversarial networks (TimeGAN) to generate a large
amount of synthetic data. This allows us to obtain the relationship between the
JND threshold, prediction horizon, and the overall reliability including
communication reliability and prediction reliability. We take 5G New Radio as
an example to demonstrate the proposed framework and optimize bandwidth
allocation and data rates of devices. Our numerical and experimental results
show that the proposed framework can reduce wireless resource consumption up to
77.80% compared with a task-agnostic benchmark.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:39:37 GMT""}]","2023-02-23"
"2302.11065","Gao-Chan Yong","Zhi-Min Wu, Gao-Chan Yong","Probing the incompressibility of dense hadronic matter near QCD phase
  transition in relativistic heavy-ion collisions","5 pages, 4 figures, accepted by PRC, in production","Phys. Rev. C 107, 034902 (2023)","10.1103/PhysRevC.107.034902",,"nucl-th nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Based on the extended hadronic transport model of relativistic heavy-ion
collisions, the incompressibility of dense hadronic matter created in
relativistic Au+Au heavy-ion collisions at $\sqrt{s_{NN}} = 3$ GeV is studied.
By comparing experimental proton directed flow, productions of strange hadrons
$\phi$, $K^{-}$ as well as their ratio $\phi/K^{-}$, proton high-order
cumulants to the model calculations, a large incompressibility of dense
hadronic matter is obtained from nucleon observabels while a rather small
incompressibility is needed to fit the data of strange hadrons. This may
indicate hadronic matter possesses different incompressibilities in different
density regions, i.e., the incompressibility may become stiffer from saturation
density to a certain baryon density and then turn to soft before reaching
hadron-quark phase transition. The study also shows that the incompressibility
significantly affects the critical baryon density of hadron-quark phase
transition.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:43:11 GMT""}]","2023-03-07"
"2302.11066","Cristina Garcia Cardona","Benjamin C. DiPrete, Rao V. Garimella, Cristina Garcia Cardona,
  Navamita Ray","Reinforcement Learning for Block Decomposition of CAD Models","AAAI-2022 Fall Symposium Series",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present a novel AI-assisted method for decomposing (segmenting) planar CAD
(computer-aided design) models into well shaped rectangular blocks as a
proof-of-principle of a general decomposition method applicable to complex 2D
and 3D CAD models. The decomposed blocks are required for generating good
quality meshes (tilings of quadrilaterals or hexahedra) suitable for numerical
simulations of physical systems governed by conservation laws. The problem of
hexahedral mesh generation of general CAD models has vexed researchers for over
3 decades and analysts often spend more than 50% of the design-analysis cycle
time decomposing complex models into simpler parts meshable by existing
techniques. Our method uses reinforcement learning to train an agent to perform
a series of optimal cuts on the CAD model that result in a good quality block
decomposition. We show that the agent quickly learns an effective strategy for
picking the location and direction of the cuts and maximizing its rewards as
opposed to making random cuts. This paper is the first successful demonstration
of an agent autonomously learning how to perform this block decomposition task
effectively thereby holding the promise of a viable method to automate this
challenging process.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:43:19 GMT""}]","2023-02-23"
"2302.11067","Rich Wang","Tanya Khovanova and Rich Wang","Ending States of a Special Variant of the Chip-Firing Algorithm","34 pages, 5 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a special variant of chip-firing, in which we consider an
infinite set of rooms on a number line, some of which are occupied by
violinists. In a move, we take two violinists in adjacent rooms, and send one
of them to the closest unoccupied room to the left and the other to the closest
unoccupied room to the right. We classify the different possible final states
from repeatedly performing this operation. We introduce numbers $R(N,\ell,x)$
that count labeled recursive rooted trees with $N$ vertices, $\ell$ leaves, and
the smallest rooted path ending in $x$. We describe the properties of these
numbers and connect them to permutations. We conjecture that these numbers
describe the probabilities ending with different final states when the moves
are chosen uniformly.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:45:05 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 22:57:13 GMT""}]","2023-03-30"
"2302.11068","Yuzhou Gu","Yuzhou Gu, Zhao Song, Junze Yin, Lichen Zhang","Low Rank Matrix Completion via Robust Alternating Minimization in Nearly
  Linear Time",,,,,"cs.LG cs.DS math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion
problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in
\mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a
few entries masked by a binary matrix $P_{\Omega}\in \{0, 1 \}^{m\times n}$. As
a particular instance of the weighted low rank approximation problem, solving
low rank matrix completion is known to be computationally hard even to find an
approximate solution [RSW16]. However, due to its practical importance, many
heuristics have been proposed for this problem. In the seminal work of Jain,
Netrapalli, and Sanghavi [JNS13], they show that the alternating minimization
framework provides provable guarantees for low rank matrix completion problem
whenever $M$ admits an incoherent low rank factorization. Unfortunately, their
algorithm requires solving two exact multiple response regressions per
iteration and their analysis is non-robust as they exploit the structure of the
exact solution.
  In this paper, we take a major step towards a more efficient and robust
alternating minimization framework for low rank matrix completion. Our main
result is a robust alternating minimization algorithm that can tolerate
moderate errors even though the regressions are solved approximately.
Consequently, we also significantly improve the running time of [JNS13] from
$\widetilde{O}(mnk^2 )$ to $\widetilde{O}(mnk )$ which is nearly linear in the
problem size, as verifying the low rank approximation takes $O(mnk)$ time. Our
core algorithmic building block is a high accuracy regression solver that
solves the regression in nearly linear time per iteration.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:49:36 GMT""}]","2023-02-23"
"2302.11069","Alexander Balandin","Zahra Barani, Tekwam Geremew, Megan Stokey, Nicholas Sesing, Maedeh
  Taheri, Matthew J. Hilfiker, Fariborz Kargar, Mathias Schubert, Tina T.
  Salguero, and Alexander A. Balandin","Quantum Composites with the Functionality Defined by the
  Charge-Density-Wave Phase Transitions","23 pages, 5 figures",,,,"cond-mat.mtrl-sci cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We demonstrate a unique class of advanced materials - quantum composites
based on polymers with fillers comprised of a van der Waals quantum material
that reveals multiple charge-density-wave quantum condensate phases. Materials
that exhibit quantum phenomena are typically crystalline, pure, and have few
defects because disorder destroys the coherence of the electrons and phonons,
leading to collapses of the quantum states. We succeeded in preserving the
macroscopic charge-density-wave phases of filler particles after multiple
composite processing steps. The prepared composites manifest strong
charge-density-wave phenomena even above room temperature. The dielectric
constant experiences more than two orders of magnitude enhancement while the
material maintains its electrically insulating properties, opening a venue for
advanced applications in energy storage and electronics. The results present a
conceptually different approach for engineering the properties of materials,
extending the application domain for van der Waals materials.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:53:28 GMT""}]","2023-02-23"
"2302.11070","Zheng Xiong","Zheng Xiong, Jacob Beck, Shimon Whiteson","Universal Morphology Control via Contextual Modulation",,,,,"cs.AI cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning a universal policy across different robot morphologies can
significantly improve learning efficiency and generalization in continuous
control. However, it poses a challenging multi-task reinforcement learning
problem, as the optimal policy may be quite different across robots and
critically depend on the morphology. Existing methods utilize graph neural
networks or transformers to handle heterogeneous state and action spaces across
different morphologies, but pay little attention to the dependency of a robot's
control policy on its morphology context. In this paper, we propose a
hierarchical architecture to better model this dependency via contextual
modulation, which includes two key submodules: (1) Instead of enforcing hard
parameter sharing across robots, we use hypernetworks to generate
morphology-dependent control parameters; (2) We propose a morphology-dependent
attention mechanism to modulate the interactions between different limbs in a
robot. Experimental results show that our method not only improves learning
performance on a diverse set of training robots, but also generalizes better to
unseen morphologies in a zero-shot fashion.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:04:12 GMT""}]","2023-02-23"
"2302.11071","Junhyeon Jo","Junhyeon Jo, Francesco Calavalle, Beatriz Mart\'in-Garc\'ia, F\`elix
  Casanova, Andrey Chuvilin, Luis E. Hueso, Marco Gobbi","Exchange bias in molecule/Fe3GeTe2 van der Waals heterostructures via
  spinterface effects",,"Adv. Mater. 34, 2200474 (2022)","10.1002/adma.202200474",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The exfoliation of layered magnetic materials generates atomically thin
flakes characterized by an ultrahigh surface sensitivity, which makes their
magnetic properties tunable via external stimuli, such as electrostatic gating
and proximity effects. Another powerful approach to tailor magnetic materials
is molecular functionalization, which leads to hybrid interface states with
peculiar magnetic properties, called spinterfaces. However, spinterface effects
have not yet been explored on layered magnetic materials. Here, we demonstrate
the emergence of spinterface effects at the interface between flakes of the
prototypical layered magnetic metal Fe3GeTe2 and thin films of paramagnetic
Co-phthalocyanine. Magnetotransport measurements show that the molecular layer
induces a magnetic exchange bias in Fe3GeTe2, indicating that the unpaired
spins in Co-phthalocyanine develop antiferromagnetic ordering by proximity and
pin the magnetization reversal of Fe3GeTe2. The effect is strongest for a
Fe3GeTe2 thickness of 20 nm, for which the exchange bias field reaches -840 Oe
and is measurable up to approximately 110 K. This value compares very favorably
with previous exchange bias fields reported for Fe3GeTe2 in all-inorganic van
der Waals heterostructures, demonstrating the potential of molecular
functionalization to tailor the magnetism of van der Waals layered materials.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:05:39 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 12:34:46 GMT""}]","2023-02-27"
"2302.11072","Rabindra N. Mohapatra","Rabindra N. Mohapatra and Nobuchika Okada","Conformal B-L and Pseudo-Goldstone Dark Matter","16 pages and seven figures; references updated",,"10.1103/PhysRevD.107.095023",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We show that a conformal extension of the standard model with local B-L
symmetry and two complex scalars breaking B-L can provide a unified description
of neutrino mass, origin of matter and dark matter. There are two hierarchical
B-L breaking vacuum expectation value (VEV) scales in the model, the higher
denoted by $v_B$ and the lower by $v_A$. The higher breaking scale is
dynamically implemented via the Coleman-Weinberg mechanism and plays a key role
in the model since it induces electroweak symmetry breaking as well as the
lower B-L breaking scale. It is also responsible for neutrino masses via the
seesaw mechanism and origin of matter. The imaginary part of the complex scalar
with lower B-L breaking VEV plays the role of a pseudo-Goldstone dark matter
(DM). The DM particle is unstable with its lifetime naturally longer than
$10^{28}$ seconds. We show that its relic density arises from the freeze-in
mechanism for a wide parameter domain. Due to the pseudo-Goldstone boson nature
of the DM particle, the direct detection cross section is highly suppressed.
The model also predicts the dark matter to be heavier than 100 TeV and it
decays to two high energy neutrinos which can be observable at the IceCube,
providing a test of this model.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:06:28 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 18:33:49 GMT""}]","2023-05-31"
"2302.11073","Renato G. Bettiol","Renato G. Bettiol, Mar\'ia del Mar Gonz\'alez, Ali Maalaoui","Multiplicity of singular solutions to the fractional Yamabe problem on
  spheres","LaTeX2e, 16 pages, 2 figures",,,,"math.DG math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove nonuniqueness results for complete metrics with constant positive
fractional curvature conformal to the round metric on $S^n \setminus S^k$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:12:49 GMT""}]","2023-02-23"
"2302.11074","Sudipta Kar","Sudipta Kar, Giuseppe Castellucci, Simone Filice, Shervin Malmasi,
  Oleg Rokhlenko","Preventing Catastrophic Forgetting in Continual Learning of New Natural
  Language Tasks","KDD 2022",,"10.1145/3534678.3539169",,"cs.CL cs.AI cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Multi-Task Learning (MTL) is widely-accepted in Natural Language Processing
as a standard technique for learning multiple related tasks in one model.
Training an MTL model requires having the training data for all tasks available
at the same time. As systems usually evolve over time, (e.g., to support new
functionalities), adding a new task to an existing MTL model usually requires
retraining the model from scratch on all the tasks and this can be
time-consuming and computationally expensive. Moreover, in some scenarios, the
data used to train the original training may be no longer available, for
example, due to storage or privacy concerns. In this paper, we approach the
problem of incrementally expanding MTL models' capability to solve new tasks
over time by distilling the knowledge of an already trained model on n tasks
into a new one for solving n+1 tasks. To avoid catastrophic forgetting, we
propose to exploit unlabeled data from the same distributions of the old tasks.
Our experiments on publicly available benchmarks show that such a technique
dramatically benefits the distillation by preserving the already acquired
knowledge (i.e., preventing up to 20% performance drops on old tasks) while
obtaining good performance on the incrementally added tasks. Further, we also
show that our approach is beneficial in practical settings by using data from a
leading voice assistant.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:18:25 GMT""}]","2023-02-23"
"2302.11075","Moseli Mots'oehli","Moseli Mots'oehli","Deep Active Learning in the Presence of Label Noise: A Survey","20 pages, PhD literature review",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Deep active learning has emerged as a powerful tool for training deep
learning models within a predefined labeling budget. These models have achieved
performances comparable to those trained in an offline setting. However, deep
active learning faces substantial issues when dealing with classification
datasets containing noisy labels. In this literature review, we discuss the
current state of deep active learning in the presence of label noise,
highlighting unique approaches, their strengths, and weaknesses. With the
recent success of vision transformers in image classification tasks, we provide
a brief overview and consider how the transformer layers and attention
mechanisms can be used to enhance diversity, importance, and uncertainty-based
selection in queries sent to an oracle for labeling. We further propose
exploring contrastive learning methods to derive good image representations
that can aid in selecting high-value samples for labeling in an active learning
setting. We also highlight the need for creating unified benchmarks and
standardized datasets for deep active learning in the presence of label noise
for image classification to promote the reproducibility of research. The review
concludes by suggesting avenues for future research in this area.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:27:39 GMT""}]","2023-02-23"
"2302.11076","Yian Deng","Yian Deng, Tingting Mu","Faster Riemannian Newton-type Optimization by Subsampling and Cubic
  Regularization",,,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is on constrained large-scale non-convex optimization where the
constraint set implies a manifold structure. Solving such problems is important
in a multitude of fundamental machine learning tasks. Recent advances on
Riemannian optimization have enabled the convenient recovery of solutions by
adapting unconstrained optimization algorithms over manifolds. However, it
remains challenging to scale up and meanwhile maintain stable convergence rates
and handle saddle points. We propose a new second-order Riemannian optimization
algorithm, aiming at improving convergence rate and reducing computational
cost. It enhances the Riemannian trust-region algorithm that explores curvature
information to escape saddle points through a mixture of subsampling and cubic
regularization techniques. We conduct rigorous analysis to study the
convergence behavior of the proposed algorithm. We also perform extensive
experiments to evaluate it based on two general machine learning tasks using
multiple datasets. The proposed algorithm exhibits improved computational speed
and convergence behavior compared to a large set of state-of-the-art Riemannian
optimization algorithms.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:37:44 GMT""}]","2023-02-23"
"2302.11077","Fred Song","Yu Song, Madhav V. Chitturi, David A. Noyce","Impact of Event Encoding and Dissimilarity Measures on Traffic Crash
  Characterization Based on Sequence of Events",,,"10.1016/j.aap.2023.107016",,"stat.AP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crash sequence analysis has been shown in prior studies to be useful for
characterizing crashes and identifying safety countermeasures. Sequence
analysis is highly domain-specific, but its various techniques have not been
evaluated for adaptation to crash sequences. This paper evaluates the impact of
encoding and dissimilarity measures on crash sequence analysis and clustering.
Sequence data of interstate highway, single-vehicle crashes in the United
States, from 2016-2018, were studied. Two encoding schemes and five optimal
matching based dissimilarity measures were compared by evaluating the sequence
clustering results. The five dissimilarity measures were categorized into two
groups based on correlations between dissimilarity matrices. The optimal
dissimilarity measure and encoding scheme were identified based on the
agreements with a benchmark crash categorization. The transition-rate-based,
localized optimal matching dissimilarity and consolidated encoding scheme had
the highest agreement with the benchmark. Evaluation results indicate that the
selection of dissimilarity measure and encoding scheme determines the results
of sequence clustering and crash characterization. A dissimilarity measure that
considers the relationships between events and domain context tends to perform
well in crash sequence clustering. An encoding scheme that consolidates similar
events naturally takes domain context into consideration.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:38:15 GMT""}]","2023-03-03"
"2302.11078","Tian Guo","Tian Guo","Learning Mixture Structure on Multi-Source Time Series for Probabilistic
  Forecasting","A causal view on dynamical systems workshop at the 36th Conference on
  Neural Information Processing Sys- tems (NeurIPS 2022)",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In many data-driven applications, collecting data from different sources is
increasingly desirable for enhancing performance. In this paper, we are
interested in the problem of probabilistic forecasting with multi-source time
series. We propose a neural mixture structure-based probability model for
learning different predictive relations and their adaptive combinations from
multi-source time series. We present the prediction and uncertainty
quantification methods that apply to different distributions of target
variables. Additionally, given the imbalanced and unstable behaviors observed
during the direct training of the proposed mixture model, we develop a phased
learning method and provide a theoretical analysis. In experimental
evaluations, the mixture model trained by the phased learning exhibits
competitive performance on both point and probabilistic prediction metrics.
Meanwhile, the proposed uncertainty conditioned error suggests the potential of
the mixture model's uncertainty score as a reliability indicator of
predictions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:51:44 GMT""}]","2023-02-23"
"2302.11079","Andrew Melatos","A. Melatos, M. Millhouse","Measuring the vortex-nucleus pinning force from pulsar glitch rates","34 pages, 6 figures, accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/acbb6e",,"astro-ph.HE nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Superfluid vortex avalanches are one plausible cause of pulsar glitch
activity. If they occur according to a state-dependent Poisson process, the
measured long-term glitch rate is determined by the spin-down rate of the
stellar crust, $\dot{\Omega}_{\rm c}$, and two phenomenological parameters
quantifying the vortex-nucleus pinning force: a crust-superfluid angular
velocity lag threshold, $X_{\rm cr}$, and a reference unpinning rate,
$\lambda_0$. A Bayesian analysis of 541 glitches in 177 pulsars, with $N_{\rm
g} \geq 1$ events per pulsar, yields $X_{\rm cr} = 0.15^{+0.09}_{-0.04} \, {\rm
rad \, s^{-1}}$, $\lambda_{\rm ref} = 7.6^{+3.7}_{-2.6} \times 10^{-8} \, {\rm
s^{-1}}$, and $a = -0.27^{+0.04}_{-0.03}$ assuming the phenomenological rate
law $\lambda_0 = \lambda_{\rm ref} [\tau/(1 \, {\rm yr})]^a$, where $\tau$
denotes the characteristic spin-down age. The results are broadly similar,
whether one includes or excludes quasiperiodic glitch activity, giant glitches,
or pulsars with $N_{\rm g}=0$, up to uncertainties about the completeness of
the sample and the total observation time per pulsar. The $X_{\rm cr}$ and
$\lambda_0$ estimates are consistent with first-principles calculations based
on nuclear theory, e.g. in the semiclassical local density approximation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:53:18 GMT""}]","2023-05-17"
"2302.11080","Jingcao Wu","Jingcao Wu","A relative Nadel-type vanishing theorem","19 pages, comments are welcome!",,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove a relative Nadel-type vanishing theorem on K\""{a}hler
morphisms. Then we discuss its applications on harmonic bundles. In particular,
it gives a relative vanishing concerning Saito's S-sheaves.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 00:54:39 GMT""}]","2023-02-23"
"2302.11081","Samson Zhou","Jeremiah Blocki, Seunghoon Lee, Tamalika Mukherjee, Samson Zhou","Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model","ICLR 2023",,,,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  The data management of large companies often prioritize more recent data, as
a source of higher accuracy prediction than outdated data. For example, the
Facebook data policy retains user search histories for $6$ months while the
Google data retention policy states that browser information may be stored for
up to $9$ months. These policies are captured by the sliding window model, in
which only the most recent $W$ statistics form the underlying dataset.
  In this paper, we consider the problem of privately releasing the $L_2$-heavy
hitters in the sliding window model, which include $L_p$-heavy hitters for
$p\le 2$ and in some sense are the strongest possible guarantees that can be
achieved using polylogarithmic space, but cannot be handled by existing
techniques due to the sub-additivity of the $L_2$ norm. Moreover, existing
non-private sliding window algorithms use the smooth histogram framework, which
has high sensitivity.
  To overcome these barriers, we introduce the first differentially private
algorithm for $L_2$-heavy hitters in the sliding window model by initiating a
number of $L_2$-heavy hitter algorithms across the stream with significantly
lower threshold. Similarly, we augment the algorithms with an approximate
frequency tracking algorithm with significantly higher accuracy. We then use
smooth sensitivity and statistical distance arguments to show that we can add
noise proportional to an estimation of the $L_2$ norm. To the best of our
knowledge, our techniques are the first to privately release statistics that
are related to a sub-additive function in the sliding window model, and may be
of independent interest to future differentially private algorithmic design in
the sliding window model.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:02:34 GMT""}]","2023-02-23"
"2302.11082","Guoli Wang","Guoli Wang, Pingping Wang, Jinyu Cong, Kunmeng Liu, Benzheng Wei","BB-GCN: A Bi-modal Bridged Graph Convolutional Network for Multi-label
  Chest X-Ray Recognition","under Computers in Biology and Medicine submission",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Multi-label chest X-ray (CXR) recognition involves simultaneously diagnosing
and identifying multiple labels for different pathologies. Since pathological
labels have rich information about their relationship to each other, modeling
the co-occurrence dependencies between pathological labels is essential to
improve recognition performance. However, previous methods rely on state
variable coding and attention mechanisms-oriented to model local label
information, and lack learning of global co-occurrence relationships between
labels. Furthermore, these methods roughly integrate image features and label
embedding, ignoring the alignment and compactness problems in cross-modal
vector fusion.To solve these problems, a Bi-modal Bridged Graph Convolutional
Network (BB-GCN) model is proposed. This model mainly consists of a backbone
module, a pathology Label Co-occurrence relationship Embedding (LCE) module,
and a Transformer Bridge Graph (TBG) module. Specifically, the backbone module
obtains image visual feature representation. The LCE module utilizes a graph to
model the global co-occurrence relationship between multiple labels and employs
graph convolutional networks for learning inference. The TBG module bridges the
cross-modal vectors more compactly and efficiently through the GroupSum
method.We have evaluated the effectiveness of the proposed BB-GCN in two
large-scale CXR datasets (ChestX-Ray14 and CheXpert). Our model achieved
state-of-the-art performance: the mean AUC scores for the 14 pathologies were
0.835 and 0.813, respectively.The proposed LCE and TBG modules can jointly
effectively improve the recognition performance of BB-GCN. Our model also
achieves satisfactory results in multi-label chest X-ray recognition and
exhibits highly competitive generalization performance.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:03:53 GMT""}]","2023-02-23"
"2302.11083","James Bartusek","James Bartusek, Fuyuki Kitagawa, Ryo Nishimaki, and Takashi Yamakawa","Obfuscation of Pseudo-Deterministic Quantum Circuits",,,,,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show how to obfuscate pseudo-deterministic quantum circuits, assuming the
quantum hardness of learning with errors (QLWE) and post-quantum virtual
black-box (VBB) obfuscation for classical circuits. Given the classical
description of a quantum circuit $Q$, our obfuscator outputs a quantum state
$\ket{\widetilde{Q}}$ that can be used to evaluate $Q$ repeatedly on arbitrary
inputs.
  Instantiating the VBB obfuscator for classical circuits with any candidate
post-quantum indistinguishability obfuscator gives us the first candidate
construction of indistinguishability obfuscation for all polynomial-size
pseudo-deterministic quantum circuits. In particular, our scheme is the first
candidate obfuscator for a class of circuits that is powerful enough to
implement Shor's algorithm (SICOMP 1997).
  Our approach follows Bartusek and Malavolta (ITCS 2022), who obfuscate
\emph{null} quantum circuits by obfuscating the verifier of an appropriate
classical verification of quantum computation (CVQC) scheme. We go beyond null
circuits by constructing a publicly-verifiable CVQC scheme for quantum
\emph{partitioning} circuits, which can be used to verify the evaluation
procedure of Mahadev's quantum fully-homomorphic encryption scheme (FOCS 2018).
We achieve this by upgrading the one-time secure scheme of Bartusek (TCC 2021)
to a fully reusable scheme, via a publicly-decodable \emph{Pauli functional
commitment}, which we formally define and construct in this work. This
commitment scheme, which satisfies a notion of binding against committers that
can access the receiver's standard and Hadamard basis decoding functionalities,
is constructed by building on techniques of Amos, Georgiou, Kiayias, and
Zhandry (STOC 2020) introduced in the context of equivocal but
collision-resistant hash functions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:14:20 GMT""},{""version"":""v2"",""created"":""Thu, 20 Apr 2023 16:16:38 GMT""}]","2023-04-21"
"2302.11084","Yifei Zhou Mr.","Yifei Zhou, Juntao Ren, Fengyu Li, Ramin Zabih, Ser-Nam Lim","Distribution Normalization: An ""Effortless"" Test-Time Augmentation for
  Contrastively Learned Visual-language Models","13 pages, 4 figures",,,,"cs.LG cs.CL cs.CV","http://creativecommons.org/licenses/by/4.0/","  Advances in the field of visual-language contrastive learning have made it
possible for many downstream applications to be carried out efficiently and
accurately by simply taking the dot product between image and text
representations. One of the most representative approaches proposed recently
known as CLIP has quickly garnered widespread adoption due to its
effectiveness. CLIP is trained with an InfoNCE loss that takes into account
both positive and negative samples to help learn a much more robust
representation space. This paper however reveals that the common downstream
practice of taking a dot product is only a zeroth-order approximation of the
optimization goal, resulting in a loss of information during test-time.
Intuitively, since the model has been optimized based on the InfoNCE loss,
test-time procedures should ideally also be in alignment. The question lies in
how one can retrieve any semblance of negative samples information during
inference. We propose Distribution Normalization (DN), where we approximate the
mean representation of a batch of test samples and use such a mean to represent
what would be analogous to negative samples in the InfoNCE loss. DN requires no
retraining or fine-tuning and can be effortlessly applied during inference.
Extensive experiments on a wide variety of downstream tasks exhibit a clear
advantage of DN over the dot product.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:14:30 GMT""}]","2023-02-23"
"2302.11085","Junjie Yang","Junjie Yang, Tianlong Chen, Mingkang Zhu, Fengxiang He, Dacheng Tao,
  Yingbin Liang, Zhangyang Wang","Learning to Generalize Provably in Learning to Optimize","This paper is accepted in AISTATS 2023",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning to optimize (L2O) has gained increasing popularity, which automates
the design of optimizers by data-driven approaches. However, current L2O
methods often suffer from poor generalization performance in at least two
folds: (i) applying the L2O-learned optimizer to unseen optimizees, in terms of
lowering their loss function values (optimizer generalization, or
``generalizable learning of optimizers""); and (ii) the test performance of an
optimizee (itself as a machine learning model), trained by the optimizer, in
terms of the accuracy over unseen data (optimizee generalization, or ``learning
to generalize""). While the optimizer generalization has been recently studied,
the optimizee generalization (or learning to generalize) has not been
rigorously studied in the L2O context, which is the aim of this paper. We first
theoretically establish an implicit connection between the local entropy and
the Hessian, and hence unify their roles in the handcrafted design of
generalizable optimizers as equivalent metrics of the landscape flatness of
loss functions. We then propose to incorporate these two metrics as
flatness-aware regularizers into the L2O framework in order to meta-train
optimizers to learn to generalize, and theoretically show that such
generalization ability can be learned during the L2O meta-training process and
then transformed to the optimizee loss function. Extensive experiments
consistently validate the effectiveness of our proposals with substantially
improved generalization on multiple sophisticated L2O models and diverse
optimizees. Our code is available at:
https://github.com/VITA-Group/Open-L2O/tree/main/Model_Free_L2O/L2O-Entropy.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:17:31 GMT""},{""version"":""v2"",""created"":""Tue, 28 Mar 2023 17:57:05 GMT""}]","2023-03-29"
"2302.11086","Travis Yeager","Travis Yeager and Nathan Golovich","MEGASIM: Distribution and Detection of Earth Trojan Asteroids",,,,,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  Using the MEGASIM, we present spatial distributions of Earth Trojan Asteroids
and assess the detectability of the population in current and next-generation
ground-based astronomical surveys. Our high-fidelity Earth Trojan Asteroid
(ETA) distribution maps show never-before-seen high-resolution spatial features
that evolve over timescales up to 1 Gyr. The simulation was synchronized to two
surveys, 1) the Vera C. Rubin Observatory's Legacy Survey of Space and Time
(LSST) and 2) the Zwicky Transient Facility (ZTF) public and partnership
survey. Upper limits were calculated for the ETA population for ZTF (with
assumed null detection) and LSST's cadence simulations. For LSST, a null
detection is within three sigma of the simulation results out to H=19 for the
twilight survey and H=20 for the baseline survey. Due to the Yarkovsky Effect,
no ETAs are stable on billion year timescales are likely to be detected. ETAs
large enough to remain stable on billion year timescales are very rare relative
to the rest of the ETA population. A null detection in LSST will restrict that
population to tens of objects larger than 100 meters. The null detection by ZTF
to date has already done so.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:25:00 GMT""}]","2023-02-23"
"2302.11087","Zhicheng He","Zhicheng He and Weiwen Liu and Wei Guo and Jiarui Qin and Yingxue
  Zhang and Yaochen Hu and Ruiming Tang","A Survey on User Behavior Modeling in Recommender Systems","9 pages",,,,"cs.IR cs.LG","http://creativecommons.org/licenses/by-nc-nd/4.0/","  User Behavior Modeling (UBM) plays a critical role in user interest learning,
which has been extensively used in recommender systems. Crucial interactive
patterns between users and items have been exploited, which brings compelling
improvements in many recommendation tasks. In this paper, we attempt to provide
a thorough survey of this research topic. We start by reviewing the research
background of UBM. Then, we provide a systematic taxonomy of existing UBM
research works, which can be categorized into four different directions
including Conventional UBM, Long-Sequence UBM, Multi-Type UBM, and UBM with
Side Information. Within each direction, representative models and their
strengths and weaknesses are comprehensively discussed. Besides, we elaborate
on the industrial practices of UBM methods with the hope of providing insights
into the application value of existing UBM solutions. Finally, we summarize the
survey and discuss the future prospects of this field.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:34:51 GMT""}]","2023-02-23"
"2302.11088","Konstantin Slutsky","Konstantin Slutsky","Katok's special representation theorem for multidimensional Borel flows",,,,,"math.DS math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Katok's special representation theorem states that any free ergodic
measure-preserving $\mathbb{R}^{d}$-flow can be realized as a special flow over
a $\mathbb{Z}^{d}$-action. It provides a multidimensional generalization of the
""flow under a function"" construction. We prove the analog of Katok's theorem in
the framework of Borel dynamics and show that, likewise, all free Borel
$\mathbb{R}^{d}$-flows emerge from $\mathbb{Z}^{d}$-actions through the special
flow construction using bi-Lipschitz cocycles.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:39:45 GMT""}]","2023-02-23"
"2302.11089","Arman Asgharpoor Golroudbari","Arman Asgharpoor Golroudbari and Mohammad Hossein Sabour","Recent Advancements in Deep Learning Applications and Methods for
  Autonomous Navigation: A Comprehensive Review",,,,,"cs.RO cs.AI cs.SY eess.SP eess.SY","http://creativecommons.org/licenses/by/4.0/","  This review article is an attempt to survey all recent AI based techniques
used to deal with major functions in This review paper presents a comprehensive
overview of end-to-end deep learning frameworks used in the context of
autonomous navigation, including obstacle detection, scene perception, path
planning, and control. The paper aims to bridge the gap between autonomous
navigation and deep learning by analyzing recent research studies and
evaluating the implementation and testing of deep learning methods. It
emphasizes the importance of navigation for mobile robots, autonomous vehicles,
and unmanned aerial vehicles, while also acknowledging the challenges due to
environmental complexity, uncertainty, obstacles, dynamic environments, and the
need to plan paths for multiple agents. The review highlights the rapid growth
of deep learning in engineering data science and its development of innovative
navigation methods. It discusses recent interdisciplinary work related to this
field and provides a brief perspective on the limitations, challenges, and
potential areas of growth for deep learning methods in autonomous navigation.
Finally, the paper summarizes the findings and practices at different stages,
correlating existing and future methods, their applicability, scalability, and
limitations. The review provides a valuable resource for researchers and
practitioners working in the field of autonomous navigation and deep learning.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:42:49 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 21:00:58 GMT""},{""version"":""v3"",""created"":""Tue, 23 May 2023 21:47:18 GMT""}]","2023-05-25"
"2302.11090","Guanlong  Bao","Guanlong Bao, Zengjian Lou and Xiaojing Zhou","Duality for $\alpha$-M\""obius invariant Besov spaces",,,,,"math.CV","http://creativecommons.org/licenses/by/4.0/","  For $1\leq p\leq \infty$ and $\alpha>0$, Besov spaces $B^p_\alpha$ play a key
role in the theory of $\alpha$-M\""obius invariant function spaces. In some
sense, $B^1_\alpha$ is the minimal $\alpha$-M\""obius invariant function space,
$B^2_\alpha$ is the unique $\alpha$-M\""obius invariant Hilbert space, and
$B^\infty_\alpha$ is the maximal $\alpha$-M\""obius invariant function space. In
this paper, under the $\alpha$-M\""obius invariant pairing and by the space
$B^\infty_\alpha$, we identify the predual and dual spaces of $B^1_\alpha$. In
particular, the corresponding identifications are isometric isomorphisms. The
duality theorem via the $\alpha$-M\""obius invariant pairing for $B^p_\alpha$
with $p>1$ is also given.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:53:03 GMT""}]","2023-02-23"
"2302.11091","Ling Chen","Xing Tang, Ling Chen","GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation
  Learning Method","12 pages and 9 figures",,,,"cs.LG cs.AI cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Temporal Knowledge Graph (TKG) representation learning embeds entities and
event types into a continuous low-dimensional vector space by integrating the
temporal information, which is essential for downstream tasks, e.g., event
prediction and question answering. Existing methods stack multiple graph
convolution layers to model the influence of distant entities, leading to the
over-smoothing problem. To alleviate the problem, recent studies infuse
reinforcement learning to obtain paths that contribute to modeling the
influence of distant entities. However, due to the limited number of hops,
these studies fail to capture the correlation between entities that are far
apart and even unreachable. To this end, we propose GTRL, an entity Group-aware
Temporal knowledge graph Representation Learning method. GTRL is the first work
that incorporates the entity group modeling to capture the correlation between
entities by stacking only a finite number of layers. Specifically, the entity
group mapper is proposed to generate entity groups from entities in a learning
way. Based on entity groups, the implicit correlation encoder is introduced to
capture implicit correlations between any pairwise entity groups. In addition,
the hierarchical GCNs are exploited to accomplish the message aggregation and
representation updating on the entity group graph and the entity graph.
Finally, GRUs are employed to capture the temporal dependency in TKGs.
Extensive experiments on three real-world datasets demonstrate that GTRL
achieves the state-of-the-art performances on the event prediction task,
outperforming the best baseline by an average of 13.44%, 9.65%, 12.15%, and
15.12% in MRR, Hits@1, Hits@3, and Hits@10, respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:57:42 GMT""}]","2023-02-23"
"2302.11092","Valentina Tardugno Poleo","Valentina Tardugno Poleo, Steven Finkelstein, Gene C. K. Leung, Erin
  Mentuch Cooper, Karl Gebhardt, Daniel Farrow, Eric Gawiser, Gregory Zeimann,
  Donald Schneider, Leah Morabito, Daniel Mock, and Chenxu Liu","Identifying Active Galactic Nuclei at $z\sim3$ from the HETDEX Survey
  Using Machine Learning",,,"10.3847/1538-3881/acba92",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We used data from the Hobby-Eberly Telescope Dark Energy Experiment (HETDEX)
to study the incidence of AGN in continuum-selected galaxies at $z\sim3$. From
optical and infrared imaging in the 24 deg$^{2}$ Spitzer HETDEX Exploratory
Large Area (SHELA) survey, we constructed a sample of photometric-redshift
selected $z\sim3$ galaxies. We extracted HETDEX spectra at the position of 716
of these sources and used machine learning methods to identify those which
exhibited AGN-like features. The dimensionality of the spectra was reduced
using an autoencoder, and the latent space was visualized through t-distributed
stochastic neighbor embedding (t-SNE). Gaussian mixture models were employed to
cluster the encoded data and a labeled dataset was used to label each cluster
as either AGN, stars, high-redshift galaxies, or low-redshift galaxies. Our
photometric redshift (photo-z) sample was labeled with an estimated $92\%$
overall accuracy, an AGN accuracy of $83\%$, and an AGN contamination of $5\%$.
The number of identified AGN was used to measure an AGN fraction for different
magnitude bins. The UV absolute magnitude where the AGN fraction reaches $50\%$
is $M_{UV} = -23.8$. When combined with results in the literature, our
measurements of AGN fraction imply that the bright end of the galaxy luminosity
function exhibits a power-law rather than exponential decline, with a
relatively shallow faint-end slope for the $z\sim3$ AGN luminosity function.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:16:41 GMT""}]","2023-03-29"
"2302.11093","Mehmet Parlak","Mehmet Parlak","Use Cases for Time-Frequency Image Representations and Deep Learning
  Techniques for Improved Signal Classification","4 pages, 5 figures",,,,"eess.SP eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time-frequency images (TFIs) provide a joint time-frequency representation of
a signal and have become an effective tool for analyzing, characterizing, and
processing non-stationary signals. Deep learning (DL) techniques have become
versatile for signal classification, enabling the automatic extraction of
relevant features from raw data. In this paper, we present two use cases on the
time-frequency transformation and deep learning techniques for signal
classification, where signals are first pre-processed and transformed into
TFIs, and their features are then extracted through deep learning neural
networks and classification algorithms. The specific methods and algorithms
used may vary depending on the particular application, therefore different
methods for creating TFIs; the Short-Time Fourier Transform (STFT),
Fourier-based Synchrosqueezing Transform (FSST), Wigner Ville distribution
(WVD), Smoothed Pseudo-Wigner distribution (SPWD), Choi-Williams distribution
(CWD), and Continuous Wavelet Transform (CWT) are investigated. The performance
of various deep learning, and convolutional neural network (CNN) models such as
ResNet-50, ShuffleNet, and Squeezenet are evaluated for their accuracy of
classification in different applications and the results are compared with the
results of the conventional machine learning and ensemble methods such as
Multilayer Perceptrons (MLP), Support Vector Machine (SVM), Random Forest (RF),
Decision Tree (DT), and XGboost. The results of this research demonstrate that
significant improvements in signal classification accuracy can be achieved by
leveraging the combined power of TFIs, and deep learning models. These advances
have found practical applications in a wide range of fields, including radar
signal classification, stability analysis of power systems, speech and music
recognition, and biomedical signal characterization.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:23:11 GMT""}]","2023-02-23"
"2302.11094","Zhuang Wang","Manzi Huang, Xiantao Wang, Zhuang Wang, Zhihao Xu","Locally biH\""{o}lder continuous mappings and their induced embeddings
  between Besov spaces",,,,,"math.FA math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we introduce a class of homeomorphisms between metric spaces,
which are locally biH\""{o}lder continuous mappings. Then an embedding result
between Besov spaces induced by locally biH\""{o}lder continuous mappings
between Ahlfors regular spaces is established, which extends the corresponding
result of Bj\""{o}rn-Bj\""{o}rn-Gill-Shanmugalingam (J. Reine Angew. Math. 725:
63-114, 2017). Furthermore, an example is constructed to show that our
embedding result is more general. We also introduce a geometric condition,
named as uniform boundedness, to characterize when a quasisymmetric mapping
between uniformly perfect spaces is locally biH\""{o}lder continuous.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:26:02 GMT""}]","2023-02-23"
"2302.11095","Guoli Wang","Yu Ren, Guoli Wang, Pingping Wang, Kunmeng Liu, Quanjin Liu, Hongfu
  Sun, Xiang Li, Benzheng Wei","MM-SFENet: Multi-scale Multi-task Localization and Classification of
  Bladder Cancer in MRI with Spatial Feature Encoder Network",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background and Objective: Bladder cancer is a common malignant urinary
carcinoma, with muscle-invasive and non-muscle-invasive as its two major
subtypes. This paper aims to achieve automated bladder cancer invasiveness
localization and classification based on MRI. Method: Different from previous
efforts that segment bladder wall and tumor, we propose a novel end-to-end
multi-scale multi-task spatial feature encoder network (MM-SFENet) for locating
and classifying bladder cancer, according to the classification criteria of the
spatial relationship between the tumor and bladder wall. First, we built a
backbone with residual blocks to distinguish bladder wall and tumor; then, a
spatial feature encoder is designed to encode the multi-level features of the
backbone to learn the criteria. Results: We substitute Smooth-L1 Loss with IoU
Loss for multi-task learning, to improve the accuracy of the classification
task. By testing a total of 1287 MRIs collected from 98 patients at the
hospital, the mAP and IoU are used as the evaluation metrics. The experimental
result could reach 93.34\% and 83.16\% on test set. Conclusions: The
experimental result demonstrates the effectiveness of the proposed MM-SFENet on
the localization and classification of bladder cancer. It may provide an
effective supplementary diagnosis method for bladder cancer staging.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:28:14 GMT""}]","2023-02-23"
"2302.11096","Xin-Meng Wu","Matteo Baggioli, Yan Liu and Xin-Meng Wu","Entanglement entropy as an order parameter for strongly coupled nodal
  line semimetals","35 pages, 16 figures","JHEP05(2023)221","10.1007/JHEP05(2023)221",,"hep-th cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  Topological semimetals are a class of many-body systems exhibiting novel
macroscopic quantum phenomena at the interplay between high energy and
condensed matter physics. They display a topological quantum phase transition
(TQPT) which evades the standard Landau paradigm. In the case of Weyl
semimetals, the anomalous Hall effect is a good non-local order parameter for
the TQPT, as it is proportional to the separation between the Weyl nodes in
momentum space. On the contrary, for nodal line semimetals (NLSM), the quest
for an order parameter is still open. By taking advantage of a recently
proposed holographic model for strongly-coupled NLSM, we explicitly show that
entanglement entropy (EE) provides an optimal probe for nodal topology. We
propose a generalized $c$-function, constructed from the EE, as an order
parameter for the TQPT. Moreover, we find that the derivative of the
renormalized EE with respect to the external coupling driving the TQPT diverges
at the critical point, signaling the rise of non-local quantum correlations.
Finally, we show that these quantum information quantities might be able to
characterize not only the critical point but the whole quantum critical region
at finite temperature.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:31:44 GMT""},{""version"":""v2"",""created"":""Thu, 1 Jun 2023 13:04:07 GMT""}]","2023-06-02"
"2302.11097","Ming-Liang Zhang","Ming-Liang Zhang, Fei Yin, Cheng-Lin Liu","A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from
  Diagram","Accepted to IJCAI 2023",,,,"cs.AI cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Geometry problem solving (GPS) is a high-level mathematical reasoning
requiring the capacities of multi-modal fusion and geometric knowledge
application. Recently, neural solvers have shown great potential in GPS but
still be short in diagram presentation and modal fusion. In this work, we
convert diagrams into basic textual clauses to describe diagram features
effectively, and propose a new neural solver called PGPSNet to fuse multi-modal
information efficiently. Combining structural and semantic pre-training, data
augmentation and self-limited decoding, PGPSNet is endowed with rich knowledge
of geometry theorems and geometric representation, and therefore promotes
geometric understanding and reasoning. In addition, to facilitate the research
of GPS, we build a new large-scale and fine-annotated GPS dataset named PGPS9K,
labeled with both fine-grained diagram annotation and interpretable solution
program. Experiments on PGPS9K and an existing dataset Geometry3K validate the
superiority of our method over the state-of-the-art neural solvers. Our code,
dataset and appendix material are available at
\url{https://github.com/mingliangzhang2018/PGPS}.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:38:25 GMT""},{""version"":""v2"",""created"":""Fri, 28 Apr 2023 10:04:17 GMT""}]","2023-05-01"
"2302.11098","Jared Huling","Jared D. Huling and Jennifer P. Lundine and Julie C. Leonard","Doubly structured sparsity for grouped multivariate responses with
  application to functional outcome score modeling",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  This work is motivated by the need to accurately model a vector of responses
related to pediatric functional status using administrative health data from
inpatient rehabilitation visits. The components of the responses have known and
structured interrelationships. To make use of these relationships in modeling,
we develop a two-pronged regularization approach to borrow information across
the responses. The first component of our approach encourages joint selection
of the effects of each variable across possibly overlapping groups related
responses and the second component encourages shrinkage of effects towards each
other for related responses. As the responses in our motivating study are not
normally-distributed, our approach does not rely on an assumption of
multivariate normality of the responses. We show that with an adaptive version
of our penalty, our approach results in the same asymptotic distribution of
estimates as if we had known in advance which variables were non-zero and which
variables have the same effects across some outcomes. We demonstrate the
performance of our method in extensive numerical studies and in an application
in the prediction of functional status of pediatric patients using
administrative health data in a population of children with neurological injury
or illness at a large children's hospital.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:39:06 GMT""}]","2023-02-23"
"2302.11099","Akbar Ali","Abeer M. Albalahi, Akbar Ali, Abdulaziz M. Alanazi, Akhlaq A. Bhatti,
  Amjad E. Hamza","Harmonic-Arithmetic Index of (Molecular) Trees","This is the accepted version of the paper and it will appear in
  Contrib. Math. In this version, several corrections have been made and in
  Section 3, some remarks on the chemical applicability of the HA index have
  been included",,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  Let $G$ be a graph. Denote by $d_x$, $E(G)$, and $D(G)$ the degree of a
vertex $x$ in $G$, the set of edges of $G$, and the degree set of $G$,
respectively. This paper proposes to investigate (both from mathematical and
applications points of view) those graph invariants of the form $\sum_{uv\in
E(G)}\varphi(d_v,d_w)$ in which $\varphi$ can be defined either using
well-known means of $d_v$ and $d_w$ (for example: arithmetic, geometric,
harmonic, quadratic, and cubic means) or by applying a basic arithmetic
operation (addition, subtraction, multiplication, and division) on any of two
such means, provided that $\varphi$ is a non-negative and symmetric function
defined on the Cartesian square of $D(G)$. Many existing well-known graph
invariants can be defined in this way; however, there are many exceptions too.
One of such uninvestigated graph invariants is the harmonic-arithmetic (HA)
index, which is obtained from the aforementioned setting by taking $\varphi$ as
the ratio of the harmonic and arithmetic means of $d_v$ and $d_w$. A molecular
tree is a tree whose maximum degree does not exceed four. Given the class of
all (molecular) trees with a fixed order, graphs that have the largest or least
value of the HA index are completely characterized in this paper.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:42:42 GMT""},{""version"":""v2"",""created"":""Sat, 1 Apr 2023 00:03:35 GMT""}]","2023-04-04"
"2302.11100","Hee Oh","Dongryul M. Kim, Yair Minsky and Hee Oh","Hausdorff dimension of directional limit sets for self-joinings of
  hyperbolic manifolds","To appear in Journal of Modern Dynamics. arXiv admin note:
  substantial text overlap with arXiv:2112.00877",,,,"math.DS math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The classical result of Patterson and Sullivan says that for a non-elementary
convex cocompact subgroup $\Gamma<\text{SO}^\circ (n,1)$, $n\ge 2$, the
Hausdorff dimension of the limit set of $\Gamma$ is equal to the critical
exponent of $\Gamma$. In this paper, we generalize this result for
self-joinings of convex cocompact groups in two ways. Let $\Delta$ be a
finitely generated group and $\rho_i:\Delta\to \text{SO}^\circ(n_i,1)$ be a
convex cocompact faithful representation of $\Delta$ for $1\le i\le k$.
Associated to $\rho=(\rho_1, \cdots, \rho_k)$, we consider the following
self-joining subgroup of $\prod_{i=1}^k \text{SO}(n_i,1)$:
$$\Gamma=\left(\prod_{i=1}^k\rho_i\right)(\Delta)=\{(\rho_1(g), \cdots,
\rho_k(g)):g\in \Delta\} .$$ (1). Denoting by $\Lambda\subset \prod_{i=1}^k
\mathbb{S}^{n_i-1}$ the limit set of $\Gamma$, we first prove that
$$\text{dim}_H \Lambda=\max_{1\le i\le k} \delta_{\rho_i}$$ where
$\delta_{\rho_i}$ is the critical exponent of the subgroup $\rho_{i}(\Delta)$.
  (2). Denoting by $\Lambda_u\subset \Lambda$ the $u$-directional limit set for
each $u=(u_1, \cdots, u_k)$ in the interior of the limit cone of $\Gamma$, we
obtain that for $k\le 3$, $$ \frac{\psi_\Gamma(u)}{\max_i u_i }\le \text{dim}_H
\Lambda_u \le \frac{\psi_\Gamma(u)}{\min_i u_i }$$ where
$\psi_\Gamma:\mathbb{R}^k\to \mathbb{R}\cup\{-\infty\}$ is the growth indicator
function of $\Gamma$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:45:24 GMT""},{""version"":""v2"",""created"":""Mon, 22 May 2023 02:52:11 GMT""}]","2023-05-23"
"2302.11101","Pantelis Vlachas","Pantelis R. Vlachas, Petros Koumoutsakos","Learning from Predictions: Fusing Training and Autoregressive Inference
  for Long-Term Spatiotemporal Forecasts","18 pages",,,,"cs.LG nlin.CD physics.comp-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurrent Neural Networks (RNNs) have become an integral part of modeling and
forecasting frameworks in areas like natural language processing and
high-dimensional dynamical systems such as turbulent fluid flows. To improve
the accuracy of predictions, RNNs are trained using the Backpropagation Through
Time (BPTT) method to minimize prediction loss. During testing, RNNs are often
used in autoregressive scenarios where the output of the network is fed back
into the input. However, this can lead to the exposure bias effect, as the
network was trained to receive ground-truth data instead of its own
predictions. This mismatch between training and testing is compounded when the
state distributions are different, and the train and test losses are measured.
To address this, previous studies have proposed solutions for language
processing networks with probabilistic predictions. Building on these advances,
we propose the Scheduled Autoregressive BPTT (BPTT-SA) algorithm for predicting
complex systems. Our results show that BPTT-SA effectively reduces iterative
error propagation in Convolutional RNNs and Convolutional Autoencoder RNNs, and
demonstrate its capabilities in long-term prediction of high-dimensional fluid
flows.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:46:54 GMT""}]","2023-02-23"
"2302.11102","Haiyu Wu","Haiyu Wu, Grace Bezold, Aman Bhatta, Kevin W. Bowyer","Logical Consistency and Greater Descriptive Power for Facial Hair
  Attribute Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Face attribute research has so far used only simple binary attributes for
facial hair; e.g., beard / no beard. We have created a new, more descriptive
facial hair annotation scheme and applied it to create a new facial hair
attribute dataset, FH37K. Face attribute research also so far has not dealt
with logical consistency and completeness. For example, in prior research, an
image might be classified as both having no beard and also having a goatee (a
type of beard). We show that the test accuracy of previous classification
methods on facial hair attribute classification drops significantly if logical
consistency of classifications is enforced. We propose a logically consistent
prediction loss, LCPLoss, to aid learning of logical consistency across
attributes, and also a label compensation training strategy to eliminate the
problem of no positive prediction across a set of related attributes. Using an
attribute classifier trained on FH37K, we investigate how facial hair affects
face recognition accuracy, including variation across demographics. Results
show that similarity and difference in facial hairstyle have important effects
on the impostor and genuine score distributions in face recognition. The code
is at https:// github.com/ HaiyuWu/ LogicalConsistency.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:49:21 GMT""},{""version"":""v2"",""created"":""Sun, 16 Apr 2023 14:04:19 GMT""}]","2023-04-18"
"2302.11103","Zhenjun Zhou","Zhenjun Zhou, Chaowei Jiang, Xiaoyu Yu, Yuming Wang, Yongqiang Hao,
  Jun Cui","The Mechanism of Magnetic Flux Rope Rotation During Solar Eruption",,,,,"astro-ph.SR physics.plasm-ph physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Solar eruptions often show the rotation of filaments, which is a
manifestation of the rotation of erupting magnetic flux rope (MFR). Such a
rotation of MFR can be induced by either the torque exerted by a background
shear-field component (which is an external cause) or the relaxation of the
magnetic twist of the MFR (an internal cause). For a given chirality of the
erupting field, both the external and internal drivers cause the same rotation
direction. Therefore, it remains elusive from direct observations which
mechanism yields the dominant contribution to the rotation. In this paper, we
exploit a full MHD simulation of solar eruption by tether-cutting magnetic
reconnection to study the mechanism of MFR rotation. In the simulation, the
MFR's height-rotation profile suggests that the force by the external
shear-field component is a dominant contributor to the rotation. Furthermore,
the torque analysis confirms that it is also the only factor in driving the
counterclockwise rotation. On the contrary, the Lorentz torque inside the MFR
makes a negative effect on this counterclockwise rotation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:55:03 GMT""}]","2023-02-23"
"2302.11104","Feng Ji","Feng Ji, Xingchao Jian, Wee Peng Tay","On distributional graph signals",,,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Graph signal processing (GSP) studies graph-structured data, where the
central concept is the vector space of graph signals. To study a vector space,
we have many useful tools up our sleeves. However, uncertainty is omnipresent
in practice, and using a vector to model a real signal can be erroneous in some
situations. In this paper, we want to use the Wasserstein space as a
replacement for the vector space of graph signals, to account for signal
stochasticity. The Wasserstein is strictly more general in which the classical
graph signal space embeds isometrically. An element in the Wasserstein space is
called a distributional graph signal. On the other hand, signal processing for
a probability space of graphs has been proposed in the literature. In this
work, we propose a unified framework that also encompasses existing theories
regarding graph uncertainty. We develop signal processing tools to study the
new notion of distributional graph signals. We also demonstrate how the theory
can be applied by using real datasets.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 02:59:48 GMT""}]","2023-02-23"
"2302.11105","Jiuzu Hong","Jiuzu Hong, Shrawan Kumar","Lie algebra cohomology of the positive part of twisted affine Lie
  algebras","29 pages. Comments are welcome",,,,"math.RT math-ph math.MP","http://creativecommons.org/publicdomain/zero/1.0/","  The explicit Verlinde formula for the dimension of conformal blocks, attached
to a marked projective curve $\Sigma$, a simple Lie algebra $\mathfrak{g}$ over
$\mathbb{C}$ and integrable highest weight modules of a fixed central charge of
the corresponding affine Lie algebra $\hat{L}(\mathfrak{g})$ attached to the
marked points, requires (among several other important ingredients) a Lie
algebra cohomology vanishing result due to C. Teleman for the positive part
$\hat{L}^+(\mathfrak{g})$ with coefficients in the tensor product of an
integrable highest weight module with copies of finite dimensional evaluation
modules. The aim of this paper is to extend this result of Teleman to a twisted
setting where $\mathfrak{g}$ is endowed with a special automorphism $\sigma$
and the curve $\Sigma$ is endowed with the action of $\sigma$. In this general
setting, the affine Lie algebra gets replaced by twisted affine Lie algebras.
The crucial ingredient (as in Teleman) is to prove a certain Nakano Identity.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:02:06 GMT""}]","2023-02-23"
"2302.11106","Hexiang Zhang","Hexiang Zhang, Zhenghua Xu, Dan Yao, Shuo Zhang, Junyang Chen, Thomas
  Lukasiewicz","Multi-Head Feature Pyramid Networks for Breast Mass Detection","7 pages, 3 figures,Received by the ICASSP2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analysis of X-ray images is one of the main tools to diagnose breast cancer.
The ability to quickly and accurately detect the location of masses from the
huge amount of image data is the key to reducing the morbidity and mortality of
breast cancer. Currently, the main factor limiting the accuracy of breast mass
detection is the unequal focus on the mass boxes, leading the network to focus
too much on larger masses at the expense of smaller ones. In the paper, we
propose the multi-head feature pyramid module (MHFPN) to solve the problem of
unbalanced focus of target boxes during feature map fusion and design a
multi-head breast mass detection network (MBMDnet). Experimental studies show
that, comparing to the SOTA detection baselines, our method improves by 6.58%
(in AP@50) and 5.4% (in TPR@50) on the commonly used INbreast dataset, while
about 6-8% improvements (in AP@20) are also observed on the public MIAS and
BCS-DBT datasets.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:02:52 GMT""}]","2023-02-23"
"2302.11107","Ashwin Bhat","Ashwin Bhat, Arijit Raychowdhury","Non-Uniform Interpolation in Integrated Gradients for Low-Latency
  Explainable-AI",,,,,"cs.LG cs.AI cs.AR eess.IV","http://creativecommons.org/licenses/by/4.0/","  There has been a surge in Explainable-AI (XAI) methods that provide insights
into the workings of Deep Neural Network (DNN) models. Integrated Gradients
(IG) is a popular XAI algorithm that attributes relevance scores to input
features commensurate with their contribution to the model's output. However,
it requires multiple forward \& backward passes through the model. Thus,
compared to a single forward-pass inference, there is a significant
computational overhead to generate the explanation which hinders real-time XAI.
This work addresses the aforementioned issue by accelerating IG with a
hardware-aware algorithm optimization. We propose a novel non-uniform
interpolation scheme to compute the IG attribution scores which replaces the
baseline uniform interpolation. Our algorithm significantly reduces the total
interpolation steps required without adversely impacting convergence.
Experiments on the ImageNet dataset using a pre-trained InceptionV3 model
demonstrate \textit{2.6-3.6}$\times$ performance speedup on GPU systems for
iso-convergence. This includes the minimal \textit{0.2-3.2}\% latency overhead
introduced by the pre-processing stage of computing the non-uniform
interpolation step-sizes.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:03:28 GMT""}]","2023-02-23"
"2302.11108","Adam Cox","Adam Cox, Sinan Beskok and Yildirim Hurmuzlu","Magnetically Actuated Millimeter-Scale Biped","15 pages, 17 figures",,,,"cs.RO cs.SY eess.SY","http://creativecommons.org/licenses/by/4.0/","  This paper introduces a new approach to studying bipedal locomotion. The
approach is based on magnetically actuated miniature robots. Building
prototypes of bipedal locomotion machines has been very costly and overly
complicated. We demonstrate that a magnetically actuated 0.3~gm robot, we call
Big Foot, can be used to test fundamental ideas without necessitating very
complex and expensive bipedal machines. We explore analytically and
experimentally two age old questions in bipedal locomotion: 1. Can such robots
be driven with pure hip actuation. 2. Is it better to use continuous or
impulsive actuation schemes.
  First, a numerical model has been developed in order to study the dynamics
and stability of a magnetically actuated miniature robot. We particularly focus
on stability and performance metrics. Then, these results are tested using Big
Foot. Pure hip actuation has been successful in generating gait on uphill
surfaces. In addition, complex tasks such as following prescribed gait
trajectories and navigating through a maze has been successfully performed by
the experimental prototype. The nature and timing of hip torques are also
studied. Two actuation schemes are used: Heel Strike Actuation and Constant
Pulse Wave Actuation. With each scheme, we also vary the time duration of the
applied magnetic field. Heel Strike actuation is found to have superior
stability, more uniform gait generation, and faster locomotion than the
Constant Pulse Wave option. But, Constant Pulse Wave achieves locomotion on
steeper slopes.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:07:05 GMT""}]","2023-02-23"
"2302.11109","Boyu Zhang","Zhenkun Li, Yi Xie, Boyu Zhang","A deformation of Asaeda-Przytycki-Sikora homology","14 pages, 6 figures",,,,"math.GT","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We define a 1-parameter family of homology invariants for links in thickened
oriented surfaces. It recovers the homology invariant of
Asaeda-Przytycki-Sikora (arxiv:0409414) and the invariant defined by Winkeler
(arxiv:2106.03834). The new invariant can be regarded as a deformation of
Asaeda-Przytycki-Sikora homology; it is not a Lee-type deformation as the
deformation is only non-trivial when the surface is not simply connected. Our
construction is motivated by computations in singular instanton Floer homology.
We also prove a detection property for the new invariant, which is a stronger
result than the main theorem of arxiv:2208.13963.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:08:28 GMT""}]","2023-02-23"
"2302.11110","Xiaodong He","Xiaodong He, Weijia Yao, Zhiyong Sun, Zhongkui Li","A Novel Vector-Field-Based Motion Planning Algorithm for 3D Nonholonomic
  Robots",,,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on the motion planning for mobile robots in 3D, which are
modelled by 6-DOF rigid body systems with nonholonomic kinematics constraints.
We not only specify the target position, but also bring in the requirement of
the heading direction at the terminal time, which gives rise to a new and more
challenging 3D motion planning problem. The proposed planning algorithm
involves a novel velocity vector field (VF) over the workspace, and by
following the VF, the robot can be navigated to the destination with the
specified heading direction. In order to circumvent potential collisions with
obstacles and other robots, a composite VF is designed by composing the
navigation VF and an additional VF tangential to the boundary of the dangerous
area. Moreover, we propose a priority-based algorithm to deal with the motion
coupling issue among multiple robots. Finally, numerical simulations are
conducted to verify the theoretical results.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:13:32 GMT""},{""version"":""v2"",""created"":""Sat, 8 Apr 2023 06:40:57 GMT""}]","2023-04-11"
"2302.11111","Kai Wang","Kai Wang, Zhi-Peng Ma, Ruo-Yu Liu, Yuan-Chuan Zou, Zhuo Li, Zi-Gao Dai","Implication of GRB 221009A: Can TeV Emission Come from the GRB Prompt
  Phase?","13 pages, 7 figures, 3 tables, accepted version",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Recently, the B.O.A.T. (""brightest of all time"") gamma-ray burst, dubbed GRB
221009A, was detected by various instruments. Unprecedentedly, the GRB
presented very-high-energy (VHE, energy above 0.1 TeV) gamma-ray emission with
energy extending above 10 TeV, as reported by the Large High Altitude Air
Shower Observatory (LHAASO). We here demonstrate that the VHE and especially
>10 TeV emission may originate from the internal hadronic dissipation of the
GRB, without the need of invoking any exotic processes as suggested by some
previous studies. We also discuss the constraints on the properties of the GRB
ejecta from multiwavelength and multi-messenger observations, which favors a
magnetically dominated GRB ejecta. The suggested Poynting-flux-dominated GRB
ejecta in this work supports the Blandford & Znajek (BZ) mechanism as the
possible central engine model of GRB.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:14:55 GMT""},{""version"":""v2"",""created"":""Wed, 26 Apr 2023 02:31:48 GMT""}]","2023-04-27"
"2302.11112","Si-Wu Li","Si-Wu Li, Tianfeng Feng, Xiao-Long Hu, Ze-Liang Xiang, Xiaoqi Zhou","State Transfer and Entanglement between Two- and Four-Level Atoms in A
  Cavity","12 pages, 5 figures",,,,"quant-ph physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Qudits with a large Hilbert space to host quantum information are widely
utilized in various applications, such as quantum simulation and quantum
computation, but the manipulation and scalability of qudits still face
challenges. Here, we propose a scheme to directly and locally transfer quantum
information from multiple atomic qubits to a single qudit and vice versa in an
optical cavity. With the qubit-qudit interaction, our scheme can transfer
quantum states efficiently and measurement-independently. In addition, this
scheme can be extended to the non-local case, where a high-dimensional maximal
entangled state with asymmetric particle numbers can be robustly generated for
realizing long-distance quantum communication. Such an information interface
for qubits and qudit may have enlightening significance for future research on
quantum systems in hybrid dimensions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:16:54 GMT""}]","2023-02-23"
"2302.11113","Yoshimichi Ueda","Yoshimichi Ueda","Spherical representations for $C^*$-flows III: Weight-extended branching
  graphs","24pages",,,,"math.OA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply Takesaki's and Connes's ideas on structure analysis for type III
factors to the study of links (a short term of Markov kernels) appearing in
asymptotic representation theory.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:17:57 GMT""}]","2023-02-23"
"2302.11114","Yizhou Chen","Yizhou Chen, Ruoyu Wang, Xinyi Wang, and Ben M. Chen","Sampling-based path planning under temporal logic constraints with
  real-time adaptation",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Replanning in temporal logic tasks is extremely difficult during the online
execution of robots. This study introduces an effective path planner that
computes solutions for temporal logic goals and instantly adapts to non-static
and partially unknown environments. Given prior knowledge and a task
specification, the planner first identifies an initial feasible solution by
growing a sampling-based search tree. While carrying out the computed plan, the
robot maintains a solution library to continuously enhance the unfinished part
of the plan and store backup plans. The planner updates existing plans when
meeting unexpected obstacles or recognizing flaws in prior knowledge. Upon a
high-level path is obtained, a trajectory generator tracks the path by dividing
it into segments of motion primitives. Our planner is integrated into an
autonomous mobile robot system, further deployed on a multicopter with limited
onboard processing power. In simulation and real-world experiments, our planner
is demonstrated to swiftly and effectively adjust to environmental
uncertainties.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:21:37 GMT""}]","2023-02-23"
"2302.11115","Ran Chen","Ran Chen, Di Wu, Baogang Xu","Structure and coloring of some ($P_7,C_4$)-free graphs",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $G$ be a graph. We use $P_t$ and $C_t$ to denote a path and a cycle on
$t$ vertices, respectively. A {\em diamond} is a graph obtained from two
triangles that share exactly one edge. A {\em kite} is a graph consists of a
diamond and another vertex adjacent to a vertex of degree 2 of the diamond. A
{\em gem} is a graph that consists of a $P_4$ plus a vertex adjacent to all
vertices of the $P_4$. In this paper, we prove some structural properties to
$(P_7, C_4,$ diamond)-free graphs, $(P_7, C_4,$ kite)-free graphs and $(P_7,
C_4,$ gem)-free graphs. As their corollaries, we show that (\romannumeral 1)
$\chi (G)\leq \max\{3,\omega(G)\}$ if $G$ is $(P_7, C_4,$ diamond)-free,
(\romannumeral 2) $\chi(G)\leq \omega(G)+1$ if $G$ is $(P_7, C_4,$ kite)-free
and (\romannumeral 3) $\chi(G)\leq 2\omega(G)-1$ if $G$ is $(P_7, C_4,$
gem)-free. These conclusions generalize some results of Choudum {\em et al} and
Lan {\em et al}.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:22:59 GMT""}]","2023-02-23"
"2302.11116","Anita Petzler","Anita Petzler, J. R. Dawson, Hiep Nguyen, Carl Heiles, M. Wardle, M.
  -Y. Lee, Claire E. Murray, K. L. Thompson and Snezana Stanimirovic","GNOMES II: Analysis of the Galactic diffuse molecular ISM in all four
  ground state hydroxyl transitions using Amoeba","Accepted for publication to PASA. 41 pages, 27 figures",,"10.1017/pasa.2023.8",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We present observations of the four 2 Pi 3/2 J = 3/2 ground-rotational state
transitions of the hydroxyl molecule (OH) along 107 lines of sight both in and
out of the Galactic plane: 92 sets of observations from the Arecibo telescope
and 15 sets of observations from the Australia Telescope Compact Array (ATCA).
Our Arecibo observations included off-source pointings, allowing us to measure
excitation temperature (Tex) and optical depth, while our ATCA observations
give optical depth only. We perform Gaussian decomposition using the Automated
Molecular Excitation Bayesian line-fitting Algorithm 'AMOEBA' (Petzler, Dawson,
and Wardle 2021) fitting all four transitions simultaneously with shared
centroid velocity and width. We identify 109 features across 38 sightlines
(including 58 detections along 27 sightlines with excitation temperature
measurements). While the main lines at 1665 and 1667 MHz tend to have similar
excitation temperatures (median Tex(main) difference = 0.6 K, 84% show
Tex(main) difference < 2 K), large differences in the 1612 and 1720 MHz
satellite line excitation temperatures show that the gas is generally not in
LTE. For a selection of sightlines we compare our OH features to associated
(on-sky and in velocity) HI cold gas components (CNM) identified by Nguyen et
al. (2019) and find no strong correlations. We speculate that this may indicate
an effective decoupling of the molecular gas from the CNM once it accumulates.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:25:19 GMT""}]","2023-04-19"
"2302.11117","Daniela Calzetti","Daniela Calzetti, Sean T. Linden, Timothy McQuaid, Matteo Messa,
  Zhiyuan Ji, Mark R. Krumholz, Angela Adamo, Bruce Elmegreen, Kathryn Grasha,
  Kelsey E. Johnson, Elena Sabbi, Linda Smith, Varun Bajaj","Dust Buried Compact Sources in the Dwarf Galaxy NGC 4449","27 pages, 22 figures; accepted for publication in the Astrophysical
  Journal",,"10.3847/1538-4357/acbeac",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Multi-wavelength images from the Hubble Space Telescope covering the
wavelength range 0.27-1.6 $\mu$m show that the central area of the nearby dwarf
galaxy NGC4449 contains several tens of compact sources that are emitting in
the hydrogen recombination line Pa$\beta$ (1.2818 $\mu$m) but are only
marginally detected in H$\alpha$ (0.6563 $\mu$m) and undetected at wavelengths
$\lambda\le$0.55 $\mu$m. An analysis of the spectral energy distributions
(SEDs) of these sources indicates that they are likely relatively young star
clusters heavily attenuated by dust. The selection function used to identify
the sources prevents meaningful statistical analyses of their age, mass, and
dust extinction distributions. However, these cluster candidates have ages
$\sim$5-6 Myr and A$_V>$6 mag, according to their SED fits, and are extremely
compact, with typical deconvolved radii of 1 pc. The dusty clusters are located
at the periphery of dark clouds within the galaxy and appear to be partially
embedded. Density and pressure considerations indicate that the HII regions
surrounding these clusters may be stalled, and that pre-supernova feedback has
not been able to clear the clusters of their natal cocoons. These findings are
in potential tension with existing models that regulate star formation with
pre-supernova feedback, since pre-supernova feedback acts on short timescales,
$\lesssim$4 Myr, for a standard Stellar Initial Mass function. The existence of
a population of dusty star clusters with ages $>$4 Myr, if confirmed by future
observations, paints a more complex picture for the role of stellar feedback in
controlling star formation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:25:40 GMT""}]","2023-03-29"
"2302.11118","Adela Kawka","Adela Kawka, Lilia Ferrario, Stephane Vennes","The non-explosive stellar merging origin of the ultra-massive
  carbon-rich white dwarfs","Accepted for publication in MNRAS",,"10.1093/mnras/stad553",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  We have investigated the origin of a sub-class of carbon-polluted white
dwarfs (DQ) originally identified as the ``hot DQ"" white dwarfs. These objects
are relatively hot (10 000 < T_eff < 25 000 K), have markedly higher carbon
abundance (C-enriched), are more massive (M > 0.8 M_Sun) than ordinary DQs (M ~
0.6 M_Sun), and display high space velocities. Hence, despite their young
appearance their kinematic properties are those of an old white dwarf
population. The way out of this dilemma is to assume that they formed via the
merging of two white dwarfs. In this paper we examine the observed
characteristics of this population of ``C-enriched"" DQ white dwarfs and confirm
that nearly half of the 63 known objects have kinematic properties consistent
with those of the Galactic thick disc or halo. We have also conducted
population synthesis studies and found that the merging hypothesis is indeed
compatible with observations. Studies of this sub-class of white dwarfs have
important implications for our understanding of Type Ia Supernovae (SNeIa),
commonly used to determine the expansion history of the universe, since the
same formation channel applies to both kinds of objects. Hence probing the
properties of these white dwarfs that failed to explode may yield important
constraints to the modelling of the mechanisms leading to a thermonuclear
runaway.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:30:14 GMT""}]","2023-03-01"
"2302.11119","Hangsong Su","Hangsong Su, Feng Xue, Runze Guo, Anlong Ming","Balanced Line Coverage in Large-scale Urban Scene",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Line coverage is to cover linear infrastructure modeled as 1D segments by
robots, which received attention in recent years. With the increasing
urbanization, the area of the city and the density of infrastructure continues
to increase, which brings two issues: (1) Due to the energy constraint, it is
hard for the homogeneous robot team to cover the large-scale linear
infrastructure starting from one depot; (2) In the large urban scene, the
imbalance of robots' path greatly extends the time cost of the multi-robot
system, which is more serious than that in smaller-size scenes. To address
these issues, we propose a heterogeneous multi-robot approach consisting of
several teams, each of which contains one transportation robot (TRob) and
several coverage robots (CRobs). Firstly, a balanced graph partitioning (BGP)
algorithm is proposed to divide the road network into several similar-size
sub-graphs, and then the TRob delivers a group of CRobs to the subgraph region
quickly. Secondly, a balanced ulusoy partitioning (BUP) algorithm is proposed
to extract similar-length tours for each CRob from the sub-graph. Abundant
experiments are conducted on seven road networks ranging in scales that are
collected in this paper. Our method achieves robot utilization of 90% and the
best maximal tour length at the cost of a small increase in total tour length,
which further minimizes the time cost of the whole system. The source code and
the road networks are available at
https://github.com/suhangsong/BLC-LargeScale.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:32:29 GMT""}]","2023-02-23"
"2302.11120","Peizheng Yuan","Peizheng Yuan, Hideyuki Tsukagoshi","Soft Pneumatic Actuator Capable of Generating Various Bending and
  Extension Motions Inspired by an Elephant Trunk","8 pages, 11 figures, submitted to the IEEE Robotics and Automation
  Letters (RA-L)",,,,"cs.RO cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the dexterous handling ability of an elephant's trunk, we propose
a pneumatic actuator that generates diverse bending and extension motions in a
flexible arm. The actuator consists of two flexible tubes. Each flexible tube
is restrained by a single string with variable length and tilt angle. Even if a
single tube can perform only three simple types of motions (bending, extension,
and helical), a variety of complex bending patterns can be created by arranging
a pair of tubes in parallel and making the restraint variable. This performance
takes advantage of the effect of the superposition of forces by arranging two
tubes to constructively interfere with each other. This paper described six
resulting pose patterns. First, the configuration and operating principle are
described, and the fabrication method is explained. Next, two mathematical
models and four finite element method-based analyses are introduced to predict
the tip position changes in five motion patterns. All the models were validated
through experiments. Finally, we experimentally demonstrated that the prototype
SEMI-TRUNK can realize the action of grabbing a bottle and pouring water,
verifying the effectiveness of the proposed method.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:34:17 GMT""}]","2023-02-23"
"2302.11121","Luke Guerdan","Luke Guerdan, Amanda Coston, Kenneth Holstein, Zhiwei Steven Wu","Counterfactual Prediction Under Outcome Measurement Error","FAccT 2023",,"10.1145/3593013.3594101",,"cs.LG cs.CY cs.HC stat.ME","http://creativecommons.org/licenses/by/4.0/","  Across domains such as medicine, employment, and criminal justice, predictive
models often target labels that imperfectly reflect the outcomes of interest to
experts and policymakers. For example, clinical risk assessments deployed to
inform physician decision-making often predict measures of healthcare
utilization (e.g., costs, hospitalization) as a proxy for patient medical need.
These proxies can be subject to outcome measurement error when they
systematically differ from the target outcome they are intended to measure.
However, prior modeling efforts to characterize and mitigate outcome
measurement error overlook the fact that the decision being informed by a model
often serves as a risk-mitigating intervention that impacts the target outcome
of interest and its recorded proxy. Thus, in these settings, addressing
measurement error requires counterfactual modeling of treatment effects on
outcomes. In this work, we study intersectional threats to model reliability
introduced by outcome measurement error, treatment effects, and selection bias
from historical decision-making policies. We develop an unbiased risk
minimization method which, given knowledge of proxy measurement error
properties, corrects for the combined effects of these challenges. We also
develop a method for estimating treatment-dependent measurement error
parameters when these are unknown in advance. We demonstrate the utility of our
approach theoretically and via experiments on real-world data from randomized
controlled trials conducted in healthcare and employment domains. As
importantly, we demonstrate that models correcting for outcome measurement
error or treatment effects alone suffer from considerable reliability
limitations. Our work underscores the importance of considering intersectional
threats to model validity during the design and evaluation of predictive models
for decision support.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:34:19 GMT""},{""version"":""v2"",""created"":""Thu, 18 May 2023 02:52:09 GMT""}]","2023-05-19"
"2302.11122","Hiroyasu Ejiri","Hiroyasu Ejiri","Electromagnetic transitions from isobaric analogue states to study
  nuclear matrix elements for double beta decays and astro-neutrino inverse
  beta decays","5 pages, 4 figures",,,,"nucl-ex","http://creativecommons.org/licenses/by/4.0/","  Experimental studies for nuclear matrix elements (NMEs) for neutrinoless
double beta decays (DBDs) and astro-neutrino inverse beta decays (IBDs) are
crucial for neutrino studies beyond the standard model and the astro neutrino
reactions since theoretical model calculations for the NMEs are hard due to the
high sensitivities of the NMEs to the models. The NMEs associated with DBDs and
IBDs are found for the first time to be studied experimentally by measuring
electro-magnetic (gamma) transitions from isobalic analogue states (IASs) of
the DBD and IBD nuclei. They are used to help the theoretical model
calculations for them. The IAS gamma cross sections and the event rates are
estimated to show the feasibility of the experiments.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:36:29 GMT""}]","2023-02-23"
"2302.11123","Di Wang","Di Wang, Wen Ye, Ji Zhu, Gongjun Xu, Weijing Tang, Matthew
  Zawistowski, Lars G. Fritsche, Kevin He","Incorporating External Risk Information with the Cox Model under
  Population Heterogeneity: Applications to Trans-Ancestry Polygenic Hazard
  Scores",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Polygenic hazard score (PHS) models designed for European ancestry (EUR)
individuals provide ample information regarding survival risk discrimination.
Incorporating such information can improve the performance of risk
discrimination in an internal small-sized non-EUR cohort. However, given that
external EUR-based model and internal individual-level data come from different
populations, ignoring population heterogeneity can introduce substantial bias.
In this paper, we develop a Kullback-Leibler-based Cox model (CoxKL) to
integrate internal individual-level time-to-event data with external risk
scores derived from published prediction models, accounting for population
heterogeneity. Partial-likelihood-based KL information is utilized to measure
the discrepancy between the external risk information and the internal data. We
establish the asymptotic properties of the CoxKL estimator. Simulation studies
show that the integration model by the proposed CoxKL method achieves improved
estimation efficiency and prediction accuracy. We applied the proposed method
to develop a trans-ancestry PHS model for prostate cancer and found that
integrating a previously published EUR-based PHS with an internal genotype data
of African ancestry (AFR) males yielded considerable improvement on the
prostate cancer risk discrimination.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:36:56 GMT""}]","2023-02-23"
"2302.11124","Hung Hung","Hung Hung and Su-Yun Huang","On the efficiency-loss free ordering-robustness of product-PCA","3 figures",,,,"stat.ME","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This article studies the robustness of the eigenvalue ordering, an important
issue when estimating the leading eigen-subspace by principal component
analysis (PCA). In Yata and Aoshima (2010), cross-data-matrix PCA (CDM-PCA) was
proposed and shown to have smaller bias than PCA in estimating eigenvalues.
While CDM-PCA has the potential to achieve better estimation of the leading
eigen-subspace than the usual PCA, its robustness is not well recognized. In
this article, we first develop a more stable variant of CDM-PCA, which we call
product-PCA (PPCA), that provides a more convenient formulation for theoretical
investigation. Secondly, we prove that, in the presence of outliers, PPCA is
more robust than PCA in maintaining the correct ordering of leading
eigenvalues. The robustness gain in PPCA comes from the random data partition,
and it does not rely on a data down-weighting scheme as most robust statistical
methods do. This enables us to establish the surprising finding that, when
there are no outliers, PPCA and PCA share the same asymptotic distribution.
That is, the robustness gain of PPCA in estimating the leading eigen-subspace
has no efficiency loss in comparison with PCA. Simulation studies and a face
data example are presented to show the merits of PPCA. In conclusion, PPCA has
a good potential to replace the role of the usual PCA in real applications
whether outliers are present or not.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:37:14 GMT""}]","2023-02-23"
"2302.11125","Thanh Pham","Thanh V. Pham, Steve Hranilovic, Susumu Ishihara","On the Design of Artificial Noise for Physical Layer Security in Visible
  Light Communication Channels with Clipping","arXiv admin note: text overlap with arXiv:2210.00438",,,,"cs.IT cs.SY eess.SY math.IT","http://creativecommons.org/licenses/by/4.0/","  Though visible light communication (VLC) systems are contained to a given
room, improving their security is an important criterion in any practical
deployment. In this paper, the design of artificial noise (AN) to enhance
physical layer security in VLC systems is studied in the context of input
signals with no explicit amplitude constraint (e.g., multicarrier systems). In
such systems, clipping is needed to constrain the input signals within the
limited linear ranges of the LEDs. However, this clipping process gives rise to
non-linear clipping distortion, which must be incorporated into the AN design.
To facilitate the solution of this problem, a sub-optimal design approach is
presented using the Charnes-Cooper transformation and the convex-concave
procedure (CCP). Then, a novel AN transmission scheme is proposed to reduce the
impact of clipping distortion, thus improving the secrecy performance. The
proposed scheme exploits the common structure of LED luminaries that they are
often composed of several light-emitting chips. Capitalizing on this property,
LED chips in each luminaire are divided into two groups driven by separate
driver circuits. One group is used to transmit the information-bearing signal,
while the other group transmits the AN. Numerical results show that the
clipping distortion significantly reduces the secrecy level, and using AN is
advantageous over the no-AN scheme in improving the secrecy performance.
Moreover, the proposed AN transmission scheme is shown to achieve considerable
secrecy improvements compared with the traditional transmission approaches
(e.g., about 1 bit/s/Hz improvement in the achievable secrecy rate when the
standard deviation of the LEDs' modulating current is 0.25 A and the
signal-to-interference-plus-noise ratio of the eavesdropper's received signal
is limited to $0$ dB).
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:40:04 GMT""}]","2023-02-23"
"2302.11126","Nicholas Hunt-Smith","N. T. Hunt-Smith, W. Melnitchouk, N. Sato, A. W. Thomas, X. G. Wang,
  M. J. White","Global QCD Analysis and Dark Photons","5 pages, 4 figures, 1 table",,,,"hep-ph hep-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a global QCD analysis of high energy scattering data within the
JAM Monte Carlo framework, including a coupling to a dark photon that augments
the standard model electroweak coupling via kinetic mixing with the hypercharge
$B$ boson. Including the most recent measurement of the anomalous magnetic
moment of the muon as a constraint, we find a significant reduction in the
combined $\chi^2$, favoring the inclusion of a dark photon, with a statistical
significance in excess of 8$\sigma$. With respect to the experimental data, the
improvements in the theoretical predictions are spread across a wide range of
$x$ and~$Q^2$, with the largest improvement corresponding to neutral current
data from HERA, while the best fit yields a value of $g-2$ which significantly
reduces the disagreement with the latest experimental determination. The best
fit yields a dark photon mass in the range 4.2--6.2~GeV and a mixing parameter
of order 0.1.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:41:41 GMT""}]","2023-02-23"
"2302.11127","Chongjun Ouyang","Chongjun Ouyang, Hao Xu, Xujie Zang, and Hongwen Yang","Secure Antenna Selection and Beamforming in MIMO Systems","5 pages. arXiv admin note: substantial text overlap with
  arXiv:2212.13684",,,,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  This work proposes a novel joint design for multiuser multiple-input
multiple-output wiretap channels. The base station exploits a switching network
to connect a subset of its antennas to the available radio frequency chains.
The switching network and transmit beamformers are jointly designed to maximize
the weighted secrecy sum-rate for this setting. The principal design problem
reduces to an NP-hard mixed-integer non-linear programming. We invoke the
fractional programming technique and the penalty dual decomposition method to
develop a tractable iterative algorithm that effectively approximates the
optimal design. Our numerical investigations validate the effectiveness of the
proposed algorithm and its superior performance compared with the benchmark.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:45:44 GMT""}]","2023-02-23"
"2302.11128","Felix Feng","Felix Zhiyu Feng, Wenyu Wang, Yufeng Wu, Gaoqing Zhang","Ignorance Is Bliss: The Screening Effect of (Noisy) Information","Also available on SSRN:
  https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3775306",,,,"econ.TH","http://creativecommons.org/licenses/by/4.0/","  This paper studies how the firm designs its internal information system when
facing an adverse selection problem arising from unobservable managerial
abilities. While more precise information allows the firm to make ex-post more
efficient investment decisions, noisier information has an ex-ante screening
effect that allows the firm to attract on-average better managers. The tradeoff
between more effective screening of managers and more informed investment
implies a non-monotonic relationship between firm value and information
quality, and a marginal improvement of information quality does not necessarily
lead to an overall improvement of firm value.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:49:25 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 23:07:03 GMT""}]","2023-02-28"
"2302.11129","Hsiang-Ting Chen","Carlos Alfredo Tirado Cortes, Chin-Teng Lin, Tien-Thong Nguyen Do,
  Hsiang-Ting Chen","An EEG-based Experiment on VR Sickness and Postural Instability While
  Walking in Virtual Environments","Accepted by IEEE VR 2023",,,,"cs.HC cs.GR","http://creativecommons.org/licenses/by/4.0/","  Previous studies showed that natural walking reduces the susceptibility to VR
sickness. However, many users still experience VR sickness when wearing VR
headsets that allow free walking in room-scale spaces. This paper studies VR
sickness and postural instability while the user walks in an immersive virtual
environment using an electroencephalogram (EEG) headset and a full-body motion
capture system. The experiment induced VR sickness by gradually increasing the
translation gain beyond the user's detection threshold. A between-group
comparison between participants with and without VR sickness symptoms found
some significant differences in postural stability but found none on gait
patterns during the walking. In the EEG analysis, the group with VR sickness
showed a reduction of alpha power, a phenomenon previously linked to a higher
workload and efforts to maintain postural control. In contrast, the group
without VR sickness exhibited brain activities linked to fine cognitive-motor
control. The EEG result provides new insights into the postural instability
theory: participants with VR sickness could maintain their postural stability
at the cost of a higher cognitive workload. Our result also indicates that the
analysis of lower-frequency power could complement behavioural data for
continuous VR sickness detection in both stationary and mobile VR setups.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:51:31 GMT""}]","2023-02-23"
"2302.11130","Mohamed Akrout","Mohamed Akrout, Faouzi Bellili, Amine Mezghani, Josef A. Nossek","Physically Consistent Models for Intelligent Reflective Surface-assisted
  Communications under Mutual Coupling and Element Size Constraint",,,,,"cs.IT math.IT","http://creativecommons.org/licenses/by/4.0/","  We investigate the benefits of mutual coupling effects between the passive
elements of intelligent reconfigurable surfaces (IRSs) on maximizing the
achievable rate of downlink Internet-of-Things (IoT) networks. In this paper,
we present an electromagnetic (EM) coupling model for IRSs whose elements are
connected minimum scattering antennas (i.e., dipoles). Using Chu's theory, we
incorporate the finite antenna size constraint on each element of the IRS to
obtain the IRS mutual impedance matrix. By maximizing the IRS phase shiters
using the gradient ascent procedure, our numerical results show that mutual
coupling is indeed crucial to avoid the achievable rate degradation when the
spacing between IRS elements is down to a fraction of the wavelength.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:51:53 GMT""}]","2023-02-23"
"2302.11131","Yuchen Hu","Yuchen Hu, Chen Chen, Heqing Zou, Xionghu Zhong, Eng Siong Chng","Unifying Speech Enhancement and Separation with Gradient Modulation for
  End-to-End Noise-Robust Speech Separation","5 pages, 5 figures, Accepted by ICASSP 2023",,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies in neural network-based monaural speech separation (SS) have
achieved a remarkable success thanks to increasing ability of long sequence
modeling. However, they would degrade significantly when put under realistic
noisy conditions, as the background noise could be mistaken for speaker's
speech and thus interfere with the separated sources. To alleviate this
problem, we propose a novel network to unify speech enhancement and separation
with gradient modulation to improve noise-robustness. Specifically, we first
build a unified network by combining speech enhancement (SE) and separation
modules, with multi-task learning for optimization, where SE is supervised by
parallel clean mixture to reduce noise for downstream speech separation.
Furthermore, in order to avoid suppressing valid speaker information when
reducing noise, we propose a gradient modulation (GM) strategy to harmonize the
SE and SS tasks from optimization view. Experimental results show that our
approach achieves the state-of-the-art on large-scale Libri2Mix- and
Libri3Mix-noisy datasets, with SI-SNRi results of 16.0 dB and 15.8 dB
respectively. Our code is available at GitHub.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:54:50 GMT""}]","2023-02-23"
"2302.11132","Yikai Li","Yi-Kai Li and Athina Petropulu","Minorization-based Low-Complexity Design for IRS-Aided ISAC Systems","Accepted by IEEE Radar Conference 2023",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A low-complexity design is proposed for an integrated sensing and
communication (ISAC) system aided by an intelligent reflecting surface (IRS).
The radar precoder and IRS parameter are computed alternatingly to maximize the
weighted sum signal-to-noise ratio (SNR) at the radar and communication
receivers. The IRS design problem has an objective function of fourth order in
the IRS parameter matrix, and is subject to highly non-convex unit modulus
constraints. To address this challenging problem and obtain a low-complexity
solution, we employ a minorization technique twice; the original fourth order
objective is first surrogated with a quadratic one via minorization, and is
then minorized again to a linear one. This leads to a closed form solution for
the IRS parameter in each iteration, thus reducing the IRS design complexity.
Numerical results are presented to show the effectiveness of the proposed
method.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:58:54 GMT""}]","2023-02-23"
"2302.11133","Yongmin Li","Shuaishuai Liu, Zhengguo Lu, Pu Wang, Yan Tian, Qing Lu, Xuyang Wang,
  Yongmin Li","Experimental Demonstration of Sequential Multiparty Quantum Secret
  Sharing and Quantum Conference Key Agreement",,,,,"physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum secret sharing (QSS) and quantum conference key agreement (QCKA)
provide efficient encryption approaches for realizing multi-party secure
communication, which are essential components of future quantum networks. We
present three practical, scalable, verifiable (k, n) threshold QSS protocols
that are secure against eavesdroppers and dishonest players. The proposed QSS
protocols eliminate the need for each player preparing the laser source and
laser phase locking of the overall players. The dealer can implement the
parameter evaluation and get the secret information of each player without the
cooperation from other players. We consider the practical security of the
proposed QSS systems with Trojan-horse attack, untrusted source intensity
fluctuating and untrusted noisy sources. Our QSS systems are versatile, they
can support the QCKA protocol by only modifying the classic post-processing and
requiring no changes to the underlying hardware architecture. We experimentally
implement the QSS and QCKA protocol with five parties over 25 km (55 km) single
mode fibers, and achieve a key rate of 0.0061 (7.14*10^-4) bits per pulse. Our
work paves the way for the practical applications of future QSS and QCKA.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 03:59:15 GMT""}]","2023-02-23"
"2302.11134","Zheng Feng","Zheng Feng, Wei Tan, Zuanming Jin, Yi-Jia Chen, Zhangfeng Zhong, Song
  Sun, Jin Tang, Yexing Jiang, Po-Hsun Wu, Jun Cheng, Bingfeng Miao, Haifeng
  Ding, Dacheng Wang, Yiming Zhu, Guohong Ma, Dazhi Hou, Ssu-Yen Huang","Anomalous Nernst effect induced terahertz emission in a single
  ferromagnetic film",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-sa/4.0/","  By developing a bidirectional-pump terahertz (THz) emission spectroscopy, we
reveal an anomalous Nernst effect (ANE) induced THz emission in a single
ferromagnetic film. Based on the distinctive symmetry of the THz signals, ANE
is unequivocally distinguished from the previously attributed ultrafast
demagnetization and anomalous Hall effect mechanisms. A quantitative method is
established to separate the different contributions, demonstrating a
significant ANE contribution that even overwhelms other competing mechanisms.
Our work not only clarifies the origin of the ferromagnetic-based THz emission,
but also offers a fertile platform for investigating the ultrafast magnetism
and THz spintronics.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:00:28 GMT""}]","2023-02-23"
"2302.11135","Andres Hernandez-Matamoros","Andres Hernandez-Matamoros, Kohei Sugawara, Tatsuya Kaneko, Ryota
  Wada, Masahiko Ozaki (JAMSTEC, INPEX, JAPEX, and JOGMEC)","Semi-Supervised Approach for Early Stuck Sign Detection in Drilling
  Operations","There is a conflict interest between authors",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  A real-time stuck pipe prediction methodology is proposed in this paper. We
assume early signs of stuck pipe to be apparent when the drilling data behavior
deviates from that from normal drilling operations. The definition of normalcy
changes with drill string configuration or geological conditions. Here, a
depth-domain data representation is adopted to capture the localized normal
behavior. Several models, based on auto-encoder and variational auto-encoders,
are trained on regular drilling data extracted from actual drilling data. When
the trained model is applied to data sets before stuck incidents, eight
incidents showed large reconstruction errors. These results suggest better
performance than the previously reported supervised approach. Inter-comparison
of various models reveals the robustness of our approach. The model performance
depends on the featured parameter suggesting the need for multiple models in
actual operation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:02:50 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 06:59:57 GMT""}]","2023-02-27"
"2302.11136","Rabindra Lamsal","Rabindra Lamsal, Maria Rodriguez Read, Shanika Karunasekera","A Twitter narrative of the COVID-19 pandemic in Australia","Accepted to ISCRAM 2023",,,,"cs.SI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Social media platforms contain abundant data that can provide comprehensive
knowledge of historical and real-time events. During crisis events, the use of
social media peaks, as people discuss what they have seen, heard, or felt.
Previous studies confirm the usefulness of such socially generated discussions
for the public, first responders, and decision-makers to gain a better
understanding of events as they unfold at the ground level. This study performs
an extensive analysis of COVID-19-related Twitter discussions generated in
Australia between January 2020, and October 2022. We explore the Australian
Twitterverse by employing state-of-the-art approaches from both supervised and
unsupervised domains to perform network analysis, topic modeling, sentiment
analysis, and causality analysis. As the presented results provide a
comprehensive understanding of the Australian Twitterverse during the COVID-19
pandemic, this study aims to explore the discussion dynamics to aid the
development of future automated information systems for epidemic/pandemic
management.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:06:59 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 02:01:08 GMT""}]","2023-02-27"
"2302.11137","Yiqi Zhao","Yiqi Zhao, Ziyan An, Xuqing Gao, Ayan Mukhopadhyay, Meiyi Ma","Fairguard: Harness Logic-based Fairness Rules in Smart Cities","This paper was accepted by the 8th ACM/IEEE Conference on Internet of
  Things Design and Implementation",,,,"cs.AI","http://creativecommons.org/licenses/by/4.0/","  Smart cities operate on computational predictive frameworks that collect,
aggregate, and utilize data from large-scale sensor networks. However, these
frameworks are prone to multiple sources of data and algorithmic bias, which
often lead to unfair prediction results. In this work, we first demonstrate
that bias persists at a micro-level both temporally and spatially by studying
real city data from Chattanooga, TN. To alleviate the issue of such bias, we
introduce Fairguard, a micro-level temporal logic-based approach for fair smart
city policy adjustment and generation in complex temporal-spatial domains. The
Fairguard framework consists of two phases: first, we develop a static
generator that is able to reduce data bias based on temporal logic conditions
by minimizing correlations between selected attributes. Then, to ensure
fairness in predictive algorithms, we design a dynamic component to regulate
prediction results and generate future fair predictions by harnessing logic
rules. Evaluations show that logic-enabled static Fairguard can effectively
reduce the biased correlations while dynamic Fairguard can guarantee fairness
on protected groups at run-time with minimal impact on overall performance.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:14:09 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 01:51:30 GMT""},{""version"":""v3"",""created"":""Wed, 15 Mar 2023 21:47:38 GMT""},{""version"":""v4"",""created"":""Sun, 2 Apr 2023 04:35:54 GMT""},{""version"":""v5"",""created"":""Tue, 11 Apr 2023 04:49:09 GMT""},{""version"":""v6"",""created"":""Fri, 21 Apr 2023 15:47:29 GMT""}]","2023-04-24"
"2302.11138","Yuta Taniguchi","Yuta Taniguchi","Good involutions of generalized Alexander quandles","6 pages",,,,"math.GT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quandles with good involutions, which are called symmetric quandles, can be
used to define invariants of unoriented knots and links. In this paper, we
determine the necessary and sufficient condition for good involutions of a
generalized Alexander quandle to exist. Moreover, we classify all good
involutions of a connected generalized Alexander quandle up to symmetric
quandle isomorphisms.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:20:37 GMT""}]","2023-02-23"
"2302.11139","Zachary Stier","Yonah Borns-Weil, Tahsin Saffat, Zachary Stier","A Quantum Algorithm for Functions of Multiple Commuting Hermitian
  Matrices",,,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Quantum signal processing allows for quantum eigenvalue transformation with
Hermitian matrices, in which each eigenspace component of an input vector gets
transformed according to its eigenvalue. In this work, we introduce the
multivariate quantum eigenvalue transformation for functions of commuting
Hermitian matrices. We then present a framework for working with polynomial
matrix functions in which we may solve MQET, and give the application of
computing functions of normal matrices using a quantum computer.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:23:05 GMT""}]","2023-02-23"
"2302.11140","Da Huang","Ren-Peng Zhou, Da Huang, Chao-Qiang Geng","Cosmic Birefringence from Neutrino and Dark Matter Asymmetries","25 pages, 4 figures",,,,"astro-ph.CO hep-ph","http://creativecommons.org/licenses/by/4.0/","  In light of the recent measurement of the nonzero Cosmic Microwave Background
(CMB) polarization rotation angle from the Planck 2018 data, we explore the
possibility that such a cosmic birefringence effect is induced by coupling a
fermionic current with photons via a Chern-Simons-like term. We begin our
discussion by rederiving the general formulae of the cosmic birefringence angle
with correcting a mistake in the previous study. We then identify the fermions
in the current as the left-handed electron neutrinos and asymmetric dark matter
(ADM) particles, since the rotation angle is sourced by the number density
difference between particles and antiparticles. For the electron neutrino case,
with the value of the degeneracy parameter $\xi_{\nu_e}$ recently measured by
the EMPRESS survey, we find a large parameter space which can explain the CMB
photon polarization rotations. On the other hand, for the ADM solution, we
consider two benchmark cases with $M_\chi = 5$ GeV and 5 keV. The former is the
natural value of the ADM mass if the observed ADM and baryon asymmetry in the
Universe are produced by the same mechanism, while the latter provides a warm
DM candidate. In addition, we explore the experimental constraints from the CMB
power spectra and the DM direct detections.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:31:36 GMT""}]","2023-02-23"
"2302.11141","Floyd Creevey","Floyd M. Creevey, Charles D. Hill, Lloyd C. L. Hollenberg","GASP -- A Genetic Algorithm for State Preparation",,,,,"quant-ph cs.NE","http://creativecommons.org/licenses/by/4.0/","  The efficient preparation of quantum states is an important step in the
execution of many quantum algorithms. In the noisy intermediate-scale quantum
(NISQ) computing era, this is a significant challenge given quantum resources
are scarce and typically only low-depth quantum circuits can be implemented on
physical devices. We present a genetic algorithm for state preparation (GASP)
which generates relatively low-depth quantum circuits for initialising a
quantum computer in a specified quantum state. The method uses a basis set of
R_x, R_y, R_z, and CNOT gates and a genetic algorithm to systematically
generate circuits to synthesize the target state to the required fidelity. GASP
can produce more efficient circuits of a given accuracy with lower depth and
gate counts than other methods. This variability of the required accuracy
facilitates overall higher accuracy on implementation, as error accumulation in
high-depth circuits can be avoided. We directly compare the method to the state
initialisation technique based on an exact synthesis technique by implemented
in IBM Qiskit simulated with noise and implemented on physical IBM Quantum
devices. Results achieved by GASP outperform Qiskit's exact general circuit
synthesis method on a variety of states such as Gaussian states and W-states,
and consistently show the method reduces the number of gates required for the
quantum circuits to generate these quantum states to the required accuracy.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:41:01 GMT""}]","2023-02-23"
"2302.11142","Rahul Mondal","Rahul Mondal, Nesar Hossain","Rough Statistical Convergence of Double Sequences in Probabilistic
  Normed Spaces",,,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this paper, we have defined rough convergence and rough statistical
convergence of double sequences in probabilistic normed spaces which is more
generalized version than the rough statistical convergence of double sequences
in normed linear spaces. Also, we have defined rough statistical cluster points
of double sequences and then, investigated some important results associated
with the set of rough statistical limits of double sequences in these spaces.
Moreover, in the same spaces, we have proved an important relation between the
set of all rough statistical cluster points and rough statistical limits under
certain condition.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:41:13 GMT""},{""version"":""v2"",""created"":""Fri, 17 Mar 2023 12:30:46 GMT""}]","2023-03-20"
"2302.11143","Eligio Cruz-Albaro","E. Cruz-Albaro, A. Guti\'errez-Rodr\'iguez, M. A. Hern\'andez-Ru\'iz
  and T. Cisneros-P\'erez","Searching the anomalous electromagnetic and weak dipole moments of the
  top-quark at the Bestest Little Higgs Model","77 pages, 67 figures. arXiv admin note: text overlap with
  arXiv:2208.09090, arXiv:2202.12738",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, using a Bestest Little Higgs Model (BLHM) approach, we obtain
bounds on the top-quark electromagnetic and weak dipole moments. These physical
observables are sensitive to quantum corrections induced by virtual particles
at the one-loop level. The contributions of the virtual particles are obtained
from the vertices of scalar bosons, vector bosons, and heavy quarks: $tq_iS_i$,
$S_i=h_0, H_0, A_0, \phi^{0}, \eta^{0}, \sigma, H^{\pm}, \phi^{\pm},
\eta^{\pm}$; $tq_iV_i$, $V_i= \gamma, Z, W, Z', W'$; $V q_i\bar q_i$,
$V=\gamma,Z$, $q_i=b, t, B, T, T_5, T_6, T^{2/3}, T^{5/3}$; $ V
W^{-}_{i}\Phi^{+}_i $, $W_{i} \equiv W, W'$, $\Phi^{\pm}_{i}= \phi^{\pm},
\eta^{\pm}$; $ZZH_i$, $H_i=h_0, H_0$; $ZZ' H_i$; and $VW'W'$. With these new
contributions, we evaluated the electroweak dipole moments $ a_t$, $ a^{W}_t $,
$ d_t $ and $ d^{W}_{t} $ of the top-quark in the diagonalization schemes $y_2
> y_3$ and $y_2 < y_3$ to the Yukawa couplings. For the BLHM parameters, we
choose the following values of $m_{A_0}= 1000$ GeV, $m_{\eta^0}= 100$ GeV,
$f=[1000, 3000]$ GeV, $F=[3000, 6000]$ GeV and $\tan\beta=3$, which give the
best sensitivity on the electroweak dipole moments of the top-quark in this
context: $a_t=1.39 \times 10^{-4} + i\, 6.55 \times 10^{-5}$; $a^{W}_t=6.31
\times 10^{-5} - i\, 1.39 \times 10^{-5}$ for the $y_2 > y_3 $ scenario, while
$a_t= 2.12 \times 10^{-4} + i\, 4.49 \times 10^{-5}$; $a^{W}_t= 2.13 \times
10^{-4} - i\, 1.34 \times 10^{-5}$ for the $y_2 < y_3 $ scenario.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:45:38 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 03:53:30 GMT""}]","2023-02-28"
"2302.11144","Qiang Cheng","Qiang Cheng and Qing-Feng Sun","Josephson diode based on conventional superconductors and a chiral
  quantum dot","4figures",,"10.1103/PhysRevB.107.184511",,"cond-mat.mes-hall cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose theoretically a Josephson diode consisting of the conventional
superconductors with the plain s-wave pairing and a chiral quantum dot. When an
external magnetic field is exerted on the quantum dot, the critical current of
the Josephson structure is different for the opposite directions of current
flow. The strong nonreciprocity can be obtained in a large area of the
parameter space. The inversion and the on/off state of the nonreciprocity can
be conveniently regulated by adjusting the direction of the external field. The
dependences of the nonreciprocal behaviors on the the hopping amplitude, the
magnitude of the magnetic field and the energy level of the quantum dot are
investigated in details using the Keldysh nonequilibrium Green's function
formalism under the self-consistent procedure. The symmetric and the
antisymmetric properties of the nonreciprocity are analyzed from symmetries
satisfied by the superconductors. The proposed diode effect also applies to
other chiral conductors as interlayer. Its formation has no restriction on the
type of the current-phase difference relations. The generality and flexibility
of our proposed diode effect provides more possibilities for the design of the
dissipationless diode devices.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:45:55 GMT""}]","2023-05-31"
"2302.11145","Yu Qiao","Jia Zhao, Yuqin Feng, and Yu Qiao","Para-K\""ahler and pseudo-K\""ahler structures on Lie-Yamaguti algebras","arXiv admin note: text overlap with arXiv:1711.08381 by other authors",,,,"math.RA","http://creativecommons.org/licenses/by/4.0/","  For a pre-Lie-Yamaguti algebra $A$, by using its sub-adjacent Lie-Yamaguti
algebra $A^c$, we are able to construct a semidirect product Lie-Yamaguti
algebra via a representation of $A^c$. The investigation of such semidirect
Lie-Yamaguti algebras leads us to the notions of para-K\""ahler structures and
pseudo-K\""ahler structures on Lie-Yamaguti algebras, and also gives the
definition of complex product structures on Lie-Yamaguti algebras which was
first introduced in [25]. Furthermore, a Levi-Civita product with respect to a
pseudo-Riemannian \Lie-Yamaguti algebra is introduced and we explore its
relation with pre-Lie-Yamaguti algebras.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:53:21 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 02:38:42 GMT""}]","2023-02-24"
"2302.11146","Masumi Kasai","Masumi Kasai","A unified treatment of the redshift, the Doppler effect, and the time
  dilation in general relativity",,,,,"gr-qc","http://creativecommons.org/licenses/by-nc-sa/4.0/","  WWe present a unified treatment of the gravitational and cosmological
redshift, the Doppler effect due to the moving observer or light source, and
the time dilation in the gravitational field in the framework of general
relativity.
  We apply it to the cases of moving observer or light source in the
gravitational field and obtain the Doppler effect formula, in addition to the
standard gravitational or cosmological redshift.
  In particular, the longitudinal and the transverse Doppler effects are
explicitly given which hold in fully general-relativistic situations.
  We also examine the time dilation of the moving clock on geodesic in the
gravitational field.
  We confirm that the well-known formula for the ratio of the elapsed times
$\Delta \bar{T}/\Delta T_1 = \sqrt{1 - \frac{3}{2}\frac{r_g}{r}}\Bigl/\sqrt{1 -
\frac{r_g}{r_1}}$, where $\Delta \bar{T}$ is of the moving clock on circular
orbit with radius $r$ and $\Delta T_1$ is of the observer at rest $r=r_1$ and
$r_g$ is the Schwarzschild radius, exactly holds without approximation.
  We also derive the new result for the time dilation of the moving clock on
elliptical orbit with the semi-major axis $a$.
  The ratio of the elapsed times, after the time average per cycle, is
$\langle\Delta \bar{T}\rangle/\Delta T_1 \simeq \sqrt{1 -
\frac{3}{2}\frac{r_g}{a}}\Bigl/\sqrt{1 - \frac{r_g}{r_1}}$, which holds up to
the first order of $r_g$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 04:57:27 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 02:10:03 GMT""},{""version"":""v3"",""created"":""Fri, 19 May 2023 09:48:19 GMT""}]","2023-05-22"
"2302.11147","Hoi-To Wai","Aymeric Dieuleveut, Gersende Fort, Eric Moulines, Hoi-To Wai","Stochastic Approximation Beyond Gradient for Signal Processing and
  Machine Learning","29 pages, 7 pages of supplementary materials",,,,"math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic approximation (SA) is a classical algorithm that has had since the
early days a huge impact on signal processing, and nowadays on machine
learning, due to the necessity to deal with a large amount of data observed
with uncertainties. An exemplar special case of SA pertains to the popular
stochastic (sub)gradient algorithm which is the working horse behind many
important applications. A lesser-known fact is that the SA scheme also extends
to non-stochastic-gradient algorithms such as compressed stochastic gradient,
stochastic expectation-maximization, and a number of reinforcement learning
algorithms. The aim of this article is to overview and introduce the
non-stochastic-gradient perspectives of SA to the signal processing and machine
learning audiences through presenting a design guideline of SA algorithms
backed by theories. Our central theme is to propose a general framework that
unifies existing theories of SA, including its non-asymptotic and asymptotic
convergence results, and demonstrate their applications on popular
non-stochastic-gradient algorithms. We build our analysis framework based on
classes of Lyapunov functions that satisfy a variety of mild conditions. We
draw connections between non-stochastic-gradient algorithms and scenarios when
the Lyapunov function is smooth, convex, or strongly convex. Using the said
framework, we illustrate the convergence properties of the
non-stochastic-gradient algorithms using concrete examples. Extensions to the
emerging variance reduction techniques for improved sample complexity will also
be discussed.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:00:51 GMT""}]","2023-02-23"
"2302.11148","Taichi Kato","Taichi Kato (Kyoto U)","MGAB-V240: 23-min AM CVn star showing both 12-d supercycle and
  standstills","8 pages, 5 figures, VSOLJ Variable Star Bulletin No. 111",,,,"astro-ph.SR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Using Zwicky Transient Facility (ZTF) data, I noticed that MGAB-V240 =
PS1-3PI J185529.82+323017.8 showed two different states: regularly outbursting
state with a cycle length of 12 d and standstills. I found that the regularly
outbursting state was in fact a sequence of superoutburst and intervening
normal outbursts comprising a 12 d supercycle. During one of the
superoutbursts, superhumps with a period of 0.015824(9) d (=22.79 min) were
detected in the ZTF time-resolved data. This period and behavior have confirmed
that MGAB-V240 is an AM CVn-type object with the shortest known supercycle and
the second known AM CVn star showing genuine standstills. The standstills in
this system were interrupted by short drops and the system often brightened
after these drops. This phenomenon can be explained by the accumulation of the
transferred matter in the outer part of the disk during the drops. This
phenomenon favors a constant mass-transfer from the secondary combined with the
difficulty in maintaining the hot state in a helium disk rather than a
temporary decrease of the mass-transfer rate as the cause of these drops.
MGAB-V240 should be close to the border of the thermal instability of a helium
disk, and the observed superhump period agrees very well with the activity
sequence expected by the disk instability theory and the evolutionary sequence
of AM CVn stars.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:09:54 GMT""}]","2023-02-23"
"2302.11149","Abdullah Al Mamun","Alsadig Ali, Abdullah Al-Mamun, Felipe Pereira, Arunasalam Rahunanthan","Multiscale Sampling for the Inverse Modeling of Partial Differential
  Equations",,,,,"math.NA cs.NA","http://creativecommons.org/publicdomain/zero/1.0/","  We are concerned with a novel Bayesian statistical framework for the
characterization of natural subsurface formations, a very challenging task.
Because of the large dimension of the stochastic space of the prior
distribution in the framework, typically a dimensional reduction method, such
as a Karhunen-Leove expansion (KLE), needs to be applied to the prior
distribution to make the characterization computationally tractable. Due to the
large variability of properties of subsurface formations (such as permeability
and porosity) it may be of value to localize the sampling strategy so that it
can better adapt to large local variability of rock properties. In this paper,
we introduce the concept of multiscale sampling to localize the search in the
stochastic space. We combine the simplicity of a preconditioned Markov Chain
Monte Carlo method with a new algorithm to decompose the stochastic space into
orthogonal subspaces, through a one-to-one mapping of the subspaces to
subdomains of a non-overlapping domain decomposition of the region of interest.
The localization of the search is performed by a multiscale blocking strategy
within Gibbs sampling: we apply a KL expansion locally, at the subdomain level.
Within each subdomain, blocking is applied again, for the sampling of the KLE
random coefficients. The effectiveness of the proposed framework is tested in
the solution of inverse problems related to elliptic partial differential
equations arising in porous media flows. We use multi-chain studies in a
multi-GPU cluster to show that the new algorithm clearly improves the
convergence rate of the preconditioned MCMC method. Moreover, we illustrate the
importance of a few conditioning points to further improve the convergence of
the proposed method.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:11:57 GMT""}]","2023-02-23"
"2302.11150","Pattarakrit Rattanukul","Pattarakrit Rattanukul, Chansida Makaranond, Pumipat Watanakulcharus,
  Chaiyong Ragkhitwetsagul, Tanapol Nearunchorn, Vasaka Visoottiviseth, Morakot
  Choetkiertikul, Thanwadee Sunetnanta","Microusity: A testing tool for Backends for Frontends (BFF) Microservice
  Systems",,,,,"cs.SE","http://creativecommons.org/licenses/by/4.0/","  The microservice software architecture is more scalable and efficient than
its monolithic predecessor. Despite its increasing adoption, microservices
might expose security concerns and issues that are distinct from those
associated with monolithic designs. We propose Microusity, a tool that performs
RESTful API testing on a specific type of microservice pattern called back end
for front end (BFF). We design a novel approach to trace BFF requests using the
port mapping between requests to BFF and the sub-requests sent to back-end
microservices. Furthermore, our tool can pinpoint which of the back end service
causing the internal server error, which may lead to unhandled errors or
vulnerabilities. Microusity provides an error report and a graph visualization
that reveal the source of the error and supports developers in comprehension
and debugging of the errors. The evaluation of eight software practitioners
shows that Microusity and its security test reports are useful for
investigating and understanding problems in BFF systems. The prototype tool and
the video demo of the tool can be found at
https://github.com/MUICT-SERU/MICROUSITY.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:13:03 GMT""}]","2023-02-23"
"2302.11151","Huang Lingxiao","Lingxiao Huang, Pinyan Lu, Xuan Wu","Improved Coresets for Clustering with Capacity and Fairness Constraints",,,,,"cs.DS cs.CG","http://creativecommons.org/licenses/by/4.0/","  We study coresets for clustering with capacity and fairness constraints. Our
main result is a near-linear time algorithm to construct
$\tilde{O}(k^2\varepsilon^{-2z-2})$-sized $\varepsilon$-coresets for
capacitated $(k,z)$-clustering which improves a recent
$\tilde{O}(k^3\varepsilon^{-3z-2})$ bound by [BCAJ+22, HJLW23]. As a corollary,
we also save a factor of $k \varepsilon^{-z}$ on the coreset size for fair
$(k,z)$-clustering compared to them.
  We fundamentally improve the hierarchical uniform sampling framework of
[BCAJ+22] by adaptively selecting sample size on each ring instance,
proportional to its clustering cost to an optimal solution. Our analysis relies
on a key geometric observation that reduces the number of total ``effective
centers"" from [BCAJ+22]'s $\tilde{O}(k^2\varepsilon^{-z})$ to merely $O(k\log
\varepsilon^{-1})$ by being able to ``ignore'' all center points that are too
far or too close to the ring center.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:20:26 GMT""}]","2023-02-23"
"2302.11152","Antonious Girgis","Antonious M. Girgis and Suhas Diggavi","Multi-Message Shuffled Privacy in Federated Learning",,,,,"cs.LG cs.CR","http://creativecommons.org/licenses/by/4.0/","  We study differentially private distributed optimization under communication
constraints. A server using SGD for optimization aggregates the client-side
local gradients for model updates using distributed mean estimation (DME). We
develop a communication-efficient private DME, using the recently developed
multi-message shuffled (MMS) privacy framework. We analyze our proposed DME
scheme to show that it achieves the order-optimal
privacy-communication-performance tradeoff resolving an open question in [1],
whether the shuffled models can improve the tradeoff obtained in Secure
Aggregation. This also resolves an open question on the optimal trade-off for
private vector sum in the MMS model. We achieve it through a novel privacy
mechanism that non-uniformly allocates privacy at different resolutions of the
local gradient vectors. These results are directly applied to give guarantees
on private distributed learning algorithms using this for private gradient
aggregation iteratively. We also numerically evaluate the private DME
algorithms.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:23:52 GMT""}]","2023-02-23"
"2302.11153","Hyung-Joon Tag","Han Ju Lee and Hyung-Joon Tag","Remarks on the Daugavet Property for Complex Banach Spaces","21 pages, typos are corrected",,,,"math.FA","http://creativecommons.org/licenses/by/4.0/","  In this article, we study the Daugavet property and the diametral diameter
two properties in complex Banach spaces. The characterizations for both
Daugavet and $\Delta$-points are revisited in the context of complex Banach
spaces. We also provide relationships between some variants of alternative
convexity and smoothness, nonsquareness, and the Daugavet property. As a
consequence, every strongly locally uniformly alternatively convex or smooth
(sluacs) Banach space does not contain $\Delta$-points from the fact that such
spaces are locally uniformly nonsquare. We also study the convex diametral
local diameter two property (convex-DLD2P) and the polynomial Daugavet property
in the vector-valued function space $A(K, X)$. From an explicit computation of
the polynomial Daugavetian index of $A(K, X)$, we show that the space $A(K, X)$
has the polynomial Daugavet property if and only if either the base algebra $A$
or the range space $X$ has the polynomial Daugavet property. Consequently, we
obtain that the polynomial Daugavet property, the Daugavet property, the
diameteral diameter two properties, and the property ($\mathcal{D}$) are
equivalent for infinite-dimensional uniform algebras.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:30:03 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 01:50:48 GMT""},{""version"":""v3"",""created"":""Sun, 26 Feb 2023 15:16:36 GMT""}]","2023-02-28"
"2302.11154","Hexiang Hu","Hexiang Hu, Yi Luan, Yang Chen, Urvashi Khandelwal, Mandar Joshi,
  Kenton Lee, Kristina Toutanova, Ming-Wei Chang","Open-domain Visual Entity Recognition: Towards Recognizing Millions of
  Wikipedia Entities","Dataset available at https://open-vision-language.github.io/oven",,,,"cs.CV cs.AI cs.CL","http://creativecommons.org/licenses/by/4.0/","  Large-scale multi-modal pre-training models such as CLIP and PaLI exhibit
strong generalization on various visual domains and tasks. However, existing
image classification benchmarks often evaluate recognition on a specific domain
(e.g., outdoor images) or a specific task (e.g., classifying plant species),
which falls short of evaluating whether pre-trained foundational models are
universal visual recognizers. To address this, we formally present the task of
Open-domain Visual Entity recognitioN (OVEN), where a model need to link an
image onto a Wikipedia entity with respect to a text query. We construct
OVEN-Wiki by re-purposing 14 existing datasets with all labels grounded onto
one single label space: Wikipedia entities. OVEN challenges models to select
among six million possible Wikipedia entities, making it a general visual
recognition benchmark with the largest number of labels. Our study on
state-of-the-art pre-trained models reveals large headroom in generalizing to
the massive-scale label space. We show that a PaLI-based auto-regressive visual
recognition model performs surprisingly well, even on Wikipedia entities that
have never been seen during fine-tuning. We also find existing pretrained
models yield different strengths: while PaLI-based models obtain higher overall
performance, CLIP-based models are better at recognizing tail entities.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:31:26 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 00:50:25 GMT""}]","2023-02-27"
"2302.11155","Jesus Noyola Rodriguez","J. Noyola Rodriguez and G. Omel'yanov","Solitary wave solutions of a generalization of the mKdV equation","Preparation for Journal submission",,,,"nlin.SI math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a generalization of the mKdV equation, which contains dissipation
terms similar to those contained in both the Benjamin-Bona-Mahoney equation and
the famous Camassa-Holm and Degasperis-Procesi equations. Our objective is the
construction of classical (solitons) and non-classical (peakons and cuspons)
solitary wave solutions of this equation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:31:35 GMT""}]","2023-02-23"
"2302.11156","Ruoyan Kong","Ruoyan Kong, Chuankai Zhang, Ruixuan Sun, Vishnu Chhabra, Tanushsrisai
  Nadimpalli, Joseph A. Konstan","Multi-Objective Personalization in Multi-Stakeholder Organizational Bulk
  E-mail: A Field Experiment","This is a pre-print version of a paper accepted to CSCW 2022, The
  25th ACM Conference On Computer-Supported Cooperative Work And Social
  Computing; Ruoyan Kong et al. 2022. Multi-Objective Personalization in
  Multi-Stakeholder Organizational Bulk E-mail: A Field Experiment. Proc. ACM
  Hum.-Comput. Interact. 6, CSCW2, Article 528 (November 2022)",,"10.1145/3555641",,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bulk email is often used in organizations to communicate
``important-to-organization'' messages such as policy changes, organizational
plans, and administrative updates. However, normal employees may prefer
messages more relevant to their jobs or interests. Organizations face the
challenge of balancing prioritizing the messages they prefer employees to know
(tactical goals) while maintaining employees' positive experiences with these
bulk emails, then they continue to read these emails in the future (strategic
goals).
  Could personalization help organizations achieve these tactical and strategic
goals? In an 8-week field experiment with a university newsletter, we
implemented a 4x5x5 factorial design on personalizing subject lines, top news,
and message order based on both the employees' and the organization's
preferences. We measured these designs' influences on the
open/interest/recognition/read-in-detail rate of the whole newsletter and the
single messages within it.
  We found that ``important-to-organization'' messages only got higher
recognition rates when being put on subject lines / top news (tactical goal).
Mixing them with employee-preferred messages in top news did not bring further
improvement to their own recognition rates but could improve the whole
newsletter's recognition rate. Only when the top news solely contained the
employee-preferred messages were the employees slightly more interested in the
newsletter (strategic goal). We further analyze on which topics the employees
and the organization's preferences conflicted. Finally, we discuss the design
suggestions on personalization and recommendation for organizational bulk
email.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:39:50 GMT""}]","2023-02-23"
"2302.11157","Agam Shah","Agam Shah, Ruchit Vithani, Abhinav Gullapalli, Sudheer Chava","FiNER: Financial Named Entity Recognition Dataset and Weak-Supervision
  Model",,,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The development of annotated datasets over the 21st century has helped us
truly realize the power of deep learning. Most of the datasets created for the
named-entity-recognition (NER) task are not domain specific. Finance domain
presents specific challenges to the NER task and a domain specific dataset
would help push the boundaries of finance research. In our work, we develop the
first high-quality NER dataset for the finance domain. To set the benchmark for
the dataset, we develop and test a weak-supervision-based framework for the NER
task. We extend the current weak-supervision framework to make it employable
for span-level classification. Our weak-ner framework and the dataset are
publicly available on GitHub and Hugging Face.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:41:27 GMT""}]","2023-02-23"
"2302.11158","Miriam Golubchik","Miriam Golubchik, Adi Zitrin, Justin Pierel, Lukas J. Furtak, Ashish
  K. Meena, Or Graur, Patrick L. Kelly, Dan Coe, Felipe Andrade-Santos, Maor
  Asif, Larry D. Bradley, Wenlei Chen, Brenda L. Frye, Sebastian Gomez, Saurabh
  Jha, Guillaume Mahler, Mario Nonino, Louis-Gregory Strolger and Yuanyuan Su","A search for transients in the Reionization Lensing Cluster Survey
  (RELICS): Three new supernovae","Accepted for publication in MNRAS. 10 pages, 3 figures",,"10.1093/mnras/stad1238",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Reionization Cluster Survey (RELICS) imaged 41 galaxy clusters with the
Hubble Space Telescope (HST), in order to detect lensed and high-redshift
galaxies. Each cluster was imaged to about 26.5 AB mag in three optical and
four near-infrared bands, taken in two distinct visits separated by varying
time intervals. We make use of the multiple near-infrared epochs to search for
transient sources in the cluster fields, with the primary motivation of
building statistics for bright caustic crossing events in gravitational arcs.
Over the whole sample, we do not find any significant ($\gtrsim5 \sigma$)
caustic crossing events, in line with expectations from semi-analytic
calculations but in contrast to what may be naively expected from previous
detections of some bright events, or from deeper transient surveys that do find
high rates of such events. Nevertheless, we find six prominent supernova (SN)
candidates over the 41 fields: three of them were previously reported and three
are new ones reported here for the first time. Out of the six candidates, four
are likely core-collapse (CC) SNe -- three in cluster galaxies, and among which
only one was known before, and one slightly behind the cluster at
$z\sim0.6-0.7$. The other two are likely Ia -- both of them previously known,
one probably in a cluster galaxy, and one behind it at $z\simeq2$. Our study
supplies empirical bounds for the rate of caustic crossing events in galaxy
cluster fields to typical HST magnitudes, and lays the groundwork for a future
SN rate study.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:47:33 GMT""},{""version"":""v2"",""created"":""Mon, 24 Apr 2023 12:11:26 GMT""}]","2023-05-03"
"2302.11159","Jiawei Jiang","Jiawei Jiang, Chengkai Han, Jingyuan Wang","BUAA_BIGSCity: Spatial-Temporal Graph Neural Network for Wind Power
  Forecasting in Baidu KDD CUP 2022","6 pages, 4 figures, Report for ACM KDD Workshop - Baidu KDD CUP 2022",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this technical report, we present our solution for the Baidu KDD Cup 2022
Spatial Dynamic Wind Power Forecasting Challenge. Wind power is a rapidly
growing source of clean energy. Accurate wind power forecasting is essential
for grid stability and the security of supply. Therefore, organizers provide a
wind power dataset containing historical data from 134 wind turbines and launch
the Baidu KDD Cup 2022 to examine the limitations of current methods for wind
power forecasting. The average of RMSE (Root Mean Square Error) and MAE (Mean
Absolute Error) is used as the evaluation score. We adopt two spatial-temporal
graph neural network models, i.e., AGCRN and MTGNN, as our basic models. We
train AGCRN by 5-fold cross-validation and additionally train MTGNN directly on
the training and validation sets. Finally, we ensemble the two models based on
the loss values of the validation set as our final submission. Using our
method, our team \team achieves -45.36026 on the test set. We release our codes
on Github (https://github.com/BUAABIGSCity/KDDCUP2022) for reproduction.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:47:45 GMT""}]","2023-02-23"
"2302.11160","Tom Gannon","Tom Gannon","A proof of the Ginzburg-Kazhdan conjecture",,,,,"math.AG math.RT math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that the affine closure of the cotangent bundle of the basic affine
space of a reductive group has conical symplectic singularities, which confirms
a conjecture of Ginzburg and Kazhdan. We also show that this variety is
$\mathbb{Q}$-factorial and has terminal singularities.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 05:52:23 GMT""}]","2023-02-23"
"2302.11161","Yifeng Mao","Yifeng Mao, Sathyanarayanan Chandramouli, Wenqian Xu and Mark A.
  Hoefer","Creation and Interaction of Dark and Bright Topological Breathers from
  Soliton-Cnoidal Wave Collisions",,,,,"nlin.PS physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  Two families of topological breathers are created in a core-annular flow
system by interacting a soliton and a nonlinear periodic (cnoidal) carrier.
Bright and dark breathers are observed to move faster or slower, respectively,
than the carrier while imparting a topological phase shift. Agreement with
weakly nonlinear exact solutions and numerical simulations of a strongly
nonlinear model is achieved. Collisions within and across breather families are
observed to be elastic. The breather creation method and breather properties
are expected to generalize to many continuum and discrete systems.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:05:04 GMT""}]","2023-02-23"
"2302.11162","Jon Huml","Jonathan Huml, Abiy Tasissa, Demba Ba","Sparse, Geometric Autoencoder Models of V1","Symmetry and Geometry in Neural Representations (NeurIPS) 2022",,,,"cs.AI cs.LG","http://creativecommons.org/licenses/by/4.0/","  The classical sparse coding model represents visual stimuli as a linear
combination of a handful of learned basis functions that are Gabor-like when
trained on natural image data. However, the Gabor-like filters learned by
classical sparse coding far overpredict well-tuned simple cell receptive field
(SCRF) profiles. A number of subsequent models have either discarded the sparse
dictionary learning framework entirely or have yet to take advantage of the
surge in unrolled, neural dictionary learning architectures. A key missing
theme of these updates is a stronger notion of \emph{structured sparsity}. We
propose an autoencoder architecture whose latent representations are
implicitly, locally organized for spectral clustering, which begets artificial
neurons better matched to observed primate data. The weighted-$\ell_1$ (WL)
constraint in the autoencoder objective function maintains core ideas of the
sparse coding framework, yet also offers a promising path to describe the
differentiation of receptive fields in terms of a discriminative hierarchy in
future work.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:07:20 GMT""}]","2023-02-23"
"2302.11163","Zipeng Hu","Zipeng Hu, Benjamin D. Wibking, Mark R. Krumholz","The sub-critical illusion: synthetic Zeeman effect observations from
  galactic zoom-in simulations","12 pages, 10 figures, submitted to MNRAS",,"10.1093/mnras/stad931",,"astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  Mass-to-flux ratios measured via the Zeeman effect suggest the existence of a
transition from a magnetically sub-critical state in HI clouds to a
super-critical state in molecular clouds. However, due to projection, chemical,
and excitation effects, Zeeman measurements are subject to a number of biases,
and may not reflect the true relations between gravitational and magnetic
energies. In this paper, we carry out simulations of the formation of
magnetised molecular clouds, zooming in from an entire galaxy to sub-pc scales,
which we post-process to produce synthetic HI and OH Zeeman measurements. The
mass-to-flux ratios we recover from the simulated observations show a
transition in magnetic criticality that closely matches observations, but we
find that the gravitational-magnetic energy ratios on corresponding scales are
mostly super-critical, even in the HI regime. We conclude that HI clouds in the
process of assembling to form molecular clouds are already super-critical even
before H_2 forms, and that the apparent transition from sub- to
super-criticality between HI and H_2 is primarily an illusion created by
chemical and excitation biases affecting the Zeeman measurements.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:10:31 GMT""}]","2023-04-05"
"2302.11164","Xiaodong Zhou","Mingming Shuai, Yulong Yang, Haiming Huang, Rui Song, Yi Zhu, Yanghui
  Liao, Yinyan Zhu, Xiaodong Zhou, Lifeng Yin, and Jian Shen","The influence of adatom diffusion on the formation of skyrmion lattice
  in sub-monolayer Fe on Ir(111)",,"Vacuum 212, 112071 (2023)","10.1016/j.vacuum.2023.112071",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Room temperature grown Fe monolayer (ML) on the Ir(111) single crystal
substrate has attracted great research interests as nano-skyrmion lattice can
form under proper growth conditions. The formation of the nanoscale skyrmion,
however, appears to be greatly affected by the diffusion length of the Fe
adatoms on the Ir(111) surface. We made this observation by employing
spin-polarized scanning tunneling microscopy to study skyrmion formation upon
systematically changing the impurity density on the substrate surface prior to
Fe deposition. Since the substrate surface impurities serve as pinning centers
for Fe adatoms, the eventual size and shape of the Fe islands exhibit a direct
correlation with the impurity density, which in turn determines whether
skyrmion can be formed. Our observation indicates that skyrmion only forms when
the impurity density is below 0.006/nm2, i.e., 12 nm averaged spacing between
the neighboring defects. We verify the significance of Fe diffusion length by
growing Fe on clean Ir(111) substrate at low temperature of 30 K, where no
skyrmion was observed to form. Our findings signify the importance of diffusion
of Fe atoms on the Ir(111) substrate, which affects the size, shape and lattice
perfection of the Fe islands and thus the formation of skyrmion lattice.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:13:32 GMT""},{""version"":""v2"",""created"":""Mon, 10 Apr 2023 14:55:17 GMT""}]","2023-04-11"
"2302.11165","Songlin Zhai","Songlin Zhai, Weiqing Wang, Yuanfang Li, Yuan Meng","DNG: Taxonomy Expansion by Exploring the Intrinsic Directed Structure on
  Non-gaussian Space","7figures",,,,"cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Taxonomy expansion is the process of incorporating a large number of
additional nodes (i.e., ""queries"") into an existing taxonomy (i.e., ""seed""),
with the most important step being the selection of appropriate positions for
each query. Enormous efforts have been made by exploring the seed's structure.
However, existing approaches are deficient in their mining of structural
information in two ways: poor modeling of the hierarchical semantics and
failure to capture directionality of is-a relation. This paper seeks to address
these issues by explicitly denoting each node as the combination of inherited
feature (i.e., structural part) and incremental feature (i.e., supplementary
part). Specifically, the inherited feature originates from ""parent"" nodes and
is weighted by an inheritance factor. With this node representation, the
hierarchy of semantics in taxonomies (i.e., the inheritance and accumulation of
features from ""parent"" to ""child"") could be embodied. Additionally, based on
this representation, the directionality of is-a relation could be easily
translated into the irreversible inheritance of features. Inspired by the
Darmois-Skitovich Theorem, we implement this irreversibility by a non-Gaussian
constraint on the supplementary feature. A log-likelihood learning objective is
further utilized to optimize the proposed model (dubbed DNG), whereby the
required non-Gaussianity is also theoretically ensured. Extensive experimental
results on two real-world datasets verify the superiority of DNG relative to
several strong baselines.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:15:02 GMT""},{""version"":""v2"",""created"":""Tue, 21 Mar 2023 13:28:02 GMT""}]","2023-03-22"
"2302.11166","Yucheng Zhang","Yucheng Zhang, Anthony R. Pullen, Rachel S. Somerville, Patrick C.
  Breysse, John C. Forbes, Shengqi Yang, Yin Li, Abhishek S. Maniyar","Characterizing the Conditional Galaxy Property Distribution using
  Gaussian Mixture Models","17 pages, 10 figures",,,,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  Line-intensity mapping (LIM) is a promising technique to constrain the global
distribution of galaxy properties. To combine LIM experiments probing different
tracers with traditional galaxy surveys and fully exploit the scientific
potential of these observations, it is necessary to have a physically motivated
modeling framework. As part of developing such a framework, in this work we
introduce and model the conditional galaxy property distribution (CGPD), i.e.
the distribution of galaxy properties conditioned on the host halo mass and
redshift. We consider five galaxy properties, including the galaxy stellar
mass, molecular gas mass, galaxy radius, gas phase metallicity and star
formation rate (SFR), which are important for predicting the emission lines of
interest. The CGPD represents the full distribution of galaxies in the five
dimensional property space; many important galaxy distribution functions and
scaling relations, such as the stellar mass function and SFR main sequence, can
be derived from integrating and projecting it. We utilize two different kinds
of cosmological galaxy simulations, a semi-analytic model and the IllustrisTNG
hydrodynamic simulation, to characterize the CGPD and explore how well it can
be represented using a Gaussian mixture model (GMM). We find that with just a
few ($\sim 3$) Gaussian components, a GMM can describe the CGPD of the
simulated galaxies to high accuracy for both simulations. The CGPD can be
mapped to LIM or other observables by constructing the appropriate relationship
between galaxy properties and the relevant observable tracers.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:17:16 GMT""}]","2023-02-23"
"2302.11167","Victor Flambaum","V. V. Flambaum, I.B. Samsonov","Fluctuations of atomic energy levels due to axion and scalar fields",,,,,"hep-ph astro-ph.CO nucl-th physics.atom-ph","http://creativecommons.org/licenses/by/4.0/","  The amplitude of the axion or scalar field fluctuates on a time scale of
order of million field oscillation periods which is a typical coherence time in
the axion dark matter model. This causes fluctuations of frequencies of atomic
clocks on the same time scale. We show that this effect may be employed to
search for the axion and scalar field dark matter with atomic and nuclear
clocks. We re-purpose the results of the atomic clocks experiments comparing
the variations of frequencies of hyperfine transitions in Rb and Cs atoms as
well as in hydrogen atom vs cavity frequency fluctuations, and extract new
limits on the axion coupling constant $f_a$ for masses in the range $5\times
10^{-17}\text{ eV}\lesssim m \lesssim 9\times 10^{-12}\text{ eV}$. We also show
that similar energy shifts arise in the second-order perturbation theory with
linear in the pseudoscalar field interaction. These shifts may be potentially
measured with nuclear clocks based on the low-energy transition in $^{229}$Th
nucleus.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:18:13 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 22:14:08 GMT""},{""version"":""v3"",""created"":""Sat, 1 Apr 2023 04:20:55 GMT""}]","2023-04-04"
"2302.11168","Sarah Paetzke","Sarah Paetzke, Maik Boltes, Armin Seyfried","Influence of Gender Composition in Pedestrian Single-File Experiments",,,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  Various studies address the question of what factors are relevant to the
course of the fundamental diagram in single-file experiments. Some indicate
that there are differences due to group composition when gender is taken into
account. For this reason, further single-file experiments with homogeneous and
heterogeneous group compositions were conducted. A Tukey HSD test was performed
to investigate whether there are differences between the mean of velocity in
different density ranges. A comparison of different group compositions shows
that the effect of gender can only be seen, if at all, in a small density
interval. Regression analyses were also conducted to determine whether, at high
densities, the distance between individuals depends on the gender of the
neighboring pedestrians and to establish what human factors have an effect on
the velocity. An analysis of the distances between individuals at high
densities indicates that there is no effect of the gender of the neighboring
pedestrians. Taking into account additional human factors in a regression
analysis does not improve the model.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:20:50 GMT""}]","2023-02-23"
"2302.11169","Tongcang Li","Sumukh Vaidya, Xingyu Gao, Saakshi Dikshit, Igor Aharonovich, Tongcang
  Li","Quantum sensing and imaging with spin defects in hexagonal boron nitride","review article, 21 pages, 13 figures","Advances in Physics: X, 8, 2206049 (2023)","10.1080/23746149.2023.2206049",,"quant-ph cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Color centers in hexagonal boron nitride (hBN) have recently emerged as
promising candidates for a new wave of quantum applications. Thanks to hBN's
high stability and 2-dimensional (2D) layered structure, color centers in hBN
can serve as robust quantum emitters that can be readily integrated into
nanophotonic and plasmonic structures on a chip. More importantly, the recently
discovered optically addressable spin defects in hBN provide a quantum
interface between photons and electron spins for quantum sensing applications.
The most well-studied hBN spin defects, the negatively charged boron vacancy
($V_B^-$) spin defects, have been used for quantum sensing of static magnetic
fields, magnetic noise, temperature, strain, nuclear spins, paramagnetic spins
in liquids, RF signals, and beyond. In particular, hBN nanosheets with spin
defects can form van der Waals (vdW) heterostructures with 2D magnetic or other
materials for in situ quantum sensing and imaging. This review summarizes the
rapidly evolving field of nanoscale and microscale quantum sensing with spin
defects in hBN. We introduce basic properties of hBN spin defects, quantum
sensing protocols, and recent experimental demonstrations of quantum sensing
and imaging with hBN spin defects. We also discuss methods to enhance their
sensitivity. Finally, we envision some potential developments and applications
of hBN spin defects.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:21:28 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 21:44:02 GMT""}]","2023-05-02"
"2302.11170","Ya-Shu Wang","Chi-Kwong Li, Ming-Cheng Tsai, Ya-Shu Wang and Ngai-Ching Wong","Linear maps preserving matrices annihilated by a fixed polynomial",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let ${\bf M}_n(\mathbb{F})$ be the algebra of $n\times n$ matrices over an
arbitrary field $\mathbb{F}$. We consider linear maps $\Phi: {\bf
M}_n(\mathbb{F}) \rightarrow {\bf M}_r(\mathbb{F})$ preserving matrices
annihilated by a fixed polynomial $f(x) = (x-a_1)\cdots (x-a_m)$ with $m\ge 2$
distinct zeroes $a_1, a_2, \ldots, a_m \in \mathbb{F}$; namely, $$ f(\Phi(A)) =
0\quad\text{whenever} \quad f(A) = 0. $$
  Suppose that $f(0)=0$, and the zero set $Z(f) =\{a_1, \dots, a_m\}$ is not an
additive group. Then $\Phi$ assumes the form \begin{align}\label{eq:standard} A
\mapsto S\begin{pmatrix} A \otimes D_1 &&\cr & A^{T} \otimes D_2& \cr &&
0_s\cr\end{pmatrix}S^{-1}, \tag{$\dagger$} \end{align} for some invertible
matrix $S\in {\bf M}_r(\mathbb{F})$, invertible diagonal matrices $D_1\in {\bf
M}_p(\mathbb{F})$ and $D_2\in {\bf M}_q(\mathbb{F})$, where
  $s=r-np-nq\geq 0$. The diagonal entries $\lambda$ in $D_1$ and $D_2$, as well
as $0$ in the zero matrix $0_s$, are zero multipliers of $f(x)$ in the sense
that $\lambda Z(f) \subseteq Z(f)$.
  In general, assume that $Z(f) - a_1$ is not an additive group. If $\Phi(I_n)$
commutes with $\Phi(A)$ for all $A\in {\bf M}_n(\mathbb{F})$, or if $f(x)$ has
a unique zero multiplier $\lambda=1$,
  then $\Phi$ assumes the form \eqref{eq:standard}.
  The above assertions follow from the special case when $f(x) = x(x-1)=x^2-x$,
for which the problem reduces to the study of linear idempotent preservers.
  It is shown that a linear map $\Phi: {\bf M}_n(\mathbb{F}) \rightarrow {\bf
M}_r(\mathbb{F})$ sending disjoint rank one idempotents to disjoint idempotents
always assume the above form \eqref{eq:standard} with $D_1=I_p$ and $D_2=I_q$,
unless ${\bf M}_n(\mathbb{F}) = {\bf M}_2(\mathbb{Z}_2)$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:28:56 GMT""}]","2023-02-23"
"2302.11171","Peijie Jiao","Peijie Jiao, Hao Cheng, Jiayi Li, Hongying Chen, Zhiyu Liu, Zhongnan
  Xi, Wenjuan Ding, Xingyue Ma, Jian Wang, Ningchong Zheng, Yuefeng Nie, Yu
  Deng, Laurent Bellaiche, Yurong Yang, Di Wu","Flexoelectricity-stabilized ferroelectric phase with enhanced
  reliability in ultrathin La:HfO2 films",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Doped HfO2 thin films exhibit robust ferroelectric properties even for
nanometric thicknesses, are compatible with current Si technology and thus have
great potential for the revival of integrated ferroelectrics. Phase control and
reliability are core issues for their applications. Here we show that, in
(111)-oriented 5%La:HfO2 (HLO) epitaxial thin films deposited on
(La0.3Sr0.7)(Al0.65Ta0.35)O3 substrates, the flexoelectric effect, arising from
the strain gradient along the films normal, induces a rhombohedral distortion
in the otherwise Pca21 orthorhombic structure. Density functional calculations
reveal that the distorted structure is indeed more stable than the pure Pca21
structure, when applying an electric field mimicking the flexoelectric field.
This rhombohedral distortion greatly improves the fatigue endurance of HLO thin
films by further stabilizing the metastable ferroelectric phase against the
transition to the thermodynamically stable non-polar monoclinic phase during
repetitive cycling. Our results demonstrate that the flexoelectric effect,
though negligibly weak in bulk, is crucial to optimize the structure and
properties of doped HfO2 thin films with nanometric thicknesses for integrated
ferroelectric applications.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:38:33 GMT""}]","2023-02-23"
"2302.11172","Tanvir Rahman","Ahmad Al Asad, Kazi Nishat Anwar, Ilhum Zia Chowdhury, Akif Azam,
  Tarif Ashraf, Tanvir Rahman","Impact of a Batter in ODI Cricket Implementing Regression Models from
  Match Commentary",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Cricket, ""a Gentleman's Game"", is a prominent sport rising worldwide. Due to
the rising competitiveness of the sport, players and team management have
become more professional with their approach. Prior studies predicted
individual performance or chose the best team but did not highlight the
batter's potential. On the other hand, our research aims to evaluate a player's
impact while considering his control in various circumstances. This paper seeks
to understand the conundrum behind this impactful performance by determining
how much control a player has over the circumstances and generating the
""Effective Runs"",a new measure we propose. We first gathered the fundamental
cricket data from open-source datasets; however, variables like pitch, weather,
and control were not readily available for all matches. As a result, we
compiled our corpus data by analyzing the commentary of the match summaries.
This gave us an insight into the particular game's weather and pitch
conditions. Furthermore, ball-by-ball inspection from the commentary led us to
determine the control of the shots played by the batter. We collected data for
the entire One Day International career, up to February 2022, of 3 prominent
cricket players: Rohit G Sharma, David A Warner, and Kane S Williamson. Lastly,
to prepare the dataset, we encoded, scaled, and split the dataset to train and
test Machine Learning Algorithms. We used Multiple Linear Regression (MLR),
Polynomial Regression, Support Vector Regression (SVR), Decision Tree
Regression, and Random Forest Regression on each player's data individually to
train them and predict the Impact the player will have on the game. Multiple
Linear Regression and Random Forest give the best predictions accuracy of 90.16
percent and 87.12 percent, respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:42:20 GMT""}]","2023-02-23"
"2302.11173","Yingzhi Xia","Yingzhi Xia, Qifeng Liao, Jinglai Li","VI-DGP: A variational inference method with deep generative prior for
  solving high-dimensional inverse problems",,,,,"math.NA cs.NA physics.comp-ph stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solving high-dimensional Bayesian inverse problems (BIPs) with the
variational inference (VI) method is promising but still challenging. The main
difficulties arise from two aspects. First, VI methods approximate the
posterior distribution using a simple and analytic variational distribution,
which makes it difficult to estimate complex spatially-varying parameters in
practice. Second, VI methods typically rely on gradient-based optimization,
which can be computationally expensive or intractable when applied to BIPs
involving partial differential equations (PDEs). To address these challenges,
we propose a novel approximation method for estimating the high-dimensional
posterior distribution. This approach leverages a deep generative model to
learn a prior model capable of generating spatially-varying parameters. This
enables posterior approximation over the latent variable instead of the complex
parameters, thus improving estimation accuracy. Moreover, to accelerate
gradient computation, we employ a differentiable physics-constrained surrogate
model to replace the adjoint method. The proposed method can be fully
implemented in an automatic differentiation manner. Numerical examples
demonstrate two types of log-permeability estimation for flow in heterogeneous
media. The results show the validity, accuracy, and high efficiency of the
proposed method.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:48:10 GMT""}]","2023-02-23"
"2302.11174","Junwen Yao","Junwen Yao, N. Benjamin Erichson, Miles E. Lopes","Error Estimation for Random Fourier Features","Accepted to AISTATS 2023",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random Fourier Features (RFF) is among the most popular and broadly
applicable approaches for scaling up kernel methods. In essence, RFF allows the
user to avoid costly computations on a large kernel matrix via a fast
randomized approximation. However, a pervasive difficulty in applying RFF is
that the user does not know the actual error of the approximation, or how this
error will propagate into downstream learning tasks. Up to now, the RFF
literature has primarily dealt with these uncertainties using theoretical error
bounds, but from a user's standpoint, such results are typically impractical --
either because they are highly conservative or involve unknown quantities. To
tackle these general issues in a data-driven way, this paper develops a
bootstrap approach to numerically estimate the errors of RFF approximations.
Three key advantages of this approach are: (1) The error estimates are specific
to the problem at hand, avoiding the pessimism of worst-case bounds. (2) The
approach is flexible with respect to different uses of RFF, and can even
estimate errors in downstream learning tasks. (3) The approach enables adaptive
computation, so that the user can quickly inspect the error of a rough initial
kernel approximation and then predict how much extra work is needed. Lastly, in
exchange for all of these benefits, the error estimates can be obtained at a
modest computational cost.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:54:27 GMT""}]","2023-02-23"
"2302.11175","Yuta Taniguchi","Yuta Taniguchi","Twisted Alexander matrices of quandles associated with a certain
  Alexander pair","20 pages",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ishii and Oshiro introduced the notion of an $f$-twisted Alexander matrix,
which is a quandle version of a twisted Alexander matrix and defined an
invariant of finitely presented quandles. In this paper, we study $f$-twisted
Alexander matrices of certain quandles with the Alexander pair obtained from a
quandle 2-cocycle. We show that the 0-th elementary ideal of $f$-twisted
Alexander matrix of the knot quandle of a surface knot with the Alexander pair
obtained from a quandle 2-cocycle can be described with the
Carter-Saito-Satoh's invariant. We also discuss a relationship between
$f$-twisted Alexander matrices of connected quandles with the Alexander pair
obtained from a quandle 2-cocycle and quandle homology groups.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 06:59:15 GMT""}]","2023-02-23"
"2302.11176","Valery Pipin","V.V. Pipin","Spatio-temporal non-localities in a solar-like mean-field dynamo","10 pages, 8 Figures, published in MNRAS",,"10.1093/mnras/stad1150",,"astro-ph.SR physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The scale separation approximation, which is in the base of the solar mean
field dynamo models, can be hardly justified both by observations and
theoretical applications to astrophysical dynamos.{ The general expression for
the mean turbulent electromotive force can be written in integral form with
convolution of the turbulent effects and mean magnetic field variations over
scales of the turbulent flows and global scales of the mean field dynamo.
Following results of DNS, which had been reported earlier, we take the
Lorentzian form of the integral convolution kernels as an experimental fact.
}It allows us to approximate the governing equation for the mean electromotive
force by the reaction--diffusion type equation. Solution of the eigenvalue
problem reveals a few curious properties of the dynamo model with the nonlocal
mean electromotive force. We find a decrease of the critical dynamo instability
threshold, and an increase the dynamo periods of the unstable modes, as
reported in earlier studies. Simultaneously, the nonlocal model shows
substantially lower growth rate of the unstable dynamo modes in proximity of
the critical threshold than the model which employ the scale separation
approximation. We verify these findings using the nonlinear solar dynamo model.
For the supercritical regime, when the $\alpha$ effect magnitude is about twice
of the instability threshold, the model shows the Parker's dynamo wave
solutions with the wave propagating from the mid latitude at the bottom of the
convection zone toward the solar equator at the surface. In the weakly
nonlinear regime, when the $\alpha$ effect magnitude is near the instability
threshold, the interference of the dynamo modes of different spatial
localization shows the Grand activity cycles of a period about 300 years.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:02:27 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 03:05:50 GMT""}]","2023-05-17"
"2302.11177","Wei-Hua Li","Wei-Hua Li, Jhen-Dong Lin, Ping-Yuan Lo, Guan-Hao Peng, Ching-Yu Hei,
  Shao-Yu Chen, Shun-Jen Cheng","The key role of non-local screening in the environment-insensitive
  exciton fine structures of transition-metal dichalcogenide monolayers","29 pages, 4 figures",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  In this work, we present a comprehensive theoretical and computational
investigation of exciton fine structures of WSe$_2$-monolayers, one of the best
known two-dimensional (2D) transition-metal dichalcogenides (TMD's), in various
dielectric-layer environments by solving the first-principles-based
Bethe-Salpeter equation. While the physical and electronic properties of
atomically thin nano-materials are normally sensitive to the variation of
surrounding environment, our studies reveal that the influence of dielectric
environment on the exciton fine structures of TMD-ML's is surprisingly limited.
We point out that the non-locality of Coulomb screening plays a key role to
suppress the factor of dielectric environment and drastically shrink the fine
structure splittings between bright exciton (BX) states and various dark
exciton (DX) states of TMD-ML's. The intriguing non-locality of screening in 2D
materials can be manifested by the measurable {\it non-linear} correlation
between the BX-DX splittings and exciton binding energies with varying the
surrounding dielectric environments. The revealed environment-insensitive
exciton fine structures of TMD-ML's suggest the robustness of prospective
dark-exciton-based opto-electronics against the inevitable variation of
inhomogeneous dielectric environment.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:03:46 GMT""}]","2023-02-23"
"2302.11178","Seyed Majid Zahedi","Maizi Liao, Wojciech Golab, Seyed Majid Zahedi","IRS: An Incentive-compatible Reward Scheme for Algorand","This work has been accepted for publication in AAMAS'23",,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  Founded in 2017, Algorand is one of the world's first carbon-negative, public
blockchains inspired by proof of stake. Algorand uses a Byzantine agreement
protocol to add new blocks to the blockchain. The protocol can tolerate
malicious users as long as a supermajority of the stake is controlled by
non-malicious users. The protocol achieves about 100x more throughput compared
to Bitcoin and can be easily scaled to millions of nodes. Despite its
impressive features, Algorand lacks a reward-distribution scheme that can
effectively incentivize nodes to participate in the protocol. In this work, we
study the incentive issue in Algorand through the lens of game theory. We model
the Algorand protocol as a Bayesian game and propose a novel reward scheme to
address the incentive issue in Algorand. We derive necessary conditions to
ensure that participation in the protocol is a Bayesian Nash equilibrium under
our proposed reward scheme even in the presence of a malicious adversary. We
also present quantitative analysis of our proposed reward scheme by applying it
to two real-world deployment scenarios. We estimate the costs of running an
Algorand node and simulate the protocol to measure the overheads in terms of
computation, storage, and networking.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:19:18 GMT""}]","2023-02-23"
"2302.11179","Haoran Yin","Haoran Yin, Jiaojiao Xiong, Yu Zhou, Chi Zhang, Di Zhang, Xizhang Wei,
  Yanqun Tang","Cyclic Delay-Doppler Shift: A Simple Transmit Diversity Technique for
  Delay-Doppler Waveforms in Doubly Selective Channels",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Delay-Doppler waveform design has been considered as a promising solution to
achieve reliable communication under high-mobility channels for the
space-air-ground-integrated networks (SAGIN). In this paper, we introduce the
cyclic delay-Doppler shift (CDDS) technique for delay-Doppler waveforms to
extract transmit diversity in doubly selective channels. Two simple CDDS
schemes, named time-domain CDDS (TD-CDDS) and modulation-domain CDDS (MD-CDDS),
are proposed in the setting of multiple-input multiple-output (MIMO). We
demonstrate the applications of CDDS on two representative delay-Doppler
waveforms, namely orthogonal time frequency space (OTFS) and affine frequency
division multiplexing (AFDM), by deriving their corresponding CDDS matrices.
Furthermore, we prove theoretically and experimentally that CDDS can provide
OTFS and AFDM with full transmit diversity gain on most occasions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:19:30 GMT""}]","2023-02-23"
"2302.11180","Minghai Qin","Minghai Qin, Chao Sun, Jaco Hofmann, Dejan Vucinic","DISCO: Distributed Inference with Sparse Communications",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Deep neural networks (DNNs) have great potential to solve many real-world
problems, but they usually require an extensive amount of computation and
memory. It is of great difficulty to deploy a large DNN model to a single
resource-limited device with small memory capacity. Distributed computing is a
common approach to reduce single-node memory consumption and to accelerate the
inference of DNN models. In this paper, we explore the ""within-layer model
parallelism"", which distributes the inference of each layer into multiple
nodes. In this way, the memory requirement can be distributed to many nodes,
making it possible to use several edge devices to infer a large DNN model. Due
to the dependency within each layer, data communications between nodes during
this parallel inference can be a bottleneck when the communication bandwidth is
limited. We propose a framework to train DNN models for Distributed Inference
with Sparse Communications (DISCO). We convert the problem of selecting which
subset of data to transmit between nodes into a model optimization problem, and
derive models with both computation and communication reduction when each layer
is inferred on multiple nodes. We show the benefit of the DISCO framework on a
variety of CV tasks such as image classification, object detection, semantic
segmentation, and image super resolution. The corresponding models include
important DNN building blocks such as convolutions and transformers. For
example, each layer of a ResNet-50 model can be distributively inferred across
two nodes with five times less data communications, almost half overall
computations and half memory requirement for a single node, and achieve
comparable accuracy to the original ResNet-50 model. This also results in 4.7
times overall inference speedup.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:20:34 GMT""}]","2023-02-23"
"2302.11181","Katsuhisa Ouchi","Katsuhisa Ouchi and Hiroyuki Masuyama","A Subgeometric Convergence Formula for Total-variation Error of the
  Level-increment Truncation Approximation of M/G/1-type Markov Chains","20 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the level-increment (LI) truncation approximation of
M/G/1-type Markov chains. The LI truncation approximation is usually used to
implement Ramaswami's recursion for the stationary distribution in M/G/1-type
Markov chains. The main result of this paper is a subgeometric convergence
formula for the total-variation distance between the stationary distribution
and its LI truncation approximation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:20:58 GMT""}]","2023-02-23"
"2302.11182","Pierre Perrault","Pierre Perrault","When Combinatorial Thompson Sampling meets Approximation Regret","Neurips 2022",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the Combinatorial Thompson Sampling policy (CTS) for combinatorial
multi-armed bandit problems (CMAB), within an approximation regret setting.
Although CTS has attracted a lot of interest, it has a drawback that other
usual CMAB policies do not have when considering non-exact oracles: for some
oracles, CTS has a poor approximation regret (scaling linearly with the time
horizon $T$) [Wang and Chen, 2018]. A study is then necessary to discriminate
the oracles on which CTS could learn. This study was started by Kong et al.
[2021]: they gave the first approximation regret analysis of CTS for the greedy
oracle, obtaining an upper bound of order $\mathcal{O}(\log(T)/\Delta^2)$,
where $\Delta$ is some minimal reward gap. In this paper, our objective is to
push this study further than the simple case of the greedy oracle. We provide
the first $\mathcal{O}(\log(T)/\Delta)$ approximation regret upper bound for
CTS, obtained under a specific condition on the approximation oracle, allowing
a reduction to the exact oracle analysis. We thus term this condition
REDUCE2EXACT, and observe that it is satisfied in many concrete examples.
Moreover, it can be extended to the probabilistically triggered arms setting,
thus capturing even more problems, such as online influence maximization.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:27:59 GMT""}]","2023-02-23"
"2302.11183","Junichiro Kawamura","Yoshihiko Abe, Tetsutaro Higaki, Junichiro Kawamura and Tatsuo
  Kobayashi","Quark and lepton hierarchies from $S_4^\prime$ modular flavor symmetry","15 pages, 3 tables",,,"CTPU-PTC-23-04, EPHOU-23-006","hep-ph","http://creativecommons.org/licenses/by/4.0/","  We propose models in which the hierarchical structures of the masses and
mixing in both quark and lepton sectors are explained by the $S_4^\prime$
modular flavor symmetry near the fixed point $\tau \sim i\infty$. The model
provides the first explicit example which explains hierarchies of both quarks
and leptons. The hierarchies are realized by powers of $\epsilon = e^{2\pi i
\tau/4} = \mathcal{O}(0.01)$ and $2\,\mathrm{Im}\,\tau \sim 5$, where $\tau$
being the modulus. The small parameter $\epsilon$ plays a role of flavon in the
Froggatt-Nielsen mechanism under the residual $Z_4^T$ symmetry, and powers of
$2\,\mathrm{Im}\,\tau$ in the Yukawa couplings are controlled by modular
weights via the canonical normalization. The doublet quarks are identified to a
$S_4^\prime$ triplet to explain the hierarchical structure of the quark mixing
angles, while the doublet leptons are composed of three singlets for the large
mixing angles in the lepton sector. We show that the $S_4^\prime$ modular
symmetry alone can explain the hierarchies in both quark and lepton sectors by
$\mathcal{O}(1)$ coefficients.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:33:59 GMT""}]","2023-02-23"
"2302.11184","Jin Zhu","Jin Zhu, Guang Yang and Pietro Lio","A residual dense vision transformer for medical image super-resolution
  with segmentation-based perceptual loss fine-tuning","Preprint submitted to Medical Image Analysis and under review",,,,"eess.IV cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Super-resolution plays an essential role in medical imaging because it
provides an alternative way to achieve high spatial resolutions and image
quality with no extra acquisition costs. In the past few decades, the rapid
development of deep neural networks has promoted super-resolution performance
with novel network architectures, loss functions and evaluation metrics.
Specifically, vision transformers dominate a broad range of computer vision
tasks, but challenges still exist when applying them to low-level medical image
processing tasks. This paper proposes an efficient vision transformer with
residual dense connections and local feature fusion to achieve efficient
single-image super-resolution (SISR) of medical modalities. Moreover, we
implement a general-purpose perceptual loss with manual control for image
quality improvements of desired aspects by incorporating prior knowledge of
medical image segmentation. Compared with state-of-the-art methods on four
public medical image datasets, the proposed method achieves the best PSNR
scores of 6 modalities among seven modalities. It leads to an average
improvement of $+0.09$ dB PSNR with only 38\% parameters of SwinIR. On the
other hand, the segmentation-based perceptual loss increases $+0.14$ dB PSNR on
average for SOTA methods, including CNNs and vision transformers. Additionally,
we conduct comprehensive ablation studies to discuss potential factors for the
superior performance of vision transformers over CNNs and the impacts of
network and loss function components. The code will be released on GitHub with
the paper published.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:39:09 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 06:51:27 GMT""}]","2023-03-06"
"2302.11185","Hristo Djidjev","Hristo N. Djidjev","Quantum annealing with inequality constraints: the set cover problem","22 pages, 3 figures",,,,"quant-ph cs.ET","http://creativecommons.org/licenses/by/4.0/","  This paper presents two novel approaches for solving the set cover problem
(SCP) with multiple inequality constraints on quantum annealers. The first
method uses the augmented Lagrangian approach to represent the constraints,
while the second method employs a higher-order binary optimization (HUBO)
formulation. Our experimental analysis demonstrate that both approaches
outperform the standard approach with slack variables for solving problems with
inequality constraints on D-Wave quantum annealers. The results show that the
augmented Lagrangian method can be successfully used to implement a large
number of inequality constraints, making it applicable to a wide range of
constrained problems beyond the SCP. The HUBO formulation performs slightly
better than the augmented Lagrangian method in solving the SCP, but it is less
scalable in terms of embeddability in the quantum chip. These findings could
impact the use of quantum annealers for solving constrained optimization
problems.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:39:51 GMT""}]","2023-02-23"
"2302.11186","Chao Zhang","Chao Zhang, Bo Li, Tara N. Sainath, Trevor Strohman, Shuo-yiin Chang","UML: A Universal Monolingual Output Layer for Multilingual ASR","Published as a conference paper at ICASSP 2023",,,,"eess.AS cs.CL cs.SD","http://creativecommons.org/licenses/by/4.0/","  Word-piece models (WPMs) are commonly used subword units in state-of-the-art
end-to-end automatic speech recognition (ASR) systems. For multilingual ASR,
due to the differences in written scripts across languages, multilingual WPMs
bring the challenges of having overly large output layers and scaling to more
languages. In this work, we propose a universal monolingual output layer (UML)
to address such problems. Instead of one output node for only one WPM, UML
re-associates each output node with multiple WPMs, one for each language, and
results in a smaller monolingual output layer shared across languages.
Consequently, the UML enables to switch in the interpretation of each output
node depending on the language of the input speech. Experimental results on an
11-language voice search task demonstrated the feasibility of using UML for
high-quality and high-efficiency multilingual streaming ASR.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:40:01 GMT""}]","2023-02-23"
"2302.11187","Jiwoon Lee","Jiwoon Lee, Jaeho Lee","Debiased Distillation by Transplanting the Last Layer",,,,,"cs.LG cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep models are susceptible to learning spurious correlations, even during
the post-processing. We take a closer look at the knowledge distillation -- a
popular post-processing technique for model compression -- and find that
distilling with biased training data gives rise to a biased student, even when
the teacher is debiased. To address this issue, we propose a simple knowledge
distillation algorithm, coined DeTT (Debiasing by Teacher Transplanting).
Inspired by a recent observation that the last neural net layer plays an
overwhelmingly important role in debiasing, DeTT directly transplants the
teacher's last layer to the student. Remaining layers are distilled by matching
the feature map outputs of the student and the teacher, where the samples are
reweighted to mitigate the dataset bias. Importantly, DeTT does not rely on the
availability of extensive annotations on the bias-related attribute, which is
typically not available during the post-processing phase. Throughout our
experiments, DeTT successfully debiases the student model, consistently
outperforming the baselines in terms of the worst-group accuracy.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:41:09 GMT""}]","2023-02-23"
"2302.11188","Yao Qin","Yao Qin, Xuezhi Wang, Balaji Lakshminarayanan, Ed H. Chi and Alex
  Beutel","What Are Effective Labels for Augmented Data? Improving Calibration and
  Robustness with AutoLabel","Accepted to SaTML-2023",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A wide breadth of research has devised data augmentation approaches that can
improve both accuracy and generalization performance for neural networks.
However, augmented data can end up being far from the clean training data and
what is the appropriate label is less clear. Despite this, most existing work
simply uses one-hot labels for augmented data. In this paper, we show re-using
one-hot labels for highly distorted data might run the risk of adding noise and
degrading accuracy and calibration. To mitigate this, we propose a generic
method AutoLabel to automatically learn the confidence in the labels for
augmented data, based on the transformation distance between the clean
distribution and augmented distribution. AutoLabel is built on label smoothing
and is guided by the calibration-performance over a hold-out validation set. We
successfully apply AutoLabel to three different data augmentation techniques:
the state-of-the-art RandAug, AugMix, and adversarial training. Experiments on
CIFAR-10, CIFAR-100 and ImageNet show that AutoLabel significantly improves
existing data augmentation techniques over models' calibration and accuracy,
especially under distributional shift.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:44:17 GMT""}]","2023-02-23"
"2302.11189","Xiangdong Zhang","Yongbin Du and Xiangdong Zhang","Topological classes of BTZ black holes","10 pages and 5 figures; v2, references updated",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  In the recent paper [Phys. Rev. Lett. 129, 191101 (2022)], the black holes
were viewed as topological thermodynamic defects by using the generalized
off-shell free energy. Their work indicates that all black hole solutions in
the pure Einstein-Maxwell gravity theory could be classified into three
different topological classes for four and higher spacetime dimensions. In this
paper, we investigate the topological number of BTZ black holes with different
charges $(Q)$ and rotational $(J)$ parameters. By using generalized free energy
and Duan's $\phi$-mapping topological current theory, we interestingly found
only two topological classes for BTZ spacetime. Particularly, for $Q=J=0$ BTZ
black hole, there has only one zero point and therefore the total topological
number is 1. While for rotating or charged cases, there are always two zero
points and the global topological number is zero.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:52:21 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 03:59:05 GMT""}]","2023-02-24"
"2302.11190","Donghao Ying","Ali Yekkehkhany, Han Feng, Donghao Ying, Javad Lavaei","A Hitting Time Analysis for Stochastic Time-Varying Functions with
  Applications to Adversarial Attacks on Computation of Markov Decision
  Processes",,,,,"math.OC","http://creativecommons.org/publicdomain/zero/1.0/","  Stochastic time-varying optimization is an integral part of learning in which
the shape of the function changes over time in a non-deterministic manner. This
paper considers multiple models of stochastic time variation and analyzes the
corresponding notion of hitting time for each model, i.e., the period after
which optimizing the stochastic time-varying function reveals informative
statistics on the optimization of the target function. The studied models of
time variation are motivated by adversarial attacks on the computation of value
iteration in Markov decision processes. In this application, the hitting time
quantifies the extent that the computation is robust to adversarial
disturbance. We develop upper bounds on the hitting time by analyzing the
contraction-expansion transformation appeared in the time-variation models. We
prove that the hitting time of the value function in the value iteration with a
probabilistic contraction-expansion transformation is logarithmic in terms of
the inverse of a desired precision. In addition, the hitting time is analyzed
for optimization of unknown continuous or discrete time-varying functions whose
noisy evaluations are revealed over time. The upper bound for a continuous
function is super-quadratic (but sub-cubic) in terms of the inverse of a
desired precision and the upper bound for a discrete function is logarithmic in
terms of the cardinality of the function domain. Improved bounds for convex
functions are obtained and we show that such functions are learned faster than
non-convex functions. Finally, we study a time-varying linear model with
additive noise, where hitting time is bounded with the notion of shape
dominance.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:54:28 GMT""}]","2023-02-23"
"2302.11191","Federico Milano","Georgios Tzounas, Federico Milano","On the Emulation of Synchronous Machine Dynamics by Converter-Interfaced
  Generators",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This paper discusses the conditions that a device needs to satisfy to
replicate the behavior of a conventional synchronous machine (SM) connected to
a power network. The conditions pertain to the device's stored energy, time
scale of response, oscillation damping, and behavior during short-circuits.
Relevant remarks for devices that do/don't satisfy these conditions are
discussed through an illustrative numerical example as well as through
simulation results based on a modified version of the well-known WSCC 9-bus
test system.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:55:26 GMT""}]","2023-02-23"
"2302.11192","Xiaoq Wa","Xiaoqiang Wang, Yanqing Liu, Jinyu Li, Sheng Zhao","Improving Contextual Spelling Correction by External Acoustics Attention
  and Semantic Aware Data Augmentation","Accepted by ICASSP 2023",,,,"cs.SD cs.CL cs.LG eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We previously proposed contextual spelling correction (CSC) to correct the
output of end-to-end (E2E) automatic speech recognition (ASR) models with
contextual information such as name, place, etc. Although CSC has achieved
reasonable improvement in the biasing problem, there are still two drawbacks
for further accuracy improvement. First, due to information limitation in text
only hypothesis or weak performance of ASR model on rare domains, the CSC model
may fail to correct phrases with similar pronunciation or anti-context cases
where all biasing phrases are not present in the utterance. Second, there is a
discrepancy between the training and inference of CSC. The bias list in
training is randomly selected but in inference there may be more similarity
between ground truth phrase and other phrases. To solve above limitations, in
this paper we propose an improved non-autoregressive (NAR) spelling correction
model for contextual biasing in E2E neural transducer-based ASR systems to
improve the previous CSC model from two perspectives: Firstly, we incorporate
acoustics information with an external attention as well as text hypotheses
into CSC to better distinguish target phrase from dissimilar or irrelevant
phrases. Secondly, we design a semantic aware data augmentation schema in
training phrase to reduce the mismatch between training and inference to
further boost the biasing accuracy. Experiments show that the improved method
outperforms the baseline ASR+Biasing system by as much as 20.3% relative name
recall gain and achieves stable improvement compared to the previous CSC method
over different bias list name coverage ratio.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:00:08 GMT""}]","2023-02-23"
"2302.11193","Andrzej Makowski","A. Makowski, M. C. Barton, P. Magierski, K. Sekizawa and G.
  Wlaz{\l}owski","Manifestation of pairing modes in nuclear collisions","2 figures, 56th Zakopane Conference On Nuclear Physics","Acta Phys. Pol. B Proc. Suppl. 16, 4-A38 (2023)","10.5506/APhysPolBSupp.16.4-A38",,"nucl-th","http://creativecommons.org/licenses/by/4.0/","  We discuss the possible manifestation of pairing dynamics in nuclear
collisions beyond the standard quasi-static treatment of pairing correlations.
These involve solitonic excitations induced by pairing phase difference of
colliding nuclei and pairing dynamic enhancement in the di-nuclear system
formed by merging nuclei.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:05:07 GMT""}]","2023-03-28"
"2302.11194","Diego Barberena","Diego Barberena, Robert J. Lewis-Swan, Ana Maria Rey, James K.
  Thompson","Ultra Narrow Linewidth Frequency Reference via Measurement and Feedback","11 pages, 3 figures, 2 tables. Peer-reviewed, corrected following
  requests and accepted for publication in Comptes Rendus Physique
  https://comptes-rendus.academie-sciences.fr/physique",,,,"quant-ph physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The generation of very narrow linewidth light sources is of great importance
in modern science. One such source is the superradiant laser, which relies on
collectively interacting ultra long lived dipoles driven by incoherent light.
Here we discuss a different way of generating spectrally pure light by
coherently driving such dipoles inside an optical QED cavity. The light exiting
the cavity carries information about the detuning between the driving light and
the atomic transition, but is also affected by the noise originating from all
the decoherence processes that act on the combined atom-cavity system. We
calculate these effects to obtain fundamental limits for frequency estimation
and stabilization across a range of values of input light intensities and
atom-light interaction strengths, estimate these limits in state-of-the-art
cavity experiments with alkaline-earth atoms and identify favorable operating
conditions. We find that the achievable linewidths are comparable to those of
the superradiant laser.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:07:19 GMT""}]","2023-02-23"
"2302.11195","Yijia Wang","Chao Min, Yijia Wang, Huohai Yang and Wei Zhao","Prediction of single well production rate in water-flooding oil fields
  driven by the fusion of static, temporal and spatial information",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is very difficult to forecast the production rate of oil wells as the
output of a single well is sensitive to various uncertain factors, which
implicitly or explicitly show the influence of the static, temporal and spatial
properties on the oil well production. In this study, a novel machine learning
model is constructed to fuse the static geological information, dynamic well
production history, and spatial information of the adjacent water injection
wells. There are 3 basic modules in this stacking model, which are regarded as
the encoders to extract the features from different types of data. One is
Multi-Layer Perceptron, which is to analyze the static geological properties of
the reservoir that might influence the well production rate. The other two are
both LSTMs, which have the input in the form of two matrices rather than
vectors, standing for the temporal and the spatial information of the target
well. The difference of the two modules is that in the spatial information
processing module we take into consideration the time delay of water flooding
response, from the injection well to the target well. In addition, we use
Symbolic Transfer Entropy to prove the superiorities of the stacking model from
the perspective of Causality Discovery. It is proved theoretically and
practically that the presented model can make full use of the model structure
to integrate the characteristics of the data and the experts' knowledge into
the process of machine learning, greatly improving the accuracy and
generalization ability of prediction.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:10:25 GMT""}]","2023-02-23"
"2302.11196","Fatin Al-Obaidi","Fatin E. M. Al-Obaidi, Anwar H. Al-Saleh, Shaymaa H. Kafi, Ali
  J.Karam, Ali A. D. Al-Zuky","Invariant Target Detection in Images through the Normalized 2-D
  Correlation Technique",,,,,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The normalized 2-D correlation technique is a robust method for detecting
targets in images due to its ability to remain invariant under rotation,
translation, and scaling. This paper examines the impact of translation, and
scaling on target identification in images. The results indicate a high level
of accuracy in detecting targets, even when they are exhibit variations in
location and size. The results indicate that the similarity between the image
and the two used targets improves as the resize ratio increases. All
statistical estimators demonstrate a strong similarity between the original and
extracted targets. The elapsed time for all scenarios falls within the range
(44.75-44.85), (37.48-37.73) seconds for bird and children targets
respectively, and the correlation coefficient displays stable relationships
with values that fall within the range of (0.90-0.98) and (0.87-0.93) for bird
and children targets respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:13:34 GMT""}]","2023-02-23"
"2302.11197","Junren Chen","Junren Chen, Yueqi Wang, Michael K. Ng","Quantized Low-Rank Multivariate Regression with Random Dithering","14 pages, 5 figures. (Submitted)",,,,"stat.ML cs.LG eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-rank multivariate regression (LRMR) is an important statistical learning
model that combines highly correlated tasks as a multiresponse regression
problem with low-rank priori on the coefficient matrix. In this paper, we study
quantized LRMR, a practical setting where the responses and/or the covariates
are discretized to finite precision. We focus on the estimation of the
underlying coefficient matrix. To make consistent estimator that could achieve
arbitrarily small error possible, we employ uniform quantization with random
dithering, i.e., we add appropriate random noise to the data before
quantization. Specifically, uniform dither and triangular dither are used for
responses and covariates, respectively. Based on the quantized data, we propose
the constrained Lasso and regularized Lasso estimators, and derive the
non-asymptotic error bounds. With the aid of dithering, the estimators achieve
minimax optimal rate, while quantization only slightly worsens the
multiplicative factor in the error rate. Moreover, we extend our results to a
low-rank regression model with matrix responses. We corroborate and demonstrate
our theoretical results via simulations on synthetic data or image restoration.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:14:24 GMT""}]","2023-02-23"
"2302.11198","Xiaoming Kong","Tianmin Wu, Yude Bu, Jianhang Xie, Junchao Liang, Wei Liu, Zhenping
  Yi, Xiaoming Kong, and Meng Liu","Estimating Stellar Parameters and Identifying Very Metal-poor Stars
  Using Convolutional Neural Networks for Low-resolution Spectra (R~200)","13 pages, 9 figures",,,,"astro-ph.SR astro-ph.GA astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Very metal-poor (VMP, [Fe/H]<-2.0) stars offer a wealth of information on the
nature and evolution of elemental production in the early galaxy and universe.
The upcoming China Space Station Telescope (CSST) will provide us with a large
amount of spectroscopic data that may contain plenty of VMP stars, and thus it
is crucial to determine the stellar atmospheric parameters ($T_{eff}$, $\log
g$, and [Fe/H]) for low-resolution spectra similar to the CSST spectra (R~200).
In this paper, a two-dimensional Convolutional Neural Network (CNN) model with
three convolutional layers and two fully connected layers is constructed. The
principal aim of this work is to measure the ability of this model to estimate
stellar parameters on low-resolution (R~200) spectra and to identify VMP stars
so that we can better search for VMP stars in the spectra observed by CSST.We
mainly use 10,008 observed spectra of VMP stars from LAMOST DR3, and 16,638
spectra of common stars ([Fe/H]>-2.0) from LAMOST DR8 for the experiment and
make comparisons. All spectra are reduced to R~200 to match the resolution of
the CSST and are preprocessed and collapsed into two-dimensional spectra for
input to the CNN model. The results show that the MAE values are 99.40 K for
$T_{eff}$, 0.22 dex for $\log g$, 0.14 dex for [Fe/H], and 0.26 dex for [C/Fe],
respectively. Besides, the CNN model efficiently identifies VMP stars with a
precision of 94.77%. The validation and practicality of this model are also
tested on the MARCS synthetic spectra. This paper powerfully demonstrates the
effectiveness of the proposed CNN model in estimating stellar parameters for
low-resolution spectra (R~200) and recognizing VMP stars that are of interest
for stellar population and galactic evolution work.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:15:22 GMT""}]","2023-02-23"
"2302.11199","Thibault Cordier","Thibault Cordier and Tanguy Urvoy and Fabrice Lefevre and Lina M.
  Rojas-Barahona","Few-Shot Structured Policy Learning for Multi-Domain and Multi-Task
  Dialogues","8 pages, at the EACL2023 conference (Findings)",,,,"cs.CL","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Reinforcement learning has been widely adopted to model dialogue managers in
task-oriented dialogues. However, the user simulator provided by
state-of-the-art dialogue frameworks are only rough approximations of human
behaviour. The ability to learn from a small number of human interactions is
hence crucial, especially on multi-domain and multi-task environments where the
action space is large. We therefore propose to use structured policies to
improve sample efficiency when learning on these kinds of environments. We also
evaluate the impact of learning from human vs simulated experts. Among the
different levels of structure that we tested, the graph neural networks (GNNs)
show a remarkable superiority by reaching a success rate above 80% with only 50
dialogues, when learning from simulated experts. They also show superiority
when learning from human experts, although a performance drop was observed,
indicating a possible difficulty in capturing the variability of human
strategies. We therefore suggest to concentrate future research efforts on
bridging the gap between human data, simulators and automatic evaluators in
dialogue frameworks.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:18:49 GMT""}]","2023-02-23"
"2302.11200","Mahyar Bolhassani","Mahyar Bolhassani, Ilkay Oksuz","Semi-Supervised Segmentation of Multi-vendor and Multi-center Cardiac
  MRI using Histogram Matching","5 pages, 8 figures, IEEE conference published paper","IEEE Conference on Signal Processing and Communications
  applications (SIU 2021)",,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automatic segmentation of the heart cavity is an essential task for the
diagnosis of cardiac diseases. In this paper, we propose a semi-supervised
segmentation setup for leveraging unlabeled data to segment Left-ventricle,
Right-ventricle, and Myocardium. We utilize an enhanced version of residual
U-Net architecture on a large-scale cardiac MRI dataset. Handling the class
imbalanced data issue using dice loss, the enhanced supervised model is able to
achieve better dice scores in comparison with a vanilla U-Net model. We applied
several augmentation techniques including histogram matching to increase the
performance of our model in other domains. Also, we introduce a simple but
efficient semi-supervised segmentation method to improve segmentation results
without the need for large labeled data. Finally, we applied our method on two
benchmark datasets, STACOM2018, and M\&Ms 2020 challenges, to show the potency
of the proposed model. The effectiveness of our proposed model is demonstrated
by the quantitative results. The model achieves average dice scores of 0.921,
0.926, and 0.891 for Left-ventricle, Right-ventricle, and Myocardium
respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:23:19 GMT""}]","2023-02-23"
"2302.11201","Vadim Bednyakov Dr.","V. A. Bednyakov","Coherence in scattering of massive weakly interacting neutral particles
  off nuclei","50 pages, 10 figures, the text is English translation of Russian
  paper published in Physics of Particles and Nuclei, 2023, vol. 54, no. 2, pp.
  275--339",,"10.1134/S1063779623020028",,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  The paper presents a novel approach to the description of the nonrelativistic
weak interaction of a massive neutral particle (lepton) and a nucleus, in which
the latter retains its integrity. The cross section of such a process is a sum
of the elastic (or coherent) contribution, when the nucleus remains in its
original state, and the inelastic (incoherent) contribution, when the nucleus
is in an excited state. Smooth transition from elastic scattering to inelastic
scattering is governed by the dependence of the nuclear form factors on the
momentum transferred to the nucleus. The intensity of the weak interaction is
set by the parameters that determine the contributions to the probability
amplitude from the scalar products of the leptonic and nucleon currents. The
resulting expressions are of interest, at least in the problem of direct
detection of neutral massive weakly interacting particles of dark matter, since
in this case, in contrast to the generally accepted approach, both elastic and
inelastic processes are simultaneously considered. It is shown that the
presence of the inelastic contribution accompanied by emission of
characteristic radiation (photons) from the deexcitation of the nucleus turns
out to be decisive when the coherent cross section is strongly suppressed or
cannot be detected. Therefore in order to extract maximum information about
dark matter particles, one should plan experiments aimed at the direct
detection of dark matter particles in a setting that allows one to detect both
the recoil energy of the nucleus and the gamma quanta from the deexcitation of
the nucleus.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:26:02 GMT""}]","2023-05-10"
"2302.11202","Dali Zangurashvili","Dali Zangurashvili","On stable-projective and injective-costable decompositions of modules",,,,,"math.RA math.CT","http://creativecommons.org/licenses/by/4.0/","  It is proved that, for a left hereditary ring, an arbitrary left module has a
representation in the form of the direct sum of a stable left module and
indecomposable projective left modules (if and only if an arbitrary left module
has a representation in the form of the direct sum of a stable left module and
a projective left module) if and only if the ring is left perfect and right
coherent. In that case, the above-mentioned representations are unique up to
isomorphism; the latter representation is also functorial. The essential
ingredient in the proofs of the above-mentioned statements is a certain purely
categorical result. These statements, in particular, imply that, for any
principal ideal domain that is not a field, the fundamental theorem on finitely
generated modules over it can not be generalized to the case of all modules.
Moreover, with the aid of the above-mentioned categorical approach, we give a
new proof of the Zheng-Xu He's result asserting that any module of a ring has a
unique up to isomorphism injective-costable decomposition if and only if the
ring is left hereditary and left Noetherian. The above-mentioned statements, in
particular, imply that if the category of left modules over a left hereditary
ring is Krull-Schmidt, then the ring is left Artinian. Yet another criterion
for a ring to be left hereditary, left perfect and right coherent (resp. left
hereditary left Noetherian) found in the paper requires that the pair $(Stable$
$modules$, $Projective$ $modules)$ (resp. $(Injective$ $Modules, Costable$ $
Modules)$) of module classes be a pre-torsion theory. This implies that the
pair $(Stable$ $modules$, $Projective$ $modules)$ is a torsion theory if and
only if the ring is left hereditary and the injective envelope of the ring,
viewed as a left module over itself, is projective.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:30:14 GMT""}]","2023-02-23"
"2302.11203","Chao Yu","Chao Yu, Yifei Sun, Yan Luo and Rui Wang","mmAlert: mmWave Link Blockage Prediction via Passive Sensing",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this letter, the mmAlert system, predicting millimeter wave (mmWave) link
blockage during data communication, is elaborated and demonstrated. The passive
sensing method is adopted for mobile blocker detection, where two receive beams
with separated radio frequency (RF) chains are equipped at the data
communication receiver. One receive beam is aligned to the direction of
line-of-sight (LoS) path, and the other one periodically sweeps the region
close to the LoS path. By comparing the signals received by the above two
beams, the Doppler frequencies of the signal scattered from the mobile blocker
can be detected. Furthermore, by tracking the Doppler frequencies and the
angle-of-arrivals (AoAs) of the scattered signals, the trajectory of the mobile
blocker can be estimated, such that the potential link blockage can be
predicted by assuming consistent mobile velocity. It is demonstrated via
experiments that the mmAlert system can always detect the motions of the
walking person close to the LoS path, and predict 90\% of the LoS blockage with
sensing time of 1.4 seconds.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:31:57 GMT""}]","2023-02-23"
"2302.11204","Parth Mehta","Parth Mehta, Agulla Surya Bharath, Kumar Appaiah, Rajbabu Velmurugan,
  Debasattam Pal","Lattice All-Pass Filter based Precoder Adaptation for MIMO Wireless
  Channels",,,,,"eess.SP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Modern 5G communication systems employ multiple-input multiple-output (MIMO)
in conjunction with orthogonal frequency division multiplexing (OFDM) to
enhance data rates, particularly for wideband millimetre wave (mmW)
applications. Since these systems use a large number of subcarriers, feeding
back the estimated precoder for even a subset of subcarriers from the receiver
to the transmitter is prohibitive. Moreover, such frequency domain approaches
also do not exploit the predominant line-of-sight component that is present in
such channels to reduce feedback. In this work, we view the precoder in the
time domain as a matrix all-pass filter, and model the discrete-time precoder
filter using a matrix-lattice structure that aids in reducing the overall
feedback while still maintaining the desired frequency-phase delay profile.
This provides an efficient precoder representation across the subcarriers using
fewer coefficients, and is amenable to tracking over time with much lower
feedback than past approaches. Compared to frequency domain geodesic
interpolation, Givens rotation based parameterisation, and the angle-delay
domain approach that depends on approximate discrete-time representation, the
proposed approach yields higher achievable rates with a much lower feedback
burden. Via extensive simulations over mmW channel models, we confirm the
effectiveness of our claims, and show that the proposed approach can reduce the
feedback burden by up to 70%.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:36:11 GMT""},{""version"":""v2"",""created"":""Sat, 18 Mar 2023 04:38:34 GMT""}]","2023-03-21"
"2302.11205","Philipp G\""otz","Philipp G\""otz, Cagdas Tuna, Andreas Walther, Emanu\""el A. P. Habets","Contrastive Representation Learning for Acoustic Parameter Estimation","Accepted for ICASSP 2023, Camera-ready version",,,,"eess.AS cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A study is presented in which a contrastive learning approach is used to
extract low-dimensional representations of the acoustic environment from
single-channel, reverberant speech signals. Convolution of room impulse
responses (RIRs) with anechoic source signals is leveraged as a data
augmentation technique that offers considerable flexibility in the design of
the upstream task. We evaluate the embeddings across three different downstream
tasks, which include the regression of acoustic parameters reverberation time
RT60 and clarity index C50, and the classification into small and large rooms.
We demonstrate that the learned representations generalize well to unseen data
and perform similarly to a fully-supervised baseline.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:37:43 GMT""},{""version"":""v2"",""created"":""Mon, 13 Mar 2023 07:25:47 GMT""}]","2023-03-14"
"2302.11206","Raveen De Silva Mr.","L. Raveen S. De Silva","Critical analysis on efficiency and noise reduction methodologies of a
  switch mode power supply using LISN topology","This study focuses on the design of LISN model to reduce output noise
  from traditional SMPSs used with non-ideal components. A traditional DC/DC
  buck SMPS was employed, and filters were designed using LISN to suppress SMPS
  noise. Simulation results demonstrate that the designed filter significantly
  reduced SMPS output noise when compared to initial and final observations",,,,"eess.SY cs.SY eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This critical analysis offers a comprehensive overview of the efficiency and
noise reduction methodologies applied in switch mode power supplies (SMPSs) and
the emerging trends in the field. The study acknowledges that power supplies
are an essential element in most electronic devices, and the recent
developments have placed a greater emphasis on precision, miniaturization, and
effectiveness of these components. The research focuses on SMPSs in comparison
with other power supply methodologies and investigates the identification and
mitigation of internal and external noise in DC Buck converter design through
simulations. The study explores the latest and established technologies
employed in improving SMPSs' power supply units and achieving maximum
performance. The paper highlights the use of a Linear Impedance Stabilization
Network (LISN) topology and filter topologies to stabilize and eliminate noises
in non-ideal scenarios, starting from an ideal buck converter. The research
also emphasizes the design, analysis, and implementation of energy-efficient
switch mode isolated converters commonly used in everyday life. Therefore, the
study concludes that the integration of the LISN methodology in SMPSs design
can play a crucial role in achieving maximum performance and efficiency.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:40:15 GMT""}]","2023-02-23"
"2302.11207","Manish Kumar","Manish Kumar, Anisur Rahaman Molla, Sumathi Sivasubramaniam","Improved Deterministic Leader Election in Diameter-Two Networks","arXiv admin note: text overlap with arXiv:1809.00273 by other authors",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the leader election problem in diameter-two
networks. Recently, Chatterjee et al. [DC 2020] studied the leader election in
diameter-two networks. They presented a $O(\log n)$-round deterministic
{implicit} leader election algorithm which incurs optimal $O(n\log n)$
messages, but a drawback of their algorithm is that it requires knowledge of
$n$. An important question -- whether it is possible to remove the assumption
on the knowledge of $n$ was left open in their paper. Another interesting open
question raised in their paper is whether {\em explicit} leader election can be
solved in $\tilde{O}(n)$ messages deterministically. In this paper, we give an
affirmative answer to them. Further, we solve the {\em broadcast problem},
another fundamental problem in distributed computing, deterministically in
diameter-two networks with $\tilde{O}(n)$ messages and $\tilde{O}(1)$ rounds
without the knowledge of $n$. In fact, we address all the open questions raised
by Chatterjee et al. for the deterministic leader election problem in
diameter-two networks. To the best of our knowledge, this is the first
$\tilde{O}(n)$ deterministic result for the explicit leader election in the
diameter-two networks, that too without the knowledge of $n$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:40:22 GMT""}]","2023-02-23"
"2302.11208","Kaikai Zhao","Kaikai Zhao and Norimichi Ukita","KS-DETR: Knowledge Sharing in Attention Learning for Detection
  Transformer",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  Scaled dot-product attention applies a softmax function on the scaled
dot-product of queries and keys to calculate weights and then multiplies the
weights and values. In this work, we study how to improve the learning of
scaled dot-product attention to improve the accuracy of DETR. Our method is
based on the following observations: using ground truth foreground-background
mask (GT Fg-Bg Mask) as additional cues in the weights/values learning enables
learning much better weights/values; with better weights/values, better
values/weights can be learned. We propose a triple-attention module in which
the first attention is a plain scaled dot-product attention, the second/third
attention generates high-quality weights/values (with the assistance of GT
Fg-Bg Mask) and shares the values/weights with the first attention to improve
the quality of values/weights. The second and third attentions are removed
during inference. We call our method knowledge-sharing DETR (KS-DETR), which is
an extension of knowledge distillation (KD) in the way that the improved
weights and values of the teachers (the second and third attentions) are
directly shared, instead of mimicked, by the student (the first attention) to
enable more efficient knowledge transfer from the teachers to the student.
Experiments on various DETR-like methods show consistent improvements over the
baseline methods on the MS COCO benchmark. Code is available at
https://github.com/edocanonymous/KS-DETR.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:48:08 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 04:54:05 GMT""}]","2023-03-17"
"2302.11209","Zai Yang","Zai Yang and Kaijie Wang","Nonasymptotic Performance Analysis of Direct-Augmentation and
  Spatial-Smoothing ESPRIT for Localization of More Sources Than Sensors Using
  Sparse Arrays","17 pages, 3 figures, submitted for publication",,,,"eess.SP cs.IT math.IT","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Direction augmentation (DA) and spatial smoothing (SS), followed by a
subspace method such as ESPRIT or MUSIC, are two simple and successful
approaches that enable localization of more uncorrelated sources than sensors
with a proper sparse array. In this paper, we carry out nonasymptotic
performance analyses of DA-ESPRIT and SS-ESPRIT in the practical
finite-snapshot regime. We show that their absolute localization errors are
bounded from above by $C_1\frac{\max\{\sigma^2, C_2\}}{\sqrt{L}}$ with
overwhelming probability, where $L$ is the snapshot number, $\sigma^2$ is the
Gaussian noise power, and $C_1,C_2$ are constants independent of $L$ and
$\sigma^2$, if and only if they can do exact source localization with
infinitely many snapshots. We also show that their resolution increases with
the snapshot number, without a substantial limit. Numerical results
corroborating our analysis are provided.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:50:37 GMT""}]","2023-02-23"
"2302.11210","Clemens Vittmann","Clemens Vittmann","The Axion-Instanton Weak Gravity Conjecture and Scalar Fields","Thesis submitted in 2018, previously available at
  https://wwwth.mpp.mpg.de/members/palti/images/ClemensThesis.pdf",,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We study the Weak Gravity Conjecture in the presence of scalar fields. The
Weak Gravity Conjecture is a consistency condition for a theory of quantum
gravity asserting that for a U(1) gauge field, there is a particle charged
under this field whose mass is bounded by its charge. It was extended to a
statement about any canonical pair of (p - 1)-dimensional object and p-form
coupling to it, in particular to axion-instanton pairs. The gauge-scalar Weak
Gravity Conjecture is a modification of this bound that includes scalar
interactions. We propose a similar extension to cases where scalar fields are
present for the axion-instanton Weak Gravity Conjecture and provide evidence
from Type IIA supergravity.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:51:17 GMT""}]","2023-02-23"
"2302.11211","Duy Nguyen","Duy Nguyen, Ngoc Bui, Viet Anh Nguyen","Distributionally Robust Recourse Action","25 pages",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  A recourse action aims to explain a particular algorithmic decision by
showing one specific way in which the instance could be modified to receive an
alternate outcome. Existing recourse generation methods often assume that the
machine learning model does not change over time. However, this assumption does
not always hold in practice because of data distribution shifts, and in this
case, the recourse action may become invalid. To redress this shortcoming, we
propose the Distributionally Robust Recourse Action (DiRRAc) framework, which
generates a recourse action that has a high probability of being valid under a
mixture of model shifts. We formulate the robustified recourse setup as a
min-max optimization problem, where the max problem is specified by Gelbrich
distance over an ambiguity set around the distribution of model parameters.
Then we suggest a projected gradient descent algorithm to find a robust
recourse according to the min-max objective. We show that our DiRRAc framework
can be extended to hedge against the misspecification of the mixture weights.
Numerical experiments with both synthetic and three real-world datasets
demonstrate the benefits of our proposed framework over state-of-the-art
recourse methods.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:52:01 GMT""}]","2023-02-23"
"2302.11212","Jordan Roulleau-Pasdeloup","Chunbing Cai, Jordan Roulleau-Pasdeloup","Simple Analytics of the Government Investment Multiplier","40 pages without Appendix, 6 figures",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  What are the effects of investing in public infrastructure? We answer this
question with a New Keynesian model. We recast the model as a Markov chain and
develop a general solution method that nests existing ones inside and outside
the lower bound as special cases. Our framework delivers a simple expression
for the contribution of public infrastructure. We show that it provides a
unified framework to study the effects of public investment in three scenarios:
$(i)$ normal times $(ii)$ a short-lived liquidity trap $(iii)$ a long-lived
liquidity trap. We also provide closed-form results for intermediate cases with
a liquidity trap of arbitrary duration.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:52:41 GMT""}]","2023-02-23"
"2302.11213","Duy Nguyen","Duy Nguyen, Ngoc Bui, Viet Anh Nguyen","Feasible Recourse Plan via Diverse Interpolation","20 pages",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Explaining algorithmic decisions and recommending actionable feedback is
increasingly important for machine learning applications. Recently, significant
efforts have been invested in finding a diverse set of recourses to cover the
wide spectrum of users' preferences. However, existing works often neglect the
requirement that the recourses should be close to the data manifold; hence, the
constructed recourses might be implausible and unsatisfying to users. To
address these issues, we propose a novel approach that explicitly directs the
diverse set of actionable recourses towards the data manifold. We first find a
diverse set of prototypes in the favorable class that balances the trade-off
between diversity and proximity. We demonstrate two specific methods to find
these prototypes: either by finding the maximum a posteriori estimate of a
determinantal point process or by solving a quadratic binary program. To ensure
the actionability constraints, we construct an actionability graph in which the
nodes represent the training samples and the edges indicate the feasible action
between two instances. We then find a feasible path to each prototype, and this
path demonstrates the feasible actions for each recourse in the plan. The
experimental results show that our method produces a set of recourses that are
close to the data manifold while delivering a better cost-diversity trade-off
than existing approaches.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:52:50 GMT""}]","2023-02-23"
"2302.11214","Chao Sun","Jun Zhong, Dongpu Wang, Chao Sun","From sheared annular centrifugal Rayleigh-B\'enard convection to
  radially heated Taylor-Couette flow: How buoyancy and shear affect heat
  transfer and flow structure",,,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  We investigate the coupling effect of buoyancy and shear based on an annular
centrifugal Rayleigh-B\'enard convection (ACRBC) system in which two cylinders
rotate with an angular velocity difference. Direct numerical simulations are
performed in a Rayleigh number range 10^6 \le Ra \le 10^8, at fixed Prandtl
number Pr=4.3, inversed Rossby number Ro^{-1}=20 and radius ratio \eta=0.5. The
shear, represented by the non-dimensional rotational speed difference \Omega,
varies from 0 to 10, corresponding to an ACRBC without shear and a radially
heated Taylor-Couette flow with only the inner cylinder rotating, respectively.
A stable regime is found in the middle part of the interval of \Omega, and
divides the whole parameter space into three regimes: buoyancy-dominated
regime, stable regime, and shear-dominated regime. Clear boundaries between the
regimes are given by linear stability analysis. In the buoyancy-dominated
regime, the flow is a quasi-two-dimensional flow on the r\varphi plane; as
shear increases, both the growth rate of instability and the heat transfer is
depressed. In the shear-dominated regime, the flow is mainly on the rz plane,
and the heat transfer in this regime is greatly enhanced. The study shows shear
can stabilize buoyancy-driven convection and reveals the complex coupling
mechanism of shear and buoyancy, which may have implications for fundamental
studies and industrial designs.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:53:10 GMT""}]","2023-02-23"
"2302.11215","Zehao Xiao","Zehao Xiao, Xiantong Zhen, Shengcai Liao, Cees G. M. Snoek","Energy-Based Test Sample Adaptation for Domain Generalization","Accepted by ICLR 2023",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  In this paper, we propose energy-based sample adaptation at test time for
domain generalization. Where previous works adapt their models to target
domains, we adapt the unseen target samples to source-trained models. To this
end, we design a discriminative energy-based model, which is trained on source
domains to jointly model the conditional distribution for classification and
data distribution for sample adaptation. The model is optimized to
simultaneously learn a classifier and an energy function. To adapt target
samples to source distributions, we iteratively update the samples by energy
minimization with stochastic gradient Langevin dynamics. Moreover, to preserve
the categorical information in the sample during adaptation, we introduce a
categorical latent variable into the energy-based model. The latent variable is
learned from the original sample before adaptation by variational inference and
fixed as a condition to guide the sample update. Experiments on six benchmarks
for classification of images and microblog threads demonstrate the
effectiveness of our proposal.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:55:09 GMT""}]","2023-02-23"
"2302.11216","Amos Amitai Hari","Amos A. Hari, Sefi Givli","A New Method for the Calculation of Functional and Path Integrals",,,,,"math-ph math.MP stat.CO","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Functional integrals are central to modern theories ranging from quantum
mechanics and statistical thermodynamics to biology, chemistry, and finance. In
this work we present a new method for calculating functional integrals based on
a finite-element formulation. This approach is far more robust, versatile, and
powerful than existing methods, thus allowing for more sophisticated
computations and the study of problems that could not previously be tackled.
Importantly, existing procedures, element libraries and shape functions, which
have been developed throughout the years in the context of engineering analysis
and partial differential equations, may be directly employed for this purpose.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:04:00 GMT""}]","2023-02-23"
"2302.11217","Paul Voigtlaender","Paul Voigtlaender and Soravit Changpinyo and Jordi Pont-Tuset and Radu
  Soricut and Vittorio Ferrari","Connecting Vision and Language with Video Localized Narratives","Accepted at CVPR 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose Video Localized Narratives, a new form of multimodal video
annotations connecting vision and language. In the original Localized
Narratives, annotators speak and move their mouse simultaneously on an image,
thus grounding each word with a mouse trace segment. However, this is
challenging on a video. Our new protocol empowers annotators to tell the story
of a video with Localized Narratives, capturing even complex events involving
multiple actors interacting with each other and with several passive objects.
We annotated 20k videos of the OVIS, UVO, and Oops datasets, totalling 1.7M
words. Based on this data, we also construct new benchmarks for the video
narrative grounding and video question answering tasks, and provide reference
results from strong baseline models. Our annotations are available at
https://google.github.io/video-localized-narratives/.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:04:00 GMT""},{""version"":""v2"",""created"":""Wed, 15 Mar 2023 10:30:18 GMT""}]","2023-03-16"
"2302.11218","Mickael Bosco","Mickael Bosco (IREM), Nicolas Michel","Retour d'exp{\'e}rience : Int{\'e}grer des applications transverses
  (Physique et Chimie) de l'enseignement de l'Alg{\`e}bre","in French","{\'E}pijournal de Didactique et Epist{\'e}mologie des
  Math{\'e}matiques pour l'Enseignement Sup{\'e}rieur, 2021",,,"math.HO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a Physicist and a Chemist , we have had the opportunity to teach Algebra
in our engineering school in Aix-en-Provence. The article deals with the
interactions made between Physics, Chemistry and Algebra.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:04:07 GMT""}]","2023-02-23"
"2302.11219","Clement Jailin","Cl\'ement Jailin (GE Healthcare), Pablo Milioni De Carvalho (GE
  Healthcare), Sara Mohamed, Laurence Vancamberg (GE Healthcare), Amr Farouk
  Ibrahim Moustafa (BAHEYA), Mohammed Gomaa (BAHEYA), Rasha Mohammed Kamal
  (BAHEYA), Serge Muller (GE Healthcare)","Deformable registration with intensity correction for CESM monitoring
  response to Neoadjuvant Chemotherapy",,"Biomedical Physics & Engineering Express (2023)","10.1088/2057-1976/acba9f",,"physics.med-ph eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a robust longitudinal registration method for Contrast
Enhanced Spectral Mammography in monitoring neoadjuvant chemotherapy. Because
breast texture intensity changes with the treatment, a non-rigid registration
procedure with local intensity compensations is developed. The approach allows
registering the low energy images of the exams acquired before and after the
chemotherapy. The measured motion is then applied to the corresponding
recombined images. The difference of registered images, called residual, makes
vanishing the breast texture that did not changed between the two exams.
Consequently, this registered residual allows identifying local density and
iodine changes, especially in the lesion area. The method is validated with a
synthetic NAC case where ground truths are available. Then the procedure is
applied to 51 patients with 208 CESM image pairs acquired before and after the
chemotherapy treatment. The proposed registration converged in all 208 cases.
The intensity-compensated registration approach is evaluated with different
mathematical metrics and through the repositioning of clinical landmarks (RMSE:
5.9 mm) and outperforms state-of-the-art registration techniques.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:05:39 GMT""}]","2023-02-23"
"2302.11220","Francesco Tonin","Francesco Tonin, Qinghua Tao, Panagiotis Patrinos, Johan A. K. Suykens","Deep Kernel Principal Component Analysis for Multi-level Feature
  Learning",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Principal Component Analysis (PCA) and its nonlinear extension Kernel PCA
(KPCA) are widely used across science and industry for data analysis and
dimensionality reduction. Modern deep learning tools have achieved great
empirical success, but a framework for deep principal component analysis is
still lacking. Here we develop a deep kernel PCA methodology (DKPCA) to extract
multiple levels of the most informative components of the data. Our scheme can
effectively identify new hierarchical variables, called deep principal
components, capturing the main characteristics of high-dimensional data through
a simple and interpretable numerical optimization. We couple the principal
components of multiple KPCA levels, theoretically showing that DKPCA creates
both forward and backward dependency across levels, which has not been explored
in kernel methods and yet is crucial to extract more informative features.
Various experimental evaluations on multiple data types show that DKPCA finds
more efficient and disentangled representations with higher explained variance
in fewer principal components, compared to the shallow KPCA. We demonstrate
that our method allows for effective hierarchical data exploration, with the
ability to separate the key generative factors of the input data both for large
datasets and when few training samples are available. Overall, DKPCA can
facilitate the extraction of useful patterns from high-dimensional data by
learning more informative features organized in different levels, giving
diversified aspects to explore the variation factors in the data, while
maintaining a simple mathematical formulation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:07:56 GMT""}]","2023-02-23"
"2302.11221","Vincent Brugidou","Vincent Brugidou","A q-analog of certain symmetric functions and one of its specializations","17 pages, 1 figure",,,,"math.CO math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let be the symmetric functions defined for the pair of integers $\left(
n,r\right) $ $n\geq r\geq 1$ by $p_{n}^{\left( r\right)}=\sum m_{\lambda}$
where the $m_{\lambda}$ are the monomial symmetric functions, the sum being
over the partitions $\lambda$ of the integer $n$ of length $r$. In this article
we introduce a $q$-analog of $p_{n}^{\left( r\right) }$, through generating
functions and give some of its properties which are $q$-analogs of its
classical correspondent in particular when $r=1$. We then prove that this
$q$-analog of $p_{n}^{\left( r\right) }$can be expressed in terms of the
classical $p_{n}^{\left( j\right) }$, through the $q$-Stirling numbers of the
second kind. We also begin,with the same procedure, the study of a $p,q$-analog
of $p_{n}^{\left( r\right) }$.
  In the rest of the article we specialize to the series $\sum
q^{\binom{n}{2}}t^{n}/n!$ . We show that $p_{n}^{\left( r\right) }$ is then
related to the $q^{r}$-analog of $p_{n-r}$. We deduce the existence of a double
sequence of polynomials denoted $J_{n,r}\left( q\right) $ with integer
coefficients. We identify these polynomials with the inversion enumerators
introduced for specific rooted forests. These polynomials verify a ''positive''
linear recurrence which allows to build row by row the table of $J_{n,r}$ from
the initial conditions $J_{r,r}=1$. We also give the form of the linear
recurrence, for the reciprocal polynomials of \ $J_{n,r}$, which are the sum
enumerators of parking functions. The linear recurrence permits to obtain an
explicit calculation formula for $J_{n,r}$ . This formula leads us to introduce
new statistics on rooted trees and forests for $J_{n,r}$ or its reciprocal.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:10:04 GMT""}]","2023-02-23"
"2302.11222","Weiyu Li","Lu Lin and Weiyu Li","Source-Function Weighted-Transfer Learning for Nonparametric Regression
  with Seemingly Similar Sources",,,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The homogeneity, or more generally, the similarity between source domains and
a target domain seems to be essential to a positive transfer learning. In
practice, however, the similarity condition is difficult to check and is often
violated. In this paper, instead of the popularly used similarity condition, a
seeming similarity is introduced, which is defined by a non-orthogonality
together with a smoothness. Such a condition is naturally satisfied under
common situations and even implies the dissimilarity in some sense. Based on
the seeming similarity together with an $L_2$-adjustment, a source-function
weighted-transfer learning estimation (sw-TLE) is constructed. By
source-function weighting, an adaptive transfer learning is achieved in the
sense that it is applied to similar and dissimilar scenarios with a relatively
high estimation efficiency. Particularly, under the case with homogenous source
and target models, the sw-TLE even can be competitive with the full data
estimator. The hidden relationship between the source-function weighting
estimator and the James-Stein estimator is established as well, which reveals
the structural reasonability of our methodology. Moreover, the strategy does
apply to nonparametric and semiparametric models. The comprehensive simulation
studies and real data analysis can illustrate that the new strategy is
significantly better than the competitors.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:10:09 GMT""}]","2023-02-23"
"2302.11223","Pierre-Alexandre Kamienny Mr","Pierre-Alexandre Kamienny, Guillaume Lample, Sylvain Lamprier, Marco
  Virgolin","Deep Generative Symbolic Regression with Monte-Carlo-Tree-Search",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Symbolic regression (SR) is the problem of learning a symbolic expression
from numerical data. Recently, deep neural models trained on
procedurally-generated synthetic datasets showed competitive performance
compared to more classical Genetic Programming (GP) algorithms. Unlike their GP
counterparts, these neural approaches are trained to generate expressions from
datasets given as context. This allows them to produce accurate expressions in
a single forward pass at test time. However, they usually do not benefit from
search abilities, which result in low performance compared to GP on
out-of-distribution datasets. In this paper, we propose a novel method which
provides the best of both worlds, based on a Monte-Carlo Tree Search procedure
using a context-aware neural mutation model, which is initially pre-trained to
learn promising mutations, and further refined from successful experiences in
an online fashion. The approach demonstrates state-of-the-art performance on
the well-known \texttt{SRBench} benchmark.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:10:20 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 16:20:24 GMT""}]","2023-05-11"
"2302.11224","Jiaming Zhou","Jiaming Zhou, Shiwan Zhao, Ning Jiang, Guoqing Zhao, Yong Qin","MADI: Inter-domain Matching and Intra-domain Discrimination for
  Cross-domain Speech Recognition","Accepted to ICASSP 2023",,,,"cs.CL cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  End-to-end automatic speech recognition (ASR) usually suffers from
performance degradation when applied to a new domain due to domain shift.
Unsupervised domain adaptation (UDA) aims to improve the performance on the
unlabeled target domain by transferring knowledge from the source to the target
domain. To improve transferability, existing UDA approaches mainly focus on
matching the distributions of the source and target domains globally and/or
locally, while ignoring the model discriminability. In this paper, we propose a
novel UDA approach for ASR via inter-domain MAtching and intra-domain
DIscrimination (MADI), which improves the model transferability by fine-grained
inter-domain matching and discriminability by intra-domain contrastive
discrimination simultaneously. Evaluations on the Libri-Adapt dataset
demonstrate the effectiveness of our approach. MADI reduces the relative word
error rate (WER) on cross-device and cross-environment ASR by 17.7% and 22.8%,
respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:11:06 GMT""}]","2023-02-23"
"2302.11225","Manoel Horta Ribeiro","Manoel Horta Ribeiro, Veniamin Veselovsky, Robert West","The Amplification Paradox in Recommender Systems","Accepted at ICWSM'23 please cite accordingly",,,,"cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Automated audits of recommender systems found that blindly following
recommendations leads users to increasingly partisan, conspiratorial, or false
content. At the same time, studies using real user traces suggest that
recommender systems are not the primary driver of attention toward extreme
content; on the contrary, such content is mostly reached through other means,
e.g., other websites. In this paper, we explain the following apparent paradox:
if the recommendation algorithm favors extreme content, why is it not driving
its consumption? With a simple agent-based model where users attribute
different utilities to items in the recommender system, we show through
simulations that the collaborative-filtering nature of recommender systems and
the nicheness of extreme content can resolve the apparent paradox: although
blindly following recommendations would indeed lead users to niche content,
users rarely consume niche content when given the option because it is of low
utility to them, which can lead the recommender system to deamplify such
content. Our results call for a nuanced interpretation of ``algorithmic
amplification'' and highlight the importance of modeling the utility of content
to users when auditing recommender systems. Code available:
https://github.com/epfl-dlab/amplification_paradox.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:12:48 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 07:43:52 GMT""}]","2023-04-06"
"2302.11226","Rosario Cosentino","G. Bonano, C. Bonoli, F. Bortoletto, P. Bruno, M. Comari, R.
  Cosentino, M. D'Alessandro, D. Fantinel, E. Giro, S. Scuderi","The CCD Controller and Detector","15 pages","Scientific dedication of the ""Telescopio Nazionale Galileo - proc.
  CNNA-INAF Meeting - 2000 p.114",,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  All the scientific instruments of the Italian National Telescope ""Galileo""
(TNG). as well as the tracking systems and the Shack-Hartmann wavefront systems
use CCDs as detectors. The CCD procurement is crucial to optimize the
instruments performance, and, of course, equal importance assumes the design
and realization of controllers able to drive various kinds of CCDs with a very
low readout noise. Detectors characterization is of fundamental importance when
they have to be used in scientific instrumentation. Various CCDs have been
assembled in cryostats and tested at our laboratory in order to select the
suitable detector for the optical instruments of the TNG. The relevant phases
of the group activity are here described, as well as the commissioning at the
telescope and the work that is in progress.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:17:33 GMT""}]","2023-02-23"
"2302.11227","Yuan-Chuan Zou","Hao Wang, Yuan-Chuan Zou, Yu Liu","Phenomenological relationship between eccentric and quasi-circular
  orbital binary black hole waveform","19 pages, 18 figures",,,,"gr-qc","http://creativecommons.org/licenses/by/4.0/","  Eccentricity, an important parameter of gravitational waves, has been paid
more and more attention because it can reflect the dynamics of compact object
mergers. Obtaining an accurate and fast gravitational waveform template is of
great significance for the estimation of gravitational wave parameters. This
paper aims to do an extended study of the phenomenological fitting model
proposed by Setyawati and Ohme for adding eccentricity to quasi-circular
orbital waveforms. It can be applied to higher eccentricity up to e = 0.4. But
the higher the eccentricity, the less the accuracy. For e in [0, 0.1], it gives
an overlap of more than 99.99%. For e in [0.1, 0.2], it gives an overlap of
more than 99.9%. For e in [0.2, 0.3], it gives an overlap of more than 99%. For
e in [0.3, 0.4], it gives an overlap of more than 90%. The reason for these
phenomena is that the larger the eccentricity, the larger the deviation of the
eccentricity estimator from the cosine function due to the large change in the
morphology of the eccentric waveform, and the worse the fitting effect of the
model. It can be applied to higher-order modes and gives the same overlap
behavior. After adding a shift parameter, it can be applied to spin-aligned or
spin-antialigned waveforms. After obtaining spin-precessing effect, it can be
applied to the spin-precessing case. In summary, non-spining, spin-aligned,
spin-antialigned or spin-precessing waveforms with eccentricity can be
constructed from quasi-circular non-spining waveforms by the phenomenological
model, which is not only helpful for us to quickly construct phenomenological
gravitational wave templates, but also reveals a phenomenological and universal
relationship between eccentric waveform and quasi-circular orbital waveform.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:18:41 GMT""}]","2023-02-23"
"2302.11228","Rosario Cosentino","Bortoletto F., Benetti S., Bonanno G., Bonoli C., Cosentino R.,
  D'Alessandro M., Fantinel D., Ghedina A., Giro E., Magazzu A., Pernechele C.,
  Vuerli C","The optical imager Galileo (OIG)",,"Scientific dedication of the ""Telescopio Nazionale Galileo - proc.
  CNNA-INAF Meeting - 2000 p.148",,,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present paper describes the construction, the installation and the
operation of the Optical Imager Galileo (OIG), a scientific instrument
dedicated to the 'imaging' in the visible. OIG was the first instrument
installed on the focal plane of the Telescopio Nazionale Galileo (TNG) and it
has been extensively used for the functional verification of several parts of
the telescope (as an example the optical quality, the rejection of spurious
light, the active optics and the tracking), in the same way also several parts
of the TNG informatics system (instrument commanding, telemetry and data
archiving) have been verified making extensive use of OIG. This paper provides
also a frame of work for a further development of the imaging dedicated
instrumentation inside TNG. OIG, coupled with the first near-IR camera
(ARNICA), has been the 'workhorse instrument' during the first period of
telescope experimental and scientific scheduling.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:18:42 GMT""}]","2023-02-23"
"2302.11229","Khalil El Bourakadi","K. El Bourakadi, Z. Sakhi, M. Bennai","Observational constraints on Tachyon inflation and reheating in f(Q)
  gravity",,,,,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  In this work we study one of the most appealing string theory-motivated
models, we present a tachyonic inflationary model in the recently proposed
symmetric teleparallel framework, and examine constraints on tachyon inflation
with the exponential potential along with the reheating for a chosen $f(Q)$
gravity model. Considering a reheating phase parametrized by a number of
e-folds $N_{re},$ a temperature $T_{re}$, and an equation of state $\omega
_{re}$, we relate the reheating parameters as functions of the exponential
tachyon potential, $f(Q)$ model, and\ the spectral index $n_{s}$ parameters. We
argue that our model predicts inflationary e-folds bounded as $50\leq N\leq
64$. While for the reheating phase, wide ranges of reheating e-folds numbers
and temperatures can be obtained as we increase $\omega_{re} $ towards the
value $1/4$ according to recent Planck Data.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:18:57 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 19:04:34 GMT""}]","2023-02-27"
"2302.11230","Tzvi Diskin","Nerya Granot, Tzvi Diskin, Nicolas Dobigeon and Ami Wiesel","Probabilistic Simplex Component Analysis by Importance Sampling",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the problem of linear unmixing hidden random
variables defined over the simplex with additive Gaussian noise, also known as
probabilistic simplex component analysis (PRISM). Previous solutions to tackle
this challenging problem were based on geometrical approaches or
computationally intensive variational methods. In contrast, we propose a
conventional expectation maximization (EM) algorithm which embeds importance
sampling. For this purpose, the proposal distribution is chosen as a simple
surrogate distribution of the target posterior that is guaranteed to lie in the
simplex. This distribution is based on the Gaussian linear minimum mean squared
error (LMMSE) approximation which is accurate at high signal-to-noise ratio.
Numerical experiments in different settings demonstrate the advantages of this
adaptive surrogate over state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:21:40 GMT""}]","2023-02-23"
"2302.11231","Honglin Shu","Honglin Shu, Pei Gao, Lingwei Zhu, and Zheng Chen","Drugs Resistance Analysis from Scarce Health Records via Multi-task
  Graph Representation","12 pages, 5 figures",,,,"cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Clinicians prescribe antibiotics by looking at the patient's health record
with an experienced eye. However, the therapy might be rendered futile if the
patient has drug resistance. Determining drug resistance requires
time-consuming laboratory-level testing while applying clinicians' heuristics
in an automated way is difficult due to the categorical or binary medical
events that constitute health records. In this paper, we propose a novel
framework for rapid clinical intervention by viewing health records as graphs
whose nodes are mapped from medical events and edges as correspondence between
events in given a time window. A novel graph-based model is then proposed to
extract informative features and yield automated drug resistance analysis from
those high-dimensional and scarce graphs. The proposed method integrates
multi-task learning into a common feature extracting graph encoder for
simultaneous analyses of multiple drugs as well as stabilizing learning. On a
massive dataset comprising over 110,000 patients with urinary tract infections,
we verify the proposed method is capable of attaining superior performance on
the drug resistance prediction problem. Furthermore, automated drug
recommendations resemblant to laboratory-level testing can also be made based
on the model resistance analysis.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:22:13 GMT""},{""version"":""v2"",""created"":""Wed, 8 Mar 2023 05:52:48 GMT""}]","2023-03-09"
"2302.11232","Jonas Saqri","J. Saqri, A. M. Veronig, E. C. M. Dickson, T. Podladchikova, A.
  Warmuth, H. Xiao, D. E. Gary, A. F. Battaglia and S. Krucker","Multi-point study of the energy release and impulsive CME dynamics in an
  eruptive C7 flare",,,"10.1051/0004-6361/202245079",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine observations from different vantage points to perform a detailed
study of a long duration eruptive C7 class flare that occurred on 17 April 2021
and was partially occulted from Earth view. The dynamics and thermal properties
of the flare-related plasma flows, the flaring arcade, and the energy releases
and particle acceleration are studied together with the kinematic evolution of
the associated CME in order to place this long duration event in context of
previous eruptive flare studies. The flare showed hard X-ray (HXR) bursts over
the duration of an hour in two phases lasting from 16:04 UT to 17:05 UT. During
the first phase, a strong increase in emission from hot plasma and impulsive
acceleration of the CME was observed. The CME acceleration profile shows a
three-part evolution of slow rise, acceleration, and propagation in line with
the first STIX HXR burst phase, which is triggered by a rising hot (14 MK)
plasmoid. During the CME acceleration phase, we find signatures of ongoing
magnetic reconnection behind the erupting structure, in agreement with the
standard eruptive flare scenario. The subsequent HXR bursts that occur about 30
minutes after the primary CME acceleration show a spectral hardening (from
$\delta \approx $ 7 to $\delta \approx $ 4) but do not correspond to further
CME acceleration and chromospheric evaporation. Therefore, the CME-flare
feedback relationship may only be of significance within the first 25 minutes
of the event under study, as thereafter the flare and the CME eruption evolve
independently of each other.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:25:43 GMT""}]","2023-03-29"
"2302.11233","Yuhan Xie","Yuhan Xie, Minghao Lu, Rui Peng and Peng Lu","Learning Agile Flights through Narrow Gaps with Varying Angles using
  Onboard Sensing",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper addresses the problem of traversing through unknown, tilted, and
narrow gaps for quadrotors using Deep Reinforcement Learning (DRL). Previous
learning-based methods relied on accurate knowledge of the environment,
including the gap's pose and size. In contrast, we integrate onboard sensing
and detect the gap from a single onboard camera. The training problem is
challenging for two reasons: a precise and robust whole-body planning and
control policy is required for variable-tilted and narrow gaps, and an
effective Sim2Real method is needed to successfully conduct real-world
experiments. To this end, we propose a learning framework for agile gap
traversal flight, which successfully trains the vehicle to traverse through the
center of the gap at an approximate attitude to the gap with aggressive tilted
angles. The policy trained only in a simulation environment can be transferred
into different domains with fine-tuning while maintaining the success rate. Our
proposed framework, which integrates onboard sensing and a neural network
controller, achieves a success rate of 84.51% in real-world experiments, with
gap orientations up to 60deg. To the best of our knowledge, this is the first
paper that performs the learning-based variable-tilted narrow gap traversal
flight in the real world, without prior knowledge of the environment.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:25:53 GMT""}]","2023-02-23"
"2302.11234","Maximilian Toller","Maximilian B. Toller and Bernhard C. Geiger and Roman Kern","Cluster Purging: Efficient Outlier Detection based on Rate-Distortion
  Theory",,"IEEE Transactions on Knowledge and Data Engineering 35 (2023)
  1270-1282","10.1109/TKDE.2021.3103571",,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Rate-distortion theory-based outlier detection builds upon the rationale that
a good data compression will encode outliers with unique symbols. Based on this
rationale, we propose Cluster Purging, which is an extension of
clustering-based outlier detection. This extension allows one to assess the
representivity of clusterings, and to find data that are best represented by
individual unique clusters. We propose two efficient algorithms for performing
Cluster Purging, one being parameter-free, while the other algorithm has a
parameter that controls representivity estimations, allowing it to be tuned in
supervised setups. In an experimental evaluation, we show that Cluster Purging
improves upon outliers detected from raw clusterings, and that Cluster Purging
competes strongly against state-of-the-art alternatives.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:32:37 GMT""}]","2023-02-23"
"2302.11235","Oleg Utesov I.","Oleg I. Utesov","Magnons in the fan phase of anisotropic frustrated antiferromagnets","9 pages, 3 figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Elementary excitations spectrum of the fan phase of anisotropic frustrated
antiferromagnets is discussed analytically. In the linear spin-wave
approximation, the spectrum is determined by the Hamiltonian, including normal,
anomalous, and umklapp terms. The latter mix states with momenta which differ
by two modulation vectors of the fan structure. This mixing leads to essential
rearrangement of the low-energy part of the spectrum, which is shown to consist
of a gapless phason branch with linear dispersion and a gapped ``optical''
branch, which corresponds to the fan structure amplitude oscillations. In the
high-energy part of the spectrum, the effect of the umklapps is negligible, and
the excitations are similar to the magnons of the fully polarized phase.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:34:54 GMT""}]","2023-02-23"
"2302.11236","Jos\'e L. Risco-Mart\'in","Josefa D\'iaz \'Alvarez, Jos\'e L. Risco-Mart\'in and J. Manuel
  Colmenar","Multi-objective optimization of energy consumption and execution time in
  a single level cache memory for embedded systems",,"Journal of Systems and Software, 111, pp. 200-212, 2016","10.1016/j.jss.2015.10.012",,"cs.NE cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Current embedded systems are specifically designed to run multimedia
applications. These applications have a big impact on both performance and
energy consumption. Both metrics can be optimized selecting the best cache
configuration for a target set of applications. Multi-objective optimization
may help to minimize both conflicting metrics in an independent manner. In this
work, we propose an optimization method that based on Multi-Objective
Evolutionary Algorithms, is able to find the best cache configuration for a
given set of applications. To evaluate the goodness of candidate solutions, the
execution of the optimization algorithm is combined with a static profiling
methodology using several well-known simulation tools. Results show that our
optimization framework is able to obtain an optimized cache for Mediabench
applications. Compared to a baseline cache memory, our design method reaches an
average improvement of 64.43\% and 91.69\% in execution time and energy
consumption, respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:35:03 GMT""}]","2023-02-23"
"2302.11237","Cedric Simenel","R\'emi Bernard, C\'edric Simenel and Guillaume Blanchon","Hartree-Fock-Bogoliubov study of quantum shell effects on the path to
  fission in $^{180}$Hg, $^{236}$U and $^{256}$Fm","11 pages, 7 figures. References updated","Eur. Phys. J. A (2023) 59: 51","10.1140/epja/s10050-023-00964-2",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum shell effects stabilising fission fragments with various shapes have
been invoked as a factor determining the distribution of nucleons between the
fragments at scission. Shell effects also induce asymmetric shapes in the
nucleus on its way to fission well before the final fragments are (pre)formed.
These shell effects are studied in fission of $^{180}$Hg, $^{236}$U and
$^{256}$Fm with constrained Hartree-Fock-Bogoliubov calculations using the D1S
parametrisation of the Gogny interaction. Strutinsky shell energy correction
and single-particle energy level density near the Fermi surface are computed.
Several neutron and proton shell effects are identified as drivers towards
asymmetric fission. Shell effects are also used to identify the preformation of
the fragments in the later stage of fission.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:38:04 GMT""},{""version"":""v2"",""created"":""Wed, 12 Apr 2023 02:01:23 GMT""}]","2023-04-13"
"2302.11238","Sergey Derkachov","S. E. Derkachov, A. P. Isaev and L. A. Shumilov","Ladder and zig-zag Feynman diagrams, operator formalism and conformal
  triangles",,,,,"hep-th","http://creativecommons.org/licenses/by/4.0/","  We develop an operator approach to the evaluation of multiple integrals for
multiloop Feynman massless diagrams. A commutative family of graph building
operators $H_\alpha$ for ladder diagrams is constructed and investigated. The
complete set of eigenfunctions and the corresponding eigenvalues for the
operators $H_\alpha$ are found. This enables us to explicitly express a wide
class of four-point ladder diagrams and a general two-loop propagator-type
master diagram (with arbitrary indices on the lines) as Mellin-Barnes-type
integrals. Special cases of these integrals are explicitly evaluated. A certain
class of zig-zag four-point and two-point planar Feynman diagrams (relevant to
the bi-scalar $D$-dimensional ""fishnet"" field theory and to the calculation of
the $\beta$-function in $\phi^4$-theory) is considered. The graph building
operators and convenient integral representations for these Feynman diagrams
are obtained. The explicit form of the eigenfunctions for the graph building
operators of the zig-zag diagrams is fixed by conformal symmetry and these
eigenfunctions coincide with the 3-point correlation functions in
$D$-dimensional conformal field theories. By means of this approach, we exactly
evaluate the diagrams of the zig-zag series in special cases. In particular, we
find a fairly simple derivation of the values for the zig-zag multi-loop
two-point diagrams for $D=4$. The role of conformal symmetry in this approach,
especially a connection of the considered graph building operators with
conformal invariant solutions of the Yang-Baxter equation is investigated in
detail.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:39:01 GMT""},{""version"":""v2"",""created"":""Sat, 11 Mar 2023 16:09:31 GMT""}]","2023-03-14"
"2302.11239","Zhong Li","Zhong Li, Matthijs van Leeuwen","Explainable Contextual Anomaly Detection using Quantile Regression
  Forests","Manuscript submitted to Data Mining and Knowledge Discovery in
  October 2022 for possible publication. This is the revised version submitted
  in April 2023",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Traditional anomaly detection methods aim to identify objects that deviate
from most other objects by treating all features equally. In contrast,
contextual anomaly detection methods aim to detect objects that deviate from
other objects within a context of similar objects by dividing the features into
contextual features and behavioral features. In this paper, we develop
connections between dependency-based traditional anomaly detection methods and
contextual anomaly detection methods. Based on resulting insights, we propose a
novel approach to inherently interpretable contextual anomaly detection that
uses Quantile Regression Forests to model dependencies between features.
Extensive experiments on various synthetic and real-world datasets demonstrate
that our method outperforms state-of-the-art anomaly detection methods in
identifying contextual anomalies in terms of accuracy and interpretability.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:39:59 GMT""},{""version"":""v2"",""created"":""Fri, 28 Apr 2023 15:20:59 GMT""}]","2023-05-01"
"2302.11240","Kerstin Weinberg","Marcel Fischbach and Kerstin Weinberg","Effect of physical aging on the flexural creep in 3D printed
  thermoplastic",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extrusion-based 3D printing has become one of the most common additive
manufacturing methods and is widely used in engineering. This contribution
presents the results of flexural creep experiments on 3D printed PLA specimens,
focusing on changes in creep behavior due to physical aging. It is shown
experimentally that the creep curves obtained on aged specimens are shifted to
each other on the logarithmic time scale in a way that the theory of physical
aging can explain. The reason for the physical aging of 3D printed
thermoplastics is assumed to be the special heat treatment that the polymer
undergoes during extrusion. Additionally, results of a long-term flexural creep
experiment are shown, demonstrating that non-negligible creep over long periods
can be observed even at temperatures well below the glass transition
temperature. Such creep effects should be considered for designing components
made of 3D printed thermoplastics.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:42:15 GMT""}]","2023-02-23"
"2302.11241","Johannes Lederer","Ayla Jungbluth and Johannes Lederer","The DeepCAR Method: Forecasting Time-Series Data That Have Change Points",,,,,"cs.LG cs.AI stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many methods for time-series forecasting are known in classical statistics,
such as autoregression, moving averages, and exponential smoothing. The DeepAR
framework is a novel, recent approach for time-series forecasting based on deep
learning. DeepAR has shown very promising results already. However, time series
often have change points, which can degrade the DeepAR's prediction performance
substantially. This paper extends the DeepAR framework by detecting and
including those change points. We show that our method performs as well as
standard DeepAR when there are no change points and considerably better when
there are change points. More generally, we show that the batch size provides
an effective and surprisingly simple way to deal with change points in DeepAR,
Transformers, and other modern forecasting models.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:43:00 GMT""}]","2023-02-23"
"2302.11242","Jos\'e L. Risco-Mart\'in","Jos\'e L. Risco-Mart\'in, Kevin Henares, Saurabh Mittal, Luis F.
  Almendras and Katzalin Olcoz","A Unified Cloud-Enabled Discrete Event Parallel and Distributed
  Simulation Architecture",,"Simulation Modelling Practice and Theory, 118, 2022","10.1016/j.simpat.2022.102539",,"cs.DC cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  Cloud simulation environments today are largely employed to model and
simulate complex systems for remote accessibility and variable capacity
requirements. In this regard, scalability issues in Modeling and Simulation
(M\&S) computational requirements can be tackled through the elasticity of
on-demand Cloud deployment. However, implementing a high performance cloud M\&S
framework following these elastic principles is not a trivial task as
parallelizing and distributing existing architectures is challenging. Indeed,
both the parallel and distributed M\&S developments have evolved following
separate ways. Parallel solutions has always been focused on ad-hoc solutions,
while distributed approaches, on the other hand, have led to the definition of
standard distributed frameworks like the High Level Architecture (HLA) or
influenced the use of distributed technologies like the Message Passing
Interface (MPI). Only a few developments have been able to evolve with the
current resilience of computing hardware resources deployment, largely focused
on the implementation of Simulation as a Service (SaaS), albeit independently
of the parallel ad-hoc methods branch. In this paper, we present a unified
parallel and distributed M\&S architecture with enough flexibility to deploy
parallel and distributed simulations in the Cloud with a low effort, without
modifying the underlying model source code, and reaching important speedups
against the sequential simulation, especially in the parallel implementation.
Our framework is based on the Discrete Event System Specification (DEVS)
formalism. The performance of the parallel and distributed framework is tested
using the xDEVS M\&S tool, Application Programming Interface (API) and the
DEVStone benchmark with up to eight computing nodes, obtaining maximum speedups
of $15.95\times$ and $1.84\times$, respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:47:09 GMT""}]","2023-02-23"
"2302.11243","Haoran Yang","Hao-Ran Yang and Xiang-Dong Li","Magnetic Inclination Evolution of Accreting Neutron Stars in
  Intermediate/Low-Mass X-ray Binaries","12 pages, 7 figures, accepted for publication in ApJ",,"10.3847/1538-4357/acba09",,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  The magnetic inclination angle $\chi$, namely the angle between the spin and
magnetic axes of a neutron star (NS), plays a vital role in its observational
characteristics. However, there are few systematic investigations on its
long-term evolution, especially for accreting NSs in binary systems. Applying
the model of \citet{2021MNRAS.505.1775B} and the binary evolution code \mesa{},
we simultaneously simulate the evolution of the accretion rate, spin period,
magnetic field, and magnetic inclination angle of accreting NSs in
intermediate/low X-ray binaries (I/LMXBs). We show that the evolution of $\chi$
depends not only on the initial parameters of the binary systems, but also on
the mass transfer history and the efficiency of pulsar loss. Based on the
calculated results we present the characteristic distribution of $\chi$ for
various types of systems including ultracompact X-ray binaries, binary
millisecond pulsars, and ultraluminous X-ray sources, and discuss their
possible observational implications.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:47:36 GMT""}]","2023-03-08"
"2302.11244","Benjamin Vandersmissen","Benjamin Vandersmissen and Jose Oramas","Considering Layerwise Importance in the Lottery Ticket Hypothesis",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  The Lottery Ticket Hypothesis (LTH) showed that by iteratively training a
model, removing connections with the lowest global weight magnitude and
rewinding the remaining connections, sparse networks can be extracted.
  This global comparison removes context information between connections within
a layer. Here we study means for recovering some of this layer distributional
context and generalise the LTH to consider weight importance values rather than
global weight magnitudes.
  We find that given a repeatable training procedure, applying different
importance metrics leads to distinct performant lottery tickets with little
overlapping connections. This strongly suggests that lottery tickets are not
unique
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:51:00 GMT""}]","2023-02-23"
"2302.11245","Daniel Althoff","Daniel Althoff and Georgia Destouni","The global freshwater system: Patterns and predictability of green-blue
  water flux partitioning",,,,,"physics.geo-ph physics.ao-ph physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  The partitioning of precipitation (P) water input on land between green
(evapotranspiration, ET) and blue (runoff, R) water fluxes distributes the
annually renewable freshwater resource among sectors and ecosystems. We
decipher the worldwide pattern and key determinants of this water flux
partitioning (WFP) and investigate its predictability based on a machine
learning (ML) model trained and tested on data for 3,614 hydrological
catchments around the world. The results show considerably higher WFP to the
green (ET/P) than the blue (R/P) flux in most of the world. Land-use changes
toward expanded agriculture and forestry will increase this WFP asymmetry,
jeopardizing blue-water availability and making it more vulnerable to future P
changes for other sectors and ecosystems. The predictive ML-model of WFP
developed in this study can be used with climate model projections of P to
assess future blue and green water security for various regions, sectors, and
ecosystems around the world.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:52:02 GMT""}]","2023-02-23"
"2302.11246","Tom Lefebvre","Tom Lefebvre, Sander De Witte, Thomas Neve and Guillaume Crevecoeur","Differential Flatness of Slider-Pusher Systems for Constrained Time
  Optimal Collision Free Path Planning",,,,,"math.DS","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this work we show that the differential kinematics of slider-pusher
systems are differentially flat assuming quasi-static behaviour and
frictionless contact. Second we demonstrate that the state trajectories are
invariant to time-differential transformations of the path parametrizing
coordinate. For one this property allows to impose arbitrary velocity profiles
on the slider without impacting the geometry of the state trajectory. This
property implies that certain path planning problems may be decomposed
approximately into a strictly geometric path planning and an auxiliary
throughput speed optimization problem. Building on these insights we elaborate
a numerical approach tailored to constrained time optimal collision free path
planning and apply it to the slider-pusher system.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:54:01 GMT""}]","2023-02-23"
"2302.11247","Iurii Babyk","Iurii Babyk and Brian McNamara","The Halo Mass-Temperature Relation for Clusters, Groups, and Galaxies","12 pages, 4 figures, submitted to the Astrophysical Journal","2023 ApJ, Vol. 946, P. 54","10.3847/1538-4357/acbf4b",,"astro-ph.GA","http://creativecommons.org/publicdomain/zero/1.0/","  The halo mass-temperature relation for a sample of 216 galaxy clusters,
groups, and individual galaxies observed by $Chandra$ X-ray Observatory is
presented. Using accurate spectral measurements of their hot atmospheres, we
derive the $M-T$ relation for systems with temperatures ranging between
0.4-15.0 keV. We measure the total mass of clusters, groups, and galaxies at
radius $R_{2500}$, finding that the $M_{2500} \propto T^{\alpha}$ relation
follows a power-law with $\alpha$ = 1.65$\pm$0.06. Our relation agrees with
recent lensing studies of the $M-T$ relation at $R_{200}$ and is consistent
with self-similar theoretical prediction and recent simulations. This agreement
indicates that the $M-T$ relation is weakly affected by non-gravitational
heating processes. Using lensing masses within $R_{200}$ we find $M_{200}-T$
follows a power-law with slope 1.61$\pm$0.19, consistent with the $M_{2500}-T$
relation. No evidence for a break or slope change is found in either relation.
Potential biases associated with sample selection, evolution, and the
assumption of hydrostatic equilibrium that may affect the scaling are examined.
No significant impacts attributable to these biases are found. Non-cool-core
clusters and early spirals produce higher scatter in the $M-T$ relation than
cool-core clusters and elliptical galaxies.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:56:30 GMT""}]","2023-04-06"
"2302.11248","Rahul Ramachandran Nair","Rahul R. Nair, Grzegorz Wilk, Zbigniew W{\l}odarczyk","Signatures of deuteron synthesis on the modified combinants in nuclear
  collisions",,,,,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mechanism of deuteron production in heavy-ion collisions is shown to have
a significant impact on the shape of the modified combinants of their
multiplicity distribution. In light of this observation, an experimental study
is proposed to tackle the long-standing problem of nuclei synthesis in hadronic
and nuclear collisions. The proposed approach has the potential to provide
stringent constraints on the models of deuteron synthesis.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:58:29 GMT""}]","2023-02-23"
"2302.11249","Honghao Luo","Honghao Luo, Rang Liu, Ming Li, and Qian Liu","RIS-Aided Integrated Sensing and Communication: Joint Beamforming and
  Reflection Design","Accepted by IEEE TVT",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Integrated sensing and communication (ISAC) has been envisioned as a
promising technique to alleviate the spectrum congestion problem. Inspired by
the applications of reconfigurable intelligent surface (RIS) in dynamically
manipulating wireless propagation environment, in this paper, we investigate to
deploy a RIS in an ISAC system to pursue performance improvement. Particularly,
we consider a RIS-assisted ISAC system where a multi-antenna base station (BS)
performs multi-target detection and multi-user communication with the
assistance of a RIS. Our goal is maximizing the weighted summation of target
detection signal-to-noise ratios (SNRs) by jointly optimizing the transmit
beamforming and the RIS reflection coefficients, while satisfying the
communication quality-of-service (QoS) requirement, the total transmit power
budget, and the restriction of RIS phase-shift. An efficient alternating
optimization algorithm combining the majorization-minimization (MM),
penalty-based, and manifold optimization methods is developed to solve the
resulting complicated non-convex optimization problem. Simulation results
illustrate the advantages of deploying RIS in ISAC systems and the
effectiveness of our proposed algorithm.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:58:31 GMT""}]","2023-02-23"
"2302.11250","Martin Hoefer","Henri Froese, Martin Hoefer, Lisa Wilhelmi","The Complexity of Debt Swapping","36 pages, 10 figures",,,,"cs.DS cs.CC cs.GT q-fin.RM","http://creativecommons.org/licenses/by/4.0/","  A debt swap is an elementary edge swap in a directed, weighted graph, where
two edges with the same weight swap their targets. Debt swaps are a natural and
appealing operation in financial networks, in which nodes are banks and edges
represent debt contracts. They can improve the clearing payments and the
stability of these networks. However, their algorithmic properties are not
well-understood.
  We analyze the computational complexity of debt swapping in networks with
ranking-based clearing. Our main interest lies in semi-positive swaps, in which
no creditor strictly suffers and at least one strictly profits. These swaps
lead to a Pareto-improvement in the entire network. We consider network
optimization via sequences of $v$-improving debt swaps from which a given bank
$v$ strictly profits. We show that every sequence of semi-positive
$v$-improving swaps has polynomial length. In contrast, for arbitrary
$v$-improving swaps, the problem of reaching a network configuration that
allows no further swaps is PLS-complete. We identify cases in which short
sequences of semi-positive swaps exist even without the $v$-improving property.
  In addition, we study reachability problems, i.e., deciding if a sequence of
swaps exists between given initial and final networks. We identify a
polynomial-time algorithm for arbitrary swaps, show NP-hardness for
semi-positive swaps and even PSPACE-completeness for $v$-improving swaps or
swaps that only maintain a lower bound on the assets of a given bank $v$. A
variety of our results can be extended to arbitrary monotone clearing.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:59:17 GMT""}]","2023-02-23"
"2302.11251","Evgenii Reznichenko","Evgenii Reznichenko and Mikhail Tkachenko","Countable subsets of the pseudocompact quasitopological Korovin group
  are discrete",,,,,"math.GN","http://creativecommons.org/licenses/by/4.0/","  It is shown that in any quasitopological group of the form of a Korovin
orbit, all countable subsets are discrete, closed, and $C^*$-embedded.
Consequently, such pseudocompact groups are not homeomorphic to topological
groups. Moreover, Korovin's pseudocompact quasitopological groups are not
homeomorphic to any Mal'tsev space.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 09:59:40 GMT""},{""version"":""v2"",""created"":""Mon, 27 Mar 2023 20:40:20 GMT""}]","2023-03-29"
"2302.11252","Quoc Viet Pham","Viet-Quoc Pham, Nao Mishima","Focusing On Targets For Improving Weakly Supervised Visual Grounding","accepted by ICASSP2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Weakly supervised visual grounding aims to predict the region in an image
that corresponds to a specific linguistic query, where the mapping between the
target object and query is unknown in the training stage. The state-of-the-art
method uses a vision language pre-training model to acquire heatmaps from
Grad-CAM, which matches every query word with an image region, and uses the
combined heatmap to rank the region proposals. In this paper, we propose two
simple but efficient methods for improving this approach. First, we propose a
target-aware cropping approach to encourage the model to learn both object and
scene level semantic representations. Second, we apply dependency parsing to
extract words related to the target object, and then put emphasis on these
words in the heatmap combination. Our method surpasses the previous SOTA
methods on RefCOCO, RefCOCO+, and RefCOCOg by a notable margin.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:02:21 GMT""}]","2023-02-23"
"2302.11253","Emanuel Schwarzhans","Emanuel Schwarzhans, Felix C. Binder, Marcus Huber, Maximilian P. E.
  Lock","Quantum measurements and equilibration: the emergence of objective
  reality via entropy maximisation","7+6 pages, 1 figure",,,,"quant-ph","http://creativecommons.org/licenses/by/4.0/","  Textbook quantum physics features two types of dynamics, reversible unitary
dynamics and irreversible measurements. The latter stands in conflict with the
laws of thermodynamics and has evoked debate on what actually constitutes a
measurement. With the help of modern quantum statistical mechanics, we take the
first step in formalising the hypothesis that quantum measurements are instead
driven by the natural tendency of closed systems to maximize entropy, a notion
that we call the Measurement-Equilibration Hypothesis. In this paradigm, we
investigate how objective measurement outcomes can emerge within an purely
unitary framework, and find that: (i) the interactions used in standard
measurement models fail to spontaneously feature emergent objectivity and (ii)
while ideal projective measurements are impossible, we can (for a given form of
Hamiltonian) approximate them exponentially well as we collect more physical
systems together into an ``observer'' system. We thus lay the groundwork for
self-contained models of quantum measurement, proposing improvements to our
simple scheme.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:06:17 GMT""}]","2023-02-23"
"2302.11254","Meng Liu","Meng Liu, Kong Aik Lee, Longbiao Wang, Hanyi Zhang, Chang Zeng, Jianwu
  Dang","Cross-modal Audio-visual Co-learning for Text-independent Speaker
  Verification",,,,,"cs.SD cs.CV cs.LG eess.AS eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual speech (i.e., lip motion) is highly related to auditory speech due to
the co-occurrence and synchronization in speech production. This paper
investigates this correlation and proposes a cross-modal speech co-learning
paradigm. The primary motivation of our cross-modal co-learning method is
modeling one modality aided by exploiting knowledge from another modality.
Specifically, two cross-modal boosters are introduced based on an audio-visual
pseudo-siamese structure to learn the modality-transformed correlation. Inside
each booster, a max-feature-map embedded Transformer variant is proposed for
modality alignment and enhanced feature generation. The network is co-learned
both from scratch and with pretrained models. Experimental results on the
LRSLip3, GridLip, LomGridLip, and VoxLip datasets demonstrate that our proposed
method achieves 60% and 20% average relative performance improvement over
independently trained audio-only/visual-only and baseline fusion systems,
respectively.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:06:37 GMT""}]","2023-02-23"
"2302.11255","Gianluca Francica","Gianluca Francica, Luca Dell'Anna","Quasiprobability distribution of work in the Ising model","14 pages, 4 figures. Comments welcome",,,,"quant-ph cond-mat.stat-mech","http://creativecommons.org/licenses/by/4.0/","  A complete understanding of the statistics of the work done by quenching a
parameter of a quantum many-body system is still lacking in the presence of an
initial quantum coherence in the energy basis. In this case, the work can be
represented by a class of quasiprobability distributions. Here, we try to
clarify the genuinely quantum features of the process by studying the work
quasiprobability for an Ising model in a transverse field. We consider both a
global and a local quench, by focusing mainly on the thermodynamic limit. We
find that, while for a global quench there is a symmetric non-contextual
representation with a Gaussian probability distribution of work (apart from
subdominant terms), for a local quench we can get quantum contextuality as
signaled by a negative fourth moment of the work. Furthermore, we examine the
universal features related to a quantum phase transition and the role of the
initial quantum coherence as useful resource.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:07:49 GMT""}]","2023-02-23"
"2302.11256","Xiaochen Hao","Xiaochen Hao, Zijian Ding, Jieming Yin, Yuan Wang and Yun Liang","ALEGO: Towards Cost-Aware Architecture and Integration Co-Design for
  Chiplet-based Spatial Accelerators",,,,,"cs.AR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Advanced packaging offers a new design paradigm in the post-Moore era, where
many smaller chiplets could be assembled into a large system to achieve extreme
scalability and cost reduction. Recently proposed chiplet-based DNN
accelerators demonstrate its effectiveness but fail to explore the tradeoffs
between PPA and the fabrication cost. Specifically, we should explore both the
architectural design space for individual chiplets and different integration
options to assemble these chiplets. More advanced (and costly) packaging
technology can enhance connectivity, but may meanwhile reduce the budget on
chiplets.
  In this paper, we propose ALEGO, an architecture-and-integration co-design
approach for chiplet-based spatial accelerators. Based on a heterogeneous
integration paradigm, ALEGO can optimize each chiplet design for different
workloads to achieve better efficiency. The co-design is enabled by using
uniform architecture and integration encoding and a systematic design space
exploration flow. We develop an architecture modeling framework and an ML-based
approach to optimize the design parameters. Experiments demonstrate that ALEGO
achieves 24%, 16%, or 23% improvement in latency, energy, and cost,
respectively compared with the best of separate architecture or integration
optimization.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:08:51 GMT""}]","2023-02-23"
"2302.11257","Arif Shaikh Md","Md Arif Shaikh, Vijay Varma, Harald P. Pfeiffer, Antoni Ramos-Buades
  and Maarten van de Meent","Defining eccentricity for gravitational wave astronomy","Python implementation available at
  https://pypi.org/project/gw-eccentricity/",,,,"gr-qc astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  Eccentric compact binary mergers are significant scientific targets for
current and future gravitational wave observatories. To detect and analyze
eccentric signals, there is an increasing effort to develop waveform models,
numerical relativity simulations, and parameter estimation frameworks for
eccentric binaries. Unfortunately, current models and simulations adopt
different internal parameterisations of eccentricity in the absence of a unique
natural definition of eccentricity in general relativity, which can result in
incompatible eccentricity measurements. In this paper, we present a standard
definition of eccentricity and mean anomaly based solely on waveform
quantities. This definition is free of gauge ambiguities, has the correct
Newtonian limit, and can be applied as a postprocessing step when comparing
eccentricity measurements from different models. This standardization puts all
models and simulations on the same footing and enables direct comparisons
between eccentricity estimates from gravitational wave observations and
astrophysical predictions. We demonstrate the applicability of our definition
for waveforms of different origins, including post-Newtonian theory, effective
one body, extreme mass ratio inspirals, and numerical relativity simulations.
We focus on binaries without spin-precession in this work, but possible
generalizations to spin-precessing binaries are discussed. We make our
implementation publicly available through an easy-to-use Python package,
gw_eccentricity.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:10:45 GMT""}]","2023-02-23"
"2302.11258","Jale Basten","Jale Basten, Katja Ickstadt, Nina Timmesfeld","Bias through time-varying covariates in the analysis of cohort stepped
  wedge trials: a simulation study",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  In stepped wedge cluster randomized trials (SW-CRTs), observations collected
under the control condition are, on average, from an earlier time than
observations collected under the intervention condition. In a cohort design,
participants are followed up throughout the study, so correlations between
measurements within a participant are dependent of the timing in which the
observations are made. Therefore, changes in participants' characteristics over
time must be taken into account when estimating intervention effects. For
example, participants' age progresses, which may impact the outcome over the
study period. Motivated by an SW-CRT of a geriatric care intervention to
improve quality of life, we conducted a simulation study to compare model
formulations analysing data from an SW-CRT under different scenarios in which
time was related to the covariates and the outcome. The aim was to find a model
specification that produces reliable estimates of the intervention effect. Six
linear mixed effects (LME) models with different specification of fixed effects
were fitted. Across 1000 simulations per parameter combination, we computed
mean and standard error of the estimated intervention effects. We found that
LME models with fixed categorical time effects additional to the fixed
intervention effect and two random effects used to account for clustering
(within-cluster correlation) and multiple measurements on participants
(within-individual correlation) seem to produce unbiased estimates of the
intervention effect even if time-varying confounders or their functional
influence on outcome were unknown or unmeasured and if secular time trends
occurred. Therefore, including (time-varying) covariates describing the study
cohort seems to be avoidable.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:11:33 GMT""}]","2023-02-23"
"2302.11259","Stefan Kollmannsberger","Stefan Kollmannsberger, Divya Singh and Leon Herrmann","Transfer Learning Enhanced Full Waveform Inversion","7 pages, 5 figures",,,,"cs.LG physics.comp-ph physics.geo-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We propose a way to favorably employ neural networks in the field of
non-destructive testing using Full Waveform Inversion (FWI). The presented
methodology discretizes the unknown material distribution in the domain with a
neural network within an adjoint optimization. To further increase efficiency
of the FWI, pretrained neural networks are used to provide a good starting
point for the inversion. This reduces the number of iterations in the Full
Waveform Inversion for specific, yet generalizable settings.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:12:07 GMT""}]","2023-02-23"
"2302.11260","Shin-Ichiro Nagahiro","Shin-ichiro Nagahiro and Yoshinori Hayakawa","Inverse Magnus Effect Induced by Dilute Water Fog","7 pages, 9 figures, 1 table",,,,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The inverse Magnus effect is a phenomenon in which a spinning sphere
experiences a lift force opposite to the conventional Magnus effect. This
effect is typically observed in the flow higher than a critical Reynolds number
or spin ratio. We experimentally studied the inverse Magnus effect on a
spinning sphere in a flow containing suspended micrometer size droplets. The
lift force was measured by injecting droplets into a closed return wind tunnel.
We investigated the threshold of the inverse Magnus effect for several types of
dispersed droplets. Our results indicate that the flow with suspended water
droplets significantly affects the onset of the inverse Magnus effect, causing
a decrease in the critical Reynolds number and spin ratio.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:12:51 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 02:52:18 GMT""},{""version"":""v3"",""created"":""Wed, 7 Jun 2023 07:45:45 GMT""}]","2023-06-08"
"2302.11261","Maximilian Ammer","Maximilian Ammer, Stephan Durr","Calculation of $c_\mathrm{SW}$ at one-loop order for Brillouin fermions","23 pages, 6 figures, 10 tables",,,,"hep-lat","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Brillouin action is a Wilson-like lattice fermion action with a 81-point
stencil, which was found to ameliorate the Wilson action in many respects. The
Sheikholeslami-Wohlert coefficient $c_\mathrm{SW}$ of the clover improvement
term has a perturbative expansion
$c_\mathrm{SW}=c_\mathrm{SW}^{(0)}+g_0^2c_\mathrm{SW}^{(1)}+\mathcal{O}(g_0^4)$.
At tree-level $c_\mathrm{SW}^{(0)}=r$ holds for Wilson and Brillouin fermions
alike. We present the Feynman rules for the Brillouin action in lattice
perturbation theory, and employ them to calculate the one-loop coefficient
$c_\mathrm{SW}^{(1)}$ with plaquette or L\""uscher-Weisz gluons. Numerically its
value is found to be about half that of the Wilson action.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:14:03 GMT""}]","2023-02-23"
"2302.11262","Ori Grossman","Ori Grossman and Erez Berg","Unavoidable Fermi liquid instabilities in sign problem-free models","4 pages + 3 appendix",,,,"cond-mat.str-el cond-mat.stat-mech physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Determinant Quantum Monte Carlo (DQMC) is a powerful numerical technique to
study many-body fermionic systems. In recent years, several classes of
sign-free (SF) models have been discovered, where the notorious sign problem
can be circumvented. However, it is not clear what are the inherent physical
characteristics and limitations of SF models. In particular, which
zero-temperature quantum phases of matter are accessible within such models,
and which are fundamentally inaccessible? Here, we show that a model of any of
the known SF classes within DQMC cannot have a stable Fermi liquid ground state
in spatial dimension $d\ge 2$. For SF models belonging to one of the symmetry
classes (where the absence of the sign problem follows from a combination of
non-unitary symmetries of the fermionic action), any putative Fermi liquid
fixed point generically includes an attractive Cooper-like interaction that
destabilizes it. In the recently discovered lower-symmetry classes of SF
models, the Fermi surface is generically unstable even at the level of the
quadratic action. Our results suggest a fundamental link between Fermi liquids
and the fermion sign problem.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:17:04 GMT""}]","2023-02-23"
"2302.11263","Tomoki Omama","Tomoki Omama, Masahiro Tsujimoto, Ken Ebisawa, Misaki Mizumoto","X-ray time lag evaluation of MAXI J1820+070 with a differential
  cross-correlation analysis","12 pages, 12 figures",,"10.3847/1538-4357/acba00",,"astro-ph.HE astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MAXI J1820$+$070 is a transient black hole binary (BHB) discovered on 2018
March 11. The unprecedented rich statistics brought by the NICER X-ray
telescope allows detailed timing analysis up to $\sim$1~kHz uncompromised by
the photon shot noise. To estimate the time lags, the Fourier analysis was
applied, which led to two different conclusions for the system configuration;
one supporting the lamp-post configuration with a stable accretion disk
extending close to the innermost stable circular orbit and the other supporting
the truncated accretion disk contracting with time. Using the same data set, we
present the results based on the cross-correlation function (CCF). The CCF is
calculated between two different X-ray bands and one side is subtracted from
the other side, which we call the differential CCF (dCCF). The soft and hard
lags respectively of $\sim$0.03 and 3~s are clearly identified without being
diluted by the spectral mixture, demonstrating the effectiveness of the dCCF
analysis. The evolution of these lags is tracked, along with spectral changes
for the first 120~days since the discovery. Both the dCCF and spectral fitting
results are interpreted that the soft lag is a reverberation lag between the
Comptonized emission and the soft excess emission and that the hard lag is
between the disk black body emission and the Comptonized emission. The
evolution of these lags is in line with the picture of the truncated disk
contracting with time.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:19:35 GMT""}]","2023-03-15"
"2302.11264","Jesse van Rhijn","Bodo Manthey and Jesse van Rhijn","Approximation Ineffectiveness of a Tour-Untangling Heuristic","12 pages, 4 figures",,,,"cs.DS cs.DM math.PR","http://creativecommons.org/licenses/by/4.0/","  We analyze a tour-uncrossing heuristic for the Travelling Salesperson
Problem, showing that its worst-case approximation ratio is $\Omega(n)$ and its
average-case approximation ratio is $\Omega(\sqrt{n})$ in expectation. We
furthermore evaluate the approximation performance of this heuristic
numerically on average-case instances, and find that it performs far better
than the average-case lower bound suggests. This indicates a shortcoming in the
approach we use for our analysis, which is a rather common approach in the
analysis of local search heuristics.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:22:18 GMT""},{""version"":""v2"",""created"":""Mon, 1 May 2023 15:01:14 GMT""}]","2023-05-02"
"2302.11265","Daniel Clarkson","Daniel L. Clarkson, Eduard P. Kontar, Nicole Vilmer, Mykola
  Gordovskyy, Xingyao Chen, Nicolina Chrysaphi","Solar Radio Spikes and Type IIIb Striae Manifestations of Sub-second
  Electron Acceleration Triggered by a Coronal Mass Ejection","Accepted for publication in the Astrophysical Journal (on 16 Feb
  2023), 17 pages, 15 figures","ApJ, 946, 33 (2023)","10.3847/1538-4357/acbd3f",,"astro-ph.SR physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  Understanding electron acceleration associated with magnetic energy release
at sub-second scales presents a major challenges in solar physics. Solar radio
spikes observed as sub-second, narrow bandwidth bursts with
$\Delta{f}/f\sim10^{-3}-10^{-2}$ are indicative of sub-second evolution of the
electron distribution. We present a statistical analysis of frequency, and
time-resolved imaging of individual spikes and Type IIIb striae associated with
a coronal mass ejection (CME). LOFAR imaging reveals that co-temporal ($<2$ s)
spike and striae intensity contours almost completely overlap. On average, both
burst types have similar source size with fast expansion at millisecond scales.
The radio source centroid velocities are often superluminal, and independent of
frequency over 30-45 MHz. The CME perturbs the field geometry, leading to
increased spike emission likely due to frequent magnetic reconnection. As the
field restores towards the prior configuration, the observed sky-plane emission
locations drift to increased heights over tens of minutes. Combined with
previous observations above 1 GHz, average decay time and source size estimates
follow $\sim1/f$ dependency over three decades in frequency, similar to
radio-wave scattering predictions. Both time and spatial characteristics of the
bursts between 30-70 MHz are consistent with radio-wave scattering with strong
anisotropy of the density fluctuation spectrum. Consequently, the site of
radio-wave emission does not correspond to the observed burst locations and
implies acceleration and emission near the CME flank. The bandwidths suggest
intrinsic emission source sizes $<1$ arcsec at 30 MHz, and magnetic field
strengths a factor of two larger than average in events that produce decameter
spikes.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:25:30 GMT""}]","2023-04-06"
"2302.11266","Sean MacAvaney","Sean MacAvaney, Luca Soldaini","One-Shot Labeling for Automatic Relevance Estimation",,,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dealing with unjudged documents (""holes"") in relevance assessments is a
perennial problem when evaluating search systems with offline experiments.
Holes can reduce the apparent effectiveness of retrieval systems during
evaluation and introduce biases in models trained with incomplete data. In this
work, we explore whether large language models can help us fill such holes to
improve offline evaluations. We examine an extreme, albeit common, evaluation
setting wherein only a single known relevant document per query is available
for evaluation. We then explore various approaches for predicting the relevance
of unjudged documents with respect to a query and the known relevant document,
including nearest neighbor, supervised, and prompting techniques. We find that
although the predictions of these One-Shot Labelers (1SLs) frequently disagree
with human assessments, the labels they produce yield a far more reliable
ranking of systems than the single labels do alone. Specifically, the strongest
approaches can consistently reach system ranking correlations of over 0.85 with
the full rankings over a variety of measures. Meanwhile, the approach
substantially reduces the false positive rate of t-tests due to holes in
relevance assessments (from 15-30% down to under 5%), giving researchers more
confidence in results they find to be significant.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:25:54 GMT""}]","2023-02-23"
"2302.11267","C. Jess Riedel","Daniel Ranard and C. Jess Riedel","A spin-energy operator inequality for Heisenberg-coupled qubits","8 pages single column",,,,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We slightly strengthen an operator inequality identified by Correggi et al.
that lower bounds the energy of a Heisenberg-coupled graph of $s=1/2$ spins
using the total spin. In particular, $\Delta H \ge C \Delta\vec{S}^2$ for a
graph-dependent constant $C$, where $\Delta H$ is the energy above the ground
state and $\Delta\vec{S}^2$ is the amount by which the square of the total spin
$\vec{S} = \sum_i \vec{\sigma}_i/2$ falls below its maximum possible value. We
obtain explicit constants in the special case of a cubic lattice. We briefly
discuss the interpretation of this bound in terms of low-energy, approximately
non-interacting magnons in spin wave theory and contrast it with another
inequality found by B\""arwinkel et al.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:29:00 GMT""}]","2023-02-23"
"2302.11268","Marco Giordani","Filippo Bragato, Tommaso Lotta, Gianmaria Ventura, Matteo Drago,
  Federico Mason, Marco Giordani, Michele Zorzi","Towards Decentralized Predictive Quality of Service in Next-Generation
  Vehicular Networks","This paper has been accepted for publication at IEEE Information
  Theory and Applications Workshop (ITA), 2023",,,,"cs.NI cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To ensure safety in teleoperated driving scenarios, communication between
vehicles and remote drivers must satisfy strict latency and reliability
requirements. In this context, Predictive Quality of Service (PQoS) was
investigated as a tool to predict unanticipated degradation of the Quality of
Service (QoS), and allow the network to react accordingly. In this work, we
design a reinforcement learning (RL) agent to implement PQoS in vehicular
networks. To do so, based on data gathered at the Radio Access Network (RAN)
and/or the end vehicles, as well as QoS predictions, our framework is able to
identify the optimal level of compression to send automotive data under low
latency and reliability constraints. We consider different learning schemes,
including centralized, fully-distributed, and federated learning. We
demonstrate via ns-3 simulations that, while centralized learning generally
outperforms any other solution, decentralized learning, and especially
federated learning, offers a good trade-off between convergence time and
reliability, with positive implications in terms of privacy and complexity.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:35:00 GMT""}]","2023-02-23"
"2302.11269","Song Duong","Song Duong, Alberto Lumbreras, Mike Gartrell, Patrick Gallinari","Learning from Multiple Sources for Data-to-Text and Text-to-Data","AISTATS 2023",,,,"cs.LG cs.AI cs.CL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data-to-text (D2T) and text-to-data (T2D) are dual tasks that convert
structured data, such as graphs or tables into fluent text, and vice versa.
These tasks are usually handled separately and use corpora extracted from a
single source. Current systems leverage pre-trained language models fine-tuned
on D2T or T2D tasks. This approach has two main limitations: first, a separate
system has to be tuned for each task and source; second, learning is limited by
the scarcity of available corpora. This paper considers a more general scenario
where data are available from multiple heterogeneous sources. Each source, with
its specific data format and semantic domain, provides a non-parallel corpus of
text and structured data. We introduce a variational auto-encoder model with
disentangled style and content variables that allows us to represent the
diversity that stems from multiple sources of text and data. Our model is
designed to handle the tasks of D2T and T2D jointly. We evaluate our model on
several datasets, and show that by learning from multiple sources, our model
closes the performance gap with its supervised single-source counterpart and
outperforms it in some cases.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:39:33 GMT""}]","2023-02-23"
"2302.11270","Christian Seifert","Christian Budde and Christian Seifert","Perturbations of non-autonomous second-order abstract Cauchy problems","15 pages",,,,"math.FA math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper we present time-dependent perturbations of second-order
non-autonomous abstract Cauchy problems associated to a family of operators
with constant domain. We make use of the equivalence to a first-order
non-autonomous abstract Cauchy problem in a product space, which we elaborate
in full detail. As an application we provide a perturbed non-autonomous wave
equation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:41:21 GMT""}]","2023-02-23"
"2302.11271","Eusebio J. Rodr\'iguez","E. J. Rodr\'iguez, A. A. Reynoso, J. P. Baltan\'as, J. Nitta and D.
  Frustaglia","Magnetic switching of spin-scattering centers in Dresselhaus [110]
  circuits","11 pages, 6 figures",,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin carriers subject to Dresselhaus [110] (D110) spin-orbit coupling (SOC)
gather null spin phases in closed circuits, contrary to usual Rashba and
Dresselhaus [001] SOC. We show that D110 spin phases can be activated in square
circuits by introducing an in-plane Zeeman field, where localized field
inhomogeneities act as effective spin-scattering centers. Our simulations show
rich interference patterns in the quantum conductance, which work as maps for a
geometric classification of the propagating spin states. We also find that
disorder allows for valuable low-field implementations.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:43:50 GMT""}]","2023-02-23"
"2302.11272","Felix Stutz","Felix Stutz","Asynchronous Multiparty Session Type Implementability is Decidable --
  Lessons Learned from Message Sequence Charts","25 pages, 41 pages including appendix; to appear in ECOOP 2023",,,,"cs.FL cs.DC cs.PL","http://creativecommons.org/licenses/by/4.0/","  Multiparty session types (MSTs) provide efficient means to specify and verify
asynchronous message-passing systems. For a global type, which specifies all
interactions between roles in a system, the implementability problem asks
whether there are local specifications for all roles such that their
composition is deadlock-free and generates precisely the specified executions.
Decidability of the implementability problem is an open question. We answer it
positively for global types with sender-driven choice, which allow a sender to
send to different receivers upon branching and a receiver to receive from
different senders. To achieve this, we generalise results from the domain of
high-level message sequence charts (HMSCs). This connection also allows us to
comprehensively investigate how HMSC techniques can be adapted to the MST
setting. This comprises techniques to make the problem algorithmically more
tractable as well as a variant of implementability that may open new design
space for MSTs. Inspired by potential performance benefits, we introduce a
generalisation of the implementability problem that we, unfortunately, prove to
be undecidable.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:45:35 GMT""},{""version"":""v2"",""created"":""Wed, 7 Jun 2023 15:47:51 GMT""}]","2023-06-08"
"2302.11273","Takeru Yokota","Takeru Yokota, Yuta Ito, Hideo Matsufuru, Yusuke Namekawa, Jun
  Nishimura, Asato Tsuchiya, Shoichiro Tsutsui","Color superconductivity on the lattice -- analytic predictions from QCD
  in a small box","30 pages, 15 figures, 1 table, v2: A.3 modified, Ref. [57] added",,,"RIKEN-iTHEMS-Report-23, KEK-TH-2496","hep-lat hep-th","http://creativecommons.org/licenses/by/4.0/","  We investigate color superconductivity on the lattice using the gap equation
for the Cooper pair condensate. The weak coupling analysis is justified by
choosing the physical size of the lattice to be smaller than the QCD scale,
while keeping the aspect ratio of the lattice small enough to suppress thermal
excitations. In the vicinity of the critical coupling constant that separates
the superconducting phase and the normal phase, the gap equation can be
linearized, and by solving the corresponding eigenvalue problem, we obtain the
critical point and the Cooper pair condensate without assuming its explicit
form. The momentum components of the condensate suggest spatially isotropic
s-wave superconductivity with Cooper pairs formed by quarks near the Fermi
surface. The chiral symmetry in the massless limit is spontaneously broken by
the Cooper pair condensate, which turns out to be dominated by the scalar and
the pseudo-scalar components. Our results provide useful predictions, in
particular, for future lattice simulations based on methods to overcome the
sign problem such as the complex Langevin method.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:47:41 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 09:50:54 GMT""}]","2023-03-06"
"2302.11274","Pawan Kumar Gupta","Pawan Kumar Gupta, Jan Steinhoff, Tanja Hinderer","Effect of dynamical gravitomagnetic tides on measurability of tidal
  parameters for binary neutron stars using gravitational waves","20 pages, 14 figures",,,,"gr-qc astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Gravitational waves (GWs) from binary neutron stars (NSs) have opened unique
opportunities to constrain the nuclear equation of state by measuring tidal
effects associated with the excitation of characteristic modes of the NSs. This
includes gravitomagnetic modes associated with the Coriolis effect, whose
frequencies are proportional to the NS's spin frequency, and for which the spin
orientation determines the subclass of modes that are predominantly excited. We
advance the GW models for these effects that are needed for data analysis by
first developing a description for the adiabatic signatures from
gravitomagnetic modes in slowly rotating NSs. We show that they can be
encapsulated in an effective Love number which differs before and after a mode
resonance. Combining this with a known generic model for abrupt changes in the
GWs at the mode resonance and a point-mass baseline leads to an efficient
description which we use to perform case studies of the impacts of
gravitomagnetic effects for measurements with Cosmic Explorer, an envisioned
next-generation GW detector. We quantify the extent to which neglecting
(including) the effect of gravitomagnetic modes induces biases (significantly
reduces statistical errors) in the measured tidal deformability parameters,
which depend on the equation of state. Our results substantiate the importance
of dynamical gravitomagnetic tidal effects for measurements with third
generation detectors.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:47:52 GMT""}]","2023-02-23"
"2302.11275","Abhishek Ghosh","Abhishek Ghosh, Michael Ruzhansky","Sparse bounds for oscillating multipliers on stratified groups",,,,,"math.CA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we address sparse bounds for a class of spectral multipliers
that include oscillating multipliers on stratified Lie groups. Our results can
be applied to obtain weighted bounds for general Riesz means and for solutions
of dispersive equations.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:48:10 GMT""}]","2023-02-23"
"2302.11276","Yongyun Chen","Chen Yongyun, Gu Qiusheng, Fan Junhui, Yu Xiaoling, Ding Nan, Xiong
  Dingrong, Guo Xiaotong","Curvature of the spectral energy distribution, Compton dominance and
  synchrotron peak frequency in jetted AGNs","14 pages, 7 figures, accept for publication in ApJ. arXiv admin note:
  text overlap with arXiv:2202.07490 by other authors",,,,"astro-ph.HE astro-ph.GA","http://creativecommons.org/licenses/by/4.0/","  We collect a large sample with a reliable redshift detected by the Fermi
satellite after 10 years of data (4FGL-DR2), including blazars, $\gamma$-ray
Narrow-line Seyfert 1 galaxies ($\gamma$NLS1s), and radio galaxies. The
spectral energy distributions (SEDs) of these Fermi sources are fitted by using
a second-degree polynomial, and some important parameters including spectral
curvature, synchrotron peak frequency, and peak luminosity are obtained. Based
on those parameters, we discuss the Fermi blazar sequence and the particle
acceleration mechanism. Our main results are as follows:(i) By studying the
relationship between the synchrotron peak frequency and the synchrotron peak
frequency luminosity, jet kinetic power, and $\gamma$-ray luminosity for jetted
AGNs, we find an ``L'' shape in the Fermi blazar sequence. (ii) There is a
significant anti-correlation between Compton dominance, black hole spin, and
the synchrotron peak frequency for jetted AGNs, respectively. These results
support that the $\gamma$NLS1s and radio galaxies belong to the Fermi blazar
sequence. (iii) On the basis of previous work, statistical or stochastic
acceleration mechanisms can be used to explain the relationship between
synchrotron peak frequency and synchrotron curvature. For different subclasses,
the correlation slopes are different, which implies that the Fermi sources of
different subclasses have different acceleration mechanisms. (iv) The FSRQs and
$\gamma$NLS1s have a higher median spin of a black hole than BL Lacs and radio
galaxies.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:49:23 GMT""}]","2023-02-23"
"2302.11277","Yannick Oswald","Yannick Oswald, Nick Malleson, Keiran Suchak","An agent-based model of the 2020 international policy diffusion in
  response to the COVID-19 pandemic with particle filter",,,,,"cs.MA physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global problems, such as pandemics and climate change, require rapid
international coordination and diffusion of policy. These phenomena are rare
however, with one notable example being the international policy response to
the COVID-19 pandemic in early 2020. Here we build an agent-based model of this
rapid policy diffusion, where countries constitute the agents and with the
principal mechanism for diffusion being peer mimicry. Since it is challenging
to predict accurately the policy diffusion curve, we utilize data assimilation,
that is an ``on-line'' feed of data to constrain the model against
observations. The specific data assimilation algorithm we apply is a particle
filter because of its convenient implementation, its ability to handle
categorical variables and because the model is not overly computationally
expensive, hence a more efficient algorithm is not required. We find that the
model alone is able to predict the policy diffusion relatively well with an
ensemble of at least 100 simulation runs. The particle filter however improves
the fit to the data, reliably so from 500 runs upwards, and increasing
filtering frequency results in improved prediction.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:52:48 GMT""}]","2023-02-23"
"2302.11278","Zhun Lu","Xiaoyan Luan and Zhun Lu","Generalized parton distributions of sea quark at zero skewness in the
  light-cone Model","8 pages, 5 figures",,,,"hep-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  We study the chiral-even generalized parton distributions (GPDs) of $\bar{u}$
and $\bar{d}$ quarks at zero skewness using the overlap representation within
the light cone formalism. The GPDs of $\bar{u}$ and $\bar{d}$ quarks can be
expressed as the convolution of the light cone wave functions which are
obtained from the baryon-meson fluctuation model in terms of the
$|q\bar{q}B\rangle$ Fock states. We present the numerical results for
$H^{\bar{u}/P}(x,\xi,\Delta^2)$, $H^{\bar{d}/P}(x,\xi,\Delta^2)$,
$E^{\bar{u}/P}(x,\xi,\Delta^2)$ and $E^{\bar{d}/P}(x,\xi,\Delta^2)$. We apply
the model resulting GPDs to calculate the orbital angular momentum of the
$\bar{u}$ and $\bar{d}$ quarks, showing that $L^{\bar{u}/P}$, $L^{\bar{d}/P}$
are positive and $L^{\bar{u}/P}$ is smaller than $L^{\bar{d}/P}$. The sea quark
OAM distributions in the impact parameter space
$L_{\bar{q}}(x,\boldsymbol{b_T})$ are also calculated.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:57:08 GMT""}]","2023-02-23"
"2302.11279","Alexander Rieder","Markus Faustmann and Alexander Rieder","FEM-BEM coupling in Fractional Diffusion",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  We derive and analyze a fully computable discrete scheme for fractional
partial differential equations posed on the full space $\mathbb{R}^d$ . Based
on a reformulation using the well-known Caffarelli-Silvestre extension, we
study a modified variational formulation to obtain well-posedness of the
discrete problem. Our scheme is obtained by combining a diagonalization
procedure with a reformulation using boundary integral equations and a coupling
of finite elements and boundary elements. For our discrete method we present
a-priori estimates as well as numerical examples.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:57:17 GMT""}]","2023-02-23"
"2302.11280","Donghuo Zeng","Donghuo Zeng, Jianming Wu, Yanan Wang, Kazunori Matsumoto, Gen
  Hattori, Kazushi Ikeda","Topic-switch adapted Japanese Dialogue System based on PLATO-2","10 pages, 8 figures, 7 tables",,,,"cs.CL cs.MM","http://creativecommons.org/licenses/by-sa/4.0/","  Large-scale open-domain dialogue systems such as PLATO-2 have achieved
state-of-the-art scores in both English and Chinese. However, little work
explores whether such dialogue systems also work well in the Japanese language.
In this work, we create a large-scale Japanese dialogue dataset,
Dialogue-Graph, which contains 1.656 million dialogue data in a tree structure
from News, TV subtitles, and Wikipedia corpus. Then, we train PLATO-2 using
Dialogue-Graph to build a large-scale Japanese dialogue system, PLATO-JDS. In
addition, to improve the PLATO-JDS in the topic switch issue, we introduce a
topic-switch algorithm composed of a topic discriminator to switch to a new
topic when user input differs from the previous topic. We evaluate the user
experience by using our model with respect to four metrics, namely, coherence,
informativeness, engagingness, and humanness. As a result, our proposed
PLATO-JDS achieves an average score of 1.500 for the human evaluation with
human-bot chat strategy, which is close to the maximum score of 2.000 and
suggests the high-quality dialogue generation capability of PLATO-2 in
Japanese. Furthermore, our proposed topic-switch algorithm achieves an average
score of 1.767 and outperforms PLATO-JDS by 0.267, indicating its effectiveness
in improving the user experience of our system.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:57:59 GMT""}]","2023-02-23"
"2302.11281","Erwann Bocquillon","Alexandre Gourmelon, Elric Frigerio, Hiroshi Kamata, Lukas Lunczer,
  Anne Denis, Pascal Morfin, Michael Rosticher, Jean-Marc Berroir, Gwendal
  F\`eve, Bernard Pla\c{c}ais, Hartmut Buhmann, Laurens W. Molenkamp, Erwann
  Bocquillon","Velocity and confinement of edge plasmons in HgTe-based 2D topological
  insulators","8 pages, 6 figures, + supplementary material",,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  High-frequency transport in the edge states of the quantum spin Hall (QSH)
effect has to date rarely been explored, though it could cast light on the
scattering mechanisms taking place therein. We here report on the measurement
of the plasmon velocity in topological HgTe quantum wells both in the QSH and
quantum Hall (QH) regimes, using harmonic GHz excitations and phase-resolved
detection. We observe low plasmon velocities corresponding to large transverse
widths, which we ascribe to the prominent influence of charge puddles forming
in the vicinity of edge channels. Together with other recent works, it suggests
that puddles play an essential role in the edge state physics and probably
constitute a main hurdle on the way to clean and robust edge transport.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:58:00 GMT""}]","2023-02-23"
"2302.11282","Md Zia Ullah","Josiane Mothe and Md Zia Ullah","Effectiveness and Efficiency Trade-off in Selective Query Processing","5",,,,"cs.IR","http://creativecommons.org/licenses/by/4.0/","  Query processing in search engines can be optimized for use for all queries.
For this, system component parameters such as the weighting function or the
automatic query expansion model can be optimized or learned from past queries.
However, it may be more interesting to optimize the processing thread on a
query-by-query basis by adjusting the component parameters; this is what
selective query processing does. Selective query processing uses one of the
candidate processing threads chosen at query time. The choice is based on query
features. In this paper, we examine selective query processing in different
settings, both in terms of effectiveness and efficiency; this includes
selective query expansion and other forms of selective query processing (e.g.,
when the term weighting function varies or when the expansion model varies). We
found that the best trade-off between effectiveness and efficiency is obtained
when using the best trained processing thread and its query expansion counter
part. This seems to be also the most natural for a real-word engine since the
two threads use the same core engine (e.g., same term weighting function).
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:59:35 GMT""}]","2023-02-23"
"2302.11283","Yu Guo","Yu Guo, Ryan Wen Liu, Jingxiang Qu, Yuxu Lu, Fenghua Zhu, Yisheng Lv","Asynchronous Trajectory Matching-Based Multimodal Maritime Data Fusion
  for Vessel Traffic Surveillance in Inland Waterways",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  The automatic identification system (AIS) and video cameras have been widely
exploited for vessel traffic surveillance in inland waterways. The AIS data
could provide the vessel identity and dynamic information on vessel position
and movements. In contrast, the video data could describe the visual
appearances of moving vessels, but without knowing the information on identity,
position and movements, etc. To further improve vessel traffic surveillance, it
becomes necessary to fuse the AIS and video data to simultaneously capture the
visual features, identity and dynamic information for the vessels of interest.
However, traditional data fusion methods easily suffer from several potential
limitations, e.g., asynchronous messages, missing data, random outliers, etc.
In this work, we first extract the AIS- and video-based vessel trajectories,
and then propose a deep learning-enabled asynchronous trajectory matching
method (named DeepSORVF) to fuse the AIS-based vessel information with the
corresponding visual targets. In addition, by combining the AIS- and
video-based movement features, we also present a prior knowledge-driven
anti-occlusion method to yield accurate and robust vessel tracking results
under occlusion conditions. To validate the efficacy of our DeepSORVF, we have
also constructed a new benchmark dataset (termed FVessel) for vessel detection,
tracking, and data fusion. It consists of many videos and the corresponding AIS
data collected in various weather conditions and locations. The experimental
results have demonstrated that our method is capable of guaranteeing
high-reliable data fusion and anti-occlusion vessel tracking.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:00:34 GMT""}]","2023-02-23"
"2302.11284","Gioana Teora","Stefano Berrone and Gioana Teora and Fabio Vicini","Improving high-order VEM stability on badly-shaped elements",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  For the 2D and 3D Virtual Element Methods (VEM), a new approach to improve
the conditioning of local and global matrices in the presence of badly-shaped
polytopes is proposed. It defines the local projectors and the local degrees of
freedom with respect to a set of scaled monomials recomputed on more
well-shaped polytopes. This new approach is less computationally demanding than
using the orthonormal polynomial basis. The effectiveness of our procedure is
tested on different numerical examples characterized by challenging geometries
of increasing complexity.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:00:54 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 13:09:40 GMT""}]","2023-04-04"
"2302.11285","Simone Mender","Simone Mender, Lena Linhoff, Tarek Hassan, Cosimo Nigro, Dominik
  Els\""asser (for the MAGIC collaboration)","Computing sky maps using the open-source package Gammapy and MAGIC data
  in a standardized format","6 pages, 6 figures, Proceedings of the 7th Heidelberg International
  Symposium on High-Energy Gamma-Ray Astronomy, PoS(Gamma2022)215",,,,"astro-ph.IM astro-ph.HE","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The open-source Python package Gammapy, developed for the high-level analysis
of gamma-ray data, requires gamma-like event lists combined with the
corresponding instrument response functions. For a morphological analysis,
these data have to include a background acceptance model. Here we report an
approach to generate such a model for the MAGIC telescope data, accounting for
the azimuth and zenith dependencies of the MAGIC background acceptance. We
validate this method using observations of the Crab Nebula with different
offsets from the pointing position.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:03:24 GMT""}]","2023-02-23"
"2302.11286","Marine Collery","Marine Collery, Philippe Bonnard, Fran\c{c}ois Fages and Remy Kusters","Neural-based classification rule learning for sequential data","Published as a conference paper at ICLR 2023",,,,"cs.LG cs.AI","http://creativecommons.org/licenses/by/4.0/","  Discovering interpretable patterns for classification of sequential data is
of key importance for a variety of fields, ranging from genomics to fraud
detection or more generally interpretable decision-making. In this paper, we
propose a novel differentiable fully interpretable method to discover both
local and global patterns (i.e. catching a relative or absolute temporal
dependency) for rule-based binary classification. It consists of a
convolutional binary neural network with an interpretable neural filter and a
training strategy based on dynamically-enforced sparsity. We demonstrate the
validity and usefulness of the approach on synthetic datasets and on an
open-source peptides dataset. Key to this end-to-end differentiable method is
that the expressive patterns used in the rules are learned alongside the rules
themselves.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:05:05 GMT""}]","2023-02-23"
"2302.11287","Cleon Barroso S.","Cleon S. Barroso","Remarks on the FPP in Banach spaces with unconditional Schauder basis","All comments welcome",,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents new results on the FPP in Banach spaces with a Schauder
basis. We focus on the open problem of determining whether there is a Banach
space isomorphic to $\co$ with the FPP. We first show that if $X$ is a Banach
space with a pre-monotone basic sequence equivalent to the unit basis of $\co$,
then it fails the FPP for nonexpansive maps. We then highlight sufficient
conditions ensuring the existence of such sequences. Several interesting
results are obtained. As e.g., it is proved that if $X$ has a $1$-suppression
unconditional basis and fails the PCP, then $X$ fails the FPP. In addition, new
fixed-point results related to the weak-FPP are also obtained.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:10:44 GMT""}]","2023-02-23"
"2302.11288","William Pearson","W. J. Pearson, L. E. Suelves, S. C. -C. Ho, N. Oi, NEP Team and GAMA
  Team","Pitfalls of AI classification of rare objects: Galaxy Mergers","4 pages, 3 figures, proceedings for EAS 2022 S11, to be published in
  Memorie della SAIt",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galaxy mergers are hugely important in our current dark matter cosmology.
These powerful events cause the disruption of the merging galaxies, pushing the
gas, stars and dust of the galaxies resulting in changes to morphologies. This
disruption can also cause more extreme events inside the galaxies: periods of
extreme star formation rates and the rapid increase in active galactic nuclei
activity. Hence, to better understand what goes on in these rare events, we
need to be able to identify statistically large samples.
  In the last few years, the growth of artificial intelligence techniques has
seen application to identifying galaxy mergers. These techniques have shown to
be highly accurate and their application has grown beyond academic studies of
``can we?'' to deeper scientific use. However, these classifications are not
without their problems.
  In this proceedings, we will explore how galaxy merger classification can be
improved by adding pre-extracted galaxy morphologies alongside the traditional
imaging data. This demonstrates that current neural networks are not extracting
all the information from the images they are given. It will also explore how
the resulting samples of rare objects could be highly contaminated. This has a
knock on impact on the upcoming large scale surveys like Euclid and Rubin-LSST.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:13:32 GMT""}]","2023-02-23"
"2302.11289","Guangyuan Shi","Guangyuan Shi, Qimai Li, Wenlong Zhang, Jiaxin Chen, Xiao-Ming Wu","Recon: Reducing Conflicting Gradients from the Root for Multi-Task
  Learning","Accepted as a conference paper at ICLR 2023",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fundamental challenge for multi-task learning is that different tasks may
conflict with each other when they are solved jointly, and a cause of this
phenomenon is conflicting gradients during optimization. Recent works attempt
to mitigate the influence of conflicting gradients by directly altering the
gradients based on some criteria. However, our empirical study shows that
``gradient surgery'' cannot effectively reduce the occurrence of conflicting
gradients. In this paper, we take a different approach to reduce conflicting
gradients from the root. In essence, we investigate the task gradients w.r.t.
each shared network layer, select the layers with high conflict scores, and
turn them to task-specific layers. Our experiments show that such a simple
approach can greatly reduce the occurrence of conflicting gradients in the
remaining shared layers and achieve better performance, with only a slight
increase in model parameters in many cases. Our approach can be easily applied
to improve various state-of-the-art methods including gradient manipulation
methods and branched architecture search methods. Given a network architecture
(e.g., ResNet18), it only needs to search for the conflict layers once, and the
network can be modified to be used with different methods on the same or even
different datasets to gain performance improvement. The source code is
available at https://github.com/moukamisama/Recon.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:14:16 GMT""}]","2023-02-23"
"2302.11290","Tim Seppelt","Tim Seppelt","Logical Equivalences, Homomorphism Indistinguishability, and Forbidden
  Minors","26 pages, 1 figure, 1 table",,,,"math.CO cs.CC cs.DM cs.LO","http://creativecommons.org/licenses/by-sa/4.0/","  Two graphs $G$ and $H$ are homomorphism indistinguishable over a class of
graphs $\mathcal{F}$ if for all graphs $F \in \mathcal{F}$ the number of
homomorphisms from $F$ to $G$ is equal to the number of homomorphisms from $F$
to $H$. Many natural equivalence relations comparing graphs such as (quantum)
isomorphism, spectral, and logical equivalences can be characterised as
homomorphism indistinguishability relations over certain graph classes.
  Abstracting from the wealth of such instances, we show in this paper that
equivalences w.r.t. any self-complementarity logic admitting a characterisation
as homomorphism indistinguishability relation can be characterised by
homomorphism indistinguishability over a minor-closed graph class.
Self-complementarity is a mild property satisfied by most well-studied logics.
This result follows from a correspondence between closure properties of a graph
class and preservation properties of its homomorphism indistinguishability
relation.
  Furthermore, we classify all graph classes which are in a sense finite
(essentially profinite) and satisfy the maximality condition of being
homomorphism distinguishing closed, i.e. adding any graph to the class strictly
refines its homomorphism indistinguishability relation. Thereby, we answer
various question raised by Roberson (2022) on general properties of the
homomorphism distinguishing closure.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:17:40 GMT""},{""version"":""v2"",""created"":""Tue, 2 May 2023 14:03:11 GMT""}]","2023-05-03"
"2302.11291","Yongjie Yang","Yongjie Yang","Complexity of Manipulating and Controlling Approval-Based Multiwinner
  Voting","45pages, 1figure, full version of a paper at IJCAI 2019",,,,"cs.GT","http://creativecommons.org/licenses/by/4.0/","  We investigate the complexity of several manipulation and control problems
under numerous prevalent approval-based multiwinner voting rules. Particularly,
the rules we study include approval voting (AV), satisfaction approval voting
(SAV), net-satisfaction approval voting (NSAV), proportional approval voting
(PAV), approval-based Chamberlin-Courant voting (ABCCV), minimax approval
voting (MAV), etc. We show that these rules generally resist the strategic
types scrutinized in the paper, with only a few exceptions. In addition, we
also obtain many fixed-parameter tractability results for these problems with
respect to several natural parameters, and derive polynomial-time algorithms
for certain special cases.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:20:29 GMT""}]","2023-02-23"
"2302.11292","Keita Emura","Keita Emura and Masato Yoshimi","An End-To-End Encrypted Cache System with Time-Dependent Access Control",,,,,"cs.CR","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Due to the increasing use of encrypted communication, such as Transport Layer
Security (TLS), encrypted cache systems are a promising approach for providing
communication efficiency and privacy. Cache-22 is an encrypted cache system
(Emura et al. ISITA 2020) that makes it possible to significantly reduce
communication between a cache server and a service provider. In the final
procedure of Cache-22, the service provider sends the corresponding decryption
key to the user via TLS and this procedure allows the service provider to
control which users can access the contents. For example, if a user has
downloaded ciphertexts of several episodes of a show, the service provider can
decide to provide some of the contents (e.g., the first episode) available for
free while requiring a fee for the remaining contents. However, no concrete
access control method has been implemented in the original Cache-22 system. In
this paper, we add a scalable access control protocol to Cache-22.
Specifically, we propose a time-dependent access control that requires a
communication cost of $O(\log T_{\sf max})$ where $T_{\sf max}$ is the maximum
time period. Although the protocol is stateful, we can provide time-dependent
access control with scalability at the expense of this key management. We
present experimental results and demonstrate that the modified system is
effective for controlling access rights. We also observe a relationship between
cache capacity and network traffic because the number of duplicated contents is
higher than that in the original Cache-22 system, due to time-dependent access
control.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:25:07 GMT""}]","2023-02-23"
"2302.11293","Mehtaab Sawhney","Ashwin Sah, Mehtaab Sawhney","The intransitive dice kernel: $\frac{\mathbf{1}_{x\ge
  y}-\mathbf{1}_{x\le y}}{4} - \frac{3(x-y)(1+xy)}{8}$","37 pages",,,,"math.PR math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Answering a pair of questions of Conrey, Gabbard, Grant, Liu, and Morrison,
we prove that a triplet of dice drawn from the multiset model are intransitive
with probability $1/4+o(1)$ and the probability a random pair of dice tie tends
toward $\alpha n^{-1}$ for an explicitly defined constant $\alpha$. This
extends and sharpens the recent results of Polymath regarding the balanced
sequence model. We further show the distribution of larger tournaments
converges to a universal tournamenton in both models. This limit naturally
arises from the discrete spectrum of a certain skew-symmetric operator (given
by the kernel in the title acting on $L^2([-1,1])$). The limit exhibits a
degree of symmetry and can be used to prove that, for instance, the limiting
probability that $A_i$ beats $A_{i+1}$ for $1\le i\le 4$ and that $A_5$ beats
$A_1$ is $1/32+o(1)$. Furthermore, the limiting tournamenton has range
contained in the discrete set $\{0,1\}$. This proves that the associated
tournamenton is non-quasirandom in a dramatic fashion, vastly extending work of
Cornacchia and H\k{a}z{\l}a regarding the continuous analogue of the balanced
sequence model.
  The proof is based on a reduction to conditional central limit theorems
(related to work of Polymath), the use of a ""Poissonization"" style method to
reduce to computations with independent random variables, and the systematic
use of switching-based arguments to extract cancellation in Fourier estimates
when establishing local limit-type estimates.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:25:13 GMT""}]","2023-02-23"
"2302.11294","SeungHwan An","SeungHwan An, Jong-June Jeon","Distributional Variational AutoEncoder To Infinite Quantiles and Beyond
  Gaussianity","9 pages for main part and 14 pages for Appendix, 4 figures",,,,"stat.ML cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Gaussianity assumption has been pointed out as the main limitation of the
Variational AutoEncoder (VAE) in spite of its usefulness in computation. To
improve the distributional capacity (i.e., expressive power of distributional
family) of the VAE, we propose a new VAE learning method with a nonparametric
distributional assumption on its generative model. By estimating an infinite
number of conditional quantiles, our proposed VAE model directly estimates the
conditional cumulative distribution function, and we call this approach
distributional learning of the VAE. Furthermore, by adopting the continuous
ranked probability score (CRPS) loss, our proposed learning method becomes
computationally tractable. To evaluate how well the underlying distribution of
the dataset is captured, we apply our model for synthetic data generation based
on inverse transform sampling. Numerical results with real tabular datasets
corroborate our arguments.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:26:50 GMT""}]","2023-02-23"
"2302.11295","Simon Wietheger","Katrin Casel, Tobias Friedrich, Martin Schirneck, Simon Wietheger","Fair Correlation Clustering in Forests",,,,,"cs.LG cs.CC cs.CY cs.DM cs.DS","http://creativecommons.org/licenses/by/4.0/","  The study of algorithmic fairness received growing attention recently. This
stems from the awareness that bias in the input data for machine learning
systems may result in discriminatory outputs. For clustering tasks, one of the
most central notions of fairness is the formalization by Chierichetti, Kumar,
Lattanzi, and Vassilvitskii [NeurIPS 2017]. A clustering is said to be fair, if
each cluster has the same distribution of manifestations of a sensitive
attribute as the whole input set. This is motivated by various applications
where the objects to be clustered have sensitive attributes that should not be
over- or underrepresented.
  We discuss the applicability of this fairness notion to Correlation
Clustering. The existing literature on the resulting Fair Correlation
Clustering problem either presents approximation algorithms with poor
approximation guarantees or severely limits the possible distributions of the
sensitive attribute (often only two manifestations with a 1:1 ratio are
considered). Our goal is to understand if there is hope for better results in
between these two extremes. To this end, we consider restricted graph classes
which allow us to characterize the distributions of sensitive attributes for
which this form of fairness is tractable from a complexity point of view.
  While existing work on Fair Correlation Clustering gives approximation
algorithms, we focus on exact solutions and investigate whether there are
efficiently solvable instances. The unfair version of Correlation Clustering is
trivial on forests, but adding fairness creates a surprisingly rich picture of
complexities. We give an overview of the distributions and types of forests
where Fair Correlation Clustering turns from tractable to intractable. The most
surprising insight to us is the fact that the cause of the hardness of Fair
Correlation Clustering is not the strictness of the fairness condition.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:27:06 GMT""}]","2023-02-23"
"2302.11296","Mashaan Alshammari Dr.","Mashaan Alshammari, John Stavrakakis, Masahiro Takatsuka","Refining a $k$-nearest neighbor graph for a computationally efficient
  spectral clustering",,"Pattern Recognition, Volume 114, 2021","10.1016/j.patcog.2021.107869",,"cs.LG cs.AI cs.IR cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spectral clustering became a popular choice for data clustering for its
ability of uncovering clusters of different shapes. However, it is not always
preferable over other clustering methods due to its computational demands. One
of the effective ways to bypass these computational demands is to perform
spectral clustering on a subset of points (data representatives) then
generalize the clustering outcome, this is known as approximate spectral
clustering (ASC). ASC uses sampling or quantization to select data
representatives. This makes it vulnerable to 1) performance inconsistency
(since these methods have a random step either in initialization or training),
2) local statistics loss (because the pairwise similarities are extracted from
data representatives instead of data points). We proposed a refined version of
$k$-nearest neighbor graph, in which we keep data points and aggressively
reduce number of edges for computational efficiency. Local statistics were
exploited to keep the edges that do not violate the intra-cluster distances and
nullify all other edges in the $k$-nearest neighbor graph. We also introduced
an optional step to automatically select the number of clusters $C$. The
proposed method was tested on synthetic and real datasets. Compared to ASC
methods, the proposed method delivered a consistent performance despite
significant reduction of edges.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:31:32 GMT""}]","2023-02-23"
"2302.11297","Mashaan Alshammari Dr.","Mashaan Alshammari, Masahiro Takatsuka","Approximate spectral clustering with eigenvector selection and
  self-tuned $k$",,"Pattern Recognition Letters, Volume 122, 2019","10.1016/j.patrec.2019.02.006",,"cs.LG cs.AI cs.IR cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recently emerged spectral clustering surpasses conventional clustering
methods by detecting clusters of any shape without the convexity assumption.
Unfortunately, with a computational complexity of $O(n^3)$, it was infeasible
for multiple real applications, where $n$ could be large. This stimulates
researchers to propose the approximate spectral clustering (ASC). However, most
of ASC methods assumed that the number of clusters $k$ was known. In practice,
manual setting of $k$ could be subjective or time consuming. The proposed
algorithm has two relevance metrics for estimating $k$ in two vital steps of
ASC. One for selecting the eigenvectors spanning the embedding space, and the
other to discover the number of clusters in that space. The algorithm used a
growing neural gas (GNG) approximation, GNG is superior in preserving input
data topology. The experimental setup demonstrates the efficiency of the
proposed algorithm and its ability to compete with similar methods where $k$
was set manually.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:32:24 GMT""}]","2023-02-23"
"2302.11298","Mashaan Alshammari Dr.","Mashaan Alshammari, Masahiro Takatsuka","Approximate spectral clustering density-based similarity for noisy
  datasets",,"Pattern Recognition Letters, Volume 128, 2019","10.1016/j.patrec.2019.08.020",,"cs.LG cs.AI cs.IR cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approximate spectral clustering (ASC) was developed to overcome heavy
computational demands of spectral clustering (SC). It maintains SC ability in
predicting non-convex clusters. Since it involves a preprocessing step, ASC
defines new similarity measures to assign weights on graph edges. Connectivity
matrix (CONN) is an efficient similarity measure to construct graphs for ASC.
It defines the weight between two vertices as the number of points assigned to
them during vector quantization training. However, this relationship is
undirected, where it is not clear which of the vertices is contributing more to
that edge. Also, CONN could be tricked by noisy density between clusters. We
defined a directed version of CONN, named DCONN, to get insights on vertices
contributions to edges. Also, we provided filtering schemes to ensure CONN
edges are highlighting potential clusters. Experiments reveal that the proposed
filtering was highly efficient when noise cannot be tolerated by CONN.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:33:17 GMT""}]","2023-02-23"
"2302.11299","Gen Luo","Gen Luo, Yiyi Zhou, Lei Jin, Xiaoshuai Sun, Rongrong Ji","Towards End-to-end Semi-supervised Learning for One-stage Object
  Detection",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Semi-supervised object detection (SSOD) is a research hot spot in computer
vision, which can greatly reduce the requirement for expensive bounding-box
annotations. Despite great success, existing progress mainly focuses on
two-stage detection networks like FasterRCNN, while the research on one-stage
detectors is often ignored. In this paper, we focus on the semi-supervised
learning for the advanced and popular one-stage detection network YOLOv5.
Compared with Faster-RCNN, the implementation of YOLOv5 is much more complex,
and the various training techniques used in YOLOv5 can also reduce the benefit
of SSOD. In addition to this challenge, we also reveal two key issues in
one-stage SSOD, which are low-quality pseudo-labeling and multi-task
optimization conflict, respectively. To address these issues, we propose a
novel teacher-student learning recipe called OneTeacher with two innovative
designs, namely Multi-view Pseudo-label Refinement (MPR) and Decoupled
Semi-supervised Optimization (DSO). In particular, MPR improves the quality of
pseudo-labels via augmented-view refinement and global-view filtering, and DSO
handles the joint optimization conflicts via structure tweaks and task-specific
pseudo-labeling. In addition, we also carefully revise the implementation of
YOLOv5 to maximize the benefits of SSOD, which is also shared with the existing
SSOD methods for fair comparison. To validate OneTeacher, we conduct extensive
experiments on COCO and Pascal VOC. The extensive experiments show that
OneTeacher can not only achieve superior performance than the compared methods,
e.g., 15.0% relative AP gains over Unbiased Teacher, but also well handle the
key issues in one-stage SSOD. Our source code is available at:
https://github.com/luogen1996/OneTeacher.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:35:40 GMT""}]","2023-02-23"
"2302.11300","Babak Vakili","Leila S. Tabatabaei and Babak Vakili","Bi-directional quantum teleportation of GHZ-like states","13 pages, no figures, 2 tables, to appear in IJQI",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose a method through which $n$-qubit states can
simultaneously be bi-directionally transmitted between two users. We assume
that Alice and Bob, the legitimate users, each have a $n$-qubit GHZ-like state
and want to teleport it to the other party. Also, a four-qubit cluster state
plays the role of the quantum channel of this bi-directional quantum
teleportation. The protocol is based on the method that at first, each user,
through a series of $\mbox{CNOT}$ gates, converts the $n$-qubit state into a
single qubit and some $0$ qubits. Then, by means of the Bell state measurement
and proper operation, the single qubit state is transferred over the channel
between the two sides. By re-applying the $\mbox{CNOT}$ gates on the
transmitted qubits and auxiliary $0$ states, each user reconstructs the initial
GHZ-like state. Finally, we investige the effects of some kind of noises on the
density marix of the channel due to its interaction with the environment and
present a method to protect the channel against the bit-flip error.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:36:17 GMT""}]","2023-02-23"
"2302.11301","Xiaoyue Wan","Xiaoyue Wan, Zhuo Chen, Xu Zhao","View Consistency Aware Holistic Triangulation for 3D Human Pose
  Estimation","8 pages, 6 figures, currently under review at Computer Vision and
  Image Understanding (CVIU) journal",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The rapid development of multi-view 3D human pose estimation (HPE) is
attributed to the maturation of monocular 2D HPE and the geometry of 3D
reconstruction. However, 2D detection outliers in occluded views due to neglect
of view consistency, and 3D implausible poses due to lack of pose coherence,
remain challenges. To solve this, we introduce a Multi-View Fusion module to
refine 2D results by establishing view correlations. Then, Holistic
Triangulation is proposed to infer the whole pose as an entirety, and anatomy
prior is injected to maintain the pose coherence and improve the plausibility.
Anatomy prior is extracted by PCA whose input is skeletal structure features,
which can factor out global context and joint-by-joint relationship from
abstract to concrete. Benefiting from the closed-form solution, the whole
framework is trained end-to-end. Our method outperforms the state of the art in
both precision and plausibility which is assessed by a new metric.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:36:40 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 02:01:36 GMT""}]","2023-02-24"
"2302.11302","Iain Hammond Mr","Iain Hammond, Valentin Christiaens, Daniel J. Price, Claudia Toci,
  Christophe Pinte, Sandrine Juillard and Himanshi Garg","Confirmation and Keplerian motion of the gap-carving protoplanet HD
  169142 b","Accepted for publication in MNRAS Letters. 5 pages, 5 figures",,"10.1093/mnrasl/slad027",,"astro-ph.EP astro-ph.SR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We present the re-detection of a compact source in the face-on protoplanetary
disc surrounding HD 169142, using VLT/SPHERE data in YJH bands. The source is
found at a separation of 0.''319 ($\sim$37 au) from the star. Three lines of
evidence argue in favour of the signal tracing a protoplanet: (i) it is found
in the annular gap separating the two bright rings of the disc, as predicted by
theory; (ii) it is moving at the expected Keplerian velocity for an object at
$\sim$37 au in the 2015, 2017 and 2019 datasets; (iii) we also detect a
spiral-shaped signal whose morphology is consistent with the expected outer
spiral wake triggered by a planet in the gap, based on dedicated hydrodynamical
simulations of the system. The YJH colours we extracted for the object are
consistent with tracing scattered starlight, suggesting that the protoplanet is
enshrouded in a significant amount of dust, as expected for a circumplanetary
disc or envelope surrounding a gap-clearing Jovian-mass protoplanet.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:38:43 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 05:46:26 GMT""}]","2023-03-15"
"2302.11303","Maximilian Stritzinger","M. D. Stritzinger (Aarhus), S. Holmbo, N. Morrell, M. M. Phillips, C.
  R. Burns, S. Castellon, G. Folatelli, M. Hamuy, G. Leloudas, N. B. Suntzeff,
  J. P. Anderson, C. Ashall, E. Baron, S. Boissier, E. Y. Hsiao, E.
  Karamehmetoglu, F. Olivares","The Carnegie Supernova Project-I. Optical spectroscopy of
  stripped-envelope supernovae","Resubmitted to A&A after address referee's comments. Comments
  welcomed, and let us know if we missed to reference your paper?",,,,"astro-ph.HE","http://creativecommons.org/licenses/by/4.0/","  We present 170 optical spectra of 35 low-redshift stripped-envelope
core-collapse supernovae observed by the Carnegie Supernova Project-I between
2004 and 2009. The data extend from as early as -19 days (d) prior to the epoch
of B-band maximum to +322 d, with the vast majority obtained during the
so-called photospheric phase covering the weeks around peak luminosity. In
addition to histogram plots characterizing the red-shift distribution, number
of spectra per object, and the phase distribution of the sample, spectroscopic
classification is also provided following standard criteria. The CSP-I spectra
are electronically available and a detailed analysis of the data set is
presented in a companion paper being the fifth and final paper of the series
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:40:12 GMT""}]","2023-02-23"
"2302.11304","Maximilian Stritzinger","S. Holmbo (Aarhus), M. D. Stritzinger, E. Karamehmetoglu, C. R. Burns,
  N. Morrell, C. Ashall, E. Y. Hsiao, L. Galbany, G. Folatelli, M. M. Phillips,
  E. Baron, C. P. Gutierrez, G. Leloudas, T. E. Muller-Bravo, P. Hoeflich, F.
  Taddia, N. B. Suntzeff","The Carnegie Supernova Project-I. Spectroscopic analysis of
  stripped-envelope supernovae","Re-submitted to A&A after addressing constructive comments from the
  referee. Comments are welcomed, particularly notice to any work that should
  be referenced",,,,"astro-ph.HE astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  An analysis leveraging 170 optical spectra of 35 stripped-envelope (SE)
core-collapse supernovae observed by the Carnegie Supernova Project-I and
published in a companion paper is presented. Mean template spectra are
constructed for the SNe IIb, Ib and Ic sub-types and parent ions associated
with designated spectral features are identified with the aid of the spectral
synthesis code SYNAPPS. Our modeled mean spectra suggest the ~6150~\AA\ feature
in SNe~IIb may have an underlying contribution due to silicon, while the same
feature in some SNe Ib may have an underlying contribution due to hydrogen.
Standard spectral line diagnostics consisting of pseudo-equivalent widths (pEW)
and blue-shifted Doppler velocity are measured for each of the spectral
features. Correlation matrices and rolling mean values of both spectral
diagnostics are constructed. A Principle Component Analysis (PCA) is applied to
various wavelength ranges of the entire data set and suggests clear separation
among the different SE SN sub-types, which follows from trends previously
identified in the literature. In addition, our finds reveal the presence of two
SNe IIb sub-types, a handful of SNe Ib displaying signatures of weak,
high-velocity hydrogen, and a single SN~Ic with evidence of weak helium
features. Our PCA results can be leveraged to obtain robust sub-typing of SE SN
based on a single spectrum taken during the so-called photospheric phase,
separating SNe IIb from SNe Ib with ~80 percent completion.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:40:17 GMT""}]","2023-02-23"
"2302.11305","M S Akshaya","M. S. Akshaya and Thiem Hoang","Alignment and Rotational Disruption of Dust Grains in the Galactic
  Centre Revealed by Polarized Dust Emission","20 pages, 22 figures. Accepted for publication in MNRAS",,"10.1093/mnras/stad1246",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the alignment and rotational disruption of dust grains at the centre
of our Galaxy using polarized thermal dust emission observed by SOFIA/HAWC+ and
JCMT/SCUPOL at 53, 216, and 850 $\mu$m. We analyzed the relationship between
the observed polarization degree with total emission intensity, dust
temperature, gas column density, and polarization angle dispersion.
Polarization degree from this region follows the predictions of the RAdiative
Torque (RAT) alignment theory, except at high temperatures and long wavelengths
where we found evidence for the rotational disruption of grains as predicted by
the RAdiative Torque Disruption mechanism. The grain alignment and disruption
sizes were found to be around 0.1 $\mu$m and 1 $\mu$m, respectively. The
maximum polarization degree observed was around $p\sim13$% at 216 $\mu$m and
comes from a region of high dust temperature, low column density, and ordered
magnetic field. Magnetically Enhanced RAT alignment (MRAT) was found to be
important for grain alignment due to the presence of a strong magnetic field
and can induce perfect alignment even when grains contain small iron clusters.
We estimated the mass fraction of aligned grains using a parametric model for
the fraction of the grains at high-$J$ attractors and found it to correlate
weakly with the observed polarization degree. We observe a change in the
polarization ratio, from $p_{216\mu m}/p_{850\mu m}<1$ to $p_{216\mu
m}/p_{850\mu m}>1$ at $T_{\rm d}\gtrsim35$ K, which suggests a change in the
grain model from a composite to a separate population of carbon and silicate
grains as implied by previous numerical modeling.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:41:36 GMT""},{""version"":""v2"",""created"":""Tue, 25 Apr 2023 07:48:05 GMT""}]","2023-05-01"
"2302.11306","HongYu Liu","Hongyu Liu and Xintong Han and Chengbin Jin and Lihui Qian and Huawei
  Wei and Zhe Lin and Faqiang Wang and Haoye Dong and Yibing Song and Jia Xu
  and Qifeng Chen","Human MotionFormer: Transferring Human Motions with Vision Transformers","Accepted by ICLR2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human motion transfer aims to transfer motions from a target dynamic person
to a source static one for motion synthesis. An accurate matching between the
source person and the target motion in both large and subtle motion changes is
vital for improving the transferred motion quality. In this paper, we propose
Human MotionFormer, a hierarchical ViT framework that leverages global and
local perceptions to capture large and subtle motion matching, respectively. It
consists of two ViT encoders to extract input features (i.e., a target motion
image and a source human image) and a ViT decoder with several cascaded blocks
for feature matching and motion transfer. In each block, we set the target
motion feature as Query and the source person as Key and Value, calculating the
cross-attention maps to conduct a global feature matching. Further, we
introduce a convolutional layer to improve the local perception after the
global cross-attention computations. This matching process is implemented in
both warping and generation branches to guide the motion transfer. During
training, we propose a mutual learning loss to enable the co-supervision
between warping and generation branches for better motion representations.
Experiments show that our Human MotionFormer sets the new state-of-the-art
performance both qualitatively and quantitatively. Project page:
\url{https://github.com/KumapowerLIU/Human-MotionFormer}
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:42:44 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 14:59:45 GMT""}]","2023-02-28"
"2302.11307","Qiming Sun","Qiming Sun","Various integral estimations and screening schemes for extended systems
  in PySCF",,,,,"physics.chem-ph","http://creativecommons.org/licenses/by/4.0/","  In this document, we briefly review the two-electron integral algorithms
based on the range-separated algorithms and Fourier transform integral
algorithms that are implement ed in the PySCF package. For each integral
algorithm, we estimate the upper bound of relevant integrals and derive the
necessary conditions for the screening parameters, including distance cutoff
and energy cutoff, to reach the desired accuracy. Our numerical tests show that
the proposed integral estimators and screening parameters can effectively
address the required accuracy while computational efforts are not wasted on
unintended accuracy.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:44:13 GMT""}]","2023-02-23"
"2302.11308","Songhao Yin","Songhao Yin, Hiroshi Kori, and Yuki Izumida","Synchronization approach to achieving maximum power and thermal
  efficiency for weakly-coupled low-temperature-differential Stirling engines",,,,,"nlin.AO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Low-temperature-differential (LTD) Stirling engines are heat engines that can
operate autonomously with a slight temperature difference between
low-temperature heat reservoirs and are thus expected to contribute to a
sustainable society. A minimal dynamical-system model with only two variables
has been proposed to explain the principle of autonomous rotational motion
caused by temperature differences, and the maximum efficiency of the engine was
formulated [Y. Izumida, Eurohys. Lett. 121, 50004 (2018); Phys. Rev. E 102,
012142 (2020)]. This paper aims to clarify the coupling effects on the
dynamics, power, and thermal efficiency of a pair of weakly coupled LTD
Stirling engines and formulate the maximum thermal efficiency of the coupled
system in the quasilinear response regime. We show that different kinds of
bifurcations occur in the forward and backward processes, and the dependence of
frequency difference on the coupling strength is characterized by a hysteresis.
Then, by generalizing thermodynamic fluxes and forces and their quasilinear
relations for engines under weak coupling, we show that the coupling improves
the power exerted against the load torques and the thermal efficiency. We
further show that their maximum values are achieved when the engines are
synchronized. As in the case of the frequency difference, the dependence of
thermal efficiency on the coupling strength is also characterized by a
hysteresis. Finally, the load torque that achieves the maximum thermal
efficiency of the coupled system is formulated.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:45:35 GMT""}]","2023-02-23"
"2302.11309","Jan Vorberger","Jan Vorberger, Thomas R. Preston, Nikita Medvedev, Maximilian P.
  B\""ohme, Zhandos A. Moldabekov, Dominik Kraus, and Tobias Dornheim","Revealing Non-equilibrium and Relaxation in Warm Dense Matter",,,,,"physics.plasm-ph","http://creativecommons.org/licenses/by-sa/4.0/","  Experiments creating extreme states of matter almost invariably create
non-equilibrium states. These are very interesting in their own right but need
to be understood even if the ultimate goal is to probe high-pressure or
high-temperature equilibrium properties like the equation of state. Here, we
report on the capabilities of the newly developed imaginary time correlation
function (ITCF) technique [1] to detect and quantify non-equilibrium in
pump-probe experiments fielding time resolved x-ray scattering diagnostics. We
find a high sensitivity of the ITCF even to a small fraction of non-equilibrium
electrons in the Wigner distribution. The behavior of the ITCF technique is
such that modern lasers and detectors should be able to trace the
non-equilibrium relaxation from tens of femto-seconds to several 10s of
picoseconds without the need for a model.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:46:22 GMT""}]","2023-02-23"
"2302.11310","Firat Diker","Firat Diker, Zafer Gedik","The Degree of Quantum Contextuality in terms of Concurrence for the KCBS
  Scenario","The final publication is available at Springer via
  https://doi.org/10.1007/s10773-022-05245-0","Int J Theor Phys 61, 266 (2022)","10.1007/s10773-022-05245-0",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum contextuality is the key concept which explains the fact that the
result of a measurement is not independent of the context in which it is found.
It is observed to be an intrinsic feature, i.e., neither entanglement nor
spatial separation is required. In this work, we revisit the previous studies
which state that entanglement is an intrinsic property called
self-entanglement. Using this fact, we explicitly show the correlation between
quantum contextuality and concurrence in the KCBS scenario, which is the
simplest approach to observing contextuality. We also derive the equation for
the maximal violation of the KCBS scenario for a given concurrence and find the
linear relation between them. Using this relation, we also show how the maximal
violations of the KCBS and CHSH inequalities are related for an arbitrary
entanglement. Moreover, we discuss the special cases of maximal entanglement,
and non-entanglement for which we have found a lower local bound.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:48:18 GMT""}]","2023-02-23"
"2302.11311","James Avery","Mark Runciman, Enrico Franco, James Avery, Ferdinando Rodriguez y
  Baena, and George Mylonas","Model Based Position Control of Soft Hydraulic Actuators","Final Version of Paper, updated figures and discussion. Accepted for
  IEEE International Conference on Robotics and Automation ICRA 2023",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article, we investigate the model based position control of soft
hydraulic actuators arranged in an antagonistic pair. A dynamical model of the
system is constructed by employing the port-Hamiltonian formulation. A control
algorithm is designed with an energy shaping approach which accounts for the
pressure dynamics of the fluid. A nonlinear observer is included to compensate
the effect of unknown external forces. Simulations demonstrate the
effectiveness of the proposed approach, and experiments achieve positioning
accuracy of 0.043 mm with a standard deviation of 0.033 mm in the presence of
constant external forces up to 1 N.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:48:29 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 12:09:31 GMT""}]","2023-03-06"
"2302.11312","Zifeng Zhuang","Zifeng Zhuang, Kun Lei, Jinxin Liu, Donglin Wang, Yilang Guo","Behavior Proximal Policy Optimization","ICLR2023 Poster",,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Offline reinforcement learning (RL) is a challenging setting where existing
off-policy actor-critic methods perform poorly due to the overestimation of
out-of-distribution state-action pairs. Thus, various additional augmentations
are proposed to keep the learned policy close to the offline dataset (or the
behavior policy). In this work, starting from the analysis of offline monotonic
policy improvement, we get a surprising finding that some online on-policy
algorithms are naturally able to solve offline RL. Specifically, the inherent
conservatism of these on-policy algorithms is exactly what the offline RL
method needs to overcome the overestimation. Based on this, we propose Behavior
Proximal Policy Optimization (BPPO), which solves offline RL without any extra
constraint or regularization introduced compared to PPO. Extensive experiments
on the D4RL benchmark indicate this extremely succinct method outperforms
state-of-the-art offline RL algorithms. Our implementation is available at
https://github.com/Dragon-Zhuang/BPPO.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:49:12 GMT""}]","2023-02-23"
"2302.11313","Anindya Mondal","Jhon A. Castro-Correa, Jhony H. Giraldo, Anindya Mondal, Mohsen
  Badiey, Thierry Bouwmans, Fragkiskos D. Malliaros","Time-varying Signals Recovery via Graph Neural Networks","Accepted at ICASSP 2023",,"10.1109/ICASSP49357.2023.10096168",,"eess.SP cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recovery of time-varying graph signals is a fundamental problem with
numerous applications in sensor networks and forecasting in time series.
Effectively capturing the spatio-temporal information in these signals is
essential for the downstream tasks. Previous studies have used the smoothness
of the temporal differences of such graph signals as an initial assumption.
Nevertheless, this smoothness assumption could result in a degradation of
performance in the corresponding application when the prior does not hold. In
this work, we relax the requirement of this hypothesis by including a learning
module. We propose a Time Graph Neural Network (TimeGNN) for the recovery of
time-varying graph signals. Our algorithm uses an encoder-decoder architecture
with a specialized loss composed of a mean squared error function and a Sobolev
smoothness operator.TimeGNN shows competitive performance against previous
methods in real datasets.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:50:39 GMT""},{""version"":""v2"",""created"":""Fri, 5 May 2023 21:04:21 GMT""}]","2023-05-10"
"2302.11314","Yilin Geng","Ying Wang, Qin Jiang, Yilin Geng, Yuren Hu, Yue Tang, Jixiang Li,
  Junmei Zhang, Wolfgang Mayer, Shanmei Liu, Hong-Yu Zhang, Xianghua Yan,
  Zaiwen Feng","SGMFQP:An Ontology-based Swine Gut Microbiota Federated Query Platform",,,,,"cs.DB q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Gut microbiota plays a crucial role in modulating pig development and health,
and gut microbiota characteristics are associated with differences in feed
efficiency. To answer open questions in feed efficiency analysis, biologists
seek to retrieve information across multiple heterogeneous data sources.
However, this is error-prone and time-consuming work since the queries can
involve a sequence of multiple sub-queries over several databases. We present
an implementation of an ontology-based Swine Gut Microbiota Federated Query
Platform (SGMFQP) that provides a convenient, automated, and efficient query
service about swine feeding and gut microbiota. The system is constructed based
on a domain-specific Swine Gut Microbiota Ontology (SGMO), which facilitates
the construction of queries independent of the actual organization of the data
in the individual sources. This process is supported by a template-based query
interface. A Datalog+-based federated query engine transforms the queries into
sub-queries tailored for each individual data source, and an automated workflow
orchestration mechanism executes the queries in each source database and
consolidates the results. The efficiency of the system is demonstrated on
several swine feeding scenarios.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:52:31 GMT""}]","2023-02-23"
"2302.11315","Hamza Ennaji","Hamza Ennaji, Noureddine Igbida, Ghadir Jradi","Prediction-Correction Pedestrian Flow by Means of Minimum Flow Problem",,,,,"math.AP cs.NA math.NA math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a new variant of mathematical prediction-correction model for crowd
motion. The prediction phase is handled by a transport equation where the
vector field is computed via an eikonal equation $\Vert \nabla\varphi\Vert=f$,
with a positive continuous function $f$ connected to the speed of the
spontaneous travel. The correction phase is handled by a new version of the
minimum flow problem. This model is flexible and can take into account
different types of interactions between the agents, from gradient flow in
Wassersetin space to granular type dynamics like in sandpile. Furthermore,
different boundary conditions can be used, such as non-homogeneous Dirichlet
(e.g., outings with different exit-cost penalty) and Neumann boundary
conditions (e.g., entrances with different rates). Combining finite volume
method for the transport equation and Chambolle-Pock's primal dual algorithm
for the eikonal equation and minimum flow problem, we present numerical
simulations to demonstrate the behavior in different scenarios.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:00:12 GMT""}]","2023-02-23"
"2302.11316","Zhi-Hui Guo","Cheng Chen, Nai-Qian Cheng, Lin-Wan Yan, Chun-Gui Duan, Zhi-Hui Guo","Revisit of tensor-meson nonet in resonance chiral theory","18 pages, 3 tables, no figure",,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the properties of the lowest multiplet of light-flavor tensor meson
resonances, i.e. $f_2(1270)$, $a_2(1320)$, $K_2^*(1430)$ and $f_2'(1525)$,
within the resonance chiral theory approach. The higher-order resonance chiral
operators by including the light-quark mass and $1/N_C$ corrections are
simultaneously incorporated in our study. The use of resonance chiral
expressions allows us to analyze not only the relevant experimental data but
also in the meantime the lattice results at unphysical quark masses, including
the masses of the lowest multiplet of tensor resonances and their decay widths
into two pseudoscalar mesons. In addition, the radiative decays of the tensor
resonances into one photon plus one pseudoscalar meson and two photons are
studied as well.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:01:16 GMT""}]","2023-02-23"
"2302.11317","Kai-Wei Sun","Kai-Wei Sun and Fa Wang","Neural Network Analytic Continuation for Monte Carlo: Improvement by
  Statistical Errors",,,,,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study explores the use of neural network-based analytic continuation to
extract spectra from Monte Carlo data. We apply this technique to both
synthetic and Monte Carlo-generated data. The training sets for neural networks
are carefully synthesized without ``data leakage"". We found that the training
set should match the input correlation functions in terms of statistical error
properties, such as noise level, noise dependence on imaginary time, and
imaginary time-displaced correlations. We have developed a systematic method to
synthesize such training datasets. Our improved algorithm outperform the widely
used maximum entropy method in highly noisy situations. As an example, our
method successfully extracted the dynamic structure factor of the spin-1/2
Heisenberg chain from quantum Monte Carlo simulations.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:03:22 GMT""}]","2023-02-23"
"2302.11318","Aldo Morselli","Aldo Morselli (on behalf of the CTA Consortium)","Search for dark matter with IACTs and the Cherenkov Telescope Array","6 pages, 7 figures, 12th Cosmic Ray International Seminar - CRIS 2022","Journal of Physics: Conference Series 2429 (2023)","10.1088/1742-6596/2429/1/012019",,"astro-ph.HE hep-ex hep-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In the last decades an incredible amount of evidence for the existence of
dark matter (DM) has been accumulating. At the same time, many efforts have
been undertaken to try to identify what dark matter is made of. Indirect
searches look at places in the Universe where dark matter is known to be
abundant and seek for possible annihilation or decay signatures. Indirect
searches with the Fermi Gamma ray Space Telescope and Imaging Atmospheric
Cherenkov Telescopes (IACTs) are playing a crucial role in constraining the
nature of the DM particle through the study of their annihilation into gamma
rays from different astrophysical structures. In this talk I will review the
status of the search with IACTs and I will describe the sensitivity projections
for dark matter searches on the various targets taking into account the latest
instrument response functions expected for the Cherenkov Telescope Array (CTA)
together with estimations for the systematic uncertainties from diffuse
astrophysical and cosmic-ray
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:04:41 GMT""}]","2023-02-23"
"2302.11319","Kai Ino","Kai Ino, Omar Leon Sanchez","Separably differentially closed fields",,,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce and study a new class of differential fields in positive
characteristic. We call them separably differentially closed fields and
demonstrate that they are the differential analogue of separably closed fields.
We prove several (algebraic and model-theoretic) properties of this class.
Among other things, we show that it is an elementary class, whose theory we
denote $\SDCF$, and that its completions are determined by specifying the
characteristic $p$ and the differential degree of imperfection $\epsilon$.
Furthermore, after adding what we call the differential $\lambda$-functions, we
prove that the theory $\SDCFl$ admits quantifier elimination, is stable, and
prime model extensions exist.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:05:00 GMT""}]","2023-02-23"
"2302.11320","Keita Kanno","Keita Kanno, Masaya Kohda, Ryosuke Imai, Sho Koh, Kosuke Mitarai,
  Wataru Mizukami, Yuya O. Nakagawa","Quantum-Selected Configuration Interaction: classical diagonalization of
  Hamiltonians in subspaces selected by quantum computers","28 pages, 15 figures",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose quantum-selected configuration interaction (QSCI), a class of
hybrid quantum-classical algorithms for calculating the ground- and
excited-state energies of many-electron Hamiltonians on noisy quantum devices.
Suppose that an approximate ground state can be prepared on a quantum computer
either by variational quantum eigensolver or by some other method. Then, by
sampling the state in the computational basis, which is hard for classical
computation in general, one can identify the electron configurations that are
important for reproducing the ground state. The Hamiltonian in the subspace
spanned by those important configurations is diagonalized on classical
computers to output the ground-state energy and the corresponding eigenvector.
The excited-state energies can be obtained similarly. The result is robust
against statistical and physical errors because the noisy quantum devices are
used only to define the subspace, and the resulting ground-state energy
strictly satisfies the variational principle even in the presence of such
errors. The expectation values of various other operators can also be estimated
for obtained eigenstates with no additional quantum cost, since the explicit
eigenvectors in the subspaces are known. We verified our proposal by numerical
simulations, and demonstrated it on a quantum device for an 8-qubit molecular
Hamiltonian. The proposed algorithms are potentially feasible to tackle some
challenging molecules by exploiting quantum devices with several tens of
qubits, assisted by high-performance classical computing resources for
diagonalization.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:05:31 GMT""}]","2023-02-23"
"2302.11321","A-Man Zhang","A-Man Zhang, Shi-Min Li, Pu Cui, Shuai Li, Yun-Long Liu","Interactions between a central bubble and a surrounding bubble cluster",,,"10.1016/j.taml.2023.100438",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The interaction of multiple bubbles is a complex physical problem. A
simplified case of multiple bubbles is studied theoretically with a bubble
located at the center of a circular bubble cluster. All bubbles in the cluster
are equally spaced and own the same initial conditions as the central bubble.
The unified theory for bubble dynamics (Zhang et al. arXiv:2301.13698) is
applied to model the interaction between the central bubble and the circular
bubble cluster. To account for the effect of the propagation time of pressure
waves, the emission source of the wave is obtained by interpolating the
physical information on the time axis. An underwater explosion experiment with
two bubbles of different scales is used to validate the theoretical model. The
effect of the bubble cluster with a variation in scale on the pulsation
characteristics of the central bubble is studied.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:06:25 GMT""}]","2023-02-23"
"2302.11322","Bar Weinstein","Bar Weinstein and Daniel Nevo","Causal inference with misspecified interference structure",,,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Interference occurs when the potential outcomes of a unit depend on the
treatments assigned to other units. That is frequently the case in many
domains, such as in the social sciences and infectious disease epidemiology.
Often, the interference structure is represented by a network, which is
typically assumed to be given and accurate. However, correctly specifying the
network can be challenging, as edges can be censored, the structure can change
over time, and contamination between clusters may exist. Building on the
exposure mapping framework, we derive the bias arising from estimating causal
effects under a misspecified interference structure. To address this problem,
we propose a novel estimator that uses multiple networks simultaneously and is
unbiased if one of the networks correctly represents the interference
structure, thus providing robustness to the network specification.
Additionally, we propose a sensitivity analysis that quantifies the impact of a
postulated misspecification mechanism on the causal estimates. Through
simulation studies, we illustrate the bias from assuming an incorrect network
and show the bias-variance tradeoff of our proposed
network-misspecification-robust estimator. We demonstrate the utility of our
methods in two real examples.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:08:21 GMT""}]","2023-02-23"
"2302.11323","Matei Hanu","Matei Hanu, Jonas Latz, Claudia Schillings","Subsampling in ensemble Kalman inversion",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Ensemble Kalman Inversion which has been recently introduced
as an efficient, gradient-free optimisation method to estimate unknown
parameters in an inverse setting. In the case of large data sets, the Ensemble
Kalman Inversion becomes computationally infeasible as the data misfit needs to
be evaluated for each particle in each iteration. Here, randomised algorithms
like stochastic gradient descent have been demonstrated to successfully
overcome this issue by using only a random subset of the data in each
iteration, so-called subsampling techniques. Based on a recent analysis of a
continuous-time representation of stochastic gradient methods, we propose,
analyse, and apply subsampling-techniques within Ensemble Kalman Inversion.
Indeed, we propose two different subsampling techniques: either every particle
observes the same data subset (single subsampling) or every particle observes a
different data subset (batch subsampling).
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:08:30 GMT""}]","2023-02-23"
"2302.11324","Rogemar Andre Riffel","R. A. Riffel, T. Storchi-Bergmann, R. Riffel, M. Bianchin, N. L.
  Zakamska, D. Ruschel-Dutra, M. C. Bentz, L. Burtscher, D. M. Crenshaw, L. G.
  Dahmer-Hahn, N. Z. Dametto, R. I. Davies, M. R. Diniz, T. C. Fischer, C. M.
  Harrison, V. Mainieri, M. Revalski, A. Rodriguez-Ardila, D. J. Rosario, A. J.
  Schonell","The AGNIFS survey: spatially resolved observations of hot molecular and
  ionised outflows in nearby active galaxies","37 pages, published in MNRAS - A few typos in the text and in the
  label of Fg 1 were corrected in this version","MNRAS, 521, 1832 (2023)","10.1093/mnras/stad599",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the hot molecular and warm ionised gas kinematics for 33 nearby
($0.001\lesssim z\lesssim0.056$) X-ray selected active galaxies using the H$_2
2.1218 \mu$m and Br$\gamma$ emission lines observed in the K-band with the
Gemini Near-Infrared Field Spectrograph (NIFS). The observations cover the
inner 0.04$-$2 kpc of each AGN at spatial resolutions of 4$-$250 pc with a
velocity resolution of $\sigma_{\rm inst}\approx$20 ${\rm km s^{-1}}$. We find
that 31 objects (94 per cent) present a kinematically disturbed region (KDR)
seen in ionised gas, while such regions are observed in hot molecular gas for
25 galaxies (76 per cent). We interpret the KDR as being due to outflows with
masses of 10$^2-$10$^7$ M$_\odot$ and 10$^0-$10$^4$ M$_\odot$ for the ionised
and hot molecular gas, respectively. The ranges of mass-outflow rates
($\dot{M}_{\rm out}$) and kinetic power ($\dot{E}_{\rm K}$) of the outflows are
10$^{-3}-$10$^{1}$ M$_\odot$yr$^{-1}$ and $\sim$10$^{37}$$-$10$^{43}$ erg
s$^{-1}$ for the ionised gas outflows, and 10$^{-5}$$-$10$^{-2}$ M$_\odot$
yr$^{-1}$ and 10$^{35}$$-$10$^{39}$ erg s$^{-1}$ for the hot molecular gas
outflows. The median coupling efficiency in our sample is $\dot{E}_{K}/L_{\rm
bol}\approx1.8\times10^{-3}$ and the estimated momentum fluxes of the outflows
suggest they are produced by radiation-pressure in low-density environment,
with possible contribution from shocks.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:09:36 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 22:52:16 GMT""},{""version"":""v3"",""created"":""Tue, 14 Mar 2023 17:30:04 GMT""}]","2023-03-15"
"2302.11325","Chengxi Zeng","Chengxi Zeng, Xinyu Yang, David Smithard, Majid Mirmehdi, Alberto M
  Gambaruto, Tilo Burghardt","Video-SwinUNet: Spatio-temporal Deep Learning Framework for VFSS
  Instance Segmentation",,,,,"cs.CV cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper presents a deep learning framework for medical video segmentation.
Convolution neural network (CNN) and transformer-based methods have achieved
great milestones in medical image segmentation tasks due to their incredible
semantic feature encoding and global information comprehension abilities.
However, most existing approaches ignore a salient aspect of medical video data
- the temporal dimension. Our proposed framework explicitly extracts features
from neighbouring frames across the temporal dimension and incorporates them
with a temporal feature blender, which then tokenises the high-level
spatio-temporal feature to form a strong global feature encoded via a Swin
Transformer. The final segmentation results are produced via a UNet-like
encoder-decoder architecture. Our model outperforms other approaches by a
significant margin and improves the segmentation benchmarks on the VFSS2022
dataset, achieving a dice coefficient of 0.8986 and 0.8186 for the two datasets
tested. Our studies also show the efficacy of the temporal feature blending
scheme and cross-dataset transferability of learned capabilities. Code and
models are fully available at https://github.com/SimonZeng7108/Video-SwinUNet.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:09:39 GMT""}]","2023-02-23"
"2302.11326","Luca Zanolini","Francesco D'Amato and Luca Zanolini","Recent Latest Message Driven GHOST: Balancing Dynamic Availability With
  Asynchrony Resilience",,,,,"cs.DC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Dynamic participation has recently become a crucial requirement for devising
permissionless consensus protocols. It enhances robustness against events
involving portions of participants going offline, thus preserving the safety
and liveness of such dynamically available protocols. This concept, formalized
by Pass and Shi (ASIACRYPT 2017) through the sleepy model, has been implicitly
adopted to model various blockchain protocols, such as Ethereum's consensus
protocol, Gasper.
  Neu, Tas, and Tse (S&P 2021) demonstrated that LMD-GHOST, Gasper's dynamic
availability component, is not secure even in a full-participation context,
i.e., with all validators online. Subsequent mitigations were developed to
address its shortcomings. However, the resulting protocol still fails to
achieve dynamic availability, motivating further research into more secure,
dynamically available protocols.
  In this work, we introduce RLMD-GHOST, a synchronous, dynamically available
protocol that maintains safety during bounded periods of asynchrony. This
protocol is particularly appealing for practical systems where strict synchrony
assumptions may not always hold, contrary to general assumptions in standard
synchronous protocols. Additionally, we present the generalized sleepy model,
within which our results are proven. Building upon the original sleepy model
proposed by Pass and Shi, this model extends it with more generalized and
stronger constraints on the corruption and sleepiness power of the adversary.
This approach allows us to explore a wide range of dynamic participation
regimes, spanning from complete dynamic participation to no dynamic
participation, i.e., with every participant online. Consequently, this model
provides a foundation for analyzing dynamically available protocols.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:12:44 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 10:29:00 GMT""}]","2023-05-04"
"2302.11327","Seyedsaman Emami","Seyedsaman Emami and Gonzalo Mart\'inez-Mu\~noz","A Gradient Boosting Approach for Training Convolutional and Deep Neural
  Networks",,,"10.1109/OJSP.2023.3279011",,"cs.CV","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Deep learning has revolutionized the computer vision and image classification
domains. In this context Convolutional Neural Networks (CNNs) based
architectures are the most widely applied models. In this article, we
introduced two procedures for training Convolutional Neural Networks (CNNs) and
Deep Neural Network based on Gradient Boosting (GB), namely GB-CNN and GB-DNN.
These models are trained to fit the gradient of the loss function or
pseudo-residuals of previous models. At each iteration, the proposed method
adds one dense layer to an exact copy of the previous deep NN model. The
weights of the dense layers trained on previous iterations are frozen to
prevent over-fitting, permitting the model to fit the new dense as well as to
fine-tune the convolutional layers (for GB-CNN) while still utilizing the
information already learned. Through extensive experimentation on different
2D-image classification and tabular datasets, the presented models show
superior performance in terms of classification accuracy with respect to
standard CNN and Deep-NN with the same architectures.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:17:32 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 09:13:03 GMT""}]","2023-05-24"
"2302.11328","Deqiang Li","Deqiang Li, Shicheng Cui, Yun Li, Jia Xu, Fu Xiao and Shouhuai Xu","PAD: Towards Principled Adversarial Malware Detection Against Evasion
  Attacks","Accepted by IEEE Transactions on Dependable and Secure Computing; To
  appear",,"10.1109/TDSC.2023.3265665",,"cs.CR cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine Learning (ML) techniques can facilitate the automation of malicious
software (malware for short) detection, but suffer from evasion attacks. Many
studies counter such attacks in heuristic manners, lacking theoretical
guarantees and defense effectiveness. In this paper, we propose a new
adversarial training framework, termed Principled Adversarial Malware Detection
(PAD), which offers convergence guarantees for robust optimization methods. PAD
lays on a learnable convex measurement that quantifies distribution-wise
discrete perturbations to protect malware detectors from adversaries, whereby
for smooth detectors, adversarial training can be performed with theoretical
treatments. To promote defense effectiveness, we propose a new mixture of
attacks to instantiate PAD to enhance deep neural network-based measurements
and malware detectors. Experimental results on two Android malware datasets
demonstrate: (i) the proposed method significantly outperforms the
state-of-the-art defenses; (ii) it can harden ML-based malware detection
against 27 evasion attacks with detection accuracies greater than 83.45%, at
the price of suffering an accuracy decrease smaller than 2.16% in the absence
of attacks; (iii) it matches or outperforms many anti-malware scanners in
VirusTotal against realistic adversarial malware.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:24:49 GMT""},{""version"":""v2"",""created"":""Thu, 6 Apr 2023 07:25:14 GMT""}]","2023-04-07"
"2302.11329","Qiheng Mao","Qiheng Mao, Zemin Liu, Chenghao Liu, Jianling Sun","HINormer: Representation Learning On Heterogeneous Information Networks
  with Graph Transformer",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent studies have highlighted the limitations of message-passing based
graph neural networks (GNNs), e.g., limited model expressiveness,
over-smoothing, over-squashing, etc. To alleviate these issues, Graph
Transformers (GTs) have been proposed which work in the paradigm that allows
message passing to a larger coverage even across the whole graph. Hinging on
the global range attention mechanism, GTs have shown a superpower for
representation learning on homogeneous graphs. However, the investigation of
GTs on heterogeneous information networks (HINs) is still under-exploited. In
particular, on account of the existence of heterogeneity, HINs show distinct
data characteristics and thus require different treatment. To bridge this gap,
in this paper we investigate the representation learning on HINs with Graph
Transformer, and propose a novel model named HINormer, which capitalizes on a
larger-range aggregation mechanism for node representation learning. In
particular, assisted by two major modules, i.e., a local structure encoder and
a heterogeneous relation encoder, HINormer can capture both the structural and
heterogeneous information of nodes on HINs for comprehensive node
representations. We conduct extensive experiments on four HIN benchmark
datasets, which demonstrate that our proposed model can outperform the
state-of-the-art.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:25:07 GMT""},{""version"":""v2"",""created"":""Fri, 3 Mar 2023 05:44:48 GMT""}]","2023-03-06"
"2302.11330","Shigeru Wakita","Shigeru Wakita, Brandon C. Johnson, Jason M. Soderblom, Jahnavi Shah,
  Catherine D. Neish, Jordan K. Steckloff","Modeling the formation of Selk impact crater on Titan: Implications for
  Dragonfly","32 pages, 11 figures, accepted for publication in PSJ",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Selk crater is an $\sim$ 80 km diameter impact crater on the Saturnian icy
satellite, Titan. Melt pools associated with impact craters like Selk provide
environments where liquid water and organics can mix and produce biomolecules
like amino acids. It is partly for this reason that the Selk region has been
selected as the area that NASA's Dragonfly mission will explore and address one
of its primary goals: to search for biological signatures on Titan. Here we
simulate Selk-sized impact craters on Titan to better understand the formation
of Selk and its melt pool. We consider several structures for the icy target
material by changing the thickness of the methane clathrate layer, which has a
substantial effect on the target thermal structure and crater formation. Our
numerical results show that a 4 km-diameter-impactor produces a Selk-sized
crater when 5-15 km thick methane clathrate layers are considered. We confirm
the production of melt pools in these cases and find that the melt volumes are
similar regardless of methane clathrate layer thickness. The distribution of
the melted material, however, is sensitive to the thickness of the methane
clathrate layer. The melt pool appears as a torus-like shape with a few km
depth in the case of 10-15 km thick methane clathrate layer, and as a shallower
layer in the case of a 5 km thick clathrate layer. Melt pools of this thickness
may take tens of thousands of years to freeze, allowing more time for complex
organics to form.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:26:29 GMT""}]","2023-02-23"
"2302.11331","Jori Merikoski","Jori Merikoski","On Gaussian primes in sparse sets","68 pages, v2: minor changes",,,,"math.NT","http://creativecommons.org/licenses/by/4.0/","  We show that there exists some $\delta > 0$ such that, for any set of
integers $B$ with $B\cap[1,Y]\gg Y^{1-\delta}$ for all $Y \gg 1$, there are
infinitely many primes of the form $a^2+b^2$ with $b\in B$. We prove a
quasi-explicit formula for the number of primes of the form $a^2+b^2 \leq X$
with $b \in B$ for any $|B|=X^{1/2-\delta}$ with $\delta < 1/10$ and $B
\subseteq [\eta X^{1/2},(1-\eta)X^{1/2}] \cap \mathbb{Z}$, in terms of zeros of
Hecke $L$-functions on $\mathbb{Q}(i)$. We obtain the expected asymptotic
formula for the number of such primes provided that the set $B$ does not have a
large subset which consists of multiples of a fixed large integer. In
particular, we get an asymptotic formula if $B$ is a sparse subset of primes.
For an arbitrary $B$ we obtain a lower bound for the number of primes with a
weaker range for $\delta$, by bounding the contribution from potential
exceptional characters.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:26:40 GMT""},{""version"":""v2"",""created"":""Tue, 4 Apr 2023 10:52:50 GMT""}]","2023-04-05"
"2302.11332","Andrea Gentile","Vincenzo Amato, Andrea Gentile, Carlo Nitsch, Cristina Trombetti","On the gradient rearrangement of functions",,,,,"math.AP","http://creativecommons.org/licenses/by/4.0/","  In this paper, we introduce a symmetrization technique for the gradient of a
BV function, which separates its absolutely continuous part from its singular
part (sum of jump and Cantorian part). In particular, we prove a $L^1$
comparison between the function and the symmetrization just mentioned.
Furthermore, we apply this result to obtain Saint-Venant type inequalities for
some geometric functionals.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:28:08 GMT""}]","2023-02-23"
"2302.11333","Jun Tao Wang","Jiang Yang, Pengfei He, Juntao Wang","On profiniteness and Hausdorffness of topological residuated lattices",,,,,"math.LO","http://creativecommons.org/licenses/by/4.0/","  The aim of this paper is to study the profiniteness of compact topological
residuated lattices and the existence of Hausdorff topological residuated
lattices. Firstly, we study profinite residuated lattices and obtain sufficient
and necessary conditions for profiniteness in compact topological residuated
lattices. These conditions include topological and algebraic characterizations.
Moreover, it order to study the existence of Hausdorf topological residuated
lattices, we investigate finiteness conditions in residuated lattices. Finally,
we investigate linear topological residuated lattices and give the class of
residuated lattices that can be endowed with a non-trivial Hausdorff topology.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:29:22 GMT""}]","2023-02-23"
"2302.11334","Jiyuan Kuang","Jiyuan Kuang, Yabin Gao, Yizhuo Sun, Jiahui Wang, Aohua Liu, Yue Zhao,
  Jianxing Liu","Stabilization with Prescribed Instant via Lyapunov Method",,,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This letter investigates the prescribed-instant stabilization problem for
high-order integrator systems. In anothor word, the settling time under the
presented controller is independent of the initial conditions and equals the
prescribed time instant. The controller is designed with the concept of
backstepping. A strict proof based on the Lyapunov method is presented to clamp
the settling time to the prescribed time instant from both the left and right
sides. This proof serves as an example to present a general framework to verify
the designed stabilization property. It should be emphasized that the
prescribed-time stability (PSTS) [1] can only prescribe the upper bound of the
settling time and is different from this work. The detailed argumentation will
be presented after a brief review of the existing important research.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:30:43 GMT""}]","2023-02-23"
"2302.11336","Xiongxin Yang","Zhiguo Fu, Tianyu Liu, Xiongxin Yang","Approximability of the Four-Vertex Model","15 pages, 4 figures",,,,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the approximability of the four-vertex model, a special case of the
six-vertex model.We prove that, despite being NP-hard to approximate in the
worst case, the four-vertex model admits a fully polynomial randomized
approximation scheme (FPRAS) when the input satisfies certain linear equation
system over GF(2).The FPRAS is given by a Markov chain known as the worm
process, whose state space and rapid mixing rely on the solution of the linear
equation system. This is the first attempt to design an FPRAS for the
six-vertex model with unwindable constraint functions.Additionally, we explore
the applications of this technique on planar graphs, providing efficient
sampling algorithms.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:33:07 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 10:38:47 GMT""}]","2023-05-04"
"2302.11339","Jianing Lou","Lingxiao Huang, Shaofeng H.-C. Jiang, Jianing Lou","The Power of Uniform Sampling for $k$-Median",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the power of uniform sampling for $k$-Median in various metric
spaces. We relate the query complexity for approximating $k$-Median, to a key
parameter of the dataset, called the balancedness $\beta \in (0, 1]$ (with $1$
being perfectly balanced). We show that any algorithm must make $\Omega(1 /
\beta)$ queries to the point set in order to achieve $O(1)$-approximation for
$k$-Median. This particularly implies existing constructions of coresets, a
popular data reduction technique, cannot be query-efficient. On the other hand,
we show a simple uniform sample of $\mathrm{poly}(k \epsilon^{-1} \beta^{-1})$
points suffices for $(1 + \epsilon)$-approximation for $k$-Median for various
metric spaces, which nearly matches the lower bound. We conduct experiments to
verify that in many real datasets, the balancedness parameter is usually well
bounded, and that the uniform sampling performs consistently well even for the
case with moderately large balancedness, which justifies that uniform sampling
is indeed a viable approach for solving $k$-Median.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:35:36 GMT""}]","2023-02-23"
"2302.11341","A. R. Sricharan","Monika Henzinger and A. R. Sricharan and Teresa Anna Steiner","Differentially Private Data Structures under Continual Observation for
  Histograms and Related Queries",,,,,"cs.DS cs.CR","http://creativecommons.org/licenses/by-sa/4.0/","  Binary counting under continual observation is a well-studied fundamental
problem in differential privacy. A natural extension is maintaining column
sums, also known as histogram, over a stream of rows from $\{0,1\}^d$, and
answering queries about those sums, e.g. the maximum column sum or the median,
while satisfying differential privacy. Jain et al. (2021) showed that computing
the maximum column sum under continual observation while satisfying event-level
differential privacy requires an error either polynomial in the dimension $d$
or the stream length $T$. On the other hand, no $o(d\log^2 T)$ upper bound for
$\epsilon$-differential privacy or $o(\sqrt{d}\log^{3/2} T)$ upper bound for
$(\epsilon,\delta)$-differential privacy are known. In this work, we give new
parameterized upper bounds for maintaining histogram, maximum column sum,
quantiles of the column sums, and any set of at most $d$ low-sensitivity,
monotone, real valued queries on the column sums. Our solutions achieve an
error of approximately $O(d\log^2 c_{\max}+\log T)$ for $\epsilon$-differential
privacy and approximately $O(\sqrt{d}\log^{3/2}c_{\max}+\log T)$ for
$(\epsilon,\delta)$-differential privacy, where $c_{\max}$ is the maximum value
that the queries we want to answer can assume on the given data set.
  Furthermore, we show that such an improvement is not possible for a slightly
expanded notion of neighboring streams by giving a lower bound of $\Omega(d
\log T)$. This explains why our improvement cannot be achieved with the
existing mechanisms for differentially private histograms, as they remain
differentially private even for this expanded notion of neighboring streams.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:38:02 GMT""}]","2023-02-23"
"2302.11342","Trishul Dhalia","Trishul Dhalia, Rohit Juneja, Laxman Prasad Goswami, Srimanta Maity
  and Amita Das","Harmonic generation in magnetized plasma for Electromagnetic wave
  propagating parallel to external magnetic field","25 pages, 15 figures",,,,"physics.plasm-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  The harmonic generation has always been of fundamental interest in studying
the nonlinear nature of any physical system. In the present study, Particle -
In - Cell (PIC) simulations have been carried out to explore the harmonic
generation of Electromagnetic waves in a magnetized plasma. The EM wave
propagation is chosen to be parallel to the applied external magnetic field.
The simulations show the excitation of odd higher harmonics of RCP (Right
circularly polarized) and LCP (Left circularly polarized) when the incident
wave is linearly polarised. The harmonic generation is maximum when the
incident EM wave frequency matches the electron cyclotron frequency. When the
incident EM wave has a circular polarization, no harmonics get excited. A
theoretical understanding of these observations has also been provided. The
studies thus show that by appropriately tailoring of plasma parameters EM waves
of higher frequencies and desired nature of circular polarization can be
generated.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:38:39 GMT""}]","2023-02-23"
"2302.11345","Rebecca Crossley","Rebecca M. Crossley, Philip K. Maini, Tommaso Lorenzi, Ruth E. Baker","Travelling waves in a coarse-grained model of volume-filling cell
  invasion: Simulations and comparisons","21 pages, 6 figures",,,,"q-bio.CB math.AP q-bio.PE q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many reaction-diffusion models produce travelling wave solutions that can be
interpreted as waves of invasion in biological scenarios such as wound healing
or tumour growth. These partial differential equation models have since been
adapted to describe the interactions between cells and extracellular matrix
(ECM), using a variety of different underlying assumptions. In this work, we
derive a system of reaction-diffusion equations, with cross-species
density-dependent diffusion, by coarse-graining an agent-based, volume-filling
model of cell invasion into ECM. We study the resulting travelling wave
solutions both numerically and analytically across various parameter regimes.
Subsequently, we perform a systematic comparison between the behaviours
observed in this model and those predicted by simpler models in the literature
which do not take into account volume-filling effects in the same way. Our
study justifies the use of some of these simpler, more analytically tractable
models in reproducing the qualitative properties of the solutions in some
parameter regimes, but it also reveals some interesting properties arising from
the introduction of cell and ECM volume-filling effects, where standard model
simplifications might not be appropriate.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:39:48 GMT""}]","2023-02-23"
"2302.11347","R\'emi Pr\'ebet","Nazrul Islam (Diebold Nixdorf), Adrien Poteaux (CRIStAL) and R\'emi
  Pr\'ebet (PolSys)","Algorithm for connectivity queries on real algebraic curves",,,,,"cs.SC math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of answering connectivity queries on a real algebraic
curve. The curve is given as the real trace of an algebraic curve, assumed to
be in generic position, and being defined by some rational parametrizations.
The query points are given by a zero-dimensional parametrization. We design an
algorithm which counts the number of connected components of the real curve
under study, and decides which query point lie in which connected component, in
time log-linear in $N^6$, where $N$ is the maximum of the degrees and
coefficient bit-sizes of the polynomials given as input. This matches the
currently best-known bound for computing the topology of real plane curves. The
main novelty of this algorithm is the avoidance of the computation of the
complete topology of the curve.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:40:48 GMT""}]","2023-02-23"
"2302.11349","Sangnie Bhardwaj","Sangnie Bhardwaj, Willie McClinton, Tongzhou Wang, Guillaume Lajoie,
  Chen Sun, Phillip Isola, Dilip Krishnan","Steerable Equivariant Representation Learning",,,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  Pre-trained deep image representations are useful for post-training tasks
such as classification through transfer learning, image retrieval, and object
detection. Data augmentations are a crucial aspect of pre-training robust
representations in both supervised and self-supervised settings. Data
augmentations explicitly or implicitly promote invariance in the embedding
space to the input image transformations. This invariance reduces
generalization to those downstream tasks which rely on sensitivity to these
particular data augmentations. In this paper, we propose a method of learning
representations that are instead equivariant to data augmentations. We achieve
this equivariance through the use of steerable representations. Our
representations can be manipulated directly in embedding space via learned
linear maps. We demonstrate that our resulting steerable and equivariant
representations lead to better performance on transfer learning and robustness:
e.g. we improve linear probe top-1 accuracy by between 1% to 3% for transfer;
and ImageNet-C accuracy by upto 3.4%. We further show that the steerability of
our representations provides significant speedup (nearly 50x) for test-time
augmentations; by applying a large number of augmentations for
out-of-distribution detection, we significantly improve OOD AUC on the
ImageNet-C dataset over an invariant representation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:42:45 GMT""}]","2023-02-23"
"2302.11350","Alessandra Sabina Lanotte","Graziano Frungieri, Matthaus U. Babler, Luca Biferale, Alessandra S.
  Lanotte","Ductile Breakup of Tracer Aggregates in Homogenous Isotropic Turbulence",,,,,"physics.flu-dyn nlin.CD","http://creativecommons.org/licenses/by/4.0/","  In this paper we study the ductile breakup of tracer aggregates in an
incompressible, homogeneous, and isotropic three-dimensional turbulent flow.
The flow dynamics is studied by means of a direct numerical simulation, whereas
the Lagrangian velocities and stress statistics along trajectories are obtained
by particle tracking. We investigate the breakup dynamics under the hypothesis
that aggregates are able to deform and accumulate energy. Within this
framework, breakup occurs when the energy transferred to the aggregate by the
flow exceeds a critical value. We contrast our predictions for ductile breakup
with those obtained for brittle breakup. We observe that turbulence
intermittency is crucial for the breakup of brittle aggregates, while it
becomes less relevant for ductile aggregates. In the limit of highly ductile
aggregates the breakup rate is dictated by the mean properties of the flow. We
propose a simple model to capture this behaviour.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:47:22 GMT""}]","2023-02-23"
"2302.11351","Anika Theresa L\""owe","Anika T. L\""owe, L\'eo Touzo, Paul S. Muhle-Karbe, Andrew M. Saxe,
  Christopher Summerfield, Nicolas W. Schuck","Regularised neural networks mimic human insight","17 pages, 5 figures",,,,"cs.AI q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  Humans sometimes show sudden improvements in task performance that have been
linked to moments of insight. Such insight-related performance improvements
appear special because they are preceded by an extended period of impasse, are
unusually abrupt, and occur only in some, but not all, learners. Here, we ask
whether insight-like behaviour also occurs in artificial neural networks
trained with gradient descent algorithms. We compared learning dynamics in
humans and regularised neural networks in a perceptual decision task that
provided a hidden opportunity which allowed to solve the task more efficiently.
We show that humans tend to discover this regularity through insight, rather
than gradually. Notably, neural networks with regularised gate modulation
closely mimicked behavioural characteristics of human insights, exhibiting
delay of insight, suddenness and selective occurrence. Analyses of network
learning dynamics revealed that insight-like behaviour crucially depended on
noise added to gradient updates, and was preceded by ``silent knowledge'' that
is initially suppressed by regularised (attentional) gating. This suggests that
insights can arise naturally from gradual learning, where they reflect the
combined influences of noise, attentional gating and regularisation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:48:45 GMT""}]","2023-02-23"
"2302.11352","Tom van Sonsbeek","Tom van Sonsbeek and Marcel Worring","X-TRA: Improving Chest X-ray Tasks with Cross-Modal Retrieval
  Augmentation","IPMI 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An important component of human analysis of medical images and their context
is the ability to relate newly seen things to related instances in our memory.
In this paper we mimic this ability by using multi-modal retrieval augmentation
and apply it to several tasks in chest X-ray analysis. By retrieving similar
images and/or radiology reports we expand and regularize the case at hand with
additional knowledge, while maintaining factual knowledge consistency. The
method consists of two components. First, vision and language modalities are
aligned using a pre-trained CLIP model. To enforce that the retrieval focus
will be on detailed disease-related content instead of global visual appearance
it is fine-tuned using disease class information. Subsequently, we construct a
non-parametric retrieval index, which reaches state-of-the-art retrieval
levels. We use this index in our downstream tasks to augment image
representations through multi-head attention for disease classification and
report retrieval. We show that retrieval augmentation gives considerable
improvements on these tasks. Our downstream report retrieval even shows to be
competitive with dedicated report generation methods, paving the path for this
method in medical imaging.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:53:33 GMT""}]","2023-02-23"
"2302.11353","Samuel Sloetjes","Samuel D. Sl\""oetjes, Mat\'ias P. Grassi, Vassilios Kapaklis","Polymerization in magnetic metamaterials",,,,,"cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  We numerically study a mesoscopic system consisting of magnetic nanorings in
the presence of thermal magnetization fluctuations. We find the formation of
dipolar-field-mediated ``bonds"" promoting the formation of annuli clusters,
where the amount of bonds between two rings varies between zero and two. This
system resembles the formation of polymers from artificial atoms, which in our
case are the annuli and where the valency of the atom is set by the ring
multipolarity. We investigate the thermodynamic properties of the resulting
structures, and find a transition associated with the formation of the bonds.
In addition, we find that the system has a tendency to form topological
structures, with a distinct critical temperature in relation to the one for
bond formation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:55:13 GMT""}]","2023-02-23"
"2302.11354","Tiexin Qin","Tiexin Qin and Benjamin Walker and Terry Lyons and Hong Yan and
  Haoliang Li","Learning Dynamic Graph Embeddings with Neural Controlled Differential
  Equations","13 pages, 3 figures",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper focuses on representation learning for dynamic graphs with
temporal interactions. A fundamental issue is that both the graph structure and
the nodes own their own dynamics, and their blending induces intractable
complexity in the temporal evolution over graphs. Drawing inspiration from the
recent process of physical dynamic models in deep neural networks, we propose
Graph Neural Controlled Differential Equation (GN-CDE) model, a generic
differential model for dynamic graphs that characterise the continuously
dynamic evolution of node embedding trajectories with a neural network
parameterised vector field and the derivatives of interactions w.r.t. time. Our
framework exhibits several desirable characteristics, including the ability to
express dynamics on evolving graphs without integration by segments, the
capability to calibrate trajectories with subsequent data, and robustness to
missing observations. Empirical evaluation on a range of dynamic graph
representation learning tasks demonstrates the superiority of our proposed
approach compared to the baselines.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:59:38 GMT""}]","2023-02-23"
"2302.11355","Soubhik Kumar","Soubhik Kumar, Rafiqul Rahaman, Ritesh K. Singh","Measuring Electroweak Quantum Numbers of Color Sextet Resonances at the
  LHC",,,,,"hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the prospect of measuring the electroweak quantum numbers of beyond
the Standard Model (SM) color sextet particles that decay into same-sign top
quark pairs. Among these particles, the color sextet scalars give rise to top
quarks with the same chirality, while the top quarks coming from the color
sextet vector would have opposite chirality. This difference gets encoded in
the angular distributions of the bottom quarks and leptons originating from the
decays of the top quarks. We utilize this feature and the energy distributions
of the final state jets and leptons to distinguish among the three possible
color sextet resonances, taking into account various SM background processes.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:02:44 GMT""}]","2023-02-23"
"2302.11356","Haiyi Mao","Haiyi Mao, Cong Peng, Yue Liu, Jinping Tang, Hua Peng and Wei Yi","Poisson Conjugate Prior for PHD Filtering based Track-Before-Detect
  Strategies in Radar Systems","in 2023 IEEE Radar Conference (RadarConf2023), 2023",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A variety of filters with track-before-detect (TBD) strategies have been
developed and applied to low signal-to-noise ratio (SNR) scenarios, including
the probability hypothesis density (PHD) filter. Assumptions of the standard
point measurement model based on detect-before-track (DBT) strategies are not
suitable for the amplitude echo model based on TBD strategies. However, based
on different models and unmatched assumptions, the measurement update formulas
for DBT-PHD filter are just mechanically applied to existing TBD-PHD filters.
In this paper, based on the Kullback-Leibler divergence minimization criterion,
finite set statistics theory and rigorous Bayes rule, a principled closed-form
solution of TBD-PHD filter is derived. Furthermore, we emphasize that PHD
filter is conjugated to the Poisson prior based on TBD strategies. Next, a
capping operation is devised to handle the divergence of target number
estimation as SNR increases. Moreover, the sequential Monte Carlo
implementations of dynamic and amplitude echo models are proposed for the radar
system. Finally, Monte Carlo experiments exhibit good performance in Rayleigh
noise and low SNR scenarios.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:03:31 GMT""}]","2023-02-23"
"2302.11357","Rajib Chattopadhyay","Lekshmi S, Rajib Chattopadhyay, D.S. Pai, M. Rajeevan, Vinu Valsala,
  K.S. Hosalikar, M. Mohapatra","On the Relative Role of East and West Pacific Sea Surface Temperature
  (SST) Gradients in the Prediction Skill of Central Pacific NINO3.4 SST","21 pages, 11 figures",,,,"physics.ao-ph physics.data-an","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Dominant modes of SST in the west and east Pacific show strong but regionally
different gradients caused by waves, internal dynamics, and anthropogenic
warming, which drives air-sea interaction in the Pacific. The study discusses
the relative contribution of SST gradients over the western and eastern Pacific
to the prediction skill of SST in the central Pacific, where El-Nino, La-Nina,
or El-Nino Modoki events project significantly. For this, the analysis develops
a convolutional neural network (CNN) based prediction model to predict the
Nino3.4 SST. CNN-based prediction models use a spatial filter at the initial
stage, which is highly efficient in capturing the edges or gradients and hence
are useful to understand the role of SST spatial gradients in the prediction
skill. The study reports three CNN-based model experiments. The first one is a
CTRL experiment that uses the whole equatorial Pacific domain SST pattern. The
second and third models use the equatorial eastern and western Pacific domain
SST only. Another novel feature of this study is that we have generated a large
number of ensemble members (5000) through random initialization of CNN filters.
It is found that random initialization affects the forecast skill, and the
probability density function of the correlation skill of the 5000 models at
each lead time shows a gaussian distribution. The model experiments suggest
that the west Pacific SST model provides better Nino3.4 skills as compared to
the east Pacific skill. The CNN-based model forecast based on the SST pattern,
thus, shows the impact of the SST spatial pattern on the ENSO forecast.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:05:52 GMT""}]","2023-02-23"
"2302.11358","Carlos Segarra","Simon Shillaker, Carlos Segarra, Eleftheria Mappoura, Mayeul Fournial,
  Lluis Vilanova, Peter Pietzuch","Faabric: Fine-Grained Distribution of Scientific Workloads in the Cloud","12 pages",,,,"cs.DC cs.OS","http://creativecommons.org/licenses/by/4.0/","  With their high parallelism and resource needs, many scientific applications
benefit from cloud deployments. Today, scientific applications are executed on
dedicated pools of VMs, resulting in resource fragmentation: users pay for
underutilised resources, and providers cannot reallocate unused resources
between applications. While serverless cloud computing could address these
issues, its programming model is incompatible with the use of shared memory and
message passing in scientific applications: serverless functions do not share
memory directly on the same VM or support message passing semantics when
scheduling functions dynamically.
  We describe Faabric, a new serverless cloud runtime that transparently
distributes applications with shared memory and message passing across VMs.
Faabric achieves this by scheduling computation in a fine-grained
(thread/process) fashion through a new execution abstraction called Granules.
To support shared memory, Granules are isolated using WebAssembly but share
memory directly; to support message passing, Granules offer asynchronous
point-to-point communication. Faabric schedules Granules to meet an
application's parallelism needs. It also synchronises changes to Granule's
shared memory, and migrates Granules to improve locality.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:10:07 GMT""}]","2023-02-23"
"2302.11359","Jacob Fields","Jacob Fields, Aviral Prakash, Matteo Breschi, David Radice, Sebastiano
  Bernuzzi, Andr\'e da Silva Schneider","Thermal Effects in Binary Neutron Star Mergers","5 pages, 3 figures",,,,"astro-ph.HE gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the impact of finite-temperature effects in numerical-relativity
simulations of binary neutron star mergers with finite-temperature
microphysical equations of state and neutrino transport in which we vary the
effective nucleon masses in a controlled way. We find that, as the specific
heat is increased, the merger remnants become colder and more compact due to
the reduced thermal pressure support. Using a full Bayesian analysis, we
demonstrate that this effect will be measurable in the postmerger gravitational
wave signal with next-generation observatories at signal-to-noise ratios as low
as 10, i.e., close to the detectability threshold of post-merger signals.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:14:26 GMT""}]","2023-02-23"
"2302.11360","Fernando Diaz","Andres Ferraro, Gustavo Ferreira, Fernando Diaz, Georgina Born","Commonality in Recommender Systems: Evaluating Recommender Systems to
  Enhance Cultural Citizenship","extended version of ""Measuring Commonality in Recommendation of
  Cultural Content: Recommender Systems to Enhance Cultural Citizenship"",
  published at RecSys 2022",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recommender systems have become the dominant means of curating cultural
content, significantly influencing individual cultural experience. Since
recommender systems tend to optimize for personalized user experience, they can
overlook impacts on cultural experience in the aggregate. After demonstrating
that existing metrics do not center culture, we introduce a new metric,
commonality, that measures the degree to which recommendations familiarize a
given user population with specified categories of cultural content. We
developed commonality through an interdisciplinary dialogue between researchers
in computer science and the social sciences and humanities. With reference to
principles underpinning public service media systems in democratic societies,
we identify universality of address and content diversity in the service of
strengthening cultural citizenship as particularly relevant goals for
recommender systems delivering cultural content. We develop commonality as a
measure of recommender system alignment with the promotion of content toward a
shared cultural experience across a population of users. We empirically compare
the performance of recommendation algorithms using commonality with existing
metrics, demonstrating that commonality captures a novel property of system
behavior complementary to existing metrics. Alongside existing fairness and
diversity metrics, commonality contributes to a growing body of scholarship
developing `public good' rationales for machine learning systems.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:16:55 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 02:46:12 GMT""}]","2023-02-24"
"2302.11361","Ahmed Khan","Ahmed Khan, Minoru Kuribayashi, KokSheik Wong, Vishnu Monn Baskaran","HDR image watermarking using saliency detection and quantization index
  modulation",,,,,"cs.CV cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-dynamic range (HDR) images are circulated rapidly over the internet with
risks of being exploited for unauthorized usage. To protect these images, some
HDR image based watermarking (HDR-IW) methods were put forward. However, they
inherited the same problem faced by conventional IW methods for standard
dynamic range (SDR) images, where only trade-offs among conflicting
requirements are managed instead of simultaneous improvement. In this paper, a
novel saliency (eye-catching object) detection based trade-off independent
HDR-IW is proposed, to simultaneously improve robustness, imperceptibility and
payload. First, the host image goes through our proposed salient object
detection model to produce a saliency map, which is, in turn, exploited to
segment the foreground and background of the host image. Next, the binary
watermark is partitioned into the foregrounds and backgrounds using the same
mask and scrambled using a random permutation algorithm. Finally, the watermark
segments are embedded into selected bit-plane of the corresponding host
segments using quantized indexed modulation. Experimental results suggest that
the proposed work outperforms state-of-the-art methods in terms of improving
the conflicting requirements.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:25:29 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 08:55:04 GMT""}]","2023-02-24"
"2302.11362","Yuchen Hu","Yuchen Hu, Chen Chen, Ruizhe Li, Qiushi Zhu, Eng Siong Chng","Gradient Remedy for Multi-Task Learning in End-to-End Noise-Robust
  Speech Recognition","5 pages, 5 figures, Accepted by ICASSP 2023",,,,"eess.AS cs.LG cs.SD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Speech enhancement (SE) is proved effective in reducing noise from noisy
speech signals for downstream automatic speech recognition (ASR), where
multi-task learning strategy is employed to jointly optimize these two tasks.
However, the enhanced speech learned by SE objective may not always yield good
ASR results. From the optimization view, there sometimes exists interference
between the gradients of SE and ASR tasks, which could hinder the multi-task
learning and finally lead to sub-optimal ASR performance. In this paper, we
propose a simple yet effective approach called gradient remedy (GR) to solve
interference between task gradients in noise-robust speech recognition, from
perspectives of both angle and magnitude. Specifically, we first project the SE
task's gradient onto a dynamic surface that is at acute angle to ASR gradient,
in order to remove the conflict between them and assist in ASR optimization.
Furthermore, we adaptively rescale the magnitude of two gradients to prevent
the dominant ASR task from being misled by SE gradient. Experimental results
show that the proposed approach well resolves the gradient interference and
achieves relative word error rate (WER) reductions of 9.3% and 11.1% over
multi-task learning baseline, on RATS and CHiME-4 datasets, respectively. Our
code is available at GitHub.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:31:13 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 05:06:51 GMT""}]","2023-05-04"
"2302.11363","Maria Francesca  Marino","Marco Alf\'o, Maria Francesca Marino, Maria Giovanna Ranalli, Nicola
  Salvati","lqmix: an R package for longitudinal data analysis via linear quantile
  mixtures","25 pages, 2 figures",,,,"stat.CO stat.ME","http://creativecommons.org/licenses/by/4.0/","  The analysis of longitudinal data poses a series of issues, but it also gives
the chance to observe changes in the unit behavior over time which may be of
prime interest. This has been the focus of a huge literature in the context of
linear and generalized linear regression which, in the last ten years or so,
has moved to the context of linear quantile regression models for continuous
responses. In this paper, we present lqmix, a novel R package that helps
estimate a class of linear quantile regression models for longitudinal data, in
the presence of time-constant and/or time-varying, unit-specific, random
coefficients, having unspecific distribution. Model parameters are estimated in
a maximum likelihood framework, via an extended EM algorithm, and parameters'
standard errors are estimated via a block-bootstrap procedure. The analysis of
a benchmark dataset is used to give details of the package functions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:32:06 GMT""}]","2023-02-23"
"2302.11364","Paolo Panicucci","Paolo Panicucci, J\'er\'emy Lebreton, Roland Brochard, Emmanuel Zenou,
  and Michel Delpech","Vision-Based Estimation of Small Body Rotational State during the
  Approach Phase",,,,,"astro-ph.EP astro-ph.IM cs.CV","http://creativecommons.org/licenses/by/4.0/","  The heterogeneity of the small body population complicates the prediction of
the small body properties before the spacecraft's arrival. In the context of
autonomous small body exploration, it is crucial to develop algorithms that
estimate the small body characteristics before orbit insertion and close
proximity operations. This paper develops a vision-based estimation of the
small-body rotational state (i.e., the center of rotation and rotation axis
direction) during the approach phase. In this mission phase, the spacecraft
observes the celestial body rotating and tracks features in images. As feature
tracks are the projection of landmarks' circular movement, the possible
rotation axes are computed. Then, the rotation axis solution is chosen among
the possible candidates by exploiting feature motion and a heuristic approach.
Finally, the center of rotation is estimated from the center of brightness. The
algorithm is tested on more than 800 test cases with two different asteroids
(i.e., Bennu and Itokawa), three different lighting conditions, and more than
100 different rotation axis orientations. Results show that the rotation axis
can be determined with limited error in most cases implying that the proposed
algorithm is a valuable method for autonomous small body characterization.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:32:58 GMT""}]","2023-02-23"
"2302.11365","Shantanu Agarwal","Shantanu Agarwal, Steven Fincke, Chris Jenkins, Scott Miller,
  Elizabeth Boschee","Impact of Subword Pooling Strategy on Cross-lingual Event Detection",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Pre-trained multilingual language models (e.g., mBERT, XLM-RoBERTa) have
significantly advanced the state-of-the-art for zero-shot cross-lingual
information extraction. These language models ubiquitously rely on word
segmentation techniques that break a word into smaller constituent subwords.
Therefore, all word labeling tasks (e.g. named entity recognition, event
detection, etc.), necessitate a pooling strategy that takes the subword
representations as input and outputs a representation for the entire word.
Taking the task of cross-lingual event detection as a motivating example, we
show that the choice of pooling strategy can have a significant impact on the
target language performance. For example, the performance varies by up to 16
absolute $f_{1}$ points depending on the pooling strategy when training in
English and testing in Arabic on the ACE task. We carry out our analysis with
five different pooling strategies across nine languages in diverse
multi-lingual datasets. Across configurations, we find that the canonical
strategy of taking just the first subword to represent the entire word is
usually sub-optimal. On the other hand, we show that attention pooling is
robust to language and dataset variations by being either the best or close to
the optimal strategy. For reproducibility, we make our code available at
https://github.com/isi-boston/ed-pooling.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:33:21 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 02:04:27 GMT""}]","2023-02-24"
"2302.11366","Neepa T. Maitra","Lionel Lacombe and Neepa T. Maitra","Non-Adiabatic Approximations in Time-Dependent Density Functional
  Theory: Progress and Prospects",,,,,"physics.chem-ph cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Time-dependent density functional theory continues to draw a large number of
users in a wide range of fields exploring myriad applications involving
electronic spectra and dynamics. Although in principle exact, the predictivity
of the calculations is limited by the available approximations for the
exchange-correlation functional. In particular, it is known that the exact
exchange-correlation functional has memory-dependence, but in practise
adiabatic approximations are used which ignore this. Here we review the
development of non-adiabatic functional approximations, their impact on
calculations, and challenges in developing practical and accurate
memory-dependent functionals for general purposes.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:33:58 GMT""},{""version"":""v2"",""created"":""Wed, 3 May 2023 21:43:45 GMT""}]","2023-05-05"
"2302.11367","Matteo Sfragara","Daniel Ahlberg, Maria Deijfen, Matteo Sfragara","Chaos, concentration and multiple valleys in first-passage percolation","30 pages, 2 figures. A video summary may be found at
  https://youtu.be/Y29t_KUzv7k",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A decade and a half ago Chatterjee established the first rigorous connection
between anomalous fluctuations and a chaotic behaviour of the ground state in
certain Gaussian disordered systems. The purpose of this paper is to show that
Chatterjee's work gives evidence of a more general principle, by establishing
an analogous connection between fluctuations and chaos in the context of
first-passage percolation. The notion of `chaos' here refers to the sensitivity
of the time-minimising path between two points when exposed to a slight
perturbation. More precisely, we resample a small proportion of the edge
weights, and find that a vanishing fraction of the edges on the
distance-minimising path still belongs to the time-minimising path obtained
after resampling. We also show that the chaotic behaviour implies the existence
of a large number of almost-optimal paths that are almost disjoint from the
time-minimising path, a phenomenon known as `multiple valleys'.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:35:52 GMT""}]","2023-02-23"
"2302.11368","Rafa{\l} Lutowski","Rafa{\l} Lutowski and Andrzej Szczepa\'nski","Minimal non-solvable Bieberbach groups",,,,,"math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It has been shown by several authors that there exists a non-solvable
Bieberbach group of dimension $15$. In this note we show that this is in fact a
minimal dimension for such kind of groups.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:39:29 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 07:58:26 GMT""}]","2023-02-24"
"2302.11369","Misha Padidar","David Bindel, Matt Landreman, Misha Padidar","Direct Optimization of Fast-Ion Confinement in Stellarators",,,"10.1088/1361-6587/acd141",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  Confining energetic ions such as alpha particles is a prime concern in the
design of stellarators. However, directly measuring alpha confinement through
numerical simulation of guiding-center trajectories has been considered to be
too computationally expensive and noisy to include in the design loop, and
instead has been most often used only as a tool to assess stellarator designs
post hoc. In its place, proxy metrics, simplified measures of confinement, have
often been used to design configurations because they are computationally more
tractable and have been shown to be effective. Despite the success of proxies,
it is unclear what is being sacrificed by using them to design the device
rather than relying on direct trajectory calculations. In this study, we
optimize stellarator designs for improved alpha particle confinement without
the use of proxy metrics. In particular, we numerically optimize an objective
function that measures alpha particle losses by simulating alpha particle
trajectories. While this method is computationally expensive, we find that it
can be used successfully to generate configurations with low losses.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:39:33 GMT""}]","2023-05-24"
"2302.11370","Fernando Diaz","Fernando Diaz, Bhaskar Mitra","Recall, Robustness, and Lexicographic Evaluation","Under review",,,,"cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Researchers use recall to evaluate rankings across a variety of retrieval,
recommendation, and machine learning tasks. While there is a colloquial
interpretation of recall in set-based evaluation, the research community is far
from a principled understanding of recall metrics for rankings. The lack of
principled understanding of or motivation for recall has resulted in criticism
amongst the retrieval community that recall is useful as a measure at all. In
this light, we reflect on the measurement of recall in rankings from a formal
perspective. Our analysis is composed of three tenets: recall, robustness, and
lexicographic evaluation. First, we formally define `recall-orientation' as
sensitivity to movement of the bottom-ranked relevant item. Second, we analyze
our concept of recall orientation from the perspective of robustness with
respect to possible searchers and content providers. Finally, we extend this
conceptual and theoretical treatment of recall by developing a practical
preference-based evaluation method based on lexicographic comparison. Through
extensive empirical analysis across 17 TREC tracks, we establish that our new
evaluation method, lexirecall, is correlated with existing recall metrics and
exhibits substantially higher discriminative power and stability in the
presence of missing labels. Our conceptual, theoretical, and empirical analysis
substantially deepens our understanding of recall and motivates its adoption
through connections to robustness and fairness.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:39:54 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 02:44:32 GMT""},{""version"":""v3"",""created"":""Mon, 24 Apr 2023 00:06:59 GMT""}]","2023-04-25"
"2302.11371","Antonio Briola","David Vidal-Tom\'as, Antonio Briola, Tomaso Aste","FTX's downfall and Binance's consolidation: the fragility of Centralized
  Digital Finance","23 pages, 10 figures, 2 tables",,,,"q-fin.GN q-fin.ST","http://creativecommons.org/licenses/by-nc-nd/4.0/","  This paper investigates the causes of the FTX digital currency exchange's
failure in November 2022. We identify the collapse of the Terra-Luna ecosystem
as the pivotal event that triggered a significant decrease in the exchange's
liquidity. Analysing on-chain data, we report that FTX heavily relied on
leveraging and misusing its native token, FTT, and we show how this behaviour
exacerbated the company's fragile financial situation. To gain further insights
into the downfall, we study evolutionary dependency structures of 199
cryptocurrencies on an hourly basis, and we investigate public trades at the
time of the events. Results suggest that the collapse was actively accelerated
by Binance tweets causing a systemic reaction in the cryptocurrency market.
Finally, identifying the actors who mostly benefited from the FTX's collapse
and highlighting a generalised trend toward centralisation in the crypto space,
we emphasise the importance of genuinely decentralised finance for a
transparent, future digital economy.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:42:29 GMT""},{""version"":""v2"",""created"":""Wed, 5 Apr 2023 06:52:39 GMT""}]","2023-04-06"
"2302.11372","Felipe Matus","Felipe Matus, Jan St\v{r}ele\v{c}ek, Pavel Cejnar","Analytic approach to the Landau-Zener problem in bounded parameter space","21 pages, 8 figures",,"10.1088/1751-8121/accf4f",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three analytic solutions to the Schr\""{o}dinger equation for the
time-dependent Landau-Zener Hamiltonian are presented. They correspond to
specific finite-time driving paths in a bounded parameter space of a two-level
system. Two of these paths go through the avoided crossing of levels, either
with a constant speed or with variable speed that decreases in the region of
reduced energy gap, the third path bypasses the crossing such that the energy
gap remains constant. The solutions yield exact time dependencies of the
excitation probability for the system evolving from the ground state of the
initial Hamiltonian. The Landau-Zener formula emerges as an approximation valid
within a certain interval of driving times for the constant-speed driving
through the avoided crossing. For long driving times, all solutions converge to
the prediction of the adiabatic perturbation theory. The excitation probability
vanishes at some discrete time instants.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:43:34 GMT""},{""version"":""v2"",""created"":""Fri, 5 May 2023 13:01:15 GMT""}]","2023-05-24"
"2302.11373","Bairen Zhu","Bairen Zhu, Ke Xiao, Siyuan Yang, Kenji Watanabe, Takashi Taniguchi,
  Xiaodong Cui","In-Plane Electric Field Induced Orbital Hybridization of Excitonic
  States In Monolayer WSe2",,,,,"cond-mat.mes-hall physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  The giant exciton binding energy and the richness of degrees of freedom make
monolayer transition metal dichalcogenide an unprecedented playground for
exploring exciton physics in 2D systems. Thanks to the well energetically
separated excitonic states, the response of the discrete excitonic states to
the electric field could be precisely examined. Here we utilize the
photocurrent spectroscopy to probe excitonic states under a static in-plane
electric field. We demonstrate that the in-plane electric field leads to a
significant orbital hybridization of Rydberg excitonic states with different
angular momentum (especially orbital hybridization of 2s and 2p) and
consequently optically actives 2p-state exciton. Besides, the electric-field
controlled mixing of the high lying exciton state and continuum band enhances
the oscillator strength of the discrete excited exciton states. This electric
field modulation of the excitonic states in monolayer TMDs provides a paradigm
of the manipulation of 2D excitons for potential applications of the
electro-optical modulation in 2D semiconductors.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:44:10 GMT""}]","2023-02-23"
"2302.11374","Alessandro Mura PhD","Alessandro Mura","Energetic Neutral Atom Imaging of Planetary Environments","PhD Thesis",,,,"astro-ph.EP astro-ph.IM physics.plasm-ph physics.space-ph","http://creativecommons.org/licenses/by/4.0/","  The aim of this work is to investigate the applications of the neutral atom
imaging to the environments of the Earth, Mars and Mercury. This innovative
technique permits the study of energetic plasma by means of analysing the
result of the interaction of this plasma with a neutral thermal population or
with a surface. The main advantage, when compared to the direct ion detection,
is that it is possible to have an instantaneous survey of the whole
magnetosphere of a planet. An example could help. Before the first ENA data,
most of the knowledge about the Earth magnetospheric plasma came from in situ
measurements of ions, electrons and electromagnetic fields. Those measurements,
of course, could not represent any real instantaneous situation, but only an
averaged picture of it, since the temporal and spatial variation cannot be
easily be distinguished. Some short time scale phenomena, such as substorms,
have been found difficult to comprehend without a global and continuous
imaging. Even if some information about the plasma may be extracted from other
sources, such as UV imaging [like aurorae, e.g. Horwitz, 1987], some
populations (for example, the ring current) remained invisible. Furthermore,
neutral atom imaging gives information not only about the energetic plasma, but
also about the thermal neutral population (in the case of charge-exchange) or
about the surface composition (in the case of sputtering). Conversely, it is
necessary to set up some dedicated unfolding techniques to recover the 3D
plasma distributions from the 2D ENA images.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:46:02 GMT""}]","2023-02-23"
"2302.11375","Stefano Pozza","Stefano Pozza","A new closed-form expression for the solution of ODEs in a ring of
  distributions and its connection with the matrix algebra",,,,,"math.NA cs.NA","http://creativecommons.org/licenses/by/4.0/","  A new expression for solving homogeneous linear ODEs based on a
generalization of the Volterra composition was recently introduced. In this
work, we extend such an expression, showing that it corresponds to inverting an
infinite matrix. This is done by studying a particular subring and connecting
it with a subalgebra of infinite matrices.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:48:03 GMT""}]","2023-02-23"
"2302.11376","Timo Mitze","Bj\""orn Alecke and Timo Mitze","Institutional reforms and the employment effects of spatially targeted
  investment grants: The case of Germany's GRW",,,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Spatially targeted investment grant schemes are a common tool to support
firms in lagging regions. We exploit exogenous variations in Germany's main
regional policy instrument (GRW) arriving from institutional reforms to analyse
local employment effects of investment grants. Findings for reduced-form and IV
regressions point to a significant policy channel running from higher funding
rates to increased firm-level investments and newly created jobs. When we
contrast effects for regions with high but declining funding rates to those
with low but rising rates, we find that GRW reforms led to diminishing
employment increases. Especially small firms responded to changing funding
conditions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:49:51 GMT""}]","2023-02-23"
"2302.11377","Masashi Aiko","Masashi Aiko and Motoi Endo","Electroweak precision test of axion-like particles","32 pages, 8 figures, version accepted by JHEP",,"10.1007/JHEP05(2023)147","KEK-TH-2497","hep-ph","http://creativecommons.org/licenses/by/4.0/","  We study the contributions of an axion-like particle to the electroweak
precision observables. The particle is assumed to couple with the standard
model electroweak gauge bosons. We provide the formulae of the contributions
valid for any mass of the axion-like particle. It is found that the effects
arise not only via the oblique $S$ and $U$ parameters but also via radiative
corrections to the gauge couplings. Besides, the decay of $Z\to a\gamma$
affects the total width of the $Z$ boson. All of those contributions are
considered simultaneously in the global fit analysis of the electroweak
precision observables. Also, we discuss the recent CDF result of the $W$-boson
mass measurement. Since the model is tightly constrained by flavor and collider
constraints, it is found that the discrepancy from the standard model
prediction is solved only when the axion-like particle is heavier than 500 GeV
and its coupling to di-photon is suppressed.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:50:12 GMT""},{""version"":""v2"",""created"":""Tue, 16 May 2023 15:46:05 GMT""}]","2023-05-31"
"2302.11378","The Tien Mai","T. Tien Mai, Gerry Tonkin-Hill, John A. Lees, Jukka Corander","Quantifying the common genetic variability of bacterial traits",,,,,"q-bio.GN","http://creativecommons.org/licenses/by/4.0/","  The study of common heritability, or co-heritability, among multiple traits
has been widely established in quantitative and molecular genetics. However, in
bacteria, genome-based estimation of heritability has only been considered very
recently and no methods are currently available for considering
co-heritability. Here we introduce such a method and demonstrate its usefulness
by multi-trait analyses of the three major human pathogens \textit{Escherichia
coli}, \textit{Neisseria gonorrhoeae} and \textit{Streprococcus pneumoniae}. We
anticipate that the increased availability of high-throughput genomic and
phenotypic screens of bacterial populations will spawn ample future
opportunities to understand the common molecular basis of different traits in
bacteria.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:52:40 GMT""}]","2023-02-23"
"2302.11379","Matteo Sfragara","Daniel Ahlberg, Maria Deijfen, Matteo Sfragara","From stability to chaos in last-passage percolation","11 pages. A video summary may be found at
  https://youtu.be/Y29t_KUzv7k",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the transition from stability to chaos in a dynamic last passage
percolation model on $\mathbb{Z}^d$ with random weights at the vertices. Given
an initial weight configuration at time $0$, we perturb the model over time in
such a way that the weight configuration at time $t$ is obtained by resampling
each weight independently with probability $t$. On the square $[0,n]^2$, we
study geodesics, that is, weight-maximizing up-right paths from $(0,0)$ to
$(n,n)$, and their passage time $T$. Under mild conditions on the weight
distribution, we prove a phase transition between stability and chaos at $t
\asymp \frac{\mathrm{Var}(T)}{n}$. Indeed, as $n$ grows large, for small values
of $t$, the passage times at time $0$ and time $t$ are highly correlated, while
for large values of $t$, the geodesics become almost disjoint.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:52:51 GMT""}]","2023-02-23"
"2302.11380","Nesma Talaat Abbas Mahmoud","Nesma Mahmoud, Hanna Antson, Jaesik Choi, Osamu Shimmi, Kallol Roy","Stress and Adaptation: Applying Anna Karenina Principle in Deep Learning
  for Image Classification",,,,"12nesma","cs.LG cs.AI","http://creativecommons.org/licenses/by-nc-nd/4.0/","  Image classification with deep neural networks has reached state-of-art with
high accuracy. This success is attributed to good internal representation
features that bypasses the difficulties of the non-convex optimization
problems. We have little understanding of these internal representations, let
alone quantifying them. Recent research efforts have focused on alternative
theories and explanations of the generalizability of these deep networks. We
propose the alternative perturbation of deep models during their training
induces changes that lead to transitions to different families. The result is
an Anna Karenina Principle AKP for deep learning, in which less generalizable
models unhappy families vary more in their representation than more
generalizable models happy families paralleling Leo Tolstoy dictum that all
happy families look alike, each unhappy family is unhappy in its own way. Anna
Karenina principle has been found in systems in a wide range: from the surface
of endangered corals exposed to harsh weather to the lungs of patients
suffering from fatal diseases of AIDs. In our paper, we have generated
artificial perturbations to our model by hot-swapping the activation and loss
functions during the training. In this paper, we build a model to classify
cancer cells from non-cancer ones. We give theoretical proof that the internal
representations of generalizable happy models are similar in the asymptotic
limit. Our experiments verify similar representations of generalizable models.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:53:20 GMT""}]","2023-02-23"
"2302.11381","Emmeran Johnson","Emmeran Johnson, Ciara Pike-Burke, Patrick Rebeschini","Optimal Convergence Rate for Exact Policy Mirror Descent in Discounted
  Markov Decision Processes","33 pages, 1 figure. New result (Theorem 3) on necessity of adaptive
  step-size",,,,"math.OC cs.LG math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  Policy Mirror Descent (PMD) is a general family of algorithms that covers a
wide range of novel and fundamental methods in reinforcement learning.
Motivated by the instability of policy iteration (PI) with inexact policy
evaluation, unregularised PMD algorithmically regularises the policy
improvement step of PI without regularising the objective function. With exact
policy evaluation, PI is known to converge linearly with a rate given by the
discount factor $\gamma$ of a Markov Decision Process. In this work, we bridge
the gap between PI and PMD with exact policy evaluation and show that the
dimension-free $\gamma$-rate of PI can be achieved by the general family of
unregularised PMD algorithms under an adaptive step-size. We show that both the
rate and step-size are unimprovable for PMD: we provide matching lower bounds
that demonstrate that the $\gamma$-rate is optimal for PMD methods as well as
PI and that the adaptive step-size is necessary to achieve it. Our work is the
first to relate PMD to rate-optimality and step-size necessity. Our study of
the convergence of PMD avoids the use of the performance difference lemma,
which leads to a direct analysis of independent interest. We also extend the
analysis to the inexact setting and establish the first dimension-optimal
sample complexity for unregularised PMD under a generative model, improving
upon the best-known result.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:55:08 GMT""},{""version"":""v2"",""created"":""Tue, 30 May 2023 14:30:52 GMT""}]","2023-05-31"
"2302.11383","Yikai Wang","Yikai Wang, Jianan Wang, Guansong Lu, Hang Xu, Zhenguo Li, Wei Zhang,
  and Yanwei Fu","Entity-Level Text-Guided Image Manipulation","Extension of our CVPR 2022 oral paper: 2204.04428. Yikai Wang and
  Jianan Wang contribute equally. The arxiv version uses small size figures for
  fast preview, the full size pdf version can be found in our project page:
  https://yikai-wang.github.io/semani/. arXiv admin note: substantial text
  overlap with arXiv:2204.04428",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing text-guided image manipulation methods aim to modify the appearance
of the image or to edit a few objects in a virtual or simple scenario, which is
far from practical applications. In this work, we study a novel task on
text-guided image manipulation on the entity level in the real world (eL-TGIM).
The task imposes three basic requirements, (1) to edit the entity consistent
with the text descriptions, (2) to preserve the entity-irrelevant regions, and
(3) to merge the manipulated entity into the image naturally. To this end, we
propose an elegant framework, dubbed as SeMani, forming the Semantic
Manipulation of real-world images that can not only edit the appearance of
entities but also generate new entities corresponding to the text guidance. To
solve eL-TGIM, SeMani decomposes the task into two phases: the semantic
alignment phase and the image manipulation phase. In the semantic alignment
phase, SeMani incorporates a semantic alignment module to locate the
entity-relevant region to be manipulated. In the image manipulation phase,
SeMani adopts a generative model to synthesize new images conditioned on the
entity-irrelevant regions and target text descriptions. We discuss and propose
two popular generation processes that can be utilized in SeMani, the discrete
auto-regressive generation with transformers and the continuous denoising
generation with diffusion models, yielding SeMani-Trans and SeMani-Diff,
respectively. We conduct extensive experiments on the real datasets CUB,
Oxford, and COCO datasets to verify that SeMani can distinguish the
entity-relevant and -irrelevant regions and achieve more precise and flexible
manipulation in a zero-shot manner compared with baseline methods. Our codes
and models will be released at https://github.com/Yikai-Wang/SeMani.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:56:23 GMT""}]","2023-02-23"
"2302.11384","Soumya Bera","Ferdinand Evers and Soumya Bera","The internal clock of many-body (de-)localization","15 pages, 12+2 figures",,,,"cond-mat.dis-nn cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  After a decade of many claims to the opposite, there now is a growing
consensus that generic disordered quantum wires, e.g. the XXZ-Heisenberg chain,
do not exhibit many-body localization (MBL) - at least not in a strict sense
within a reasonable window of disorder values $W$. Specifically, computational
studies of short wires exhibit an extremely slow but unmistakable flow of
physical observables with increasing time and system size (``creep"") that is
consistently directed away from (strict) localization. Our work sheds fresh
light on delocalization physics: Strong sample-to-sample fluctuations indicate
the absence of a generic time scale, i.e. of a naive ``clock rate""; however,
the concept of an ``internal clock"" survives, at least in an ensemble sense.
Specifically, we investigate the relaxation of the imbalance $\mathcal{I}(t)$
and its temporal fluctuations $\mathcal{F}(t)$, the entanglement and Renyi
entropies, $\mathcal{S}_{\mathrm{e}}(t)$ and $ \mathcal{S}_2(t)$, in a 1D
system of interacting disordered fermions. We observe that adopting
$\mathcal{S}_{\mathrm{e}}(t), \mathcal{S}_2(t)$ as a measure for the internal
time per sample reduces the sample-to-sample fluctuations but does not
eliminate them. However, a (nearly) perfect collapse of the average
$\overline{\mathcal{I}}(t)$ and $\overline{\mathcal{F}}(t)$ for different $W$
is obtained when plotted against $\overline{\mathcal{S}}_{\mathrm{e}}(t)$ or
$\overline{\mathcal{S}}_2(t)$, indicating that the average entropy
appropriately models the ensemble-averaged internal clock. We take the tendency
for faster-than-logarithmic growth of $\overline{\mathcal{S}}_{\mathrm{e}}(t)$
together with smooth dependency on $W$ of all our observables within the entire
simulation window as support for the cross-over scenario, discouraging an MBL
transition within the traditional parametric window of computational studies.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:57:44 GMT""}]","2023-02-23"
"2302.11385","Zhen Gao","Keke Ying, Zhen Gao, Sheng Chen, Xinyu Gao, Michail Matthaiou, Rui
  Zhang, and Robert Schober","Reconfigurable Massive MIMO: Harnessing the Power of the Electromagnetic
  Domain for Enhanced Information Transfer","7 pages, 3 figures. This paper is accepted by IEEE Wireless
  Communications Magazine. Copyright may be transferred without notice, after
  which this version may no longer be accessible",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The capacity of commercial massive multiple-input multiple-output (mMIMO)
systems is constrained by the limited array aperture at the base station, and
cannot meet the ever-increasing traffic demands of wireless networks. Given the
array aperture, holographic MIMO with infinitesimal antenna spacing can
maximize the capacity, but is physically unrealizable. As a promising
alternative, reconfigurable mMIMO is proposed to harness the unexploited power
of the electromagnetic (EM) domain for enhanced information transfer.
Specifically, the reconfigurable pixel antenna technology provides each antenna
with an adjustable EM radiation (EMR) pattern, introducing extra degrees of
freedom for information transfer in the EM domain. In this article, we present
the concept and benefits of availing the EMR domain for mMIMO transmission.
Moreover, we propose a viable architecture for reconfigurable mMIMO systems,
and the associated system model and downlink precoding are also discussed. In
particular, a three-level precoding scheme is proposed, and simulation results
verify its considerable spectral and energy efficiency advantages compared to
traditional mMIMO systems. Finally, we further discuss the challenges,
insights, and prospects of deploying reconfigurable mMIMO, along with the
associated hardware, algorithms, and fundamental theory.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:58:10 GMT""}]","2023-02-23"
"2302.11386","Warren Powell","Xiaohe Luo, Warren B. Powell","Entropy Minimization for Optimization of Expensive, Unimodal Functions",,,,,"math.OC","http://creativecommons.org/licenses/by/4.0/","  Maximization of an expensive, unimodal function under random observations has
been an important problem in hyperparameter tuning. It features expensive
function evaluations (which means small budgets) and a high level of noise. We
develop an algorithm based on entropy reduction of a probabilistic belief about
the optimum. The algorithm provides an efficient way of estimating the
computationally intractable surrogate objective in the general Entropy Search
algorithm by leveraging a sampled belief model and designing a metric that
measures the information value of any search point.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:02:42 GMT""}]","2023-02-23"
"2302.11387","Michael Verhage","Michael Verhage, Tun\c{c} H. \c{C}ift\c{c}i, Michiel Reul, Tamar
  Cromwijk, Thijs J. N. van Stralen, Bert Koopmans, Oleg Kurnosikov, and Kees
  Flipse","Switchable-magnetisation planar probe MFM sensor","36 pages, 13 Figures, 1 ToC",,,,"physics.ins-det","http://creativecommons.org/licenses/by/4.0/","  We present an alternative switching-magnetization magnetic force microscopy
(SM- MFM) method using planar tip-on-chip probes. Unlike traditional
needle-like tips, the planar probe approach integrates a microdevice near the
tip apex with dedicated functionality. Its 1 mm x 1 mm planar surface paves the
way for freedom in ultra thin-film engineering and micro-/nano-tailoring for
application-oriented tip functionalization. Here, we form a microscale current
pathway near the tip end to control tip magnetisation. The chip like probe or
planar probe, was applied to study the complex magnetic behaviour of epitaxial
transition metal oxide perovskite LaMnO3, which was previously shown to behave
as complex material with domains associated with superpara-, antiferro- and
ferromagnetism. To this end we successfully imaged an inhomogeneous
distribution of weak ferromagnetic islands with a resolution better than 10 nm.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:02:50 GMT""}]","2023-02-23"
"2302.11388","Abdallah Shihadeh","Abdallah Shihadeh","Graded prime ideals over graded Lie algebras",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we extend the definition of the graded prime ideals from those
in commutative graded rings to the ideals over graded Lie algebras. We prove
some facts about graded prime Lie ideals in arbitrary Lie algebras that are
similar to those about graded prime ideals over a commutative or
non-commutative ring.In addition, the ideas of graded semiprime Lie ideals and
graded total prime Lie ideals will be introduced.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:03:53 GMT""}]","2023-02-23"
"2302.11389","Alexander Petrov","Alexander Petrov","Non-decomposability of the de Rham complex and non-semisimplicity of the
  Sen operator","comments welcome!",,,,"math.AG math.KT math.NT","http://creativecommons.org/publicdomain/zero/1.0/","  We describe the obstruction to decomposing in degrees $\leq p$ the de Rham
complex of a smooth variety over a perfect field $k$ of characteristic $p$ that
lifts over $W_2(k)$, and show that there exist liftable smooth projective
varieties of dimension $p+1$ whose Hodge-to-de Rham spectral sequence does not
degenerate at the first page. We also describe the action of the Sen operator
on the de Rham complex in degrees $\leq p$ and give examples of varieties with
a non-semisimple Sen operator.
  Our methods rely on the commutative algebra structure on de Rham and
Hodge-Tate cohomology, and are inspired by the properties of Steenrod
operations on cohomology of cosimplicial commutative algebras. The example of a
non-degenerate Hodge-to-de Rham spectral sequence relies on a non-vanishing
result on cohomology of groups of Lie type. We give applications to other
situations such as describing extensions in the canonical filtration on de
Rham, Hodge, and \'etale cohomology of an abelian variety equipped with a group
action. We also show that the de Rham complex of a smooth variety over $k$ is
formal as an $E_{\infty}$-algebra if and only if the variety lifts to $W_2(k)$
together with its Frobenius endomorphism.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:06:38 GMT""}]","2023-02-23"
"2302.11390","Gabor Kun","Panna T\'imea Fekete, G\'abor Kun","Easy testability for posets","Preliminary version",,,,"math.CO cs.DM cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Alon and Shapira proved that every class of undirected graphs closed under
the removal of edges and vertices is strongly testable. We show that every
class of posets closed under the removal of edges is easily testable, that is,
strongly testable with a polynomial bound on the queries. We get this result
via a removal lemma with polynomial bound. We also give a simple
classification: for every class of posets closed under the removal of edges and
vertices there is an $h$ such that the class is indistinguishable from the
class of posets without chains of length $h$ (by testing with a constant number
of queries). The analogous results hold for comparability graphs.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:08:22 GMT""}]","2023-02-23"
"2302.11391","Youngjae Kim Dr.","Youngjae Kim","Attosecond Transient Absorption Spectroscopy of Strongly Correlated Mott
  Insulators: Signature of the Creation and Annihilation of Double Occupancy","7 pages, 8 figures",,,,"cond-mat.str-el physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We applied the time-resolved attosecond transient absorption spectroscopy to
systematically investigate ultrafast optical responses of condensed matter
systems. Under an intense pump pulse, absorption spectra indicate that the
non-interacting electrons of band insulators produce a field-induced redshift,
known as the dynamical Franz-Keldysh effect, as commonly expected. In contrast
to the band insulators, in Mott insulators, unconventional spectra are observed
which do not fully reflect the dynamical Franz-Keldysh effect. While it still
exhibits the fishbone-like structures mimicking the dynamical Franz-Keldysh
effect, the spectra show a negative difference absorption below the band edge,
rendering a blueshift. In addition, the decomposed difference absorption
reveals the creation and the annihilation of double occupancy mainly contribute
to the negative signal, implying that the unconventional spectra are purely
driven by the electron-correlations. These demonstrations of unconventional
responses would guide us to the correlation-embedded attosecond electron
dynamics in condensed matter systems.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:10:06 GMT""}]","2023-02-23"
"2302.11392","Alexander Brown","Alex J. Brown, Steven G. Parsons, Jan van Roestel, Alberto
  Rebassa-Mansergas, Elm\'e Breedt, Vik S. Dhillon, Martin J. Dyer, Matthew J.
  Green, Paul Kerry, Stuart P. Littlefair, Thomas R. Marsh, James Munday,
  Ingrid Pelisoli, David I. Sahman, James F. Wild","Photometric follow-up of 43 new eclipsing white dwarf plus main-sequence
  binaries from the ZTF survey","12 pages with a 5 page appendix and 14 figures. Accepted for
  publication in MNRAS",,"10.1093/mnras/stad612",,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  Wide-field time-domain photometric sky surveys are now finding hundreds of
eclipsing white dwarf plus M dwarf binaries, a population encompassing a wealth
of information and potential insight into white dwarf and close binary
astrophysics. Precise follow-up observations are essential in order to fully
constrain these systems and capitalise on the power of this sample. We present
the first results from our program of high-speed, multi-band photometric
follow-up. We develop a method to measure temperatures, (model-dependent)
masses, and radii for both components from the eclipse photometry alone and
characterize 34 white dwarf binaries, finding general agreement with
independent estimates using an alternative approach while achieving around a
factor of two increase in parameter precision. In addition to these parameter
estimates, we discover a number of interesting systems -- finding four with
sub-stellar secondaries, doubling the number of eclipsing examples, and at
least six where we find the white dwarf to be strongly magnetic, making these
the first eclipsing examples of such systems and key to investigating the
mechanism of magnetic field generation in white dwarfs. We also discover the
first two pulsating white dwarfs in detached and eclipsing post-common-envelope
binaries -- one with a low-mass, likely helium core, and one with a relatively
high mass, towards the upper end of the known sample of ZZ Cetis. Our results
demonstrate the power of eclipse photometry, not only as a method of
characterising the population, but as a way of discovering important systems
that would have otherwise been missed by spectroscopic follow-up.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:13:25 GMT""}]","2023-03-08"
"2302.11393","Oliver Gasser","Florian Streibelt, Patrick Sattler, Franziska Lichtblau, Carlos H.
  Ga\~n\'an, Anja Feldmann, Oliver Gasser, and Tobias Fiebig","How Ready Is DNS for an IPv6-Only World?",,"Proceedings of the Passive and Active Measurement Conference 2023
  (PAM '23)",,,"cs.NI","http://creativecommons.org/licenses/by/4.0/","  DNS is one of the core building blocks of the Internet. In this paper, we
investigate DNS resolution in a strict IPv6-only scenario and find that a
substantial fraction of zones cannot be resolved. We point out, that the
presence of an AAAA resource record for a zone's nameserver does not
necessarily imply that it is resolvable in an IPv6-only environment since the
full DNS delegation chain must resolve via IPv6 as well. Hence, in an IPv6-only
setting zones may experience an effect similar to what is commonly referred to
as lame delegation. Our longitudinal study shows that the continuing
centralization of the Internet has a large impact on IPv6 readiness, i.e., a
small number of large DNS providers has, and still can, influence IPv6
readiness for a large number of zones. A single operator that enabled IPv6 DNS
resolution -- by adding IPv6 glue records -- was responsible for around 20.3%
of all zones in our dataset not resolving over IPv6 until January 2017. Even
today, 10% of DNS operators are responsible for more than 97.5% of all zones
that do not resolve using IPv6.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:19:18 GMT""}]","2023-02-23"
"2302.11394","Austin Mcdowell","Austin McDowell, Andrew MacFadyen","Revisiting the Parameter Space of Binary Neutron Star Merger Event
  GW170817",,,"10.3847/1538-4357/acbd8e",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the gravitational wave event GW170817 and gamma-ray burst GW170817A
there have been numerous studies constraining the burst properties through
analysis of the afterglow light curves. Most agree that the burst was viewed
off-axis with a ratio of the observer angle to the jet angle
($\theta_{obs}/\theta_j$) between 4 - 6. We use a parameterized model and
broadband synchrotron data up to $\sim 800$ days post-merger to constrain
parameters of the burst. To reproduce the hydrodynamics of a gamma-ray burst
outflow we use a two-parameter ""boosted fireball"" model. The structure of a
boosted fireball is determined by the specific internal energy, $\eta_0$, and
the bulk Lorentz factor, $\gamma_B(\sim 1/\theta_j)$ with shapes varying
smoothly from a quasi-spherical outflow for low values of $\gamma_B$ to a
highly collimated jet for high values. We run simulations with $\gamma_B$ in
the range $1-20$ and $\eta_0$ in the range $2-15$. To calculate light curves we
use a synchrotron radiation model characterized by $F_{peak}$, $\nu_m$, and
$\nu_c$ and calculate millions of spectra at different times and $\theta_{obs}$
values using the \texttt{boxfit} radiation code. We can tabulate the spectral
parameter values from our spectra and rapidly generate arbitrary light curves
for comparison to data in MCMC analysis. We find that our model prefers a
gamma-ray burst with jet energy $E_j\sim10^{50}$ ergs and with an observer
angle of $\theta_{obs}=0.65^{+0.13}_{-0.14}$ radians and ratio to jet opening
angle of ($\theta_{obs}/\theta_j$) = 5.4$^{+0.53}_{-0.38}$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:22:29 GMT""}]","2023-03-29"
"2302.11395","Nikki Sonenberg","Nikki Sonenberg, Victoria Volodina, Peter G. Challenor, Jim Q. Smith","Using infinite server queues with partial information for occupancy
  prediction","25 pages, 12 figures",,,,"stat.AP math.PR","http://creativecommons.org/licenses/by/4.0/","  Motivated by demand prediction for the custodial prison population in England
and Wales, this paper describes an approach to the study of service systems
using infinite server queues, where the system has non-empty initial state and
the elapsed time of individuals initially present is not known. By separating
the population into initial content and new arrivals, we can apply several
techniques either separately or jointly to those sub-populations, to enable
both short-term queue length predictions and longer-term considerations such as
managing congestion and analysing the impact of potential interventions. The
focus in the paper is the transient behaviour of the $M_t/G/\infty$ queue with
a non-homogeneous Poisson arrival process and our analysis considers various
possible simplifications, including approximation. We illustrate the approach
in that domain using publicly available data in a Bayesian framework to perform
model inference.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:23:03 GMT""}]","2023-02-23"
"2302.11396","Zhizhi Yu","Zhizhi Yu, Di Jin, Cuiying Huo, Zhiqiang Wang, Xiulong Liu, Heng Qi,
  Jia Wu, Lingfei Wu","KGTrust: Evaluating Trustworthiness of SIoT via Knowledge Enhanced Graph
  Neural Networks","Accepted by WWW-23",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social Internet of Things (SIoT), a promising and emerging paradigm that
injects the notion of social networking into smart objects (i.e., things),
paving the way for the next generation of Internet of Things. However, due to
the risks and uncertainty, a crucial and urgent problem to be settled is
establishing reliable relationships within SIoT, that is, trust evaluation.
Graph neural networks for trust evaluation typically adopt a straightforward
way such as one-hot or node2vec to comprehend node characteristics, which
ignores the valuable semantic knowledge attached to nodes. Moreover, the
underlying structure of SIoT is usually complex, including both the
heterogeneous graph structure and pairwise trust relationships, which renders
hard to preserve the properties of SIoT trust during information propagation.
To address these aforementioned problems, we propose a novel knowledge-enhanced
graph neural network (KGTrust) for better trust evaluation in SIoT.
Specifically, we first extract useful knowledge from users' comment behaviors
and external structured triples related to object descriptions, in order to
gain a deeper insight into the semantics of users and objects. Furthermore, we
introduce a discriminative convolutional layer that utilizes heterogeneous
graph structure, node semantics, and augmented trust relationships to learn
node embeddings from the perspective of a user as a trustor or a trustee,
effectively capturing multi-aspect properties of SIoT trust during information
propagation. Finally, a trust prediction layer is developed to estimate the
trust relationships between pairwise nodes. Extensive experiments on three
public datasets illustrate the superior performance of KGTrust over
state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:24:45 GMT""}]","2023-02-23"
"2302.11397","S\'ebastien Bongard","Nicholas Mondrik, Michael Coughlin, Marc Betoule, S\'ebastien Bongard,
  Joseph P. Rice, Ping-Shine Shaw, Christopher W. Stubbs, John T. Woodward and
  LSST Dark Energy Science Collaboration","Measurement of telescope transmission using a Collimated Beam Projector",,,"10.1088/1538-3873/acbe1c",,"astro-ph.IM astro-ph.GA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  With the increasingly large number of type Ia supernova being detected by
current-generation survey telescopes, and even more expected with the upcoming
Rubin Observatory Legacy Survey of Space and Time, the precision of
cosmological measurements will become limited by systematic uncertainties in
flux calibration rather than statistical noise. One major source of systematic
error in determining SNe Ia color evolution (needed for distance estimation) is
uncertainty in telescope transmission, both within and between surveys. We
introduce here the Collimated Beam Projector (CBP), which is meant to measure a
telescope transmission with collimated light. The collimated beam more closely
mimics a stellar wavefront as compared to flat-field based instruments,
allowing for more precise handling of systematic errors such as those from
ghosting and filter angle-of-incidence dependence. As a proof of concept, we
present CBP measurements of the StarDICE prototype telescope, achieving a
standard (1 sigma) uncertainty of 3 % on average over the full wavelength range
measured with a single beam illumination.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:32:55 GMT""}]","2023-03-29"
"2302.11398","Pierre van Moerbeke","Mark Adler and Pierre van Moerbeke","Double Interlacing in Random Tiling Models","67 pages","J. Math. Phys. 64 (2023) Special Collection in Honor of Freeman
  Dyson","10.1063/5.0093542",,"math-ph math.MP math.PR","http://creativecommons.org/licenses/by/4.0/","  Random tilings of very large domains will typically lead to a solid, a
liquid, and a gas phase. In the two-phase case, the solid-liquid boundary
(arctic curve) is smooth, possibly with singularities. At the point of tangency
of the arctic curve with the domain-boundary, the tiles of a certain shape form
for large-size domains a singly interlacing set, fluctuating according to the
eigenvalues of the principal minors of a GUE-matrix (Gaussian unitary
ensemble). Introducing non-convexities in large domains may lead to the
appearance of several interacting liquid regions: they can merely touch,
leading to either a split tacnode (also called hard tacnode), with two distinct
adjacent frozen phases descending into the tacnode, or a soft tacnode. For
appropriate scaling of the nonconvex domains and probing about such split
tacnodes, filaments of tiles of a certain type will connect the liquid patches:
they evolve in a bricklike-sea of dimers of another type. Nearby, the tiling
fluctuations are governed by a discrete tacnode kernel; i.e., a determinantal
point process on a doubly interlacing set of dots belonging to a discrete array
of parallel lines. This kernel enables one to compute the joint distribution of
the dots along those lines. This kernel appears in two very different models:
(i) domino-tilings of skew-Aztec rectangles and (ii) lozenge-tilings of
hexagons with cuts along opposite edges. Soft, opposed to hard, tacnodes appear
when two arctic curves gently touch each other amidst a bricklike sea of dimers
of one type, unlike the split tacnode. We hope that this largely expository
paper will provide a view on the subject and be accessible to a wider audience.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:33:45 GMT""}]","2023-02-23"
"2302.11399","Xiulai Xu Prof","Shushu Shi, Shan Xiao, Jingnan Yang, Shulun Li, Xin Xie, Jianchen
  Dang, Longlong Yang, Danjie Dai, Bowen Fu, Sai Yan, Yu Yuan, Rui Zhu, Bei-Bei
  Li, Zhanchun Zuo, Can Wang, Haiqiao Ni, Zhichuan Niu, Kuijuan Jin, Qihuang
  Gong and Xiulai Xu","Controllable Spin-Resolved Photon Emission Enhanced by Slow-Light Mode
  in Photonic Crystal Waveguides on Chip","7 pages,5 figures","Optics Express, 2023","10.1364/OE.483244",,"cond-mat.mes-hall","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We report the slow-light enhanced spin-resolved in-plane emission from a
single quantum dot (QD) in a photonic crystal waveguide (PCW). The slow light
dispersions in PCWs are designed to match the emission wavelengths of single
QDs. The resonance between two spin states emitted from a single QD and a slow
light mode of a waveguide is investigated under a magnetic field with Faraday
configuration. Two spin states of a single QD experience different degrees of
enhancement as their emission wavelengths are shifted by combining diamagnetic
and Zeeman effects with an optical excitation power control. A circular
polarization degree up to 0.81 is achieved by changing the off-resonant
excitation power. Strongly polarized photon emission enhanced by a slow light
mode shows great potential to attain controllable spin-resolved photon sources
for integrated optical quantum networks on chip.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:35:14 GMT""}]","2023-03-22"
"2302.11400","Giancarlos Troncoso Parady","Chenglin Han, Lichen Luo, Giancarlos Parady, Kiyoshi Takami, Makoto
  Chikaraishi, Noboru Harata","Modeling joint eating-out destination choices incorporating group-level
  impedance: A case study of the Greater Tokyo Area","19 pages, 8 figures",,,,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Individuals undertake both solo and joint activities as part of their overall
activity-travel patterns. Compared to work and maintenance activities, social
and leisure activities differ in that they exhibit high levels of temporal and
spatial flexibility. In this study we used data from an ego-centric social
networks survey in the Greater Tokyo Area and follow-up group activity survey
to estimate a joint eating-out destination choice model explicitly
incorporating group-level impedance. Consistent with the literature, travel
time has a large impact on destination choice as measured by its elasticity;
however, the elasticities of group-level maximum, average and median travel
times are larger than individual-level travel times. Furthermore, we show that
incorporating group-level impedance increases model performance up to 49%
against the ego-level impedance model, a substantial increase that underscores
the need to incorporate group-level characteristics in travel behavior models.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:37:04 GMT""}]","2023-02-23"
"2302.11401","Rosanne Turner","Rosanne J. Turner and Peter D. Gr\""unwald","Safe Sequential Testing and Effect Estimation in Stratified Count Data","Preprint, to be published in the Proceedings of the 26th
  International Conference on Artificial Intelligence and Statistics (AISTATS)
  2023, Valencia, Spain. PMLR: Volume 206",,,,"stat.ME","http://creativecommons.org/licenses/by/4.0/","  Sequential decision making significantly speeds up research and is more
cost-effective compared to fixed-n methods. We present a method for sequential
decision making for stratified count data that retains Type-I error guarantee
or false discovery rate under optional stopping, using e-variables. We invert
the method to construct stratified anytime-valid confidence sequences, where
cross-talk between subpopulations in the data can be allowed during data
collection to improve power. Finally, we combine information collected in
separate subpopulations through pseudo-Bayesian averaging and switching to
create effective estimates for the minimal, mean and maximal treatment effects
in the subpopulations.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:37:51 GMT""}]","2023-02-23"
"2302.11407","Spencer Bryngelson","Spencer H. Bryngelson, Kevin Schmidmayer, Tim Colonius","A quantitative comparison of phase-averaged models for bubbly,
  cavitating flows",,"International Journal of Multiphase Flow, 115, 137-143 (2019)","10.1016/j.ijmultiphaseflow.2019.03.028",,"physics.flu-dyn physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  We compare the computational performance of two modeling approaches for the
flow of dilute cavitation bubbles in a liquid. The first approach is a
deterministic model, for which bubbles are represented in a Lagrangian
framework as advected features, each sampled from a distribution of equilibrium
bubble sizes. The dynamic coupling to the liquid phase is modeled through local
volume averaging. The second approach is stochastic; ensemble-phase averaging
is used to derive mixture-averaged equations and field equations for the
associated bubble properties are evolved in an Eulerian reference frame. For
polydisperse mixtures, the probability density function of the equilibrium
bubble radii is discretized and bubble properties are solved for each
representative bin. In both cases, the equations are closed by solving
Rayleigh-Plesset-like equations for the bubble dynamics as forced by the local
or mixture-averaged pressure, respectively. An acoustically excited dilute
bubble screen is used as a case study for comparisons. We show that observables
of ensemble- and volume-averaged simulations match closely and that their
convergence is first order under grid refinement. Guidelines are established
for phase-averaged simulations by comparing the computational costs of methods.
The primary costs are shown to be associated with stochastic closure;
polydisperse ensemble-averaging requires many samples of the underlying PDF and
volume-averaging requires repeated, randomized simulations to accurately
represent a homogeneous bubble population. The relative sensitivities of these
costs to spatial resolution and bubble void fraction are presented.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:41:38 GMT""}]","2023-02-23"
"2302.11408","Yi Zeng","Minzhou Pan, Yi Zeng, Lingjuan Lyu, Xue Lin and Ruoxi Jia","ASSET: Robust Backdoor Data Detection Across a Multiplicity of Deep
  Learning Paradigms","18 pages, with 13 pages of main text",,,,"cs.LG cs.AI cs.CR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Backdoor data detection is traditionally studied in an end-to-end supervised
learning (SL) setting. However, recent years have seen the proliferating
adoption of self-supervised learning (SSL) and transfer learning (TL), due to
their lesser need for labeled data. Successful backdoor attacks have also been
demonstrated in these new settings. However, we lack a thorough understanding
of the applicability of existing detection methods across a variety of learning
settings. By evaluating 56 attack settings, we show that the performance of
most existing detection methods varies significantly across different attacks
and poison ratios, and all fail on the state-of-the-art clean-label attack. In
addition, they either become inapplicable or suffer large performance losses
when applied to SSL and TL. We propose a new detection method called Active
Separation via Offset (ASSET), which actively induces different model behaviors
between the backdoor and clean samples to promote their separation. We also
provide procedures to adaptively select the number of suspicious points to
remove. In the end-to-end SL setting, ASSET is superior to existing methods in
terms of consistency of defensive performance across different attacks and
robustness to changes in poison ratios; in particular, it is the only method
that can detect the state-of-the-art clean-label attack. Moreover, ASSET's
average detection rates are higher than the best existing methods in SSL and
TL, respectively, by 69.3% and 33.2%, thus providing the first practical
backdoor defense for these new DL settings. We open-source the project to drive
further development and encourage engagement:
https://github.com/ruoxi-jia-group/ASSET.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:43:33 GMT""}]","2023-02-23"
"2302.11409","Markus Klar","Florian Fischer, Arthur Fleig, Markus Klar, Viktorija Paneva, J\""org
  M\""uller","Towards a Deep(er) Understanding of Interaction through Modeling,
  Simulation, and Optimization","8 pages, 3 figures. Submitted as extended abstract to CHI 2023
  workshop on ""Future of Computational Approaches for Understanding & Adapting
  User Interfaces""",,,,"cs.HC","http://creativecommons.org/licenses/by-sa/4.0/","  The traditional user-centered design process can hardly keep up with the ever
faster technical development and increasingly diverse user preferences. As a
solution, we propose to augment the tried-and-tested approach of conducting
user studies with simulation and optimization of the entire human-computer
interaction loop. This approach allows to better understand phenomena through
explicit modeling, build virtual prototypes through simulation, and improve
interaction techniques through optimization. Building predictive user models
also supports the creation and validation of HCI theories, and constitutes a
decisive step towards new, intelligent, and adaptive user interfaces. We report
our experience in virtually developing new interaction techniques on the
example of acoustic levitation, and present our optimization-based framework
for HCI. With this, we strive to gain a better understanding of interaction and
at the same time feed the discussion on questions such as which tools and
tutorials are necessary to make virtual prototyping more accessible to
different audiences.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:44:16 GMT""}]","2023-02-23"
"2302.11410","Ce Ju","Ce Ju, Reinmar Josef Kobler and Cuntai Guan","Score-Based Data Generation for EEG Spatial Covariance Matrices: Towards
  Boosting BCI Performance","7 pages, 4 figures; This work has been accepted by the 2023 45th
  Annual International Conference of the IEEE Engineering in Medicine & Biology
  Conference (IEEE EMBC 2023'). Copyright will be transferred without notice,
  after which this version may no longer be accessible",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The efficacy of Electroencephalogram (EEG) classifiers can be augmented by
increasing the quantity of available data. In the case of geometric deep
learning classifiers, the input consists of spatial covariance matrices derived
from EEGs. In order to synthesize these spatial covariance matrices and
facilitate future improvements of geometric deep learning classifiers, we
propose a generative modeling technique based on state-of-the-art score-based
models. The quality of generated samples is evaluated through visual and
quantitative assessments using a left/right-hand-movement motor imagery
dataset. The exceptional pixel-level resolution of these generative samples
highlights the formidable capacity of score-based generative modeling.
Additionally, the center (Frechet mean) of the generated samples aligns with
neurophysiological evidence that event-related desynchronization and
synchronization occur on electrodes C3 and C4 within the Mu and Beta frequency
bands during motor imagery processing. The quantitative evaluation revealed
that 84.3% of the generated samples could be accurately predicted by a
pre-trained classifier and an improvement of up to 8.7% in the average accuracy
over ten runs for a specific test subject in a holdout experiment.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:44:28 GMT""},{""version"":""v2"",""created"":""Sun, 23 Apr 2023 09:56:21 GMT""}]","2023-04-25"
"2302.11411","Douglas Coates","Douglas Coates, Stefano Luzzatto","Persistent Non-Statistical Dynamics in One-Dimensional Maps","27 pages, 1 figure",,,,"math.DS","http://creativecommons.org/licenses/by/4.0/","  We study a class $\widehat{\mathfrak{F}}$ of one-dimensional full branch maps
introduced in [Doubly Intermittent Full Branch Maps with Critical Points and
Singularities; D. Coates, S. Luzzatto, M. Mubarak, 2022], admitting two
indifferent fixed points as well as critical points and/or singularities with
unbounded derivative. We show that $\widehat{\mathfrak{F}}$ can be partitioned
into 3 pairwise disjoint subfamilies $$\widehat{\mathfrak{F}} = \mathfrak{F}
\cup \mathfrak{F}_\pm \cup \mathfrak{F}_*$$ such that all $g \in \mathfrak{F}$
have a unique physical measure equivalent to Lebesgue, all $g \in
\mathfrak{F}_{\pm}$ have a physical measure which is a Dirac-$\delta$ measure
on one of the (repelling) fixed points, and all $g \in \mathfrak{F}_{*}$ are
non-statistical and in particular have no physical measure. Moreover we show
that these subfamilies are intermingled: they can all be approximated by maps
in the other subfamilies in natural topologies.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:47:09 GMT""}]","2023-02-23"
"2302.11412","Domagoj Plu\v{s}\v{c}ec","Domagoj Plu\v{s}\v{c}ec, Jan \v{S}najder","Data Augmentation for Neural NLP",,,,,"cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  Data scarcity is a problem that occurs in languages and tasks where we do not
have large amounts of labeled data but want to use state-of-the-art models.
Such models are often deep learning models that require a significant amount of
data to train. Acquiring data for various machine learning problems is
accompanied by high labeling costs. Data augmentation is a low-cost approach
for tackling data scarcity. This paper gives an overview of current
state-of-the-art data augmentation methods used for natural language
processing, with an emphasis on methods for neural and transformer-based
models. Furthermore, it discusses the practical challenges of data
augmentation, possible mitigations, and directions for future research.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:47:15 GMT""}]","2023-02-23"
"2302.11413","Michael Rotman","Erez Sheffi, Michael Rotman, Lior Wolf","Gradient Adjusting Networks for Domain Inversion",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  StyleGAN2 was demonstrated to be a powerful image generation engine that
supports semantic editing. However, in order to manipulate a real-world image,
one first needs to be able to retrieve its corresponding latent representation
in StyleGAN's latent space that is decoded to an image as close as possible to
the desired image. For many real-world images, a latent representation does not
exist, which necessitates the tuning of the generator network. We present a
per-image optimization method that tunes a StyleGAN2 generator such that it
achieves a local edit to the generator's weights, resulting in almost perfect
inversion, while still allowing image editing, by keeping the rest of the
mapping between an input latent representation tensor and an output image
relatively intact. The method is based on a one-shot training of a set of
shallow update networks (aka. Gradient Modification Modules) that modify the
layers of the generator. After training the Gradient Modification Modules, a
modified generator is obtained by a single application of these networks to the
original parameters, and the previous editing capabilities of the generator are
maintained. Our experiments show a sizable gap in performance over the current
state of the art in this very active domain. Our code is available at
\url{https://github.com/sheffier/gani}.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:47:57 GMT""}]","2023-02-23"
"2302.11414","Bowen Zhao","Bowen Zhao, Chen Chen, Qian-Wei Wang, Anfeng He, Shu-Tao Xia","Delving into Identify-Emphasize Paradigm for Combating Unknown Bias",,,,,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dataset biases are notoriously detrimental to model robustness and
generalization. The identify-emphasize paradigm appears to be effective in
dealing with unknown biases. However, we discover that it is still plagued by
two challenges: A, the quality of the identified bias-conflicting samples is
far from satisfactory; B, the emphasizing strategies only produce suboptimal
performance. In this paper, for challenge A, we propose an effective
bias-conflicting scoring method (ECS) to boost the identification accuracy,
along with two practical strategies -- peer-picking and epoch-ensemble. For
challenge B, we point out that the gradient contribution statistics can be a
reliable indicator to inspect whether the optimization is dominated by
bias-aligned samples. Then, we propose gradient alignment (GA), which employs
gradient statistics to balance the contributions of the mined bias-aligned and
bias-conflicting samples dynamically throughout the learning process, forcing
models to leverage intrinsic features to make fair decisions. Furthermore, we
incorporate self-supervised (SS) pretext tasks into training, which enable
models to exploit richer features rather than the simple shortcuts, resulting
in more robust models. Experiments are conducted on multiple datasets in
various settings, demonstrating that the proposed solution can mitigate the
impact of unknown biases and achieve state-of-the-art performance.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:50:24 GMT""}]","2023-02-23"
"2302.11415","Carlo Maria Lazzarini","C. M. Lazzarini, G. M. Grittani, P. Valenta, I. Zymak, R. Antipenkov,
  U. Chaulagain, L. V. N. Goncalves, A. Grenfell, M. Lamac, S. Lorenz, M.
  Nevrkla, V. Sobr, A. Spacek, W. Szuba, P. Bakule, G. Korn and S. V. Bulanov","50 MeV electron beams accelerated by a terawatt scalable kHz laser","9 pages, 3 figures, 1 table",,,,"physics.plasm-ph physics.acc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show the laser-driven acceleration of unprecedented, collimated (2 mrad)
and quasi-monoenergetic (dE/E = 25%) electron beams with energy up to 50 MeV at
1 kHz repetition rate. The laser driver is a multi-cycle (15 fs) 1 kHz OPCPA
system, operating at 26 mJ (1.7 TW). The scalability of the driver laser
technology and the electron beams reported in this work pave the way towards
developing high brilliance X-ray sources for medical imaging, innovative
devices for brain cancer treatment and represent a step forward to the
realization of a kHz GeV electron beamline.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:51:53 GMT""}]","2023-02-23"
"2302.11416","Haofeng Li","Wei Lou, Xiang Wan, Guanbin Li, Xiaoying Lou, Chenghang Li, Feng Gao,
  Haofeng Li","Structure Embedded Nucleus Classification for Histopathology Images",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nuclei classification provides valuable information for histopathology image
analysis. However, the large variations in the appearance of different nuclei
types cause difficulties in identifying nuclei. Most neural network based
methods are affected by the local receptive field of convolutions, and pay less
attention to the spatial distribution of nuclei or the irregular contour shape
of a nucleus. In this paper, we first propose a novel polygon-structure feature
learning mechanism that transforms a nucleus contour into a sequence of points
sampled in order, and employ a recurrent neural network that aggregates the
sequential change in distance between key points to obtain learnable shape
features. Next, we convert a histopathology image into a graph structure with
nuclei as nodes, and build a graph neural network to embed the spatial
distribution of nuclei into their representations. To capture the correlations
between the categories of nuclei and their surrounding tissue patterns, we
further introduce edge features that are defined as the background textures
between adjacent nuclei. Lastly, we integrate both polygon and graph structure
learning mechanisms into a whole framework that can extract intra and
inter-nucleus structural characteristics for nuclei classification.
Experimental results show that the proposed framework achieves significant
improvements compared to the state-of-the-art methods.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:52:06 GMT""}]","2023-02-23"
"2302.11417","Kevin Mann","Henning Fernau and Kevin Mann","Hitting the Romans",,,,,"cs.CC","http://creativecommons.org/licenses/by/4.0/","  Roman domination is one of few examples where the related extension problem
is polynomial-time solvable even if the original decision problem is
NP-complete. This is interesting, as it allows to establish polynomial-delay
enumeration algorithms for finding minimal Roman dominating functions, while it
is open for more than four decades if all minimal dominating sets of a graph or
if all hitting sets of a hypergraph can be enumerated with polynomial delay. To
find the reason why this is the case, we combine the idea of hitting set with
the idea of Roman domination. We hence obtain and study two new problems,
called Roman Hitting Function and Roman Hitting Set, both generalizing Roman
Domination. This allows us to delineate the borderline of polynomial-delay
enumerability. Here, we assume what we call the Hitting Set Transversal Thesis,
claiming that it is impossible to enumerate all minimal hitting sets of a
hypergraph with polynomial delay. Our first focus is on the extension versions
of these problems. While doing this, we find some conditions under which the
Extension Roman Hitting Function problem is NP-complete. We then use
parameterized complexity to get a better understanding of why Extension Roman
Hitting Function behaves in this way. Furthermore, we analyze the parameterized
and approximation complexity of the underlying optimization problems. We also
discuss consequences for Roman variants of other problems like Vertex Cover.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:53:52 GMT""}]","2023-02-23"
"2302.11418","Chuanting Zhang","Chuanting Zhang, Shuping Dang, Junqing Zhang, Haixia Zhang, Mark A.
  Beach","Federated Radio Frequency Fingerprinting with Model Transfer and
  Adaptation","This paper was accepted by IEEE INFOCOM 2023 Workshop (DeepWireless)",,,,"cs.AI cs.CR cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Radio frequency (RF) fingerprinting technique makes highly secure device
authentication possible for future networks by exploiting hardware
imperfections introduced during manufacturing. Although this technique has
received considerable attention over the past few years, RF fingerprinting
still faces great challenges of channel-variation-induced data distribution
drifts between the training phase and the test phase. To address this
fundamental challenge and support model training and testing at the edge, we
propose a federated RF fingerprinting algorithm with a novel strategy called
model transfer and adaptation (MTA). The proposed algorithm introduces dense
connectivity among convolutional layers into RF fingerprinting to enhance
learning accuracy and reduce model complexity. Besides, we implement the
proposed algorithm in the context of federated learning, making our algorithm
communication efficient and privacy-preserved. To further conquer the data
mismatch challenge, we transfer the learned model from one channel condition
and adapt it to other channel conditions with only a limited amount of
information, leading to highly accurate predictions under environmental drifts.
Experimental results on real-world datasets demonstrate that the proposed
algorithm is model-agnostic and also signal-irrelevant. Compared with
state-of-the-art RF fingerprinting algorithms, our algorithm can improve
prediction performance considerably with a performance gain of up to 15\%.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:55:30 GMT""}]","2023-02-23"
"2302.11419","Charlotte Bunne","Vignesh Ram Somnath, Matteo Pariset, Ya-Ping Hsieh, Maria Rodriguez
  Martinez, Andreas Krause, Charlotte Bunne","Aligned Diffusion Schr\""odinger Bridges",,,,,"cs.LG q-bio.QM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Diffusion Schr\""odinger bridges (DSB) have recently emerged as a powerful
framework for recovering stochastic dynamics via their marginal observations at
different time points. Despite numerous successful applications, existing
algorithms for solving DSBs have so far failed to utilize the structure of
aligned data, which naturally arises in many biological phenomena. In this
paper, we propose a novel algorithmic framework that, for the first time,
solves DSBs while respecting the data alignment. Our approach hinges on a
combination of two decades-old ideas: The classical Schr\""odinger bridge theory
and Doob's $h$-transform. Compared to prior methods, our approach leads to a
simpler training procedure with lower variance, which we further augment with
principled regularization schemes. This ultimately leads to sizeable
improvements across experiments on synthetic and real data, including the tasks
of rigid protein docking and temporal evolution of cellular differentiation
processes.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:55:57 GMT""}]","2023-02-23"
"2302.11420","Ryo Hayami","Ryo Hayami","Higher Courant-Dorfman algebras and associated higher Poisson vertex
  algebras","Doctoral thesis(submitted)",,,,"math-ph math.MP math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this thesis, we consider a notion of a higher version of the relation
between Courant-Dorfman algebras and Poisson vertex algebras. We define a
higher Courant-Dorfman algebra, and study the relationship with graded
symplectic geometry. In particular, we give graded Poisson algebras of degree
$-n$ in the non-degenerate case. For higher Courant-Dorfman algebras coming
from finite-dimensional vector bundles, they coincide with the algebras of
functions of the associated differential-graded(dg) symplectic manifolds of
degree $n$.
  We define a higher Lie conformal algebra and Poisson vertex algebra, and give
a higher (weak) Courant-Dorfman algebraic structure arising from them.
Moreover, we prove that the higher Lie conformal algebras and higher Poisson
vertex algebras have properties like Lie conformal algebras and Poisson vertex
algebras. As an example, we obtain an algebraic description of
Batalin-Fradkin-Vilkovisky(BFV) current algebras.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:56:13 GMT""},{""version"":""v2"",""created"":""Tue, 14 Mar 2023 14:09:49 GMT""}]","2023-03-15"
"2302.11421","Seonghoon Choi","Seonghoon Choi and Artur F. Izmaylov","Measurement optimization techniques for excited electronic states in
  near-term quantum computing algorithms",,,,,"quant-ph physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The variational quantum eigensolver (VQE) remains one of the most popular
near-term quantum algorithms for solving the electronic structure problem. Yet,
for its practicality, the main challenge to overcome is improving the quantum
measurement efficiency. Numerous quantum measurement techniques have been
developed recently, but it is unclear how these state-of-the-art measurement
techniques will perform in extensions of VQE for obtaining excited electronic
states. Assessing the measurement techniques' performance in the excited state
VQE is crucial because the measurement requirements in these extensions are
typically much greater than in conventional VQE, as one must measure the
expectation value of multiple observables in addition to that of the electronic
Hamiltonian. Here, we adapt various measurement techniques to two widely used
excited state VQE algorithms: multi-state contraction and quantum subspace
expansion. Then, the measurement requirements of each measurement technique are
numerically compared. We find that the best methods for multi-state contraction
are ones utilizing Hamiltonian data and wavefunction information to minimize
the number of measurements. In contrast, randomized measurement techniques are
more appropriate for quantum subspace expansion, with many more observables of
vastly different energy scales to measure. Nevertheless, when the best possible
measurement technique for each excited state VQE algorithm is considered,
significantly fewer measurements are required in multi-state contraction than
in quantum subspace expansion.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:58:49 GMT""},{""version"":""v2"",""created"":""Wed, 10 May 2023 12:36:49 GMT""}]","2023-05-11"
"2302.11422","Fei Pang","Hanxiang Wu, Jianfeng Guo, Suonan Zhaxi, Hua Xu, Shuo Mi, Le Wang,
  Shanshan Chen, Rui Xu, Wei Ji, Fei Pang, Zhihai Cheng","Controllable CVD-Growth of 2D Cr5Te8 Nanosheets with Thickness-Dependent
  Magnetic Domains",,"ACS Applied Materials & Interfaces 2023","10.1021/acsami.3c02446",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a typical 2D magnetic material with self-intercalated structure, Cr5Te8
exhibits many fascinating magnetic properties. Although the ferromagnetism of
2D Cr5Te8 has been reported, the study of its magnetic domain is still blank.
Herein, we successfully fabricated 2D Cr5Te8 nanosheets with controlled
thickness and lateral size by chemical vapor deposition (CVD). Then magnetic
property measurement system suggested Cr5Te8 nanosheets possessing intense
out-of-plane ferromagnetism with the Curie temperature of 179 K. Most
importantly, we found magnetic bubbles and thickness-dependent maze-like
magnetic domains by cryogenic magnetic force microscopy (MFM) for the first
time. The domain width of the maze-like magnetic domains increases rapidly with
decreasing sample thickness, while domain contrast decreases. This indicates
dipolar interaction is the dominant role over exchange interaction and magnetic
anisotropy. Our work not only paves a way for the controllable growth of 2D
magnetic materials, but also suggests new directions for controlling magnetic
phases and systematically adjusting domain properties.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:01:00 GMT""},{""version"":""v2"",""created"":""Fri, 24 Feb 2023 14:07:34 GMT""}]","2023-05-23"
"2302.11423","Li Lin","Li Lin and Didier Sornette","A parsimonious inverse Cox-Ingersoll-Ross process for financial price
  modeling",,,,,"q-fin.MF q-fin.PR","http://creativecommons.org/licenses/by/4.0/","  We propose a formulation to construct new classes of financial price
processes based on the insight that the key variable driving prices $P$ is the
earning-over-price ratio $\gamma \simeq 1/P$, which we refer to as the earning
yield and is analogous to the yield-to-maturity of an equivalent perpetual
bond. This modeling strategy is illustrated with the choice for real-time
$\gamma$ in the form of the Cox-Ingersoll-Ross (CIR) process, which allows us
to derive analytically many stylised facts of financial prices and returns,
such as the power law distribution of returns, transient super-exponential
bubble behavior, and the fat-tailed distribution of prices before bubbles
burst. Our model sheds new light on rationalizing the excess volatility and the
equity premium puzzles. The model is calibrated to five well-known historical
bubbles in the US and China stock markets via a quasi-maximum likelihood method
with the L-BFGS-B optimization algorithm. Using $\phi$-divergence statistics
adapted to models prescribed in terms of stochastic differential equations, we
show the superiority of the CIR process for $\gamma_t$ against three
alternative models.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:02:22 GMT""}]","2023-02-23"
"2302.11424","Sonia Fornasier","S. Fornasier, H.V. Hoang, M. Fulle, E. Quirico, M. Ciarniello","Volatile exposures on the 67P/Churyumov-Gerasimenko nucleus","24 pages, 19 Figures; paper accepted for publication in Astron. and
  Astrophysics on February 2023","A&A 672, A136 (2023)","10.1051/0004-6361/202245614",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the most extensive catalog of exposures of volatiles on the
67P/Churyumov-Gerasimenko nucleus generated from observations acquired with the
OSIRIS cameras on board the Rosetta mission. We identified more than 600
volatile exposures on the comet. Bright spots are found isolated on the nucleus
or grouped in clusters, usually at the bottom of cliffs, and most of them are
small, typically a few square meters or smaller. Several of them are clearly
correlated with the cometary activity. We note a number of peculiar exposures
of volatiles with negative spectral slope values in the high-resolution
post-perihelion images, which we interpret as the presence of large ice grains
($>$ 1000 $\mu$m) or local frosts condensation. We observe a clear difference
both in the spectral slope and in the area distributions of the bright spots
pre- and post-perihelion, with these last having lower average spectral slope
values and a smaller size, with a median surface of 0.7 m$^2$, even if the size
difference is mainly due to the higher resolution achieved post-perihelion. The
minimum duration of the bright spots shows three clusters: an area-independent
cluster dominated by short-lifetime frosts; an area-independent cluster with
lifetime of 0.5--2 days, probably associated with the seasonal fallout of
dehydrated chunks; and an area-dependent cluster with lifetime longer than 2
days consistent with water-driven erosion of the nucleus. Even if numerous
bright spots are detected, the total surface of exposed water ice is less than
0.1% of the total 67P nucleus surface, confirming that the 67P surface is
dominated by refractory dark terrains, while exposed ice occupies only a tiny
fraction. Moreover, the abundance of volatile exposures is six times less in
the small lobe than in the big lobe, adding additional evidence to the
hypothesis that comet 67P is composed of two distinct bodies.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:05:04 GMT""},{""version"":""v2"",""created"":""Tue, 28 Feb 2023 09:59:54 GMT""}]","2023-04-19"
"2302.11425","Karim Johannes Becher","Karim Johannes Becher, Nicolas Daans, David Grimm, Gonzalo
  Manzano-Flores, Marco Zaninelli","The Pythagoras number of a rational function field in two variables",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that every sum of squares in the rational function field in two
variables $K(X,Y)$ over a hereditarily pythagorean field $K$ is a sum of $8$
squares. More precisely, we show that the Pythagoras number of every finite
extension of $K(X)$ is at most $5$. The main ingredients of the proof are a
local-global principle for quadratic forms over function fields in one variable
over a complete rank-$1$ valued field due to V. Mehmeti and a valuation
theoretic characterization of hereditarily pythagorean fields due to L.
Br\""ocker.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:05:10 GMT""}]","2023-02-23"
"2302.11426","Tai Dinh","Tai Dinh, Philippe Fournier-Viger, Huynh Van Hong","Mining compact high utility sequential patterns","Nippon (Japan) Applied Informatics Society Journal",,,,"cs.DB cs.IR","http://creativecommons.org/licenses/by/4.0/","  High utility sequential pattern mining (HUSPM) aims to mine all patterns that
yield a high utility (profit) in a sequence dataset. HUSPM is useful for
several applications such as market basket analysis, marketing, and website
clickstream analysis. In these applications, users may also consider high
utility patterns frequently appearing in the dataset to obtain more fruitful
information. However, this task is high computation since algorithms may
generate a combinatorial explosive number of candidates that may be redundant
or of low importance. To reduce complexity and obtain a compact set of frequent
high utility sequential patterns (FHUSPs), this paper proposes an algorithm
named CHUSP for mining closed frequent high utility sequential patterns
(CHUSPs). Such patterns keep a concise representation while preserving the same
expressive power of the complete set of FHUSPs. The proposed algorithm relies
on a CHUS data structure to maintain information during mining. It uses three
pruning strategies to eliminate early low-utility and non-frequent patterns,
thereby reducing the search space. An extensive experimental evaluation was
performed on six real-life datasets to evaluate the performance of CHUSP in
terms of execution time, memory usage, and the number of generated patterns.
Experimental results show that CHUSP can efficiently discover the compact set
of CHUSPs under different user-defined thresholds.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:05:18 GMT""}]","2023-02-23"
"2302.11427","Anh-Kiet Duong","Anh-Kiet Duong, Hoang-Lan Nguyen, Toan-Thinh Truong","Enhanced Face Authentication With Separate Loss Functions","in Vietnamese language",,,,"cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The overall objective of the main project is to propose and develop a system
of facial authentication in unlocking phones or applications in phones using
facial recognition. The system will include four separate architectures: face
detection, face recognition, face spoofing, and classification of closed eyes.
In which, we consider the problem of face recognition to be the most important,
determining the true identity of the person standing in front of the screen
with absolute accuracy is what facial recognition systems need to achieve.
Along with the development of the face recognition problem, the problem of the
anti-fake face is also gradually becoming popular and equally important. Our
goal is to propose and develop two loss functions: LMCot and Double Loss. Then
apply them to the face authentication process.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:07:29 GMT""}]","2023-02-23"
"2302.11428","Zhaoyuan Ma","Zhaoyuan Ma and Jing Xiao","Robotic Perception-motion Synergy for Novel Rope Wrapping Tasks",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces a novel and general method to address the problem of
using a general-purpose robot manipulator with a parallel gripper to wrap a
deformable linear object (DLO), called a rope, around a rigid object, called a
rod, autonomously. Such a robotic wrapping task has broad potential
applications in automotive, electromechanical industries construction
manufacturing, etc., but has hardly been studied. Our method does not require
prior knowledge of the physical and geometrical properties of the objects but
enables the robot to use real-time RGB-D perception to determine the wrapping
state and feedback control to achieve high-quality results. As such, it
provides the robot manipulator with the general capabilities to handle wrapping
tasks of different rods or ropes. We tested our method on 6 combinations of 3
different ropes and 2 rods. The result shows that the wrapping quality improved
and converged within 5 wraps for all test cases.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:08:23 GMT""},{""version"":""v2"",""created"":""Tue, 11 Apr 2023 03:49:22 GMT""}]","2023-04-12"
"2302.11429","Christian K\""ading","Christian K\""ading, Mario Pitschmann, Hartmut Abele","Green's function analysis of the Neutron Lloyd interferometer","14 pages, 2 figures, as published in Zeitschrift f\""ur Naturforschung
  A",,,,"quant-ph nucl-ex","http://creativecommons.org/licenses/by/4.0/","  The neutron optical Lloyd interferometer can serve as a potent experiment for
probing fundamental physics beyond the standard models of particles and
cosmology. In this article, we provide a full Green's function analysis of a
Lloyd interferometer in the limit that the reflecting mirror extends to the
screen. We consider two distinct situations: first, we will review the
theoretical case of no external fields being present. Subsequently, we will
analyze the case in which a gravitational field is acting on the neutrons. The
latter case provides the theory necessary for using a Lloyd interferometer as a
probe of gravitational fields.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:11:14 GMT""},{""version"":""v2"",""created"":""Thu, 8 Jun 2023 14:06:03 GMT""}]","2023-06-09"
"2302.11430","Nikolay Dokholyan","Congzhou M. Sha, Jian Wang, Nikolay V. Dokholyan","Differentiable Rotamer Sampling with Molecular Force Fields","41 pages, 1 graphical abstract, 5 figures",,,,"physics.comp-ph cs.AI physics.bio-ph","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Molecular dynamics is the primary computational method by which modern
structural biology explores macromolecule structure and function. Boltzmann
generators have been proposed as an alternative to molecular dynamics, by
replacing the integration of molecular systems over time with the training of
generative neural networks. This neural network approach to MD samples rare
events at a higher rate than traditional MD, however critical gaps in the
theory and computational feasibility of Boltzmann generators significantly
reduce their usability. Here, we develop a mathematical foundation to overcome
these barriers; we demonstrate that the Boltzmann generator approach is
sufficiently rapid to replace traditional MD for complex macromolecules, such
as proteins in specific applications, and we provide a comprehensive toolkit
for the exploration of molecular energy landscapes with neural networks.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:12:28 GMT""}]","2023-02-23"
"2302.11431","Jiachen T. Wang","Jiachen T. Wang, Ruoxi Jia","A Note on ""Towards Efficient Data Valuation Based on the Shapley Value''",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Shapley value (SV) has emerged as a promising method for data valuation.
However, computing or estimating the SV is often computationally expensive. To
overcome this challenge, Jia et al. (2019) propose an advanced SV estimation
algorithm called ``Group Testing-based SV estimator'' which achieves favorable
asymptotic sample complexity. In this technical note, we present several
improvements in the analysis and design choices of this SV estimator. Moreover,
we point out that the Group Testing-based SV estimator does not fully reuse the
collected samples. Our analysis and insights contribute to a better
understanding of the challenges in developing efficient SV estimation
algorithms for data valuation.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:13:45 GMT""}]","2023-02-23"
"2302.11432","Nicol\'as Zalduendo","Yamit Yalanda and Nicol\'as Zalduendo","Restricted Maximum of Non-Intersecting Brownian Bridges",,,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Consider a system of $N$ non-intersecting Brownian bridges in $[0,1]$, and
let $\mathcal M_N(p)$ be the maximal height attained by the top path in the
interval $[0,p]$, $p\in[0,1]$. It is known that, under a suitable rescaling,
the distribution of $\mathcal M_N(p)$ converges, as $N\to\infty$, to a
one-parameter family of distributions interpolating between the Tracy-Widom
distributions for the Gaussian Orthogonal and Unitary Ensembles (corresponding,
respectively, to $p\to1$ and $p\to0$). It is also known that, for fixed $N$,
$\mathcal M_N(1)$ is distributed as the top eigenvalue of a random matrix drawn
from the Laguerre Orthogonal Ensemble. Here we show a version of these results
for $\mathcal M_N(p)$ for fixed $N$, showing that $\mathcal M_N(p)/\sqrt{p}$
converges in distribution, as $p\to0$, to the rightmost charge in a generalized
Laguerre Unitary Ensemble, which coincides with the top eigenvalue of a random
matrix drawn from the Antisymmetric Gaussian Ensemble.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:14:55 GMT""}]","2023-02-23"
"2302.11433","Pingan Cheng","Peyman Afshani and Pingan Cheng","Lower Bounds for Intersection Reporting among Flat Objects","Accepted by SoCG'23",,,,"cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, Ezra and Sharir [ES22a] showed an $O(n^{3/2+\sigma})$ space and
$O(n^{1/2+\sigma})$ query time data structure for ray shooting among triangles
in $\mathbb{R}^3$. This improves the upper bound given by the classical
$S(n)Q(n)^4=O(n^{4+\sigma})$ space-time tradeoff for the first time in almost
25 years and in fact lies on the tradeoff curve of
$S(n)Q(n)^3=O(n^{3+\sigma})$. However, it seems difficult to apply their
techniques beyond this specific space and time combination. This pheonomenon
appears persistently in almost all recent advances of flat object intersection
searching, e.g., line-tetrahedron intersection in $\mathbb{R}^4$ [ES22b],
triangle-triangle intersection in $\mathbb{R}^4$ [ES22b], or even among flat
semialgebraic objects [AAEKS22].
  We give a timely explanation to this phenomenon from a lower bound
perspective. We prove that given a set $\mathcal{S}$ of $(d-1)$-dimensional
simplicies in $\mathbb{R}^d$, any data structure that can report all
intersections with small ($n^{o(1)}$) query time must use
$\Omega(n^{2(d-1)-o(1)})$ space. This dashes the hope of any significant
improvement to the tradeoff curves for small query time and almost matches the
classical upper bound. We also obtain an almost matching space lower bound of
$\Omega(n^{6-o(1)})$ for triangle-triangle intersection reporting in
$\mathbb{R}^4$ when the query time is small. Along the way, we further develop
the previous lower bound techniques by Afshani and Cheng [AC21, AC22].
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:15:39 GMT""}]","2023-02-23"
"2302.11434","Fan Yang","Fan Yang, Chen Wang, Cesar Cadena, and Marco Hutter","iPlanner: Imperative Path Planning","9 pages, 11 figures, Robotics: Science and Systems (RSS) 2023",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of path planning has been studied for years. Classic planning
pipelines, including perception, mapping, and path searching, can result in
latency and compounding errors between modules. While recent studies have
demonstrated the effectiveness of end-to-end learning methods in achieving high
planning efficiency, these methods often struggle to match the generalization
abilities of classic approaches in handling different environments. Moreover,
end-to-end training of policies often requires a large number of labeled data
or training iterations to reach convergence. In this paper, we present a novel
Imperative Learning (IL) approach. This approach leverages a differentiable
cost map to provide implicit supervision during policy training, eliminating
the need for demonstrations or labeled trajectories. Furthermore, the policy
training adopts a Bi-Level Optimization (BLO) process, which combines network
update and metric-based trajectory optimization, to generate a smooth and
collision-free path toward the goal based on a single depth measurement. The
proposed method allows task-level costs of predicted trajectories to be
backpropagated through all components to update the network through direct
gradient descent. In our experiments, the method demonstrates around 4x faster
planning than the classic approach and robustness against localization noise.
Additionally, the IL approach enables the planner to generalize to various
unseen environments, resulting in an overall 26-87% improvement in SPL
performance compared to baseline learning methods.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:16:00 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 20:08:57 GMT""},{""version"":""v3"",""created"":""Wed, 24 May 2023 22:16:13 GMT""}]","2023-05-26"
"2302.11435","Debarshi Basu","Debarshi Basu, Lavish and Boudhayan Paul","Entanglement Negativity in $\text{T}\bar{\text{T}}$-deformed CFT$_2$s","12 pages + 1 appendix, 5 figures",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the entanglement negativity for various bipartite mixed states in
$\text{T}\bar{\text{T}}$-deformed CFT$_2$s at a finite temperature. Utilizing
the replica method, we construct a general formula for the entanglement
negativity of bipartite mixed states up to first order in the deformation
parameter. Subsequently, we compute the entanglement negativity for bipartite
states involving two disjoint, two adjacent and a single interval utilizing our
formula. Furthermore, we advance a holographic construction to compute the
entanglement negativity in such bipartite states in the
$\text{T}\bar{\text{T}}$-deformed CFT$_2$s and find agreement with the
corresponding field theoretic results in the limit of small deformation
parameter.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:17:12 GMT""}]","2023-02-23"
"2302.11436","Mckay Jensen","Mckay Jensen, Nicholas Emery-Xu, Robert Trager","Industrial Policy for Advanced AI: Compute Pricing and the Safety Tax","32 pages, 7 figures",,,,"econ.GN q-fin.EC","http://creativecommons.org/licenses/by/4.0/","  Using a model in which agents compete to develop a potentially dangerous new
technology (AI), we study how changes in the pricing of factors of production
(computational resources) affect agents' strategies, particularly their
spending on safety meant to reduce the danger from the new technology. In the
model, agents split spending between safety and performance, with safety
determining the probability of a ``disaster"" outcome, and performance
determining the agents' competitiveness relative to their peers. For given
parameterizations, we determine the theoretically optimal spending strategies
by numerically computing Nash equilibria. Using this approach we find that (1)
in symmetric scenarios, compute price increases are safety-promoting if and
only if the production of performance scales faster than the production of
safety; (2) the probability of a disaster can be made arbitrarily low by
providing a sufficiently large subsidy to a single agent; (3) when agents
differ in productivity, providing a subsidy to the more productive agent is
often better for aggregate safety than providing the same subsidy to other
agent(s) (with some qualifications, which we discuss); (4) when one agent is
much more safety-conscious, in the sense of believing that safety is more
difficult to achieve, relative to his competitors, subsidizing that agent is
typically better for aggregate safety than subsidizing its competitors;
however, subsidizing an agent that is only somewhat more safety-conscious often
decreases safety. Thus, although subsidizing a much more safety-conscious, or
productive, agent often improves safety as intuition suggests, subsidizing a
somewhat more safety-conscious or productive agent can often be harmful.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:18:12 GMT""}]","2023-02-23"
"2302.11437","Lukas A. Widmer","Lukas A. Widmer, Andrew Bean, David Ohlssen, Sebastian Weber","Principled Drug-Drug Interaction Terms for Bayesian Logistic Regression
  Models of Drug Safety in Oncology Phase I Combination Trials","14 pages, 3 figures",,,,"stat.AP stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Oncology, trials evaluating drug combinations are becoming more common.
While combination therapies bring the potential for greater efficacy, they also
create unique challenges for ensuring drug safety. In Phase-I dose escalation
trials of drug combinations, model-based approaches enable efficient use of
information gathered, but the models need to account for trial complexities:
appropriate modeling of interactions becomes increasingly important with
growing numbers of drugs being tested simultaneously in a given trial. In
principle, we can use data from multiple arms testing varying combinations to
jointly estimate toxicity of the drug combinations. However, such efforts have
highlighted limitations when modelling drug-drug interactions in the Bayesian
Logistic Regression Model (BLRM) framework used to ensure patient safety.
Previous models either do not account for non-monotonicity due to antagonistic
toxicity, or exhibit the fundamental flaw of exponentially overpowering the
contributions of the individual drugs in the dose-response. This specifically
leads to issues when drug combinations exhibit antagonistic toxicity, in which
case the toxicity probability gets vanishingly small as doses get very large.
  We put forward additional constraints inspired by Paracelsus' intuition of
""the dose makes the poison"" which avoid this flaw and present an improved
interaction model which is compatible with these constraints. We create
instructive data scenarios that showcase the improved behavior of this more
constrained drug-drug interaction model in terms of preventing further dosing
at overly toxic dose combinations and more sensible dose-finding under
antagonistic drug toxicity. This model is now available in the open-source
OncoBayes2 R package that implements the BLRM framework for an arbitrary number
of drugs and trial arms.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:18:57 GMT""}]","2023-02-23"
"2302.11438","Georgiy Karev","Georgiy Karev","On the scope of applicability of the models of Darwinian dynamics","39 pages, 11 figures",,,,"q-bio.PE","http://creativecommons.org/publicdomain/zero/1.0/","  In their well-known textbook (Vincent & Brown, 2005), Vincent and Brown
suggested an attractive approach for studying evolutionary dynamics of
populations that are heterogeneous with respect to some strategy that affects
the fitness of individuals in the population. The authors developed a theory,
whose goal was to expand the applicability of mathematical models of population
dynamics by including dynamics of an evolving heritable phenotype trait subject
to natural selection. The authors studied both the case of evolution of
individual traits and of mean traits in the population (or species) and the
dynamics of total population size. The authors consider the developed approach
as (more or less) universally applicable to models with any fitness function
and any initial distribution of strategies, which is symmetric and has small
variance. Here it was shown that the scope of the approach proposed by Vincent
& Brown is unfortunately much more limited. I show that the approach gives
exact results only if the population dynamics linearly depends on the trait;
examples where the approach is incorrect are given.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:22:38 GMT""}]","2023-02-23"
"2302.11439","Franziska Scheibel","Franziska Scheibel, Wei Liu, Lukas Pfeuffer, Navid Shayanfar, Andreas
  Taubel, Konstantin P. Skokov, Stefan Riegg, Yuye Wu, Oliver Gutfleisch","Influence of Gd-rich precipitates on the martensitic transformation,
  magnetocaloric effect and mechanical properties of Ni-Mn-In Heusler alloys --
  A comparative study","Keywords: metal matrix composites, magnetocaloric, magneto-structural
  phase transitions, microstructure, mechanical properties, Heusler alloy","Journal of Applied Physics 133, 075104 (2023)","10.1063/5.0143507",,"cond-mat.mtrl-sci physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  A multi-stimuli cooling cycle can be used to increase the cyclic caloric
performance of multicaloric materials like Ni-Mn-In Heusler alloys. However,
the use of a uniaxial compressive stress as an additional external stimulus to
a magnetic field requires good mechanical stability. Improvement of mechanical
stability and strength by doping has been shown in several studies. However,
doping is always accompanied by grain refinement and a change in transition
temperature. This raises the question of the extent to which mechanical
strength is related to grain refinement, transition temperature, or
precipitates. This study shows a direct comparison between a single-phase
Ni-Mn-Sn and a two-phase Gd-doped Ni-Mn-In alloy with the same transition
temperature and grain size. It is shown that the excellent magnetocaloric
properties of the Ni-Mn-In matrix are maintained with doping. The isothermal
entropy change and adiabatic temperature change are reduced by only 15% in the
two-phase Ni-Mn-In-Heusler alloy compared to the single-phase alloy, which is
resulting from a slight increase in thermal hysteresis and the width of the
transition. Due to the same grain size and transition temperature, this effect
can be directly related to the precipitates. The introduction of Gd
precipitates leads to a 100% improvement in mechanical strength, which is
significantly lower than the improvement observed for Ni-Mn-In alloys with
grain refinement and Gd precipitates. This reveals that a significant
contribution to the improved mechanical stability in Gd-doped Heusler alloys is
related to grain refinement.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:22:39 GMT""}]","2023-02-23"
"2302.11440","Susanna Heikkil\""a","Susanna Heikkil\""a and Pekka Pankka","De Rham algebras of closed quasiregularly elliptic manifolds are
  Euclidean",,,,,"math.CV math.DG","http://creativecommons.org/licenses/by/4.0/","  We show that, if a closed, connected, and oriented Riemannian $n$-manifold
$N$ admits a non-constant quasiregular mapping from the Euclidean $n$-space
$\mathbb R^n$, then the de Rham cohomology algebra $H_{\mathrm{dR}}^*(N)$ of
$N$ embeds into the exterior algebra ${\bigwedge}^*\mathbb R^n$. As a
consequence, we obtain a homeomorphic classification of closed simply connected
quasiregularly elliptic $4$-manifolds.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:22:50 GMT""}]","2023-02-23"
"2302.11441","Nicholas Ng","Nicholas Ng","On homogeneous closed gradient Laplacian solitons",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a structure theorem for homogeneous closed gradient Laplacian
solitons and use it to show some examples of closed Laplacian solitons cannot
be made gradient. More specifically, we show that the Laplacian solitons on
nilpotent Lie groups found by Nicolini are not gradient up to homothetic
$G_2$-structures except for $N_1$, where $f$ must be a Gaussian. We also show
that the closed $G_2$-structure $\varphi_{12}$ on $N_{12}$ constructed by
Fern\'andez-Fino-Manero cannot be a gradient soliton. We further show that
closed non-torsion-free gradient Laplacian solitons on almost abelian
solvmanifolds are isometric to products $N \times \mathbb R^k$ with $f$
constant on $N$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:23:11 GMT""}]","2023-02-23"
"2302.11442","Peter Matak","Tom\'a\v{s} Bla\v{z}ek, Peter Mat\'ak, Viktor Zaujec","$CPT$ and unitarity constraints for higher-order $CP$ asymmetries at
  finite temperature","8th Symposium on Prospects in the Physics of Discrete Symmetries
  (DISCRETE 2022) 7-11 November 2022",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use an unconventional diagrammatic approach to formulate $CPT$ and
unitarity constraints for higher-order $CP$ asymmetries entering the source
term in the Boltzmann equation. Usually, the reaction rate asymmetries in these
constraints are computed within the classical kinetic theory, using
zero-temperature quantum field theory to describe particles' interactions. We
approximate the rates, otherwise obtained within the closed-time-path
formalism, in terms of diagrams drawn on a cylindrical surface and their
holomorphic cuts. The resulting equilibrium asymmetry constraints incorporate
thermal-mass effects and allow tracking the cancellations of reaction rate
asymmetries computed with quantum statistics. We use the top Yukawa corrections
to the asymmetries in the seesaw type-I leptogenesis as an example.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:23:33 GMT""}]","2023-02-23"
"2302.11443","Tim Niklas Uhl","Peter Sanders and Tim Niklas Uhl","Engineering a Distributed-Memory Triangle Counting Algorithm","11 pages, 8 figures, to be published in 2023 IEEE International
  Parallel and Distributed Processing Symposium (IPDPS)",,,,"cs.DC cs.DS cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Counting triangles in a graph and incident to each vertex is a fundamental
and frequently considered task of graph analysis. We consider how to
efficiently do this for huge graphs using massively parallel distributed-memory
machines. Unsurprisingly, the main issue is to reduce communication between
processors. We achieve this by counting locally whenever possible and reducing
the amount of information that needs to be sent in order to handle (possible)
nonlocal triangles. We also achieve linear memory requirements despite
superlinear communication volume by introducing a new asynchronous
sparse-all-to-all operation. Furthermore, we dramatically reduce startup
overheads by allowing this communication to use indirect routing. Our
algorithms scale (at least) up to 32 768 cores and are up to 18 times faster
than the previous state of the art.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:26:44 GMT""}]","2023-02-23"
"2302.11444","Nao Komiyama","Nao Komiyama, Takeshi Shinohara","Shuffle product of desingularized multiple zeta functions at integer
  points","37 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the ``shuffle-type'' formula for special values
of desingularized multiple zeta functions at integer points. It is proved by
giving an iterated integral/differential expression for the desingularized
multiple zeta functions at integer points.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:28:33 GMT""}]","2023-02-23"
"2302.11445","Xuan Yao","Xuan Yao","On the Yamabe invariant of certain compact manifolds with boundary","22 pages, comments welcome!",,,,"math.DG math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We generalize Kobayashi's connected-sum inequality to the $\lambda$-Yamabe
invariants. As an application, we calculate the $\lambda$-Yamabe invariants of
$\#m_1\mathbb{RP}^n\# m_2(\mathbb{RP}^{n-1}\times S^1)\#lH^n\#kS_+^n$, for any
$\lambda\in [0,1]$, $n\geq 3$, provided $k+l\geq 1$.
  As a corollary, we prove that $\mathbb{RP}^n$ minus finitely many disjoint
$n$-balls have the same $\lambda$-Yamabe invariants as the hemi-sphere, which
forms an interesting contrast with the famous Bray-Neves results on the Yamabe
invariants of $\mathbb{RP}^3$.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:28:57 GMT""},{""version"":""v2"",""created"":""Wed, 29 Mar 2023 23:37:00 GMT""}]","2023-03-31"
"2302.11446","Jehan Ghafuri","Jehan Ghafuri, Sabah Jassim","Singular value decomposition based matrix surgery","11 pages, 5 figures",,,,"math.AT cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper aims to develop a simple procedure to reduce and control the
condition number of random matrices, and investigate the effect on the
persistent homology (PH) of point clouds of well- and ill-conditioned matrices.
For a square matrix generated randomly using Gaussian/Uniform distribution, the
SVD-Surgery procedure works by: (1) computing its singular value decomposition
(SVD), (2) replacing the diagonal factor by changing a list of the smaller
singular values by a convex linear combination of the entries in the list, and
(3) compute the new matrix by reversing the SVD. Applying SVD-Surgery on a
matrix often results in having different diagonal factor to those of the input
matrix. The spatial distribution of random square matrices are known to be
correlated to the distribution of their condition numbers. The persistent
homology (PH) investigations, therefore, are focused on comparing the effect of
SVD-Surgery on point clouds of large datasets of randomly generated
well-conditioned and ill-conditioned matrices, as well as that of the point
clouds formed by their inverses. This work is motivated by the desire to
stabilise the impact of Deep Learning (DL) training on medical images in terms
of the condition numbers of their sets of convolution filters as a mean of
reducing overfitting and improving robustness against tolerable amounts of
image noise. When applied to convolution filters during training, the
SVD-Surgery acts as a spectral regularisation of the DL model without the need
for learning extra parameters. We shall demonstrate that for several point
clouds of sufficiently large convolution filters our simple strategy preserve
filters norm and reduces the norm of its inverse depending on the chosen linear
combination parameters. Moreover, our approach showed significant improvements
towards the well-conditioning of matrices and stable topological behaviour.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:30:08 GMT""}]","2023-02-23"
"2302.11447","Sara Bertocco","S. Bertocco","Modeling software solutions and computation facilities for FAIR access","Will appear in Proceedings ADASSXXXII ASP Conference Series",,,,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We are in the era of the Big Data. In Astronomy and Astrophysics, the massive
amounts of data generated are, as of today, in the Peta-scale if not already in
the Exa-scale. In the near future, we will see the data collected size and
complexity grow further constantly, setting new challenges for data processing,
reduction and analysis. This will pose new needs in terms of software and
hardware solutions but also in terms of new models for resource management,
access and sharing. In Astronomy and Astrophysics, in the environment of the
International Virtual Observatory Alliance (IVOA), a big work has already been
done with regards to data, gaining complete data FAIRness. In this paper, a
model is proposed, based on the IVOA architecture, for software and hardware
solutions for data analysis. The goal of this model is to build a cloud to
access Astronomy and Astrophysics resources following the FAIR principles.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:31:54 GMT""}]","2023-02-23"
"2302.11448","Stefano Fioravanti","Stefano Fioravanti","On properties described by terms in commutator relation",,,,,"math.RA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We investigate properties of varieties of algebras described by a new concept
of equation that we call \emph{commutator equation}. A commutator equation is a
relaxation of the standard term equality obtained substituting the equality
relation with the commutator relation. Namely, an algebra $\mathbf{A}$
satisfies the commutator equation $p \approx_{C} q$ if for each congruence
$\theta$ in $\text{Con}(\mathbf{A})$ and for each substitution $p^{\mathbf{A}},
q^{\mathbf{A}}$ of elements in the same $\theta$-class, then $(p^{\mathbf{A}},
q^{\mathbf{A}}) \in [\theta, \theta]$. This concept of equation is inspired by
the definition of weak difference term and allows for further generalization of
this notion. Furthermore, we prove that if the variety generated by the abelian
algebras of the idempotent reduct of a variety satisfies a non-trivial
idempotent Mal'cev condition then also the entire variety satisfies a
non-trivial idempotent Mal'cev condition. This result represents an improvement
of Taylor's characterization of the class of varieties satisfying a non-trivial
idempotent Mal'cev condition obtained with a relaxation of the hypothesis.
Moreover, we provide an algorithm to connect congruence equations that hold in
the variety generated by the abelian algebras of the idempotent reduct of a
variety and congruence equations that hold in the whole variety.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:34:23 GMT""}]","2023-02-23"
"2302.11449","Daniel Sanz-Alonso","N. Garcia Trillos and B. Hosseini and D. Sanz-Alonso","From Optimization to Sampling Through Gradient Flows","This article will appear in the Notices of the American Mathematical
  Society",,,,"stat.CO","http://creativecommons.org/licenses/by/4.0/","  This article overviews how gradient flows, and discretizations thereof, are
useful to design and analyze optimization and sampling algorithms. The
interplay between optimization, sampling, and gradient flows is an active
research area; our goal is to provide an accessible and lively introduction to
some core ideas, emphasizing that gradient flows uncover the conceptual unity
behind many optimization and sampling algorithms, and that they give a rich
mathematical framework for their rigorous analysis.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:37:10 GMT""}]","2023-02-23"
"2302.11450","Emil Zeuthen","Sergey A. Fedorov and Emil Zeuthen","Prediction-retrodiction measurements for teleportation and conditional
  state transfer",,,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous measurements allow predicting the future and retrodicting the past
of quantum systems. These two possibilities are not exhaustive, and some
measurements leave the future and the past uncertain, yet establish a relation
between them; such measurements are non-local in time. We introduce a procedure
for continuous time-non-local measurements formulated as a superposition of
prediction and retrodiction, and apply it to the problems of teleportation and
conditional state transfer between two quantum oscillators interacting with
traveling fields. The two observables that need to be measured to transfer a
state are the position and momentum differences between the source oscillator
at the initial time and the target oscillator at the final time of the
interaction. Such measurements do not condition regular quantum states, but
two-time states that contain components propagating in opposite directions in
time. Our approach enables us to analytically determine the fidelities of the
state transfer based on homodyne detection, and to identify strategies for
performing the transfer perfectly across a wide range of linear
oscillator-field interactions beyond the pure beam-splitter and
two-mode-squeezing types.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:37:17 GMT""}]","2023-02-23"
"2302.11451","Christian Diem","Christian Diem and Andr\'as Borsos and Tobias Reisch and J\'anos
  Kert\'esz and Stefan Thurner","Estimating the loss of economic predictability from aggregating
  firm-level production networks",,,,,"econ.GN physics.soc-ph q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To estimate the reaction of economies to political interventions or external
disturbances, input-output (IO) tables -- constructed by aggregating data into
industrial sectors -- are extensively used. However, economic growth,
robustness, and resilience crucially depend on the detailed structure of
non-aggregated firm-level production networks (FPNs). Due to non-availability
of data little is known about how much aggregated sector-based and detailed
firm-level-based model-predictions differ. Using a nearly complete nationwide
FPN, containing 243,399 Hungarian firms with 1,104,141 supplier-buyer-relations
we self-consistently compare production losses on the aggregated industry-level
production network (IPN) and the granular FPN. For this we model the
propagation of shocks of the same size on both, the IPN and FPN, where the
latter captures relevant heterogeneities within industries. In a COVID-19
inspired scenario we model the shock based on detailed firm-level data during
the early pandemic. We find that using IPNs instead of FPNs leads to errors up
to 37% in the estimation of economic losses, demonstrating a natural limitation
of industry-level IO-models in predicting economic outcomes. We ascribe the
large discrepancy to the significant heterogeneity of firms within industries:
we find that firms within one sector only sell 23.5% to and buy 19.3% from the
same industries on average, emphasizing the strong limitations of industrial
sectors for representing the firms they include. Similar error-levels are
expected when estimating economic growth, CO2 emissions, and the impact of
policy interventions with industry-level IO models. Granular data is key for
reasonable predictions of dynamical economic systems.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:39:21 GMT""}]","2023-02-23"
"2302.11452","Stefano Fioravanti","Paolo Aglian\`o, Stefano Bartali, Stefano Fioravanti","On Freese's technique",,,,,"math.RA","http://creativecommons.org/licenses/by-nc-nd/4.0/","  In this paper we explore some applications of a certain technique (that we
call the Freese's technique), which is a tool for identifying certain lattices
as sublattices of the congruence lattice of a given algebra. In particular we
will give sufficient conditions for two family of lattices (called the rods and
the snakes) to be admissible as sublattices of a variety generated by a given
algebra, extending an unpublished result of R. Freese and P. Lipparini.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:39:30 GMT""}]","2023-02-23"
"2302.11453","Sara Bertocco","S. Bertocco, D. Goz, S.A. Russo, M. Moliaro, G. Taffoni","Requirements analysis for HPC\&HTC infrastructures integration in ESCAPE
  Science Analysis Platform","Will appear in Proceedings ADASSXXX ASP Conference Series",,,,"astro-ph.IM","http://creativecommons.org/licenses/by-nc-sa/4.0/","  ESCAPE (European Science Cluster of Astronomy and Particle physics ESFRI
research infrastructures) is a project to set up a cluster of ESFRI (European
Strategy Forum on Research Infrastructures) facilities for astronomy,
astroparticle and particle physics to face the challenges emerging through the
modern multi-disciplinary data driven science. One of the main goal of ESCAPE
is the building of ESAP (ESFRI Science Analysis Platform), a science platform
for the analysis of open access data available through the EOSC (European Open
Science Cloud) environment. ESAP will allow EOSC researchers to identify and
stage existing data collections for analysis, share data, share and run
scientific workflows. For many of the concerned ESFRIs and RIs, the data scales
involved require significant computational resources (storage and compute) to
support processing and analysis. The EOSC-ESFRI science platform therefore must
implement appropriate interfaces to an underlying HPC (High Performance
Computing) or HTC (High Throughput Computing) infrastructure to take advantage
of it. This poster describes the analysis done to identify the main
requirements for the implementation of the interfaces enabling the ESAP data
access and computation resources integration in HPC and HTC computation
infrastructures in terms of authentication and authorization policies, data
management, workflow deployment and run.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:40:14 GMT""}]","2023-02-23"
"2302.11454","David Gosset","Sergey Bravyi, Anirban Chowdhury, David Gosset, Vojtech Havlicek,
  Guanyu Zhu","Quantum complexity of the Kronecker coefficients",,,,,"quant-ph cs.CC math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Whether or not the Kronecker coefficients of the symmetric group count some
set of combinatorial objects is a longstanding open question. In this work we
show that a given Kronecker coefficient is proportional to the rank of a
projector that can be measured efficiently using a quantum computer. In other
words a Kronecker coefficient counts the dimension of the vector space spanned
by the accepting witnesses of a QMA verifier, where QMA is the quantum analogue
of NP. This implies that approximating the Kronecker coefficients to within a
given relative error is not harder than a certain natural class of quantum
approximate counting problems that captures the complexity of estimating
thermal properties of quantum many-body systems. A second consequence is that
deciding positivity of Kronecker coefficients is contained in QMA,
complementing a recent NP-hardness result of Ikenmeyer, Mulmuley and Walter. We
obtain similar results for the related problem of approximating row sums of the
character table of the symmetric group. Finally, we discuss an efficient
quantum algorithm that approximates normalized Kronecker coefficients to
inverse-polynomial additive error.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:43:26 GMT""}]","2023-02-23"
"2302.11455","El Mehdi Haress","Ludovic Gouden\`ege, El Mehdi Haress, Alexandre Richard","Numerical approximation of SDEs with fractional noise and distributional
  drift",,,,,"math.PR cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the well-posedness and numerical approximation of multidimensional
stochastic differential equations (SDEs) with distributional drift, driven by a
fractional Brownian motion.
  First, we prove weak existence for such SDEs. This holds under a condition
that relates the Hurst parameter $H$ of the noise to the Besov regularity of
the drift. Then under a stronger condition, we study the error between a
solution $X$ of the SDE with drift $b$ and its tamed Euler scheme with
mollified drift $b^n$. We obtain a rate of convergence in $L^m(\Omega)$ for
this error, which depends on the Besov regularity of the drift. This result
covers the critical case of the regime of strong existence and pathwise
uniqueness. When the Besov regularity increases and the drift becomes a bounded
measurable function, we recover the (almost) optimal rate of convergence
$1/2-\varepsilon$. As a byproduct of this convergence, we deduce that pathwise
uniqueness holds in a class of H\""older continuous solutions and that any such
solution is strong.
  The proofs rely on stochastic sewing techniques, especially to deduce new
regularising properties of the discrete-time fractional Brownian motion. We
also present several examples and numerical simulations that illustrate our
results.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:43:30 GMT""}]","2023-02-23"
"2302.11456","Michele Pernice","Michele Pernice","Hyperelliptic $A_r$-stable curves (and their moduli stack)","The paper is one of the four papers that compose the author's PhD
  thesis. In particular, it contains Section 1.1, Section 1.3 and Section 1.4
  of arXiv:2211.09793. Some typos have been corrected and the exposition was
  improved. 35 pages; comments are very welcome",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is the second in a series of four papers aiming to describe the
(almost integral) Chow ring of $\Mbar_3$, the moduli stack of stable curves of
genus $3$. In this paper, we introduce the moduli stack $\Htilde_g^r$ of
hyperelliptic $A_r$-stable curves and generalize the theory of hyperelliptic
stable curves to hyperelliptic $A_r$-stable curves. In particular, we prove
that $\Htilde_g^r$ is a smooth algebraic stacks which can be described using
cyclic covers of twisted curves of genus $0$ and it embeds in $\Mtilde_g^r$
(the moduli stack of $A_r$-stable curves) as the closure of the moduli stack of
smooth hyperelliptic curves.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:47:56 GMT""}]","2023-02-23"
"2302.11457","Ismail Lotfi","Ismail Lotfi, Dusit Niyato, Sumei Sun, Dong In Kim, Xuemin Shen","Semantic Information Marketing in The Metaverse: A Learning-Based
  Contract Theory Framework","submitted to JSAC",,,,"cs.AI cs.GT","http://creativecommons.org/licenses/by/4.0/","  In this paper, we address the problem of designing incentive mechanisms by a
virtual service provider (VSP) to hire sensing IoT devices to sell their
sensing data to help creating and rendering the digital copy of the physical
world in the Metaverse. Due to the limited bandwidth, we propose to use
semantic extraction algorithms to reduce the delivered data by the sensing IoT
devices. Nevertheless, mechanisms to hire sensing IoT devices to share their
data with the VSP and then deliver the constructed digital twin to the
Metaverse users are vulnerable to adverse selection problem. The adverse
selection problem, which is caused by information asymmetry between the system
entities, becomes harder to solve when the private information of the different
entities are multi-dimensional. We propose a novel iterative contract design
and use a new variant of multi-agent reinforcement learning (MARL) to solve the
modelled multi-dimensional contract problem. To demonstrate the effectiveness
of our algorithm, we conduct extensive simulations and measure several key
performance metrics of the contract for the Metaverse. Our results show that
our designed iterative contract is able to incentivize the participants to
interact truthfully, which maximizes the profit of the VSP with minimal
individual rationality (IR) and incentive compatibility (IC) violation rates.
Furthermore, the proposed learning-based iterative contract framework has
limited access to the private information of the participants, which is to the
best of our knowledge, the first of its kind in addressing the problem of
adverse selection in incentive mechanisms.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:52:37 GMT""},{""version"":""v2"",""created"":""Sat, 25 Feb 2023 05:42:15 GMT""}]","2023-02-28"
"2302.11458","Manuel Stoiber","Manuel Stoiber, Mariam Elsayed, Anne E. Reichert, Florian Steidle,
  Dongheui Lee, Rudolph Triebel","Fusing Visual Appearance and Geometry for Multi-modality 6DoF Object
  Tracking","Submitted to IEEE/RSJ International Conference on Intelligent Robots",,,,"cs.CV","http://creativecommons.org/licenses/by/4.0/","  In many applications of advanced robotic manipulation, six degrees of freedom
(6DoF) object pose estimates are continuously required. In this work, we
develop a multi-modality tracker that fuses information from visual appearance
and geometry to estimate object poses. The algorithm extends our previous
method ICG, which uses geometry, to additionally consider surface appearance.
In general, object surfaces contain local characteristics from text, graphics,
and patterns, as well as global differences from distinct materials and colors.
To incorporate this visual information, two modalities are developed. For local
characteristics, keypoint features are used to minimize distances between
points from keyframes and the current image. For global differences, a novel
region approach is developed that considers multiple regions on the object
surface. In addition, it allows the modeling of external geometries.
Experiments on the YCB-Video and OPT datasets demonstrate that our approach
ICG+ performs best on both datasets, outperforming both conventional and deep
learning-based methods. At the same time, the algorithm is highly efficient and
runs at more than 300 Hz. The source code of our tracker is publicly available.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:53:00 GMT""}]","2023-02-23"
"2302.11459","Michael Tait","Jacob Johnston and Michael Tait","Extremal values for the spectral radius of the normalized distance
  Laplacian",,,,,"math.CO","http://creativecommons.org/licenses/by/4.0/","  The normalized distance Laplacian of a graph $G$ is defined as
$\mathcal{D}^\mathcal{L}(G)=T(G)^{-1/2}(T(G)-\mathcal{D}(G))T(G)^{-1/2}$ where
$\mathcal{D}(G)$ is the matrix with pairwise distances between vertices and
$T(G)$ is the diagonal transmission matrix. In this project, we study the
minimum and maximum spectral radii associated with this matrix, and the
structures of the graphs that achieve these values. In particular, we prove a
conjecture of Reinhart that the complete graph is the unique graph with minimum
spectral radius, and we give several partial results towards a second
conjecture of Reinhart regarding which graph has the maximum spectral radius.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:53:09 GMT""}]","2023-02-23"
"2302.11460","Adailton Ara\'ujo Filho","P. Sedaghatnia, H. Hassanabadi, A. A. Ara\'ujo Filho, J. Porf\'irio,
  W. S. Chung","Thermodynamical properties of a deformed Schwarzschild black hole via
  Dunkl generalization","12 pages and 5 figures",,,,"gr-qc hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we construct a deformed Schwarzschild black hole from the de
Sitter gauge theory of gravity within Dunkl generalization and we determine the
metric coefficients versus Dunkl parameter and parity operators. Since the
spacetime coordinates are not affected by the group transformations, only
fields are allowed to change under the action of the symmetry group. A
particular ansatz for the gauge fields is chosen and the components of the
strength tensor are computed as well. Additionally, we analyze the
modifications on the thermodynamic properties to a spherically symmetric black
hole due to Dunkl parameters for even and odd parities. Finally, we verify a
novel remark highlighted from heat capacity: the appearance of a phase
transition when the odd parity is taken into account.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:53:28 GMT""}]","2023-02-23"
"2302.11461","Meilin Chen","Meilin Chen, Yizhou Wang, Shixiang Tang, Feng Zhu, Haiyang Yang, Lei
  Bai, Rui Zhao, Donglian Qi, Wanli Ouyang","Saliency Guided Contrastive Learning on Scene Images","12 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:2106.11952 by other authors",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Self-supervised learning holds promise in leveraging large numbers of
unlabeled data. However, its success heavily relies on the highly-curated
dataset, e.g., ImageNet, which still needs human cleaning. Directly learning
representations from less-curated scene images is essential for pushing
self-supervised learning to a higher level. Different from curated images which
include simple and clear semantic information, scene images are more complex
and mosaic because they often include complex scenes and multiple objects.
Despite being feasible, recent works largely overlooked discovering the most
discriminative regions for contrastive learning to object representations in
scene images. In this work, we leverage the saliency map derived from the
model's output during learning to highlight these discriminative regions and
guide the whole contrastive learning. Specifically, the saliency map first
guides the method to crop its discriminative regions as positive pairs and then
reweighs the contrastive losses among different crops by its saliency scores.
Our method significantly improves the performance of self-supervised learning
on scene images by +1.1, +4.3, +2.2 Top1 accuracy in ImageNet linear
evaluation, Semi-supervised learning with 1% and 10% ImageNet labels,
respectively. We hope our insights on saliency maps can motivate future
research on more general-purpose unsupervised representation learning from
scene data.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:54:07 GMT""},{""version"":""v2"",""created"":""Thu, 23 Feb 2023 05:46:53 GMT""}]","2023-02-24"
"2302.11462","Jos\'e \'Angel Castellanos-Reyes","Jos\'e \'Angel Castellanos-Reyes, Paul Zeiger, Anders Bergman, Demie
  Kepaptsoglou, Quentin M. Ramasse, Juan Carlos Idrobo, and J\'an Rusz","Unveiling the impact of temperature on magnon diffuse scattering
  detection in scanning transmission electron microscopy",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magnon diffuse scattering (MDS) signals could be studied with high spatial
resolution in scanning transmission electron microscopy (STEM), thanks to
recent technological progress in electron energy loss spectroscopy. However,
detecting MDS signals in STEM is challenging due to their overlap with the
stronger thermal diffuse scattering (TDS) signals. In bcc Fe at 300~K, MDS
signals greater than or comparable to TDS signals occur under the central Bragg
disk, into a currently inaccesible energy-loss region. Therefore, to detect MDS
in STEM, it is necessary to identify conditions in which TDS and MDS signals
can be distinguished from one another. Temperature may be a key factor due to
the distinct thermal signatures of magnon and phonon signals. In this work, we
present a study on the effects of temperature on MDS and TDS in bcc Fe --
considering a detector outside the central Bragg disk -- using the frozen
phonon and frozen magnon multislice methods. Our study reveals that neglecting
the effects of atomic vibrations causes the MDS signal to grow approximately
linearly up to the Curie temperature of Fe, after which it exhibits less
variation. The MDS signal displays an alternating behavior due to dynamical
diffraction, instead of increasing monotonically as a function of thickness.
The inclusion of the Debye-Waller factor (DWF) causes the linear growth of the
MDS signal to change to an oscillatory behavior that exhibits a predominant
peak for each thickness, which increases and shifts to higher temperatures as
the thickness increases. In contrast, the TDS signal grows more linearly than
the MDS signal (with DWF) but still exhibits dynamical diffraction effects. An
analysis of the signal-to-noise ratio (SNR) shows that the MDS signal can be a
statistically significant contribution to the total scattering intensity under
realistic measurement conditions and reasonable acquisition times.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:55:34 GMT""}]","2023-02-23"
"2302.11463","Hemaditya Malla","H.Malla, A.Martinez, U.Ebert and J.Teunissen","Double-pulse streamer simulations for varying interpulse times in air",,,,,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study how streamer discharges are influenced by a previous
voltage pulse. We simulate double-pulse positive streamers with an axisymmetric
model in dry air at 1 bar, varying the time between the pulses between 5 ns and
10 $\mu$s. For increasing interpulse times, we observe three regimes during the
second pulse: streamer continuation, inhibited growth and streamer repetition.
In the streamer continuation regime, a new streamer emerges from the tip of the
previous one. In the inhibited regime, the previous channel is partially
re-ionized, but there is considerably less field enhancement and almost no
light emission. Finally, for the longest interpulse times, a new streamer forms
that is similar to the first one. The remaining electron densities at which we
observe streamer continuation agree with earlier experimental work. We
introduce an estimate which relates streamer continuation to the dielectric
relaxation time, the background field and the pulse duration. Furthermore, we
show that for interpulse times above 100 ns several electron detachment
reactions significantly slow down the decay of the electron density.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:55:56 GMT""}]","2023-02-23"
"2302.11464","Baoliang Chen","Baoliang Chen, Hanwei Zhu, Lingyu Zhu, and Shiqi Wang","Debiased Mapping for Full-Reference Image Quality Assessment",,,,,"cs.CV eess.IV","http://creativecommons.org/licenses/by/4.0/","  Mapping images to deep feature space for comparisons has been wildly adopted
in recent learning-based full-reference image quality assessment (FR-IQA)
models. Analogous to the classical classification task, the ideal mapping space
for quality regression should possess both inter-class separability and
intra-class compactness. The inter-class separability that focuses on the
discrimination of images with different quality levels has been highly
emphasized in existing models. However, the intra-class compactness that
maintains small objective quality variance of images with the same or
indistinguishable quality escapes the research attention, potentially leading
to the perception-biased measures. In this paper, we reveal that such bias is
mainly caused by the unsuitable subspace that the features are projected and
compared in. To account for this, we develop the Debiased Mapping based quality
Measure (DMM), which relies on the orthonormal bases of deep learning features
formed by singular value decomposition (SVD). The SVD in deep learning feature
domain, which overwhelmingly separates the quality variations with singular
values and projection bases, facilitates the quality inference with dedicatedly
designed distance measure. Experiments on different IQA databases demonstrate
the mapping method is able to mitigate the perception bias efficiently, and the
superior performance on quality prediction verifies the effectiveness of our
method. The implementation will be publicly available.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:57:03 GMT""},{""version"":""v2"",""created"":""Thu, 16 Mar 2023 14:20:14 GMT""}]","2023-03-17"
"2302.11536","Paolo Frumento","Paolo Frumento","Against normality testing","11 pages, 2 figures, 1 table",,,,"stat.OT","http://creativecommons.org/licenses/by/4.0/","  I reject the following null hypothesis: {H0: your data are normal}. Such
drastic decision is motivated by theoretical reasons, and applies to your
current data, the past ones, and the future ones. While this situation may
appear embarrassing, it does not invalidate any of your results. Moreover, it
allows to save time and energy that are currently spent in vain by performing
the following unnecessary tasks: (i) carrying out normality tests; (ii)
pretending to do something if normality is rejected; and (iii) arguing about
normality with Referee #2.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:24:13 GMT""}]","2023-02-23"
"2302.11573","Mohammad Hossein Zhoolideh Haghighi","Mohammad H. Zhoolideh Haghighi","Analyzing Astronomical Data with Machine Learning Techniques","Proceedings based on the lectures given at the hands-on workshop of
  the ICRANet-ISFAHAN Astronomy Meeting, to be published in Astronomical and
  Astrophysical Transactions",,,,"astro-ph.IM astro-ph.SR physics.comp-ph physics.data-an","http://creativecommons.org/licenses/by/4.0/","  Classification is a popular task in the field of Machine Learning (ML) and
Artificial Intelligence (AI), and it happens when outputs are categorical
variables. There are a wide variety of models that attempts to draw some
conclusions from observed values, so classification algorithms predict
categorical class labels and use them in classifying new data. Popular
classification models including logistic regression, decision tree, random
forest, Support Vector Machine (SVM), multilayer perceptron, Naive Bayes, and
neural networks have proven to be efficient and accurate applied to many
industrial and scientific problems. Particularly, the application of ML to
astronomy has shown to be very useful for classification, clustering, and data
cleaning. It is because after learning computers, these tasks can be done
automatically by them in a more precise and more rapid way than human
operators. In view of this, in this paper, we will review some of these popular
classification algorithms, and then we apply some of them to the observational
data of nonvariable and the RR Lyrae variable stars that come from the SDSS
survey. For the sake of comparison, we calculate the accuracy and F1-score of
the applied models.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:15:31 GMT""}]","2023-02-24"
"2302.11999","Soumi Tribedi","Soumi Tribedi, Duy-Khoi Dang, Bikash Kanungo, Vikram Gavini, Paul M.
  Zimmerman","Exchange Correlation Potentials from Accurate FCI Densities Constructed
  from Slater Basis Functions","13 pages, 13 figures",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  RKS theory builds a bridge between wave function theory and density
functional theory by using quantities from the former to produce accurate
exchange-correlation potentials needed by the latter. In this work, the RKS
method is developed and tested alongside Slater atomic orbital basis functions
for the first time. To evaluate this approach, Full Configuration Interaction
computations in the Slater orbitals are employed to give quality input to RKS
method, allowing full correlation to be present along with correct nuclei cusps
and asymptotic decay of the wavefunction. The RKS method will be shown to be an
efficient algorithm to arrive at exchange correlation potentials without
unphysical artifacts in moderately-sized basis sets. Furthermore, enforcement
of the nuclear cusp conditions will be shown to be vital for the success of the
Slater-basis RKS method. Examples of weakly and strongly correlated molecular
systems will demonstrate the main features of Slater RKS.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:47:05 GMT""},{""version"":""v2"",""created"":""Fri, 12 May 2023 20:48:11 GMT""}]","2023-05-16"
"2302.12000","Mashaan Alshammari","Mashaan Alshammari, John Stavrakakis, Adel F. Ahmed, Masahiro
  Takatsuka","Graph Construction using Principal Axis Trees for Simple Graph
  Convolution",,,,,"cs.LG cs.AI cs.IR cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph Neural Networks (GNNs) are increasingly becoming the favorite method
for graph learning. They exploit the semi-supervised nature of deep learning,
and they bypass computational bottlenecks associated with traditional graph
learning methods. In addition to the feature matrix $X$, GNNs need an adjacency
matrix $A$ to perform feature propagation. In many cases the adjacency matrix
$A$ is missing. We introduce a graph construction scheme that construct the
adjacency matrix $A$ using unsupervised and supervised information.
Unsupervised information characterize the neighborhood around points. We used
Principal Axis trees (PA-trees) as a source of unsupervised information, where
we create edges between points falling onto the same leaf node. For supervised
information, we used the concept of penalty and intrinsic graphs. A penalty
graph connects points with different class labels, whereas intrinsic graph
connects points with the same class label. We used the penalty and intrinsic
graphs to remove or add edges to the graph constructed via PA-tree. This graph
construction scheme was tested on two well-known GNNs: 1) Graph Convolutional
Network (GCN) and 2) Simple Graph Convolution (SGC). The experiments show that
it is better to use SGC because it is faster and delivers better or the same
results as GCN. We also test the effect of oversmoothing on both GCN and SGC.
We found out that the level of smoothing has to be selected carefully for SGC
to avoid oversmoothing.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:02:23 GMT""},{""version"":""v2"",""created"":""Wed, 1 Mar 2023 12:43:16 GMT""}]","2023-03-02"
"2302.12001","Mashaan Alshammari Dr.","Mashaan Alshammari, John Stavrakakis, Adel F. Ahmed, Masahiro
  Takatsuka","Random Projection Forest Initialization for Graph Convolutional Networks",,,,,"cs.LG cs.AI cs.IR cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph convolutional networks (GCNs) were a great step towards extending deep
learning to unstructured data such as graphs. But GCNs still need a constructed
graph to work with. To solve this problem, classical graphs such as $k$-nearest
neighbor are usually used to initialize the GCN. Although it is computationally
efficient to construct $k$-nn graphs, the constructed graph might not be very
useful for learning. In a $k$-nn graph, points are restricted to have a fixed
number of edges, and all edges in the graph have equal weights. We present a
new way to construct the graph and initialize the GCN. It is based on random
projection forest (rpForest). rpForest enables us to assign varying weights on
edges indicating varying importance, which enhanced the learning. The number of
trees is a hyperparameter in rpForest. We performed spectral analysis to help
us setting this parameter in the right range. In the experiments, initializing
the GCN using rpForest provides better results compared to $k$-nn
initialization.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:49:19 GMT""}]","2023-02-24"
"2302.12007","Shannan Guan","Shannan Guan, Xin Yu, Wei Huang, Gengfa Fang, Haiyan Lu","DMMG: Dual Min-Max Games for Self-Supervised Skeleton-Based Action
  Recognition",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we propose a new Dual Min-Max Games (DMMG) based
self-supervised skeleton action recognition method by augmenting unlabeled data
in a contrastive learning framework. Our DMMG consists of a viewpoint variation
min-max game and an edge perturbation min-max game. These two min-max games
adopt an adversarial paradigm to perform data augmentation on the skeleton
sequences and graph-structured body joints, respectively. Our viewpoint
variation min-max game focuses on constructing various hard contrastive pairs
by generating skeleton sequences from various viewpoints. These hard
contrastive pairs help our model learn representative action features, thus
facilitating model transfer to downstream tasks. Moreover, our edge
perturbation min-max game specializes in building diverse hard contrastive
samples through perturbing connectivity strength among graph-based body joints.
The connectivity-strength varying contrastive pairs enable the model to capture
minimal sufficient information of different actions, such as representative
gestures for an action while preventing the model from overfitting. By fully
exploiting the proposed DMMG, we can generate sufficient challenging
contrastive pairs and thus achieve discriminative action feature
representations from unlabeled skeleton data in a self-supervised manner.
Extensive experiments demonstrate that our method achieves superior results
under various evaluation protocols on widely-used NTU-RGB+D and NTU120-RGB+D
datasets.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 08:53:11 GMT""}]","2023-02-24"
"2302.12015","Mario Mastriani","Mario Mastriani","Entanglement parallelization via quantum Fourier transform","34 pages, 15 figures, 8 tables",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we present a technique based on the quantum Fourier transform
(QFT) that allows the generation of disjoint sets of entangled particles, in
such a way that particles of the same set are entangled with each other, while
particles of different sets are completely independent. Several applications of
this technique are implemented on three physical platforms, of 5 (Belem), 7
(Oslo), and 14 (Melbourne) qubits, of the international business machine (IBM
Q) quantum experience program, where all these applications were specially
selected due to their particular commitment to the future Quantum Internet.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:04:58 GMT""}]","2023-02-24"
"2302.12020","Huy Hieu Pham","Van-Tuan Tran, Huy-Hieu Pham, Kok-Seng Wong","Personalized Privacy-Preserving Framework for Cross-Silo Federated
  Learning",,,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Federated learning (FL) is recently surging as a promising decentralized deep
learning (DL) framework that enables DL-based approaches trained
collaboratively across clients without sharing private data. However, in the
context of the central party being active and dishonest, the data of individual
clients might be perfectly reconstructed, leading to the high possibility of
sensitive information being leaked. Moreover, FL also suffers from the
nonindependent and identically distributed (non-IID) data among clients,
resulting in the degradation in the inference performance on local clients'
data. In this paper, we propose a novel framework, namely Personalized
Privacy-Preserving Federated Learning (PPPFL), with a concentration on
cross-silo FL to overcome these challenges. Specifically, we introduce a
stabilized variant of the Model-Agnostic Meta-Learning (MAML) algorithm to
collaboratively train a global initialization from clients' synthetic data
generated by Differential Private Generative Adversarial Networks (DP-GANs).
After reaching convergence, the global initialization will be locally adapted
by the clients to their private data. Through extensive experiments, we
empirically show that our proposed framework outperforms multiple FL baselines
on different datasets, including MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:24:08 GMT""}]","2023-02-24"
"2302.12023","Cameron Bunney","Cameron R. D. Bunney, Steffen Biermann, Vitor S. Barroso, August
  Geelmuyden, Cisco Gooding, Gr\'egoire Ithier, Xavier Rojas, Jorma Louko and
  Silke Weinfurtner","Third sound detectors in accelerated motion","10 pages, 4 figures. v2: Figure 2 axis amended, typos correct,
  abstract and introduction made clearer",,,,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An accelerated observer moving through empty space sees particles appearing
and disappearing, while an observer with a constant velocity does not register
any particles. This phenomenon, generally known as the Unruh effect, relies on
an initial vacuum state, thereby unifying the experience of all inertial
observers. We propose an experiment to probe this observer-dependent detector
response, using a laser beam in circular motion as a local detector of
superfluid helium-4 surface modes or third sound waves. To assess experimental
feasibility, we develop a theoretical framework to include a non-zero
temperature initial state. We find that an acceleration-dependent signal
persists, independent of the initial temperature. By introducing a
signal-to-noise measure we show that observing this signal is within
experimental reach.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:58:15 GMT""},{""version"":""v2"",""created"":""Thu, 30 Mar 2023 17:14:47 GMT""}]","2023-03-31"
"2302.12025","Jian-Zhou Zhu","Jian-Zhou Zhu","Similar oscillations on both sides of a shock. Part I. Even-odd
  alternative dispersions and general assignments of Fourier dispersions
  towards a unfication of dispersion models",,,,,"math-ph math.MP nlin.PS","http://creativecommons.org/licenses/by/4.0/","  We consider assigning different dispersions for different dynamical modes,
particularly with the distinguishment and alternation of opposite signs for
alternative Fourier components. The Korteweg-de Vries (KdV) equation with
periodic boundary condition and longest-wave sinusoidal initial field, as used
by N. Zabusky and M. D. Kruskal, is chosen for our case study with such
alternating-dispersion of the Fourier modes of (normalized) even and odd
wavenumbers. Numerical results verify the capability of our new model to
produce two-sided (around the shock) oscillations, as appear on both sides of
some ion-acoustic and quantum shocks, not admitted by models such as the
KdV(-Burgers) equation, but also indicate even more, including singular
zero-dispersion limit or non-convergence to the classical shock (described by
the entropy solution), non-thermalization (of the Galerkin-truncated models)
and applicability to other models (showcased by the modified KdV equation with
cubic nonlinearity). A unification of various dispersive models, keeping the
essential mathematical elegance (such as the variational principle and
Hamiltonian formulation) of each, for phenomena with complicated dispersion
relation is thus suggested with a further explicit example of two even-order
dispersions (from the Hilbert transforms) extending the Benjamin-Ono model. The
most general situation can be simply formulated by the introduction of the
dispersive derivative, the indicator function and the Fourier transform,
resulting in an integro-differential dispersion equation. Other issues such as
the real-number order dispersion model and the transition from
non-thermalization to thermalization and, correspondingly, from regularization
to non-regularization for untruncated models are also briefly remarked.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:23:02 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 16:43:41 GMT""},{""version"":""v3"",""created"":""Fri, 31 Mar 2023 16:56:13 GMT""}]","2023-04-03"
"2302.12028","Vincent Lemaire","Colin Troisemaine and Vincent Lemaire and St\'ephane Gosselin and
  Alexandre Reiffers-Masson and Joachim Flocon-Cholet and Sandrine Vaton","Novel Class Discovery: an Introduction and Key Concepts","30 pages",,,,"cs.LG","http://creativecommons.org/licenses/by/4.0/","  Novel Class Discovery (NCD) is a growing field where we are given during
training a labeled set of known classes and an unlabeled set of different
classes that must be discovered. In recent years, many methods have been
proposed to address this problem, and the field has begun to mature. In this
paper, we provide a comprehensive survey of the state-of-the-art NCD methods.
We start by formally defining the NCD problem and introducing important
notions. We then give an overview of the different families of approaches,
organized by the way they transfer knowledge from the labeled set to the
unlabeled set. We find that they either learn in two stages, by first
extracting knowledge from the labeled data only and then applying it to the
unlabeled data, or in one stage by conjointly learning on both sets. For each
family, we describe their general principle and detail a few representative
methods. Then, we briefly introduce some new related tasks inspired by the
increasing number of NCD works. We also present some common tools and
techniques used in NCD, such as pseudo labeling, self-supervised learning and
contrastive learning. Finally, to help readers unfamiliar with the NCD problem
differentiate it from other closely related domains, we summarize some of the
closest areas of research and discuss their main differences.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:07:01 GMT""}]","2023-02-24"
"2302.12093","Shuangning Li","Shuangning Li, Ramesh Johari, Stefan Wager, Kuang Xu","Experimenting under Stochastic Congestion",,,,,"eess.SY cs.SY math.OC stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stochastic congestion, a phenomenon in which a system becomes temporarily
overwhelmed by random surges in demand, occurs frequently in service
applications. While randomized experiments have been effective in gaining
causal insights and prescribing policy improvements in many domains, using them
to study stochastic congestion has proven challenging. This is because
congestion can induce interference between customers in the service system and
thus hinder subsequent statistical analysis. In this paper, we aim at getting
tailor-made experimental designs and estimators for the interference induced by
stochastic congestion. In particular, taking a standard queueing system as a
benchmark model of congestion, we study how to conduct randomized experiments
in a service system that has a single queue with an outside option. We study
switchback experiments and a local perturbation experiment and propose
estimators based on the experiments to estimate the effect of a system
parameter on the average arrival rate. We establish that the estimator from the
local perturbation experiment is asymptotically more accurate than the
estimators from the switchback experiments because it takes advantage of the
structure of the queueing system.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 01:57:37 GMT""}]","2023-02-24"
"2302.12095","Jindong Wang","Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong
  Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, Binxin Jiao, Yue Zhang,
  Xing Xie","On the Robustness of ChatGPT: An Adversarial and Out-of-distribution
  Perspective","Technical report; code is at:
  https://github.com/microsoft/robustlearn",,,,"cs.AI cs.CL cs.LG","http://creativecommons.org/licenses/by/4.0/","  ChatGPT is a recent chatbot service released by OpenAI and is receiving
increasing attention over the past few months. While evaluations of various
aspects of ChatGPT have been done, its robustness, i.e., the performance to
unexpected inputs, is still unclear to the public. Robustness is of particular
concern in responsible AI, especially for safety-critical applications. In this
paper, we conduct a thorough evaluation of the robustness of ChatGPT from the
adversarial and out-of-distribution (OOD) perspective. To do so, we employ the
AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart
review and DDXPlus medical diagnosis datasets for OOD evaluation. We select
several popular foundation models as baselines. Results show that ChatGPT shows
consistent advantages on most adversarial and OOD classification and
translation tasks. However, the absolute performance is far from perfection,
which suggests that adversarial and OOD robustness remains a significant threat
to foundation models. Moreover, ChatGPT shows astounding performance in
understanding dialogue-related texts and we find that it tends to provide
informal suggestions for medical tasks instead of definitive answers. Finally,
we present in-depth discussions of possible research directions.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 11:01:20 GMT""},{""version"":""v2"",""created"":""Mon, 27 Feb 2023 02:13:38 GMT""},{""version"":""v3"",""created"":""Thu, 2 Mar 2023 08:33:04 GMT""},{""version"":""v4"",""created"":""Wed, 29 Mar 2023 14:21:51 GMT""}]","2023-03-30"
"2302.12183","Delfim F. M. Torres","J. Vanterler da C. Sousa, D. S. Oliveira, Gastao S. F. Frederico,
  Delfim F. M. Torres","Existence, uniqueness and controllability for Hilfer differential
  equations on times scales","This is a 20 pages preprint of a paper whose final and definite form
  is published in 'Math. Meth. Appl. Sci.', Online ISSN: 1099-1476",,"10.1002/mma.9183",,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new version of $\psi$-Hilfer fractional derivative, on an
arbitrary time scale. The fundamental properties of the new operator are
investigated and, in particular, we prove an integration by parts formula.
Using the Laplace transform and the obtained integration by parts formula, we
then propose a $\psi$-Riemann-Liouville fractional integral on times scales.
The applicability of the new operators is illustrated by considering a
fractional initial value problem on an arbitrary time scale, for which we prove
existence, uniqueness and controllability of solutions in a suitable Banach
space. The obtained results are interesting and nontrivial even for particular
choices: (i) of the time scale; (ii) of the order of differentiation; and/or
(iii) function $\psi$; opening new directions of investigation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:12:02 GMT""}]","2023-02-28"
"2302.12191","Yuri Shimane","Yuri Shimane, Nick Gollins, Koki Ho","Orbital Facility Location Problem for Satellite Constellation Servicing
  Depots","Submitted to the Journal of Spacecraft and Rockets, 34 pages, 11
  figures",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  This work proposes an adaptation of the Facility Location Problem for the
optimal placement of on-orbit servicing depots for satellite constellations in
high-altitude orbit. The high-altitude regime, such as Medium Earth Orbit
(MEO), is a unique dynamical environment where existing low-thrust propulsion
systems can provide the necessary thrust to conduct plane-change maneuvers
between the various orbital planes of the constellation. As such, on-orbit
servicing architectures involving servicer spacecraft that conduct round-trips
between servicing depots and the client satellites of the constellation may be
conceived. To this end, orbital facility location problem is a binary linear
program, where the costs of operating and allocating the facility(ies) to
satellites are considered in terms of the sum of Equivalent Mass to Low Earth
Orbit (EMLEO), is proposed. The low-thrust transfers between the facilities and
the clients are computed using a parallel implementation of a Lyapunov feedback
controller. The total launch cost of the depot along with its servicers,
propellant, and payload are taken into account as the cost to establish a given
depot. The proposed approach is applied to designing on-orbit servicing depots
for the Galileo and the GPS constellations.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 20:41:18 GMT""},{""version"":""v2"",""created"":""Mon, 3 Apr 2023 13:29:46 GMT""}]","2023-04-04"
"2302.12652","Sergio Javier Bustos Ju\'arez","Sergio B. Ju\'arez","Quantum Information Geometry and its classical aspect","Master's thesis",,,,"quant-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis explores important concepts in the area of quantum information
geometry and their relationships. We highlight the unique characteristics of
these concepts that arise from their quantum mechanical foundations and
emphasize the differences from their classical counterparts. However, we also
demonstrate that for Gaussian states, classical analogs can be used to obtain
the same mathematical results, providing a valuable tool for simplifying
calculations.
  To establish the groundwork for the subsequent analysis, we introduce some
fundamental ideas from quantum field theory. We then explore the structure of
parameter space using the fidelity and the Quantum Geometric Tensor (QGT),
which is composed of the Quantum Metric Tensor and the Berry curvature. We also
introduce the Quantum Covariance Matrix (QCM) and show its relationship to the
QGT. We present how the QCM can be used to study entanglement between quantum
systems by obtaining the purity, linear entropy, and von Neumann entropy. To
illustrate these concepts, we calculate all these quantities for several
systems, including the Stern-Gerlach, a two qubits system, two symmetrically
coupled harmonic oscillators, and N coupled harmonic oscillators.
  In the final section of this thesis, we examine how the aforementioned
quantum concepts can be applied in a classical sense, following the approach
taken by Hannay with the Berry phase. We examine classical analogs of the QGT
and QCM and since for Gaussian states, all the necessary information to
calculate purity, linear entropy, and von Neumann entropy is contained within
the QCM, we also generate classical analogs for them. These results in turn can
be used to derive measures of separability for classical systems.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:39:02 GMT""}]","2023-02-27"
"2302.12722","Colin Orion Chandler","Colin Orion Chandler, William J. Oldroyd, Chadwick A. Trujillo,
  William A. Burris, Henry H. Hsieh, Jay K. Kueny, Michele T. Mazzucato, Milton
  K. D. Bosch, Tiffany Shaw-Diaz","New Active Asteroid 2015 VA108: A Citizen Science Discovery","4 pages, 1 figure","Res. Notes AAS 7 27 (2023)","10.3847/2515-5172/acbbce",,"astro-ph.EP","http://creativecommons.org/licenses/by/4.0/","  We announce the discovery of activity, in the form of a distinct cometary
tail, emerging from main-belt asteroid 2015 VA108. Activity was first
identified by volunteers of the Citizen Science project Active Asteroids (a
NASA Partner). We uncovered one additional image from the same observing run
which also unambiguously shows 2015 VA108 with a tail oriented between the
anti-solar and anti-motion vectors that are often correlated with activity
orientation on sky. Both publicly available archival images were originally
acquired UT 2015 October 11 with the Dark Energy Camera (DECam) on the Blanco 4
m telescope at the Cerro Tololo Inter-American Observatory (Chile) as part of
the Dark Energy Camera Legacy Survey. Activity occurred near perihelion and,
combined with its residence in the main asteroid belt, 2015 VA108 is a
candidate main-belt comet, an active asteroid subset known for volatile
sublimation.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:00:01 GMT""}]","2023-02-27"
"2302.14054","Qiaozhi Zha","Qiaozhi Zha, Diego Aliaga, Radovan Krejci, Victoria Sinclair, Cheng
  Wu, Wiebke Scholz, Liine Heikkinen, Eva Partoll, Yvette Gramlich, Wei Huang,
  Markus Leiminger, Joonas Enroth, Otso Per\""akyl\""a, Runlong Cai, Xuemeng
  Chen, Alkuin Maximilian Koenig, Fernando Velarde, Isabel Moreno, Tuukka
  Pet\""aj\""a, Paulo Artaxo, Paolo Laj, Armin Hansel, Samara Carbone, Markku
  Kulmala, Marcos Andrade, Douglas Worsnop, Claudia Mohr, Federico Bianchi","Oxidized organic molecules in the tropical free troposphere over
  Amazonia",,,,,"physics.ao-ph astro-ph.EP physics.geo-ph","http://creativecommons.org/licenses/by-nc-nd/4.0/","  New particle formation (NPF) in the tropical free troposphere (FT) is a
globally important source of cloud condensation nuclei, affecting cloud
properties and climate. Oxidized organic molecules (OOMs) produced from
biogenic volatile organic compounds are believed to contribute to aerosol
formation in the tropical FT, but without direct chemical observations. We
performed in-situ molecular-level OOMs measurements at the Bolivian station
Chacaltaya at 5240 meters above sea level, on the western edge of Amazonia. For
the first time, we demonstrate the presence of OOMs, mainly with 4-5 carbon
atoms, simultaneously in both gas and particulate phases in tropical FT air
from Amazonia. These observations, combined with air mass history analyses,
indicate that the observed OOMs are linked to isoprene emitted from the
rainforests hundreds of kilometers away. Based on particle-phase measurements,
we find that these compounds can contribute to the growth of newly formed
particles, and are potentially crucial for new particle formation in the
tropical free troposphere on a continental scale. Our study will thus improve
the understanding of aerosol formation process in the tropics.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 12:45:12 GMT""}]","2023-03-01"
"2302.14649","Dario Spiller","Dario Spiller, Gabriele Santin, Alessandro Sebastianelli, Lorenzo
  Lucchini, Riccardo Gallotti, Brennan Lake, Silvia Liberata Ullo, Bertrand Le
  Saux, Bruno Lepri","Analysis of COVID-19 first wave in the US based on demographic,
  mobility, and environmental variables","Submitted to the Scientific Reports, COVID-19 Collection, for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible",,,,"physics.soc-ph","http://creativecommons.org/licenses/by/4.0/","  COVID-19 had a strong and disruptive impact on our society, and yet further
analyses on most relevant factors explaining the spread of the pandemic are
needed. Interdisciplinary studies linking epidemiological, mobility,
environmental, and socio-demographic data analysis can help understanding how
historical conditions, concurrent social policies and environmental factors
impacted on the evolution of the pandemic crisis. This work deals with a
regression analysis linking COVID-19 mortality to socio-demographic, mobility,
and environmental data in the US during the first half of 2020, i.e., during
the COVID-19 pandemic first wave. This study can provide very useful insights
about risk factors enhancing mortality rates before non-pharmaceutical
interventions or vaccination campaigns took place. Our cross-sectional
ecological regression analysis demonstrates that, when considering the entire
US area, the socio-demographic variables globally play the most important role
with respect to environmental and mobility variables in describing COVID-19
mortality. Compared to the complete generalized linear model considering all
socio-demographic, mobility, and environmental data, the regression based only
on socio-demographic data provides a better approximation and proves to be a
better explanatory model when compared to the mobility-based and
environmental-based models. However, when looking at single entries within each
of the three groups, we see that the mobility data can become relevant
descriptive predictors at local scale, as in New Jersey where the time spent at
work is one of the most relevant explanatory variables, while environmental
data play contradictory roles.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:22:49 GMT""}]","2023-03-01"
"2302.14654","Aaron Hendrickson","Aaron Hendrickson, David P. Haefner, Nicholas R. Shade, Eric R. Fossum","Experimental Verification of PCH-EM Algorithm for Characterizing DSERN
  Image Sensors","8 pages, 9 figures",,,,"physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  The Photon Counting Histogram Expectation Maximization (PCH-EM) algorithm has
recently been reported as a candidate method for the characterization of Deep
Sub-Electron Read Noise (DSERN) image sensors. This work describes a
comprehensive demonstration of the PCH-EM algorithm applied to a DSERN capable
quanta image sensor. The results show that PCH-EM is able to characterize DSERN
pixels for a large span of quanta exposure and read noise values. The per-pixel
characterization results of the sensor are combined with the proposed Photon
Counting Distribution (PCD) model to demonstrate the ability of PCH-EM to
predict the ensemble distribution of the device. The agreement between
experimental observations and model predictions demonstrates both the
applicability of the PCD model in the DSERN regime as well as the ability of
the PCH-EM algorithm to accurately estimate the underlying model parameters.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 19:06:49 GMT""}]","2023-03-01"
"2302.14660","Rafael Ravedutti Lucio Machado","Rafael Ravedutti Lucio Machado, Jan Eitzinger, Jan Laukemann, Georg
  Hager, Harald K\""ostler, Gerhard Wellein","MD-Bench: Engineering the in-core performance of short-range molecular
  dynamics kernels from state-of-the-art simulation packages","17 pages, 10 figures, 5 tables. arXiv admin note: text overlap with
  arXiv:2207.13094",,,,"physics.chem-ph cs.PF physics.comp-ph","http://creativecommons.org/licenses/by/4.0/","  Molecular dynamics (MD) simulations provide considerable benefits for the
investigation and experimentation of systems at atomic level. Their usage is
widespread into several research fields, but their system size and timescale
are also crucially limited by the computing power they can make use of.
Performance engineering of MD kernels is therefore important to understand
their bottlenecks and point out possible improvements. For that reason, we
developed MD-Bench, a proxy-app for short-range MD kernels that implements
state-of-the-art algorithms from multiple production applications such as
LAMMPS and GROMACS. MD-Bench is intended to have simpler, understandable and
extensible source code, as well as to be transparent and suitable for teaching,
benchmarking and researching MD algorithms. In this paper we introduce
MD-Bench, describe its design and structure and implemented algorithms.
Finally, we show five usage examples of MD-Bench and describe how these are
useful to have a deeper understanding of MD kernels from a performance point of
view, also exposing some interesting performance insights.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 15:04:06 GMT""}]","2023-03-01"
"2302.14662","Yuanjing Ji","Yuanjing Ji, Zebo Tang, Chen Li, Xin Li, Ming Shao","A novel fast response and radiation-resistant scintillator detector for
  beam loss monitor",,"Journal of Instrumentation 12.07 (2017): C07042","10.1088/1748-0221/12/07/C07042",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  At high luminosity areas, beam loss monitor with fast response and high
radiation resistance is crucial for accelerator operation. In this article, we
report the design and test results of a fast response and radiation-resistant
scintillator detector as the beam loss monitor for high luminosity colliders,
especially at low energy regions such as RFQ. The detector consists of a 2 cm*2
cm 0.5 cm LYSO crystal readout by a 6 mm*6 mm Silicon photomultiplier. Test
results from various radioactive sources show that the detector has good
sensitivity to photons from tens of keV to several MeV with good linearity and
energy resolution (23% for 60 keV {\gamma}-ray). For the field test, two such
detectors are installed outside of the vacuum chamber shell of an 800 MeV
electron storage ring. The details of the test and results are introduced.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 23:48:19 GMT""}]","2023-03-01"
"2302.14829","Wei Fan","Wei Fan, Pengyang Wang, Dongkun Wang, Dongjie Wang, Yuanchun Zhou,
  Yanjie Fu","Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time
  Series Forecasting","Accepted by AAAI 2023",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The distribution shift in Time Series Forecasting (TSF), indicating series
distribution changes over time, largely hinders the performance of TSF models.
Existing works towards distribution shift in time series are mostly limited in
the quantification of distribution and, more importantly, overlook the
potential shift between lookback and horizon windows. To address above
challenges, we systematically summarize the distribution shift in TSF into two
categories. Regarding lookback windows as input-space and horizon windows as
output-space, there exist (i) intra-space shift, that the distribution within
the input-space keeps shifted over time, and (ii) inter-space shift, that the
distribution is shifted between input-space and output-space. Then we
introduce, Dish-TS, a general neural paradigm for alleviating distribution
shift in TSF. Specifically, for better distribution estimation, we propose the
coefficient net (CONET), which can be any neural architectures, to map input
sequences into learnable distribution coefficients. To relieve intra-space and
inter-space shift, we organize Dish-TS as a Dual-CONET framework to separately
learn the distribution of input- and output-space, which naturally captures the
distribution difference of two spaces. In addition, we introduce a more
effective training strategy for intractable CONET learning. Finally, we conduct
extensive experiments on several datasets coupled with different
state-of-the-art forecasting models. Experimental results show Dish-TS
consistently boosts them with a more than 20% average improvement. Code is
available.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:56:45 GMT""},{""version"":""v2"",""created"":""Thu, 9 Mar 2023 06:17:13 GMT""},{""version"":""v3"",""created"":""Tue, 14 Mar 2023 06:05:01 GMT""}]","2023-03-15"
"2303.02142","Marcello Musso","Marcello Musso (U. Salamanca) and Ravi K. Sheth (UPenn & ICTP)","Getting in shape with minimal energy. A variational principle for
  protohaloes","5 pages, 6 figures",,"10.1093/mnrasl/slad044",,"astro-ph.GA astro-ph.CO","http://creativecommons.org/licenses/by/4.0/","  In analytical models of structure formation, protohalos are routinely assumed
to be peaks of the smoothed initial density field, with the smoothing filter
being spherically symmetric. This works reasonably well for identifying a
protohalo's center of mass, but not its shape. To provide a more realistic
description of protohalo boundaries, one must go beyond the spherical picture.
We suggest that this can be done by looking for regions of fixed volume, but
arbitrary shape, that minimize the enclosed energy. Such regions are surrounded
by surfaces over which (a slightly modified version of) the gravitational
potential is constant. We show that these equipotential surfaces provide an
excellent description of protohalo shapes, orientations and associated torques.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 07:04:36 GMT""}]","2023-04-12"
"2303.02156","Jos\'e Antonio Fern\'andez-Fern\'andez","Jos\'e Antonio Fern\'andez-Fern\'andez and Fabian L\""oschner and Lukas
  Westhofen and Andreas Longva and Jan Bender","SymX: Energy-based Simulation from Symbolic Expressions",,,,,"cs.CE cs.GR","http://creativecommons.org/licenses/by/4.0/","  Optimization time integrators have proven to be effective at solving complex
multi-physics problems, such as deformation of solids with non-linear material
models, contact with friction, strain limiting, etc. For challenging problems
with high accuracy requirements, Newton-type optimizers are often used. This
necessitates first- and second-order derivatives of the global non-linear
objective function. Manually differentiating, implementing and optimizing the
resulting code is extremely time-consuming, error-prone, and precludes quick
changes to the model.
  We present SymX, a framework based on symbolic expressions that computes the
first and second derivatives by symbolic differentiation, generates efficient
vectorized source code, compiles it on-the-fly, and performs the global
assembly of element contributions in parallel. The user only has to provide the
symbolic expression of an energy function for a single element in the
discretization and our system will determine the assembled derivatives for the
whole model. SymX is designed to be an integral part of a simulation system and
can easily be integrated into existing ones. We demonstrate the versatility of
our framework in various complex simulations showing different non-linear
materials, higher-order finite elements, rigid body systems, adaptive cloth,
frictional contact, and coupling multiple interacting physical systems.
Moreover, we compare our method with alternative approaches and show that SymX
is significantly faster than a current state-or-the-art framework (up to two
orders of magnitude for a higher-order FEM simulation).
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:53:34 GMT""}]","2023-03-07"
"2303.03120","Antoine Chan-Lock","Antoine Chan-Lock, Jesus Perez, Miguel Otaduy","High-Order Elasticity Interpolants for Microstructure Simulation","Published at Computer Graphics Forum (Proc. of ACM/SIGGRAPH SCA),
  2022. Project website http://mslab.es/projects/HiOInterp/",,,,"cs.CE cs.GR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We propose a novel formulation of elastic materials based on high-order
interpolants, which fits accurately complex elastic behaviors, but remains
conservative. The proposed high-order interpolants can be regarded as a
high-dimensional extension of radial basis functions, and they allow the
interpolation of derivatives of elastic energy, in particular stress and
stiffness. Given the proposed parameterization of elasticity models, we devise
an algorithm to find optimal model parameters based on training data. We have
tested our methodology for the homogenization of 2D microstructures, and we
show that it succeeds to match complex behaviors with high accuracy.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:42:35 GMT""}]","2023-03-07"
"2303.06054","Vasily Shaginyan","V.R. Shaginyan, A.Z. Msezane, G.S. Japaridze","Comment on paper: Evidence for Dirac flat band superconductivity enabled
  by quantum geometry, Nature 614, 440 (2023)","1 page",,,,"cond-mat.supr-con cond-mat.str-el","http://creativecommons.org/licenses/by/4.0/","  We demonstrate that an absolutely flat band retains the superconducting state
at $T_c\to 0$. When $T_c>0$ the flat band disappears, since it must be modified
by the superconducting state. Thus, a number of the results on ultra-strong
coupling superconductivity in flat band considered in the article (""Evidence
for Dirac flat band superconductivity enabled by quantum geometry"", Nature 614,
440 (2023)) were predicted and explained many years ago. One has to take into
account that at $T_c>0$ the flat band distorts, becoming tilted. As a result,
the charge carriers' velocity $v_F\propto T_c$ becomes finite, rather than
being extremely slow, as it is stated in the article. Thus, the statement ""the
charge carriers' group velocity $v_ F$ is extremely slow"" is incorrect and
leads the authors to the conceptional misunderstanding, confusing the reader.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 14:47:33 GMT""},{""version"":""v2"",""created"":""Sat, 18 Mar 2023 19:22:15 GMT""},{""version"":""v3"",""created"":""Tue, 11 Apr 2023 22:34:05 GMT""}]","2023-04-13"
"2303.06065","Ssu-Ying Chen","Ssu-Ying Chen, Camelia Prodan","Symmetry-Preserving Coupling Method for Topological Acoustic
  Metamaterials","7 pages, 5 figures",,,,"physics.app-ph","http://creativecommons.org/licenses/by/4.0/","  In this paper we investigate different types of couplings used in acoustic
metamaterials requiring preservation of symmetries. For testing we use the SSH
model to test whether topologically edge and interface modes are supported with
the different types of connection. We observed that a modular platform where
the resonators are coupled through the bottom is the simplest method that is
accurate and flexible.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 17:50:58 GMT""}]","2023-03-13"
"2303.17509","Eric Schwitzgebel","Eric Schwitzgebel","The Full Rights Dilemma for A.I. Systems of Debatable Personhood",,,,,"cs.CY cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An Artificially Intelligent system (an AI) has debatable personhood if it's
epistemically possible either that the AI is a person or that it falls far
short of personhood. Debatable personhood is a likely outcome of AI development
and might arise soon. Debatable AI personhood throws us into a catastrophic
moral dilemma: Either treat the systems as moral persons and risk sacrificing
real human interests for the sake of entities without interests worth the
sacrifice, or don't treat the systems as moral persons and risk perpetrating
grievous moral wrongs against them. The moral issues become even more
perplexing if we consider cases of possibly conscious AI that are subhuman,
superhuman, or highly divergent from us in their morally relevant properties.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 18:10:18 GMT""}]","2023-03-31"
"2304.01345","Selena (Shuo) Wang","Selena Wang, Yiting Wang, Frederick H. Xu, Li Shen, Yize Zhao (and for
  the Alzheimer's Disease Neuroimaging Initiative)","Establishing group-level brain structural connectivity incorporating
  anatomical knowledge under latent space modeling",,,,,"q-bio.NC stat.ME","http://creativecommons.org/licenses/by/4.0/","  Brain structural connectivity, capturing the white matter fiber tracts among
brain regions inferred by diffusion MRI (dMRI), provides a unique
characterization of brain anatomical organization. One fundamental question to
address with structural connectivity is how to properly summarize and perform
statistical inference for a group-level connectivity architecture, for
instance, under different sex groups, or disease cohorts. Existing analyses
commonly summarize group-level brain connectivity by a simple entry-wise sample
mean or median across individual brain connectivity matrices. However, such a
heuristic approach fully ignores the associations among structural connections
and the topological properties of brain networks. In this project, we propose a
latent space-based generative network model to estimate group-level brain
connectivity. We name our method the attributes-informed brain connectivity
(ABC) model, which compared with existing group-level connectivity estimations,
(1) offers an interpretable latent space representation of the group-level
connectivity, (2) incorporates the anatomical knowledge of nodes and tests its
co-varying relationship with connectivity and (3) quantifies the uncertainty
and evaluates the likelihood of the estimated group-level effects against
chance. We devise a novel Bayesian MCMC algorithm to estimate the model. By
applying the ABC model to study brain structural connectivity stratified by sex
among Alzheimer's Disease (AD) subjects and healthy controls incorporating the
anatomical attributes (volume, thickness and area) on nodes, our method shows
superior predictive power on out-of-sample structural connectivity and
identifies meaningful sex-specific network neuromarkers for AD.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 21:20:56 GMT""}]","2023-04-05"
"2304.11058","Ankan Mullick","Ankan Mullick","Novel Intent Detection and Active Learning Based Classification (Student
  Abstract)","AAAI 2023 Student Abstract",,,,"cs.CL cs.IR","http://creativecommons.org/licenses/by/4.0/","  Novel intent class detection is an important problem in real world scenario
for conversational agents for continuous interaction. Several research works
have been done to detect novel intents in a mono-lingual (primarily English)
texts and images. But, current systems lack an end-to-end universal framework
to detect novel intents across various different languages with less human
annotation effort for mis-classified and system rejected samples. This paper
proposes NIDAL (Novel Intent Detection and Active Learning based
classification), a semi-supervised framework to detect novel intents while
reducing human annotation cost. Empirical results on various benchmark datasets
demonstrate that this system outperforms the baseline methods by more than 10%
margin for accuracy and macro-F1. The system achieves this while maintaining
overall annotation cost to be just ~6-10% of the unlabeled data available to
the system.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 13:04:17 GMT""}]","2023-04-24"
"2304.13522","Christian Anti\'c","Christian Anti\'c","Sequential decomposition of propositional logic programs","arXiv admin note: text overlap with arXiv:2109.05300,
  arXiv:2009.05774",,,,"cs.LO cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The sequential composition of propositional logic programs has been recently
introduced. This paper studies the sequential {\em decomposition} of programs
by studying Green's relations $\mathcal{L,R,J}$ -- well-known in semigroup
theory -- between programs. In a broader sense, this paper is a further step
towards an algebraic theory of logic programming.
","[{""version"":""v1"",""created"":""Tue, 21 Feb 2023 16:14:57 GMT""}]","2023-04-27"
"2305.01551","Karimjon Sabirov","K.K. Sabirov, R.R. Ashurov","A derivation of boundary conditions for the space-fractional operator
  with order $0<\alpha<1$ at the vertices of metric graphs",,,,,"math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the space-fractional operator with order $0<\alpha<1$ on the
metric star graph. The boundary conditions at the vertices of the metric star
graph providing the self-adjointness of the operator are derived. The obtained
result is extended to the other topologies of the metric graphs.
","[{""version"":""v1"",""created"":""Wed, 22 Feb 2023 10:28:37 GMT""}]","2023-05-03"
